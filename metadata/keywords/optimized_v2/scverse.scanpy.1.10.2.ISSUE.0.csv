quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability," ![tmpdm8256t1](https://user-images.githubusercontent.com/8238804/144899323-c439785d-5d57-4a18-b6e5-2b12412465f8.PNG); > ; > Instead of having an argument which changes the interpretation of the earlier arguments, I would prefer more orthogonal arguments.; > ; > I think you'd be able to get an output close to what you would currently like with:; > ; > ```python; > import scanpy as sc, pandas as pd, numpy as np; > ; > pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); > pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); > df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]); > ; > summarized = df.pivot_table(; > index=[""louvain"", ""sampleid""],; > values=""LDHB"",; > aggfunc=[np.mean, np.count_nonzero]; > ); > color_df = summarized[""mean""].unstack(); > size_df = summarized[""count_nonzero""].unstack(); > ; > # I don't think the var_names or groupby variables are actually important here; > sc.pl.DotPlot(; > pbmc,; > var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; > dot_color_df=color_df, dot_size_df=size_df,; > ).style(cmap=""Reds"").show(); > ```; > ; > I think this functionality could be more generic, and inspired by the `pd.pivot_table` function. This could end up looking like:; > ; > ```python; > # Imaginary implementation:; > sc.pl.heatmap(; > pbmc,; > var_names=""LDHB"",; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144901891-45c3a8aa-1b56-4521-abc1-66f968a59d23.png); > ; > ```python; > sc.pl.heatmap(; > pbmc,; > var_names=[""LDHB"", ""LYZ"", ""CD79A""],; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png); > ; > What do you think about that?. Thanks @ivirshup !. I like these lines you suggested- perhaps I can adopt to make it more elegant when creating color_df/size_df:; ```; import scanpy as sc, pandas as pd, numpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664:1756,error,error,1756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664,1,['error'],['error']
Availability, 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:5903,error,error,5903,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability," 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'genome'; ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA; on highly variable genes; with n_comps=30; finished (0:01:25); computing neighbors; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:04); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:18); running Leiden clustering; finished: found 23 clusters and added; 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04); ```; But when I check my anndata, none present. As such if I try to generate a umap image I get the following error; ```; AnnData object with n_obs × n_vars = 28752 × 22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'; uns: 'genome', 'log1p', 'hvg'; ```. ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; ```pytb; raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm""; ```. #### Versions. <details>. [-----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.2.0; PyQt5 NA; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330:1527,error,error,1527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330,1,['error'],['error']
Availability, 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23127,mask,mask-,23127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_re,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22717,mask,mask-,22717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1988,ERROR,ERROR,1988,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31) ===============. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:75148,ERROR,ERROR,75148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,6,"['ERROR', 'error']","['ERROR', 'errors']"
Availability," (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:2656,error,error,2656,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability, (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2517,ERROR,ERROR,2517,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; --> 158 raise ValueError(; 159 f""Key {k} could be found in both .{idxdim}_names and .{coldim}.columns""; 160 ). ValueError: Key var_id could be found in both .var_names and .obs.columns; ```. ## Repeats in var_names. When there are repeats in `var_names` (pretty frequent occurence), getting a dataframe with keys that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:4516,error,errors,4516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability," 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key); 125 ; 126 key = com._apply_if_callable(key, self.obj); --> 127 return self._getitem_axis(key, axis=axis); 128 ; 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1106 return self._get_loc(key, axis=axis); 1107 ; -> 1108 return self._get_label(key, axis=axis); 1109 ; 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis); 143 raise IndexingError('no slices here, handle elsewhere'); 144 ; --> 145 return self.obj._xs(label, axis=axis); 146 ; 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level); 2342 drop_level=drop_level); 2343 else:; -> 2344 loc = self.index.get_loc(key); 2345 ; 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2525 return self._engine.get_loc(key); 2526 except KeyError:; -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2528 ; 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, ; Olivia**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109:2309,toler,tolerance,2309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109,3,['toler'],['tolerance']
Availability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2104,ERROR,ERROR,2104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2983,ERROR,ERROR,2983,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability," 678 colors = ['dpt_pseudotime']; --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']; 680 if color is not None: colors = color; 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key); 2137 return self._getitem_multilevel(key); 2138 else:; -> 2139 return self._getitem_column(key); 2140 ; 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2144 # get column; 2145 if self.columns.is_unique:; -> 2146 return self._get_item_cache(key); 2147 ; 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 1840 res = cache.get(item); 1841 if res is None:; -> 1842 values = self._data.get(item); 1843 res = self._box_item_values(item, values); 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath); 3841 ; 3842 if not isna(item):; -> 3843 loc = self.items.get_loc(item); 3844 else:; 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2525 return self._engine.get_loc(key); 2526 except KeyError:; -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2528 ; 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'; ```. ---; scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:3024,toler,tolerance,3024,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,3,['toler'],['tolerance']
Availability," 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 255 # ]; 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):; --> 257 color_source_vector = _get_color_source_vector(; 258 adata,; 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1165 ] # TODO: Throw helpful error if this doesn't work; 1166 if use_raw and value_to_plot not in adata.obs.columns:; -> 1167 values = adata.raw.obs_vector(value_to_plot); 1168 else:; 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:2691,error,error,2691,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,1,['error'],['error']
Availability," = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver=""arpack""); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50); sc.tl.leiden(adata, resolution=1.0); sc.tl.paga(adata, groups=""leiden""); sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]); adata.uns['iroot']=0; sc.tl.dpt(adata). import matplotlib.pyplot as plt; fig,ax=plt.subplots(1,1,figsize=(7,1)); path_data = sc.pl.paga_path(; adata,; [4, 5],; [""Elane""],; ax=ax,; show_node_names=False,; ytick_fontsize=12,; return_data=True,; #n_avg=1,; color_map=""Greys"",; groups_key=""leiden"",; color_maps_annotations={""dpt_pseudotime"": ""viridis""}; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[1], line 15; 13 import matplotlib.pyplot as plt; 14 fig,ax=plt.subplots(1,1,figsize=(7,1)); ---> 15 path_data = sc.pl.paga_path(; 16 adata,; 17 [4, 5],; 18 [""Elane""],; 19 ax=ax,; 20 show_node_names=False,; 21 ytick_fontsize=12,; 22 return_data=True,; 23 #n_avg=1,; 24 color_map=""Greys"",; 25 groups_key=""leiden"",; 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}; 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:1446,Error,Error,1446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['Error'],['Error']
Availability," @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you might want to check that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:1210,error,error,1210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664,1,['error'],['error']
Availability," A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/.virtualenvs/pytorch_latest/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078:1381,ERROR,ERROR,1381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078,1,['ERROR'],['ERROR']
Availability," Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` takes 334s, while Dask with `scipy.sparse` takes 138s, a 2.4x speedup. That's a significant speedup, but I'm not sure that it justifies the code overhead. I'd be interested to hear what others think. . ### Other notes. #### Code; See this branch: https://github.com/theislab/scanpy/compare/master...tomwhite:sparse-dask. #### CuPy and GPUs; I also wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_cupy_sparse.py) around the GPU equivalent of `scipy.sparse`, [`cupyx.scipy.sparse`](https://docs-cupy.chainer.org/en/stable/reference/sparse.html). Many operations work, however `cupyx.scipy.sparse` has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:; * `multiply` - not implemented by `cupyx.scipy.sparse.csr.csr_matrix`; * `mean` - no method on `cupyx.scipy.sparse.csr.csr_matrix` (note that it does have `sum`); * column subset not supported, e.g. `xs[:, 1:3]` (note that row subset is); * boolean indexing, i.e. `xs[:, subset]`, where `subset` is e.g. `np.array([True, False, True, False, True])`; note this fails for rows too. #### NumPy 1.16 vs NumPy 1.17; I used NumPy 1.16 for the above experiments. However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921:3294,down,down,3294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921,1,['down'],['down']
Availability, AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image fi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48199,Error,Error,48199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability, ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2862,ERROR,ERROR,2862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability, ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74329,ERROR,ERROR,74329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability, ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68924,ERROR,ERROR,68924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability," Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. **The problem is the error in importing gene names both when using id and when using symbolic labeling. All genes have the same name. if you use `anndata=0.10.3` instead of `anndata=0.10.4`, then everything works correctly.**. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib; import seaborn as sns. path='<path_to_files>'. adata = sc.read_10x_mtx(; path, ; var_names='gene_symbols', ; cache=True). adata.var_names_make_unique(). adata.var; ```. ### Error output. ```pycon; >>> # then anndata=0.10.4; >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. ### Expected. ```pycon; >>> # then anndata=0.10.3; >>> print(adata.var); gene_ids feature_types; 4933401J01Rik ENSMUSG00000102693 Gene Expression; Gm26206 ENSMUSG00000064842 Gene Expression; Xkr4 ENSMUSG00000051951 Gene Expression; Gm18956 ENSMUSG00000102851 Gene Expression; Gm37180 ENSMUSG00000103377 Gene Expression; ... ... ...; mt-Nd6 ENSMUSG00000064368 Gene Expression; mt-Te ENS",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:7240,Error,Error,7240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['Error'],['Error']
Availability," I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:943,error,error,943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,3,"['ERROR', 'error']","['ERROR', 'error', 'errored']"
Availability, ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9412,ERROR,ERROR,9412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," In certain combinations of `groupby` variables, some valuese get lost. . I wasn't able to make a minimal reproducible example, but I obfuscated the `obs` table of my real data and can share it here: ; https://www.dropbox.com/scl/fi/jsbrb2ulki7mmih2242kc/adata_aggregate_bug.h5ad?rlkey=qczuaf2v5vlwb00zyuxmzjkix&dl=1. ### Minimal code sample. ```python; >>> test_adata = sc.read_h5ad(""adata_aggregate_bug.h5ad""). >>> test_adata.obs[""patient_id""].nunique(); 69. >>> test_adata.obs.isnull().sum(); patient_id 0; timepoint 0; external_batch_id 0; dtype: int64. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 15. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69; ```. ### Error output. ```pytb; So only if using all three variables, some patient IDs are lost. I don't see why this would be happening.; ```. ### Versions. <details>. ```; Package Version Editable project location; ------------------------- --------------- -------------------------------------------------------------------------------------------------------------------------; aiohttp 3.9.3; aiosignal 1.3.1; anndata 0.10.5.post1; anyio 4.3.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array_api_compat 1.5; arrow 1.3.0; asciitree 0.3.3; asttokens 2.4.1; async-lru 2.0.4; async-timeout 4.0.3; attrs 23.2.0; Babel 2.14.0; beautifulsoup4 4.12.3; bleach 6.1.0; bokeh 3.3.4; branca 0.7.1; Brotli 1.1.0; cached-property 1.5.2; cachetools 5.3.3; certifi 2024.2.2; cffi 1.16.0; charset-normalizer 3.3.2; click 8.1.7; click-plugins 1.1.1; cligj 0.7.2; cloudpickle 3.0.0; colorama 0.4.6; colorcet 3.1.0; comm 0.2.1; confluent-kafka 1.9.2; contourpy 1.2.0; cubinlinker 0.3.0; cucim 24.2.0; cuda-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964:1368,Error,Error,1368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964,1,['Error'],['Error']
Availability," This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 32",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:1496,error,error,1496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2542,ERROR,ERROR,2542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3421,ERROR,ERROR,3421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability," \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/cat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2444,down,downcast,2444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['down'],['downcast']
Availability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3679,Toler,Tolerance,3679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,"['Error', 'Toler']","['Error', 'Tolerance']"
Availability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1839,error,errors,1839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183,3,['error'],"['error', 'errors']"
Availability," `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2365:1647,Down,Download,1647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365,1,['Down'],['Download']
Availability," ```python; > sc.pl.heatmap(; > pbmc,; > var_names=[""LDHB"", ""LYZ"", ""CD79A""],; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png); > ; > What do you think about that?. Thanks @ivirshup !. I like these lines you suggested- perhaps I can adopt to make it more elegant when creating color_df/size_df:; ```; import scanpy as sc, pandas as pd, numpy as np. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]). summarized = df.pivot_table(; index=[""louvain"", ""sampleid""],; values=""LDHB"",; aggfunc=[np.mean, np.count_nonzero]; ); color_df = summarized[""mean""].unstack(); size_df = summarized[""count_nonzero""].unstack(). # I don't think the var_names or groupby variables are actually important here; sc.pl.DotPlot(; pbmc,; var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; dot_color_df=color_df, dot_size_df=size_df,; ).style(cmap=""Reds"").show(); ```; this is the output:; ![image](https://user-images.githubusercontent.com/10910559/145053489-c550d5a7-a8fe-4a61-b672-9103ccf1d228.png); some work are needed to modify the grid/axis size, legend and scale. Actually this is the reason I work on top of the _dotplot and _baseplot function/ classes to implement the solution- to make the plots the same style with scanpy dotplot without doing too much work on the cosmetics. But I can certainly change grouby_expand from bool to an actual variable `group_cols` as you suggested in #2055 . Or should we call it `col_groups` as you did in your sc.pl.heatmap pseudo code? ; I'd be more than happy to make it more generalized, i.e., to sc.pl.heatmap, but I may need some time to understand sc.pl.heatmap first. The plotting functions are getting really complex- it took me some time to understand _dotplot and _baseplot :). Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664:3309,error,error,3309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664,1,['error'],['error']
Availability," ```python; sc.pl.spatial(adata, color=""leiden"", groups=[""0""]); ```; <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons; - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object; - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:; ```python; if img is _empty:; 	ax.invert_yaxis(); ```; This is the behviour; ```python; sc.pl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514:2755,avail,available,2755,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514,2,['avail'],['available']
Availability," ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782:1389,error,error,1389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782,1,['error'],['error']
Availability," `from skmisc.loess import loess`; ```python; from skmisc.loess import loess; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4345,Down,Downloads,4345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,2,['Down'],['Downloads']
Availability," `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ""9""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:346: in impl; if min_ver i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1212,error,error,1212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,2,['error'],['error']
Availability," a year ago for various reasons (see below). Meanwhile, the following two functions can maybe direcly imported from UMAP, if not, we could make a PR there or use pynndescent?; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. There is a chance that this can also be solved with an import from UMAP.; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. As just discussed, @Koncopd, can you look into this and make a PR that gets rid of the umap legacy code?. Thank you so much!; Alex. PS: Just wrote an explanation for the reasons why I intorduced the duplicated code in the first place.; > The duplicated code in Scanpy came about as I wanted to very quickly move forward with a version 1.0 of Scanpy about a year ago. UMAP was just becoming available on GitHub and there wasn’t even a preprint, I think. It changed very quickly and there were dramatic bugs every now and then. Nonetheless it was clear that it’s a major improvement over existing solutions, both in terms of computational performance, quality of the result and ease of installation and use. I wanted to achieve two things: (i) I had to rewrite some parts of UMAP so that I could decompose it a neighbors computing and a dedicated embedding step; you know that in Scanpy, the neighborhood graph is used for many other things other than for the embedding (clustering and trajectory inference). I also added the Gaussian kernel solution that I had before switching to a “UMAP backend” for `pp.neighbors`; which was needed so that results for DPT could be reproduced. All of this would have been quite a discussion with Leland. Until we would have had settled on the “Scanpy needs” that certainly weren’t aligned with the development of an independent young package, PRs would have been integrated ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522:1068,avail,available,1068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522,1,['avail'],['available']
Availability," adata.var_names.str.startswith('mt'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'); sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the follow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:1736,error,error,1736,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['error'],['error']
Availability," are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Basically I am creating a stacked violin plot that uses a list of marker genes for the ""var_names"" argument. But whenever I create the plot, it has extra whitespace at the top of the plot where the marker gene labels should go. This is very evident when you add a figure title, which gets place above the padding whitespace. I have not really found a way around this, and am currently looking through the scanpy internal code to see if there is some padding setting that I can undo. If there is a workaround to this or some option that I am missing I would like to know. Thanks!. ### Minimal code sample. ```py; # I have an AnnData object that has undergone the Seurat analysis. I named the Leiden clustering output ""spatial_clusters"" since I was testing a spatial dataset read in via spatialdata then converted to AnnData with ""spatialdata_io.experimental.to_legacy_anndata"". marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. sc.pl.stacked_violin(adata, marker_genes, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). ### COMPARISON TO MARKER GENES WITH LABELS; marker_genes = {""IHC"": [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1""], ""Random"": [""Sox2""]}. sc.pl.stacked_violin(adata, marker_genes, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). ```. ### Error output. Will post in the next comment on this thread. Seems I cannot drag-n-drop images into this block. ### Versions. <details>. I am including relevant package versions. Can provide more if needed. Python 3.12.7. ```; anndata==0.10.6; matplotlib==3.9.0; pandas==2.2.1; scanpy-1.10.3; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3320:1730,Error,Error,1730,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320,1,['Error'],['Error']
Availability," as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```; # First run on a machine on with 8 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences betw",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409:1160,echo,echo,1160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409,1,['echo'],['echo']
Availability," as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4686,error,error,4686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['error'],['error']
Availability," as_heatmap:; 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 245 timeseries_as_heatmap(; 246 adata.X[adata.obs[""dpt_order_indices""].values],; 247 var_names=adata.var_names,; 248 highlights_x=adata.uns[""dpt_changepoints""],; 249 color_map=color_map,; 250 ); 251 else:; 252 # plot time series as gene expression vs time; 253 timeseries(; 254 adata.X[adata.obs[""dpt_order_indices""].values],; 255 var_names=adata.var_names,; (...); 258 marker=marker,; 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 223 x_new[:, _hold:] = X[:, hold:]; 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)); 226 img = ax.imshow(; --> 227 np.array(X, dtype=np.float_),; 228 aspect=""auto"",; 229 interpolation=""nearest"",; 230 cmap=color_map,; 231 ); 232 plt.colorbar(img, shrink=0.5); 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence.; ```. Error in dpt_groups_pseudotime:. ```pytb; ValueError Traceback (most recent call last); Cell In[91], line 1; ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker); 274 """"""Plot groups and pseudotime.""""""; 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1); --> 276 timeseries_subplot(; 277 adata.obs[""dpt_groups""].cat.codes,; 278 time=adata.obs[""dpt_order""].values,; 279 color=np.asarray(adata.obs[""dpt_groups""]),; 280 highlights_x=adata.uns[""dpt_changepoints""],; 281 ylabel=""dpt groups"",; 282 yticks=(;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:2635,Error,Error,2635,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,1,['Error'],['Error']
Availability," checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python; adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); Cell In[2], line 6; 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'; 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'; ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path); 387 logg.warning(; 388 f""You seem to be missing an image file.\n""; 389 f""Could not find '{f}'.""; 390 ); 391 else:; --> 392 raise OSError(f""Could not find '{f}'""); 394 adata.uns[""spatial""][library_id][""images""] = dict(); 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3085:1055,Error,Error,1055,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085,1,['Error'],['Error']
Availability," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/884:1562,error,error,1562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884,1,['error'],['error']
Availability," conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2730:1022,Error,Error,1022,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730,1,['Error'],['Error']
Availability," data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2381:1946,error,error,1946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381,1,['error'],['error']
Availability," data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2210,down,downcast,2210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,2,['down'],['downcast']
Availability," dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isn’t great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setupto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2744:1648,Error,Error,1648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744,1,['Error'],['Error']
Availability, errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image fil,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1196,Error,Error,1196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1639,down,downstream,1639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,1,['down'],['downstream']
Availability, files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3678,Error,Error,3678,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability, from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14569,mask,mask-,14569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residua,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16474,mask,mask-,16474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability," has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python; import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, ; 'celltypes',; key_added = 'wilcoxon',; reference = 'PT',; layer = 'data',; method='wilcoxon',; pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, ; group = 'aPT', ; key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],; ascending = False ). sc.tl.rank_genes_groups( rna_ann, ; 'celltypes',; key_added = 'wilcoxon2',; reference = 'PT',; layer = 'data',; method='wilcoxon',; pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, ; group = 'aPT', ; key = 'wilcoxon2', ); ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">; <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.1; -----; PIL 9.2.0; anyio NA; argcomplete NA; arrow 1.3.0; asciitree NA; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.13.0; backcall 0.2.0; bamnostic NA; brotli 1.0.9; certifi 2024.06.02; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3.3.0; cloudpickle 3.0.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3106:1079,Error,Error,1079,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106,1,['Error'],['Error']
Availability, import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2295,ERROR,ERROR,2295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability, import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47815,Error,Error,47815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability," improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1095,Error,Error,1095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability," issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Trying to store normalised values in a layer 'normalised', then plot from that layer with sc.pl.highest_expr_genes(). But the function fails with the layer parameter. ### Minimal code sample. ```py; import numpy as np; import pandas as pd; import anndata as ad. # Create a small data matrix; data = np.random.rand(10, 5). # Create observation (cell) and variable (gene) annotations; obs = pd.DataFrame(index=[f'Cell_{i}' for i in range(data.shape[0])]); var = pd.DataFrame(index=[f'Gene_{i}' for i in range(data.shape[1])]). # Create the AnnData object; adata = ad.AnnData(X=data, obs=obs, var=var). # Test layer call function; adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test; sc.pl.highest_expr_genes(adata, layer='normalised'); ```. ### Error output. ```pytb; Output exceeds the size limit. Open the full output data in a text editor; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[32], line 17; 15 # Test layer call function; 16 adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test; ---> 17 sc.pl.highest_expr_genes(adata, layer='normalised'); 19 # Test layer call function; 20 adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test. File c:\Users\U062951\Miniconda3\envs\imc_ome_v1_spatial\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File c:\Users\U062",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3318:1073,Error,Error,1073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318,1,['Error'],['Error']
Availability," it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```; $ conda create -yn flit-deps python=3.8 flit; $ conda activate flit-deps; $ flit install -s --dep=develop # Make development install of scanpy; $ pip install scvelo # Install project that depends on scanty; ...; Attempting uninstall: scanpy; Found existing installation: scanpy 1.8.0.dev49-ge715cd98; Uninstalling scanpy-1.8.0.dev49-ge715cd98:; Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98; ...; # Development version of scanpy has now been uninstalled; ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852:1816,error,error,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852,1,['error'],['error']
Availability," making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):; <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):; <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(); ```. ### Error output. ```pytb; (Error output is a bad plot, included in the description above.); ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; IPython 8.13.2; PIL 10.0.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.10.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; dot_parser NA; entrypoints 0.4; exceptiongroup 1.1.1; executing 1.2.0; fasteners 0.17.3; flytekitplugins NA; gmpy2 2.1.2; google NA; h5py 3.8.0; icu 2.11; igraph 0.11.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.8.3; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; natsort 8.3.1; numba 0.59.1; numcodecs 0.11.0; numexpr 2.7.3; numpy 1.26.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; plotly 5.14.1; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062:1932,Error,Error,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062,1,['Error'],['Error']
Availability," mangled = func(compiler_state); 274 if mangled not in (True, False):; 275 msg = (""CompilerPass implementations should return True/False. "". C:\ProgramData\Anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 392 lower = lowering.Lower(targetctx, library, fndesc, interp,; 393 metadata=metadata); --> 394 lower.lower(); 395 if not flags.no_cpython_wrapper:; 396 lower.create_cpython_wrapper(flags.release_gil). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 166 if self.generator_info is None:; 167 self.genlower = None; --> 168 self.lower_normal_function(self.fndesc); 169 else:; 170 self.genlower = self.GeneratorLower(self). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc); 220 # Init argument values; 221 self.extract_function_arguments(); --> 222 entry_block_tail = self.lower_function_body(); 223 ; 224 # Close tail of entry block, do not emit debug metadata else the. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self); 249 bb = self.blkmap[offset]; 250 self.builder.position_at_end(bb); --> 251 self.lower_block(block); 252 self.post_lower(); 253 return entry_block_tail. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 263 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block); 267 . C:\ProgramData\Anaconda3\lib\contextlib.py in __exit__(self, typ, value, traceback); 135 value = typ(); 136 try:; --> 137 self.gen.throw(typ, value, traceback); 138 except StopIteration as exc:; 139 # Suppress StopIteration *unless* it's the same exception that. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 835 else:; 836 tb = None; --> 837 raise newerr.with_traceback(tb); 838 elif use_new_style_errors():; 839 raise e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:11687,error,errors,11687,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability," matplotlib; >>> import seaborn as sns; >>> !ls -lh ./H004/; -rwxrwxrwx. 1 nikolay nikolay 49K Mar 25 2021 barcodes.tsv.gz; -rwxrwxrwx. 1 nikolay nikolay 424K Mar 25 2021 features.tsv.gz; -rwxrwxrwx. 1 nikolay nikolay 101M Mar 25 2021 matrix.mtx.gz; >>> adata = sc.read_10x_mtx(; ... './H004/', ; ... var_names='gene_symbols', ; ... cache=True); >>> adata.var_names_make_unique(); >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. **The problem is the error in importing gene names both when using id and when using symbolic labeling. All genes have the same name. if you use `anndata=0.10.3` instead of `anndata=0.10.4`, then everything works correctly.**. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib; import seaborn as sns. path='<path_to_files>'. adata = sc.read_10x_mtx(; path, ; var_names='gene_symbols', ; cache=True). adata.var_names_make_unique(). adata.var; ```. ### Error output. ```pycon; >>> # then anndata=0.10.4; >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:6744,error,error,6744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['error'],['error']
Availability," mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error output. ```pytb; mtx is parse=False. Rescaled with my_scale_function:; True; Rescaled with scanpy:; False. Original matrix:; [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01; -2.09179729e-01 -5.31203270e-01]; [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01; -3.13310266e-01 -5.96654296e-01]; [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01; -1.70931697e-01 1.37899971e+00]; ...; [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02; -1.61111996e-01 2.04149699e+00]; [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03; -1.35240912e-01 -4.82111037e-01]; [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02; -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:; [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01; -2.0917973e-01 -5.3120327e-01]; [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01; -3.1331027e-01 -5.9665430e-01]; [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629:1993,Error,Error,1993,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629,1,['Error'],['Error']
Availability," more predictability at the expense of backwards compatibility*? Especially the “euclidean” condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'` … ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean “connectivity method”. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (“build a symmetric mask”, …) *not covered, but also the logic shouldn’t have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umap’s `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we don’t actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2536:1890,mask,mask,1890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536,1,['mask'],['mask']
Availability," n_bins, flavor, subset, inplace, batch_key, check_values); 425 span=span,; 426 subset=subset,; --> 427 inplace=inplace,; 428 ); 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 ); 66 ; ---> 67 df['means'], df['variances'] = _get_mean_var(X); 68 ; 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis); 6 def _get_mean_var(X, *, axis=0):; 7 if sparse.issparse(X):; ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis); 9 else:; 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1995:2362,error,error,2362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995,1,['error'],['error']
Availability," nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.6.0; igraph 0.9.8; joblib 1.1.0; kiwisolv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:2181,error,error,2181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124:1167,error,error,1167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124,2,"['Error', 'error']","['Error', 'error']"
Availability," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:1732,down,downstream,1732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,2,['down'],['downstream']
Availability," on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose); 216 projection=projection,; 217 sparse_pca=sparse_pca,; --> 218 verbose=verbose,; 219 ); 220 . ~/anaconda3/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157:1083,Error,Error,1083,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157,1,['Error'],['Error']
Availability, print(prot.X); ```; Output; ```; before; [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165; -0.05565361]; [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884; 0.03547253]; [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176; -0.05032819]; ...; [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771; -0.01558504]; [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814; 0.0116325 ]; [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189; 0.02879048]]; after; [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232; -0.03857614]; [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566; 0.02458768]; [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355; -0.03488484]; ...; [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253; -0.01080273]; [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221; 0.00806304]; [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191; 0.01995604]]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.20.2; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.39.1; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.0; s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668:1814,Error,Error,1814,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668,1,['Error'],['Error']
Availability," pyproject.toml; testpaths: scanpy; plugins: nunit-1.0.6, mock-3.12.0; [1mcollecting ... [0mcollected 1474 items. scanpy/_utils/compute/is_constant.py::scanpy._utils.compute.is_constant.is_constant [32mPASSED[0m[32m [ 0%][0m; scanpy/datasets/_ebi_expression_atlas.py::scanpy.datasets._ebi_expression_atlas.ebi_expression_atlas [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pl.py::scanpy.external.pl.phate [33mSKIPPED[0m (needs modul...)[32m [ 0%][0m; scanpy/external/pp/_bbknn.py::scanpy.external.pp._bbknn.bbknn [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_harmony_integrate.py::scanpy.external.pp._harmony_integrate.harmony_integrate [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_hashsolo.py::scanpy.external.pp._hashsolo.hashsolo [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_magic.py::scanpy.external.pp._magic.magic [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_scanorama_integrate.py::scanpy.external.pp._scanorama_integrate.scanorama_integrate Fatal Python error: Illegal instruction. Thread 0x00007f00347c4640 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 316 in wait; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 581 in wait; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/tqdm/_monitor.py"", line 60 in run; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 937 in _bootstrap. Current thread 0x00007f004e08eb80 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 522 in nn_approx; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 590 in fill_table; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 631 in find_ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:1789,error,error,1789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,1,['error'],['error']
Availability," run_command; self.distribution.run_command(command); File ""/cluster/software/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/cluster/software/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/cluster/software/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/cluster/software/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/scratch/tmp/pip-build-g14yf1xi/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 65, in __getattr__; self.data_files = self._get_data_files(); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 79, in _get_data_files; return list(map(self._get_pkg_data_files, self.packages or ())); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files; for file in self.find_data_files(package, src_dir); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: must be str, not list; ```. </details>. I have never had this error message before and Google can't find anything. . Debugging this a bit, it happens because in this line in build_py.py:. ```py; globs = (self.package_data.get('', []); + self.package_data.get(package, [])); ```. package is ""scanpy"" and the first part before the + is `""*.txt""` and the second part after the + is `[]`. This is Python 3.6.0a1 and pip 9.0.1 on Centos 6.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:8469,error,error,8469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['error'],['error']
Availability," save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ---------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3134,toler,tolerance,3134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,['toler'],['tolerance']
Availability," scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,; ```; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Minimal code sample. ```python. import scanpy as sc; import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25); adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],; jitter=0.4, multi_panel=True, save=""_before_QC.pdf""); ```. ### Error output. ```pytb; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata); Detected doublet rate = 1.7%; Estimated detectable doublet fraction = 41.1%; Overall doublet rate:; 	Expected = 6.0%; 	Estimated = 4.1%; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.; adata.obs[obs_metrics.columns] = obs_metrics; WARNING: saving figure to file figures/violin_before_QC.pdf; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight; self._figure.tight_layout(*args, **kwargs); /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI bac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2627:1175,Error,Error,1175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627,1,['Error'],['Error']
Availability," scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:1098,error,error,1098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2254,down,down,2254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,2,['down'],['down']
Availability," strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1616,error,error,1616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability," the left (fig. 1); sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) # see the tb (if there's only 1 category, in the group, it doesn't crash). a.X[:16, :] = 10 + np.random.RandomState(42).normal(size=(16, 50)); a.X[16:32, :] = -10 + np.random.RandomState(42).normal(size=(16, 50)); a.obs['foo'].iloc[:16, :] = 0; a.obs['foo'].iloc[16:32, :] = 1; a.obs['foo'].iloc[32:, :] = 2; # wrong label-color mapping; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 2; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 3. # but not when there are colors in `.uns; a.uns['foo_colors'] = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 4; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 5; # xlabels are not centered + horizntal lines are slightly shifted downwards (really have to zoom in); sc.pl.heatmap(a, var_names=a.var_names, groupby=""foo"", swap_axes=False, figsize=(50, 50)); ```; If you look closely (e.g. between fig. 2 and fig.3, or fig. 4 and fig. 5), the within group order is also broken. ```pytb; TypeError Traceback (most recent call last); <ipython-input-56-f1ba710dac43> in <module>; 9 ; 10 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=None, swap_axes=True) # is shifted to the left (fig. 1); ---> 11 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) ; 12 ; 13 a.X[:16, :] = 0. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1220 groupby_cmap,; 1221 norm,; -> 1222 ) = _plot_categories_as_colorblocks(; 1223 groupby_ax, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591:1825,down,downwards,1825,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591,1,['down'],['downwards']
Availability," this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default; * Consolidate implementation to a single well maintained library; * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points?. * `tsne` should allow weights to be passed through (whether perplexity based, or not); * There should be a warning to notify the user if the weights were computed in a non-standard way; * There should be a function for computing a perplexity weighted nearest neighbor gr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636:1183,error,erroring,1183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636,1,['error'],['erroring']
Availability, to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/ve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:18942,error,error,18942,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability," use_raw or k in adata.obs.columns:; --> 173 df[k] = adata.obs_vector(l, layer=layer); 174 else:; 175 df[k] = adata.raw.obs_vector(l). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/anndata.py in obs_vector(self, k, layer); 1362 ); 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; --> 158 raise ValueError(; 159 f""Key {k} could be found in both .{idxdim}_names and .{coldim}.columns""; 160 ). ValueError: Key var_id could be found in both .var_names and .obs.columns; ```. ## Repeats in var_names. When there are repeats in `var_names` (pretty frequent occurence), getting a dataframe with keys that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:4238,error,error,4238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability," was a single variable which would be used to fill cell in the plot. As an example:. ```python; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2). sc.pl.dotplot(pbmc, var_names='LDHB', groupby=['louvain', 'sampleid'], groupby_expand=True); ```. ![tmpdm8256t1](https://user-images.githubusercontent.com/8238804/144899323-c439785d-5d57-4a18-b6e5-2b12412465f8.PNG). Instead of having an argument which changes the interpretation of the earlier arguments, I would prefer more orthogonal arguments. I think you'd be able to get an output close to what you would currently like with:. ```python; import scanpy as sc, pandas as pd, numpy as np. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]). summarized = df.pivot_table(; index=[""louvain"", ""sampleid""],; values=""LDHB"",; aggfunc=[np.mean, np.count_nonzero]; ); color_df = summarized[""mean""].unstack(); size_df = summarized[""count_nonzero""].unstack(). # I don't think the var_names or groupby variables are actually important here; sc.pl.DotPlot(; pbmc,; var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; dot_color_df=color_df, dot_size_df=size_df,; ).style(cmap=""Reds"").show(); ```. I think this functionality could be more generic, and inspired by the `pd.pivot_table` function. This could end up looking like:. ```python; # Imaginary implementation:; sc.pl.heatmap(; pbmc,; var_names=""LDHB"",; row_groups=""louvain"",; col_groups=""sampleid""; ); ```. ![image](https://user-images.githubusercontent.com/8238804/144901891-45c3a8aa-1b56-4521-abc1-66f968a59d23.png). ```python; sc.pl.heatmap(; pbmc,; var_names=[""LDHB"", ""LYZ"", ""CD79A""],; row_groups=""louvain"",; col_groups=""sampleid""; ); ```. ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png). What do you think about that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-987049315:1644,error,error,1644,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-987049315,1,['error'],['error']
Availability," we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot. I would like it to have order 0-5 by default. <img width=""393"" alt=""image"" src=""https://user-images.githubusercontent.com/8322751/78272834-8bd8a380-74fd-11ea-9034-6c8d0aefebe8.png"">. **5. Cannot pass clusters to `c` parameter in plt.scatter**; I would like this to just work. Instead it throws a huge error.; ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['leiden']); ```. **6. Clusters as categories frustrate subclustering**; I understand this is a niche application, but like 4 and 5, this would be fixed by matching the output of sklearn.cluster operators.; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). cluster_zero = adata[adata.obs['leiden'] == '0']; sub_clusters = cluster.KMeans(n_clusters=2).fit_predict(adata.X). # Here I'm trying to break up cluster '0' into subclusters with ; # new names that don't clash with the existing clusters; # However, np.max() and the + operators aren't well defined for ; # cateogricals of strings; sub_clusters = sub_clusters + np.max(adata.obs['leiden']); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:2303,error,error,2303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,1,['error'],['error']
Availability, with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files di,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48084,Error,Error,48084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability," y):; 40 """"""Reduced Euclidean distance.; 41 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.conda/envs/rpy/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:4482,error,errors,4482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,2,['error'],['errors']
Availability,"![image](https://user-images.githubusercontent.com/43333475/126772609-6fbdc819-46e1-4fac-8e8c-d73033192991.png). I have tried pynndescent, and I receive the same errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-885560293:162,error,errors,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-885560293,1,['error'],['errors']
Availability,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169:4381,error,error,4381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169,1,['error'],['error']
Availability,""", ""repeated_col"", ""var_id""],; index=pd.Index([f""cell_{i}"" for i in range(M)], name=""obs_index""),; ),; var=pd.DataFrame(; index=pd.Index([""var_id""] + [f""gene_{i}"" for i in range(N-1)], name=""var_index""),; ),; ); ```. ## Repeated column in `adata.obs`. I think this should be an error. This is because downstream functions (like plotting) currently assume that for each key input here, there will be one output column. Turns out this isn't exactly pandas behaviour with repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:1452,error,errors,1452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361:14,fault,fault,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361,2,"['Error', 'fault']","['Error', 'fault']"
Availability,"""cell_ranger""'); --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 255 if sz == 0:; 256 raise ValueError(""Cannot cut empty array""); --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)); 259 mn, mx = (mi + 0.0 for mi in rng); 261 if np.isinf(mn) or np.isinf(mx):; 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds); 145 result = alt(values, axis=axis, skipna=skipna, **kwds); 146 else:; --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds); 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs); 401 if datetimelike and mask is None:; 402 mask = isna(values); --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs); 406 if datetimelike:; 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask); 1086 if values.size == 0:; 1087 return _na_for_min_count(values, axis); -> 1089 values, mask = _get_values(; 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask; 1091 ); 1092 result = getattr(values, meth)(axis); 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask); 314 if datetimelike or _na_ok_dtype(dtype):; 315 values = values.copy(); --> 316 np.putmask(values, mask, fill_value); 317 else:; 318 # np.where will promote if needed; 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:11076,mask,mask,11076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,5,['mask'],['mask']
Availability,"""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dodge,; 2935 gap=gap,; 2936 split=split,; 2937 color=color,; 2938 fill=fill,; 2939 linecolor=linecolor,; 2940 linewidth=linewidth,; 2941 inner=inner,; 2942 density_norm=density_norm,; 2943 common_norm=common_norm,; 2944 kde_kws=kde_kws,; 2945 inner_kws=inner_kws,; 2946 plot_kws=plot_kws,; 2947 ); 2949 elif kind == ""boxen"":; 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws); 1151 legend_artist = _get_patch_legend_artist(fill); 1152 common_kws = {**plot_kws, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:1589,error,errorbar,1589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['error'],['errorbar']
Availability,# Error Output. Output when using a list of marker genes in the `var_names` arg; ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg; ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3320#issuecomment-2436143352:2,Error,Error,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320#issuecomment-2436143352,1,['Error'],['Error']
Availability,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I have two different datasets, both with raw counts. After using the function `sc.pp.normalize_total` and `sc.pp.log1p` and plotting the data with UMAP coordinates, there is no gene expression in cells coming from one of the datasets. I did the analysis separately (without concatenating) and the same happens. . I thought that maybe is a problem with the data type, but when I checked this, both anndatas.X were np.float32 and sparse.csr_matrixes ( #1612 ). Also, I made sure the anndata matrix related to the problematic dataset has acceptable values and they are not zeros. Any idea about this problem?. ### Minimal code sample. ```python; sc.pp.normalize_total(adata); sc.pp.log1p(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 9.1.0; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; cycler 0.10.0; cython_runtime NA; dask 2022.8.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.4; fastjsonschema NA; fsspec 2022.7.1; google NA; h5py 3.4.0; idna 3.3; igraph 0.9.6; ipykernel 6.4.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.38.0; louvain 0.7.0; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; mpmath 1.3.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.55.1; numexpr 2.7.3; numpy 1.21.6; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2556:998,Error,Error,998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556,1,['Error'],['Error']
Availability,"# What happened?. Hi!. I am new to scanpy and I am facing some trouble reading my data in an appropriate way. I noticed that anndata objects in memory require roughly 4x the space they require on disk, so working with large datasets (>50GB on disk) is prohibitive in most scenarios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:1257,down,downloading,1257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['down'],['downloading']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2201?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2201 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2202 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2213?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3ac9169`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9c0054f differs from pull request most recent head 02123f2. Consider uploading reports for the commit 02123f2 to get more accurate results. ```diff; @@ Coverage Diff @@; ## 1.9.x #2213 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2221?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6cc7541`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2221 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2226?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a08c155`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2226 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2241?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@cab9f78`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2241 +/- ##; =========================================; Coverage ? 71.74% ; =========================================; Files ? 99 ; Lines ? 11560 ; Branches ? 0 ; =========================================; Hits ? 8294 ; Misses ? 3266 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706:327,error,error-reference,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2275?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@5bcb539`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2275 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2279?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4d0d8be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2279 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6b5f786`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 6fb5f26 differs from pull request most recent head fb557a1. Consider uploading reports for the commit fb557a1 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2348 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@cf6d820`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2350 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2419?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@97c2617`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 72ea692 differs from pull request most recent head 8fb038a. Consider uploading reports for the commit 8fb038a to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2419 +/- ##; ========================================; Coverage ? 71.83% ; ========================================; Files ? 98 ; Lines ? 11543 ; Branches ? 0 ; ========================================; Hits ? 8292 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2435?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1fbbfcd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2435 +/- ##; ========================================; Coverage ? 71.88% ; ========================================; Files ? 98 ; Lines ? 11546 ; Branches ? 0 ; ========================================; Hits ? 8300 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1413?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`master@62bb643`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `74.48%`. ```diff; @@ Coverage Diff @@; ## master #1413 +/- ##; =========================================; Coverage ? 71.34% ; =========================================; Files ? 92 ; Lines ? 11186 ; Branches ? 0 ; =========================================; Hits ? 7981 ; Misses ? 3205 ; Partials ? 0 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1413?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_main\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L19fbWFpbl9fLnB5) | `0.00% <0.00%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.74% <ø> (ø)` | |; | [scanpy/plotting/\_tools/paga.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9wYWdhLnB5) | `70.62% <ø> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-846966462:329,error,error-reference,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-846966462,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@c943b93`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `71.86%`. [![Impacted file tree graph](https://codecov.io/gh/theislab/scanpy/pull/1693/graphs/tree.svg?width=650&height=150&src=pr&token=UsIEoV0aqg)](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #1693 +/- ##; =========================================; Coverage ? 71.32% ; =========================================; Files ? 89 ; Lines ? 10969 ; Branches ? 0 ; =========================================; Hits ? 7824 ; Misses ? 3145 ; Partials ? 0 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=tree) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_main\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L19fbWFpbl9fLnB5) | `0.00% <0.00%> (ø)` | |; | [scanpy/plotting/\_dotplot.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19kb3RwbG90LnB5) | `86.79% <ø> (ø)` | |; | [scanpy/plotting/\_matrixplot.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `97.87% <ø> (ø)` | |; | [scanpy/plotting/\_preprocessing.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19wcmVwcm9jZXNzaW5nLnB5) | `87.75% <ø> (ø)` | |; | [scanpy/plotting/\_qc.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19xYy5weQ==) | `88.23% <ø> (ø)` | |; | [scanpy/plotting/\_rcmod.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19yY21vZC5weQ==) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_stacked\_violin.py](https://codecov.io/gh/theislab,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892:228,error,error-reference,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1920?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@8750212`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1920 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11248 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3194 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1920#issuecomment-873816651:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1920#issuecomment-873816651,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1923?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@d0f851f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1923 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11248 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3194 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1923#issuecomment-873930176:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1923#issuecomment-873930176,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1924?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@1605f63`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1924 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8053 ; Misses ? 3193 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1924#issuecomment-873973489:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1924#issuecomment-873973489,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1935?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@8c51f19`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1935 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935#issuecomment-875351624:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935#issuecomment-875351624,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1938?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@2883269`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1938 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1938#issuecomment-875422302:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1938#issuecomment-875422302,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1947?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@9360422`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1947 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1947#issuecomment-878124023:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947#issuecomment-878124023,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1952?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@c9d319e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1952 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1952#issuecomment-882418271:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1952#issuecomment-882418271,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1961?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@aeaa07b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1961 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1961#issuecomment-887335708:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961#issuecomment-887335708,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1962?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@370d1c6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1962 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1962#issuecomment-887353669:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1962#issuecomment-887353669,2,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1966?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@b9cd8c8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1966 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1966#issuecomment-888502703:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1966#issuecomment-888502703,2,['error'],['error-reference']
Availability,"# a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 Please use .at[] or .iat[] accessors.; 910 ; --> 911 Parameters; 912 ----------; 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 -------; 952 series : Series; --> 953 If label is contained, will be reference to calling Series,; 954 otherwise a new object; 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4344 ; 4345 elif not is_list_like(value):; -> 4346 new_data = self._data.fillna(value=value, limit=limit,; 4347 inplace=inplace,; 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4357 return self._constructor(new_data).__finalize__(self); 4358 ; -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):; 4360 """"""; 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 # in which case we are going to conform to the passed Categorical; 502 new_target = np.asarray(new_target); --> 503 if is_categorical_dtype(target):; 504 new_target = target._shallow_copy(new_target, name=self.name); 505 else:. ValueError: cannot reindex with a non-unique indexer. **; ```; The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450:1821,down,downcast,1821,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450,2,['down'],['downcast']
Availability,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:206,Error,Error,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,3,"['Error', 'FAILURE', 'Failure']","['Error', 'FAILURES', 'Failure']"
Availability,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439,1,['error'],['error']
Availability,"## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1921:161,error,error,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921,1,['error'],['error']
Availability,"## Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have a bunch of matrix.mtx, barcode.tsv and genes.tsv. When I want to read in the files with:; `data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True)`. I get the following error:; `FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'`. The thing is that the file exist here:; ![kép](https://github.com/user-attachments/assets/a3ee8f51-833d-4adb-ab9f-f6ff5b19387f). I have changed the *genes.tsv.gz file's name to *features.tsv.gz but still got the same error. Here is the full error log:; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], [line 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/Pipe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:866,error,error,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['error']
Availability,"## Test failures on 141eb6a315542317ddab2f7a413a24559c84492f. 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31). Noting some of the big causes:. ### Expected warnings not thrown. A few times. ### Older versions of pandas do not support `na_action`. Likely caused during [Fix more pandas warnings by flying-sheep · Pull Request #2789 · scverse/scanpy](https://github.com/scverse/scanpy/pull/2789). Which did also bump up the required pandas version to 2.1.3. However, I think we'll want to revert that bump because:. * According to the scientific python versioning specification we're still meant to be on 1.4 ; * More than half of pandas users are still on 1.*; * Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:8,failure,failures,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,2,"['error', 'failure']","['errors', 'failures']"
Availability,"## Xarray and anndata. Theoretically, `AnnData` objects are kind of like a special case of `xarray.Dataset`s. While `AnnData` objects have an `obs` and a `var` dimension `xarray.Dataset` can have any number of dimensions. `AnnData` objects are just specializing to the the 2d case. I think it would make a lot of sense to eventually have `anndata` and `scanpy` be based on `xarray`, or something like it. In practice there are a number of difficulties here. The biggest one is support for sparse data, and I'll briefly point out a couple others. ### Sparse arrays. I could probably rant about this for a while, since it's always a problem. Efficient processing of scRNA-seq data needs sparse matrices. The only fully featured sparse array library in python right now is `scipy.sparse`. All of it's sparse arrays only follow the `np.matrix` interface, which is deprecated. This means that they only kind-of work like arrays, and need to be special cased pretty frequently. `xarray` seems to work pretty well with a number of different array types, as long as they act like `np.ndarray`s. They have explicit support for `pydata/sparse`, but that library isn't well supported by the rest of the ecosystem, probably because it doesn't have CSR or CSC matrices yet. This leaves `xarray` with a level of sparse array support that isn't usable for us. ### Pairwise arrays and other weird behaviour. * Having an array where multiple axes have the same name doesn't work well with `xarray`. This is a problem if you're frequently using adjacency matrices like we do.; * `xarray.DataArray`s do not necessarily have the same behaviour as numpy arrays. For example, they have specific behaviour for matrix multiplication. Any transition would be much easier if `DataArrays` could be used as drop-in replacements for numpy arrays (plus some errors for misaligned data). We need to map this out more before we could make any attempt at integrating the libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154:1828,error,errors,1828,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154,2,['error'],['errors']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2516?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2979f99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2516 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2523?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec78ca9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 249ef59 differs from pull request most recent head c69bc0f. Consider uploading reports for the commit c69bc0f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2523 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2528?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@af11c8f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2528 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2538?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@120dcd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2538 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@c40d2ee`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2549 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2567?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2567 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2568?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2568 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2574?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@053f47e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2574 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2597?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@64fab42`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2597 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2606?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@b5506e1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2606 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2613?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2613 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2616?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2616 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2619?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fbd73ac`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2619 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2620?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a6f6c6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2620 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2638?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@9ba0251`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2638 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2641?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@8aa93e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2641 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2643?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6e8a8b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2643 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2652?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@16e7e9f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2652 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2659?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@efce8f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head eea03bb differs from pull request most recent head 256ce44. Consider uploading reports for the commit 256ce44 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2659 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2676?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fc498c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2676 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 104 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2677?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@46969b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2677 +/- ##; ========================================; Coverage ? 71.69% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8347 ; Misses ? 3296 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2686?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@418baff`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 503876d differs from pull request most recent head 5c315d4. Consider uploading reports for the commit 5c315d4 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2686 +/- ##; ========================================; Coverage ? 71.98% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2687?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@8353e45`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 601888e differs from pull request most recent head f257b7f. Consider uploading reports for the commit f257b7f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2687 +/- ##; =========================================; Coverage ? 71.97% ; =========================================; Files ? 108 ; Lines ? 11907 ; Branches ? 0 ; =========================================; Hits ? 8570 ; Misses ? 3337 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250:332,error,error-reference,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2690?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3c15b99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2690 +/- ##; ========================================; Coverage ? 71.99% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2697?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d71a4a9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2697 +/- ##; ========================================; Coverage ? 72.01% ; ========================================; Files ? 104 ; Lines ? 11656 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3262 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2721?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@05405f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2721 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2722?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4936b7e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2722 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2727?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@0b624b0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2727 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2728?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1083b36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2728 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2738?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d1fe8da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2738 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8383 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2751?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec4d79f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2751 +/- ##; ========================================; Coverage ? 71.87% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8363 ; Misses ? 3272 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2752?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@295d889`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2752 +/- ##; ========================================; Coverage ? 72.10% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8389 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2774?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@70d55d5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2774 +/- ##; ========================================; Coverage ? 72.11% ; ========================================; Files ? 103 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2783?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4058e36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 09a432a differs from pull request most recent head 3b44d11. Consider uploading reports for the commit 3b44d11 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2783 +/- ##; ========================================; Coverage ? 17.51% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 2040 ; Misses ? 9605 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:405,error,error-reference,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:405,error,error-reference,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168,2,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2972?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`main@3ceb740`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2972 +/- ##; =======================================; Coverage ? 75.49% ; =======================================; Files ? 116 ; Lines ? 12911 ; Branches ? 0 ; =======================================; Hits ? 9747 ; Misses ? 3164 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769:422,error,error-reference,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769,2,['error'],['error-reference']
Availability,"### 1. Passing anndata objects to numpy and sklearn operators. I think this would be great! This would be easy to implement if python had generic functions. This is kinda something that's being worked on for numpy, but the assumptions a ufunc has about it's input data does not match with what an AnnData object is. I've worked on a side project of just wrapping the sklearn transformers so you can pass anndata objects, and could try and get that cleaned up for use if it'd be valuable. --------------------------------. I'm not really sure what you expect this line to do though:. ```python; adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]; ```. I would probably throw an error for that, since the var names wouldn't be the same. It's also not obvious to me which arrays would be subtracted (all of them? some of them?). If this is meant to do:. ```python; adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X; ```. I don't think that's so much more work. > I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease?. If it should return the whole object, but not update the original, then all of the values from the original need to be copied to prevent unintentional modification. This is really expensive for large objects, which single cell datasets often are. For your example of `adata = np.sqrt(adata)` vs `adata_sq = np.sqrt(adata)`, there's no way for us to tell which of those statements was made while evaluating `np.sqrt`. That would require the ability to overload assignment, and for python to have different evaluation rules. ### 2. Requirement to use .var_vector or .obs_vector for single columns. Is what you're saying that you want: `adata[:, adata.var_names[0]].X` to be one dimensional?. This used to be the behaviour, but it got confusing quickly. Suddenly, `adata.X` could be a differ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:690,error,error,690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,2,['error'],['error']
Availability,"### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**; - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**; - Subset of genes defined by `var_names` is now used. **In addition:**; - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix.; - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis).; - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`; - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct.; - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2384:613,down,downstream,613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384,2,"['down', 'error']","['downstream', 'error']"
Availability,"### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); cats = pbmc.obs[""louvain""].cat.categories; genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]); ```. ```pytb; ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-580bb69f9615> in <module>; ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:343,error,errors,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python; This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',; 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',; 'NKT', 'NK_0', 'NK_1', 'NK_2',; 'ncMo', 'cMo', 'DC_1', 'DC_2', 'MΦ_1', 'MΦ_2',; 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True); ```; ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005:1270,Error,Error,1270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. (extracted from #3167). Utilizing the murine hematopoietic progenitors from [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480), as well as the regev_lab_cell_cycle_genes.txt, one issue is apparent. Currently the code doesn’t produce the expected number of bins of equal or approximately equal size. Bin 24 is empty when n_bins = 25.; ![current_hist](https://github.com/user-attachments/assets/35e5d1a4-fdd0-406e-a2f9-1b53efacc8fa). ### The current ranking system code within score_genes(); ```py; n_items = int(np.round(len(obs_avg) / (n_bins - 1))); obs_cut = obs_avg.rank(method=""min"") // n_items; ```. ### The modified code in #3167; ```py; obs_avg.sort_values(ascending=True, inplace=True); n_items = int(np.ceil(len(obs_avg) / (n_bins))); rank = np.repeat(np.arange(n_bins), n_items)[:len(obs_avg)]; obs_cut = pd.Series(rank, index=obs_avg.index); ```. The modified code performs as expected producing 25 bins containing approximately equal number of genes. The last bin can have up to 24 less than expected because the total number of genes is not perfectly divisible by 25.; ![modified_hist](https://github.com/user-attachments/assets/6ced8eec-b56b-4642-a33c-71acaee98369). ### Minimal code sample. ```python; TODO; ```. ### Error output. _No response_. ### Versions. <details>. ```; Python 3.10.12 ; scanpy==1.10.2 anndata==0.10.8 umap==0.5.6 numpy==1.26.4 scipy==1.14.0 pandas==2.2.2 scikit-learn==1.5.0 statsmodels==0.14.2 igraph==0.11.6 louvain==0.8.2 pynndescent==0.5.13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3168:1541,Error,Error,1541,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3168,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. (extracted from https://github.com/scverse/scanpy/pull/3167). The code fails completely when the gene set has zero expression in some cells. The data used to illustrate this problem is located here: [test_data.h5ad](https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/test_data.h5ad) . Since relatively few genes are typically selected for measurement, this will be a common occurrence.; ![hist](https://github.com/user-attachments/assets/d578327b-6cf8-4c8f-b3c9-01744f35832b). If the expression data is **scaled** the problem is more intrusive since it occurs in the middle of the expression range. The bins with no genes give a Nan result.; ![hist2](https://github.com/user-attachments/assets/81946f65-2673-427e-b540-46303224544a). The proposed code modification in #3167 has no problem with this data set, either scaled or unscaled.; ![image](https://github.com/user-attachments/assets/6273b44b-7def-4fb4-b410-3de67416f5db). ### Minimal code sample. ```python; TODO; ```. ### Error output. _No response_. ### Versions. <details>. ```; Python 3.10.12 ; scanpy==1.10.2 anndata==0.10.8 umap==0.5.6 numpy==1.26.4 scipy==1.14.0 pandas==2.2.2 scikit-learn==1.5.0 statsmodels==0.14.2 igraph==0.11.6 louvain==0.8.2 pynndescent==0.5.13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3169:1281,Error,Error,1281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3169,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # start from scratch; del adata.obs[""louvain""]; adata.uns = {}; adata_ref.uns = {}. # example code for ingest function:; sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs=""louvain""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[11], line 23; 21 sc.pp.neighbors(adata_ref); 22 sc.tl.umap(adata_ref); ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:520,error,error,520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,2,['error'],"['error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Dear scanpy teams, research fellows,; I downloaded some scRNA-seq data from https://zenodo.org/records/3357167,; and when I was tring to use `anndata.AnnData.concatenate` to combine two read count data(I checked their dimensions and the result were `Baron_human: [2133,22758]` and `Segerstolpe: [8569,17500]` which means they certainly have different annotated genes), I got below error. Could u help. many thanks!!. ### Minimal code sample. ```python; all_adata = anndata.AnnData.concatenate(train_adata,test_adata); ```. ### Error output. ```pytb; File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate; raise AttributeError(""Can only use .str accessor with string values!""); AttributeError: Can only use .str accessor with string values!; ```. ### Versions. <details>. ```; >>> scanpy.logging.print_versions(); -----; anndata 0.8.0; scanpy 1.9.3; -----; CIForm NA; PIL 9.1.0; astunparse 1.6.3; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.11.0; igraph 0.10.4; joblib 1.2.0; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.3.1; nt NA; numba 0.56.4; numpy 1.23.5; opt_einsum v3.3.0; packaging 21.3; pandas 2.2.3; plotly 5.13.1; psutil 5.9.4; pyparsing 3.0.9; pytz 2022.1; scipy 1.10.0; session_info 1.0.0; six 1.16.0; sklearn 1.2.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 1.13.1+cpu; tqdm 4.64.1; typing_extensions NA; yaml 6.0; zoneinfo NA; zope NA; -----; Python 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; -----; Session information updated at 2024",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261:329,down,downloaded,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261,3,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi!. I am new to scanpy and I am facing some trouble reading my data in an appropriate way. I noticed that anndata objects in memory require roughly 4x the space they require on disk, so working with large datasets (>50GB on disk) is prohibitive in most scenarios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:947,mask,mask,947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['mask'],['mask']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, I am running the Scrublet function to remove doublets.; the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540.; [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python; # 240520鳞癌，不用; # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # 240520 去掉癌旁，只用癌; lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:830,error,error,830,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, I recently started using scanpy and python. I am running into the following error. Any help is much appreciated. ![image](https://github.com/user-attachments/assets/76e1c619-a764-45ac-a475-4bad342854b1). ### Minimal code sample. ```python; sc.pl.umap(adata,color =[""leiden""]); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.6; -----; PIL 9.5.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; bottleneck 1.3.6; cffi 1.15.0; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.5.1; decorator 4.4.2; defusedxml 0.7.1; dill 0.3.8; dot_parser NA; entrypoints 0.4; executing 0.8.3; fasteners 0.18; get_annotations NA; google NA; h5py 3.8.0; igraph 0.10.8; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.4.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; msgpack 1.0.5; natsort 8.4.0; numba 0.59.0; numcodecs 0.12.1; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.23.0; prompt_toolkit 3.0.20; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynvml NA; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.11.2; seaborn 0.13.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.3.2; sphinxcontrib NA; stack_data 0.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215:369,error,error,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I am using Rstudio as the only means available by my institution through slurm to do single cell analysis. and the plots using scanpy are messed up. i tried different parameters. I am not sure if this issue is related to rstudio or i am doing something wrong. . ### Minimal code sample. ```python; sc.pl.umap(; sample,; color=[""supercluster_term""],; legend_loc=""right margin"", # or choose the location you prefer; legend_fontsize=5, # Adjust font size if needed; frameon=True,; title=[""Provided cell type""],; ); ```. ### Error output. _No response_. ### Versions. -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; absl NA; array_api_compat 1.4.1; attr 23.2.0; chex 0.1.85; contextlib2 NA; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; docrep 0.3.2; etils 1.5.2; exceptiongroup 1.2.0; flax 0.8.1; fsspec 2024.2.0; h5py 3.10.0; igraph 0.10.8; importlib_resources NA; jax 0.4.25; jaxlib 0.4.25; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; lightning 2.1.4; lightning_utilities 0.10.1; llvmlite 0.42.0; louvain 0.8.1; markupsafe 2.1.5; matplotlib 3.8.3; ml_collections NA; ml_dtypes 0.3.2; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.8; mudata 0.2.3; multipledispatch 0.6.0; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; numpyro 0.14.0; opt_einsum v3.3.0; optax 0.2.1; packaging 23.2; pandas 2.2.1; pkg_resources NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.1.2; pyro 1.9.0; pytz 2024.1; rich NA; rpycall NA; rpytools NA; scipy 1.12.0; scvi 1.1.2; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; skmisc 0.3.1; sympy 1.12; texttable 1.7.0; threadpoolctl 3.3.0; toolz 0.12.1; torch 2.2.1+cu121; torchgen NA; torchmetrics 1.3.1; tqdm 4.66.2; typing_extensions NA; umap ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2955:326,avail,available,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2955,2,"['Error', 'avail']","['Error', 'available']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have a bunch of matrix.mtx, barcode.tsv and genes.tsv. When I want to read in the files with:; `data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True)`. I get the following error:; `FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'`. The thing is that the file exist here:; ![kép](https://github.com/user-attachments/assets/a3ee8f51-833d-4adb-ab9f-f6ff5b19387f). I have changed the *genes.tsv.gz file's name to *features.tsv.gz but still got the same error. Here is the full error log:; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], [line 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/Pip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:512,error,error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have an AnnData object, and I try to slice it with . `adata[adata.obs.Phenotype == 'CON']`. But I get an error: . ```; AssertionError: Don’t call _normalize_index with non-categorical/string names; ```. Curiously, `adata.obs[adata.obs.Phenotype == 'CON']` works just fine. . I verified that both `adata.obs.index` and `(adata.obs.Phenotype == 'CON').index` are both regular Int64Indexes. . What might be going wrong? . I noticed a similar issue in the past (xref https://github.com/scverse/scanpy/issues/747) but the solutions listed didn't work for me. . ### Minimal code sample. ```python; `adata[adata.obs.Phenotype == 'CON']`; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy version 1.9.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2979:396,error,error,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2979,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I tried to run the code below on a Windows laptop and received the error (also below). I've tried uninstalling and reinstalling igraph, leidenalg, and scanpy. I tried running the code with flavor=""leidenalg"" and got the same/basically the same error. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"", ; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[159], line 1; ----> 1 sc.tl.leiden( #So leidan is identifying and coloring clusters for you, but not changing the shape of the graph.; 2 adata, #lets just pretend that I understand what each of those things mean; 3 resolution=0.9,; 4 random_state=0,; 5 flavor=""igraph"", #did pip install leidenalg and started receiving the no flavor keyword error; https://github.com/scverse/scanpy/issues/350 indicates this is to be expected, but https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.leiden.html indicates it should have it ; 6 n_iterations=2,; 7 directed=False,; 8 ). File ~\miniconda3\Lib\site-packages\scanpy\tools\_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 msg = 'In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph\'s implementation.'; 143 _utils.warn_once(msg, FutureWarning, stacklevel=3); --> 144 except ImportError:; 145 raise ImportError(; 146 ""Please install the leiden algorithm: `conda i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python; sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90); ```. ### Error output. ```pytb; --------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[51], line 1; ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 823 if return_fig:; 824 return vp; --> 825 vp.make_figure(); 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self); 789 return_ax_dict[""gene_gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3140:384,error,error,384,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. In #3048 we started raising errors for functions that don’t support backed mode, but seems like a tutorial used `dendrogram` in backed mode: https://scverse-tutorials.readthedocs.io/en/latest/notebooks/scverse_data_backed.html. ![grafik](https://github.com/user-attachments/assets/0317c570-0af8-4c5e-8f3f-7831335763af). That was probably a mistake and the data just got loaded to memory, but since `dendrogram` can be reimplemented using `.get.aggregate`, we should do that!. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.filename = ""test.h5ad""; sc.pl.dotplot(adata, [""FCN1""], groupby=""index"", dendrogram=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.pl.dotplot(mdata[""rna""], var_names=[""CD2""], groupby=""leiden"", figsize=(10, 3), dendrogram=True, swap_axes=True). File ~/.local/share/hatch/env/virtual/scverse-tutorials/_YRPCeuX/basic-scrna/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/.local/share/hatch/env/virtual/scverse-tutorials/_YRPCeuX/basic-scrna/lib/python3.12/site-packages/scanpy/plotting/_dotplot.py:1046, in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3199:317,error,errors,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3199,2,"['Error', 'error']","['Error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python; sc.datasets.pbmc3k(); pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'); pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'); pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")); sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AxisError Traceback (most recent call last); Cell In[8], line 3; 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'); 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")); ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 312 if isinstance(qc_vars, str):; 313 qc_vars = [qc_vars]; --> 315 obs_metrics = describe_obs(; 316 adata,; 317 expr_type=expr_type,; 318 var_type=var_type,; 319 qc_vars=qc_vars,; 320 percent_top=percent_top,; 321 inplace=inplace,; 322 X=X,; 323 log1p=log1p,; 324 ); 325 var_metrics = describe_var(; 326 adata,; 327 expr_type=expr_type,; (...); 331 log1p=log1p,; 332 ); 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, lay",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3004:827,Error,Error,827,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. On import, I'm getting:; `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python; import scanpy; ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3071:440,Error,Error,440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. On version 1.10.1 & manuals for v.1.10.x:. [If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""]. If provided, values of adata.uns[""{var}_colors""] will be set.](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pl.embedding.html). ![image](https://github.com/user-attachments/assets/9d6f328b-3afb-41c5-92ca-0a75bec6ce2c). ### Minimal code sample. Here I have an anndata with a categorical obs variable and having {var}_colors in uns; still, mpl.rcParams[""axes.prop_cycle""] is used:. ```python; ## the type of data.obs['study']: category. Name: study, Length: 48256, dtype: category; Categories (2, object): ['NatGenet', 'HongProj']. data.uns['study_colors']; -> array(['#ff7f0e', '#17becf'], dtype=object); sc.pl.embeddings(data, 'anyembedding', 'study'); ->; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy==1.10.1 anndata==0.8.0 umap==0.5.5 numpy==1.26.3 scipy==1.11.4 pandas==1.5.3 scikit-learn==1.4.0 statsmodels==0.14.0 igraph==0.10.3 pynndescent==0.5.8; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3193:1152,Error,Error,1152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3193,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Python compiler of Pandas is giving Future Warning that in line:; disp_grouped = df.groupby(""mean_bin"")[""dispersions""] ; at \preprocessing\_highly_variable_genes.py:226; Gives this warning:; ""The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning."". ### Minimal code sample. ```python; disp_grouped = df.groupby(""mean_bin"", observed=False)[""dispersions""]; ```. ### Error output. ```pytb; \scanpy\preprocessing\_highly_variable_genes.py:226: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.; ```. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.9.0; hypergeom_ufunc NA; igraph 0.11.4; invgauss_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.0; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; nt NA; numba 0.59.0; numpy 1.26.4; packaging 23.1; pandas 2.2.1; psutil 5.9.8; pyparsing 3.0.9; pythoncom NA; pytz 2023.3.post1; pywin32_system32 NA; pywintypes NA; scipy 1.11.4; session_info 1.0.0; setuptools 68.2.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; texttable 1.7.0; threadpoolctl 2.2.0; torch 2.2.1; torchgen NA; tqdm 4.65.0; typing_extensions NA; wcwidth 0.2.13; win32api NA; win32com NA; yaml ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2967:819,Error,Error,819,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2967,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python; pip install zappy; pytest scanpy/tests/test_preprocessing_distributed.py; ```. ### Error output. ```pytb; ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):; > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_normalization.py:240: in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; scanpy/preprocessing/_normalization.py:49: in _normalize_data; return axis_mul_or_truediv(; /usr/lib/python3.12/functools.py:909: in wrapper;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3087:606,Error,Error,606,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Thanks a lot, I am new to scanpy. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; why scale is not here,which is needed in traditional sc-rna seq. ```; sc.pp.normalize_total(adata, inplace=True); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=""seurat"", n_top_genes=2000); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ); ```. ### Minimal code sample. ```python; sc.pp.normalize_total(adata, inplace=True); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=""seurat"", n_top_genes=2000); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ); ```; ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.3; scanpy 1.9.8; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963:1111,Error,Error,1111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Thanks a lot; when I read docs in ; https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale); https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python; no code; ```. ### Error output. _No response_. ### Versions. <details>. ```; [; <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">; ](url); ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3095:734,Error,Error,734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python; sc.tl.umap(adata, maxiter=50); ```. ### Error output. ```pytb; computing UMAP; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies ; [0.01180801 0.01616286 0.01491355]; not reaching the requested tolerance 1e-08.; Use iteration 19 instead with accuracy ; 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies ; [0.0114102 0.01466 0.01555016]; not reaching the requested tolerance 1e-08.; eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (1:07:21); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0; prompt_toolkit 3.0.38; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3139:469,Error,Error,469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:363,error,error,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,7,"['down', 'error']","['down', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I use `sc.pl.dotplot` to show the markers betwween different clusters, in tutorials it shows the dendrogram but in prcatice it not. This caused me a great obstacle in observing. How should I slove it? Thanks!; ![output](https://github.com/user-attachments/assets/c980ed28-0192-4956-bc2a-4a75a32d126f). ### Minimal code sample. ```python; sc.tl.dendrogram(adata, groupby='leiden', key_added='dendrogram_leiden'); #%%; sc.pl.dotplot(adata, marker_genes, groupby=""leiden"", standard_scale=""var"", dendrogram='dendrogram_leiden'); #%%; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy 1.10.2; python 3.12.4; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3201:833,Error,Error,833,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. ; The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python; #Create dummy anndata with batch key. Batch 3 contains 1 sample.; test_ad = ad.AnnData(X=np.random.randn(10,100), ; obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})); #This works fine; sc.pp.highly_variable_genes(test_ad). #This returns division by zero error; #sc.pp.highly_variable_genes(test_ad, batch_key='batch'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ZeroDivisionError Traceback (most recent call last); Cell In[41], line 11; 9 with warnings.catch_warnings(): #ignore future_warning in groupby; 10 warnings.simplefilter(action='ignore', category=FutureWarning); ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count); 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]; 467 adata_subset = adata_subset[:, filt]; --> 469 hvg = _highly_variable_genes_single_batch(; 470 adata_subset,; 471 layer=layer,; 472 min_disp=min_disp,; 473 max_disp=max_disp,; 474 min_mean=min_mean,; 475 max_mean=max_mean,; 476 n_top_genes=n_top_genes,; 477 n_bins=n_bins,; 478 flavor=flavor,; 479 ); 481 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103:475,error,error,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python; sc.pp.neighbors(adata); ```. ### Error output. ```pytb; `api_export.__init__() got an unexpected keyword argument 'metaclass'`; ```. ### Versions. Latest version of scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3143:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. ```; /opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/ehrapy/plot/_scanpy_pl_api.py:606: in <module>; scale: Literal[""area"", ""count"", ""width""] = StackedViolin.DEFAULT_SCALE,; E AttributeError: type object 'StackedViolin' has no attribute 'DEFAULT_SCALE'; ```. ### Minimal code sample. ```python; `import scanpy as sc`; ```. ### Error output. _No response_. ### Versions. Latest main -> pre-release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2899:636,Error,Error,636,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2899,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python; sc.tl.dpt(a1,n_branchings=2); sc.pl.dpt_groups_pseudotime(a1); sc.pl.dpt_timeseries(a1); ```. ### Error output. Error in dpt_timeseries:. ```pytb; WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); Cell In[85], line 1; ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker); 242 # only if number of genes is not too high; 243 if as_heatmap:; 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 245 timeseries_as_heatmap(; 246 adata.X[adata.obs[""dpt_order_indices""].values],; 247 var_names=adata.var_names,; 248 highlights_x=adata.uns[""dpt_changepoints""],; 249 color_map=color_map,; 250 ); 251 else:; 252 # plot time series as gene expression vs time; 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:370,error,error,370,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. i have a trouble when i run neighbors. ### Minimal code sample. ```python; sc.pp.neighbors(adata); ```. ### Error output. ```pytb; computing neighbors; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'; Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'; Traceback (most recent call last):; File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__; self._connected_components = connected_components(self._connectivities); ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:29:05); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141:397,Error,Error,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669:422,error,error-in-highly-variable-gene-selection,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669,3,"['Error', 'error']","['Error', 'error', 'error-in-highly-variable-gene-selection']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. After upgrading annData to 0.10.4 I tried to read in some Visium data with read_10x_mtx(); The resulting table only had one variable (/gene/column), and had it over and over again. ### Minimal code sample. ```python; S = scanpy.read_10x_mtx(mydata); ```. ### Error output. ```pytb; /home/lhw/pkgs/mambaforge/envs/env2/lib/python3.11/site-packages/anndata/_core/anndata.py:1908: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""). In [6]: S.var_names; Out[6]: ; Index(['NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L',; 'NOC2L', 'NOC2L',; ...; 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L',; 'NOC2L', 'NOC2L'],; dtype='object', length=18085). To test, I ran in another environment with scanpy 1.9.6 but annData 0.10.3.; Below are the results:. In [4]: S = scanpy.read_10x_mtx(mydata). In [5]: S.var_names; Out[5]: ; Index(['SAMD11', 'NOC2L', 'KLHL17', 'PLEKHN1', 'PERM1', 'HES4', 'ISG15',; 'AGRN', 'RNF223', 'C1orf159',; ...; 'MT-ND2', 'MT-CO2', 'MT-ATP6', 'MT-CO3', 'MT-ND3', 'MT-ND4L', 'MT-ND4',; 'MT-ND5', 'MT-ND6', 'MT-CYB'],; dtype='object', length=18085); ```. ### Versions; Scanpy 1.9.6; annData 0.10.3 works, annData 0.10.4 does not; <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2825:550,Error,Error,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2825,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675:407,error,error,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello,. With the new scanpy version `1.9.7` I'm not able to plot embeddings such as UMAPs when using numpy `1.23` (it's probably also true for other ""old"" versions of numpy). Note that I can't update numpy to a newer version because of other packages I'm using, but `1.23` is more recent that what scanpy requires anyway (i.e., `numpy>=1.17.0`). For instance, the `spatialdata` library requires `numpy<=1.23.4` because of `xarray-spatial`: thus, it seems that the latest version of `scanpy` is not compatible with `spatialdata` (cc @LucaMarconato for information). The error seems to be due to this commit in `_validate_palette`: https://github.com/scverse/scanpy/commit/d1fe8da28ab4865b6c2b3d9cd151a8186f148844 (@flying-sheep). ### Minimal code sample. ```python; # Just plotting a dummy UMAP. import anndata; import pandas as pd; import numpy as np; import scanpy as sc. n_obs = 10. adata = anndata.AnnData(; X=np.random.randint(0, 5, size=(n_obs, 8)),; obs=pd.DataFrame({; ""cell_type"": np.random.choice([""A"", ""B"", ""C""], size=n_obs)},; index=[str(i) for i in range(n_obs)]; ),; ). sc.pp.neighbors(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""cell_type""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); Cell In[6], line 1; ----> 1 sc.pl.umap(adata, color=""cell_type""). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:674, in umap(adata, **kwargs); 615 @_wraps_plot_scatter; 616 @_doc_params(; 617 adata_color_etc=doc_adata_color_etc,; (...); 621 ); 622 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:; 623 """"""\; 624 Scatter plot in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830:860,error,error,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi all. I was having issues generating rank gene groups. The error is as below. When I used the ""Manuscript_Identity"" group, I got such error message, but when I used another group ""CellType_Category"", it worked. These two groups are in the same type. Could you tell me how to fix it?; Look forward to your response, thanks a lot!. ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata_sc, groupby=""Manuscript_Identity"", use_raw=False). adata_sc.obs['CellType_Category'].cat.categories; Index(['Endothelial', 'Epithelial', 'Lymphoid', 'Multiplet', 'Myeloid',; 'Stromal'],; dtype='object'); adata_sc.obs['Manuscript_Identity'].cat.categories; Index(['ATI', 'ATII', 'Aberrant_Basaloid', 'B', 'B_Plasma', 'Basal',; 'Ciliated', 'Club', 'DC_Langerhans', 'DC_Mature', 'Fibroblast',; 'Goblet', 'ILC_A', 'ILC_B', 'Ionocyte', 'Lymphatic', 'Macrophage',; 'Macrophage_Alveolar', 'Mast', 'Mesothelial', 'Multiplet',; 'Myofibroblast', 'NK', 'PNEC', 'Pericyte', 'SMC', 'T', 'T_Cytotoxic',; 'T_Regulatory', 'VE_Arterial', 'VE_Capillary_A', 'VE_Capillary_B',; 'VE_Peribronchial', 'VE_Venous', 'cDC1', 'cDC2', 'cMonocyte',; 'ncMonocyte', 'pDC'],; dtype='object'); ```. ### Error output. ```pytb; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 592, in rank_genes_groups; test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 106, in __i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:352,error,error,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:458,error,error,458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I was trying to extract gene expression mean values per Subject, so I have a dataframe with genes in columns, subjects in rows, and the mean values of the expression. . To obtain the mean values for each Subject for the selected genes, I ran the following command:; `adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0))`. Having a look at the expression of genes in a specific Subject, it looks like this:. ![image](https://github.com/scverse/scanpy/assets/94078098/f9d7443c-3837-4054-b930-4864d07f9434). However, the mean expression value for NTM is 0. and for CRYAB is 1.56, what it doesn't make sense with the heatmap plot. Am I doing wrong in the extraction of mean values?. Thanks!. ### Minimal code sample. ```python; adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0)); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2740:1149,Error,Error,1149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2740,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am following the tutorial but everytime I try to run a violin plot the kernel crashes, this doesnt happen with other seaborn graphs. I have tried updating packeges, changing environment, etc, etc & nothing works any help would be great !!. ![image](https://github.com/scverse/scanpy/assets/127498480/b5cc12b1-00af-4919-abd0-7ea99b72cade). ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(; 'data/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`; adata; sc.pl.highest_expr_genes(adata, n_top=20, ); sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0-4, multi_panel=True); ```. ### Error output. ```pytb; Kernel Restarting; The kernel for Tests/scanpytutorial/Untitled.ipynb appears to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840:769,error,errors,769,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840,1,['error'],['errors']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:570,Error,Error,570,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:587,error,error,587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: ; upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names; result = pd.DataFrame(; {group + '_' + key: results[key][group]; for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []; for i in groups:; group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]; group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}); group['group'] = i; de_results.append(group); de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True); de_results; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2628:1719,Error,Error,1719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I expect `<code/>`, not `<cite/>`. ![grafik](https://github.com/scverse/scanpy/assets/291575/0874f428-c7a6-495f-9451-502afdc28c13). It has nothing to do with our custom the following, I checked:. 1. scanpydoc; 2. our custom `cite` extension. I assume it’s MyST breaking `default_role`. ### Minimal code sample. ```markdown; Params; ------; foo; 	x `y` z; ```. ### Error output. ```html; <dt>foo; <dd>x <cite>y</cite> z; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2829:655,Error,Error,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2829,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:720,error,error,720,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2564:418,error,error,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564,3,"['Error', 'down', 'error']","['Error', 'downgrade', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just copied the code of official example, and changed the path to my own documents. But it seems that it doesn't work. One folder of the total containing ""barcodes"", ""features"" and ""matrix"" has been attached below and the entire raw data comes from here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE139324. ### Minimal code sample. ```python; import scanpy as sc. path = r'RAW'; adata = sc.read_10x_mtx('RAW/HD PBMC_1/',var_names='gene_symbols', cache=True) ; adata.var_names_make_unique(); sc.pp.filter_cells(adata, min_genes=200) ; sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; IndexError: index (2444) out of range; ```. ### Versions. <details>. ```. ```. </details>. [HD PBMC_1.zip](https://github.com/scverse/scanpy/files/13404294/HD.PBMC_1.zip); ![2](https://github.com/scverse/scanpy/assets/147734739/0db8909d-84e4-41c5-8beb-09480d7adc3a)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2759:886,Error,Error,886,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2759,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2542:327,error,error,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I'm encountering an error when running the sc.pl.rank_genes_groups_heatmap function in the scanpy package. The error message is ""Linkage 'Z' contains negative distances."" What could be causing this error and how can I fix it?. ### Minimal code sample. ```python; sc.pl.rank_genes_groups_heatmap(adata, n_genes=10, groupby='clusters',show_gene_labels=True,save='cluster.markers.heatmap.svg'); ```. ### Error output. ```pytb; sc.pl.rank_genes_groups_heatmap(adata, n_genes=10, groupby=cluster,show_gene_labels=True,save=(id+'_processed.top10.cluster.markers.heatmap.svg')); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 673, in rank_genes_groups_heatmap; return _rank_genes_groups_plot(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 592, in _rank_genes_groups_plot; return heatmap(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1087, in heatmap; dendro_data = _reorder_categories_after_dendrogram(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 2134, in _reorder_categories_after_dendrogram; key = _get_dendrogram_key(adata, dendrogram, groupby); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 2236, in _get_dendrogram_key; dendrogram(adata, groupby, key_added=dendrogram_key); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py"", line 143, in dendrogram; dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scipy/cluster/hierarchy.py"", line 3301, in dendrogram; is_valid_linkage(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804:311,error,error,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804,4,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I'm trying to use `sc.pl.spatial` with the dataset that is available on 10X Visium with the sample ID `CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma`. I can open and do some basic QC just fine, but when I try to plot, I get the error `TypeError: can't multiply sequence by non-int of type 'float`. ### Minimal code sample. ```python; import scanpy as sc; import anndata as an; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as plt; import seaborn as sns; import scanorama. sc.set_figure_params(facecolor=""white"", figsize=(8, 8)); sc.settings.verbosity = 3. # Loading dataset; adata = sc.read_visium(; path=r""\external"",; count_file=""CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5"",; load_images=True,; source_image_path=r""\spatial"",; ). adata.var_names_make_unique(). # Quality control; adata.var[""mito""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(; adata, qc_vars=[""mito""], percent_top=None, log1p=False, inplace=True; ); sc.pl.spatial(adata); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""\scanpy\plotting\_tools\scatterplots.py"", line 1002, in spatial; File ""\plotting\_tools\scatterplots.py"", line 391, in embedding; # if user did not set alpha, set alpha to 0.7; File ""\scanpy\plotting\_utils.py"", line 1107, in circles; if scale_factor != 1.0:; TypeError: can't multiply sequence by non-int of type 'float'; ```; The json file on the spatial folder with the scale factors is as follows:. ```json; {; ""regist_target_img_scalef"": 0.16836435,; ""tissue_hires_scalef"": 0.056121446,; ""tissue_lowres_scalef"": 0.016836435,; ""fiducial_diamet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778:350,avail,available,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778,2,"['avail', 'error']","['available', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2570:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:427,avail,available,427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,2,"['Error', 'avail']","['Error', 'available']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In scanpy version 1.9.3. ### Minimal code sample. ```python; adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2565:602,Error,Error,602,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:418,Error,Error,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:331,error,error,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2730:498,error,error,498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2747:594,Error,Error,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The `read_10x_mtx()` function does not work due to the update of the anndata package to 0.10.4 (January 14, 2024); (?Error reading the file *features.tsv.gz*). The launch was carried out on the following data: ; https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5733023. You can also download files using my google drive:; https://drive.google.com/drive/folders/1p6ilbsJX_cYZb4HG0OSbLHAwQObqmncW?usp=sharing. # **My actions**:. 1) I have installed the latest version of `scanpy=1.9.6` using conda:; ```console; $ conda --version; conda 23.10.0; $ conda install scanpy; # Channels:; # - conda-forge; # - bioconda; # - defaults; # Platform: linux-64. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.4 pyhd8ed1ab_0 conda-forge; array-api-compat 1.4 pyhd8ed1ab_0 conda-forge; brotli 1.1.0 hd590300_1 conda-forge; brotli-bin 1.1.0 hd590300_1 conda-forge; bzip2 1.0.8 hd590300_5 conda-forge; c-ares 1.25.0 hd590300_0 conda-forge; ca-certificates 2023.11.17 hbcca054_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.11.17 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; contourpy 1.2.0 py311h9547e67_0 conda-forge; cycler 0.12.1 pyhd8ed1ab_0 conda-forge; exceptiongroup 1.2.0 pyhd8ed1ab_2 conda-forge; fonttools 4.47.2 py311h459d7ec_0 conda-forge; freetype 2.12.1 h267a509_2 conda-forge; get-annotations 0.1.2 pyhd8ed1ab_0 conda-forge; h5py 3.10.0 nompi_py311hebc2b07_101 conda-forge; hdf5 1.14.3 nompi_h4f84152_100 conda-forge; icu 73.2 h59595ed_0 conda-forge; joblib 1.3.2 pyhd8ed1ab_0 conda-forge; keyutils 1.6.1 h166bdaf_0 conda-forge; kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:408,Error,Error,408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,2,"['Error', 'down']","['Error', 'download']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:333,Error,Error,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,4,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I install scanpy==1.9.6 with pip (anndata==0.10.4), something wrong and adata.X.nnz is 0.; I changed the version of anndata to 0.9.2, it works normal. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(my_sample, # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=False) # write a cache file for faster subsequent reading; # sc.pl.highest_expr_genes(adata, n_top=20, ); adata.X.nnz; ```. ### Error output. _No response_. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.5; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; bottleneck 1.3.5; cffi 1.16.0; comm 0.1.2; cycler 0.12.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 4.4.2; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; hurry NA; ipykernel 6.25.0; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.7; numpy 1.26.0; packaging 23.2; pandas 1.5.3; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydev",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2822:584,error,errors,584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2822,1,['error'],['errors']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization ; After 1 runs, maximum modularity is Q = 0.794615; After 16 runs, maximum modularity is Q = 0.796318; Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python; from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)); phenograph = external.tl.phenograph ; cluster_ph = phenograph(df.values, k=60, method='leiden')[0]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.4; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; functions NA; google NA; h5py 3.9.0; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.3.2; jupyter_server 1.18.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1rc1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; plotly 5.14.1; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.11.2; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2653:874,Error,Error,874,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to produce a violin plot using `pl.rank_genes_groups_violin()` of the ranked genes and passing `gene_symbols=""gene_symbols""` I get a `KeyError`. However `pl.rank_genes_groups()` works fine with the option `gene_symbols=""gene_symbols""` and the same `adata` object. ### Minimal code sample. ```python; sc.pl.rank_genes_groups_violin(; adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; ); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[258], line 1; ----> 1 sc.pl.rank_genes_groups_violin(; 2 adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; 3 ). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/plotting/_tools/__init__.py:1157, in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 1155 if isinstance(_gene_names, np.ndarray):; 1156 _gene_names = _gene_names.tolist(); -> 1157 df = obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols); 1158 new_gene_names = df.columns; 1159 df['hue'] = adata.obs[groups_key].astype(str).values. File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/get/get.py:272, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 269 else:; 270 alias_index = None; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,; 275 ""obs"",; 276 keys,; 277 alias_index=alias_index,; 278 use_raw=use_raw,; 279 ); 281 # Make df; 282 df = pd.DataFrame(index=adata.obs_names). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2540:728,Error,Error,728,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2540,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using sc.pl.highest_expr_genes, seaborn throws a FutureWarning. Specifically:. envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead. ### Minimal code sample. ```python; sc.pl.highest_expr_genes(adata, n_top=20, ); ```. ### Error output. ```pytb; envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; asttokens NA; backcall 0.2.0; comm 0.1.2; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 0.8.3; h5py 3.10.0; ipykernel 6.25.0; jedi 0.18.1; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 23.1; pandas 2.1.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.1.1; pytz 2023.3.post1; scipy 1.11.3; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; stack_data 0.2.0; statsmodels 0.14.0; threadpoolctl 3.2.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.7.1; umap 0.5.4; wcwidth 0.2.5; zmq 25.1.0; -----; IPython 8.15.0; jupyter_client 8.6.0; jupyter_core 5.5.0; ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2755:672,Error,Error,672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2755,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ﻿﻿; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:394,error,error,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. hello, why dose my code ""sc.pp.filter_genes(adata, min_cells=3)"" error after running ""sc.pp.filter_cells(adata, min_genes=200)""?. ### Minimal code sample. ```python; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; ERROR:. /root/anaconda3/envs/c2s/lib/python3.11/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; /root/anaconda3/envs/c2s/lib/python3.11/site-packages/anndata/_core/views.py:79: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; ____________________________________________________________________________________________________; AND the process is out of memory. [17371499.406473] Out of memory: Killed process 465550 (python) total-vm:132596812kB, anon-rss:129055148kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:253640kB oom_score_adj:0; ```. ### Versions. <details>; scanpy 1.9.5; python 3.11.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2754:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure.; The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error; Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,; then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`; It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python; adata: any anndata; markers: gene list include in var_names; group: obs key; celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(; 	adata, markers, group, show=False, swap_axes=True,; 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,; ); ```. ### Error output. ```pytb; K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:856,Error,Error,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python; See `test_scrublet_data` under `anndata_dev`; ```. ### Error output. ```pytb; E AssertionError: ; E Not equal to tolerance rtol=1e-15, atol=1e-15; E ; E Mismatched elements: 1 / 200 (0.5%); E Max absolute difference: 0.0126501664; E Max relative difference: 0.1823112224; E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,; E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,; E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,...; E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,; E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,; E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,...; ```. ### Versions. <details>. ```; Package Version; ----------------- -------------------------; anndata 0.11.0.dev114+g105f354; annoy 1.17.3; scipy 1.13.0; scprep 1.1.0; seaborn 0.13.2; session-info 1.0.0; setuptools 69.5.1; setuptools-scm 8.1.0; six 1.16.0; sniffio 1.3.1; sortedcontainers 2.4.0; sparse 0.16.0a6; statsmodels 0.14.2; stdlib-list 0.10.0; tasklogger 1.2.0; tblib 3.0.0; texttable 1.7.0; textual 0.60.1; threadpoolctl 3.5.0; tifffile 2024.5.10; toolz 0.12.1; tornado 6.4; tqdm 4.66.4; typing-extensions 4.12.0rc1; tzdata 2024.1; uc-micro-py 1.0.3; umap-learn 0.5.6; urllib3 2.2.1; uv 0.1.44; virtualenv 20.26.2; wrapt 1.16.0; zarr 2.18.1; zi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3068:577,error,errors,577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068,3,"['Error', 'error', 'toler']","['Error', 'errors', 'tolerance']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Function Rank_genes_groups() does not return a figure -> returns None type; Cannot get Figure via plt.gcf(), plt.gca(). Potential Fix:; https://github.com/scverse/scanpy/blob/main/src/scanpy/plotting/_tools/__init__.py; Line 485: cann be extended to the following as in other functions below:; ```; savefig_or_show(f""{key}_"", show=show, save=save); show = settings.autoshow if show is None else show; if show:; return None; return ax; ```. ### Minimal code sample. ```python; fig = sc.pl.rank_genes_groups(adata, show=False); type(fig); #NoneType; plt.gca() -> empty axes; plt.gcf() -> empty figure; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.8; scanpy 1.10.2; -----; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3205:898,Error,Error,898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. HVG can produce more than the number of genes asked for as highly variable. This occurs on these two datasets:. ```; wget https://datasets.cellxgene.cziscience.com/e00ab1f4-28cd-497d-b889-94d45840f423.h5ad; ```. ### Minimal code sample. ```python; import scanpy as sc. adata1 = sc.read('e00ab1f4-28cd-497d-b889-94d45840f423.h5ad'). sc.pp.normalize_total(adata1, target_sum=1e4). sc.pp.log1p(adata1). n_top_gene = 10000; sc.pp.highly_variable_genes(adata1, n_top_genes = n_top_gene). hvg_system1 = set(adata1.var[adata1.var['highly_variable']].index); assert len(hvg_system1) == n_top_gene, f""found {len(hvg_system1)} instead of {n_top_gene}"". ```. ### Error output. ```pytb; AssertionError Traceback (most recent call last); Cell In[12], line 1; ----> 1 assert len(hvg_system1) == n_top_gene, f""found {len(hvg_system1)} instead of {n_top_gene}"". AssertionError: found 13355 instead of 10000; ```. ### Versions. <details>. ```; import scanpy; scanpy.logging.print_versions(); -----; anndata 0.10.8; scanpy 1.10.0rc2.dev85+gb918a23e; -----; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157:941,Error,Error,941,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi,. Thanks a lot for helping!; I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""); AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks!. Best,; B. ### Minimal code sample. ```python; sc.pp.scrublet(adata, batch_key=""lib_prep""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); /tmp/ipykernel_54187/3500521297.py in <module>; ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; backcall 0.2.0; cffi 1.14.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; exceptiongroup 1.2.0; get_annotations NA; google NA; h5py 3.10.0; importlib_resources NA; ipykernel 6.2.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.2; matplotlib_inline NA; mpl_toolkits NA; mudata 0.2.3; muon 0.1.6; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 21.0; pandas 2.1.3; parso 0.8.2; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.11; pyparsing 2.4.7; pytz 2023.3.post1; scipy 1.11.4; scrublet NA; seaborn 0.12.2; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.3.2; statsmodels 0.14.0; storemagic NA; threadpoolctl 3.2.0; torch 1.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3026:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi,; since statsmodels 0.14, perfect separation no longer raises an error but a warning (see [function doc here](https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html#statsmodels-genmod-generalized-linear-model-glm)). Because scanpy currently only catches the now-outdated error (instead of catch the warning), users may see many warnings from `regress_out` when no perfect separation exists (see usage in scanpy [here](https://github.com/scverse/scanpy/blob/main/src/scanpy/preprocessing/_simple.py#L759-L761)). It seems to follow on the heels of [this issue](https://github.com/statsmodels/statsmodels/issues/2680) in statsmodels. I propose to implement that the warning is caught just as the errors were being caught.; Cheers,; Jesko. ### Minimal code sample. ```python; import anndata as ad; import scanpy as sc; import numpy as np; import pandas as pd; adata = ad.AnnData(np.array([[0,0,1,1]]).T, obs=pd.DataFrame({""a"":[0,0,1,1]})); sc.pp.regress_out(adata, ""a""); ```. ### Error output. ```pytb; .../statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified; warnings.warn(msg, category=PerfectSeparationWarning); ```. ### Versions. <details>. ```; anndata 0.10.4; scanpy 1.9.6; statsmodels 0.14.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3260:357,error,error,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3260,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have always had a question: do I need to scale my adata before running sc.tl.score_genes?. ### Minimal code sample. ```python; sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes); ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3080:523,Error,Error,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Leiden and Louvain clustering params are not saved to matching `key_added` key in `uns` dictionary but are ovewritten to hardcoded key instead. One use case is that a user may want to run Leiden/Louvain clustering multiple times with different resolutions / parameters. One may specify different keys to store results under. However, if you do so, the metadata for the parameterization of the clustering algorithms are overwritten because the lines below do not respect the user provided `key_added` parameter. I think the desired behavior is to store data under `adata.uns[key_added][""params""]`. I think I've found the pertinent lines below. Happy to submit a PR if maintainers agree :D.; - https://github.com/scverse/scanpy/blob/91ea0fbb03392795d1506d297d4b4847c646db04/scanpy/tools/_leiden.py#L206; - https://github.com/scverse/scanpy/blob/91ea0fbb03392795d1506d297d4b4847c646db04/scanpy/tools/_louvain.py#L259. ### Minimal code sample. ```python; sc.tl.leiden(adata, resolution=0.8, key_added=""leiden_0.8""); assert ""leiden_0.8"" not in adata.uns; params = adata.uns[""leiden""] . sc.tl.leiden(adata, resolution=1.2, key_added=""leiden_1.2""); assert ""leiden_1.2"" not in adata.uns; overwritten_params = adata.uns[""leiden""] ; assert params == overwritten_params # should fail; ```. ### Error output. _No response_. ### Versions. <details>; Confirmed that params are overwritten in source in main branch. (see permalinks); </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2887:1572,Error,Error,1572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2887,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Shouldn't max Value for `scale` and zero_center also clip the negative values?. ### Minimal code sample. ```python; bdata = sc.datasets.pbmc3k(); sc.pp.scale(bdata,max_value= 1); print(bdata.X.min(),bdata.X.max()); ```. ### Error output. ```pytb; -2.62718 1.0. shouldn't this be -1,1; ```. ### Versions. scanpy build from github main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2912:513,Error,Error,513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2912,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. The column label and color is wrong after using 'swap_axes=True'; ![lyz1](https://github.com/user-attachments/assets/1783ed72-a9ad-457a-afdf-bf6f10fd766f); ![lyz2](https://github.com/user-attachments/assets/3c819376-ba09-49b4-a645-aa8e7b1bf3a9). ### Minimal code sample. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon',tie_correct=True,pts=True,key_added='wilcoxon'); sc.pl.rank_genes_groups_stacked_violin(adata, n_genes=5, key=""wilcoxon"", groupby=""bulk_labels""); sc.pl.rank_genes_groups_stacked_violin(adata, n_genes=5, key=""wilcoxon"", groupby=""bulk_labels"",swap_axes=True); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.2.0; attrs 23.2.0; babel 2.14.0; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; google NA; h5py 3.11.0; idna 3.7; igraph 0.11.4; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.0; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numpy 1.26.4; nvfuser NA; opt_einsum v3.3.0; overrides NA; packaging 24.0; pandas 1.5.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3152:962,Error,Error,962,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3152,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks!. ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python; sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[37], line 1; ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax); 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""); 161 if (; 162 (x in adata.obs.keys() or x in var_index); 163 and (y in adata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102:763,Error,Error,763,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When reading docs from the readthedocs website, clicking the ""source"" link will navigate to the wrong spot. I think the structure was changed slightly in a commit since these were updated. The locations are still obtainable by manually walking the tree, but they are no longer what is pointed to in those [source] links. I am happy to try my hand at a fix, I just need some direction in terms of whether this is would be helpful, and how the docs are updated. ; This is where I am navigated to when i click the link for scanpy.pp.calculate_qc_metrics.; <img width=""690"" alt=""image"" src=""https://github.com/user-attachments/assets/1cd8f7ba-a54b-49c4-9f00-a19633d5e606"">. ### Minimal code sample. ```python; no code, UI fix.; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3219:1022,Error,Error,1022,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3219,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:402,down,downstream,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['down'],['downstream']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. aggregate throws error when aggregating `obsm` or `varm`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean"", obsm=""X_umap""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[3], line 1; ----> 1 sc.get.aggregate(pbmc, by=""louvain"", func=""mean"", obsm=""X_umap""). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/functools.py:909, in singledispatch.<locals>.wrapper(*args, **kw); 905 if not args:; 906 raise TypeError(f'{funcname} requires at least '; 907 '1 positional argument'); --> 909 return dispatch(args[0].__class__)(*args, **kw). File /mnt/workspace/repos/scanpy/scanpy/get/_aggregated.py:272, in aggregate(adata, by, func, axis, mask, dof, layer, obsm, varm); 264 # Actual computation; 265 layers = aggregate(; 266 data,; 267 by=categorical,; (...); 270 dof=dof,; 271 ); --> 272 result = AnnData(; 273 layers=layers,; 274 obs=new_label_df,; 275 var=getattr(adata, ""var"" if axis == 0 else ""obs""),; 276 ); 278 if axis == 1:; 279 return result.T. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:271, in AnnData.__init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, obsp, varp, oidx, vidx); 269 self._init_as_view(X, oidx, vidx); 270 else:; --> 271 self._init_as_actual(; 272 X=X,; 273 obs=obs,; 274 var=var,; 275 uns=uns,; 276 obsm=obsm,; 277 varm=varm,; 278 raw=raw,; 279 layers=layers,; 280 dtype=dtype,; 281 shape=shape,; 282 obsp=obsp,; 283 varp=varp,; 284 filename=filename,; 285 fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:306,error,error,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. cc: @Intron7 . The array types returned for the various aggregations in `sc.get.aggregate` are different (see example). This can lead to somewhat confusing behavior downstream, especially while we are using the sparse matrix classes. I would suggest we default to a dense result and consider adding an argument `array_type` that determines the type of the arrays added to `layers`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(). aggregated = sc.get.aggregate(adata, ""louvain"", [""sum"", ""count_nonzero""]); type(aggregated.layers[""sum""]); # numpy.ndarray. type(aggregated.layers[""count_nonzero""]); # scipy.sparse._csr.csr_matrix; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.10.0.dev315+gf6d5ac94; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.1; dateutil 2.8.2; decorator 5.1.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.11.3; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.41.1; markupsafe 2.1.4; matplotlib 3.8.2; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.9.0; prompt_toolkit 3.0.43; psutil 5.9.8; ptyprocess 0.7.0; pure_eval 0.2.2; pygments 2.17.2; pyparsing 3.1.1; pytz 2023.4; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.0; sparse 0.15.1; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.1; toolz 0.12.1; traitlets 5.14.1; wcwidth 0.2.13; yaml 6.0.1; zarr 2.16.1; zipp NA; -----; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2892:454,down,downstream,454,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2892,2,"['Error', 'down']","['Error', 'downstream']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. was running the standard pipeline on some data and when i run; `sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False) `; it spits out infinite lines of ignored exceptions. it does not actually crash the kernel, but does bog it down and causes everything to to take much more time than necesarry. ; I am working in a conda env on a Win 10 , 64bit, x64 system; the problem also occurs using the pbmc3k dataset. ### Minimal code sample. ```python; # example with own data, but same happens with pbmc3k data; sc.pp.filter_cells(em_adata, min_genes=200); sc.pp.filter_genes(em_adata, min_cells=3); em_adata.shape; # [out] -> (42753, 21636). sc.pp.calculate_qc_metrics(em_adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True); em_adata.obs[""outlier_mt""] = em_adata.obs.pct_counts_mt > 15; em_adata.obs[""outlier_total""] = em_adata.obs.total_counts > 30000; em_adata.obs[""outlier_ngenes""] = em_adata.obs.n_genes_by_counts > 6000; em_adata = em_adata[~em_adata.obs[""outlier_mt""], :]; em_adata = em_adata[~em_adata.obs[""outlier_total""], :]; em_adata = em_adata[~em_adata.obs[""outlier_ngenes""], :]; sc.pp.filter_genes(em_adata,min_cells=1). sc.pp.scrublet(em_adata); em_adata.layers['counts'] = em_adata.X.copy(); sc.pp.normalize_total(em_adata); sc.pp.log1p(em_adata); sc.pp.highly_variable_genes(em_adata,flavor='seurat'); sc.pl.highly_variable_genes(em_adata); em_adata = em_adata[:, em_adata.var[""highly_variable""]]; em_adata.shape; # [out] -> (41749, 1425); sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```. ### Error output. ```pytb; Exception i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969:549,down,down,549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969,1,['down'],['down']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. 导入scanpy1.9.1时，matplotlib在3.7版本以下然后发生元类错误. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>; from util import *; File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>; import scanpy as sc; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>; from . import plotting as pl; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>; from ._anndata import (; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>; from . import _utils; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. 进程已结束,退出代码1; ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029:398,Error,Error,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. ![image](https://github.com/scverse/scanpy/assets/43333475/08fe247f-bd56-4b6c-b9e5-5a69499e7b44). Hi, I intend to use n_top_gene to determine the number of hvgs I intend to have, but I met such errors. I used to meet this error previously, but no effective solutions. . Could you please double check it? Thanks. ### Minimal code sample. ![image](https://github.com/scverse/scanpy/assets/43333475/08fe247f-bd56-4b6c-b9e5-5a69499e7b44). ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>. anndata 0.9.2; scanpy 1.9.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819:485,error,errors,485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819,3,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629:691,down,down,691,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629,1,['down'],['down']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi!. My recent PR (https://github.com/scverse/scanpy/pull/2772) made me realize that `.getnnz(axis=xx)` is used in several places in the codebase. From the Scipy docs for sparse arrays:; > Deprecated since version 1.11.0: This method will be removed in SciPy 1.13.0. Use X.nnz instead. The axis argument will no longer be supported; please let us know if you still need this functionality. From what I understand, sparse *matrices* should be fine. Can we assume that an AnnData contains a sparse matrix and not a sparse array? If not, it may be good to do one or more of the following:; - Preventively put scipy < 1.13 in the requirements; - Signal to Scipy that the `axis` argument is important to this widely used package. Pinging @dschult again for that; - At some point move to `.nnz`. Best,. GJ. (edited because I originally confused `csr_array` and `csr_matrix`). ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; latest; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2773:1016,Ping,Pinging,1016,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2773,2,"['Error', 'Ping']","['Error', 'Pinging']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with ; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this?. ### Minimal code sample. ```python; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48; ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2634:414,down,download,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634,2,"['Error', 'down']","['Error', 'download']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. N/A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2609:684,Error,Error,684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:514,error,errored,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,2,"['Error', 'error']","['Error', 'errored']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was trying to install `scanpy=1.9.6` using conda in a `python=3.9` environment that had 1.9.5 working with `seaborn=0.13`.; Conda raised a solving issue due to ; `package scanpy-1.9.6-pyhd8ed1ab_0 requires seaborn !=0.13.0, but none of the providers can be installed`; I tried the second build (1ab_1) and the error stayed:; ` package scanpy-1.9.6-pyhd8ed1ab_1 requires seaborn !=0.13.0, but none of the providers can be installed`. I checked github and saw that the dependency in `pyproject.toml` is `""seaborn>=0.13.0""` but when i checked the conda package's `index.json` i saw `""seaborn !=0.13.0""`. The discrepancy between the dependencies is unclear. the full `index.json`:; ```json; {; ""arch"": null,; ""build"": ""pyhd8ed1ab_1"",; ""build_number"": 1,; ""depends"": [; ""anndata >=0.7.4"",; ""get-annotations"",; ""h5py >=3"",; ""joblib"",; ""matplotlib-base >=3.6"",; ""natsort"",; ""networkx >=2.3"",; ""numba >=0.41"",; ""numpy >=1.17"",; ""packaging"",; ""pandas >=1.1.1,!=2.1.2"",; ""patsy"",; ""python >=3.8"",; ""scikit-learn >=0.24"",; ""scipy >=1.4"",; ""seaborn !=0.13.0"",; ""session-info"",; ""statsmodels >=0.11"",; ""tqdm"",; ""umap-learn >=0.3.10""; ],; ""license"": ""BSD-3-Clause"",; ""license_family"": ""BSD"",; ""name"": ""scanpy"",; ""noarch"": ""python"",; ""platform"": null,; ""subdir"": ""noarch"",; ""timestamp"": 1699376683854,; ""version"": ""1.9.6""; }; ```. ### Minimal code sample. ```python; conda create -n test ""python=3.9"" ""scanpy=1.9.6"" ""seaborn=0.13"" -c conda-forge; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2791:603,error,error,603,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2562:785,Error,Error,785,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Many different calls in scanpy emit warnings that are currently suppressed by our testing framework (I think). . ### Minimal code sample. I discovered this unrelatedly by editing the notebooks, see for example: https://github.com/scverse/scanpy-tutorials/blob/master/spatial/integration-scanorama.ipynb. @flying-sheep mentioned that the scanpy tests filter out warnings and indeed you can reproduce these by e.g.,:; ```sh; pytest -W error::FutureWarning -n auto scanpy/tests/test_plotting.py; ```. ### Error output. - [x] `…/scanpy/plotting/_tools/scatterplots.py:401:`. > UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored. - [x] `…/scanpy/plotting/_tools/__init__.py:1269:`. > FutureWarning: The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect. ; > `_ax = sns.violinplot(`. - [x] `…/scanpy/preprocessing/_simple.py:274:`. > ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; > `adata.var[""n_cells""] = number`. - [x] `…/scanpy/plotting/_stacked_violin.py:503: FutureWarning:`. > Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect. ; > `row_ax = sns.violinplot(`. ### Versions. <details>. ```; -----; anndata 0.10.4; scanpy 1.10.0.dev191+gf7f5d5c6; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cffi 1.16.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.0; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jedi 0.19.1; jinja2 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2839:724,error,error,724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2839,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Running the highly_variable_genes function produced an error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[101], line 2; 1 # Identify highly-variable genes and plot; ----> 2 sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:440, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2547:346,error,error,346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why it’s happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2688:796,Error,Error,796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688,2,"['Error', 'FAILURE']","['Error', 'FAILURES']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The test suite keeps failing with a segfault on the `python=3.9` build. I haven't been able to reproduce locally. Interestingly, I haven't seen it error when I rerun the check. It looks like this always happens during the call to `nn_approx`. ### Minimal code sample. ```python; NA; ```. ### Error output. ```pytb; platform linux -- Python 3.9.18, pytest-8.0.1, pluggy-1.4.0 -- /opt/hostedtoolcache/Python/3.9.18/x64/bin/python; cachedir: .pytest_cache; rootdir: /home/vsts/work/1/s; configfile: pyproject.toml; testpaths: scanpy; plugins: nunit-1.0.6, mock-3.12.0; [1mcollecting ... [0mcollected 1474 items. scanpy/_utils/compute/is_constant.py::scanpy._utils.compute.is_constant.is_constant [32mPASSED[0m[32m [ 0%][0m; scanpy/datasets/_ebi_expression_atlas.py::scanpy.datasets._ebi_expression_atlas.ebi_expression_atlas [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pl.py::scanpy.external.pl.phate [33mSKIPPED[0m (needs modul...)[32m [ 0%][0m; scanpy/external/pp/_bbknn.py::scanpy.external.pp._bbknn.bbknn [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_harmony_integrate.py::scanpy.external.pp._harmony_integrate.harmony_integrate [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_hashsolo.py::scanpy.external.pp._hashsolo.hashsolo [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_magic.py::scanpy.external.pp._magic.magic [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_scanorama_integrate.py::scanpy.external.pp._scanorama_integrate.scanorama_integrate Fatal Python error: Illegal instruction. Thread 0x00007f00347c4640 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 316 in wait; File ""/opt/hostedtoolcache/Python/3.9.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python; sc.tl.filter_rank_genes_groups; sc.tl.filter_rank_genes_groups; Both default use; ```. ### Error output. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /; ```. ### Versions. anndata: 0.9.2; scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2666:653,Error,Error,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When reading the `tissue_positions.csv` file generated by SpaceRanger v2.0 or later, `read_visium` reads the header from the second row (with `header=1`), while it should read from the first row instead (with `header=0`). ### Minimal code sample. ```python; positions = pd.read_csv(; files['tissue_positions_file'],; header=0 if tissue_positions_file.name == ""tissue_positions.csv"" else None,; index_col=0,; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.2; scanpy 1.10.0.dev157+g9b7f6032; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2746:711,Error,Error,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2746,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running the tests with pytest<=8, the doctest for `scanpy.preprocessing._simple.filter_cells` errors in a way I can't quite figure out how to fix. . I think what's happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most rec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:390,error,errors,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,3,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2506:359,error,errors,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506,3,"['avail', 'error']","['available', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using `sc.queries.biomart_annotations`, it still generates the file `.pybiomart.sqlite` even when `use_cache=False` is used. To me this is a problem because the generated hidden file interferes with `Omnipath` and makes it crash. It used to be the case that `use_cache` used to work but not anymore. . Thank you for your time. ### Minimal code sample. ```python; import scanpy as sc. annot = sc.queries.biomart_annotations(; 'hsapiens',; ['ensembl_gene_id', 'external_gene_name'],; use_cache=False; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.8; -----; PIL 10.2.0; asttokens NA; attr 23.1.0; attrs 23.1.0; brotli 1.1.0; cattr NA; cattrs NA; certifi 2023.11.17; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; executing 2.0.1; future 0.18.3; h5py 3.10.0; idna 3.4; igraph 0.11.2; ipykernel 6.26.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.4; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 3.11.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 15.0.0; pybiomart 0.2.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.1.1; pytz 2024.1; requests 2.31.0; requests_cache 1.1.1; scipy 1.11.3; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; socks 1.7.1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.2.0; tornado 6.3.3; traitlets 5.13.0; typing_extensions NA; url_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861:807,Error,Error,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When working on one of the notebooks in `spatialdata-notebooks` I noticed that for `library_id` in `scatterplots.py` the type hints are inconsistent. Specifically here it is indicated to be either `Empty` or `str`:. https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L921. While here the type hint includes `None`:; https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L1287. I think the case should be that None should be included. Very minor, but just noticed it so I thought to open an issue. ### Minimal code sample. ```python; NA; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asciitree NA; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nt NA; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; packaging 23.1; pandas 1.5.3; psutil 5.9.5; pyarrow 12.0.0; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywintypes NA; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; win32api NA; win32com NA; yaml 6.0; zarr 2.14.2; zipp NA; zoneinfo NA; -----; Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:51:25) [MSC v.1934 64 bit (AMD64)]; Windows-10-10.0.22621-SP0. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2539:970,Error,Error,970,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2539,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When you print something in the search bar on the [documentation website](https://scanpy.readthedocs.io/en/stable/index.html), sometimes suggested links are broken. See the example for `sc.pl.umap` below. Using google, I was able to find a correct page. Here is the correct and the broken link:; - Broken: https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.umap.html#scanpy-pl-umap; - Correct: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html#scanpy-pl-umap. The difference is in latest/stable part. I tried searching for other functions as well, but did not notice any pattern. Here are some other links from search suggestion that are broken:; - https://scanpy.readthedocs.io/en/latest/generated/scanpy.external.tl.phenograph.html; - https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.rank_genes_groups_dotplot.html; - Same for other visualizations of rank_genes_group. `tl.rank_genes_groups` works, though. And a related issue. Why doesn't scanpy have a custom 404 page? 😄 . ### Minimal code sample. Here's an example with looking for umap plot:; - Search suggests a page:; ; <img width=""514"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/35199218/893b7a60-d30d-40a2-bc8f-0fbb46b25ce0"">. - First link (to the tool) is correct, but by clicking on the second one (for plotting) user gets 404:. <img width=""907"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/35199218/f56fefd4-ec7c-4afc-953a-96a5832b848c"">. ### Error output. _No response_. ### Versions. I was at the ""stable"" version on the website. Current scanpy version is 1.9.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2763:1765,Error,Error,1765,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2763,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. `@doctest_needs` decorator causes test failures on scanpy import in anndata test suite. https://dev.azure.com/scverse/anndata/_build/results?buildId=5802&view=logs&jobId=0497d03e-5796-547f-cc56-989f8152a63c&j=0497d03e-5796-547f-cc56-989f8152a63c&t=ea3acdad-0250-5b8b-a1da-6cd02463cf17. ### Minimal code sample. ```python; NA; ```. ### Error output. ```pytb; else:; enum_member = enum_class._new_member_(enum_class, *args); if not hasattr(enum_member, '_value_'):; if enum_class._member_type_ is object:; enum_member._value_ = value; else:; try:; enum_member._value_ = enum_class._member_type_(*args); except Exception as exc:; new_exc = TypeError(; '_value_ not set in __new__, unable to create it'; ); new_exc.__cause__ = exc; > raise new_exc; E TypeError: _value_ not set in __new__, unable to create it; ```. ### Versions. <details>. ```; See anndata test failure; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2878:330,failure,failures,330,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2878,3,"['Error', 'failure']","['Error', 'failure', 'failures']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hello scanpy!; First time, please let me know what to fix about my question asking!; When running sc.pp.highly_variable_genes I get this error; ""ImportError: Please install skmisc package via `pip install --user scikit-misc ""; I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python; print(key); adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ); print(adata); ; # Separate RNA and protein data; rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']; protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']; ; # Verify the separated data; print(""RNA data shape:"", rna_data.shape); print(""Protein data shape:"", protein_data.shape); ```. ### Error output. ```pytb; MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085; obs: 'in_tissue', 'array_row', 'array_col'; var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'; uns: 'spatial'; obsm: 'spatial'; RNA data shape: (2256, 18085); Protein data shape: (2256, 0); ```. ### Versions. <details>. ```; 1.10.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3113:1172,Error,Error,1172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Tried to run this function:; sc.tl.leiden(test, resolution = 0.1, restrict_to = ('leiden', ['5'])). and instead it is subsetting cluster 5 into over 400 new subsets, even with my resolution set to 0.1. I've also tried different resolutions and none of them work, it ignores the resolution altogether. ; ![leiden](https://github.com/scverse/scanpy/assets/88872118/7fa7114e-d8ae-4e91-94b6-ece1f9505594). ### Minimal code sample. ```python; sc.tl.leiden(test, resolution = 0.1, restrict_to = ('leiden', ['5'])); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.0.1; appnope 0.1.2; asttokens NA; attr 23.1.0; bottleneck 1.3.5; brotli NA; celltypist 1.6.2; certifi 2023.11.17; cffi 1.16.0; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2022.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; dill 0.3.7; docrep 0.3.2; entrypoints 0.4; exceptiongroup 1.2.0; executing 0.8.3; fsspec 2023.10.0; h5py 3.7.0; idna 3.4; igraph 0.10.8; inflect NA; ipykernel 6.28.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.3; joblib 1.3.2; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.7; numpy 1.26.3; omnipath 1.0.8; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prompt_toolkit 3.0.43; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pyda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906:807,Error,Error,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; np.random.seed(0). # Get AnnData; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X.copy().tocsr(); adata.obs[""Age""] = np.random.randint(0, 6, (2700,)); adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess; sc.pp.filter_genes(adata, min_counts = 10); sc.pp.normalize_total(adata); sc.pp.log1p(adata). # Subset = False; ad_nosub = adata.copy(); sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards; ad_nosub_subbed = ad_nosub.copy(); ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True; ad_sub = adata.copy(); sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True); ```. ### Error output. ```pytb; >>> # As expected; >>> print(np.sum(ad_nosub.var[""highly_variable""])); 1000; >>> ; >>> # As expected; >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])); 1000; >>> ; >>> # Not as expected; >>> print(np.sum(ad_sub.var[""highly_variable""])); 101; ```. ### Versions. <details>. ``` bash; → conda list | grep scanpy; scanpy 1.10.1 pyhd8ed1ab_0 conda-forge. → conda list | grep anndata; anndata 0.10.7 pyhd8ed1ab_0 conda-forge; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3027:1469,Error,Error,1469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. `sc.tl.ingest` uses `pkg_version('anndata')`, which errors out using the latest version of `anndata`. ### Minimal code sample. ```python; from scanpy._compat import pkg_version; pkg_version(""anndata""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ----> 1 pkg_version(""anndata""). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/scanpy/_compat.py:80, in pkg_version(package); 76 @cache; 77 def pkg_version(package):; 78 from importlib.metadata import version as v; ---> 80 return version.parse(v(package)). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:52, in parse(version); 43 def parse(version: str) -> ""Version"":; 44 """"""Parse the given version string.; 45 ; 46 >>> parse('1.0.dev1'); ref='/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:0'>0</a>;32m (...); 50 :raises InvalidVersion: When the version string is not a valid version.; 51 """"""; ---> 52 return Version(version). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:195, in Version.__init__(self, version); 184 """"""Initialize a Version object.; 185 ; 186 :param version:; ...; --> 195 match = self._regex.search(version); 196 if not match:; 197 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.10.0; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cairo 1.23.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; colorlog NA; comm 0.1.4; cupy 12.2.0; cupy_backends NA; cupyx NA; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978:341,error,errors,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978,2,"['Error', 'error']","['Error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python; sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'); ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2670:712,Error,Error,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The exception happened when try to run scanpy `highly_variable_genes` with sparse dataset loaded in backed mode. ### Minimal code sample. ```python; # read backed; adata = anndata.read_h5ad(file_path, backed='r'); X = adata.raw.X if adata.raw is not None else adata.X; # dataset must be sparse there; print(issparse(X[0])); # calculate dispersions; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, inplace=False); ```; True; ```. ### Error output. ```pytb; loop of ufunc does not support argument 0 of type SparseDataset which has no callable expm1 method!; ```. goes from https://github.com/scverse/scanpy/blob/bc349b999be62196aa51b59db6e2daa37f428322/scanpy/preprocessing/_highly_variable_genes.py#L206. ### Versions. <details>. ```; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.3.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; igraph 0.10.2; ipykernel 6.17.1; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.0; llvmlite 0.39.1; louvain 0.8.0; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; numba 0.56.4; numpy 1.23.5; packaging 21.3; pandas 1.2.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.4; plotly 5.11.0; prompt_toolkit 3.0.33; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.6; scipy 1.9.3; session_info 1.0.0; setuptools 62.3.2; sitecustomize NA; six 1.16.0; sklearn 1.1.3; stack_data 0.6.1; texttable 1.6.6; threadpoolctl 3.1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2764:754,Error,Error,754,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2764,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2665:804,Error,Error,804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, . Apologies if I've missed this addressed somewhere else, however I would like to save my figured to a defined directory. It doesn't seem I can do that without first changing the current working directory outside the line of code. What is the best way to save my plot to a specific directory without having to change it each time using os.chdir? . I have seen this [issue](https://github.com/scverse/scanpy/issues/1508#issue-750736685) from 2 years ago but wondered if any changes have been made since. ### Minimal code sample. ```; output_dir_fig = ""chosen/path/to/directory""; sc.pl.highest_expr_genes(adata, n_top=10, save= f""{output_dir_fig}/highest_expr_genes.png""). ```. ### Error output. ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[85], line 1; ----> 1 sc.pl.highest_expr_genes(adata, n_top=10, save= f""{output_dir_fig}/highest_expr_genes.png""). File /opt/anaconda3/envs/scanpy/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/anaconda3/envs/scanpy/lib/python3.11/site-packages/scanpy/plotting/_qc.py:105, in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 103 ax.set_xscale(""log""); 104 show = settings.autoshow if show is None else show; --> 105 _utils.savefig_or_show(""highest_expr_genes"", show=show, save=save); 106 if show:; 107 retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3276:973,Error,Error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi; I am trying to read in my Visium HD file which is in non-zarr format. ; Here is the error that I get. . ### Minimal code sample. from spatialdata_io import visium_hd; import spatialdata as sd. path_read ='...'; sdata= visium_hd(path_read). ### Error output. Its says the dataset_id needs to be specified, but there isn't a dataset_id in my folder. ; I tried specifying dataset_id=""None"" or just blank or some possible names from my parent folder that could be it. ; But it does not read it. . ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3341:377,error,error,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3341,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have non zarr format Visium HD data. ; I tried reading it with sdata = visium_hd(path_read). it keeps asking me for a dataset_id which is not there in the feature_slice file name or my folder. ; Nonetheless, I kept setting it to None or """" or other possible dataset id values. I cannot find any tech support on the error either. . (I also tried specifying the file path to the different binned folders). ### Minimal code sample. path_read = '/Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs'; sdata = visium_hd(path_read). ### Error output. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:606,error,error,606,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,3,"['Down', 'Error', 'error']","['Downloads', 'Error', 'error']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. There are a few instances where the input for `sc.get.obs_df` could be described better to avoid some edge cases that don't throw errors (or throw cryptic errors). . 1. The param descriptions say that `obsm_keys` expects a [Tuple of (key, column)](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L240-L241), but this gives an error:; ```py; adata = sc.datasets.pbmc3k_processed(); sc.get.obs_df(adata, obsm_keys = ('X_pca', 1)); ``` ; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[15], line 1; ----> 1 sc.get.obs_df(adata, obsm_keys = ('X_pca', 1)). File /oak/stanford/groups/pritch/users/emma/miniforge3/envs/perturb-vs-tissue-env/lib/python3.10/site-packages/scanpy/get/get.py:328, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 325 if keys:; 326 df = df[keys]; --> 328 for k, idx in obsm_keys:; 329 added_k = f""{k}-{idx}""; 330 val = adata.obsm[k]. ValueError: too many values to unpack (expected 2); ```; The function works if you pass a list of Tuples:; ```; sc.get.obs_df(adata, obsm_keys = [('X_pca', 1)]); ```; So perhaps the parameter descriptions should say `List of Tuples of (key, column)`? Or the case of extracting a single column should be handled. . 2. The input for the `keys` is described as [""keys""](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L238-L239), but if you pass only one key as a string, the function returns a `pd.Series` instead of a `pd.DataFrame`. This is not a massive problem, unless you also pass something to `obsm_keys`. When you do that, the function",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3310:419,error,errors,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310,3,['error'],"['error', 'errors']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we tried to compute QC metrics for our dataset we got this error (see title). Produced by the X.eliminate_zeros() call. We also traced the error back to genes that have only zeros in them, which would remove these columns and thus change the shape of the matrix. When we removed these genes the error vanished and the program ran successfully. ### Minimal code sample. sc.pp.calculate_qc_metrics(; raw_data, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, log1p=True; ). ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.9; scanpy 1.10.3; -----; PIL 10.4.0; asttokens NA; charset_normalizer 3.4.0; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.5; decorator 5.1.1; executing 2.1.0; h5py 3.11.0; ipykernel 6.29.5; jedi 0.19.1; joblib 1.4.2; kiwisolver 1.4.7; legacy_api_wrap NA; llvmlite 0.43.0; matplotlib 3.9.2; matplotlib_inline 0.1.7; mpl_toolkits NA; natsort 8.4.0; numba 0.60.0; numpy 2.0.2; packaging 24.1; pandas 2.2.3; parso 0.8.4; pickleshare 0.7.5; platformdirs 4.3.6; prompt_toolkit 3.0.47; psutil 6.0.0; pure_eval 0.2.3; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.18.0; pyparsing 3.1.4; pytz 2024.1; scipy 1.14.1; session_info 1.0.0; six 1.16.0; sklearn 1.5.2; stack_data 0.6.2; threadpoolctl 3.5.0; tornado 6.4.1; traitlets 5.14.3; vscode NA; wcwidth 0.2.13; yaml 6.0.2; zmq 26.2.0; -----; IPython 8.27.0; jupyter_client 8.6.3; jupyter_core 5.7.2; -----; Python 3.12.6 | packaged by conda-forge | (main, Sep 22 2024, 14:16:49) [GCC 13.3.0]; Linux-5.15.0-122-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-10-30 08:33. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3331:353,error,error,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331,4,"['Error', 'error']","['Error', 'error']"
Availability,"### Test failures as of d36b977fa0c85d67b96799da4cb86b8582868048. Significantly improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:9,failure,failures,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,6,"['Error', 'error', 'failure']","['Error', 'errors', 'failures']"
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Currently sc.pp.subsample does not allow for sampling with replacement. When n_obs is provided, and it is larger than the size of the adata object, an error message from numpy.random.choice is given.; ""obs_indices = np.random.choice(old_n_obs, size=new_n_obs, replace=False)"". It seems like replace is automatically set to False. It would be great if sc.pp.subsample provided a paramater to change the np.random.choice's 'replace' parameter to True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2854:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2854,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3054:403,robust,robust,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054,2,['robust'],['robust']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It’s basically unmaintained: https://github.com/airspeed-velocity/asv/issues/1219. In https://github.com/scverse/scanpy/pull/3031, I ran into https://github.com/airspeed-velocity/asv/issues/966 which seems to make it almost unusable for our purposes. We need `setup` to run reliably.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3052:436,reliab,reliably,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052,1,['reliab'],['reliably']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. On the recommendation of the library authors, we should change the default leiden backend to `igraph` (https://github.com/scverse/scanpy/issues/1053) now that this has been made available in https://github.com/scverse/scanpy/pull/2815). At the same time, we should change the number of default iterations. Right now, we iterate until convergence. This can be very slow, especially for large datasets. We should probably just stick with the default of the underlying library (which is 2).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865:340,avail,available,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865,1,['avail'],['available']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. ```; /home/zeth/miniconda3/envs/pertpy/lib/python3.11/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.; warnings.warn(; ```. They raise warnings in downstream frameworks. Some are catching the Futurewarning, but some are not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2795:416,down,downstream,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2795,1,['down'],['downstream']
Availability,### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. currently `pp.scale` with a `mask_obs` with a sparse matrix and with `zero_center== False` takes a really long time to update the sparse matrix. This also takes up a lot of memory because of the parity calculations. I would suggest a numba kernel that just swaps out the data. This works really well for rapids-singlecell and greatly improves performance and reduces the memory overhead.; I would open a PR with this kernel. ------; Performance for 90k cells and 25k genes:; without mask:; CPU 645 ms | GPU 37 ms | 20x; with mask:; CPU 22 s | GPU 50 ms | 460x,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2941:645,mask,mask,645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2941,2,['mask'],['mask']
Availability,"### What kind of feature would you like to request?. Additional function parameters. ### Please describe your wishes. All the plotting functions in the `pl.rank_genes_groups_<plot-type>` group are able to pass additional keywords to their parent plot type for extra tuning, apart from `pl.rank_genes_groups_violin`. Was this by design, or is it an omission? If the latter, I'm happy to work on a PR to fix it (I found myself today wanting to pass `log=True`, only to get an error).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2954:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2954,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hello Scanpy team!. In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2630:405,avail,available,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630,1,['avail'],['available']
Availability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667:444,error,error,444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667,1,['error'],['error']
Availability,"### 📄 `_make_forest_dict()` in `scanpy/neighbors/__init__.py`. 📈 Performance improved by **`77%`** (**`0.77x` faster**). ⏱️ Runtime went down from **`5670.84μs`** to **`3195.82μs`**; ### Explanation and details. I have used `numpy.array` and `numpy.concatenate` for your sizes and dat object which are much faster than `numpy.fromiter` and assignation respectively, especially when dealing with a large dataset. The sizes of your data_list are computed only once and used where needed. Which results in runtime improvements compared to previous code, where data sizes were computed multiple times in different parts of the code. ### Correctness verification. The new optimized code was tested for correctness. The results are listed below. #### ✅ 8 Passed − 🌀 Generated Regression Tests; <details>; <summary>(click to show generated tests)</summary>. ```python; # imports; import numpy as np; import pytest. # function to test; # (The function definition is omitted as it was provided in the original prompt). # helper class to create mock trees with properties; class MockTree:; def __init__(self, hyperplanes, offsets, children, indices):; self.hyperplanes = np.array(hyperplanes); self.offsets = np.array(offsets); self.children = np.array(children); self.indices = np.array(indices). # unit tests. # Test with a single tree with one-dimensional properties; def test_single_tree_one_dimensional():; tree = MockTree(hyperplanes=[1, 2], offsets=[3], children=[4, 5], indices=[6, 7]); forest = [tree]; result = _make_forest_dict(forest); assert result[""hyperplanes""][""start""][0] == 0; assert result[""offsets""][""start""][0] == 0; assert np.array_equal(result[""hyperplanes""][""data""], tree.hyperplanes); assert np.array_equal(result[""offsets""][""data""], tree.offsets). # Test with multiple trees with two-dimensional properties; def test_multiple_trees_two_dimensional():; tree1 = MockTree(hyperplanes=[[1, 2], [3, 4]], offsets=[5, 6], children=[[7, 8], [9, 10]], indices=[[11, 12], [13, 14]]); tree2 = Moc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2971:137,down,down,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2971,1,['down'],['down']
Availability,"#### Problem; File `tissue_positions_list.csv` not found when running `sc.read_visium`; This issue was caused by the file name change by `spaceranger`. . #### Solution; Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem; The following error messages appeared when running `sc.pl.spatial`:; ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [4], line 1; ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1000 cmap_img = None; 1001 circle_radius = size * scale_factor * spot_size * 0.5; -> 1003 axs = embedding(; 1004 adata,; 1005 basis=basis,; 1006 scale_factor=scale_factor,; 1007 size=circle_radius,; 1008 na_color=na_color,; 1009 show=False,; 1010 save=False,; 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):; 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 389 # if user did not set alpha, set alpha to 0.7; 390 kwargs['alpha'] = 0.7 if alpha is None else alpha; --> 392 cax = scatter(; 393 coords[:, 0],; 394 coords[:, 1],; 395 marker=""."",; 396 c=color_vector,; 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; 399 **kwargs,; 400 ); 402 # remo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2345:309,error,error,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345,1,['error'],['error']
Availability,"#**Here is an example:** . adata.var.ix['Wfdc18']; result: ; gene_ids ENSMUSG00000000983; n_cells 2411; Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); filter_result = sc.pp.filter_genes_dispersion(; adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]; adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2524 try:; -> 2525 return self._engine.get_loc(key); 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-53-fb4aad8315fd> in <module>(); 1 print (adata.var.ix['Wfdc18']); ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key); 125 ; 126 key = com._apply_if_callable(key, self.obj); --> 127 return self._getitem_axis(key, axis=axis); 128 ; 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1106 return self._get_loc(key, axis=axis); 1107 ; -> 1108 return self._get_label(key, axis=axis); 1109 ; 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis); 143 raise IndexingError('no slices here, handle elsewhere'); 144 ; --> 145 return self.obj._xs(label, axis=axis); 146 ; 147 def _get_loc(self, key, axis=None):. /usr/local/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109:552,toler,tolerance,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109,1,['toler'],['tolerance']
Availability,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816,2,['error'],"['error', 'errors']"
Availability,"#2733 bumps the minimum version **up** to 3.6 and adds two good reasons why that exact minimum version requirement is chosen:. 1. matplotlib’s maintenance schedule drops support for 3.5 in a little bit; 2. we use a feature from 3.5. If some piece of infrastructure doesn’t allow bumping versions of client libraries, that piece of infrastructure needs improvement. Jupyter allows distinct environments for kernels and the server for a reason. So while colab should be able to pin and use whatever they need on the server, there’s zero reason why colab should dictate any version of anything other than `ipykernel` for the user environment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509:143,mainten,maintenance,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509,1,['mainten'],['maintenance']
Availability,' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12476,mask,mask-,12476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9937,mask,mask-,9937,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4362,toler,tolerance,4362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackages/forceatlas2-0.3.5$; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:29933,error,errors,29933,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,7,"['error', 'failure']","['error', 'errors', 'failure']"
Availability,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:4007,down,downgrade,4007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,1,['down'],['downgrade']
Availability,(feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048:16,error,errors,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048,1,['error'],['errors']
Availability,"(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4205,toler,tolerance,4205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:3420,Error,Error,3420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['Error'],['Error']
Availability,"); 733 ; 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4595,error,error,4595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args); [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:; [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs); [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):; --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/); ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:3757,Error,Error,3757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,2,['Error'],['Error']
Availability,"* ; scanpy ; During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); computing neighbors; using 'X_pca' with n_pcs = 40; ; LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x000001FF1D57B970> (trying to write member #1). File ""C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py (53). TypeError Traceback (most recent call last); C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 822 try:; --> 823 yield; 824 except NumbaError as e:. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 438 ty = self.typeof(inst.target.name); --> 439 val = self.lower_assign(ty, inst); 440 argidx = None. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_assign(self, ty, inst); 625 elif isinstance(value, ir.Expr):; --> 626 return self.lower_expr(ty, value); 627 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_expr(self, resty, expr); 1161 elif expr.op == 'call':; -> 1162 res = self.lower_call(resty, expr); 1163 return res. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:1067,error,errors,1067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,* Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`); * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32; * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released; * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724,1,['error'],['error']
Availability,* fixed vmin/vmax for categorical data #800 ; * added error message when vmin is not valid to point out how to format it; * updated test to cover categorical data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/804:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/804,1,['error'],['error']
Availability,"* installing the master branch via `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git` fails:. ```; UPDATING build/lib.linux-x86_64-3.5/None; error: [Errno 2] No such file or directory: 'build/lib.linux-x86_64-3.5/None'; ```; ; maybe `_version.py` returns `None` instead of a version string for the master branch. * installing the tag works: `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git@0.0` but the installed version will be `0.1`, not `0.0` as the tag says (i’m not sure 0.0 is a legal version anyway)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/15:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15,1,['error'],['error']
Availability,**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2104:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2104,1,['error'],['error']
Availability,"+1, I have the same error (on different data), which also only seems to appear when I don't filter to leave only the highly variable genes. In my case,. ```; np.any(adata.X.sum(axis=0) == 0); np.any(adata.X.sum(axis=1) == 0); ```; both return `False`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040,1,['error'],['error']
Availability,", **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:8087,error,error,8087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['error']
Availability,", **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:7288,error,errors,7288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,", engine, **kwds); 1617 self.options[""has_index_names""] = kwds[""has_index_names""]; 1619 self.handles: IOHandles | None = None; -> 1620 self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); 1878 if ""b"" not in mode:; 1879 mode += ""b""; -> 1880 self.handles = get_handle(; 1881 f,; 1882 mode,; 1883 encoding=self.options.get(""encoding"", None),; 1884 compression=self.options.get(""compression"", None),; 1885 memory_map=self.options.get(""memory_map"", False),; 1886 is_text=is_text,; 1887 errors=self.options.get(""encoding_errors"", ""strict""),; 1888 storage_options=self.options.get(""storage_options"", None),; 1889 ); 1890 assert self.handles is not None; 1891 f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); 761 if compression == ""gzip"":; 762 if isinstance(handle, str):; 763 # error: Incompatible types in assignment (expression has type; 764 # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> 765 handle = gzip.GzipFile( # type: ignore[assignment]; 766 filename=handle,; 767 mode=ioargs.mode,; 768 **compression_args,; 769 ); 770 else:; 771 handle = gzip.GzipFile(; 772 # No overload variant of ""GzipFile"" matches argument types; 773 # ""Union[str, BaseBuffer]"", ""str"", ""Dict[str, Any]""; (...); 776 **compression_args,; 777 ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__(self, filename, mode, compresslevel, fileobj, mtime); 190 mode += 'b'; 191 if fileobj is None:; --> 192 fileobj = self.myfileobj = builtins.open(filename, mode or 'rb'); 193 if filename is None:; 194 filename = getattr(fileobj, 'name', ''). FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'; ```. ### Versions. <details>. ```; '1.10.2'; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:24141,error,errors,24141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,2,['error'],"['error', 'errors']"
Availability,", figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1151 raise ValueError(""Cannot index with multidimensional key""); 1152 ; -> 1153 return self._getitem_iterable(key, axis=axis); 1154 ; 1155 # nested tuple slicing. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis); 1091 ; 1092 # A collection of keys; -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis); 1094 return self.obj._reindex_with_indexers(; 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis); 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr); 1313 ; -> 1314 self._validate_read_indexer(keyarr, indexer, axis); 1315 ; 1316 if needs_i8_conversion(ax.dtype) or isinstance(. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis); 1375 ; 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()); -> 1377 raise KeyError(f""{not_found} not in index""); 1378 ; 1379 . KeyError: ""['B cells'] not in index""; ```. </details>. For `rankby_abs` it does error, but is that a valid argument to pass to this function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:4321,error,error,4321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,1,['error'],['error']
Availability,", tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, indexer); 3475 # trying to reindex on an axis with duplicates; 3476 if not self._index_as_unique and len(indexer):; -> 3477 raise ValueError(""cannot reindex from a duplicate axis""); 3478 ; 3479 def reindex(self, target, method=None, level=None, limit=None, tolerance=None):. ValueError: cannot reindex from a duplicate axis; ```; Loading a single h5 file works and produces expected output:; ```; a = sc.read_10x_h5('./a.h5', gex_only = True); a; AnnData object with n_obs × n_vars = 7474 × 31053; var: 'gene_ids', 'feature_types', 'genome'; ```. So the input files appear to be valid I just can't get them to concatenate to a single object. . Any ideas would be welcome.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:4412,toler,tolerance,4412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,", which gives scanpy users an obvious advantage. . I've learned so much using this package and it has allowed me to display my data in a simple and intuitive way. Truly, from the bottom of my heart, thank you, this package is awesome and I deeply appreciate all the work the scanpy team and Theis lab has put into it. . With that said, I find myself wanting to do things with scanpy that aren't currently supported. . (1) Clustering cells based on a restricted set of genes as opposed to principle components: I understand that this is a biased approach, but I find myself wanting to do this to explore datasets and how genes vary together. I believe it would aid in understanding data topology to reduce the dimensionality of the dataset by looking at a subset of key genes that are picked by an expert who has domain knowledge. I think this is best integrated with a separate sc.pp.neighbors-like function that uses a gene list, as opposed to PCs. Integration into downstream plotting can be done with separate functions that have a similar name (sc.tl.umap_genelist or sc.tl.umap_sparse; sc.tl.paga_genelist or sc.tl.paga_sparse). . I envision that this would also be a nice stepping stone towards multi-modal analysis with CITE-seq. . (2) I want to use PAGA and UMAP to display my CytOF data as well as integrate scRNA-seq/CytOF data together. I saw a pre-print on bioRxiv that indicated that you are working on this aspect of PAGA/scanpy. This was very exciting to me and I am glad that this is being developed. Is it possible to access the current version of this software? . I think that major partitions identified with CytOF or scRNA-seq can be linked together providing a coarse-grained mechanism to demonstrate how heterogeneity identified with each technique relates to each other based on a given experimental time point. . (3) Histogram integration in the plotting api for QC metrics would be helpful. While scatter plots and violin plots are effective, I find myself wanting to make cut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510:1383,down,downstream,1383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510,1,['down'],['downstream']
Availability,",; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15879,error,errors,15879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,",; obs=pd.DataFrame(; {""celltype"": list(chain(repeat(""a"", 10), repeat(""b"", 10)))},; index=[f""cell{i}"" for i in range(a.shape[0])]; ),; var=pd.DataFrame(index=[f""gene{i}"" for i in range(a.shape[1])]),; ). # Running differential expression with t-test:. sc.tl.rank_genes_groups(adata, groupby=""celltype""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This seems wrong. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""t-test""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This also seems wrong. # Checking to make sure I'm not forgetting something obvious; print(stats.ttest_ind([0,0,0,0,0], [5,5,5,5,5])); # Ttest_indResult(statistic=-inf, pvalue=0.0) # This seems right. # Wilcoxon seems fine:. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""wilcoxon""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1.57052284e-04, 1.00000000e+00, 1.00000000e+00]) # This seems right; ```. `""logreg""` on the other hand, throws an error:. ```python; sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""); <ipython-input-7-29e46f287a31> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""). ~/github/scanpy/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 397 adata.uns[key_added]['scores'] = np.rec.fromarrays(; 398 [n for n in rankings_gene_scores],; --> 399 dtype=[(rn, 'float32') for rn in groups_order_save]); 400 adata.uns[key_added]['names'] = np.rec.fromarrays(; 401 [n for n in rankings_gene_names],. /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 615 # Determine shape from data-type.; 616 if len(descr) != len(arrayList):; --> 617 raise ValueError(""mismatch between the number of fields ""; 618 ""and the number of arrays""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620:1409,error,error,1409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620,1,['error'],['error']
Availability,"- . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). ```pytb; [Paste the error output produced by the above code here]; ```; C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1742:860,error,error,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742,1,['error'],['error']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.umap(adata); sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']); sc.tl.leiden(adata); sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb; The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this?; ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2471:594,down,downloaded,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471,1,['down'],['downloaded']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1660:705,Error,Error,705,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660,2,['Error'],['Error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy. ---; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ...; ...; test_data = sc.pp.regress_out(test_data,['n_count'], copy=True); sc.pp.scale(test_data); sc.tl.pca(test_data,n_comps=30, use_highly_variable=True); sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical; OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8; and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2404:944,error,errors,944,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404,1,['error'],['errors']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,; I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; InvalidIndexError Traceback (most recent call last); <ipython-input-54-668f41c58e57> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 231 ctrl_size ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:560,down,downloaded,560,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,2,"['down', 'error']","['downloaded', 'error']"
Availability,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1481:542,error,error,542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481,2,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## save command; adata.write(folder + ""before_regression.h5ad""); ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795:589,error,error,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello everyone, I am trying to calculate cell cycle score for my mouse data and encountering this error. I have already converted the gene name to upper case letters to read from the cell cycle genes. please help me to resolve this issue. Thank you very much. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens); ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-63-57c51b3902c0> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens). ~\anaconda3\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599:512,error,error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1368:467,down,downsample,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368,3,"['down', 'error']","['downsample', 'error']"
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1); ```. ```pytb; TypeError Traceback (most recent call last); <ipython-input-17-15b8850a67a5> in <module>; 1 #New dot plot (12 weeks feature genes); ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 151 # 1. compute fraction of cells having value > expression_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932:479,error,error,479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,; I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3); ; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-73-a5a2e6833485> in <module>(); 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 205 neigh_params.get('metric', 'euclidean'),; 206 neigh_params.get('metric_kwds', {}),; --> 207 verbose=settings.verbosity > 3,; 208 ); 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose); 1037 random_state,; 1038 metric=metric,; -> 1039 metric_kwds=metric_kwds,; 1040 ); 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1989:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1675:660,ping,pinging,660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675,1,['ping'],['pinging']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]; pd.set_option(""display.max_colwidth"", 800); first_enrichment_results.iloc[:50,:]; plot_enrich(first_enrichment_results); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-28-72ef52261ce6> in <module>; ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save); 75 fig = plt.gcf(); 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]); ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes); 78 cbar.ax.set_yticklabels(ticks_labs); 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw); 2341 'panchor']; 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2344 ; 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003:355,error,error,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; thanks; ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2171:643,error,error,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367:514,error,error,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367,2,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2380:648,error,error,648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101; obs: 'n_genes_by_counts', 'total_counts'; var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'log1p', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```; This is the command that leads to error:; ```python; sc.pp.neighbors(adata ); ```; ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-79-c7d46fa554b4> in <module>; ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 792 X = pairwise_distances(X, metric=metric, **metric_kwds); 793 metric = 'precomputed'; --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(; 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds; 796 ). ~/.local/lib/python3.8/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472:788,error,error,788,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up?. **(1) when I do:** ; sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,; save = '_test2.png'; ). I get an AttributeError: 'str' object has no attribute 'mkdir'; ; **(2) when I do:**; sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,; save = '_test2.png'; ); then nothing happens there is no error and the directory doesn't actually change. ```python; sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,; save = '_test2.png'; ). ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-fd106b753fe2> in <module>; ----> 1 sc.pl.umap(Tgd,; 2 save = '_test2.png'; 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:982,error,error,982,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2178:598,down,downloaded,598,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178,2,"['down', 'error']","['downloaded', 'errors']"
Availability,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2306:265,error,errors,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306,2,['error'],"['error', 'errors']"
Availability,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2001:740,Error,Error,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001,1,['Error'],['Error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python; sc.pp.highly_variable_genes(; adata,; flavor = ""seurat_v3"",; n_top_genes = 7000,; layer = ""counts"",; batch_key = ""combined"",; subset = True; ); ```. I get the following error:. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-3748de5bacdc> in <module>; 5 layer = ""counts"",; 6 batch_key = ""combined"",; ----> 7 subset = True; 8 ); 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 420 span=span,; 421 subset=subset,; --> 422 inplace=inplace,; 423 ); 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504:623,error,error,623,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:488,Down,Download,488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,2,['Down'],"['Download', 'Downloads']"
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:673,down,downstream,673,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['down'],['downstream']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalizatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2377:690,error,error,690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377,2,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:966,down,downstream,966,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['down'],['downstream']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I also tried 'log1p = False' and produced the other error. Thank you. . ```python; sc.pp.calculate_qc_metrics(adata); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 294, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 111, in describe_obs; obs_metrics[f""log1p_total_{expr_type}""] = np.log1p(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (35255); >; ```. `sc.pp.calculate_qc_metrics(adata, log1p = False)`. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 995, in __repr__; self.to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 1131, in to_string; return fmt.DataFrameRenderer(formatter).to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1053, in to_string; string = string_formatter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008:281,error,error,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to cluster a manifold of around 100K cells computed from scVI using the `leiden` ; algorithm as follows: . ``` ; sc.tl.leiden(adata_latent, resolution = 1, random_state = 1786); ```; This works fine:. ```; running Leiden clustering; Trying to set attribute `.obs` of view, copying.; finished: found 17 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:07:14); ```. However, when I inspect the object where I just ran `leiden`, I can't see the `leiden` labels in `adata.obs`. ; Instead, it seems to be located in `adata.uns`. . ```; AnnData object with n_obs × n_vars = 106774 × 50; obs: 'percent_mito', 'n_genes', 'n_counts'; uns: 'neighbors', 'umap', 'sampleID_colors', 'batch_colors', 'status_colors', 'leiden'; obsm: 'X_umap'; obsp: 'distances', 'connectivities'; ```. I have tried to downgrade `leidenalg` but there is no change. Do you have an idea what may be happening? . #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.1.1 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410:1063,down,downgrade,1063,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410,1,['down'],['downgrade']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:298,down,down,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['down'],['down']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2109:371,error,error,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[‘resolution_parameter’] = resolution; 143 # clustering proper; → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[‘weights’] = weights; —> 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'); ```. ```pytb; [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2487:583,error,error,583,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello !. I'm not sure whether this is a bug or it is enforced intentionally but even though users can use the kwargs to pass on to `sc.pl.embedding` any additional argument for `matplotlib.pyplot.scatter()`, trying to change the marker style doesn't work. As you can see below, the marker style is hardcoded in `sc.pl.embedding` to always be ""."" thus raising an error when trying to use another marker style due to `scatter()` being fed with the keyword argument `marker` multiple times.; Best,. Jules. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import anndata. adata = anndata.AnnData(X=np.random.rand(1000, 20)); sc.pp.neighbors(adata); sc.tl.umap(adata, min_dist=0.2); sc.pl.umap(adata,show=True, marker=""^""); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_10129/876858932.py in <module>; 5 sc.pp.neighbors(adata); 6 sc.tl.umap(adata, min_dist=0.2); ----> 7 sc.pl.umap(adata,show=True, marker=""^""). ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2122:776,error,error,776,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122,1,['error'],['error']
Availability,- [X] Tests included or not required because it's minor; - [x] Release notes not necessary because it's minor. I'm pretty sure that we've had this warning for a looooong time and it keeps showing up in a lot of downstream packages. People are either aware of it now or don't care (with the latter probably being more likely ^_^).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798:211,down,downstream,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798,1,['down'],['downstream']
Availability,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467:460,error,error,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467,2,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns; However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works; ```. random_indices=np.random.permutation(adatas['Human'].obs_names); sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',; color=['CellType'],hspace=0.9); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-48-8a1d75e9b375> in <module>; 2 np.random.seed(0); 3 random_indices=np.random.permutation(adatas['Human'].obs_names); ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',; 5 color=['Batch','Region','Condition', 'Grade', ; 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 250 groups=groups,; 251 ); --> 252 color_vector, categorical = _color_vector(; 253 adata,; 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2401:350,error,error,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2034:311,error,error,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1486:527,error,error,527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to ingest a CITEseq dataset into another clustered dataset. These datasets have different numbers of cells but I ran neighbors(n_neighbors=30) for both prior to running umap. I have confirmed that both datasets have the same variable names and the same number of variable names (38). Both objects look identical when a call adata.var. . I receive the error: ""all input arrays must have the same shape"". . ```; sc.pp.neighbors(CODEX_sub, n_neighbors=30) ; sc.tl.umap(CODEX_sub); sc.pp.neighbors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085:594,error,error,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2282:1297,Avail,Available,1297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282,1,['Avail'],['Available']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python; # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ); ```. ```pytb; [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-f7d35408db0b> in <module>; ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 671 tl.dendrogram; 672 """"""; --> 673 return _rank_genes_groups_plot(; 674 adata,; 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 590 from .._anndata import heatmap; 591 ; --> 592 return heatmap(; 593 adata,; 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2357:301,error,error,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208:414,error,error,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208,3,"['Error', 'error']","['Error', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```when I run ; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb; [Paste the error output produced by the above code here]; ```; Traceback (most recent call last):; File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:745,error,error,745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1590:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:311,Down,Downgrading,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['Down'],['Downgrading']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,3,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though; # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue; # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks; ```. ```pytb; [---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-2f4062a9e25b> in <module>; ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype); 46 Numpy data type.; 47 """"""; ---> 48 return read_text(filename, delimiter, first_column_names, dtype); 49 ; 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype); 323 else:; 324 with filename.open() as f:; --> 325 return _read_text(f, delimiter, first_column_names, dtype); 326 ; 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype); 386 first_column_names = True; 387 row_names.append(line_list[0]); --> 388 data.append(np.array(line_list[1:], dtype=dtype)); 389 else:; 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1838:570,error,errors,570,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838,1,['error'],['errors']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2321:794,error,error,794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:655,error,errors,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 # 绘制 PCA 图; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:556,error,error,556,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,2,"['error', 'toler']","['error', 'tolerance']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1556:506,error,error,506,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556,2,"['down', 'error']","['downgraded', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2383:1688,error,error,1688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2389:487,down,downstream,487,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389,1,['down'],['downstream']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python; healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'); ```. I calculated qc metrics with this command.; ```python; sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True); ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") ; ```; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_1314047/3602867448.py in <module>; ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1009 show=False,; 1010 save=False,; -> 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:437,error,error,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:345,error,errors,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,2,['error'],"['error', 'errors']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2137:936,error,error,936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey!. I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors.; Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`; ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-39-d43e888a7389> in <module>; ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850:329,error,error,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850,2,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am following all the steps from the PBMC3k tutorial (https://scanpy.readthedocs.io/en/latest/tutorials/pbmc3k.html).; I ran the wilcoxon method for finding marker genes and saved the object to a .h5ad file, after which I reloaded the object from the file and the log1p dict appears to be empty for some reason. I checked the object before saving it to the file and it had the 'base' key whereas after loading it back it was missing, causing the error below. . ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read(results_file); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2497:676,error,error,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2236:422,error,error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. If there are very few genes some of the bins in `sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger"")` can contain a single gene leading to `NaN` values in the normalized expression vector which are removed here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L261. If after this filtering the dispersion vector is shorter then than `n_top_genes` there is an indexing error when selecting the dispersion cutoff here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L268. There should probably be a check (with a warning) when this happens. ### Minimal code sample (that we can copy&paste without having any data). ```python; import anndata; import numpy as np; import scanpy as sc. adata = anndata.AnnData(np.random.poisson(2, (100, 30))); sc.pp.normalize_total(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger""); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 268, in _highly_variable_genes_single_batch; disp_cut_off = dispersion_norm[n_top_genes - 1]; IndexError: index 29 is out of bounds for axis 0 with size 21; ```. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.1.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2230:698,error,error,698,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2230,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2491:264,error,error,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:289,error,error,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python; # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'); adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:; adata.var_names_make_unique(); print(adata.uns[""name""], "": data shape"", adata.shape); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:; adata.var['mt'] = adata.var_names.str.startswith('mt-'); sc.pp.calculate_qc_metrics(; adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:; print(adata.uns[""name""], "":""); sc.pl.violin(; adata,; [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],; jitter =0.4,; multi_panel=True,; ); ```. ```pytb; zfish_Control :; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>; 1 for adata in adata_control:; 2 print(adata.uns[""name""], "":""); ----> 3 sc.pl.violin(; 4 adata,; 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 779 ); 780 else:; --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2305:338,error,error,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello; This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:; ```; #use this; sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'); ```. Error:. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-16-30381f660d76> in <module>; 1 #use this; ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 659 tl.dendrogram; 660 """"""; --> 661 return _rank_genes_groups_plot(; 662 adata,; 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1941:737,Error,Error,737,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941,1,['Error'],['Error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1661:522,error,error,522,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, after clustering I am trying to use heatmap to visualize the marker gene but got below error:; could anyone help, many thanks.; ```python; ax = sc.pl.heatmap(adata,marker_genes_dict,groupby='louvain_r1',save=""0.png""); ```. ```pytb; KeyError: ""Values ['CD79A'], from ['CD79A', 'MS4A1', 'CD3D', 'CD8A', 'CD8B', 'GNLY', 'NKG7', 'CST3', 'LYZ', 'FCGR3A', 'FCER1A'], are not valid obs/ var names or indices."". ```. #### Versions. <details>; anndata 0.7.5; scanpy 1.6.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2068:318,error,error,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2068,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2443:332,error,error,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443,4,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python; #remove all ribosomal genes; malat1 = adata1.var_names.str.startswith('MALAT1'); ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")); # we need to redefine the mito_genes since they were first ; # calculated on the full object before removing low expressed genes.; mito_genes = adata1.var_names.str.startswith('MT-'); hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1); remove = np.add(remove, hb_genes); keep = np.invert(remove). adata3 = adata1[:,keep]. adata3; ```. #### Versions; anndata 0.8.0; scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.; self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2428:814,error,error,814,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: ; celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video; hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python; # Your code here; celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'); celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']; celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'); hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']; hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-25-5f4cc5c2e544> in <module>; 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:472,down,download,472,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,2,['down'],['download']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ------it is easy for v1.9.1 out of memory.; I have the same data(200000x20000), the RAM of my compute is 64 GB, and the v1.8 can cope it easy, but the v1.9.1 is easy to occur the memoryError from the sc.read('./xxx.h5ad'). **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); sc.read('./xxx.h5ad'); ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions; v1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; ![image](https://user-images.githubusercontent.com/50618480/170998448-db4300d9-54f0-4f03-b2be-7f6880006b29.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2266:783,error,error,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2465:358,error,error,358,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465,4,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239:603,error,error,603,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; categories_order=['0','1','9','8','2','5','4','7','3','6']; sc.pl.tracksplot(adata,markers,groupby='leiden',vmax=3,categories_order=categories_order); ```. ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/50618480/166931336-26e4431a-7bdb-41b4-a575-69aa5e9ef948.png); I can not get the order as ['0','1','9','8','2','5','4','7','3','6']; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2250:675,error,error,675,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/; ├── cli.py; ├── _compat.py; ├── datasets; ├── experimental; ├── external; ├── get; ├── __init__.py; ├── logging.py; ├── __main__.py; ├── _metadata.py; ├── metrics; ├── neighbors; ├── plotting; ├── preprocessing; ├── __pycache__; ├── queries; ├── readwrite.py; ├── _settings.py; ├── sim_models; ├── tools; └── _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2378:1014,error,error,1014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378,2,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1967:610,error,error,610,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2144:627,error,error,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124:822,error,error,822,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246:258,down,download,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246,2,"['down', 'error']","['download', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1437:380,error,error,380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073:926,error,error,926,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2343:904,error,error,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143:500,error,error,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143,3,"['down', 'error']","['downloaded', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 41",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782:266,error,error,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:248,error,error,248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,3,['error'],['error']
Availability,"- [√] I have checked that this issue has not already been reported.; - [√] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; small bug report:; https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py; line 538 wrong error raised when `use_raw=True`; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is not None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; Second `not` should be removed ,Corrected codes should be; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions; this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1929:380,error,error,380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929,1,['error'],['error']
Availability,"- [✔ ] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2057:622,error,error,622,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057,1,['error'],['error']
Availability,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2095:626,error,errors,626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095,1,['error'],['errors']
Availability,"----------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 3114 else:; 3115 # set column; -> 3116 self._set_item(key, value); 3117 ; 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 3188 """"""; 3189 ; -> 3190 self._ensure_valid_index(value); 3191 value = self._sanitize_column(key, value); 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:1968,error,error,1968,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,1,['error'],['error']
Availability,"-------------------; ValueError Traceback (most recent call last); <ipython-input-2-15436b6f0954> in <module>; 3 ; 4 adata = sc.datasets.krumsiek11(); ----> 5 sc.pl.clustermap(adata, obs_keys='cell_type'). ~/Code/scanpy/scanpy/plotting/_anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 777 adata.uns[obs_keys + '_colors'])); 778 row_colors = adata.obs[obs_keys].map(lut); --> 779 g = sns.clustermap(df, row_colors=row_colors, **kwds); 780 else:; 781 g = sns.clustermap(df, **kwds). ~/Code/seaborn/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:1272,mask,mask,1272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['mask'],['mask']
Availability,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332:78,error,error,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332,3,['error'],['error']
Availability,"---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable); 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience!. ```python; adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:750,error,error,750,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3976,ERROR,ERROR,3976,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; pr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2686,error,error,2686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,4,['error'],['error']
Availability,-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4562,ERROR,ERROR,4562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERROR: Failed building wheel for llvmlite; ```. </details>. Any ideas about that?. When using **python 3.8** in a fresh new virtual environment, I get, installation of the development version works fine, but when importing scvelo. `Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/__init__.py"", line 5, in <module>; from scvelo import datasets, logging, pl, pp, settings, tl, utils; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/datasets.py"", line 10, in <module>; from scvelo.core import cleanup, SplicingDynamics; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/_anndata.py"", line 4, in <module>; from typing_extensions import Literal; ModuleNotFoundError: No module named 't",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:1909,error,error,1909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs); 1932 if metric_name is not None:; 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,; -> 1934 metric_name, **kwargs); 1935 ; 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs); 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]; 288 # validate data; --> 289 X = _convert_to_type(X, out_type=typ); 290 ; 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type); 182 ; 183 def _convert_to_type(X, out_type):; --> 184 return np.ascontiguousarray(X, dtype=out_type); 185 ; 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype); 588 ; 589 """"""; --> 590 return array(a, dtype, copy=False, order='C', ndmin=1); 591 ; 592 . ValueError: setting an array element with a sequence.; ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python; import pandas as pd; adata = sc.AnnData(A) # from above; pd.DataFrame(A) # Throws error; pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe; 0 ... 99; 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:4729,error,error,4729,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['error'],['error']
Availability,". **random_state** : typing.Union[int, mtrand.RandomState, NoneType]. A numpy random seed. **method** : {'umap', 'gauss', `None`} (default: `'umap'`). Use 'umap' [McInnes18]_ or 'gauss' (Gauss kernel following [Coifman05]_; with adaptive width [Haghverdi16]_) for computing connectivities. **metric** : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], float]], optional (default: 'euclidean'). A known metric’s name or a callable that returns a distance. **metric_kwds** : Mapping. Options for the metric. **copy** : bool. Return a copy instead of writing to adata. :Returns:. Depending on `copy`, updates or returns `adata` with the following:. . **connectivities** : sparse matrix (`.uns['neighbors']`, dtype `float32`). Weighted adjacency matrix of the neighborhood graph of data; points. Weights should be interpreted as connectivities. **distances** : sparse matrix (`.uns['neighbors']`, dtype `float32`). Instead of decaying weights, this stores distances for each pair of; neighbors.; File: ~/_hholtz/01_projects/1512_scanpy/scanpy/scanpy/neighbors/__init__.py; Type: function; ```. PS: ; - Already the [docs](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.compute_neighbors.html) show that `Neighbors.compute_neighbors` has invalid numpydoc... this was the case in several instances and I'm slowly fixing all of them... It's just a matter of adding `\` at the line breaks.; - I completely agree that the redundency between signature and docstring information lead to a a very small number of errors in the docstrings. However, in several instances, I'm setting the default value in the signature to `None`. But in the docstring, I'm giving the value to which this `None` evaluates in the default case (depending on what is passed)... There is quite a number of such cases. Clearly, one could replace all of them with `'auto'` parameters, which is probably the better way of doing this. As the whole thing is backwards compat, this is not an immediate problem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:7690,error,errors,7690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,2,['error'],['errors']
Availability,". - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1056,error,errors,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['errors']
Availability,". . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:1156,error,error,1156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,1,['error'],['error']
Availability,". ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014:1360,avail,available,1360,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014,1,['avail'],['available']
Availability,". ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]; ```. ```; [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),; (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),; (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:6645,error,errors,6645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,1,['error'],['errors']
Availability,". ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 602 compiler pipeline; 603 """"""; --> 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); 606 return pipeline.compile_extra(func). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in __init__(self, typingctx, targetctx, library, args, return_type, flags, locals); 308 config.reload_config(); 309 typingctx.refresh(); --> 310 targetctx.refresh(); 311 ; 312 self.s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:3324,error,errors,3324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,2,['error'],['errors']
Availability,".); 768 **kwds,; 769 ):; 770 """"""\; 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`); 772 ; (...); 872 tl.rank_genes_groups; 873 """"""; --> 874 return _rank_genes_groups_plot(; 875 adata,; 876 plot_type='dotplot',; 877 groups=groups,; 878 n_genes=n_genes,; 879 groupby=groupby,; 880 values_to_plot=values_to_plot,; 881 var_names=var_names,; 882 gene_symbols=gene_symbols,; 883 key=key,; 884 min_logfoldchange=min_logfoldchange,; 885 show=show,; 886 save=save,; 887 return_fig=return_fig,; 888 **kwds,; 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 529 values_df = None; 530 if values_to_plot is not None:; --> 531 values_df = _get_values_to_plot(; 532 adata,; 533 values_to_plot,; 534 var_names_list,; 535 key=key,; 536 gene_symbols=gene_symbols,; 537 ); 538 title = values_to_plot; 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols); 1629 message = (; 1630 ""Please run `sc.tl.rank_genes_groups` with ""; 1631 ""'n_genes=adata.shape[1]' to save all gene ""; 1632 f""scores. Currently, only {df.shape[0]} ""; 1633 ""are found""; 1634 ); 1635 logg.error(message); -> 1636 raise ValueError(message); 1637 df['group'] = group; 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181:2683,error,error,2683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181,1,['error'],['error']
Availability,...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69739,ERROR,ERROR,69739,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65650,ERROR,ERROR,65650,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70872,ERROR,ERROR,70872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normal,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63513,ERROR,ERROR,63513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69405,ERROR,ERROR,69405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,".0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4015,toler,tolerance,4015,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,".0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xlrd 2.0.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-11-26 11:30]. </details>; When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2371:5520,error,error,5520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371,1,['error'],['error']
Availability,".1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_O",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:5558,avail,available,5558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['avail'],['available']
Availability,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:3247,down,downgrading,3247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrading']
Availability,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1057:3072,error,errors,3072,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057,2,['error'],"['error', 'errors']"
Availability,.; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61060,ERROR,ERROR,61060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4242,Error,Error,4242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916:2309,toler,tolerance,2309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916,2,['toler'],['tolerance']
Availability,.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown loc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17203,ERROR,ERROR,17203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normaliz,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12060,mask,mask-,12060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:3162,toler,tolerance,3162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,3,['toler'],['tolerance']
Availability,".violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:2025,toler,tolerance,2025,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['toler'],['tolerance']
Availability,".win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3000,error,error,3000,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability,/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73172,ERROR,ERROR,73172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_me,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63016,ERROR,ERROR,63016,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:8069,error,errors,8069,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:8181,error,error,8181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,1,['error'],['error']
Availability,/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cann,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3144,ERROR,ERROR,3144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60404,ERROR,ERROR,60404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERRO,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70538,ERROR,ERROR,70538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70705,ERROR,ERROR,70705,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66292,ERROR,ERROR,66292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1925,error,errors,1925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,1,['error'],['errors']
Availability,/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72514,ERROR,ERROR,72514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74643,ERROR,ERROR,74643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67117,ERROR,ERROR,67117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4134,Error,Error,4134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55068,ERROR,ERROR,55068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65161,ERROR,ERROR,65161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74170,ERROR,ERROR,74170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"0 0.001387 0.043064; ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321; ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308; ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1796:5793,error,error,5793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796,1,['error'],['error']
Availability,0-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8992,ERROR,ERROR,8992,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"0/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; session_info 1.0.0; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 5.1.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1. IPython 7.9.0; jupyter_client 6.1.12; jupyter_core 4.11.1; notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]; Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>; ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332:4830,error,error,4830,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332,1,['error'],['error']
Availability,"00)`. I get this error (the error does not show up when I use the normalization command from `scanpy` instead of the normalization with size factors from `scran`):. ```; LinAlgError Traceback (most recent call last); <ipython-input-97-96c692867dde> in <module>; ----> 1 sc.preprocessing.highly_variable_genes(adultAll, n_top_genes=10000, flavor='cellranger'). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 101 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 102 ; --> 103 mean, var = materialize_as_ndarray(_get_mean_var(X)); 104 # now actually compute the dispersion; 105 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in __pow__(self, other); 226 ; 227 def __pow__(self, other):; --> 228 return matrix_power(self, other); 229 ; 230 def __ipow__(self, other):. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603 ; 604 try:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216 ; 217 def _assertFinite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. Do you have any hints? I am trying to find the error but so far I have been unsuccessful.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:2388,error,error,2388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,1,['error'],['error']
Availability,0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9202,ERROR,ERROR,9202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2116,error,errors,2116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,2,['error'],"['error', 'errors']"
Availability,"1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:2311,down,download,2311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['download']
Availability,"1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyObjCTools NA; anyio NA; appnope 0.1.3; argcomplete NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531:1820,Error,Error,1820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531,2,"['Error', 'error']","['Error', 'error']"
Availability,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:878,down,downweight,878,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134,1,['down'],['downweight']
Availability,"125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:5398,error,error,5398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['error']
Availability,"13 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fssp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5813,error,error,5813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:1660,error,error,1660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,1,['error'],['error']
Availability,2-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_high,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44497,Error,Error,44497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,2-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4439,ERROR,ERROR,4439,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"2.0.0->scanpy); Using cached python_dateutil-2.6.1-py2.py3-none-any.whl; Collecting pytz (from matplotlib==2.0.0->scanpy); Using cached pytz-2018.3-py2.py3-none-any.whl; Requirement already up-to-date: six>=1.10 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: numpy>=1.7.1 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scan; Requirement already up-to-date: patsy in /cluster/software/lib/python3.6/site-packages (from statsmodels->scanpy); Requirement already up-to-date: decorator>=4.1.0 in /cluster/software/lib/python3.6/site-packages (from networkx->scanpy); Installing collected packages: scanpy, python-dateutil, pytz; Running setup.py install for scanpy: started; Running setup.py install for scanpy: finished with status 'error'; Complete output from command /cluster/software/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/scratch/tmp/pip-build-g14yf1xi/scanpy/setup.py';; running install; running build; running build_py; creating build; creating build/lib.linux-x86_64-3.6; creating build/lib.linux-x86_64-3.6/scanpy; copying scanpy/settings.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/_version.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__init__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__main__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/readwrite.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/utils.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/exporting.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/logging.py -> build/lib.linux-x86_64-3.6/scanpy; creating build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/top_genes_visual.py -> build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/rcmod.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:2812,error,error,2812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['error'],['error']
Availability,"2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:3175,down,downgrade,3175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrade']
Availability,"20 formatter,. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_array(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting); 1238 ); 1239 ; -> 1240 return fmt_obj.get_result(); 1241 ; 1242 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result(self); 1269 ; 1270 def get_result(self) -> list[str]:; -> 1271 fmt_values = self._format_strings(); 1272 return _make_fixed_width(fmt_values, self.justify); 1273 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:10529,mask,mask,10529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,3,['mask'],['mask']
Availability,"2; - zlib=1.2.13; - zlib-ng=2.0.7; - zstd=1.5.2; - pip:; - absl-py==1.4.0; - astunparse==1.6.3; - bcbio-gff==0.7.0; - biopython==1.81; - cachetools==5.3.1; - click==8.1.7; - flatbuffers==23.5.26; - gast==0.4.0; - geoparse==2.0.3; - gffpandas==1.2.0; - google-auth==2.22.0; - google-auth-oauthlib==1.0.0; - google-pasta==0.2.0; - grpcio==1.57.0; - imageio==2.34.1; - keras==2.13.1; - lazy-loader==0.4; - libclang==16.0.6; - louvain==0.8.2; - markdown==3.4.4; - numpy==1.24.3; - oauthlib==3.2.2; - opt-einsum==3.3.0; - protobuf==4.24.1; - pyasn1==0.5.0; - pyasn1-modules==0.3.0; - requests-oauthlib==1.3.1; - rsa==4.9; - scikit-image==0.24.0; - tensorboard==2.13.0; - tensorboard-data-server==0.7.1; - tensorflow==2.13.0; - tensorflow-estimator==2.13.0; - tensorflow-macos==2.13.0; - termcolor==2.3.0; - tifffile==2024.6.18; - tqdm==4.66.1; - typing-extensions==4.5.0; - urllib3==1.26.16; - werkzeug==2.3.7; - wrapt==1.15.0; ```. ### Minimal code sample. ```python; sc.pp.scrublet(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; # Successful case; -----; anndata 0.10.5.post1; scanpy 1.10.1; -----; PIL 9.4.0; astunparse 1.6.3; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; dill 0.3.7; gmpy2 2.1.2; google NA; h5py 3.9.0; igraph 0.11.3; joblib 1.3.2; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.40.1; louvain 0.8.2; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.3; pkg_resources NA; plotly 5.16.1; psutil 5.9.5; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; sympy 1.12; texttable 1.7.0; threadpoolctl 3.2.0; torch 2.0.1; tqdm 4.66.2; typing_extensions NA; wcwidth 0.2.6; yaml 6.0.1; -----; Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]; macOS-14.3-arm64-arm-64bit; -----; Session information updated at 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3116:15553,Error,Error,15553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116,1,['Error'],['Error']
Availability,"3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:1989,error,error,1989,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,2,['error'],['error']
Availability,"3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1; S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B; PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; >>> adata.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338:2297,Error,Error,2297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338,1,['Error'],['Error']
Availability,3d UMAP memory error on ~1 million cells,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/710:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710,1,['error'],['error']
Availability,3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12684,mask,mask-,12684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"4 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 486 pm.run(self.state); 487 if self.state.cr is not None:; 488 break. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 366 (self.pipeline_name, pass_desc); 367 patched_exception = self._patch_error(msg, e); --> 368 raise patched_exception; 369 ; 370 def dependency_analysis(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 354 pass_inst = _pass_registry.get(pss).pass_inst; 355 if isinstance(pass_inst, CompilerPass):; --> 356 self._runPass(idx, pass_inst, state); 357 else:; 358 raise BaseException(""Legacy pass in use""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:8284,avail,available,8284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['avail'],['available']
Availability,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:2140,error,errors,2140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,2,['error'],"['error', 'errors']"
Availability,"5-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]); ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python; marker_genes = ['PERM1', 'GAB3', 'G6PD']; combined_bbknn.var_names_make_unique(); sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'); ```; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-17-3392793686cd> in <module>; 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']; 2 combined_bbknn.var_names_make_unique(); ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 949 return dp; 950 else:; --> 951",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:2216,error,error,2216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4708,ERROR,ERROR,4708,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['ERROR'],['ERROR']
Availability,"54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1067:1481,error,errors,1481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067,1,['error'],['errors']
Availability,"5cac3.png). Now the code that doesn't work:; ```python; sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); #sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258:2460,error,error,2460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258,1,['error'],['error']
Availability,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:4322,down,downgrade,4322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,1,['down'],['downgrade']
Availability,"6f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2835,error,error,2835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['error'],['error']
Availability,"7 ; 10958 return set_function_name(stat_func, name, cls). /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/series.py in _reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds); 3613 # dispatch to ExtensionArray interface; 3614 if isinstance(delegate, ExtensionArray):; -> 3615 return delegate._reduce(name, skipna=skipna, **kwds); 3616 elif is_datetime64_dtype(delegate):; 3617 # use DatetimeIndex implementation to handle skipna correctly. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in _reduce(self, name, axis, skipna, **kwargs); 2179 msg = 'Categorical cannot perform the operation {op}'; 2180 raise TypeError(msg.format(op=name)); -> 2181 return func(**kwargs); 2182 ; 2183 def min(self, numeric_only=None, **kwargs):. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in max(self, numeric_only, **kwargs); 2222 max : the maximum of this `Categorical`; 2223 """"""; -> 2224 self.check_for_ordered('max'); 2225 if numeric_only:; 2226 good = self._codes != -1. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in check_for_ordered(self, op); 1517 raise TypeError(""Categorical is not ordered for operation {op}\n""; 1518 ""you can use .as_ordered() to change the ""; -> 1519 ""Categorical to an ordered one\n"".format(op=op)); 1520 ; 1521 def _values_for_argsort(self):. TypeError: Categorical is not ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one; ```. I was confused for two reasons:; 1) All of my columns in obs are already converted to pandas ordered categorical data but they are still ""forced"" to be converted again into unordered categorical data;; 2) because the columns are now unordered categorical data , it raised the final error which I did not encounter in earlier versions. . Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:5010,error,error,5010,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['error'],['error']
Availability,"881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:2442,error,error,2442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['error']
Availability,"8a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/plotting/_qc.py#L100 it seems to also plot all the Categoricals that are not present in the `counts_top_genes` DataFrame. My temporary hack to fix this is to force my ""gene_symbols"" argument column to be a mixed-object dtype, which drops the Categoricals and renders the boxplot correctly; ```python; if 'gene_symbol' in adata.var.columns and adata.var['gene_symbol'].dtype.name != 'object':; adata.var['gene_symbol'] = adata.var['gene_symbol'].astype('object'); ```. ### Minimal code sample. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. sc.pl.highest_expr_genes(adata, n_top=20, gene_symbols='gene_symbol', show=True, save="".png""); ```. I also tried this with the same results. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. adata.var.index = adata.var.gene_symbol; sc.pl.highest_expr_genes(adata, n_top=20, show=True, save="".png""); ```. ### Error output. ![349265437-b0a6e963-5d56-40e6-9922-5e4a543c08cf](https://github.com/user-attachments/assets/478c6a20-817f-4e39-92a3-62f5c2a62ed0). Above is a boxplot from `sc.pl.highest_expr_genes` that shows all the Categorical genes in addition to the top-20 as specified in the function argument. <img width=""1077"" alt=""Screenshot 2024-07-17 at 1 23 27 PM"" src=""https://github.com/user-attachments/assets/cfbdb40d-57f5-4da6-bf69-b4f4f3c489cc"">. Above is the correct boxplot, after my hack was applied to force the adata.var.gene_symbols to be mixed-object datatype instead of Categorical. ### Versions. <details>. python-3-10-4. ```; aiohttp==3.8.3; anndata==0.10.6; biocode==0.10.0; biopython==1.79; cairosvg==2.7.1; dash-bio==1.0.2; #diffxpy==0.7.4; Flask==3.0.0; Flask-RESTful==0.3.9; gunicorn; h5py==3.10.0; itsdangerous==2.1.2 # See -> https://stackoverflow.com/a/71206978; jupyterlab==4.0.5; jupyter==1.0.0; kaleido==0.2.1; leidenalg==0.10.2; llvmlite==0.41.1; matplotlib==3.9.0; mod-wsgi==4.9.4;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3158:2097,Error,Error,2097,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3158,1,['Error'],['Error']
Availability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Assertion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3994,Error,Error,3994,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2959,Error,Error,2959,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366287782:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366287782,1,['error'],['error']
Availability,"; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-39-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357:1661,error,error,1661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357,1,['error'],['error']
Availability,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:3497,down,downgrade,3497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['down'],['downgrade']
Availability,"; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, indexer); 3475 # trying to reindex on an axis with duplicates; 3476 if not self._index_as_unique and len(indexer):; -> 3477 raise ValueError(""cannot reindex from a duplicate axis""); 3478 ; 3479 de",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3340,toler,tolerance,3340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1797:2925,error,errors,2925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797,2,['error'],['errors']
Availability,"; 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5042,error,error,5042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"; 669 min_disp=min_disp,; (...); 672 max_mean=max_mean,; 673 ); 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt2800",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:4719,avail,available,4719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['avail'],['available']
Availability,; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - Impor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61712,ERROR,ERROR,61712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66946,ERROR,ERROR,66946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3812,ERROR,ERROR,3812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id); 1289 if library_id is _empty:; 1290 if len(spatial_mapping) > 1:; -> 1291 raise ValueError(; 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify.""; 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}""; 1294 ); 1295 elif len(spatial_mapping) == 1:; 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:; 	['1', '10', '100', '101', '102', '103', '104', '105', '106'...; ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow; in this SquidPy [tutorial](htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2486:1991,avail,available,1991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486,1,['avail'],['available']
Availability,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; The PR uses `1-correlation` as distance matrix to compute the dendrogram as suggested in #1288 and mentioned in https://github.com/theislab/squidpy/pull/236. I opted for the minimal changes to the code. Other solution would be to use `scipy.spatial.distance.pdist` that allows a larger number of distance metrics. I am open for a discussion on this topic (ping @michalk8),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1614:591,ping,ping,591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1614,1,['ping'],['ping']
Availability,"<!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2473:233,error,error,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],"['error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. Hi,; I run scanpy in Python 3.7, matplotlib=3.1.1 - `sc.pl.paga_path` gives me the following error(s). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.dpt(adata); sc.tl.paga(adata, groups='paul15_clusters'); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201:173,avail,available,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201,2,"['Error', 'avail']","['Error', 'available']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; # neighborhood graph of cells (determine optimal number of PCs here); sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); # compute UMAP; sc.tl.umap(adata); # tSNE; tsne = TSNE( n_jobs=20 ); adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ); adata.write( f_anndata_path ); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154:518,Error,Error,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:238,error,error,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,"['down', 'error']","['down', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1136:207,Error,Error,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942:389,Error,Error,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,7,"['error', 'fault']","['error', 'errors', 'fault']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1223:520,Error,Error,520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223,2,"['Error', 'fault']","['Error', 'fault']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...; ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png); with adata like this:; ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:; ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1246:581,Error,Error,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275:424,Error,Error,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275,4,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1249:833,Error,Error,833,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170:124,error,errors,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170,2,"['Error', 'error']","['Error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python; adata = sc.datasets.visium_sge(); ```; I get ; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'; ```; I figured it is because the intermediate folder ""/data"" is missing as well - . ```python; sample_dir.mkdir(exist_ok=True); ```; in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1184:320,Error,Error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172:456,Error,Error,456,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172,2,"['Error', 'avail']","['Error', 'available']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1175:375,error,errors,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175,3,"['Error', 'avail', 'error']","['Error', 'available', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Console outputs a long list of errors/warnings when running scanpy.pp.combat().; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataCombat = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164:105,error,errors,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164,2,"['Error', 'error']","['Error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; First of all, thank you for your great platform! . When I try to export a SPRING project I get the following error (it seems that the class NeighborsView is not defined; I have a 'neighbors' key in .uns): . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1260:183,error,error,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1325:175,down,downregulated,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325,3,['down'],['downregulated']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1208:438,Error,Error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157:378,error,error,378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/967:1073,error,error,1073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; #what works:; marker_genes = ['NCAM1']; ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:; subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/999:587,Error,Error,587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181:220,error,error,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1291:688,Error,Error,688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1286:589,Error,Error,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166:209,error,error,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1284:161,error,error,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_cells(adata, min_counts=300); sc.pp.filter_genes(adata, min_counts=1); sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'); sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'); sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells; print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; True; False; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24.; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1083:721,Error,Error,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I was plotting the paga path, I got the error of TypeError: float() argument must be a string or a number, not 'csr_matrix'. I guess this might be related with the sparse format of adata.raw.X, because my codes works if I deleted adata.raw. What would be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 excep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```; Exception Traceback (most recent call last); <ipython-input-195-8f87448845a3> in <module>; 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1043:1014,Error,Error,1014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1125:341,Error,Error,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125,3,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121:721,error,error,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; In the `sc.tl.dendrogram` module, I noticed that the correlation matrix was directly inputted into the `scipy.cluster.hierarchy.linkage`. That results in calculating the distance between samples by the Euclidean(X1_cor_with_others, X2_cor_with_others). Shouldn't the distance be the pure correlation value here? Please correct me if I didn't understand it correctly. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; The one I would perfer; ```python; df = 1-adata.uns['dendrogram_sample']['correlation_matrix']; data_linkage = hierarchy.linkage(ssd.squareform(; df); ...; ```; The one currently in sc.tl.dendrogram; ```python; data_linkage = hierarchy.linkage(adata.uns['dendrogram_sample']['correlation_matrix']); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1288:858,Error,Error,858,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1027:178,error,error,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1190:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190,2,"['Avail', 'error']","['Available', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1143:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataMNN = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167:162,error,error,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1171:159,error,error,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:139,error,errors,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1322:487,Error,Error,487,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1321:562,Error,Error,562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321,2,"['Error', 'down']","['Error', 'download']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1104:145,error,error,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error', 'errored']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1174:626,Error,Error,626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:; ```; >>> sc.pl.umap(post_adata, color=['XKR4']); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap; return embedding(adata, 'umap', **kwargs); File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039:191,error,error,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333:611,Error,Error,611,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,4,"['Down', 'Error', 'error']","['Downloaded', 'Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918:422,Error,Error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1315:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032:133,down,downstream,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032,3,"['Error', 'down', 'error']","['Error', 'downstream', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:492,error,error,492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1202:257,Error,Error,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1302:317,Error,Error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; here is the code for marker filter; I think the 3 condition need to be OR instead of AND; gene_names = gene_names[; (fraction_in_cluster_matrix > min_in_group_fraction) &; (fraction_out_cluster_matrix < max_out_group_fraction) &; (fold_change_matrix > min_fold_change); ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213:476,Error,Error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; sc.pl.tracksplot, produce a wrong highlight bar without brackets. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain',; var_group_positions=[(0,2),(4,5)],var_group_labels=['set1','set2']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![image](https://user-images.githubusercontent.com/30639029/83604801-9dedb700-a52b-11ea-9c32-fc35ea959d61.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.7.dev136+g7f5c907 anndata==0.7.1 umap==0.4.1 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1265:512,Error,Error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1265,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051:385,Error,Error,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one?; Can I have all them in my h5ad object and how to switch between them?; In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1875:537,down,downstream,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [✔] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm wondering whether it is possible to show the downregulated marker genes by sc.pl.rank_genes_groups() or other functions, so that we can export the gene list for further GSEA analysis?; I know sc.pl.rank_genes_groups_dotplot can show the downregulated genes by change n_genes to negative numbers, but it didn't work in sc.pl.rank_genes_groups().; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2052:533,down,downregulated,533,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052,2,['down'],['downregulated']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2107:704,avail,available,704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107,1,['avail'],['available']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [✔] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hello Scanpy,; I'm not sure whether Scanpy already has this function. For example, if we have `query` and `ref` data, we can use `ingest` to map the `query` onto the embedding of `ref`. Then, we can get similar UMAPs between these 2 data and do downstream analysis (like scVelo) based on these 2 UMAPs (coding below). In this way, because the UMAP is similar, we can have a more clear answer about how different these 2 date is.; ```python; ref = sc.read('ref.h5ad'); query = sc.read('query.h5ad'); var_names = query.var_names.intersection(ref.var_names); query = query[:, var_names]; ref = ref[:, var_names]; sc.tl.ingest(adata=query, adata_ref=ref, obs='leiden'); sc.pl.umap(query, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False) # this step will generate new obs['leiden'] and obsm['X_umap'] for query, which is a similar embedding with ref. adata = sc.read_loom(filename='queryraw.loom'); adata.obs['leiden']=query.obs['leiden'] # copy ingested leiden to raw data; adata.obsm['X_umap']=query.obsm['X_umap'] # copy ingested X_umap to raw data; # then do scVelo on this adata by using this embedding.; ```. However, `ingest` doesn't remove the batch effect. `BBKNN` does. After `BBKNN`, both `query` and `ref` will have new UMAPs stored at the same obsm['X_umap']. I'm wondering whether it is possible to split these 2 UMAPs? For example, store `query` UMAP in obsm['X_query_umap'] and `ref` UMAP in obsm['X_ref_umap'] so that we can copy each into a raw data. ![image](https://user-images.git",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2123:719,down,downstream,719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2123,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; ...; It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1139:561,error,error,561,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1829:896,robust,robust,896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829,1,['robust'],['robust']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1352:1045,down,down,1045,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352,1,['down'],['down']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi scanpy develovepers,. A rotation student asked me what is `sc.pl.umap` showing if `sc.tl.umap` was not computed beforehand. To which I don't have the answer since I have never done it. If you know the answer I'd like to know it, but most importantly, I think it would be nice to have an error message in the UMAP plotting function if UMAP has not been computed. Unless there were meaning and a reason to use `sc.pl.umap` without running `sc.tl.umap` previously, and it was designed that way purposely. I assume this would apply to other plotting functions too. Thanks!; Alejandro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460:764,error,error,764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2249:684,error,error,684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249,2,"['down', 'error']","['downsides', 'error']"
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: ; - Cluster cells based on endogenes; - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. ; I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:; ```; sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ?; ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1500:999,down,downstream,999,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When testing for differential genes among groups with `rank_genes_groups` function, two options are available for `reference`: `'rest'` or any other single group. It would be helpful to have the possibility to choose different groups as reference (`reference: Union[Literal['rest'], Iterable[str]] = 'rest'`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/984:569,avail,available,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/984,1,['avail'],['available']
Availability,"<!-- What kind of feature would you like to request? -->; How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)?; - [ +] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy?. Thank you very much in advance; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2448:332,avail,available,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448,1,['avail'],['available']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Only check the following box if you did not include release notes -->. ## TODO:. - [x] Fix tests; - [x] Figure out PCA test case with anndata 0.8.0; - [x] Add CI job; - [x] Rename CI job to be less similar to minimal dependencies, this will probably be `MinVer`; - [x] Bump anndata requirement back down to 0.7.3 (breaks dask tests); - Maybe 0.8 is low enough?; - [x] Bump pandas requirement back down to 1.5 (breaks grouped plots ordering). ## Some thoughts. * Sibling PR to: https://github.com/scverse/anndata/pull/1314; * Not completley sure what to do about plotting tests yet. Possible we just ignore any comparison failures, but ideally we could still know if these are broken.; * Metric consistency test failure is from https://github.com/scverse/scanpy/issues/2688; * Test updates in https://github.com/scverse/scanpy/pull/2705 (plus bumping one test a little lower) fixes it. <!-- Please check (“- [x]”) and fill in the following boxes -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816:538,down,down,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816,4,"['down', 'failure']","['down', 'failure', 'failures']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes # _no existing issue_; - [ ] Tests included or not required because: _No new tests_; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: _I did not write release notes_. Hi :). I am proposing a change that speeds up `filter_cells` (x1000 speedup) and `filter_genes` (x2 speedup) for CSR sparse matrices. On my personal machine for 1M cells, `sc.pp.filter_cells(adata, min_genes=xx)` runs in 1ms instead of 10s currently. The speedup should be even stronger on sparser modalities like ATAC. In spirit, this simply replaces `np.sum(X > 0, axis=axis)` with `X.getnnz(axis=axis)`, which is much more efficient. But the axis argument in `getnnz` in `csr_array` may be deprecated. I think it should still be fine with `csr_matrix`, but since I don't know for sure I manually implemented it for the CSR case as in https://github.com/scipy/scipy/issues/19405 . What do you think?. Regarding `getnnz`: Of course it would be nicer to be able to write `.getnnz(axis=axis)`, which extends beyond CSR to other sparse matrices. Can we assume that we're getting sparse matrices and not sparse arrays ?. Pinging @dschult from the Scipy issue liked above, who mentioned: . > I'm pretty sure that a reasonable and commonly occuring use-case would be enough to make the developers include this feature somehow. (edited because I confused `csr_array` and `csr_matrix`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2772:1467,Ping,Pinging,1467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772,1,['Ping'],['Pinging']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #1263; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`; * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`; * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values; - [ ] Test sort_order argument deprecation; - [ ] Add support for `pd.Series` array values.; - [ ] Maybe `list`s?; - [ ] ""How to"" or modify existing advanced plotting tutorial; - [ ] Tests for; - [ ] Categorical ordering; - [ ] None is same as `np.arange(N)`; - [ ] direct overlap + ordering is equivalent to masking; - [ ] Continuous ordering; - [ ] ""ascending"" is like `np.argsort(values)` and vice versa; - [ ] ""ascending"" is like ""descending"" for inverted values; - [ ] Check masking for both; - [ ] Errors; - [ ] For incorrectly sized input array; - [ ] incorrect non-array input; - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2998:1249,mask,masking,1249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998,3,"['Error', 'mask']","['Errors', 'masking']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because: n_components must be less or equal to the number of samples, otherwise it would throw an error, for example, ValueError: n_components=100 must be less or equal to the batch number of samples 40. This error usually happens on the last chunk of the partial_fit.; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:. For example, my adata.shape[0] is 1041 and I run IncrementalPCA `sc.tl.pca(adata, n_comps=100, chunked=True,chunk_size=1000)`, and I got an error: ValueError: n_components=100 must be less or equal to the batch number of samples 40 on scanpy/preprocessing/_pca.py:256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3313:450,error,error,450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3313,3,['error'],['error']
Availability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2757:399,failure,failure,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757,2,['failure'],['failure']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts I’m not 100% sure about removing are; - “When to make a pre-release” – I feel like “if UR unsure, make one of these” wasn’t helping here either, so maybe that should just be fleshed out as a section now we’re down a few sections; - “Check the file contents of the wheel” should probably go into “how to code review a PR that touches the build process”, and we don’t have any other guides on how to do code reviews, so …",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720:960,down,down,960,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720,1,['down'],['down']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~ – still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2705:808,toler,tolerances,808,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705,1,['toler'],['tolerances']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2836; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. Changes:; - Removes import-time change to globals:; 	- `matplotlib.testing:setup` should be called before each (plotting) test; 	- `sc.set_figure_params(dpi=40, color_map=""viridis"")` seems to be overwritten. When calling it inline, it messes up the figure params; 	- `sc.pl.set_rcParams_defaults()` is redundant, `setup` from above does that.; - Use workaround from https://github.com/pytest-dev/pytest/issues/11759#issuecomment-1888888146",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838:799,redundant,redundant,799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838,1,['redundant'],['redundant']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3051; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. TODO:. - [x] release notes; - [x] some added text explaining things; - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest; 2. run internet tests in CI; 1. add caching to CI; 2. make sure the dataset functions don’t download already-downloaded data; 3. validate cached data instead; 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060:880,down,download,880,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060,2,['down'],"['download', 'downloaded']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3226; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. An alternative would be to subclass `PCA`, but that would involve erroring out or reimplementing all of its options. Ideally #3267 would be merged first and this one integrated into its improved decision tree.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263:552,error,erroring,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263,1,['error'],['erroring']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3260; - [x] Tests included or not required because: minor change to maintain compat with `statsmodels`>=14.0. Inspired by @mwaskom's [fix for seaborn](https://github.com/mwaskom/seaborn/pull/3356), which promotes the warning to an error and catches it (in this case with the same logic `scanpy` was using for prior versions of `statsmodels`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275:544,error,error,544,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes error if the `log1p` dict doesn't have a `base` key. Fixes https://github.com/scverse/scanpy/issues/2497, fixes https://github.com/scverse/scanpy-tutorials/issues/65, fixes https://github.com/scverse/scanpy/issues/2181",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2546:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....); * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2999:244,Error,Error,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999,1,['Error'],['Error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hi,; We are submitting PR for speed up of the _get_mean_var function. ; | | Time(sec)|; | -----------| ----- |; | Original | 18.49 |; | Updated | 3.97 |; | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To redu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099:783,Down,Downloading,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Pandas was throwing a warning:. `FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.`. This fixes that warning. The fix is a little weird, but it's what pandas says to do. Pandas explanation of the new behaviour is [here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v2.1.0.html#new-implementation-of-dataframe-stack). Changes here:. `rank_genes_group_df`. * The sort order doesn't matter here since we sort again anyways; * `dropna=True` here actually doesn't drop null values from `filter_rank_genes_groups`. AFAICT, this doesn't change anything. `StackedViolin`. Here, we were already opting in to the future behaviour with `dropna=False`. ------. This also fixes a type signature for `sc.get.rank_genes_groups_df` and makes a better error reporting for a test I saw fail locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2864:1184,error,error,1184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2864,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python; if isinstance(arg1, AnnData) and arg1.isbacked:; raise NotImplementedErrror(...); ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3004 and closes #2894; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048:260,error,errors,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048,1,['error'],['errors']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This adds the missing bibtex formatter from my review in #2901. Since this PR is necessary to productively work with the bibliography without making a mess, and y’all are on a hackathon, I’ll merge it without review. ## Content. - Replace frail line based inclusions like `:end-line: 32` with markers. If someone destroys a marker, the doc build will fail instead of containing a garbled mess.; - Moves the flit-centric dev docs to non-opinionated tooling; - Since there are no functional bib formatters that run within pre-commit (See https://github.com/ge-ne/bibtool/issues/58), we’re going to have to live with using our own. For that purpose, I took the last open source version of `betterbib` and trimmed it down a bit. Once there’s something better that we don’t have to maintain, we should use that. Companion PR: https://github.com/scverse/scanpy-tutorials/pull/103",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2983:947,down,down,947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2983,1,['down'],['down']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590:1357,Mask,Mask,1357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590,1,['Mask'],['Mask']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1999:572,error,error,572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061:812,Down,Downloading,812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110:703,down,downstream,703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110,1,['down'],['downstream']
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2155:424,down,downsampling,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155,2,"['down', 'robust']","['downsampling', 'robustness']"
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, . I am hoping to open a pull request soon to add [CellO](https://www.cell.com/iscience/fulltext/S2589-0042(20)31110-X), a cell type classification tool, to Scanpy's external API. I notice that there currently are no cell type classification tools available in Scanpy's external API. . I am wondering if there is an explicit reason no cell type classifiers have been added to date? For example, I noticed some debate regarding how/whether to include expression imputation into Scanpy [https://github.com/theislab/scanpy/issues/189](https://github.com/theislab/scanpy/issues/189), and I just want to make sure there is no such reason why cell type classifiers have not been included yet. Thank you!. Matt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1631:428,avail,available,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1631,1,['avail'],['available']
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1908:330,down,down-sampled,330,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908,1,['down'],['down-sampled']
Availability,<details>; <summary> Errors look like: </summary>. ```; FAILED scanpy/tests/test_highly_variable_genes.py::test_runs - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_supports_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_batch_matches_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_compare_to_upstream[seurat-hvg] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_sparse - ValueEr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:21,Error,Errors,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['Error'],['Errors']
Availability,"<details>; <summary> Traceback from readthedocs: </summary>. ```pytb; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1057:310,avail,available,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057,3,"['avail', 'error']","['available', 'errors']"
Availability,"=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; biothings_client 0.3.0; brotli NA; cairo 1.23.0; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4229,down,down,4229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['down'],['down']
Availability,"===========================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2844,toler,tolerance,2844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['toler'],['tolerance']
Availability,"> 'outline' could be good. We already have font outline that works similarly. Great!. > Can you take a look at the new type hints that I added. I am not sure if I did it right?. The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient.; - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return.; - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`; - `Sequence`→`Sequence[?]`; - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py; def _get_vmin_vmax(; […]; color_vector: Sequence[float],; ):; '''; […]; ```. ```py; logg.error(; ""The parameter […]""; […]; ""of plots.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089:1234,error,error,1234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089,1,['error'],['error']
Availability,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:598,mask,mask,598,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486,2,['mask'],['mask']
Availability,"> (a) a pair of completely correlated features, and (b) very strange count distributions. can you elaborate more on this? what does it mean ""completely correlated"", like an identical copy ?. > Once I used a proper variance stabilizing transform (arcsinh in this case) and remove redundant features. Interesting, never seen this used in scRNA-seq, is it common in IMC ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802666323:279,redundant,redundant,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802666323,1,['redundant'],['redundant']
Availability,"> * Make a case where a threshold can't be found (not sure how this would be done). Obviously I can test the plotting by directly unsetting the relevant things, but I'm not actually sure how to trigger a failure with the test data I'm afraid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287:204,failure,failure,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287,1,['failure'],['failure']
Availability,"> . Hi, @jlause . There's a issue when using `normalize_pearson_residuals`, it seems that we can't calculated the `log2foldchange` in `rank_genes_groups` will be failed. That's because `np.expm1` can't restore the `adata.X` after `normalize_pearson_residuals`. Could you solve this issue that completed the downstream currently?. <img width=""770"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/46667721/a8e64ab1-360d-43a2-a07b-a766049bcbcd"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2501:307,down,downstream,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2501,1,['down'],['downstream']
Availability,"> . Hi, @jlause . There's a issue when using `normalize_pearson_residuals`, it seems that we can't calculated the `log2foldchange` in `rank_genes_groups` will be failed. That's because `np.expm1` can't restore the `adata.X` after `normalize_pearson_residuals`. Could you solve this issue that completed the downstream currently?. <img width=""770"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/46667721/a8e64ab1-360d-43a2-a07b-a766049bcbcd"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1578401813:307,down,downstream,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1578401813,1,['down'],['downstream']
Availability,"> ; > ; > #530 also related. Are you including the `log_transformed=True` kwarg in your call to `rank_genes_groups()`?. oh, I'm not. But when I included it, the ’ValueError: math domain‘ error still appeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/952#issuecomment-567379722:187,error,error,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/952#issuecomment-567379722,1,['error'],['error']
Availability,"> ; > ; > Seen this recently exactly on a windows laptop. Not sure but sound like something messed up with the environment, are you working on the base env? Try creating a fresh conda environment and installing scanpy there. Thanks for the suggestion, @giovp. Was doing it in the base env earlier. Made a new env and tried it again, but ran into the same exact error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323:361,error,error,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323,1,['error'],['error']
Availability,"> ; > ; > Thanks for your response. As of today that's correct: AWS, GCP and DO. Azure support is a work in progress at the moment. It should be available by the end of this month most likely. Do you have a hard deadline on this?. No we don't. But before using it Cirun I would have to look at more closely first.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-882740958:145,avail,available,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-882740958,1,['avail'],['available']
Availability,"> ; > ; > What's your version of `numba` in this environment?. It's version 0.48.0, @ivirshup. For what it's worth, the build is py38he350917_0 and the source is conda-forge. (In the base environment where I was getting the same error, the version is the same but the build is py37h47e9c7a_0.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-610413337:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-610413337,1,['error'],['error']
Availability,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > > > Hope this helps 😊; > > ; > > ; > > Hi, the link seems to be invalid. Is there any alternative links?; > ; > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041349621:377,down,download,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041349621,1,['down'],['download']
Availability,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > > Hope this helps 😊; > ; > Hi, the link seems to be invalid. Is there any alternative links?. Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041346736:373,down,download,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041346736,1,['down'],['download']
Availability,"> > I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!; > ; > I encountered the same issue. Which version are you using to fix this?. nm, downgrading to 1.5.1 fixed my problem. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191:205,down,downgrading,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191,2,['down'],['downgrading']
Availability,"> > In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; > ; > As @LuckyMD said, this is a question for `scvelo`.; > ; > > I guess what i make the cell order was wrong ?; > ; > The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done.; > ; > > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?; > ; > Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names.; > ; > d; Thanks i would check currently, and reported the result as soon as possible. ; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872:755,robust,robust,755,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872,1,['robust'],['robust']
Availability,"> > Numba can’t correctly detect when a threading backend is available; >; > Is there a numba issue for this?. https://github.com/numba/numba/issues/6108, This issue may be specific to `tbb`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874667150:61,avail,available,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874667150,1,['avail'],['available']
Availability,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:345,down,downside,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574,1,['down'],['downside']
Availability,"> > ```python; > > scipy.io.mmwrite; > > ```; > ; > This code doesn't actually work - rows and columns are switched in the matrix, and it produces an error when you try to read in the output using either `Scanpy` or `Seurat` wrapper functions. Perhaps it's a package version thing though.. I was having the same issue as well. I ended up doing what was suggested above:. `adata.T.to_df().to_csv('matrix.csv')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-1520696083:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-1520696083,1,['error'],['error']
Availability,"> @Sunyiqing2003 we certainly don’t want you crying!; > ; > people here had problem reading with older anndata versions, but you seem to have the newest one, so it’s not the same issue. could you file a new issue?. Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1628515570:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1628515570,1,['error'],['error']
Availability,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:270,error,error,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043,1,['error'],['error']
Availability,"> @WeilerP, do you think this would be more appropriate in `scvelo`? (Side note, I have thought that tutorial; > of going from BAMs through `scvelo` would be quite useful). Hm, not sure if the functionality would match the expectation. In `scvelo`, we'd store only unspliced and spliced counts (spliced both in `adata.X` and `adata.layers`). Based on the proposed code snippet in [alexdobin/STAR#774 (comment)](https://github.com/alexdobin/STAR/issues/774#issuecomment-850477636), the expected output would be to read all of the available information?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1860#issuecomment-873990253:529,avail,available,529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860#issuecomment-873990253,1,['avail'],['available']
Availability,"> @Zethson I believe that's an upstream issue. Looks like the docs broke when `sphinx-autodoc-typehints` bumped versions from `1.12.0` to `1.13.0`.; > ; > I can build the docs locally from `master` and from this branch with `sphinx-autodoc-typehints` v1.12, but not v1.13. (You'll also see an identical error in #2099, despite that just being a dependency bump for pre-commit.); > ; > I'll submit a PR to pin `sphinx-autodoc-typehints` to version 1.12.0 shortly. Thank you for taking the time to dig into this! Much appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005073549:303,error,error,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005073549,1,['error'],['error']
Availability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:217,error,error,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,1,['error'],['error']
Availability,"> @brainfo I'm afraid that we only speak English. Hi sorry and indeed that's an automatic reply from the email service I just changed the email address so this would not be a problem later. To add one more problem encountered when writing out anndata object: ; When the anndata has 'predicted_doublet' in obs annotation from sc.external.pp.scrublet, the boolean values could not be implicitly converted to strings so that gives errors: . ```{py}; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'predicted_doublet' of <class 'h5py._hl.group.Group'> to /; ```. Users can map the values like this but would it be better to have the implicit conversion while read/write anndatas?; ```{py}; anndata.obs['predicted_doublet'] = anndata.obs['predicted_doublet'].map({True: 'True', False: 'False'}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208:428,error,errors,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208,2,['error'],"['error', 'errors']"
Availability,"> @brianpenghe, do you have a copy of your original file? Any idea what could have been different?; > ; > @dn-ra, would you be able to share the first couple lines of your file, and let me know how it was generated?. I think I found the cause: ; When the genes.tsv only has one column it doesn't work and throws this error. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-984799011:317,error,error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-984799011,1,['error'],['error']
Availability,> @fidelram Thank you for your suggestions! The example data in Scanpy worked without flaw. I will go over my code again!. Actually I solved this problem by adding more markers in the marker gene list. ; Alternatively The error will be gone if I `swap_axes=True`; Interesting,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-470945339:222,error,error,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470945339,1,['error'],['error']
Availability,"> @hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream. Figure it out. In my case it's because I have both `umap` and `umap-learn` installed, see here: https://github.com/theislab/scanpy/issues/2045#issuecomment-963533994",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478:163,down,down,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478,2,['down'],['down']
Availability,"> @ivirshup @LuckyMD; > I fixed the problem - the issue was in the original h5ad file converted from a Seurat object using SeuratDisk::Convert(). It seems the var data wasn't ported over properly for the assay I was using. I rebuilt the h5ad file using reticulate instead and that solved the problem. I have encountered the same issue as @mosquitoCat .; Although adata.var_names still returns correct gene symbols, all my name IDs become numbers:; for example, sc.pl.umap(adata,color='GeneName') will return errors. but sc.pl.umap(adata,color='123') can be recognized.; SeuratDisk::Convert() seems to cause some trouble here. Is there a way to fix it? @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/914#issuecomment-852691627:508,error,errors,508,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/914#issuecomment-852691627,1,['error'],['errors']
Availability,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253,1,['error'],['error']
Availability,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it?. We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534067279:4,down,downside,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534067279,2,['down'],"['down', 'downside']"
Availability,"> AFAICT, I think the parallelization you're seeing will be due to the underlying calls in statsmodels. If you turn down the number of threads blas can use, do you see the same utilization?. FYI more n_jobs seems to be slower for regress_out if I don't disable the BLAS multi threading:; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=1); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:04:05); ```; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=24); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:07:41); ```. I'm using scanpy 1.5.2.dev104+g8611dba1. Indeed after disabling BLAS multi threading sc.pp.regress_out will only use one core if setting n_jobs = 1. But it has to be disable by exporting these environmental variables before starting python ..., but I guess it is not a good thing because other scanpy functions may be affected?; ```; export MKL_NUM_THREADS=1; export NUMEXPR_NUM_THREADS=1; export OMP_NUM_THREADS=1; ```; More interesting is that regress_out becomes lightning fast when n_jobs = 24 and with BLAS multi threading disabled:; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=24); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:00:23); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-684103610:116,down,down,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396#issuecomment-684103610,1,['down'],['down']
Availability,"> About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. As a general point about this PR: to me, the fair amount of the work of turning on flake8 deciding on the rules. Perhaps we should start with a subset of files then? I realize you did not come to the meeting where we talked about this, so perhaps there is a difference of expectations here, but we agreed to be conservative about the rules we turned on in `pre-commit`. Going through everything to make sure changes are correctly reverted is also takes a lot of time for me as the reviewer. I'd also like to limit that. ----------------. You said you used some automated tools to get faster compliance. What were these? In general, I would prefer to have a formatter that automatically ran than a tool that told me I formatted something wrong. -----------------. > `@ivirshup` I would keep the noqas. They are very easily searchable across the whole project and can be fixed later. I'm pretty strongly against this. `noqa`s just look like the formatter/ linter was wrong, and I'm not accepting that having no plan to address bugs. I think this should be a discussion with a broader set of the team. > ""Whats up with removing leading #s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. Yes, lets ignore this. >> ""I don't like replacing x == False with not x in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this.""; >; > This should be covered by tests. In any case it is not good style and a violation. I will try and take a closer look at these changes. I'm particularly concerned that there will be cases where possible values are `None`, `True`, and `False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670:1529,error,error,1529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670,1,['error'],['error']
Availability,"> Also isn’t it cool that it points exactly to the problematic line?. Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519:332,error,error,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519,1,['error'],['error']
Availability,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?); > ; > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462:407,down,downloading,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462,2,['down'],"['downloading', 'downloads']"
Availability,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:134,down,download,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804,8,['down'],"['download', 'downloaded']"
Availability,"> Could you try building the docs and checking if anything gets added? The `scanpy.plotting.rst` file has been weird in the past. I think it's at least started being consistent with newer versions of sphinx, but it'd be good to check. The pbmc data in the docs folder does indeed get downloaded when building the docs.; Do you want me to include this path into the `.gitignore`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-847710888:284,down,downloaded,284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-847710888,1,['down'],['downloaded']
Availability,> Did you look at #454 ?. I tried to downgrade h5py but still did not work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080:37,down,downgrade,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080,1,['down'],['downgrade']
Availability,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply!; Unfortunately , no visible exception... My code is as follows:. ```py; import velocyto as vcy; import numpy as np; import scanpy as sc; import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""); S = vlm.S; S=S.transpose(); adata = anndata.AnnData(S); print(adata.X); print(adata.obs); print(adata.var). sc.pp.neighbors(adata, n_neighbors=100); adata.uns['iroot'] = 0; print(adata.uns); sc.tl.dpt(adata, n_branchings=2); sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'); ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb; WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:; def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))); [2] Du",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,2,['error'],['error']
Availability,> Encountering the same error. Updating h5py did not seem to help. Any advice on this?. This might be useful to you:; https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153,1,['error'],['error']
Availability,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935,2,"['down', 'error']","['downstream', 'error']"
Availability,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:124,error,errors,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533,1,['error'],['errors']
Availability,"> Figure out and fix this:. I think the `tbb` thing can be a `TODO` for this. Things work as is, and I don't know off the top of my head if we can reliably fix this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954623605:147,reliab,reliably,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954623605,1,['reliab'],['reliably']
Availability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:402,down,down,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,8,"['down', 'mainten']","['down', 'maintenance']"
Availability,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE?. ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py; if use_fast_tsne is not None:; warnings.warn(""..."", FutureWarning); match (use_fast_tsne, flavor):; case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'; case (None, _): ... # use specified flavor; case (True, 'auto'): ... # use 'multicore'; case (True, 'sklearn'): ... # throw error; case (True, _): ... # use specified flavor; case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'; case (False, _): ... # Throw error; case _: ... raise AssertionError(); ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668:50,down,down,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668,3,"['down', 'error']","['down', 'error']"
Availability,"> From a first glance, with seurat_v3 requiring count data, it is important that your .X (becoming the layer you refer to as counts) indeed contains counts, otherwise loess quickly runs into stability issues. I would expect there would be a warning here if this were the case, since `check_values` defaults to `True`. But at least this person had the same error caused by passing in normalized values:. * https://www.biostars.org/p/9535944/. The [author of scikit-misc says](https://github.com/has2k1/scikit-misc/issues/6#issuecomment-615304167):. > pass `surface=""direct""`. to the loess solver based only off the error message. So maybe we can enable that. I don't know enough about loess to be able to say why that would fix this. It would be interesting to see the data that caused this error. I would definitely want to have a reproducible case before attempting a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853#issuecomment-1997957671:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853#issuecomment-1997957671,3,['error'],['error']
Availability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,2,['error'],['error']
Availability,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?. Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463,1,['error'],['error']
Availability,"> Great!; > ; > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do.; > ; > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?. Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726651017:213,error,error,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726651017,2,['error'],['error']
Availability,> Great. Please ping me here when you upload the file to... I uploaded the file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436040174:16,ping,ping,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436040174,1,['ping'],['ping']
Availability,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044409149:136,error,errors,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044409149,1,['error'],['errors']
Availability,"> Hey! Just to chime in, I believe plotting functions also expect categoricals and I've had errors from other functions as well about obs columns not being categorical. I think that was `rank_genes_groups`, but I'm not sure. This is definitely true but easy enough for the user to address if the error is clear (or handle internally as needed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-801719754:92,error,errors,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747#issuecomment-801719754,4,['error'],"['error', 'errors']"
Availability,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example using a random matrix. .; > ; > The problem is even more dramatic for method=""umap"".; > ; > ### Minimal code sample (that we can copy&paste without having any data); > ```python; > import scanpy; > import numpy; > ; > matrix = numpy.random.uniform(size=[10000,1000]); > ; > adata = scanpy.AnnData(matrix); > ; > scanpy.pp.pca(adata,n_comps=10); > scanpy.pp.neighbors(adata,method=""gauss"",n_pcs=10); > ```; > ; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\L",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418:537,error,error,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418,2,['error'],"['error', 'errors']"
Availability,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. ; ### Minimal code sample. ```python. import scanpy; import numpy; > ; tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'); sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>; <summary> traceback </summary>. ```pytb; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160:468,error,error,468,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160,2,['error'],"['error', 'errors']"
Availability,"> Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py. Hi,. I have been trying to use this wrapper, but seems like there's some error during the conversion process:. RRuntimeError: Error in validObject(.Object) : ; invalid class “dgCMatrix” object: 1: invalid object for slot ""i"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 2: invalid object for slot ""p"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 3: invalid object for slot ""Dim"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 4: invalid object for slot ""x"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""numeric"". Any pointers to get around this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061:15,avail,available,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061,4,"['Error', 'avail', 'error']","['Error', 'available', 'error']"
Availability,"> Hi, no worries! I tried that but by explicitly stating ‘use_raw=True’ but it did not change the outcome. From: Fidel Ramirez <notifications@github.com> Reply-To: theislab/scanpy <reply@reply.github.com> Date: Monday, January 7, 2019 at 11:16 AM To: theislab/scanpy <scanpy@noreply.github.com> Cc: ""Heymann, Jurgen (NIH/NIDDK) [E]"" <heymannj@niddk.nih.gov>, Author <author@noreply.github.com> Subject: Re: [theislab/scanpy] sc.pl.stacked_violin: IndexError, list index out of range (#405) Hi, sorry for the late reply. Given that the function works for some mg genes but not for other, this usually indicates that the gene may not be in the matrix. Can you try to set `use_raw=True` just to check if this is the issue (although use_raw should be True by default). Still, very suspicious that it works with with other functions like matrixplot.; > On Thu, Dec 27, 2018 at 9:07 PM Alex Wolf ***@***.***> wrote: @fidelram <https://github.com/fidelram> Could it be that stacked_violin doesn't fully account for .raw? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-450221575)>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEu_1ftSP-OSKeDQYWV8Eu0-oRt6aXBAks5u9Sh_gaJpZM4ZiTv5> .; > — You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-451988385)>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AioIiKYX4lsLgg91sMNygZWO1ALRDzsqks5vA3KmgaJpZM4ZiTv5>. Same error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-470943686:1658,error,error,1658,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470943686,1,['error'],['error']
Availability,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:271,error,error,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906,6,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ?; > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function.; I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-660125494:188,ping,pinging,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-660125494,1,['ping'],['pinging']
Availability,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > ; > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > ; > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041344958:373,down,download,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041344958,1,['down'],['download']
Availability,"> Hi,; > ; > Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; > ; > 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); > 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; > 3. Your data may have been pre-processed to take out mitochondrial genes.; > ; > I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`. It really helps! Thanks very much!(by the way I am using zebrafish data and it still should be lower case, but I was just not aware of this)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639#issuecomment-491473602:120,error,error,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491473602,1,['error'],['error']
Availability,"> Hi,; > ; > Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess. Thank you for your reply. I think the 'mito_genes' vector was all boolean. Maybe it has a zero-sum. So, how can I resolve this problem, Do you have any suggestions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/647#issuecomment-493067273:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-493067273,1,['error'],['error']
Availability,"> Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?. Yes, it's definitely large and it's awesome that you solved this problem! I just meant that it's not hitting people's computational resources limits: your example is 60K x 2K, so quite big already, if you densify you need 800MB, which is easily available even on a laptop. That's what I meant. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-450220968:355,avail,available,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450220968,1,['avail'],['available']
Availability,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:14,down,download,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545,2,['down'],['download']
Availability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:211,error,error,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,1,['error'],['error']
Availability,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.; Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-996448667:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-996448667,1,['error'],['error']
Availability,"> I created a new environment (see below for package details) and there everything works as it should. Can you use this new environment to do your analysis?. I expect that the previous environment managed to get into a messy state, which can lead to very strange errors. Because of this, I generally avoid trying to update old environments much and instead opt for creating fresh ones frequently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096:263,error,errors,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096,1,['error'],['errors']
Availability,"> I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.; > ; > First I tried to upgrade numba and umap as suggested by the other individuals in the thread:; > ; > ```shell; > pip install --upgrade numba; > pip install --upgrade umap-learn; > ```; > ; > Then I essentially reinstalled scanpy using the steps in their installation docs.; > ; > ```shell; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > I think I then ended up with a version of numpy that was incompatible with numba so I ran; > ; > ```shell; > pip install numpy==1.20; > ```; > ; > After each step, you should be able to run the code from above to check if your installations worked, which I used to pinpoint what still needed work in my environment:; > ; > ```shell; > python3 -c ""import numpy as np; import umap; umap.UMAP().fit_transform(np.random.randn(10_000, 20))""; > ```; > ; > This seemed to fix my problems; I hope it's able to help others!. I followed your instruction but it still threw errors:. <frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject. Segmentation fault",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606:1167,error,errors,1167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606,4,"['error', 'fault']","['errors', 'fault']"
Availability,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:105,avail,available,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272,2,['avail'],['available']
Availability,"> I find out the solution. Thank You. Although I think that this is not an issue with Scanpy, it is usually common courtesy to post the solution to the corresponding issue. If other people search for the same error they can find your solution :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817788753:209,error,error,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817788753,1,['error'],['error']
Availability,"> I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. After this merges new ignore messages can be added for reasons like ""this rule is generally good, but not in this specific case"". Each of these will go through PR review, so will be vetted. The ones added here largely have not been vetted, and are just being added so we don't get a failure. I would like to be able to distinguish between these cases. Once more `noqa` cases are added, it gets more complicated to find cases that haven't been vetted if they don't have some associated label. --------------------------. > What do you mean? How to ignore a single line? How to fully ignore whole checks?. How to disable flake8 errors for a line or file. > I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. A link to the section of the flake8 docs on this would be great. -------------------------. > I wish it were that easy. autopep8 does not take its configuration from the flake8 config file . `autopep8` says it does this: https://github.com/hhatto/autopep8#configuration. > It formats consistently, but not necessarily compatible with other tools. I would like changes that are automatically applicable to be automatically applied. I'm thinking of things like white space in docstrings. Is there another way to automate these you can suggest?. ---------. BTW, I've added a few more points to the checklist above. I would recommend trying to build the package and build the docs in the directory you're working in to see what files get generated so they can be added to the `ignore`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782:539,failure,failure,539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782,2,"['error', 'failure']","['errors', 'failure']"
Availability,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:45,down,downloading,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241,4,"['down', 'error']","['downloading', 'error']"
Availability,"> I had also thought isort could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (imperative programming strikes again!). Yeah, I ran into this stuff when creating the flake8 PR (#1689). isort is dangerous with Scanpy and requires good testing and many exceptions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164,1,['error'],['errors']
Availability,"> I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working. Same here. I assume there is some issue with the implementation of the setter of adata.X, which prevents `adata.X = adata.X.toarray()` from updating X to its densified version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689,1,['error'],['error']
Availability,> I just had another thought... it seems like this might have to do with the initial `sc.tl.paga()` call. There you get a runtime warning about overflow in long scalars. Maybe check if you get any meaningful output in `adata.uns['paga/connectivities']` or `adata.uns['paga/connectivities_tree']`. It might just be all `nan` in there due to the above errors. Could it be that you have a 32-bit windows version and the code is trying to use 64-bit floats? Maybe that's the overflow error?. my system type is 64 bit,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-535093343:350,error,errors,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-535093343,2,['error'],"['error', 'errors']"
Availability,"> I know exactly that in PCA I can interpret a component based on its rank (and/or variance contribution). Ah, I meant more specifically that it may be easier to biologically interpret an ICA. > That would say I should try as many decompositions as possible to see when I get a good result. I'm a little unsure of your meaning here. Do you mean decompositions like decomposition techniques? If so, I don't think this is the right conclusion. I think it means: probably PCA for clustering, probably NMF for finding gene modules. I would also suspect something which finds sparser variable loadings like ICA or NMF could be more robust for cross dataset classification. If you mean, if the results are unstable how do we know which to trust – I did ask that question. I think it's the usual: have a validation dataset, maybe some ensemble/ robustness method, or do some sort of enrichment. It's an open question, but a lot of our analysis pipeline is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033:627,robust,robust,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033,2,['robust'],"['robust', 'robustness']"
Availability,"> I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. yeah also don't understand them, it might be @cache in py 3.7 has issues? will investigate next week and report back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610,1,['error'],['error']
Availability,"> I see... but as it's always `adata.uns['paga']` what would happen if I have an old object and then run a new `sc.tl.paga()` with `key` set to something. Then you'll have it under both `adata.uns['paga']` and `adata.uns['paga'][key]`. That's not backwards compatibility though. BC is running the old code (so no key='key') with an old object (where paga is under `adata.uns['paga']`) with new scanpy and getting the old result, which is satisfied here. There are weird failure modes though, like using `key='groups'` or `key='connectivities'` might override some parts of an existing, old-style paga result. We can forbid keys like these. Actually this is related to the versioning of AnnData specification. We should keep some sort of version like `/attrs/LOOM_SPEC_VERSION` in loom. Then it would be easier to understand what to expect from an anndata object that is created at any point in time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/957#issuecomment-567549770:470,failure,failure,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/957#issuecomment-567549770,1,['failure'],['failure']
Availability,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there?. I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python; sc.pp.neighbors_tsne(adata); sc.tl.tsne(adata); ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759238450:268,mainten,maintenance,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759238450,2,['mainten'],['maintenance']
Availability,"> I think the result in such a case could just contain nans and emit a warning. This sounds reasonable to me. With sparse values, it's consistently giving results, but it's the wrong results. The iteration is being chunked (probably related to number of available cores), and it looks like within each chunk all values after the constant one are filled with zeros. I should look into whether this is also numba, or a logic bug. If it's numba, it's strange that it's zeros and not `inf` or `nan`. If it's on our end, I'm not sure why the later iterations would be skipped. ----------. > p.s.: I really like how you document everything you do so nicely 😃. Thanks! Is mostly so I can remember my reasoning a month later 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245:254,avail,available,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245,1,['avail'],['available']
Availability,"> I thought at one point you guys were checking flake8 with CI. We were, sorta. The CI tool we were using had pretty stochastic reporting (which isn't really what we want in a CI tool). Hopefully it'll be back in a more reliable form soon: https://github.com/theislab/scanpy/issues/1563#issuecomment-784922713",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1679#issuecomment-784998888:220,reliab,reliable,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679#issuecomment-784998888,1,['reliab'],['reliable']
Availability,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. ; > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-762595475:1477,down,down,1477,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-762595475,1,['down'],['down']
Availability,"> I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!. I encountered the same issue. Which version are you using to fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174:201,down,downgrading,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174,1,['down'],['downgrading']
Availability,"> I'm not sure we're looking at the same code. I was looking at this:. I was looking at the [TruncatedSVD](https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/decomposition/_truncated_svd.py#L186) code. Either way, I'm not able to reproduce your assertion error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652,2,['error'],['error']
Availability,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this?. > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function?. > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395:169,avail,available,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395,4,"['avail', 'down']","['available', 'downstream']"
Availability,"> I'm not to sure what the assumptions are behind each method though. @falexwolf, any reason in particular you've chosen UMAP's method for the KNN calculation?. It's highly competitive in terms of speed and accuracy with other libraries (https://github.com/erikbern/ann-benchmarks, pynndescent is what umap uses, wasn't available at the time for Scanpy), it's a lot easier to install than everything else, and the result has been shown to harmonize well with UMAP, which I expected would become the canonical way of visualizing things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649:320,avail,available,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649,1,['avail'],['available']
Availability,"> I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']` Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file. The file I was reading in was from HTO data and only had one column:; > ; > > Hashtag1-GTCAACTCTTTAGCG; > > Hashtag2-TTCCGCCTCTCTTTG; > > Hashtag3-AAGTATCGTTTCGCA; > > unmapped; > ; > So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):; > ; > > RP11-34P13.7	RP11-34P13.7	Gene Expression; > > FO538757.3	FO538757.3	Gene Expression; > > FO538757.2	FO538757.2	Gene Expression; > > AP006222.2	AP006222.2	Gene Expression; > > RP4-669L17.10	RP4-669L17.10	Gene Expression; > ; > It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail. when you do add those columns it makes the number of genes to 0 while reading it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355,4,['error'],['error']
Availability,"> IIRC, it's discussed in more detail in Malte's paper:; > ; > > ; > ; > In the same way that cellular count data can be normalized to make them comparable between cells, gene counts can be scaled to improve comparisons between genes. Gene normalization constitutes scaling gene counts to have zero mean and unit variance (z scores). This scaling has the effect that all genes are weighted equally for downstream analysis. There is currently no consensus on whether or not to perform normalization over genes. While the popular Seurat tutorials (Butler et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0020)) generally apply gene scaling, the authors of the Slingshot method opt against scaling over genes in their tutorial (Street et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0125)). The preference between the two choices revolves around whether all genes should be weighted equally for downstream analysis, or whether the magnitude of expression of a gene is an informative proxy for the importance of the gene. In order to retain as much biological information as possible from the data, we opt to refrain from scaling over genes in this tutorial.; > ; > https://www.embopress.org/doi/full/10.15252/msb.20188746; > ; > Since there has been no new development on this topic, we cited Malte and also opted not to scale. This is also discussed by Malte himself in the issue that was cited above.; > ; > I cannot comment on spatial data itself and make confident statements here. Thanks a lot; so is there a conclusion or recommendation whether scale or not on spatial data? @ivirshup @Zethson",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034435734:402,down,downstream,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034435734,2,['down'],['downstream']
Availability,"> If I understand the .raw removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with .layers?. Pretty much every function where you would want to use `highly_variable`. > It seems to me that adding masking like this would be quite a large endeavour, no?. I think a similarly sized endeavor to adding `highly_variable`, except we can use the `highly_variable` code where it's been implemented. I would expect this to be less effort than supporting `raw`, which is a constant maintenance burden, especially for `anndata`. I think this logic could be added to the `_get_obs_rep`, and `_set_obs_rep` functions. --------------. > If you assume anything filtered out was removed because it was predominantly 0. I'm not sure I like having this assumption. Especially when a collaborator asks ""what about gene X"", but it just wasn't in the table I received. Maybe it's an annotation issue, maybe it wasn't expressed, or maybe it wasn't expressed globally at a high enough level – but could have been expressed in the cells of interest. > you can assume it would not be in the HVG intersection for that dataset and if you add it,. Is intersection the way to go? If you have cell types which are only present in some datasets, wouldn't you want to take the union?. > Typically there is sufficient gene-gene covariance that you still keep this signal somehow. I would agree that it is unlikely that this would have a huge effect on analyses like PCA or UMAP. When it comes time to do differential expression or show expression on an embedding, then it starts to be an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305:85,mask,masks,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305,3,"['mainten', 'mask']","['maintenance', 'masking', 'masks']"
Availability,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python; import vega_datasets; import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(; iris[""sepalLength""],; iris[""sepalWidth""],; c=iris[""petalLength""],; norm=norm,; vmin=3,; ); plt.colorbar(); ```. ```; MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; simultaneously is deprecated since 3.3 and will become an error two minor releases ; later. Please pass vmin/vmax directly to the norm when creating it.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569,3,['error'],['error']
Availability,"> If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however.; > ; > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284:252,error,error,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284,1,['error'],['error']
Availability,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:1216,mainten,maintenance,1216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404,2,['mainten'],['maintenance']
Availability,"> If we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now. This is quite a compelling argument for me (as I was one of the people who reported an issue like this). If an integer matrix is generally returned, then one would have to ensure all other functions will work with this data type as intended (sc.pp.log1p for example). Otherwise this would be backward-breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583:56,down,downstream,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583,1,['down'],['downstream']
Availability,"> If you change `X_coords` to `coords`, where do errors occur? Could you also point me to where you're seeing this code? I've definitely been using embeddings in `obsm` whose keys don't start with `""X_""`. Right, my bad, switched to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-601303079:49,error,errors,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-601303079,1,['error'],['errors']
Availability,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219,1,['error'],['error']
Availability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217,4,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214,5,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"> In general, are we agreed on these points? ; > tsne should allow weights to be passed through (whether perplexity based, or not) ; > There should be a warning to notify the user if the weights were computed in a non-standard way ; > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1.; * Argument for `normalize` (Isaac): closer to originally calculated weights;; * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`.; * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`; * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;; * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773303341:441,error,erroring,441,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773303341,2,['error'],['erroring']
Availability,"> In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result. As @LuckyMD said, this is a question for `scvelo`. . > I guess what i make the cell order was wrong ? . The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done. > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?. Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805:723,robust,robust,723,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805,1,['robust'],['robust']
Availability,"> It seems you do not always end up with n-1 neighbors, because for n=3, you suddenly get differing number of neighbors:. I think the varying number of neighbors is because the connectivity graph is made symmetric. ```python; import scanpy as sc, numpy as np; pbmc = sc.datasets.pbmc68k_reduced(); sc.pp.neighbors(pbmc). np.unique((pbmc.obsp[""distances""] != 0).sum(axis=1).flat); # array([14]); ```. Yeah, n_neighbors=1 should definitely throw an error (I think it does for UMAP). We do document that reasonable values start at 2, but it could also be good to have more reasoning on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1706#issuecomment-789305891:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706#issuecomment-789305891,1,['error'],['error']
Availability,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447,1,['error'],['error']
Availability,"> Just to clarify, Jan started this PR because we were explicitly asked by some of the Scanpy core developers to prepare it for the core library. . I see, my comments weren't really directed at anyone in particular -- I know we are all trying to do good work and it's great that you all have thought a lot about this particular normalization -> dim. red. problem. > We view it basically as ""scTransform done right"". And scTransform is already published and is being used. Sure, but my point is that the analytic Pearson residuals method hasn't been peer-reviewed, and while the results in your preprint appear promising there are still questions that remain; e.g., how does it compare to deviance residuals? What is the effect on datasets that do not have so many cell types, i.e, ""continuous"" datasets? What happens when looking at metrics that aren't qualitative evaluation of t-SNE embeddings?. > One option would be to hold this PR until our paper is formally accepted... That makes sense to me, or just put it in external for now, or write generic methods for ""residuals"" that includes analytic, deviance, etc, with deviance as default (and as flavors?)? I'm not sure what is appropriate here, and some guidelines from the core scanpy team would be appreciated. For example, most people I know use the `""seurat_v3""` flavor of HVG selection, but it's not the default. It makes sense to me to change defaults as more information becomes available about performance/popularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817:1440,avail,available,1440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817,2,['avail'],['available']
Availability,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering.; Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), ; but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering.; In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be ; missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) ; and mismatching color codes might also not be apparent initially. ; For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially.; This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522:223,error,error,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522,3,['error'],['error']
Availability,"> Maybe a solution would be to set `highly_variable` equal to `highly_variable_intersection` when using the `batch_key`. I think `highly_variable` is a remnant of using `highly_variable_genes_single_batch()` (or whatever the function is called) to get the individual per-batch HVGs for intersection calculation. @gokceneraslan will be able to correct me here though. Encountered this exact issue today. In my example, `highly_variable_intersection` only contains 17 genes across 30 datasets, which I imagine might silently give unexpected results downstream. In addition to that option, another option might be to allow the user to define a minimum number of `highly_variable_nbatches` so `highly_variable` is derived from `highly_variable_nbatches > NUMBER`. This is an approach used here FWIW: https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616240702:547,down,downstream,547,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616240702,1,['down'],['downstream']
Availability,"> No worries. I meant here: https://github.com/scverse/scanpy/blob/master/scanpy/tools/_leiden.py. Sorry I still don't really know what to do. After the RandomState object is passed to leiden, it passes it to igraph, which raises an error because igraph wants an int to initialize [it's own rng system](https://igraph.org/c/doc/igraph-Random.html). It seems to me like there's no easy way to fix this, no?. Maybe I should just give it an int instead? I'd just like my clustering to be reproducible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219:233,error,error,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219,1,['error'],['error']
Availability,"> Not sure whether it is resolved, just put here another solution to read_mtx and add to anndata one by one; > ; > ```; > import pandas as pd; > import scanpy as sc; > ```; > ; > ```; > adata = sc.read_mtx('./matrix.mtx'); > adata_bc=pd.read_csv('./barcodes.tsv',header=None); > adata_features=pd.read_csv('./features.tsv',header=None); > adata= adata.T; > adata.obs['cell_id']= adata_bc; > adata.var['gene_name']= adata_features[0].tolist(); > adata.var.index= adata.var['gene_name']; > ```. set the delimiter for the features to tab, then use the second column which contains the gene names and not the gene ensembl id. Using the gene names is better for downstream qc since the scanpy recommended pipeline uses the gene name prefixes to identify mitochondrial genes. ```; adata_features = pd.read_csv('./barcodes.tsv', header = None, delimiter = '\t'); ... # technically don't need to use .values or tolist() since the mtx and features file should ; # have same number of rows resulting in same index in the adata.var and adata_features dataframes. adata.var['gene_name'] = adata_features[1].values; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568:657,down,downstream,657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568,1,['down'],['downstream']
Availability,> Numba can’t correctly detect when a threading backend is available. Is there a numba issue for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874655687:59,avail,available,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874655687,1,['avail'],['available']
Availability,"> Removed 3.6. We should keep 3.6 as long as we support it. It's easy to accidentally add features which only work with 3.7+ otherwise. I'd be happy to drop 3.6 once numpy does (and in general roughly follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) as soon as the ecosystem does). > is there any reason why we are currently not additionally using Github Actions?. Depends on the task. Also depends on the definition of github actions I think? We aren't using any of their runners for testing because we'd like the ability to integrate with hosted resources on azure. Also, azure seemed like much more of a standard for numeric python packages at the time we chose it. I'd be happy to have github actions for other things, like `precommit`. `twine check` could be another one, but I haven't looked in to how ""artifact"" type things are handled with github actions to know if we'd be able to recover the built objects. We'd talked about using codecov too, which I'd like to add a check for. I'm not totally clear on the distinction between checks and actions yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019:914,recover,recover,914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019,2,['recover'],['recover']
Availability,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on?; > ; > If not, what do you think about making this a separate function? Maybe `combat_by_reference`?. Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. ; I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1501#issuecomment-730248703:203,mask,mask,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501#issuecomment-730248703,4,['mask'],['mask']
Availability,"> So I guess the real culprit is the float32 issue with AnnData. Is this something you all plan to address soon?. I think we can do that. I did a quick check and it's pretty benign in anndata. It causes test failures a few places in scanpy, but I think that's solvable with some conversion. It is a breaking change, so it will need to be in anndata 0.8. But there's a few more minor changes I'd like to make, so maybe we can be quick on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713:208,failure,failures,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713,1,['failure'],['failures']
Availability,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:588,error,error,588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028,1,['error'],['error']
Availability,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:325,down,download,325,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,4,['down'],['download']
Availability,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted?. ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118:7,failure,failures,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118,2,['failure'],['failures']
Availability,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess?. I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows?. > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759335128:1406,down,downstream,1406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759335128,2,['down'],['downstream']
Availability,> That doesn't seem to be a Scanpy or AnnData issue but an issue with a corrupted HDF5 file as such. Thanks! I struggled with this error for a long time yet it turns out the file is corrupted.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/626#issuecomment-488057644:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/626#issuecomment-488057644,1,['error'],['error']
Availability,"> That's fair. Might be worth asking the `conos` developers in this case?. Yes, could and should do this... but would slow down the process for now I guess. > Also, does using `install.packages` within a conda environment work for you? I recall that not working well for me in the past. It works if you install the R packages last and don't install anything else over the top via conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808:123,down,down,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808,1,['down'],['down']
Availability,"> The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows. I have now done a speed comparison with adata object of 1.85 million cells. igraph on adata as implemented [above](https://github.com/theislab/scanpy/issues/1053#issuecomment-1039424473) ran in **33 minutes** vs `sc.tl.leiden()` which took **~14 hours**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011:579,avail,available,579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011,2,['avail'],['available']
Availability,"> The just added changes should mimic the response from 1.6 except for duplicate names in var_names which I think should respond similarly like when doing a slicing on the AnnData object. Thinking about this more. Considering that no one has complained about this so far. I think I'm actually fine with this being an error. If there are complaints, I think we should change it back. I do think it's important that `gene_symbols` can have duplicates as long as those values aren't being accessed (as non-unique identifiers is the whole point of `gene_symbols`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710:317,error,error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710,1,['error'],['error']
Availability,"> The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences. Ah yes, I see. The stripplot result could be fixed by setting a seed with `np.random.seed`. I doubt it will fix the difference due to the used version, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488:19,toler,tolerance,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488,1,['toler'],['tolerance']
Availability,> The tolerances need to be tight enough that the tests do anything though …; > ; > I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted. This is exactly what I'm seeing in my PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829:6,toler,tolerances,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829,2,['toler'],['tolerances']
Availability,"> There are weird failure modes though, like using `key='groups'` or `key='connectivities'` might override some parts of an existing, old-style paga result. We can forbid keys like these. this is exactly what i was worried about. 'groups' is probably not such a rare case as a key. But good to take care of that. I guess in the old & new case, you just have a bit of a messy `adata.uns['paga']` dictionary, but it will still work (in most cases).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/957#issuecomment-567585303:18,failure,failure,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/957#issuecomment-567585303,1,['failure'],['failure']
Availability,"> This agrees with what I suspected: that randomized PCA itself should be pretty stable, . No, if you look into how higher PCs vary, you see that they vary drastically depending on the seed or computational platform. That also makes sense, it's a power-method that does the computation, that runs into some unstable stuff. > PCs were similar to within a couple of decimal points,. I'm very sure that you only observed this for the first couple of PCs, which you robustly estimate. Going higher, you end up in some local minima for a subsapce; I believe that it doesn't mean it doesn't capture important variation; it just means that it's a local minimum that the algorithm converges into... something we observe all the time when training models... in the context of Lanzcos and other algorithms powering SVD, PCA etc., it's usually a nuisance that you have that instability when you go higher in iterations; but also there, people just use the results even if they know they don't get the *exact* 50th eigen vector...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436041937:462,robust,robustly,462,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436041937,1,['robust'],['robustly']
Availability,"> This is actually something I've been meaning to bug you about @WeilerP, why does scvelo pin umap below 0.5?. This was only a dirty hack to make our unit tests pass (see e.g. [here](https://github.com/WeilerP/scvelo/runs/2112241472?check_suite_focus=true)). It's no longer pinned on `scvelo@develop` which we plan on merging into master in the following days to tag a new version. > We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that. I believe the problem is using `umap-learn<=0.5.0` with new `numba` versions (I think `numba>=0.53.0`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729:533,down,downstream,533,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729,2,['down'],['downstream']
Availability,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678,2,"['error', 'mask']","['error', 'masking']"
Availability,"> This is not the case study code. I think this comes from the PAGA tutorial. So I can't really say whether this is normal. I typically don't have PAGA errors or warnings.; > ; > Most of the errors seem to be deprecation warnings, so that should be fine... but the ""finite values"" on posx and posy error I haven't come across. It looks like this is on Windows. Is there a matplotlib issue with windows?. matplotlib is working well with my windows and I tried to run ; pyplot.scatter([0,1], [0,1]) it works correctly. . Maybe, this issue is caused by the difference of versions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-535106890:152,error,errors,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-535106890,3,['error'],"['error', 'errors']"
Availability,"> This is strange, i also tried to run the tests multiple times at the time of committing this and they failed every time. Maybe a dependency had a bugged release at the time?. > I am not sure what king of test. I don't want to add another save_and_compare_images test because plots seem to depend on the system at least sometimes. You could instead use `check_same_image`. Check that running `filter_rank_genes_group` then plotting is equivalent to manually passing those genes to `sc.pl.rank_genes_groups_*` plot on an object that hasn't had `filter_rank_genes_group` run on it. You can search the tests for examples of `check_same_image`. > (i have 3 failing plotting tests locally but they run fine here). Could you open an issue for this and note which tests they are? It would be good to make the tests as resilient as possible on other people's systems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649:812,resilien,resilient,812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649,1,['resilien'],['resilient']
Availability,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:829,redundant,redundant,829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417,4,['redundant'],['redundant']
Availability,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here?. Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks; -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good!. > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes.; > ...; > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway?. > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here?. No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is un",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443:152,down,downloaded,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443,1,['down'],['downloaded']
Availability,"> Though if check_values is False, it shouldn't even run the check, correct?. Yes. > So the warning would be more like,; >; > ""'seurat_v3' flavor expects raw count data. Proceed with caution."". I was thinking the warning would only occur if `check_values=True` and non integer values were found. ""partial counts"" are common enough I'd agree it's not reasonable for this to error if the results are still meaningful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-777942673:373,error,error,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-777942673,1,['error'],['error']
Availability,"> Though maybe something simpler is to be able to access a global table of functions and citations, and it gives you the bibtex. @adamgayoso From my point of view, references are already available ([source](https://github.com/theislab/scanpy/blob/master/docs/references.rst), [rendered](https://scanpy.readthedocs.io/en/latest/references.html)) and linked to in the documentation. I'm not against the idea, I'm just not seeing how it makes this information more accessible/ prominent. A separate issue for the topic would be good for more discussion. ---------------------. > Would really welcome that. I can help where I can, although not so familiar with numba. @LuckyMD, meant to say, `numba` is super easy, it's really just python. Next best thing to Julia. Definitely worth some time to learn, but also it won't take that much time to learn.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026:187,avail,available,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026,2,['avail'],['available']
Availability,> Throw an error if something other than an AnnData is passed in. I am in favor of this (so it seems like @Intron7 and I agree on this). And then using some sort of `key` arguments to specify where to fetch the aggregatable data from. > Maybe in future this could get a return_type: type[AnnData] | type[Dict] | type[xr.Dataset] = AnnData argument that controls what is returned?. I would also be in favor of this if we want to leave the option of getting a `dict` back.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2930#issuecomment-2007335971:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2930#issuecomment-2007335971,1,['error'],['error']
Availability,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066797546:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066797546,2,['error'],['error']
Availability,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043,2,['error'],['error']
Availability,"> While the single command works `adata = adata[adata[: , 'A'].X > 1, :]`; > ; > The compound command gives me the following error: TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'. Have you solved it? I have a similar problem. . My code:; adata = adata[(adata[: , 'A'].X > 0) & (adata[:, 'B'].X > 0), :]; # TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'. However, ; adata = adata[(adata[: , 'A'].X > 0), :]; It works greatly.; Hope to get help, thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1870#issuecomment-1192133374:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870#issuecomment-1192133374,1,['error'],['error']
Availability,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml?. See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request.; > ; > ```; > pr:; > branches:; > include:; > - '*' # must quote since ""*"" is a YAML reserved character; we want a string; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275:98,down,down,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275,1,['down'],['down']
Availability,"> Yeah, I can't reproduce it with a canned dataset either --- I'm doing something a bit weird and transforming imaging mass cytometry data into AnnData objects (hence the imctools dependency). I have an object that looks like:. thank you for reporting, this is very interesting use case! and thanks for the detailed evaluation. I would also try with different number of PCs to see whether that has an impact. if you open an issue on `pynndescent`, would you mind referencing this issue or pinging me there, would be interested to see what's the proposed solution/bug. @TiongSun let us know about your use case, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797652809:489,ping,pinging,489,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797652809,1,['ping'],['pinging']
Availability,"> ```; > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; > simultaneously is deprecated since 3.3 and will become an error two minor releases ; > later. Please pass vmin/vmax directly to the norm when creating it.; > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208,1,['error'],['error']
Availability,"> ```python; > scipy.io.mmwrite; > ```. This code doesn't actually work - rows and columns are switched in the matrix, and it produces an error when you try to read in the output using either `Scanpy` or `Seurat` wrapper functions. Perhaps it's a package version thing though..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-1476035869:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-1476035869,1,['error'],['error']
Availability,"> `batch1.X.mean(1)` should give you the desired result.; > Or maybe i don't get what you actually need. Thanks for the reply. Sometimes I got index error when I used the subset data view for further analysis, saying the dimension was not matched. ; It could be solved by assigning .copy() when subsetting the adata. So I was just wondering if any memory-efficient way to do this also?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1940#issuecomment-877836520:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940#issuecomment-877836520,1,['error'],['error']
Availability,"> `paul15` is downloaded automatically, very practical. Yeah, it’s really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580:14,down,downloaded,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580,1,['down'],['downloaded']
Availability,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213,1,['error'],['error']
Availability,"> and I'm fairly certain this has to do with the call to NNDescent in umap.umap_.py as if I import that directly, it raises the same errors. sorry just read this, this sounds it could be potentially data specific, have you tried playing around with other nndescent params?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797640822:133,error,errors,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797640822,1,['error'],['errors']
Availability,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/808#issuecomment-527131466:134,error,error,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808#issuecomment-527131466,1,['error'],['error']
Availability,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-726019005:68,error,error,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-726019005,2,['error'],['error']
Availability,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:262,ping,ping,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531,2,['ping'],['ping']
Availability,"> how about making green just a bit brighter/less bright to make it discernible from red for color-blind people? should not break much. I guess that would be best done by switching the green with another green somewhere down the list to not mess with the color map entirely. Not sure this is a general purpose fix for all types of colorblindness though, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/387#issuecomment-444463868:220,down,down,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387#issuecomment-444463868,1,['down'],['down']
Availability,"> it is trying to use linux formatting on a Windows machine. that’s not the issue, forward slashes and relative paths work perfectly on windows. The issue is that this code uses string manipulation to work with paths, which is error-prone. https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/readwrite.py#L440-L441. @falexwolf using `pathlib` for path manipulation as much as possible protects us from mistakes like this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532:227,error,error-prone,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532,1,['error'],['error-prone']
Availability,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:; https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283:881,mainten,maintenance,881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283,1,['mainten'],['maintenance']
Availability,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review?. Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”?. Also: can we reenable squash/rebase merges soon?. > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179:383,failure,failures,383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179,2,['failure'],"['failure', 'failures']"
Availability,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata.; 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized.; 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013:1025,down,down,1025,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013,2,['down'],['down']
Availability,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138:460,down,downloadable,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138,1,['down'],['downloadable']
Availability,"> tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough 😄 ).; another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245:179,error,errors,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245,2,"['error', 'robust']","['errors', 'robust']"
Availability,"> thank you @jlause for the PR! This is really exciting and super useful!; > This is a first round of review, most comments are re types, args and function behviour. I think it looks really good overall and maybe it's time to start writing tests ?; > please let me know if anything unclear and also thanks in advance for code explanations!. Hey @giovp ,; thanks a lot for the review, this looks very helpful! I'll address the single points above one-by-one and make the required changes over the next few days! Will also add some first tests - are there formal guidelines what you expect to be tested? After looking at the tests for `highly_variable_genes`, from my naive perspective I'd test the following:. - tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; - tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). Any advice/ideas what else should be tested?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681:890,error,errors,890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681,2,['error'],['errors']
Availability,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries!. I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-742217703:686,mask,mask,686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-742217703,2,['mask'],['mask']
Availability,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:214,Error,Error,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808,1,['Error'],['Error']
Availability,"> then I'd say NearMiss and related are straightforward and scalable (just need to compute a kmeans whcih is really fast). For sampling from datasets, I would want to go with either extremely straightforward or something that has been shown to work. Maybe we could start with use provided labels to downsample by?. > reshuflling is performed. Reshuffling meaning that the order is changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364:299,down,downsample,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364,1,['down'],['downsample']
Availability,"> with some name like key=image_name and value=path ? or something like that. sure! What do you mean with image_name? As downloaded from the 10x website, the tiff image always has the same filename (""image.tif""). Or do you mean the string ""image_name"" as key?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733618049:121,down,downloaded,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733618049,1,['down'],['downloaded']
Availability,">; ----> 1 sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds'). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, standard_scale, smallest_dot, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1809 num_categories,; 1810 layer=layer,; -> 1811 gene_symbols=gene_symbols,; 1812 ); 1813 . ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 2911 matrix = adata[:, var_names].layers[layer]; 2912 elif use_raw:; -> 2913 matrix = adata.raw[:, var_names].X; 2914 else:; 2915 matrix = adata[:, var_names].X. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in __getitem__(self, index); 94 ; 95 def __getitem__(self, index):; ---> 96 oidx, vidx = self._normalize_indices(index); 97 ; 98 # To preserve two dimensional shape. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 154 obs, var = unpack_index(packed_index); 155 obs = _normalize_index(obs, self._adata.obs_names); --> 156 var = _normalize_index(var, self.var_names); 157 return obs, var; 158 . ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 91 not_found = indexer[positions < 0]; 92 raise KeyError(; ---> 93 f""Values {list(not_found)}, from {list(indexer)}, ""; 94 ""are not valid obs/ var names or indices.""; 95 ). KeyError: ""Values ['Rgs20', 'Oprk1', 'St18', 'Gm26901'], from ['Rgs20', 'Oprk1', 'St18', 'Gm26901'], are not valid obs/ var names or indices."". sc.pl.matrixplot(adata_2, adata_2.var_names[0:4], groupby='celltype') #same error; sc.pl.tsne(adata_2, color=adata_2.var_names[0:4]) #KeyError: 'Rgs20' . ```. Any help would be much appreciated!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652:2757,error,error,2757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652,1,['error'],['error']
Availability,">Only strange thing is the getdoc function. It looks like instance methods can't have new attributes assigned (probably have slots). It's possible the `.getdoc` attribute could be added to the classes method (not sure if that's the right way to say that, here's an example):. ```python; class Foo(object):; def bar(self):; return 1. # Setting an attribute on the method of an instance raises an error; Foo().bar.x = 1; # AttributeError: 'method' object has no attribute 'x'. # Setting an attribute on the method of a class seems fine:; Foo.bar.x = 1 ; Foo().bar.x; # 1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479758866:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479758866,1,['error'],['error']
Availability,"@Chenyanjuan1993 thank you for reporting this. I think it's some typing problem with the var_names index, and so possibly regarding your anndata. Can you share the list of commands that you run before that error? Like do you concat/merge? Also, could you run that with this anndata `adata = scanpy.datasets.pbmc3k()`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-708958791:206,error,error,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-708958791,1,['error'],['error']
Availability,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![下載 (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png); ![下載 (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png); ![下載 (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619409104:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619409104,1,['error'],['error']
Availability,"@HypoChloremic,; I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-46-42a11a5bd10f> in <module>; 19 show=True,; 20 use_raw=False); ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)); 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""); 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal); 3226 decimal=decimal,; 3227 ); -> 3228 formatter.save(); 3229 ; 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self); 181 self.mode,; 182 encoding=self.encoding,; --> 183 compression=self.compression,; 184 ); 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text); 397 if encoding:; 398 # Encoding; --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""); 400 elif is_text:; 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [下載](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619083501:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619083501,1,['error'],['error']
Availability,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-723092789:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-723092789,2,"['down', 'error']","['down', 'error']"
Availability,"@Koncopd Currently breaking test for me:. ```pytb; $ pytest -k test_ingest; ===================================================== test session starts =====================================================; platform darwin -- Python 3.7.6, pytest-5.3.5, py-1.8.0, pluggy-0.12.0; rootdir: /Users/isaac/github/scanpy, inifile: pytest.ini, testpaths: scanpy/tests/; plugins: pylama-7.7.1, parallel-0.0.10, cov-2.7.1, black-0.3.7, hypothesis-5.6.0; collected 393 items / 389 deselected / 4 skipped . scanpy/tests/test_ingest.py ...F [100%]. ========================================================== FAILURES ===========================================================; _______________________________________________ test_ingest_map_embedding_umap ________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; ing = sc.tl.Ingest(adata_ref); ing.fit(adata_new); ing.map_embedding(method='umap'); ; reducer = UMAP(min_dist=0.5, random_state=0, n_neighbors=4); reducer.fit(X); umap_transformed_t = reducer.transform(T); ; > assert np.allclose(ing._obsm['X_umap'], umap_transformed_t); E assert False; E + where False = <function allclose at 0x119616b00>(array([[16.566338, 20.174282],\n [15.368203, 20.291983]], dtype=float32), array([[16.502459, 20.157679],\n [15.581459, 20.302881]], dtype=float32)); E + where <function allclose at 0x119616b00> = np.allclose. scanpy/tests/test_ingest.py:140: AssertionError; ---------------------------------------------------- Captured stderr call -----------------------------------------------------; computing neighbors; finished: added to `.uns['neighbors']`; 'distances', distances for each pair of neighbors; 'connectivities', weighted adjacency matrix (0:00:00); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:00); ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073:594,FAILURE,FAILURES,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073,1,['FAILURE'],['FAILURES']
Availability,"@Koncopd here's an example of the current implementation breaking down at `n=3`. ```python; def walk_nsteps_current(adj, n=1):; adj = adj.copy(); if n > 1:; # get up to n_rings order connections; adj += adj ** n; adj.setdiag(0); adj.eliminate_zeros(); adj.data[:] = 1.0; return adj. fig, axes = plt.subplots(nrows=3); # Fixed circle layout; pos = {i: (np.cos(-np.pi + (np.pi * i) / 4), np.sin(-np.pi + (np.pi * i) / 4)) for i in range(5)}. for n, ax in enumerate(axes):; nx.draw(; nx.Graph(walk_nsteps_current(adj, n + 1)), # making sure we start at 1; pos=pos,; ax=ax,; ); ; plt.show(); ```. ![image](https://user-images.githubusercontent.com/8238804/94672185-3cfab200-0358-11eb-84d6-11abe07f7f1c.png). For `n=3` you're missing the neighbors at depth=2. Basically, you're just jumping to the 3rd step, instead of accumulating neighbors up to that step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701296035:66,down,down,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701296035,1,['down'],['down']
Availability,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036:70,error,errors,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036,2,"['avail', 'error']","['available', 'errors']"
Availability,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-664837370:181,down,download,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-664837370,1,['down'],['download']
Availability,@LouisFaure Great!; While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. ; The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-816784411:197,down,down,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-816784411,2,"['down', 'ping']","['down', 'ping']"
Availability,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph; ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:258,down,downstream,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649,1,['down'],['downstream']
Availability,"@LuckyMD Dear Malte, Thanks a lot for your hint and reply.; Regarding to the subset, well I got actually the cells that I needed with same number of the genes that I had before so I assume it is fine.; I did a rescale of my data to 10 again but unfortunately the same warning is happening! ; I don't know really if turning all negative values to zero would really make sense because first of all as I mentioned I had negative values before and it was not a problem and if I turn all those negative values to zero I guess I will lose quite a bit of genes during my downstream analysis. What I can imagine is those problematic values are anyway not considered during the marker analysis so in the case they are NaN turning them to zero wouldn't affect my result. my fear was mainly that those genes may be really something and due to a bug or a miscommand I am not getting them but I think it is a rare probability. I guess I should leave it as it is. I will though try to take the sc.tl.rank_genes_groups function code and run it step by step",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494351528:564,down,downstream,564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494351528,1,['down'],['downstream']
Availability,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698884956:113,mainten,maintenance,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698884956,1,['mainten'],['maintenance']
Availability,"@LuckyMD Thanks! Yes, the algorithm has been in development for quite some time. I presented it already in 2016 at a conference in Amsterdam, and after that in several other places. It kept changing in relatively minor ways, although that also affected the exact guarantees it could offer. Unfortunate that the section on disconnected communities got trimmed down! Would you have more extensive results described somewhere else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-439188030:359,down,down,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-439188030,1,['down'],['down']
Availability,"@LuckyMD Thanks. This agrees with what I suspected: that randomized PCA itself should be pretty stable, but downstream clustering procedures can be very unstable. I have little experience with clustering so I cannot really comment further, but this certainly should be a big red flag for taking a clustering result seriously. It's especially impressive that float32 vs float64 can cause such a difference. Did you observe this influencing t-SNE/UMAP/etc equally drastically, or did it only affect clustering so strongly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436013237:108,down,downstream,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436013237,1,['down'],['downstream']
Availability,"@LuckyMD is this the correct way of using pd.crosstab() ? I am getting an error as seen below:. adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-95-d09a5110597d> in <module>(); ----> 1 adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). AttributeError: 'AnnData' object has no attribute 'crosstab'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/584#issuecomment-482815578:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/584#issuecomment-482815578,1,['error'],['error']
Availability,@LuckyMD yea after some further investigation I do agree with you! do you already know a method which can I use to scale my data to non-negative values? then I can scale my data only once and right after imputation and that should be fine for the rest of downstream analysis including the sub-clustering,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494571722:255,down,downstream,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494571722,1,['down'],['downstream']
Availability,@MichaelPeibo Could you install the version 1.4.5.post1? It is not available in conda and with 1.4.4.post1 I'm getting the same error. Thanks!. ```; conda search -c bioconda scanpy; Loading channels: done; # Name Version Build Channel ; scanpy 1.3.1 py36_0 bioconda ; scanpy 1.3.2 py36_0 bioconda ; scanpy 1.3.3 py36_0 bioconda ; scanpy 1.3.4 py36_0 bioconda ; scanpy 1.3.5 py36_0 bioconda ; scanpy 1.3.6 py36_0 bioconda ; scanpy 1.3.7 py36_0 bioconda ; scanpy 1.4 py_0 bioconda ; scanpy 1.4.1 py_0 bioconda ; scanpy 1.4.2 py_0 bioconda ; scanpy 1.4.3 py_0 bioconda ; scanpy 1.4.4 py_0 bioconda ; scanpy 1.4.4 py_1 bioconda ; scanpy 1.4.4.post1 py_0 bioconda ; scanpy 1.4.4.post1 py_1 bioconda ; scanpy 1.4.4.post1 py_2 bioconda ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828:67,avail,available,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828,2,"['avail', 'error']","['available', 'error']"
Availability,"@OnlyBelter I'm not getting an error from that, but I am getting a bunch of warnings, which makes it seem like something weird is going on. I'm going to split this into a new issue while we investigate, since it seems a bit different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-863733680:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-863733680,1,['error'],['error']
Availability,"@PGmajev, I would recommend setting up pre-commit for the repo (as described in the contributing guide [here](https://scanpy.readthedocs.io/en/latest/dev/getting-set-up.html#pre-commit)). It should save you from dealing with these formatting errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745:242,error,errors,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745,2,['error'],['errors']
Availability,"@RubenVanEsch Can you provide a more minimally reproducible example?. For example, paring down a bit the above to just:. ```python; import scanpy as sc. em_adata = sc.datasets.pbmc3k(). sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```; does not yield any error. ~~Could you share your system info i.e., widows or mac?~~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034402907:90,down,down,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034402907,2,"['down', 'error']","['down', 'error']"
Availability,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457:149,error,errors,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457,1,['error'],['errors']
Availability,"@WeilerP would you be willing to write a tiny test and to add the release note, please?. Thanks! Happy to merge this then if you ping me. @ivirshup generally, I agree. Think that this tiny change doesn't harm though and deprecating the magic ""read"" is something bigger.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007:129,ping,ping,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007,1,['ping'],['ping']
Availability,"@Zethson I believe that's an upstream issue. Looks like the docs broke when `sphinx-autodoc-typehints` bumped versions from `1.12.0` to `1.13.0`. I can build the docs locally from `master` and from this branch with `sphinx-autodoc-typehints` v1.12, but not v1.13. (You'll also see an identical error in #2099, despite that just being a dependency bump for pre-commit.). I'll submit a PR to pin `sphinx-autodoc-typehints` to version 1.12.0 shortly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005072811:294,error,error,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005072811,1,['error'],['error']
Availability,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. ; In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** ; Before combat execution, in concatenate process of batch data, I specified index_unique='-' . ; e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case.; I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170#issuecomment-628401842:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170#issuecomment-628401842,2,['error'],['error']
Availability,"@aditisk that depends on what you put in `adata.raw` ;). Initially `adata.raw` was used to store the full gene object when `adata.X` was filtered to only include HVGs or remove genes that aren't expressed in enough cells. Now, we just have a boolean mask in `adata.var['highly_variable']` for HVGs and so it's often not used anymore. I typically store my log-normalized expression data there if I do batch correction or regress anything out, as `adata.raw` is used as default to compute `rank_genes_groups` and to show expression values on an embedding plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284:250,mask,mask,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284,1,['mask'],['mask']
Availability,"@akshayka thanks for contributing to the conversation! The package does indeed look interesting. A couple questions about the tool:. Can we get a weighted graph out of the fit embedding object? For context, we use the UMAP weighted connectivity graph for a number of downstream tasks. This seems related to distortions, but maybe not quite what they are. I'm also wondering about just how early the package is. I would like to be able to take advantage of any new features, and wouldn't want an early API decision to lock us out of those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027:267,down,downstream,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027,1,['down'],['downstream']
Availability,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-848420774:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-848420774,1,['error'],['error']
Availability,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394,1,['error'],['error']
Availability,@brianpenghe What column did you add to the genes.tsv so that it worked? I currently have a genes.tsv file with one column for the gene names and am getting the same error as you did. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-1180871625:166,error,error,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-1180871625,1,['error'],['error']
Availability,"@chris-rands, that section of the Seurat tutorial also ends in these points:. > * We encourage users to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically.; > * We advise users to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results. > Can anyone explain/show literature on if/why the scanpy default of 50 PCs works well?. I think there is enough to show that PCA works well. I'm not sure if I can show you a paper that says either choosing a high cutoff, or using jackstraw/ elbow plots gives better downstream results. I'd note that the [cited paper](https://www.cell.com/fulltext/S0092-8674(15)00549-8) for the Seurat tutorial doesn't seem to evaluate this. ---------------. @wolf5996, I'm not sure I agree with your point that lower PCs are more likely to contain non biological variability. I don't think that a component which explains more variability in the dataset would necessarily represent biological variability. As an example, if we have a dataset with two evenly sized batches, and a rare cell type which makes up ~1% of the population, wouldn't a PC representing the batch explain much more variability than a PC corresponding to the rare cell type?. Anecdotally, I can say batch effects can show up in high principal components.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-822286073:111,down,downstream,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-822286073,3,['down'],['downstream']
Availability,"@dawe Could you also please provide a brief tutorial on how to install `scanpy` on M1? I am having troubles. I have followed [this tutorial ](https://medium.com/geekculture/the-best-way-to-setup-your-m1-mac-for-python-development-fb5dffd08fd) to set up python on my M1 Mac. Thus I have installed `miniforge` with `brew`. My versions are `Python 3.9.6` and `pip 21.2.4`. Also I have read that you succeed in install `scanpy` with `python 3.8` but I am not able to downgrade version. The error I face when I run `pip3 install scanpy` is:. ```; ERROR: Command errored out with exit status 1: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""'; __file__='""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-record-lf5rwuj7/install-record.txt --single-version-externally-managed --compile --install-headers /opt/homebrew/Caskroom/miniforge/base/include/python3.9/h5py Check the logs for full command output.```. Thank you in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004:463,down,downgrade,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004,4,"['ERROR', 'down', 'error']","['ERROR', 'downgrade', 'error', 'errored']"
Availability,@falexwolf Do you think that these errors come from the code that I modified? I think I didn't touch the function that @bebatut is using.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-432212556:35,error,errors,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-432212556,1,['error'],['errors']
Availability,"@falexwolf I like the idea of downloading the data on the fly!. For an idea of a small dataset that is already filtered and normalized, do you know if the pbmc data from 10x Genomics has some restrictions? ... nevermind, they have a Creative Commons licence.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405579971:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405579971,1,['down'],['downloading']
Availability,@falexwolf Is there anyplace where we can read into `diffxpy`? I've been benchmarking available marker gene detection algorithms and am interested to see what is included in this new package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783:86,avail,available,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783,1,['avail'],['available']
Availability,"@falexwolf Thanks for the support. . I agree that this is not an urgent changes that can quietly be tested. Have you consider having a 'develop' branch were we can put all code like this? . As you point out some differences are seen with respect to the shape of the plot when multiple panels are plot. This is mostly due to some code to add space for the colorbar and legends that can overlap nearby figures. Nevertheless, I can further adjust this to get plots that are more similar to the actual ones. I think that the tests are failing because there is a clash between the module and a method called `scatter`. Once the code is cleaned this should go away. . If you don't mind I would slowly start removing redundant code and adding further tests. So, lets keep this PR open.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357:710,redundant,redundant,710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357,1,['redundant'],['redundant']
Availability,@falexwolf This issue still persists in version 1.9.1. and the work around suggested by @Xparx results in the same error that @haskankaya has reported. Any advice on how to get around this or a potential fix?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729,1,['error'],['error']
Availability,"@falexwolf the problem is that there are functions that do now work without them and our down stream packages do not work ootb. Would it be possible to add a second file, e.g. `requirements-ect.txt` to keep track of this?. This file could also be used to create testing environments easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089:89,down,down,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089,1,['down'],['down']
Availability,"@falexwolf we just tried the solution you posted and it reveals a bug: when `ax` is not `None` you don't create the variable `axs` and thus throw an error here: https://github.com/theislab/scanpy/blob/master/scanpy/plotting/anndata.py#L634. Should be a simple fix (I think):. ```python; if ax is None:; axs, _, _, _ = setup_axes(ax=ax, panels=['x'] if groupby is None else keys, show_ticks=True, right_margin=0.3); else:; axs = [ax]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/137#issuecomment-413354154:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137#issuecomment-413354154,2,['error'],['error']
Availability,"@falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190; [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037; [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7; [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681; [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189:211,avail,available,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189,2,['avail'],['available']
Availability,"@falexwolf:. It was a mistake to use optional positional parameters for our APIs. The core python team designs all its APIs using almost exclusively keyword-only parameters, because this way, parameters can be added without having to go to the end. (And they’re *much* more conservative and thoughtful in adding parameters in the first place). E.g. in this case there’s only one central important parameter apart from `adata`, so a `*` should be after `n_top`, and @grst could add his parameter before `ax`, leaving `ax` at the end of the pameter list without breaking anything:. ```py; def highest_expr_genes(; adata: AnnData,; n_top: int = 30,; *,; show: Optional[bool] = None,; ...; ax: Optional[Axes] = None,; **kwds,; ). highest_expr_genes(ad, 12, True) # Error: show is a keyword-only param; highest_expr_genes(ad, 12, show=True) # Works; ```. I have an idea how to fix this without breaking everything: I think I can build a decorator that allows people to use parameters positionally, but sends a DeprecationWarning when they do, while the docs only report the new signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441008995:761,Error,Error,761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441008995,1,['Error'],['Error']
Availability,"@fbrundu I just had the exact same error after installing from cloned master, so just wondering if it's working for you now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524,1,['error'],['error']
Availability,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307:271,error,errors,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307,4,['error'],"['error', 'errors']"
Availability,"@fidelram Actually, a similar solution does exist for other plotting functions. @falexwolf added the `gene_symbols` parameter to `sc.pl.rank_genes_groups()` and `sc.pl.rank_genes_groups_violin()` as I was having the same issue of using Ensembl gene IDs. I'm not sure if he regrets doing that now though or not... it's not consistently applied. In either case, Ensembl gene IDs are more specific than HGNC/MGI gene symbols. For some users it may be important that this specificity is available (and you don't keep having to make copies of the data to plot). Also, if alternative splicing is investigated with single-cell data, then you cannot keep gene symbols as `var_names` throughout your dataset as a default. So this is a future-proof approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441040160:483,avail,available,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441040160,1,['avail'],['available']
Availability,"@fidelram again sorry for being late. I hope it doesn't matter that I've blackified one of the files (can revert this).; Not sure how relevant this PR will be, since @VolkerBergen has faster and more robust implementation, but as a triage version, it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-653803793:200,robust,robust,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-653803793,1,['robust'],['robust']
Availability,"@fidelram knows more about the plotting code than me, but here's some recommendations:. * Many of the downstream plotting functions for `rank_genes_groups` take `gene_symbols` arguments. See the docs for functions like: `sc.pl.rank_genes_groups_*`; * The `gene_symbols` argument is recent, and is gradually being added to functions.; * You can always set `var_names` to be gene symbols. I prefer keeping `var_names` as unique, canonical identifiers, but sometimes do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-473506355:102,down,downstream,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473506355,1,['down'],['downstream']
Availability,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377,3,['error'],['error']
Availability,"@fidelram that's a really great point and something I'd like to discuss at next meeting (already put it in the agenda). Another great example of such examples 😅 is the way @michalk8 set it up for [cellrank](https://cellrank.readthedocs.io/en/latest/auto_examples/index.html) and squidpy [not yet public].; The even nicer thing is that @michalk8 implemented a CI pipeline for the tutorials/examples part of the repo so that every time there is a change in master of the original repo, the examples are refreshed in the notebooks repo, so to have them always up to date. Would be really cool to concentrate efforts and try to get this logic also in scanpy (makes it both very user friendly and robust from a maintainer perspective)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376:692,robust,robust,692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376,1,['robust'],['robust']
Availability,"@fidelram, from `seaborn==0.12` on, the only valid positional argument will be `data` which may cause failures or unexpected behaviour. This is relevant at least [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L774) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L785). Should we add / specify the keyword argument `x` in this PR or open a separate issue and PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694389007:102,failure,failures,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694389007,1,['failure'],['failures']
Availability,"@fidelram, just wanted to add that I still cannot use the ```use_raw=False``` parameter, for example I keep getting an error when try to visualise my data with ```sc.pl.rank_genes_groups_heatmap``` or ```sc.pl.rank_genes_groups_matrixplot```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/377#issuecomment-441092773:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377#issuecomment-441092773,1,['error'],['error']
Availability,"@fidelram. Related to changes made in #794. . If a categorical column is passed in color, but maximum and minimum colors are passed as functions or strings, an error is thrown. It looks like the same error in each case. I think we just need some logic saying to only try and set vmin and vmax for numeric values. ## Example. Setup. ```python; import scanpy as sc; import numpy as np; from functools import partial. pbmc = sc.datasets.pbmc68k_reduced(); ```. Passing a function. ```python; sc.pl.umap(pbmc, color=[""bulk_labels"", ""HES4""], vmax=partial(np.quantile, q=0.99)); ```. <details>; <summary> Traceback </summary>. ```python; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); <ipython-input-13-83df06d6a2e8> in <module>; ----> 1 sc.pl.umap(pbmc, color=[""bulk_labels"",""HES4""], vmax=""p99""). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 436 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 437 """"""; --> 438 return embedding(adata, 'umap', **kwargs); 439 ; 440 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 230 ; 231 # check vmin and vmax options; --> 232 kwargs['vmin'], kwargs['vmax'] = _get_vmin_vmax(vmin, vmax, count, color_vector); 233 ; 234 # make the scatter plot. ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_vmin_vmax(vmin, vmax, index, color_vector); 390 f""correct format for percentiles.""); 391 # interpret value of vmin/vmax as quantile with the following syntax 'p99.9'; --> 392 v_value = np.percentile(color_vector, q=float(v_value[1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800:160,error,error,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800,2,['error'],['error']
Availability,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1144:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144,4,['error'],['error']
Availability,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111:148,down,downstream,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111,1,['down'],['downstream']
Availability,"@flying-sheep Added this snippet to eval the coordinates as int and not str (plotting > _utils.py > circles, lines 1138 - 1145):. ```; if not np.issubdtype(x.dtype, np.integer) or not np.issubdtype(; y.dtype, np.integer; ):; try:; x = x.astype(int); y = y.astype(int); except ValueError as e:; print(""Error converting to int:"", e); ```. This has solved my issue and can now see the tissue images using `sc.pl.spatial`. Do feel free to change the code though, this would be my first contribution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078:301,Error,Error,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078,1,['Error'],['Error']
Availability,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code ; ```; pip install git+https://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:80,error,errors,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,3,"['down', 'error']","['download', 'error', 'errors']"
Availability,"@flying-sheep I got the similar result. ```python; >>> scanpy-master]$ ls; conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. -----------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:305,Down,Download,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,4,['Down'],['Download']
Availability,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251:972,avail,avail,972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251,1,['avail'],['avail']
Availability,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120,2,['error'],['error']
Availability,"@flying-sheep I thought that by doing `adata[:, 'gene_name'].X` the AnnData object does all sorts of checks which are redundant if I only want to access a single column on the data matrix. But if you say this is fine I will not change it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197:118,redundant,redundant,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197,1,['redundant'],['redundant']
Availability,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955:132,ERROR,ERROR,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955,1,['ERROR'],['ERROR']
Availability,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1169:226,mainten,maintenance,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169,1,['mainten'],['maintenance']
Availability,@flying-sheep Regarding your first thought... it may cause issues when interfacing with other functions that do not have type annotations on the arguments. And users may then find it difficult to interpret the errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441219613:210,error,errors,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441219613,1,['error'],['errors']
Availability,@flying-sheep Thanks for fielding all this! You never wrote what thought about having the CLI layer in the scanpy repo... my main reason is that I simply think that I cannot maintain a layer that I'm not actively using (at least right now) and that the library maintenance and development is already quite some work...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437729436:261,mainten,maintenance,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437729436,2,['mainten'],['maintenance']
Availability,"@flying-sheep Thanks for the thorough response! This is a topic I have a lot of thoughts on, though I'm not so sure how coherently I can communicate all of them. On your first thought:. The worst case scenario I see here me typing something so poorly a newbie trying to follow the documentation gets horrible numba errors they can't figure out. This could happen if I hadn't thought about `Set` being a subtype of `Collection`. It can be difficult to know the `abc`s in `typing` are supposed to mean without spending a while using them. For example, this is not what I was expecting:. ```python; >>> issubclass(np.ndarray, typing.Collection); True; >>> issubclass(np.ndarray, typing.Sequence); False; ```. On defining `abc`s for this package, I think it would have to be done in a way where it was easy to discover exactly what is meant by the annotated types. Personally, I read most of my documentation through the ipython repl, where it can be difficult to figure out where a type referenced in a doc string is defined. Otherwise, I'd be interested in seeing how other people are doing it, but like @falexwolf, most of the packages I use don't have type annotations. Again, I think these would be less of an issue if quality writing on type annotation usage, particularly for scientific python, was available. As a Julia user, I found [this blog post](https://white.ucc.asn.au/2018/10/03/Dispatch,-Traits-and-Metaprogramming-Over-Reflection.html) very helpful not just for understanding how to implement trait types in Julia, but also when they're useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441414363:315,error,errors,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441414363,2,"['avail', 'error']","['available', 'errors']"
Availability,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-656556087:52,error,errors,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-656556087,1,['error'],['errors']
Availability,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154816100:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154816100,1,['error'],['error']
Availability,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1109:194,error,errors,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109,1,['error'],['errors']
Availability,"@flying-sheep Yup, I think we need to at least print a better failure message than just returning -1 for the milestone check. It's not a good experience for people that are not familiar with this. @lazappi thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055:62,failure,failure,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055,1,['failure'],['failure']
Availability,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287,1,['error'],['error']
Availability,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-668225385:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-668225385,1,['error'],['error']
Availability,"@flying-sheep sorry, I didn't use Jupyter notebook. one is because i am a fresh man in python. second is that our engineer of the lab server told us that we don't have ""??? some image software"" due to the limited memory. (I think, he means we could use R, but we cannot see the figure like Rstudio. we have to save it, download it to our PC, and view the figure.) I would try Juputer tomorrow~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/850#issuecomment-532654224:319,down,download,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850#issuecomment-532654224,1,['down'],['download']
Availability,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-534981775:58,error,errors,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830#issuecomment-534981775,1,['error'],['errors']
Availability,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:93,down,down,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437,4,"['down', 'error']","['down', 'errors']"
Availability,"@flying-sheep yes, it's exactly the same problem, with the exactly same error message that only happens when I (or the function) wanna subset an existing adata object",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-458658134:72,error,error,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-458658134,1,['error'],['error']
Availability,"@flying-sheep, any idea what's up with the black error here? Am I at fault, are all the other listed files at fault, some combination of the two?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/989#issuecomment-577146797:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989#issuecomment-577146797,3,"['error', 'fault']","['error', 'fault']"
Availability,"@flying-sheep, for this, were you thinking to update `adata.obs_vector` to throw errors with ambiguities , `sc.get.obsdf`, or both?. I'm wondering if there should be some period of deprecation warnings for that. I also think it's fair to consider it a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886:81,error,errors,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886,1,['error'],['errors']
Availability,"@flying-sheep: After the recent changes I am getting the following error:. ```bash; /apps/scanpy/scanpy/logging.py in _settings_verbosity_greater_or_equal_than(v); 36 def _settings_verbosity_greater_or_equal_than(v):; 37 if isinstance(settings.verbosity, str):; ---> 38 settings_v = _VERBOSITY_LEVELS_FROM_STRINGS[settings.verbosity]; 39 else:; 40 settings_v = settings.verbosity; KeyError: 'warning'; ```. The problem is solved by setting the verbosity level. E.g. ```; sc.settings.verbosity = 3; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/496:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/496,1,['error'],['error']
Availability,"@galamm, thanks for the report! Also thanks for the example, very useful!. I think I see what the issue is here, though your error is unexpected. Are you using the most recent version of scanpy (1.7.0)?. The `gene_symbols` argument is supposed to refer to column in `var` that has more human readable gene names. The idea here is that you might have some unique identifier as `var_names` (like ensembl ids), but would have something more interpretable sorted in `adata.var[gene_symbols]`. On my machine, I get a `KeyError` when I run your example since there is no column `""TEST""` in `adata.var`. This is expected. It's strange to me that you get a `NameError`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580,1,['error'],['error']
Availability,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:160,error,errors,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633,8,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"@giovp Looking more into the crashing I was getting with my strange use case, it turns out that I had both (a) a pair of completely correlated features, and (b) very strange count distributions. Once I used a proper variance stabilizing transform (arcsinh in this case) and remove redundant features, I can't reliably reproduce this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453:281,redundant,redundant,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453,2,"['redundant', 'reliab']","['redundant', 'reliably']"
Availability,"@gokceneraslan I like the idea, that would save quite some space. However, as a partial color blind person, I tend to avoid legends based on color because I can not map them reliably back to the figure. But otherwise, I think it is easy to adapt the current code to add such feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951:174,reliab,reliably,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951,1,['reliab'],['reliably']
Availability,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:619,mask,masking,619,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,2,['mask'],['masking']
Availability,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:218,down,download,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448,6,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"@gokceneraslan We had it switched to stable by default for some time already. I'm fine doing this again; I switched it back because I found some typos, etc., some missing explanation that I wanted to become immediately available...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560#issuecomment-477453468:219,avail,available,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-477453468,1,['avail'],['available']
Availability,"@gokceneraslan Yes, I agree a transparent benchmark repo would be very valuable. . I'd also like to see a detailed breakdown of the limitations of each method or imputation in general. It seems problematic to me to use imputed data for all downstream analyses, for example sub-clustering or DGE analysis, but I can't find a discussion of those limitations anywhere. I'm a little wary of imputation methods being part of a standard toolkit without sufficient discussion of limitations in the documentation somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769:240,down,downstream,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769,1,['down'],['downstream']
Availability,"@grst is also a good person to ping for tutorials. In general, we'll also want to link to more scverse tutorials eventually",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725:31,ping,ping,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725,1,['ping'],['ping']
Availability,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`; In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539:353,avail,available,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539,2,['avail'],['available']
Availability,"@hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963432344:161,down,down,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963432344,1,['down'],['down']
Availability,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655,1,['error'],['error']
Availability,@ilan-gold same thing without random state; I think there might be some windows error relating to numpy on linux defaulting to 64 bit integer vs windows sometimes defaulting to 32 bit (those were the first couple of google hits when i searched the error). though i dont know where the seed is generated in the source code though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034518751:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034518751,2,['error'],['error']
Availability,"@ilan-gold your minimal example causes the exact same error:. Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32. if you are curious, it spits the error out 14.210 times (71050 lines of error message). EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034445010:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034445010,3,['error'],['error']
Availability,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-624831279:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-624831279,1,['error'],['error']
Availability,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624:158,error,errors,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624,1,['error'],['errors']
Availability,"@ivirshup ; Hello ivirshup, these error comes from the below environments. When I upgrade to py3.8 and use scanpy 1.8.2, everything works well. Thanks a lot!. <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:none;}; br; 	{mso-data-placement:same-cell;}; td; 	{padding-top:1px;; 	padding-right:1px;; 	padding-left:1px;; 	mso-ignore:padding;; 	color:black;; 	font-size:11.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-number-format:General;; 	text-align:general;; 	vertical-align:middle;; 	border:none;; 	mso-background-source:auto;; 	mso-pattern:auto;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Package | Version; -- | --; Anaconda | 2.1.0; Python | 3.6.13; anndata | 0.7.6; anyio | 2.2.0; argon2-cffi | 20.1.0; async-generator | 1.1; attrs | 21.2.0; Babel | 2.9.1; backcall | 0.2.0; ble",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699,2,['error'],['error']
Availability,"@ivirshup ; Hi, thank for your help.; When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python; >>> import scanpy as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups; groups_order += [reference]; TypeError: must be str, not list. >>> import scanpy.api as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups; groups_order += [reference]; TypeError: must be str, not list. >>> import scanpy.external as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532502522:199,error,error,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532502522,1,['error'],['error']
Availability,"@ivirshup ; Yeah, it was the same data as the privious plot. I tried calling sc.tl.umap(sp, init_pos=""paga"") but meet an error. I just use the get_init_pos_from_paga function to solve this error as mention in #769 .Thanks!; ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)); [2] During: typing of call at /datc/dh_data/.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py (797). File ""../../../../.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py"", line 797:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223,4,['error'],"['error', 'errors']"
Availability,"@ivirshup @flying-sheep I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc.; ![image](https://user-images.githubusercontent.com/16916678/56281364-b3780580-610c-11e9-8e40-2f44d3007a19.png). In the auto-generated type annotations, the default values miss completely, and I don't think we'll ever restore the `, optional` descriptor, there. ![image](https://user-images.githubusercontent.com/16916678/56281431-e15d4a00-610c-11e9-990c-6a2477540535.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598:164,redundant,redundant,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598,1,['redundant'],['redundant']
Availability,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480,2,['error'],['error']
Availability,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```; sc.pp.neighors(); sc.tl.tsne(); ```; would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```; sc.pp.neighbors(method=""tsne"", perplexity=30); sc.tl.tsne(); ```; would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748543070:1348,avail,available,1348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-748543070,1,['avail'],['available']
Availability,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036:34,error,errors,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036,1,['error'],['errors']
Availability,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/752#issuecomment-517984501:41,avail,available,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752#issuecomment-517984501,1,['avail'],['available']
Availability,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-524280917:434,robust,robust,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-524280917,1,['robust'],['robust']
Availability,"@ivirshup I simplified the conditionals a bit and there are only two sets now. One to check for various `{Value/Import}Error`s and another to do the `clustering_kwargs` building. I think this is cleaner and faster since no code will run that doesn't have to. I didn't really see a way to do it with only one set of conditionals without code duplication. There's some code that's just common to both, but that shouldn't be run in the case of one of the `{Value/Import}Error`s .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908:119,Error,Error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908,2,['Error'],['Error']
Availability,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481:91,checkpoint,checkpoints,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481,1,['checkpoint'],['checkpoints']
Availability,"@ivirshup Indeed the problem is `use_raw=True` by default. In the test, I think what happens is that the raw data is being plotted and thus no error appears. The tolerance for the image difference may hide the problem if indeed the test image is correct. To avoid this confusion when plotting a layer I think it is better to override `use_raw`. This is how it was supposed to be working before the changes according to the documentation:. ```; layer : typing.Union[str, NoneType], optional (default: None); Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.; ``` ; The current logic is around this lines https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L744. PS: the `use_raw` has been a source of many confusions for me. Now I know when raw is used by default but for new users this may not be obvious. One solution is to add a warning message everytime that `use_raw` is set to `True` by the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080,2,"['error', 'toler']","['error', 'tolerance']"
Availability,@ivirshup Is the code for all the normalisations (including quantile rescaling) available somewhere?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-777280791:80,avail,available,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-777280791,1,['avail'],['available']
Availability,@ivirshup Re: `AssertionError: Error: Image files did not match.` See https://github.com/scverse/scanpy/pull/2815/files#diff-79d72f67d7be639d5fcd7d63a006524d1317f16261044fdeeae6f6da4d14e88aR30-R34 - I suspect the tolerances need to be udpated and checked. I was getting the opposite (I assume) - images that should be different were not picked up as such for sparse plots (like gene rankings).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527:31,Error,Error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527,2,"['Error', 'toler']","['Error', 'tolerances']"
Availability,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/757#issuecomment-523455880:88,error,errors,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757#issuecomment-523455880,1,['error'],['errors']
Availability,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095,1,['down'],['downloading']
Availability,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:19,failure,failures,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308,1,['failure'],['failures']
Availability,"@ivirshup any way to force Azure to clear its cache or use a different runner? The “invalid instruction” error here probably comes from using a binary wheel compiled for a newer CPU. /edit: wow, 9 attempts. Maybe just dropping Python 3.8 will get us there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417:105,error,error,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417,2,['error'],['error']
Availability,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-619321412:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-619321412,1,['error'],['error']
Availability,@ivirshup ping,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388:10,ping,ping,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388,1,['ping'],['ping']
Availability,"@ivirshup regarding the three comments:; ; * `adata.obs.columns` non_unique: I also think this should be an error as this will cause trouble at some point or another. I added a check for this which will raise a ValueError if duplicates are found; * `adata.var.index` Here I wanted to raise an error only if a `key` matched a duplicated `var_name` as you suggested. However, the selection by index, instead of `var_name`, from the matrix causes an error whenever the `var_names` contains duplicates. Actually, doing an AnnData selection when the `var_names` are not unique also raises an error. Thus, I added a ValueError if the var_names are not unique; ```PYTHON; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); adata[:, ['gene-1']]; ```. ```; --------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-58-8d1a96772653> in <module>; ----> 1 adata[:, ['gene-0']]. site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601,4,['error'],['error']
Availability,"@ivirshup. > The worst case scenario I see here me typing something so poorly a newbie trying to follow the documentation gets horrible numba errors they can't figure out. Well, that’s an improvement over the current situation of “the freeform text type annotations make me guess what I can pass and I get horrible numba errors”, right?. > `issubclass(np.ndarray, typing.Sequence) == False`. That looks like a bug. The docs to `Sequence` say: “Concrete subclasses must override `__new__` or `__init__`, `__getitem__`, and `__len__`”, and. ```py; >>> np.ndarray.__new__ ; <function ndarray.__new__(*args, **kwargs)>; >>> np.ndarray.__getitem__ ; <slot wrapper '__getitem__' of 'numpy.ndarray' objects>; >>> np.ndarray.__len__ ; <slot wrapper '__len__' of 'numpy.ndarray' objects>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441583940:142,error,errors,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441583940,2,['error'],['errors']
Availability,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534,1,['error'],['error']
Availability,"@jefferyUstc I can't reproduce this with `scanpy 1.4.3` and `anndata v0.6.21 `. Here's what I ran on my machine:. ```python; from io import StringIO; import pandas as pd; import numpy as np; import scanpy as sc. csv = """"""; Group,Group1,Group1,Group3,Group6,Group5 ; Gene1,11,0,0,14,0 ; Gene2,12,17,9,34,11 ; Gene3,0,0,0,0,2; """""". df = pd.read_csv(StringIO(csv), index_col=0); genes = df.index.values; barcodes = df.columns; adata = sc.AnnData(np.transpose(df.values), var=pd.DataFrame(genes), obs=pd.DataFrame(barcodes)); adata.var_names_make_unique(); sc.pp.filter_genes(adata, min_cells=1); adata.raw = adata; sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); ```. Could you try that? If the error still occurs, could you post the traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-508640504:704,error,error,704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-508640504,1,['error'],['error']
Availability,@k3yavi The right place to ask those questions is on the AnnData repository where all the read and write functions are located. [Here](https://icb-anndata.readthedocs-hosted.com/en/stable/api.html#reading) you can find the available read options. You are welcome to contribute! Would be great if AnnData can read EDS files.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/856#issuecomment-538301097:223,avail,available,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/856#issuecomment-538301097,1,['avail'],['available']
Availability,@kt6k were you using a conda environment when you hit this error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-479352073:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479352073,1,['error'],['error']
Availability,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928,1,['error'],['error']
Availability,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540:126,down,download,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540,1,['down'],['download']
Availability,@ktpolanski following from https://scanpy.readthedocs.io/en/stable/dev/code.html#code-style and building the docs locally gives me (among some errors that were not relevant):. ```; ...; /path/to/scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp._bbknn.bbknn:28: WARNING: py:class reference target not found: function; /path/to/scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp._bbknn.bbknn:28: WARNING: py:class reference target not found: function; ...; ```. Maybe that gives you some pointers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1868#issuecomment-861412696:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868#issuecomment-861412696,1,['error'],['errors']
Availability,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936:84,failure,failures,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936,2,"['failure', 'fault']","['failures', 'faults']"
Availability,"@liliblu `""louvain""` would work. @kleurless, sorry for such a late reponse to this! If you are still having this problem, does your `adata_2` have `.raw` set? `adata.raw.var_names` ca be different than `adata.var_names`, but is is used by default for plotting when available. Does your second call work with `sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds', use_raw=False)`?. If this is the issue, we should at least have a more clear error in the next release (#1583).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714:265,avail,available,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714,4,"['avail', 'error']","['available', 'error']"
Availability,@maarten-hifibio in the mean time if you need it I have just made some GPU wrappers available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. It includes one for leiden that would exactly act like sc.tl.leiden (it is part of my PR referenced here),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1106331321:84,avail,available,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1106331321,1,['avail'],['available']
Availability,@maarten-hifibio we are indeed actively working on this again. Feel free to join our zulip https://scverse.zulipchat.com/login/ and ping me. I can add you to the conversation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260:132,ping,ping,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260,1,['ping'],['ping']
Availability,"@massonix Latest version is available on PyPI, so you can try installing via pip install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480:28,avail,available,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480,1,['avail'],['available']
Availability,@maximilianh I think those messages are from your code? maybe you should improve the error message to include something like. > Try running sc.tl.rank_genes_groups(adata) to create the cluster annotation,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-478907896:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-478907896,1,['error'],['error']
Availability,"@maximilianh I was able to use the cell browser export function in the past but this time I am getting an error message:. INFO:root:Writing scanpy matrix to adata_cellbrowser_04_01_19_CD8_subclustered/exprMatrix.tsv.gz; INFO:root:Transposing matrix; INFO:root:Writing gene-by-gene, without using pandas; INFO:root:Writing 8068 genes in total; INFO:root:Wrote 0 genes; INFO:root:Wrote 2000 genes; INFO:root:Wrote 4000 genes; INFO:root:Wrote 6000 genes; INFO:root:Wrote 8000 genes; INFO:root:Writing UMAP coords to adata_cellbrowser_04_01_19_CD8_subclustered/umap_coords.tsv; ERROR:root:Couldnt find cluster markers list. I am using an h5ad file to import my ann data object. Is that why there is some issue with finding cluster markers ? I am able to plot the clusters in a UMAP plot so I know that the 'louvain' observation exists. Any thoughts on why this is happening ?. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-478685403:106,error,error,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-478685403,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:114,down,download,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271,5,"['down', 'redundant']","['download', 'downloads', 'redundant']"
Availability,"@maximillo Hi, sorry to bother you, I met the same error. But I don't konw how to change np.int8 to np.int32. Any help would be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524,1,['error'],['error']
Availability,"@mihem, thanks for pointing this out. I opened [this](https://github.com/theislab/scvelo/issues/443) issue on the `scvelo` repo to resolve the `typing_extensions` problem. You may want to open a new issue on `scanpy` for the `llvmlite` error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-835257528:236,error,error,236,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-835257528,1,['error'],['error']
Availability,@mmarwaosman what was the fix. I am getting the similar error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552:56,error,error,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552,1,['error'],['error']
Availability,"@mumichae ; Thanks for letting us know about the error. For now if you need multiple scatter plots on a single figure you can do something like; `import matplotlib.pyplot as plt`; `f, axs = plt.subplots(2,2)`; `sc.pl.scatter(..., ax=axs[0,0])`; `sc.pl.scatter(..., ax=axs[1,0])`; ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1986#issuecomment-916368363:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986#issuecomment-916368363,1,['error'],['error']
Availability,"@nahanoo ; Hi, there are 3 options for now:. 1. downgrading umap to 0.39; 2. installing scanpy from github; 3. waiting for a new release of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413:48,down,downgrading,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413,1,['down'],['downgrading']
Availability,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:573,error,error,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168,1,['error'],['error']
Availability,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072,2,['error'],['error']
Availability,@outlace Did you try adding more marker genes? The error is gone if you have a large number of marker genes to plot in my case.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-471159340:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471159340,1,['error'],['error']
Availability,@pchiang5 @LuckyMD what does it mean when a gene is present in adata.raw.var_names but not in adata.var_names ? I'm running into a key not found error because of the gene being in one list and not the other. Thanks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617838606:145,error,error,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617838606,1,['error'],['error']
Availability,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619398744:111,error,errors,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619398744,1,['error'],['errors']
Availability,"@rsggsr, that looks like a warning, not an error to me. Do the plots look wrong to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-615069994:43,error,error,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-615069994,1,['error'],['error']
Availability,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['error'],['error']
Availability,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:190,error,error-in-scanpy-,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051,7,"['Avail', 'avail', 'error']","['Available', 'available', 'error', 'error-in-scanpy-']"
Availability,"@stefanpeidli's code gives this error. `ValueError: Cannot take a larger sample than population when 'replace=False'`. If a group has less than required number observations, it shouldn't subsample. ```python; target_cells = 1000; cluster_key = ""cell_type"". grouped = adata.obs.groupby(cluster_key); downsampled_indices = []. for _, group in grouped:; if len(group) > target_cells:; downsampled_indices.extend(group.sample(target_cells).index); else:; downsampled_indices.extend(group.index). adata_downsampled = adata[downsampled_indices]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1397060295:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1397060295,1,['error'],['error']
Availability,"@vladie0, would you mind pulling again and checking if it works now?. @flying-sheep if at least four people can't install the package (including in a clean conda environment on a lab mate's machine), what do you call it? I don't think it's our fault, but I think there's a bug somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875:244,fault,fault,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875,1,['fault'],['fault']
Availability,"@xie186, are the variable names within each of your objects are unique?. I would guess that would be the problem. Here's a simple case that would throw this error:. ```python; import anndata as ad, numpy as np, pandas as pd. a = ad.AnnData(np.ones((3, 2)), var=pd.DataFrame(index=[""a"", ""a""])); b = ad.AnnData(np.ones((3, 3)), var=pd.DataFrame(index=[""a"", ""b"", ""c""])). a.concatenate(b); ```. I think our merge operation for the variables is only well defined if variable names are unique with each of the objects. I'm not sure there's a good default result here other than throwing an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-694683604:157,error,error,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-694683604,4,['error'],['error']
Availability,"A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290:351,robust,robust,351,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290,1,['robust'],['robust']
Availability,A neighbors error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141,1,['error'],['error']
Availability,"A number of multithreaded functions and libraries we use default to `os.cpu_count()` number of threads. This is a problem when multiple processes are running in parallel, as is the case when using pytest-xdist. This oversubscription can lead to an increase in test time when multiple workers are used. This PR limits how many threads most libraries use via `threadpoolctl`, and scales this to the number of workers available on the host. I personally see improvements of ~10x when running with this setting on a server with 16 cores, using `-n auto`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843:415,avail,available,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843,1,['avail'],['available']
Availability,A rough implementation of glmpca in python is now available here: https://github.com/willtownes/glmpca-py . I will try to get it organized as an installable package tomorrow and add unit tests. Issues/ pull requests welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867:50,avail,available,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867,1,['avail'],['available']
Availability,A temporary fix is to downgrade scipy to 1.4.1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300#issuecomment-655340510:22,down,downgrade,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300#issuecomment-655340510,1,['down'],['downgrade']
Availability,"AFAICT, I think the parallelization you're seeing will be due to the underlying calls in statsmodels. If you turn down the number of threads blas can use, do you see the same utilization?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-683633085:114,down,down,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396#issuecomment-683633085,1,['down'],['down']
Availability,"AFAIK networkx and python-igraph do the same thing, only that python-igraph is faster. We also need python-igraph anyway for louvain and so on, so maybe it would be good to get rid of networkx. Downside: python-igraph and louvain-igraph is currently deliberately an optional dependency since it’s hard to install on windows. People need to build it themselves (A task that even I didn’t manage by now, and I got *many* things to compile!) or use Christoph Grohlke’s unofficial builds ([here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph) and [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#louvain-igraph))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97:194,Down,Downside,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97,1,['Down'],['Downside']
Availability,"API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a reference for the community. For example:. ![image](https://user-images.githubusercontent.com/1140359/38873972-4953977a-4257-11e8-8675-a238738eb558.png). Another question is other single cell Python packages like magi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:1211,mainten,maintenance,1211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['mainten'],['maintenance']
Availability,"About adding all powers of adjacency matrix - i implemented it at first as you did, but then i thought that it was redundant and changed to the present variant. My thought was that the hexagonal connectivity structure would allow to get all paths of less than n_rings with only n_rings power. And this works in practice, but i agree that there can be some edge cases with isolated node blocks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872:115,redundant,redundant,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872,1,['redundant'],['redundant']
Availability,"About dpt_order in the Moignard example, if we plot the pseudotime vs. dpt-order at last manually like follows, ; `plt.figure(figsize=(8,8)); plt.plot(adata.smp['dpt_order'], adata.smp['dpt_pseudotime']); plt.xlabel('dpt-order'); plt.ylabel('pseudotime')`; we'll get; ![download 1](https://user-images.githubusercontent.com/20141984/28011291-687c20e0-6594-11e7-8068-472b4ab4d8a8.png); which is totally chaotic, unlike the one we get through `sc.pl.dpt`. Anyway, did I misunderstand the concept of dpt-order or is there a bug about this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/27#issuecomment-314053618:270,down,download,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27#issuecomment-314053618,1,['down'],['download']
Availability,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors; 2. Weighting the graph; 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python; class WrappedAffinities(openTSNE.affinity.Affinities):; def __init__(self, neighbors, symmetrize=True, verbose=False):; self.verbose = verbose; P = neighbors; if symmetrize:; P = (P + P.T) / 2; total = P.sum(); if not np.isclose(total, 1.):; P = P / total; self.P = P; ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here?. > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200:506,avail,available,506,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200,2,['avail'],['available']
Availability,"About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. . About the rules: . 1. ""I don't like replacing `x == False` with `not x` in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this."" . This should be covered by tests. In any case it is not good style and a violation. 2. ""Whats with changing from single letter variables inside expressions? Seems fine to me."". They are redefinitions of earlier variables and trip up flake8. We can call them whatever we want as long it s not `l` again. . 3. ""`lambda's also are generally fine."". See comment at the section. 4. ""Whats up with removing leading `#`s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. 5. ""So, some of the things you've adding a `# noqa` to look like bugs. I think we need to have a plan in place for doing something about these. Do you have any suggestions?"". The noqa ignore a rule for a specific line. I did not want to ""fix"" these things myself since Python is a dynamic language and you never know what happens :) Ideally we eventually get rid of all noqas, but not in this PR and not by me. I don't know the internals well enough to know whether this could have any side effects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068:254,error,error,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068,1,['error'],['error']
Availability,"Actually, no need to post more. A labmate managed to find this too. It looks like it has something to do with Matplotlib and the `TkAgg` backend (see: https://github.com/matplotlib/matplotlib/issues/13414). While this error doesn't occur in my normal environment, I can reproduce this error in a conda environment:. ```sh; conda create -yn conda_scanpy scanpy; conda activate conda_scanpy; python -c ""import matplotlib.pyplot as plt; plt.figure()""; ```. We were able to get plotting to work by switching to the `Agg` backend. You can do this by adding the following lines to the top of your script:. ```python; import matplotlib as mpl; mpl.use(""Agg""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876:218,error,error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876,2,['error'],['error']
Availability,"Addendum: different errors are generated depending on which axis is first sliced. The data set I'm loading is a dense matrix. ```; >>> data.X.dtype; dtype('<f4'); >>> data[:,0][0,:]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__; self._init_as_view(X, oidx, vidx); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 694, in _init_as_view; uns_new = deepcopy(self._adata_ref._uns); File ""/usr/lib/python3.6/copy.py"", line 180, in deepcopy; y = _reconstruct(x, memo, *rv); File ""/usr/lib/python3.6/copy.py"", line 307, in _reconstruct; y[key] = value; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 444, in __setitem__; _init_actual_AnnData(adata_view); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 367, in _init_actual_AnnData; adata_view._init_as_actual(adata_view.copy()); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 880, in _init_as_actual; self._check_dimensions(); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1879, in _check_dimensions; .format(self._n_obs, self._obs.shape[0])); ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows.; >>> data[0,:][:,0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332#issuecomment-433745600:20,error,errors,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332#issuecomment-433745600,1,['error'],['errors']
Availability,"Adding an expression atlas downloader to `sc.datasets` (proposed in #489). I've punted on replacing where datasets are downloaded by just making it a variable in settings, since it seems contentious where datasets should be downloaded by default #558. @flying-sheep when I build the docs locally, the link to the expression atlas doesn't format properly on the main `API` page, but does on it's own page. Any ideas on if we can get that to work?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573:27,down,downloader,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573,3,['down'],"['downloaded', 'downloader']"
Availability,Adding use_raw=False create errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046,1,['error'],['errors']
Availability,"Addressing https://github.com/theislab/scanpy/issues/435#issuecomment-538776417. This PR does two things:. 1. `downsample_counts` will convert the resulting downsampled matrix back to the initial dtype by default.; 2. `normalize_total` will now work with integer matrices. I think 2 should definitely be the case. 1 does have a performance cost, but it's close to @falexwolf's [suggestion](https://github.com/theislab/scanpy/issues/435#issuecomment-475999342) and removes a minor foot-gun.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865:157,down,downsampled,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865,1,['down'],['downsampled']
Availability,"Advantage of networkx is that it's easily installed... But yes, we should remove it in the future. I think with anaconda, one gets all the igraph and louvain stuff to work very easily without compiling. Without using Grohlke's binaries... One just needs to document this probably. At the latest when igraph and louvain are easily installed, networkx can be removed... PS: I'm currently preparing scanpy 1.0; there will be some slight changes to make the API less redundant... So for now, please no big changes...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822:463,redundant,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822,1,['redundant'],['redundant']
Availability,"After fixing the above error locally and continuing I ran into a similar error in the next step:; `sc.external.tl.palantir_results(...)` internally [calls](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L294) `run_palantir(ms_data=ms_data, ...)` with keyword `ms_data` which seems to have changed to just `data` in the [recent version of palantir](https://github.com/dpeerlab/Palantir/blob/master/src/palantir/core.py#L35).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412,2,['error'],['error']
Availability,"After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/701:348,down,down,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701,2,['down'],['down']
Availability,"After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:; ```python; sc.pp.neighbors(adata_hvg); sc.tl.louvain(adata_hvg); sc.tl.draw_graph(adata_hvg); ```; Till here, everything works nicely, but then I try to get the PAGA representation:. ```python; sc.tl.paga(adata_hvg, groups=""louvain""); ```. This returns the following error:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-249-7cc787ba28f9> in <module>; ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy); 93 adata.uns['paga'] = {}; 94 if not use_rna_velocity:; ---> 95 paga.compute_connectivities(); 96 adata.uns['paga']['connectivities'] = paga.connectivities; 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self); 127 def compute_connectivities(self):; 128 if self._model == 'v1.2':; --> 129 return self._compute_connectivities_v1_2(); 130 elif self._model == 'v1.0':; 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self); 161 if scaled_value > 1:; 162 scaled_value = 1; --> 163 connectivities[i, j] = scaled_value; 164 expected_n_edges[i, j] = expected_random_null; 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x); 67 if x.size != 1:; 68 raise ValueError('Trying to assign a sequence to an item'); ---> 69 self._set_intXint(row, col, x.flat[0]); 70 return; 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x); 795 def _set_intXint(self, row, col, x):; 796 i, j = self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695:408,error,error,408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695,1,['error'],['error']
Availability,"After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:; _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names_3, ; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=12,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); #data.to_csv('./write/paga_path_{}.csv'.format(descr)); #pl.savefig('./figures/paga_path.png'); pl.show(). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-8-c59dfbccf885> in <module>(); 16 title='{} path'.format(descr),; 17 return_data=True,; ---> 18 show=False); 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)); 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 932 idcs = idcs[idcs_group]; 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]); --> 934 else: x += list(adata_X[:, key].X[idcs]); 935 if ikey == 0:; 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1301 def __getitem__(self, index):; 1302 """"""Returns a sliced view of the object.""""""; -> 1303 return self._getitem_view(index); 1304 ; 1305 def _getitem_vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333,1,['error'],['error']
Availability,"Ah, I didn't know others are also automatically downloaded, very nice. paul15 uses `sc.utils.check_presence_download()`, while others use `check_datafile_present_and_download()` via `readwrite.read()`, though. Is this intentional?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364331847:48,down,downloaded,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364331847,1,['down'],['downloaded']
Availability,"Ah, I think this was reported before in #769. Would you mind checking if the error still occurs on master?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/936#issuecomment-560232016:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936#issuecomment-560232016,1,['error'],['error']
Availability,"Ah, yeah that's what I meant. If I use `setup()`, the tests on the linux server fail. However, the images generated are similar (RMSD < 10) to images made on my MacBook after running `setup()`. On the PAGA notebook, I saw errors like that when I was playing around with the dpi. Maybe fig size or dpi is being changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828:222,error,errors,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828,1,['error'],['errors']
Availability,Ah? The code seems like it just returns an empty list when there’s no results. Where is the error thrown?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-464011097:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464011097,1,['error'],['error']
Availability,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:1538,mask,masking,1538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842,2,['mask'],['masking']
Availability,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666259323:5,ping,ping,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344#issuecomment-666259323,1,['ping'],['ping']
Availability,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124:399,down,downloading,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124,1,['down'],['downloading']
Availability,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-524200077:45,avail,available,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-524200077,1,['avail'],['available']
Availability,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts; `; and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates; ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0); ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084:266,ERROR,ERROR,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084,2,['ERROR'],['ERROR']
Availability,"Also, you may want to change the error that is shown if a non-AnnData object is passed to the function. I put it as TypeError, because I didn't find how you have previously called that error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100#issuecomment-371099043:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100#issuecomment-371099043,2,['error'],['error']
Availability,"An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']; ```. Previous behavior:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/444:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444,2,"['Avail', 'error']","['Available', 'error']"
Availability,"An error jumped out when normalizing, turns out I had a bad dataset mixed in and after filter there were no cell left, hence the error. Thanks!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/121#issuecomment-381527583:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/121#issuecomment-381527583,2,['error'],['error']
Availability,"An error was raised when values_to_plot=""logfoldchanges"" was provided.; ```python; sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=5,; groupby='leiden_0.1',; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmax=20,; vmin=-20,; key='leiden_0.1_marker_filtered',; show=False; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334,1,['error'],['error']
Availability,An error when running scanpy.pl.clustermap(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,AnnDataReadError: Above error raised while reading key '/X' of type from /.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,1,['error'],['error']
Availability,"Another error I get and have no idea how to solve is when using the Wilcoxon rank-sum for testing for differential gene expression:. `sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)`. ```; ranking genes. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-385-c2fa7bb8ea8d> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 352 ; 353 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 354 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 355 scores[np.isnan(scores)] = 0; 356 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. The logistic regression and t-test work fine.; I guess it is related to my data....",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566,2,['error'],['error']
Availability,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981,1,['error'],['error']
Availability,"Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```; # ; # # Part of the error message that probably matters most; # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; *** multi-threaded process forked ***; crashed on child side of fork pre-exec. # ; # ; # ; ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/194:151,error,error,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194,2,"['error', 'fault']","['error', 'fault']"
Availability,Anyone familiar with the travis error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-404874304:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-404874304,1,['error'],['error']
Availability,"Apologies for again, the late response @fidel! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, please go ahead and remove redundant code and add further tests. We'll merge this PR eventually. And yes, we can think about a `develop` branch starting from 1.3. What do you say, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501:191,redundant,redundant,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501,1,['redundant'],['redundant']
Availability,"Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```; import scanpy.api as sc; sc.settings.verbosity = 2; adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') ; sc.pp.recipe_zheng17(adata) ; sc.pp.neighbors(adata) ; sc.tl.louvain(adata) ; adata.obs['louvain'].to_csv('clustering-scanpy.csv'); ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:; 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way?; 2. If yes, how can one modify the code to ensure reproducibility?; 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper?; 4. If the answer to the previous question is no, could you make those results publicly available somewhere?. I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params.; Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325:1335,avail,available,1335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325,1,['avail'],['available']
Availability,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:187,error,errors,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122,1,['error'],['errors']
Availability,"Are you sure about numba 0.43? This very much looks like a bug in numba. > It seems that `top_segment_proportions_sparse_csr` is new for scanpy 1.4.5. What makes you think that? It’s been there since @ivirshup added `calculate_qc_metrics` in #316. A second way for this to fail is:. ```pytb; NotImplementedError: No definition for lowering UniTuple(int64 x 2).shape; ...; numba.errors.LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); No definition for lowering UniTuple(int64 x 2).shape. File ""_qc_.py"", line 390:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; prev = 0; for j, n in enumerate(ns):; ^. [1] During: lowering ""$phi382.1_shape.158 = getattr(value=$380for_iter.2, attr=shape)"" at _qc.py (408); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263:378,error,errors,378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263,1,['error'],['errors']
Availability,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:851,avail,available,851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785,1,['avail'],['available']
Availability,"Are you talking about the `collections.abc.Mapping` in this case? [From the 3.7 docs](; https://docs.python.org/3/library/typing.html#classes-functions-and-decorators):. > In general, `isinstance()` and `issubclass()` should not be used with types. Additionally, those functions just throw an error for subscripted generics, so you definitely can't do `isinstance(m, Mapping[str, int])`. I don't think I'm totally clear on the differences in intended use cases for `ABC`s vs `Type`s. Are types only for annotation? Should ABCs not be used for annotations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-445102460:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-445102460,2,['error'],['error']
Availability,"Arguments for and against converting values in `downsample_counts`:. If we don't convert dtypes back to what they originally were, there's a slight performance boost since we don't have to have two copies. I we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197:259,down,downstream,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197,1,['down'],['downstream']
Availability,"As an alternative, I'd be up for just deprecating raw all together, as I think it causes more problems than it solves. I was talking about this recently with @falexwolf, who has come to a similar conclusion. This could be done on the `anndata` side, and just warn whenever `raw` is set. If no `raw` is present, then none of the weird behavior should come up. > I wonder how important it is to keep genes that are filtered out due to being expressed in too few cells anyway. Might be important for integration? But hopefully this could be solvable by just knowing what annotation was used so you can safely assume the missing values are 0. Also, what level of filtering are you doing here? I've tend to go `min_cells=1`. I think we do need to have a more general solution for having a ""feature-select-ed"" subset of the data, but think this can be done with `mask` argument. E.g. `sc.pp.pca(adata, mask=""highly_variable"")` (I believe we've talked about this before). This does run into memory usage problems if want do a densifying transform on the data, though I have doubts about whether this can be a good representation of the data. This can be technically solved by using a block sparse matrix type, but I'm not sure if any practically usable implementations of this are currently available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988:857,mask,mask,857,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988,6,"['avail', 'mask']","['available', 'mask']"
Availability,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919:796,mask,masks,796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919,2,"['error', 'mask']","['error', 'masks']"
Availability,"As expected the two other links here were of no use.; I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]); WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261:367,fault,fault,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261,1,['fault'],['fault']
Availability,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:26,down,downloads,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,4,['down'],"['download', 'downloaded', 'downloads']"
Availability,"As this issue is not closed I'll add a question here. . Is it possible, or if not could it be added, that the cells in the heatmaps are sorted within the groupby variables. Either by pseudotime if availible or just clustered simply by hierarchical clustering. This could add a more visually and intuitive pleasing ordering of cells. For example as in my figure above the groupby miss some property of the data with pattern over cells. If the cell ordering was random or default this pattern could not be seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/349#issuecomment-460428844:197,avail,availible,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349#issuecomment-460428844,2,['avail'],['availible']
Availability,"As you can see from the error output, this is an error within loompy. I assume you don't have the most recent version of loompy - there used to be a few bugs in it. Try with an update installation of loompy. I'm running 0.2.8 and never had any problem with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091,2,['error'],['error']
Availability,AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2797,Error,Error,2797,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"Assuming you're on a debian based linux, please check the following:; - `echo $PATH` shows your PATH variable.; - `which git` shows you the location of your git installation. If nothing is shown, you need to install it.; - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516:73,echo,echo,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516,1,['echo'],['echo']
Availability,"At some point we changed the return values of the anndata slicing and that is why I think the check for sparse was needed. My recommendation is to replace this whole block. ```python; for g in _gene_names:; if adata.raw is not None and use_raw:; X_col = adata.raw[:, g].X; if gene_symbols:; g = adata.raw.var[gene_symbols][g]; else:; X_col = adata[:, g].X; if gene_symbols:; g = adata.var[gene_symbols][g]; if issparse(X_col):; X_col = X_col.toarray().flatten(); X_col = X_col.toarray().flatten(); new_gene_names.append(g); df[g] = X_col; ```. by ; ```python; df = sc.get.obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols; new_gene_names = df.columns; ```. `sc.get.obs_df` is a well tested function and using it makes it easier for maintenance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773:752,mainten,maintenance,752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773,1,['mainten'],['maintenance']
Availability,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369,2,['error'],['error']
Availability,"At the moment we're trying to clean up `scIB` that it becomes easier to use. We're still not certain how to best deal with metrics that rely on R and C++ code though. The current plan is to make a more usable pypi package where some metrics give you a warning on additional requirements/manual C++ compilation. Apologies for the usability mess that a package that also assesses usability has become ^^. I'd prefer to keep it separate for now to facilitate maintenance and citation though. That being said, maybe we could think about an optional requirement for scIB to integrate them? At least when we've cleaned up our side of things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114:456,mainten,maintenance,456,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114,2,['mainten'],['maintenance']
Availability,"At the stage of finding neighbors, my jupyter kept showing this error:; <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:; ```; OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; And it killed the kernel entirely. ; ```. I try to make this work by running this in Linux but it got killed again. ; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359,2,['error'],['error']
Availability,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:502,down,downside,502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955,1,['down'],['downside']
Availability,"Awesome, thanks for the suggestion to look in the .uns variable! Just to confirm, are the available palettes options that can be used with the palette keyword in the call to the sc.pl.tsne() function listed in the palettes.py file? For example things like vega_20_scanpy, zeileis_26, and godsnot_64?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/156#issuecomment-390299178:90,avail,available,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156#issuecomment-390299178,1,['avail'],['available']
Availability,"AxisError was encountered while executing the regress_out function following the pbmc3k tutorial ; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; regressing out ['n_counts', 'percent_mito']; sparse input is densified and may lead to high memory use; ---------------------------------------------------------------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010:283,Error,Error,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010,1,['Error'],['Error']
Availability,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1654,fault,faults,1654,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,1,['fault'],['faults']
Availability,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935,1,['error'],['error']
Availability,Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935,1,['error'],['error']
Availability,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2159:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159,1,['error'],['error']
Availability,Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2159:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159,1,['error'],['error']
Availability,Backport PR #2209 on branch 1.9.x (Fix isinstance arg 2 must be a type error),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213:71,error,error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213,1,['error'],['error']
Availability,Backport PR #2209: Fix isinstance arg 2 must be a type error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213:55,error,error,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213,1,['error'],['error']
Availability,Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3072:35,error,errors,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072,2,['error'],['errors']
Availability,Backport PR #3069: Upload scrublet scores on test failure,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3242:50,failure,failure,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3242,2,['failure'],['failure']
Availability,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:874,down,download,874,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,2,['down'],['download']
Availability,"Based on my experience setting a single cutoff for all datasets will not work, as I've used a lot of different cutoffs depending on the distributions. I would echo @ivirshup's suggestion of looking at distributions. Joint distributions being a lot more important than individual histograms. There's a small discussion about it in our [best practices paper](https://www.embopress.org/lookup/doi/10.15252/msb.20188746)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/718#issuecomment-507264814:159,echo,echo,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718#issuecomment-507264814,1,['echo'],['echo']
Availability,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683,4,"['down', 'error']","['download', 'error', 'errors']"
Availability,Better 10x read errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/444:16,error,errors,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444,1,['error'],['errors']
Availability,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used; 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077238728:9,avail,available,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077238728,1,['avail'],['available']
Availability,"Both of these modules are not in the docs and not referenced in any tutorial and I never considered them mature code... I always planned on fixing these... but my bandwidth for this is limited... I should not have merged them into master, that's my fault... Won't happen again...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/392#issuecomment-445515498:249,fault,fault,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/392#issuecomment-445515498,1,['fault'],['fault']
Availability,Bugfix: Failure due to cugraph api change in v0.16...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1494:8,Failure,Failure,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494,1,['Failure'],['Failure']
Availability,But I think it's a little different. It's probably easier to implement since we still have all dependencies available at collection time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723:108,avail,available,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723,1,['avail'],['available']
Availability,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine 🤷",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-645460915:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-645460915,1,['error'],['error']
Availability,"But also, that looks like an h5py issue. Do you still get the error if you try `import h5py` in that environment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479721635:62,error,error,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479721635,1,['error'],['error']
Availability,But the error comes from your variable names being tuples. The following fixes it.; ```; adata.var_names = [i[0] for i in adata.var_names]; ```. Let me think where it would be best to output a warning. I'm not quite sure where else it would lead to collisions. Do you need tuples in the index?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440431843:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440431843,1,['error'],['error']
Availability,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492:78,avail,available,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492,1,['avail'],['available']
Availability,"CI runs that report coverage currently don't fail if the tests fail. This is because the way the coverage job is written swallows the error. I'm updating this use the same approach as anndata, which seems to be working.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874:134,error,error,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874,1,['error'],['error']
Availability,CPUDispatcher error with highly variable genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1995:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995,1,['error'],['error']
Availability,Calculate downregulated genes?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625:10,down,downregulated,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625,1,['down'],['downregulated']
Availability,"Calling `sc.get.obs_df()` without the `keys` parameter causes an error:. ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)]); ```. ```pytb; ~/scanpy/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 301 ; 302 # reorder columns to given order (including duplicates keys if present); --> 303 df = df[keys]; 304 for k, idx in obsm_keys:; 305 added_k = f""{k}-{idx}"". KeyError: (); ```. Also, if `keys` is not a list, the object returned is not a pandas dataframe but a Series object in which the last row is the obsm values. In other words, instead of adding a column to a dataframe with the obsm values, a row is added to a pandas Series. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)], keys='CST3'); ```; ```; index; AAAGCCTGGCTAAC-1 0.281; AAATTCGATGCACA-1 -0.176; AACACGTGGTCTTT-1 -0.818; AAGTGCACGTGCTA-1 -0.818; ACACGAACGGAGTG-1 0.854; ... ; TGTGAGTGCTTTAC-8 -0.069; TGTTACTGGCGATT-8 -0.818; TTCAGTACCGGGAA-8 -0.818; TTGAGGTGGAGAGC-8 0.428; X_umap-0 [-1.9918625454649166, -3.2486919412134108, -3....; Name: CST3, Length: 701, dtype: object; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1634:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1634,1,['error'],['error']
Availability,Calling `sc.get.obs_df` with `keys=adata.var_names` raises a value error since [here](https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/get/get.py#L303-L304) an Index object is used to re-order the dataframe. ; I think its a trivial fix to re-cast `keys` locally if an Index object is passed (aka `adata.var_names`) and could be nice for the user :),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2256:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256,1,['error'],['error']
Availability,"Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985,1,['error'],['error']
Availability,"Can rank_genes_groups be linked to use diffxpy on top of the available methods? . I am using the following code to convert the output of rank_genes_groups to a data frame, in case is useful:. ```PYTHON; def rank_genes_groups_df(adata, key='rank_genes_groups'):; # create a data frame with columns from .uns['rank_genes_groups'] (eg. names, ; # logfoldchanges, pvals). ; # Ideally, the list of columns should be consistent between methods; # but 'logreg' does not return logfoldchanges for example. dd = []; groupby = adata.uns['rank_genes_groups']['params']['groupby']; for group in adata.obs[groupby].cat.categories:; cols = []; # inner loop to make data frame by concatenating the columns per group; for col in adata.uns[key].keys():; if col != 'params':; cols.append(pd.DataFrame(adata.uns[key][col][group], columns=[col])); ; df = pd.concat(cols,axis=1); df['group'] = group; dd.append(df). # concatenate the individual group data frames into one long data frame; rgg = pd.concat(dd); rgg['group'] = rgg['group'].astype('category'); return rgg.set_index('group'); ```. This results on a table like this:. ![image](https://user-images.githubusercontent.com/4964309/64006299-5789a880-cb12-11e9-9196-305a318b9395.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294:61,avail,available,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294,1,['avail'],['available']
Availability,Can this just be inferred under the hood/raise a warning? It's a very frustrating error and not clear at all what the root issue for an end user.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-1442407575:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-1442407575,2,['error'],['error']
Availability,Can we customize the contents of left hand table of contents drop down?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379:66,down,down,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379,1,['down'],['down']
Availability,"Can we reopen this issue? I still don't see this functionality available. The ask is to be able to specify the number of rows or columns for the arrangement of the output panels from `sc.pl.violin`. Right now if I plot 8 genes, for example, they all show up on one row, yielding tiny plots. It would be nice to be able to pass in something like `ncols=4` so that the 8 panels will be arranged as a 2x4 instead of a 1x8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/348#issuecomment-745609837:63,avail,available,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348#issuecomment-745609837,1,['avail'],['available']
Availability,"Can you call `del adata.uns['cell_ontology_class_colors']`? This should throw a better error message... I can do that soon, I wonder how you managed to produce the error... cannot be anything related to a recent update... Hm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461:87,error,error,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461,2,['error'],['error']
Availability,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952,1,['error'],['error']
Availability,Can you provide an example to reproduce. From this issue #28 it seems to be related to dense matrices. Can try transforming `adata=sc.datasets.pbmc68k_reduced()` to see if you trigger the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-627888788:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-627888788,1,['error'],['error']
Availability,Cannot read Visium HD data using spatialdata-io (Recurrent error). Data is non-zarr format.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,1,['error'],['error']
Availability,Cannot write my anndata object to file. Already checked the other errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1572:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1572,1,['error'],['errors']
Availability,"Caught it. I had forgotten that arguments only get evaluated once, so if you mutate them, there is state which is maintained to other calls. I think the unhelpful `abort` message is from `louvain-igraph` expecting a weight vector of the right shape, which ended up with the error:. ```; libc++abi.dylib: terminating with uncaught exception of type char const*; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370,1,['error'],['error']
Availability,"Changing it to a property throws a different error:. <details>; <summary> from make html </summary>. ```sh; reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot ; Exception occurred:; File ""/usr/local/lib/python3.8/site-packages/sphinx/util/docfields.py"", line 369, in transform; new_list += fieldtype.make_field(fieldtypes, self.directive.domain, items,; TypeError: make_field() got an unexpected keyword argument 'inliner'; The full traceback has been saved in /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/sphinx-err-qbzn5se8.log, if you want to report the issue to the developers.; Please also report this if it was a user error, so that a better error message can be provided next time.; A bug report can be filed in the tracker at <https://github.com/sphinx-doc/sphinx/issues>. Thanks!; make: *** [html] Error 2; ```. </details>. <details>; <summary> contents of the referenced log file </summary>. ```python; # Sphinx version: 4.1.0; # Python version: 3.8.10 (CPython); # Docutils version: 0.16 release; # Jinja2 version: 2.11.2; # Last messages:; # reading sources... [ 2%] dev/documentation; # reading sources... [ 2%] dev/external-tools; # reading sources... [ 3%] dev/getting-set-up; # reading sources... [ 3%] dev/index; # reading sources... [ 3%] dev/release; # reading sources... [ 4%] dev/testing; # reading sources... [ 4%] dev/versioning; # reading sources... [ 4%] ecosystem; # reading sources... [ 5%] external; # reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot; # Loaded extensions:; # sphinx.ext.mathjax (4.1.0) from /usr/local/lib/python3.8/site-packages/sphinx/ext/mathjax.py; # sphinxcontrib.applehelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/applehelp/__init__.py; # sphinxcontrib.devhelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/devhelp/__init__.py; # sphinxcontrib.htmlhelp (2.0.0) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/htmlhelp/__init__.py; # sphinxcontrib.serializinghtml (1.1.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557,4,"['Error', 'error']","['Error', 'error']"
Availability,Changing to WIP since I'd like to improve failure handling before this gets merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478207900:42,failure,failure,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478207900,1,['failure'],['failure']
Availability,Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172,1,['error'],['error']
Availability,Combat processing errors/warnings in console,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164,1,['error'],['errors']
Availability,"Completely agree, Gökcen!. How I just thought about dealing with this in the past couple of minutes: could we not make a submodule *rtools*? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful. The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a `scanpy-contrib`: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: `anndata` is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759:955,mainten,maintenance,955,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759,1,['mainten'],['maintenance']
Availability,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298,2,"['Avail', 'error']","['Available', 'error']"
Availability,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:12,Mask,Mask,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754,3,"['Mask', 'mask']","['Mask', 'masking']"
Availability,Could you come up with the minimum amount of commands you'd need to run to reproduce this? It would also be helpful if this could be done using generated or publicly available data. [Something like this](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) would be great.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787877279:166,avail,available,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787877279,1,['avail'],['available']
Availability,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations?. @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286:310,redundant,redundant,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286,1,['redundant'],['redundant']
Availability,"Could you please provide more information about his error? How do you create the scanpy tmp?. In addition, the result of sc.tl.umap is stored in the scanpy file as obsm['X_umap']. You can try to display these data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1954#issuecomment-883854761:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1954#issuecomment-883854761,1,['error'],['error']
Availability,Could you post the full error traceback so that I see where the error is raised?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106,2,['error'],['error']
Availability,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-732724704:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-732724704,2,['error'],['error']
Availability,"Could you throw a more informative error message for `copy=False`? Maybe:. `NotImplementedError(""Inplace subsampling is not implemented for backed objects"")`. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632,1,['error'],['error']
Availability,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:29,failure,failures,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589,2,"['down', 'failure']","['down', 'failures']"
Availability,"Currently there's an error being raised because the following images in don't match. path: `scanpy/tests/notebooks/_images_paga_paul15_subsampled/paga_path.png`. **Expected**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666060-de033280-e21a-11ea-83f9-684908586f6e.png). **Actual**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666074-e2c7e680-e21a-11ea-9f08-fc495d6762b0.png). **Diff**; ![paga_path-failed-diff](https://user-images.githubusercontent.com/8322751/90666089-e78c9a80-e21a-11ea-9e0c-4e7e6a80d140.png). I'm going to update expected to match actual, but I need some help to see if this is okay",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244,1,['error'],['error']
Availability,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2323:394,down,downstream,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323,1,['down'],['downstream']
Availability,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030:465,error,error,465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030,1,['error'],['error']
Availability,"Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```; >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'); WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; ranking genes; consider 'louvain_resolution_3.0' groups:; with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups; method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics; for group_index, scores, pvals in generate_test_results:; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test; self._basic_stats(); File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats; self.means[imask], self.vars[imask] = _get_mean_var(X_mask); File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var; var *= X.shape[axis] / (X.shape[axis] - 1); ZeroDivisionError: division by zero; ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490:120,error,error,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490,1,['error'],['error']
Availability,"Cuts around 1 second off import of scanpy. ```sh; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn ; python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total; isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn ; Switched to branch 'master'; Your branch is up to date with 'upstream/master'.; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master ; python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total; ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/703:512,down,down,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703,1,['down'],['down']
Availability,D scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stack,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2632,Error,Error,2632,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,Dask update causing CI failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:23,failure,failures,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['failure'],['failures']
Availability,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnData’s shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnData’s shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:3235,error,error,3235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,Dataset maintenance,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1101:8,mainten,maintenance,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1101,1,['mainten'],['maintenance']
Availability,"Dear @LouisFaure,. thank you very much for the high quality PR.; A couple of questions:; 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found; 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-815285176:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-815285176,1,['avail'],['available']
Availability,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['error'],['error']
Availability,"Dear Olivia,; as I understand, you get a; ```; KeyError: 'Wfdc18'; ```; when calling; ```; adata1 = adata[:, filter_result.gene_subset]; adata1.var.ix['Wfdc18']; ```; Right? So, 'Wfdc18' is no longer `adata1.var_names`. You can also check by typing; ```; print('Wfdc18' in adata1.var_names); ```; which should print `False`. Regarding plotting: as stated in the [basic tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) in box [22], you have to pass `use_raw=False` if you want to access `adata.X` in plotting if `adata.raw` has been set, otherwise it assumes that you want to plot the raw data.; ```; sc.pl.pca(adata1, color='Wfdc18', use_raw=False); ```; which will throw an error after filtering if 'Wfdc18' is no longer there. Does this help and explain what you observe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560:734,error,error,734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560,1,['error'],['error']
Availability,"Dear Theis lab,; I get the following error:; `ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (0,4) and requested shape (3255,4)`; when running `sc.pl.diffmap(adata, color='leiden', projection='3d', save='_diff_3d.pdf')`. I hope you guys can help me with this.; regards",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/829:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/829,1,['error'],['error']
Availability,"Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py; sc.tl.paga(adata); ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb; running PAGA; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2656 try:; -> 2657 return self._engine.get_loc(key); 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-31-5aa170e493c3> in <module>; ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy); 92 adata.uns['paga'] = {}; 93 if not use_rna_velocity:; ---> 94 paga.compute_connectivities(); 95 adata.uns['paga']['connectivities'] = paga.connectivities; 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self); 126 def compute_connectivities(self):; 127 if self._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,2,"['error', 'toler']","['error', 'tolerance']"
Availability,"Dear all; I would like to project my umap from scanpy in 3d but I have faced the following problem:. > ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (0,4) and requested shape (816,4). It's very strange because before I update some of my packages, I could run it it with no problem with the following packages:. > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 . but after updating some of my packages it was not possible due to that error!. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. Should I roll back to the previous version of annadata or scanpy? has anyone ran this feature with my package version with no problems?. Thanks a lot. Here are the packages I use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/663:595,error,error,595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663,1,['error'],['error']
Availability,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. ; I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. ; _name_list_ is a string containing gene names and should be specified. ; _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data ; _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662:38,avail,available,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662,1,['avail'],['available']
Availability,"Dear developers, . in an attempt to instal the latest version of scanpy from GitHub (Master branch), I receive the following error:. Traceback (most recent call last):; File ""/home/vladie/PycharmProjects/PY3/RPE_MYCN_10X.py"", line 4, in <module>; import scanpy.external as sce; File ""/usr/local/lib/python3.6/dist-packages/scanpy/__init__.py"", line 33, in <module>; from . import datasets, logging, queries, external; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/__init__.py"", line 1, in <module>; from . import tl; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/tl.py"", line 4, in <module>; from ._tools._palantir import palantir; ModuleNotFoundError: No module named 'scanpy.external._tools'. I would like to run palentir through Scanpy, is this already possible ? ; Kind regards,; Vladie0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601,1,['error'],['error']
Availability,"Dear professor&nbsp;Philipp A. Thank you of your patience.; I've attached my Anndata and codes in the attachment. Kind regards. ; Original Email; ; . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). ; Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;; . 	; 	 		 			从QQ邮箱发来的超大附件 	; 	 		 				 					 						 							 						 					; 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086#issuecomment-2155872130:370,error,error,370,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086#issuecomment-2155872130,2,"['down', 'error']","['download', 'error']"
Availability,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395:280,error,error,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395,2,['error'],['error']
Availability,"Dear, ; When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last); ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs); 4226 valid_shape = False; -> 4227 raise ValueError; 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-29-c0e8bf06937e> in <module>(); ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax); 396 single_component=single_component,; 397 arrowsize=arrowsize,; --> 398 pos=pos); 399 if colorbars[icolor]:; 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state); 746 sct = ax.scatter(; 747 pos_array[:, 0], pos_array[:, 1],; --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap); 749 if fontsize is None:; 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/pytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381,1,['error'],['error']
Availability,"Dear,; When I Calculate qc metrics for visualization according to the example in https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics:. ```py; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.calculate_qc_metrics(adata, inplace=True); >>> sns.jointplot(adata.obs, ""log1p_total_counts"", ""log1p_n_genes_by_counts"", kind=""hex""); ```. The following error occurred:; AttributeError: 'str' object has no attribute 'get'; It seems that sns.jointplot are not compatible well with adata.obs, anybody who can help me ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/499:398,error,error,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/499,1,['error'],['error']
Availability,"Dears; Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb; sc_adata=sc.read_loom(sc_input,sparse = True); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom; obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs; if v.ndim > 1 and v.shape[1] > 1:; AttributeError: 'NoneType' object has no attribute 'ndim' ; ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2461:86,Error,Error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461,1,['Error'],['Error']
Availability,"Default: lzf. see theislab/anndata#123. To review without being bogged down with whitespace changes, check: https://github.com/theislab/scanpy/pull/847/files?w=1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/847:71,down,down,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847,1,['down'],['down']
Availability,Dendrogram error - symmetry,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2357:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357,1,['error'],['error']
Availability,Dendrogram returns an error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2125:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125,1,['error'],['error']
Availability,Did you check if the expected and actual images were significantly different. Some times I get errors locally because is difficult to have an identical environment as the one used by Travis.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418#issuecomment-698870987:95,error,errors,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418#issuecomment-698870987,1,['error'],['errors']
Availability,"Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515127872:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515127872,1,['error'],['error']
Availability,"Do you know how that entry could have been filled with `NaN`?. The plots and errors you were showing above are consistent with all the values being ""null"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787868527:77,error,errors,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787868527,1,['error'],['errors']
Availability,"Do you know which step of the script the results start differing? That would help in cutting down where the issue is occurring. If not, it would be useful if you could share objects with different results from the various machines. You could use the `sc.datasets.pbmc3k` for this (if your data is private). Would you also be able to share the output of `numba -s` from each of these environments? Different CPUs can give different results from numba code due to the features available. Ping resident windows expert @Koncopd",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947:93,down,down,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947,3,"['Ping', 'avail', 'down']","['Ping', 'available', 'down']"
Availability,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295,3,"['error', 'failure']","['error', 'failure']"
Availability,"Does `scanpy==1.5.1` support multiple sections in one adata object? If I concatenate several anndata object I can't plot even with `sc.pl.spatial(img_key=None)`. Try concatenating 3 mouse brain adata object and plotting:; ```python; adata = adata1.concatenate([obj2, obj3], index_unique=None); sc.pl.spatial(adata[adata.obs[""sample""]==adata.obs[""sample""].unique()[0], :], ; color=[""Rorb"", ""Vip""], img_key=None,; vmin=0, cmap='magma',; gene_symbols='SYMBOL'); ```. This is the error I get:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-9-8c84185773ec> in <module>; 6 color=[""Rorb"", ""Vip""], img_key=None,; 7 vmin=0, cmap='magma', #vmax=3.8,; ----> 8 gene_symbols='SYMBOL'; 9 ). /nfs/team283/vk7/software/miniconda3farm5/envs/cellpymc/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, size, **kwargs); 765 """"""; 766 if library_id is _empty:; --> 767 library_id = next((i for i in adata.uns['spatial'].keys())); 768 else:; 769 if library_id not in adata.uns['spatial'].keys():. KeyError: 'spatial'; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254:476,error,error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254,1,['error'],['error']
Availability,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021:130,down,down,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021,2,"['down', 'error']","['down', 'error']"
Availability,"Does this cause the same issue?. ```python; import numpy as np; import umap. umap.UMAP().fit_transform(np.random.randn(10_000, 20)); ```. And when you say ""dies"", is there a segfault message, or are you seeing a jupyter kernel failure message?. In general, this sounds like a numba issue. I'd recommend taking searching the `umap-learn` or `numba` repositories for similar issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-754547843:227,failure,failure,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-754547843,2,['failure'],['failure']
Availability,"Don't think so. I think these are closer to errors I was getting locally a few weeks ago, but couldn't get CI to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012:44,error,errors,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012,1,['error'],['errors']
Availability,Don’t error if n_top_genes > n_var,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/835:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/835,1,['error'],['error']
Availability,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:41,Error,Error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,1,['Error'],['Error']
Availability,Downgrading `scikit-learn` to `0.20.3` does not resolve the error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522:0,Down,Downgrading,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522,3,"['Down', 'error']","['Downgrading', 'error']"
Availability,Download header,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:0,Down,Download,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,1,['Down'],['Download']
Availability,Downsample branch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100,1,['Down'],['Downsample']
Availability,Downsample improvements,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/602:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/602,1,['Down'],['Downsample']
Availability,Downsample total counts,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/474:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474,1,['Down'],['Downsample']
Availability,"Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python; import scanpy as sc; from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000); adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) ; sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1096:0,Down,Downstream,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096,1,['Down'],['Downstream']
Availability,"Due to a misconfiguration in Travis setup, all tests are now running only with Python 3.7 now and there is a mysterious HDF error somewhat related to Python 3.7 and pytables.; Python version is fixed in https://github.com/theislab/scanpy/pull/201, so until we have Python 3.7 tests, we are good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782,1,['error'],['error']
Availability,"Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 104 if adata.isview: # we shouldn't need this here...; 105 adata._init_as_actual(adata.copy()); --> 106 neighbors = Neighbors(adata); 107 neighbors.compute_neighbors(; 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs); 527 self._number_connected_components = self._connected_components[0]; 528 if 'X_diffmap' in adata.obsm_keys():; --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata); 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata); 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata); 395 return np.r_[1, adata.uns['diffmap_evals']]; 396 else:; --> 397 return adata.uns['diffmap_evals']; 398 ; 399 . KeyError: 'diffmap_evals'; ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1021:334,avail,available,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021,1,['avail'],['available']
Availability,"E.g. matplotlib is only necessary when plotting, and for e.g. Docker images, it would be useful to have a slim scanpy core. An idea would be to do it like Jupyter:. - A `scanpy-core` PyPI package with just the essentials.; - A `scanpy` metapackage, which depends on `scanpy-core` and most (or all) of the optional dependencies. Users doing `pip install scanpy` will get the full package, with no annoying runtime errors, and packagers needing flexibility get `scanpy-core` and can slim everything down as needed. cc @hensing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/59:413,error,errors,413,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59,2,"['down', 'error']","['down', 'errors']"
Availability,ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62040,ERROR,ERROR,62040,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63354,ERROR,ERROR,63354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68099,ERROR,ERROR,68099,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"Either that, or allow the downstream code to gracefully handle `inf` values.; It is the binning procedure for both 'seurat' and 'cell_ranger' that seem to be a problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517842921:26,down,downstream,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517842921,1,['down'],['downstream']
Availability,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922,6,['error'],['error']
Availability,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558,1,['error'],['error']
Availability,"Env:; * Ubuntu 16.04; * python 3.7; * pandas 0.25.0; * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do; `sc.pp.highly_variable_genes(adata)`. I get the following error; ```; /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1; result = op(self._deduped_data()); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p; mean = np.log1p(mean); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p; mean = np.log1p(mean); Traceback (most recent call last):; File ""../../scvi/scvi_adata.py"", line 75, in <module>; sc.pp.highly_variable_genes(adata); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes; flavor=flavor); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763,1,['error'],['error']
Availability,Error When Saving File as .h5ad with adata.write,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['Error'],['Error']
Availability,Error after normalization with scran,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,1,['Error'],['Error']
Availability,Error at the cell cycle score calculation step,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,1,['Error'],['Error']
Availability,Error calculating neighbors on sparse array with cosine metric,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1096:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096,1,['Error'],['Error']
Availability,Error exporting adata using sc.export_to.spring_project,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1510:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510,1,['Error'],['Error']
Availability,Error filtering 'Boolean index not valid',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/768:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768,1,['Error'],['Error']
Availability,Error here; ![image](https://github.com/scverse/scanpy/assets/117483585/c23b446d-f5f9-4775-95ce-eda0a49aba81). ![image](https://github.com/scverse/scanpy/assets/117483585/09ee6450-66b0-43e2-8079-fcb3e06735d4),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184,1,['Error'],['Error']
Availability,Error in `sc.tl.umap`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579,1,['Error'],['Error']
Availability,Error in cell cycle score calculation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2156:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156,1,['Error'],['Error']
Availability,Error in importing scanpy when using scvi-tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2542:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542,1,['Error'],['Error']
Availability,Error in normalize_total with scanpy 1.9,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2210:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210,1,['Error'],['Error']
Availability,Error in pca_loadings when components > 5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/431:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431,1,['Error'],['Error']
Availability,Error in running scrublet,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['Error'],['Error']
Availability,Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313,1,['Error'],['Error']
Availability,Error in sc.pp.highly_varaible_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509,1,['Error'],['Error']
Availability,Error in sc.pp.highly_variable_genes function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193,1,['Error'],['Error']
Availability,Error in sc.tl.dendrogram: The truth value of a Index is ambiguous.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300,1,['Error'],['Error']
Availability,Error in tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/63:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63,1,['Error'],['Error']
Availability,Error installing scanpy through pip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,1,['Error'],['Error']
Availability,Error message in tl.diffmap / why n_comps must be > 2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/668:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/668,1,['Error'],['Error']
Availability,Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198,1,['Error'],['Error']
Availability,Error pip installing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,1,['Error'],['Error']
Availability,Error plotting the graph,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208,1,['Error'],['Error']
Availability,Error related to verbosity,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/496:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/496,1,['Error'],['Error']
Availability,Error running example notebook,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/24:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/24,1,['Error'],['Error']
Availability,Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,Error using rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365,1,['Error'],['Error']
Availability,Error when filtering: AttributeError: 'Series' object has no attribute 'is_dtype_equal',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34,1,['Error'],['Error']
Availability,Error when plotting PAGA,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/483:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/483,1,['Error'],['Error']
Availability,Error when repeating the tutorial for diffusion map in v1.9.1 scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2254:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254,1,['Error'],['Error']
Availability,"Error when trying this where `X` is a dask array with sparse chunks:. ```python; result = sc.pp.highly_variable_genes(adata, inplace=False); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:363, in partial_reduce(func, x, split_every, keepdims, dtype, name, reduced_meta); 362 try:; --> 363 meta = func(reduced_meta, computing_meta=True); 364 # no meta keyword argument exists for func, and it isn't required. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:685, in mean_combine(pairs, sum, numel, dtype, axis, computing_meta, **kwargs); 684 ns = deepmap(lambda pair: pair[""n""], pairs) if not computing_meta else pairs; --> 685 n = _concatenate2(ns, axes=axis).sum(axis=axis, **kwargs); 687 if computing_meta:. TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'. During handling of the above exception, another exception occurred:. IndexError Traceback (most recent call last); Cell In[19], line 1; ----> 1 result = sc.pp.highly_variable_genes(adata, inplace=False); 2 result. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:702, in highly_variable_genes(***failed resolving arguments***); 699 del min_disp, max_disp, min_mean, max_mean, n_top_genes; 701 if batch_key is None:; --> 702 df = _highly_variable_genes_single_batch(; 703 a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725,1,['Error'],['Error']
Availability,Error when writing to h5ad,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['Error'],['Error']
Availability,Error while reading h5ad file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,1,['Error'],['Error']
Availability,Error while using the read_10x_mtx() function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,1,['Error'],['Error']
Availability,Error with gene ontology enrichment analysis,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003,1,['Error'],['Error']
Availability,Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,1,['Error'],['Error']
Availability,Error with scanpy.api.pl.highest_expr_genes(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/220:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/220,1,['Error'],['Error']
Availability,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```; >>> import scanpy as sc; >>> adata_ref = sc.datasets.pbmc3k_processed(); pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]; Traceback (most recent call last):; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open; encode_chunked=req.has_header('Transfer-encoding')); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request; self._send_request(method, url, body, headers, encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request; self.endheaders(body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders; self._send_output(message_body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output; self.send(msg); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send; self.connect(); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect; server_hostname=server_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket; session=session; File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create; self.do_handshake(); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake; self._sslobj.do_handshake(); ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,1,['error'],['error']
Availability,Every piece of redundant code we delete is one we don’t have to maintain.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/556:15,redundant,redundant,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/556,1,['redundant'],['redundant']
Availability,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-1566468673:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-1566468673,1,['error'],['error']
Availability,Exactly same error here.; info:; scanpy==1.4.6 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.3.1 pandas==1.0.0 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151#issuecomment-611362371:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151#issuecomment-611362371,2,['error'],['error']
Availability,"Exactly the same error message pops up when inputting `np.int64` data into `sc.pp.log1p()`. This is with the latest scanpy, and using data that has otherwise worked well when not using `sc.pp.downsample_counts()`. I thus wouldn't consider this resolved, although I can open another issue as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334,1,['error'],['error']
Availability,"Exactly, the error was introduced by some third party update or so. Therefore there was no need for 6e797fa, and it even is is wrong, the second line *needs* to be. ```py; colors = cmap(normalize(mean_flat)); ```. It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`. And when you call it with `normalize(mean_flat[0])` (what happens in the list comprehension), vmin gets set to `min(mean_flat[0]) == mean_flat[0]` instead of `min(mean_flat)`. please do. ```sh; git reset --hard a4b3ccd88f0412461813838d5435ce0cc0b10883; git push -f; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893,1,['error'],['error']
Availability,Exit with an error if sc.pl.pca_loadings is called with indices < 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/803:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/803,1,['error'],['error']
Availability,FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'; ```. ### Minimal code sample. ```python; pip install scipy==1.14.0rc1; pytest; ```. ### Error output. _No response_. ### Versions. <details>. ```; + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba); + annoy==1.17.3; + anyio==4.4.0; + array-api-compat==1.7.1; + pillow==10.3.0; + platformdirs==4.2.2; + pluggy==1.5.0; + pre-commit==3.7.1; + profimp==0.1.0; + psutil==5.9.8; + pyarrow==16.1.0; + pygments==2.18.0; + pygsp==0.5.1; + pynndescent==0.5.12; + pyparsing==3.1.2; + pytest==8.2.1; + pytest-cov==5.0.0; + pytest-memray==1.6.0; + pytest-mock==3.14.0; + pytest-nunit==1.0.7; + pytest-xdist==3.6.1; + python-dateutil==2.9.0.post0; + pytz==2024.1; + pyyaml==6.0.1; + rich==13.7.1; + scanorama==1.7.4; + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s); + scikit-image==0.23.2; + scikit-learn==1.5.0; + scikit-misc==0.3.1; + scipy==1.14.0rc1; + scprep==1.1.0; + seaborn==0.13.2; + session-info==1.0.0; + setuptools==70.0.0; + setuptools-scm==8.1.0; + six==1.16.0; + sniffio==1.3.1; + sortedcontainers==2.4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3083:1725,Error,Error,1725,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083,1,['Error'],['Error']
Availability,"FEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Dow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:1156,Down,Download,1156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,1,['Down'],['Download']
Availability,"FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error. . I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538,2,"['down', 'error']","['downstream', 'error']"
Availability,"FWIW, I stumbled upon a related issue this morning where my kernel just crashes/restarts computing neighbors. . For me it appears to crop up when the number of neighbors is <15, metric doesn't appear to matter. I've been upgrading/downgrading various dependencies, and I'm fairly certain this has to do with the call to [`NNDescent` in `umap.umap_.py`](https://github.com/lmcinnes/umap/blob/b1223505ca56ae104feb35e4196227277d1e8058/umap/umap_.py#L328) as if I import that directly, it raises the same errors. Currently have `numba=0.52` `llvmlite=0.35.0` `scanpy=1.7.1` `pynndescent=0.5.2` `umap-learn=0.5.1`. Rebuilding my environment from scratch and will update with a complete package list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893:231,down,downgrading,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893,4,"['down', 'error']","['downgrading', 'errors']"
Availability,"Faced exactly the same problem with file ""GSE185477_GSM3178784_C41_SC_raw_counts.zip"" from [GSE185477](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE185477). The advice from @hurleyLi helped, thanks a lot! But the error is quite confusing. It would be great to read files without extra actions for the user, but is it possible to at least change the error message? E.g.; ```python; try:; ....; except KeyError:; raise KeyError(""Unexpected error, probably due to Cellranger version. Make sure to unarchive gzipped file coming from Cellranger v2""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1296918392:222,error,error,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1296918392,3,['error'],['error']
Availability,"False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:4672,error,error,4672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['error']
Availability,"Fidel, sorry to say, but I've run into some issues. Most of these actually didn't have to do with this PR, but were additional things that broke from #1499. I'll give you a few examples of what I've found, mostly by contrast with the current behaviour of 1.6.1. ```python; import scanpy as sc, pandas as pd, numpy as np. M, N = (5, 3); adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 3).reshape((M, 3)),; columns=[""repeated_col"", ""repeated_col"", ""var_id""],; index=pd.Index([f""cell_{i}"" for i in range(M)], name=""obs_index""),; ),; var=pd.DataFrame(; index=pd.Index([""var_id""] + [f""gene_{i}"" for i in range(N-1)], name=""var_index""),; ),; ); ```. ## Repeated column in `adata.obs`. I think this should be an error. This is because downstream functions (like plotting) currently assume that for each key input here, there will be one output column. Turns out this isn't exactly pandas behaviour with repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In thi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:732,error,error,732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,2,"['down', 'error']","['downstream', 'error']"
Availability,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict; self.fit(X); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit; self._min_spanning_tree) = hdbscan(X, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan; core_dist_n_jobs, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__; return self.func(*args, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree; tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs); File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__; File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric; TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-747903214:974,error,error,974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-747903214,1,['error'],['error']
Availability,"First of all congratulations for the awesome package, intuitive and works great. Just a suggestion if you have time to implement ridgeplots or joyplots like the ones available now in Seurat. They are useful to present several distributions in a compact (and attractive) way. Seems possible through the seaborn kdeplot functions (https://seaborn.pydata.org/examples/kde_joyplot.html). Just a suggestion, so feel free to close to issue at any point!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/84:166,avail,available,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/84,1,['avail'],['available']
Availability,"First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```; mamba create -yn scanpy-dev ""python=3.12""; conda activate scanpy-dev; pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster; conda deactivate scanpy-dev; conda activate scanpy-dev; pytest -n auto; ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```; pip install dask-expr; pytest -n auto; ```. <details>; <summary> Failures </summary>. ```; FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable; FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,2,"['Failure', 'error']","['Failures', 'error']"
Availability,"First, make sure your versions of numba and umap are up to date. Then running this without jupyter, just in python. I think jupyter is likely hiding whatever error the python process is crashing with. E.g.:. ```sh; $ python3 -c ""import numpy; import umap""; ```. If this fails, I think you should be opening an issue upstream with numba or umap (if you can figure out which one is at fault). I've had this sort of thing happen a few times. Some of the causes were:. * Multiple versions of C libraries being linked to; * Threading backends not working. I've been able to work around both of these in the past by using conda environments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-755097946:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-755097946,2,"['error', 'fault']","['error', 'fault']"
Availability,"Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1087:147,error,error,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087,1,['error'],['error']
Availability,Fix all the various test failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3124:25,failure,failures,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124,1,['failure'],['failures']
Availability,Fix clustermap error due to fillna call in seaborn.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['error'],['error']
Availability,Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120,1,['error'],['error']
Availability,Fix download path of pbmc3k_processed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472:4,down,download,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472,1,['down'],['download']
Availability,Fix ebi downloads,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1102:8,down,downloads,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102,1,['down'],['downloads']
Availability,Fix error formatting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2263:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2263,1,['error'],['error']
Availability,Fix isinstance arg 2 must be a type error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2209:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209,1,['error'],['error']
Availability,Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1934:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934,1,['error'],['error']
Availability,Fixes #1395. It looks like this code was originally added for dealing with the automatic flattening of `X` when indices had length 1. I also made it an error if there were no genes to score. Arguably it should be an error if any of the passed genes are missing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398:152,error,error,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398,2,['error'],['error']
Availability,"Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/155:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155,1,['error'],['error']
Availability,"Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test; 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case).; 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1548:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548,1,['error'],['error']
Availability,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1898:386,error,errors,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898,2,['error'],"['error', 'errors']"
Availability,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1893:88,error,error,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893,1,['error'],['error']
Availability,"Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2466:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466,1,['error'],['error']
Availability,"Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS; - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst; Compute distances and connectivities of neighbors. Parameters; ----------; n_neighbors; Use this number of nearest neighbors.; knn; Restrict result to `n_neighbors` nearest neighbors.; {n_pcs}; {use_rep}. Returns; -------; Writes sparse graph attributes `.distances` and `.connectivities`.; Also writes `.knn_indices` and `.knn_distances` if; `write_knn_indices==True`.; ```. <p align=center>↓↓↓</p>. ```rst; Compute distances and connectivities of neighbors.; Parameters; ----------; n_neighbors : int, optional (default: 30); Use this number of nearest neighbors.; knn : bool, optional (default: True); Restrict result to `n_neighbors` nearest neighbors.; n_pcs : `int` or `None`, optional (default: `None`); Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`.; use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`); Use the indicated representation. If `None`, the representation is chosen; automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used.; If 'X_pca' is not present, it's computed with default parameters.; Returns; -------; Writes sparse graph attributes `.distances` and `.connectivities`.; Also writes `.knn_indices` and `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192:401,avail,available,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192,1,['avail'],['available']
Availability,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941:267,error,errors,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941,1,['error'],['errors']
Availability,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182:158,avail,available,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182,1,['avail'],['available']
Availability,Fixes scanpy import error on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585,1,['error'],['error']
Availability,Fixes the current test failures. I could also do a simpler version where I just rechunk in one way instead of adding parameters here.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162:23,failure,failures,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162,1,['failure'],['failures']
Availability,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2421:123,error,error,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421,2,['error'],['error']
Availability,"Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master ; python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total; isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master ; Switched to branch 'defer-umap'; Your branch is up to date with 'origin/defer-umap'.; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap ; python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704:49,down,down,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704,1,['down'],['down']
Availability,"Follow up to https://github.com/scverse/scanpy/pull/3275#pullrequestreview-2392213666. I think that this woulda worked regardless because the `try` will define it initially anyways. However, it's best practice to only have code that can error in the `try` statement. I'll allow myself to skip a release note etc because this is minor and there hasn't been a release yet with this fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3315:237,error,error,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315,1,['error'],['error']
Availability,Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets.; This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506:159,avail,available,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506,1,['avail'],['available']
Availability,"Following up on #242. Here's my solution to the current queries being pretty unreliable for me (due to issue with bioservices module). It's all a pretty thin wrapper around `pybiomart`, which has a nice API and is well tested but has maintenance issues. . Currently I've replaced the `gene_coordinates` query with a more generic `biomart_annotations` – the example covers the functionality of `gene_coordinates`. I'm debating how to add tests given that they're network based (could fail when nothing is wrong with the code) and can take a while.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467:234,mainten,maintenance,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467,1,['mainten'],['maintenance']
Availability,"For context, the option was added in #334, and I think the scope for other feature types was much more limited at the time. > Would it already be worth either making gex_only a required input?. I'm not sure the `gex_only` argument even entirely makes sense anymore. I think a `feature_type` argument would make more sense. Erroring if nothing is passed and there are multiple kinds sounds reasonable to me, as multimodality should be handled explicitly. For backwards compatibility I think deprecation warnings for a release cycle when either `gex_only` is used or nothing is passed and there are multiple feature types present could work. -----------. Moving the 10x reading functions had been discussed in: #1387",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528:323,Error,Erroring,323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528,1,['Error'],['Erroring']
Availability,"For incremental PCA: `sc.tl.pca(adata, n_comps=ndim, chunked=True)`; sometimes, the number of samples for the last chunk is smaller than ndim, an error would be throw:; ```pytb; File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/pym3c/clustering.py:377, in run_dimension_reduction(***failed resolving arguments***); 375 if not downsample or obs_chunk_size > downsample or adata.n_obs < downsample:; 376 logger.info(f""Running IncrementalPCA without downsampling""); --> 377 sc.tl.pca(adata, n_comps=ndim, chunked=True,; 378 chunk_size=obs_chunk_size); 379 else: # downsample; 380 logger.info(f""Running IncrementalPCA with downsample = {downsample}""). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py:255, in pca(***failed resolving arguments***); 253 for chunk, _, _ in adata_comp.chunked_X(chunk_size):; 254 chunk = chunk.toarray() if issparse(chunk) else chunk; --> 255 pca_.partial_fit(chunk); 257 for chunk, start, end in adata_comp.chunked_X(chunk_size):; 258 chunk = chunk.toarray() if issparse(chunk) else chunk. File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/base.py:1473, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs); 1466 estimator._validate_params(); 1468 with config_context(; 1469 skip_parameter_validation=(; 1470 prefer_skip_nested_validation or global_skip_validation; 1471 ); 1472 ):; -> 1473 return fit_method(estimator, *args, **kwargs). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/decomposition/_incremental_pca.py:304, in IncrementalPCA.partial_fit(self, X, y, check_input); 298 raise ValueError(; 299 ""n_components=%r invalid for n_features=%d, need ""; 300 ""more rows than columns for IncrementalPCA ""; 301 ""processing"" % (self.n_components, n_features); 302 ); 303 elif not self.n_components <= n_samples:; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227:146,error,error,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227,8,"['down', 'error']","['downsample', 'downsampling', 'error']"
Availability,"For me is working properly with an earlier version of scanpy and the same matplotlib version. Can you downgrade and test if the problem is only happening in the last version. Also, you can try to see if the problem is related to some matplotlib parameters by resetting them.; ```PYTHON; matplotlib.rcdefaults(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688:102,down,downgrade,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688,1,['down'],['downgrade']
Availability,"For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-870384617:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-870384617,1,['error'],['error']
Availability,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2364261485:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2364261485,1,['error'],['error']
Availability,"For me,; adata[(adata[:,'elav'].X>0).flatten(), : ] works. otherwise, it gives error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/599#issuecomment-609054998:79,error,error,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-609054998,1,['error'],['error']
Availability,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822057782:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822057782,1,['error'],['error']
Availability,"For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2112892549:48,down,down,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2112892549,1,['down'],['down']
Availability,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960:100,avail,available,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960,1,['avail'],['available']
Availability,Found the problem. I was running the library using python v3.9 with numba v0.51. Compatibility for python 3.9 is only available in the (currently) latest version of numba v0.53. . This incompatibility generated the crash in the pynndescent library. Why it worked for certain sizes and no other remains a mistery...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-779686831:118,avail,available,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-779686831,1,['avail'],['available']
Availability,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group); 531 if encoding_type:; --> 532 EncodingVersions[encoding_type].check(; 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name); 356 def __getitem__(cls, name):; --> 357 return cls._member_map_[name]; 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,3,"['Error', 'error']","['Error', 'error']"
Availability,"Fresh install in a new env gives me the same error (jupyter kernel crashes):; ```; conda create --name squidpy python=3.8 seaborn scikit-learn statsmodels numba pytables; conda activate squidpy; conda install -c conda-forge leidenalg python-igraph; pip install scanpy squidpy imctools stardist; ```; And here's the `sc.logging.print_versions()`:; ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.5; cmocean 2.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.2; fasteners NA; get_version 2.1; h5py 2.10.0; highs_wrapper NA; igraph 0.8.3; imagecodecs 2020.12.24; imageio 2.9.0; ipykernel 5.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.52.0; numcodecs 0.7.3; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; pywt 1.1.1; scanpy 1.7.1; scipy 1.6.0; seaborn 0.11.1; sinfo 0.3.1; six 1.15.0; skimage 0.18.1; sklearn 0.24.1; squidpy 1.0.0; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tifffile 2021.3.5; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; xarray 0.17.0; yaml 5.4.1; zarr 2.6.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-glibc2.10; 72 logical CPU cores, x86_64; -----; Session information updated at 2021-03-12 11:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745,2,['error'],['error']
Availability,"From slack, @ilan-gold mentioned that the median calculation I suggested may not work (https://dask.discourse.group/t/median-with-masked-array-behaves-unexpectedly/70). It could be replaced with something like:. ```python; da.from_delayed(; delayed(np.median)(; delayed(counts[counts > 0]); ),; shape=(),; meta=np.ndarray,; dtype=counts.dtype,; ); ```. Or probably better:. ```python; def nonzero_median(x):; return np.ma.median(np.ma.masked_array(x, x > 0)). da.from_delayed(; delayed(nonzero_median)(counts),; shape=(),; meta=np.ndarray,; dtype=counts.dtype,; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981060407:130,mask,masked-array-behaves-unexpectedly,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981060407,1,['mask'],['masked-array-behaves-unexpectedly']
Availability,"From the error message, you may want to try to convert the dense matrix to sparse matrix format as follows:. ```python; from scipy.sparse impor csr_matrix; adata.X = csr_matrix(adata.X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-778224048:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-778224048,1,['error'],['error']
Availability,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo; Can you post this error with a reproducible example in scvelo repo ?. Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1433#issuecomment-704248522:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433#issuecomment-704248522,1,['error'],['error']
Availability,"GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:2924,toler,tolerance,2924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['toler'],['tolerance']
Availability,"GSE145328 is from NCBI GEO. [GSE139555_RAW.tar](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE139555) is another example that gives the same error. These are the output files generated by Cell Ranger and uploaded to NCBI GEO, based on the authors' notes in their [paper](https://www.nature.com/articles/s41586-020-2056-8). . Some examples from NCBI GEO that can be read without errors: [GSE173231](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173231) and [GSE158803](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE158803).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-874096004:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-874096004,2,['error'],"['error', 'errors']"
Availability,Gene filtering using sparse matrix error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1354:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354,1,['error'],['error']
Availability,Get errors when performing sc.pp.highly_variable_genes!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:4,error,errors,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,1,['error'],['errors']
Availability,Getting Error Variable names are not unique when using .read_10x_h5 function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/534:8,Error,Error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/534,1,['Error'],['Error']
Availability,Getting errors when loading loom files,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247:8,error,errors,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247,1,['error'],['errors']
Availability,"Getting the error: ""numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)"" when running sc.tl.umap with init_pos='paga'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,2,['error'],"['error', 'errors']"
Availability,"Getting the following error with the latest version of scanpy:. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-24-7f6e74b434f4> in <module>; ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10); 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1369:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369,1,['error'],['error']
Availability,Github actions are down. It seems like they have problems at least once a week: https://twitter.com/githubstatus. I'd be fine with having pre-commit be a required check. I'm a little antsy about having something that goes down frequently be required though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-787870905:19,down,down,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-787870905,2,['down'],['down']
Availability,Github install error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482,1,['error'],['error']
Availability,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895,5,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Good Evening,. My goal here is to get either a Gene barcode or dense matrix from a .h5 file from 10x. I'm currently trying to use the .read_10x_h5() function to help me achieve this. To my understanding I just need to input the file name into the function. When I run my code (See below), I get an error stating that ""Variable names are not unique. To make them unique, call `.var_names_make_unique`."" From the documentation I don't see a way that I can call .var_names_make_unique(). Is there some preprocessing that I'm missing?. ```python; user_input = input(""Enter the path of your file: ""); def convert_h5_to_adata(filename):; filename = str(filename); if os.access(filename, os.R_OK):; sc.read_10x_h5(filename); return; convert_h5_to_adata(user_input); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/534:298,error,error,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/534,1,['error'],['error']
Availability,"Good day!. I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">; <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:; `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`; `adata = adata[adata.obs['mt_frac'] < 0.2]; print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`; `sc.pp.filter_cells(adata, min_genes = 700); print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/751:689,error,error,689,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751,1,['error'],['error']
Availability,"Good to hear! Looking forward to learning more about it.; PS: Having a doublet detection tool in `tl` would be fine, I'd say... `pp` and `tl` are just meant to give a rough orientation for users... in some cases, it's not completely clear what *preprocessing* and what *downstream* analysis is...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845:270,down,downstream,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845,2,['down'],['downstream']
Availability,"Great that you fixed it! :). I'm in principle happy to merge the pull request! However, it contains a lot of the previous commits to master by other people; maybe you haven't properly rebased your branch to master at some point? Looking at the diff across the whole request, I see mostly old things from the 25 commits before. So, (1) could you point me to the diff across all your commits that you actually did? (2) Are we going to have a messed up history with redundant commits on the master branch if I merge this, I don't think so, but I'm not 100% sure. Sorry for the additional work, but blindly merging something into master is of course too dangerous, and going through each single commit is too tedious. ;). Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906:463,redundant,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906,1,['redundant'],['redundant']
Availability,"Great to hear! Usually when there’s weird, site-specific errors, I say I can’t help because I don’t have SSH access and “my crystal ball is currently out of order”. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146:57,error,errors,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146,1,['error'],['errors']
Availability,"Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM.; Is there a way to decrease memory usage?; I would appreciate your advice!; Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/710:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710,1,['error'],['error']
Availability,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155,1,['error'],['error']
Availability,"Great!. I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726498381:198,error,error,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726498381,1,['error'],['error']
Availability,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:688,avail,available,688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809,2,['avail'],['available']
Availability,"Great, thanks @LuckyMD! That makes a lot of sense. Aside from diffxpy, are there other packages you recommend for more robust DE approaches in these (or related) scenarios? Thanks again for your advice - and sorry for hijacking this conversation!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029:119,robust,robust,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029,1,['robust'],['robust']
Availability,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-661224338:106,error,errors,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-661224338,2,['error'],['errors']
Availability,"Great. Please ping me here when you upload the file to `scanpy_usage` and feel free to close the issue then. I'll update my script to link directly to `scanpy_usage`. > Regarding the result: the high PCs can change drastically depending on the platform and the random seed. I've seen clustering results changing completely after I became aware of it. . I don't have much experience with randomized PCA, but this is very disturbing, no? Was your feeling that the PCs themselves changed strongly (as measured, I don't know, by the %% of total captured variance, or maybe angle between subspaces, etc.), or is it rather that clustering outcome is dangerously sensitive to small changes in the data? I think this is something worth investigating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047:14,ping,ping,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047,1,['ping'],['ping']
Availability,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. ; What I did : ; - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently); - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf).; How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot); Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183,1,['error'],['error']
Availability,"HI, I tried to do what you suggested but I am getting an error saying `ValueError: only one regex group is supported with Index`.; I have multiple h5ad files with varying n_obs × n_vars. Here is my code:; ```adatas = [an.read_h5ad(filename) for filename in filenames]; batch_names = []; for i in range(len(adatas)):; adatas[i].var_names_make_unique(); batch_names.append(filenames[i].split('.')[0]); print(i,adatas[i]). adata = adatas[0].concatenate(adatas[1:],; batch_key = 'ID',; uns_merge=""unique"",; index_unique=None,; batch_categories=batch_names); ``` . and this produces the above error. Can anyone help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-1431464728:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-1431464728,2,['error'],['error']
Availability,"HI, I tried to do what you suggested but I am getting an error saying `ValueError: only one regex group is supported with Index`.; I have multiple h5ad files with varying n_obs × n_vars. Here is my code:; ```adatas = [an.read_h5ad(filename) for filename in filenames]; batch_names = []; for i in range(len(adatas)):; adatas[i].var_names_make_unique(); batch_names.append(filenames[i].split('.')[0]); print(i,adatas[i]). adata = adatas[0].concatenate(adatas[1:],; batch_key = 'ID',; uns_merge=""unique"",; index_unique=None,; batch_categories=batch_names); ```. and this produces the above error. Can anyone help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1431472348:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1431472348,2,['error'],['error']
Availability,"Ha, no I'm not on the mattermost. ivirshup@gmail.com. Though if you could cut down the dataset to something small and more shareable that would be helpful as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-826441704:78,down,down,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-826441704,1,['down'],['down']
Availability,"Ha, that’s what I meant, that you said it doesn’t make sense. > If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. I very much agree!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456793309:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456793309,1,['error'],['error']
Availability,"Had same problem. It seems it tries to look for all gene names present in the anndata object,; rather than the cell cycle genes that are requested?. I have previously checked that the s_genes and g2m_genes in call; sc.tl.score_genes_cell_cycle(gdata, s_genes=s_found, g2m_genes=g2m_found); are in the data. use_raw=False ; makes it run without error. Error message below. Note that printout of gene names in data at the beginning matches the list of keyErrors it spits out. ```; Gene_names_in_data:; Index(['HES4', 'C1orf159', 'TNFRSF18', 'TNFRSF4', 'ATAD3C', 'PRKCZ',; 'AL365255.1', 'GPR153', 'TNFRSF25', 'DNAJC11',; ...; 'MCF2', 'SPANXA2-OT1', 'AFF2', 'LINC00894', 'MAMLD1', 'PDZD4', 'F8',; 'TMLHE-AS1', 'PRKY', 'UTY'],; dtype='object', length=3658). calculating cell cycle phase; computing score 'S_score'; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-82-30815e6b6381> in <module>; 20 print(gdata.var.index); 21 ; ---> 22 sc.tl.score_genes_cell_cycle(gdata, s_genes=s_found, g2m_genes=g2m_found); 23 ; 24 gdata.obs[""cellcycle""] = gdata.obs[""phase""]. ~/.pyenv/versions/6_tes/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs); 250 # add g2m-score; 251 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). ~/.pyenv/versions/6_tes/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 128 _adata = adata.raw if use_raw else adata; 129 ; --> 130 _adata_subset = _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata; 131 if issparse(_adata_subset.X):; 132 obs_avg = pd.Series(. ~/.pyenv/version",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-767782350:344,error,error,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-767782350,2,"['Error', 'error']","['Error', 'error']"
Availability,"Had this issue again recently using python 3.7, and the solution above wasn't enough to solve it. Turns out I also needed to download the tables .whl file: `pip install .\h5py-2.10.0-cp37-cp37m-win_amd64.whl .\tables-3.6.1-cp37-cp37m-win_amd64.whl numpy==1.20.0 --user --force-reinstall`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488:125,down,download,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488,1,['down'],['download']
Availability,"Hah, I've gotten much better at numba since I wrote this function. I figured out I can just get the core part to work on floats and don't have to worry about casting between types. Makes this a much easier decision. Now floats aren't converted to integers in the first place. > We should also take care not to downcast more incompatible types: int32 can be expressed as float64, but not in float32. int64 has to stay int64. I think we can be a little flexible on this, and just generally follow numpy promotion rules (except for when they're bad).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-558449713:310,down,downcast,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-558449713,1,['down'],['downcast']
Availability,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702:177,down,downgrades,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702,1,['down'],['downgrades']
Availability,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once?. -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold; * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function?. > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448:1055,avail,available,1055,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448,2,['avail'],['available']
Availability,Has this error been fixed? Facing the same issue for scanpy version 1.7.2,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-876093110:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-876093110,1,['error'],['error']
Availability,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:9,reboot,rebooted,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185,4,"['error', 'reboot']","['error', 'errors', 'rebooted']"
Availability,"Haven't done much investigation into why, but the [Fly Cell Atlas](https://flycellatlas.org) head dataset (10x, Stringent, H5AD) causes `sc.tl.embedding_density` to error when `groupby=""annotation_broad_extrapolated""`. ```python; import scanpy as sc; # Warning: 2.5gb; !wget -O s_fca_biohub_head_10x.h5ad https://cloud.flycellatlas.org/index.php/s/LAEybPc2HZnpzKs/download. adata = sc.read_h5ad(""s_fca_biohub_head_10x.h5ad""); sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""); ```. <details>; <summary> traceback </summary>. ```pytb; /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py:563: RuntimeWarning: Degrees of freedom <= 0 for slice; self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,; /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide; c *= np.true_divide(1, fact); /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply; c *= np.true_divide(1, fact); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_4569/1429565136.py in <module>; ----> 1 sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""). ~/github/scanpy/scanpy/tools/_embedding_density.py in embedding_density(adata, basis, groupby, key_added, components); 164 embed_y = adata.obsm[f'X_{basis}'][cat_mask, components[1]]; 165 ; --> 166 dens_embed = _calc_density(embed_x, embed_y); 167 density_values[cat_mask] = dens_embed; 168 . ~/github/scanpy/scanpy/tools/_embedding_density.py in _calc_density(x, y); 19 # Calculate the point density; 20 xy = np.vstack([x, y]); ---> 21 z = gaussian_kde(xy)(xy); 22 ; 23 min_z = np.min(z). /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,2,"['down', 'error']","['download', 'error']"
Availability,"Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:; ```; sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5); ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-a78575d924b7> in <module>; 24 if len(markers) > 0:; 25 print(""Expression plots of "", names, "" markers: "", markers); ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5); 27 ; 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs); 27 If `show==False` a `matplotlib.Axis` or a list of it.; 28 """"""; ---> 29 return plot_scatter(adata, basis='umap', **kwargs); 30 ; 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 280 if sort_order is True and value_to_plot is not None and categorical is False:; 281 order = np.argsort(color_vector); --> 282 color_vector = color_vector[order]; 283 _data_points = data_points[component_idx][order, :]; 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 474 ; 475 # Perform the dataspace selection.; --> 476 selectio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/440:403,error,error,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440,1,['error'],['error']
Availability,"Hej all. it seems there is a problem on the batch correction with bbknn. It gives an error at the pca step of bbknn, but I have problem understanding if this is due to the bbknn package itself or the wrapper of scanpy around it, or if it is due to my data, even though it worked when I used it previously. ```python; sc.external.pp.bbknn(all_data_flt, batch_key='batch', n_pcs=15,); ```. gives the error. ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-23-a9dd619ada2e> in <module>; 1 #sc.neighbors.neighbors(all_data_flt, n_neighbors=40, n_pcs=15); ----> 2 sc.external.pp.bbknn(all_data_flt, n_pcs=15); 3 #sc.tools.umap(all_data_flt). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 params = locals(); 83 kwargs = params.pop('kwargs'); ---> 84 return bbknn(**params, **kwargs). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 215 batch_list = adata.obs[batch_key].values; 216 #call BBKNN proper; --> 217 bbknn_out = bbknn_pca_matrix(pca=pca,batch_list=batch_list,save_knn=save_knn,**kwargs); 218 #optionally save knn_indices; 219 if save_knn:. TypeError: bbknn_pca_matrix() got an unexpected keyword argument 'bbknn'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/514:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514,2,['error'],['error']
Availability,"Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```; sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') ; ```. or from non-raw data; ```; sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) ; ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:; ```; KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'; ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,; Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/438:415,error,error,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438,3,['error'],['error']
Availability,"Hej. I have been looking at the single-cell-tutorial repository and tried the `scran` normalization with `R`.; After calculating the size factors in `scran`, I use them to normalize cell-wise my data matrix following the tutorial commands:. ```; adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); ```; When I look for highly expressed genes with. `sc.preprocessing.highly_variable_genes(adata, n_top_genes=5000)`. I get this error (the error does not show up when I use the normalization command from `scanpy` instead of the normalization with size factors from `scran`):. ```; LinAlgError Traceback (most recent call last); <ipython-input-97-96c692867dde> in <module>; ----> 1 sc.preprocessing.highly_variable_genes(adultAll, n_top_genes=10000, flavor='cellranger'). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 101 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 102 ; --> 103 mean, var = materialize_as_ndarray(_get_mean_var(X)); 104 # now actually compute the dispersion; 105 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in __pow__(self, other); 226 ; 227 def __pow__(self, other):; --> 228 return matrix_power(self, other); 229 ; 230 def __ipow__(self, other):. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603 ;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,2,['error'],['error']
Availability,"Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py; >>> import os; >>> # p = os.path.join( ""path to outs location""); >>> print(p); ""path to outs location""; >>> print(os.path.exists(p)); True; >>> ad = sc.read_visium(p); ```. ```pytb; Traceback (most recent call last):. Cell In[6], line 1; ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium; raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'; ```. ### Session/scanpy info:; Software versions; Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]; IPython 8.10.0; OS Windows 10 10.0.22621 SP0; scanpy 1.9.3; Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2488:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488,1,['error'],['error']
Availability,Hello ; I did what you told me .. and I got this error. I changed the version of those . ![image](https://user-images.githubusercontent.com/48261734/65530250-302dbd80-debd-11e9-8026-761cd8571849.png). **matplotlib==3.1.1**. ![image](https://user-images.githubusercontent.com/48261734/65530196-17250c80-debd-11e9-8c19-986293e57d92.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534634792:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534634792,1,['error'],['error']
Availability,"Hello @Zethson ; Thanks for the response.; I read the paper. I understand that using the raw data to calculate the maker genes of clusters is an appropriate way, but the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting `use_raw=True`. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149460182-c5c11295-ca78-4bfe-aa8b-d13bade4b21f.png). Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791:406,down,downstream,406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791,1,['down'],['downstream']
Availability,"Hello @davidhbrann ,; Sorry for the late response.; I tried again without typing the `--user` in the Anaconda Powershell. Please see below. Step1: install without force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:779,Down,Downloading,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['Down'],['Downloading']
Availability,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251,2,['error'],"['error', 'errors']"
Availability,"Hello @ivirshup ,; Can you upzip these files? Please download all 7 files (.zip and .z01-.z06), and use winzip, winrar, 7-zip or bandizip to unzip the Downloads.zip file. It includes three h5ad files. I also share these three h5ad files into your gmail. I use `adata.write('C:/Users/Park_Lab/Documents/PC1.h5ad', compression='gzip')` to write these files.; And use `adata = sc.read('C:/Users/Park_Lab/Documents/PC1.h5ad')` to read these files. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654:53,down,download,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654,2,"['Down', 'down']","['Downloads', 'download']"
Availability,"Hello @ivirshup thanks for this!. Quick question (still very new to python). Upon following your suggestion I get this error:; AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then; import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562,1,['error'],['error']
Availability,"Hello Scanpy,; When I add parameter use_raw=False into sc.tl.rank_genes_groups() and sc.pl.rank_genes_groups_violin(), it generates errors as below.; ![image](https://user-images.githubusercontent.com/75048821/140627341-b0c08fbd-53b1-4ed8-b12d-9be71a65a6a5.png); ![image](https://user-images.githubusercontent.com/75048821/140627351-09708fcd-39ea-4602-8609-eca85ea6b843.png); ![image](https://user-images.githubusercontent.com/75048821/140627356-7faf0462-c852-436e-b69d-22f337dabae6.png). Another question is that, we shouldn't use the adata.raw for plotting becase the adata.raw doesn't regress out the mito gene expressions, should we?. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046:132,error,errors,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046,1,['error'],['errors']
Availability,"Hello Team,; I'm using the **sc.pp.downsample_counts** function on my adata in hopes of downsampling it to match that of another dataset. Running the function doesn't give any errors or seem to fail but when I check the total counts, there seems to be no change. . I'm wondering if there is a problem with my application or there is more going on. `sc.pp.downsample_counts(adata, total_counts=6900, random_state=0, replace=False, copy=False)`. My average total counts before and after running the function is 10000.; Any inputs would be greatly appreciated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2131:88,down,downsampling,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131,2,"['down', 'error']","['downsampling', 'errors']"
Availability,"Hello again, some months later. Unfortunately I haven’t used scanpy for a while and now I’m back I found that only two flavors are available for Louvain processing, `igraph` and `vtraag`. The latter allows for resolution parameter but relies on `python-louvain`, right? the reason for my “but” is that I’m having issues with that module on OSX, which I understand it is not a specific scanpy issue. I’ll ask again: what’s wrong with `networkx` and `community` modules? I’m asking because flavor `taynaud` is no more available",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-440373090:131,avail,available,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-440373090,2,['avail'],['available']
Availability,"Hello all,; For these 2 functions,; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; the authors make `inplace=True` as default. Because I want to tranfer the output into an variable, I change these functions to; ```python; a=sc.pp.filter_cells(adata, min_genes=200, inplace=False); sc.pp.filter_genes(a, min_cells=3, inplace=False); ```; but it creates errors and the output of a is NoType:; ```python; aceback (most recent call last):; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py”, line 3343, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File “”, line 2, in; sc.pp.filter_genes(a, min_cells=3, inplace=False) # exclude genes only expressed in <3 cells; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\scanpy\preprocessing_simple.py”, line 259, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ```. Does anybody know why inplace=False doesn’t work?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2030:391,error,errors,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030,1,['error'],['errors']
Availability,"Hello everyone !. I would like to use a custom distance when trying to compute the neighbors graph with `scanpy.pp.neighbors`.; So let's suppose I have a pre-existing distance matrix somewhere, and I just want to use it in the graph generation. Currently, I am getting an error when exceeding 4096 observations in my AnnData object.; I do not have such error when directly using the`umap` python package. ### Full error; ```bash; Traceback (most recent call last):; File ""/home/paul/Documents/Curie/Immunopeptidomics/minimal_bug_scanpy.py"", line 72, in <module>; sc.pp.neighbors(xd,; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,3,['error'],['error']
Availability,"Hello! I also have been running into issues when trying to use the `gene_symbols` parameter with the `sc.pl.dotplot()` function despite the column with the proper `gene_symbols` being in my `adata.var` Data Frame. . ```; $ adata.var.columns; $ sc.pl.dotplot(adata, marker_genes, 'clusters', dendrogram=True, gene_symbols='alternate_gene_symbols'). ==============================================================================. Index(['gene_symbols', 'feature_types', 'n_cells', 'highly_variable', 'means',; 'dispersions', 'dispersions_norm', 'mean', 'std',; 'alternate_gene_symbols'],; dtype='object'). ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621, in Index.get_loc(self, key, method, tolerance); 3620 try:; -> 3621 return self._engine.get_loc(casted_key); 3622 except KeyError as err:. File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:136, in pandas._libs.index.IndexEngine.get_loc(). File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:163, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:5198, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:5206, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'alternate_gene_symbols'; ... ```. When I tried setting `adata.var['gene_symbols'] = adata.var['alternate_gene_symbols']` and trying to generate a `dotplot` with a random gene present in `alternate_gene_symbols`, I ran into the following error: . ```; ...; KeyError: ""Could not find keys '['KH.C1.159.']' in columns of `adata.obs` or in adata.raw.var['gene_symbols'].""; ```. It seems that `sc.pl.dotplot()` is expecting `gene_symbols` that are present in the `adata.raw.var` Data Frame versus the `adata.var` Data Frame. Is this the expected behavior for this ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963:853,toler,tolerance,853,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963,1,['toler'],['tolerance']
Availability,"Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:541,error,error,541,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,2,"['Avail', 'error']","['Available', 'error']"
Availability,Hello!. Hoping to reopen this discussion as I've just encountered the same error whilst trying to do some label transfer via `scArches`. My reference object is [AIDA](https://data.humancellatlas.org/explore/projects/f0f89c14-7460-4bab-9d42-22228a91f185) PBMCs and my query data object is a combined object from [here](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA605083) and [here](https://ngdc.cncb.ac.cn/bioproject/browse/PRJCA003616). **Versions**; scanpy v1.9.3; scarches v0.5.9; anndata v0.9.2 ; numpy v1.24.4; pandas v2.0.3 ; scvi-tools v1.0.3,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2034#issuecomment-1678915525:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034#issuecomment-1678915525,1,['error'],['error']
Availability,"Hello!. I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: ; ```; sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations; plt.show(); plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric; sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters; sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'); plt.show(); plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric; sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification; sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'); plt.show(); plt.clf(); ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177:1290,down,down,1290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177,1,['down'],['down']
Availability,"Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error?. Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2156:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156,2,['error'],['error']
Availability,"Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3118:153,error,errors,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118,1,['error'],['errors']
Availability,"Hello, . I am using scanpy version 1.4 from bioconda. I am running one of the examples from the code to query datasets - . ```; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); print(pbmc); plotdf = sc.get.obs_df(; pbmc,; keys=[""CD8B"", ""n_genes""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); plotdf.plot.scatter(""X_umap0"", ""X_umap1"", c=""CD8B""); ```. the library can read the dataset but errors out saying `scanpy` has no attribute `get`. I even tried . ```File ""test.py"", line 2, in <module>; from scanpy.get import obs_df; ModuleNotFoundError: No module named 'scanpy.get'; ```. Did the API change for any of this ? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/851:390,error,errors,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851,1,['error'],['errors']
Availability,"Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions?. Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version; Scanpy version: 1.9.3; AnnData version: 0.9.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2489:369,error,error,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489,2,"['down', 'error']","['download', 'error']"
Availability,"Hello, . Whenever I try to plot gene expression I get the following KeyError, regardless of the gene/plotting function. I have confirmed that all genes I have tried do exist in adata.var_names. Id like to highlight that my adata object was created from h5ad converted from seurat. How can I check the keys? . Thank you!. Lucy. ---. ```python; sc.pl.draw_graph(myeloid, color=['SPP1']); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2645 try:; -> 2646 return self._engine.get_loc(key); 2647 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-94-440b32bde3cc> in <module>(); ----> 1 sc.pl.draw_graph(myeloid, color=['SPP1']). /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:627,toler,tolerance,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['toler'],['tolerance']
Availability,"Hello, ; I have run this command again in the fresh conda environment. Again I get the same error as before. AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-3-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028,1,['error'],['error']
Availability,"Hello, I am trying to calculate highly variable genes from my data sets using the above code from the scanpy script published on github. I am facing this error. could someone please help me with this? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1560:154,error,error,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560,1,['error'],['error']
Availability,"Hello, I am trying to use the visualize marker genes tutorial to make some plots. I am importing scanpy in the new way (import scanpy as sc) as suggested in the tutorial but I am getting an error message:. AttributeError Traceback (most recent call last); <ipython-input-5-dfc1e4d9ed06> in <module>(); ----> 1 ax = sc.pl.correlation_matrix(adata, 'cell_types'). AttributeError: module 'scanpy.plotting' has no attribute 'correlation_matrix'. Here are the versions of all the packages I am using:; scanpy==1.4 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Am I missing something ?. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544,1,['error'],['error']
Availability,"Hello, I am unable to import scanpy and the error message shows below:. ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>; from .compute.is_constant import is_constant; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>; from numba import njit; ImportError: cannot import name 'njit' from 'numba' (unknown location)```; ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2438:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438,1,['error'],['error']
Availability,"Hello, I am using the folder where I store the raw data for the analysis. There is no error message when I run the command but it does not generate any file or object with this name or any name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817682376:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817682376,1,['error'],['error']
Availability,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137,1,['error'],['error']
Availability,"Hello, I'm having a bit of trouble with this. I know the issues is closed, but I thought it might be better to continue this discussion rather than start a new one, though I can do that if you prefer. I have an AnnData object `adata` with ensembl ids as `adata.var_name` and mouse gene symbols under the column `adata.var[“gene_name”]`. When I call:; `sc.pl.umap(adata, color=['ENSMUSG00000074637'])`; It plots no problem. However, when I call:; `sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name')`; I get the following error:; ```; Traceback (most recent call last):. File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; return plot_scatter(adata, basis='umap', **kwargs). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; use_raw=use_raw, gene_symbols=gene_symbols). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; .format(value_to_plot, adata.obs.columns)). ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; 'louvain'],; dtype='object'); ```; Inspecting adata.var[""gene_name""] give:; ```; index; ENSMUSG00000002459 Rgs20; ENSMUSG00000033740 St18; ENSMUSG00000067879 3110035E14Rik; ENSMUSG00000025912 Mybl1; ENSMUSG00000016918 Sulf1; ENSMUSG00000025938 Slco5a1; ENSMUSG00000025930 Msc; ENSMUSG00000025921 Rdh10; ENSMUSG00000025777 Gdap1; ENSMUSG00000025776 Crispld1; ENSMUSG00000025927 Tfap2b; ENSMUSG00000025931 Paqr8; ENSMUSG00000026158 Ogfrl1; ...; ```; I'm not sure what I'm doing wrong here. I can do just about anything using the ensembl ids, but I am having a lot of trouble using the gene symbols. I would like to be abl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442:528,error,error,528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442,1,['error'],['error']
Availability,"Hello, everyone,. I am working om fly model. And I have met a problem when I was doing QC step use function pp.calculate_qc_metrics. I have got this error. Can anyone help me? Thanks. The code as follows: . ```python; adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-34-455e630e3278> in <module>; 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. ~\anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 51 return self._get_sliceXslice(row, col); 52 elif col.ndim == 1:; ---> 53 return self._get_sliceXarray(row, col); 54 raise IndexError('index results in >2 dimensions'); 55 elif row.ndim == 1:. ~\anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col); 314 ; 315 def _get_sliceXarray(self, row, col):; --> 316 return self._major_slice(row)._minor_index_fancy(col); 317 ; 318 def _get_arrayXint(self, row, col):. ~\anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx); 735 """"""; 736 idx_dtype = self.indices.dtype; --> 737 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259,1,['error'],['error']
Availability,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/853:135,down,downloaded,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853,5,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"Hello,. I am having a similar issue with `read_10x_mtx`, except my error is showing `Key Error: 1` and it is from 10X data we produced ourselves, do doesn't involve a GEO incompabitibility. Error below:. ```. >>> juno = sc.read_10x_mtx(path = ""../../Data/juno_influenza_pilot/hash_t_cells/umi_count""); Traceback (most recent call last):; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item; KeyError: 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 481, in read_10x_mtx; adata = read(; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 552, in _read_v3_10x_mtx; var_names = genes[1].values; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/frame.py"", line 3455, in __getitem__; indexer = self.columns.get_loc(key); File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hello,. I am having problems with reading in multiple h5 files using the code snipped that was posted by falexwolf. I am doing:; ```; filenames = ['./a.h5', './b.h5', './c.h5', './d.h5']; adatas = [sc.read_10x_h5(filename, gex_only = True) for filename in filenames]; adata = adatas[0].concatenate(adatas[1:], batch_key='gene_ids', batch_categories=filenames); ```. With or without the batch_key and batch_categories arguments I get the same error:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-20-e23ba2ca6e37> in <module>; 1 filenames = ['./a.h5', './b.h5', './c.h5', './d.h5']; 2 adatas = [sc.read_10x_h5(filename, gex_only = True) for filename in filenames]; ----> 3 adata = adatas[0].concatenate(adatas[1:], batch_key='gene_ids'). ~/anaconda3/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1764 fill_value=fill_value,; 1765 index_unique=index_unique,; -> 1766 pairwise=False,; 1767 ); 1768 . ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 817 # Annotation for other axis; 818 alt_annot = merge_dataframes(; --> 819 [getattr(a, alt_dim) for a in adatas], alt_indices, merge; 820 ); 821 . ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(index=new_index) for df in dfs]; 532 # New dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(inde",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:442,error,error,442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['error'],['error']
Availability,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252:768,error,error,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252,1,['error'],['error']
Availability,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) ; running Louvain clustering; using the ""louvain"" package of Traag (2017); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain; louvain.set_rng_seed(random_state); AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version?. thanks for your help,; Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-628933774:56,error,error,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-628933774,1,['error'],['error']
Availability,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293:276,error,error,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293,1,['error'],['error']
Availability,"Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.umap(adata, init_pos='paga', method='rapids'); ```. ```pytb; WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1837:227,error,error,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837,1,['error'],['error']
Availability,"Hello,. I just type ""import scanpy"", and it still shows the error message. . Here is my code. . ```py; import scanpy; ```. Here is what the computer showed after I ran this code:. ```pytb; AttributeError Traceback (most recent call last); <ipython-input-2-135279188441> in <module>; ----> 1 import scanpy. ~/Documents/scanpy/scanpy/scanpy/__init__.py in <module>; 34 # the actual API; 35 from ._settings import settings, Verbosity # start with settings as several tools are using it; ---> 36 from . import tools as tl; 37 from . import preprocessing as pp; 38 from . import plotting as pl. ~/Documents/scanpy/scanpy/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/Documents/scanpy/scanpy/scanpy/tools/_sim.py in <module>; 23 ; 24 from .. import _utils; ---> 25 from .. import readwrite; 26 from .._settings import settings; 27 from .. import logging as logg. ~/Documents/scanpy/scanpy/scanpy/readwrite.py in <module>; 7 import numpy as np; 8 import pandas as pd; ----> 9 import tables; 10 import anndata; 11 from anndata import (. ~/anaconda3/lib/python3.6/site-packages/tables/__init__.py in <module>; 91 ; 92 # Necessary imports to get versions stored on the cython extension; ---> 93 from .utilsextension import (; 94 get_pytables_version, get_hdf5_version, blosc_compressor_list,; 95 blosc_compcode_to_compname_ as blosc_compcode_to_compname,. tables/utilsextension.pyx in init tables.utilsextension(). ~/anaconda3/lib/python3.6/site-packages/tables/tables/__init__.py in <module>; 122 from .flavor import restrict_flavors; 123 from .description import *; --> 124 from .filters import Filters; 125 ; 126 # Import the user classes from the proper modules. ~/anaconda3/lib/python3.6/site-packages/tables/tables/filters.py in <module>; 27 from tables.req_versions import min_blosc_bitshuffle_version; 28 ;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/853#issuecomment-539798622:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853#issuecomment-539798622,1,['error'],['error']
Availability,"Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side.; Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz; > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2161:246,down,download,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161,1,['down'],['download']
Availability,"Hello,. I'm trying out the Graph abstraction and I get this error:; ```; SetKeyError Traceback (most recent call last); <ipython-input-12-928a85d4478e> in <module>(); ----> 1 sc.tl.tsne(adata); 2 sc.tl.draw_graph(adata, random_state=5) # random_state just makes a cosmetic change; 3 sc.write('krumsiek11_blobs', adata). ~/Downloads/scanpy/scanpy/tools/tsne.py in tsne(adata, n_pcs, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, recompute_pca, n_jobs, copy); 108 X_tsne = tsne.fit_transform(X); 109 # update AnnData instance; --> 110 adata.smp['X_tsne'] = X_tsne # annotate samples with tSNE coordinates; 111 logg.info(' finished', t=True, end=' '); 112 logg.info('and added\n'. ~/Downloads/scanpy/scanpy/data_structs/ann_data.py in __setitem__(self, keys, values); 382 # TODO: need to reallocate memory; 383 # or allow storing objects, or use pd.dataframes; --> 384 raise SetKeyError(k, v.dtype, self.dtype[k]); 385 super(BoundStructArray, self).__setitem__(k, v); 386 . SetKeyError: Currently you cannot implicitly reallocate memory:; Setting the array for key X_tsne001of002 with dtype float64 requires too much memory, you should init AnnData with a large enough data type from the beginning.; Probably you try to assign a string of length 8 although the array can only store strings of length 4.; ```. I'm using the latest git version of scanpy.; Any ideas?; Best wishes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40,3,"['Down', 'error']","['Downloads', 'error']"
Availability,"Hello,. I've tried setting up your package via pip, as instructed. This crashed out very quickly:. 	mib111492i:~ kp9$ pip install scanpy; 	Collecting scanpy; 	 Downloading scanpy-0.2.9.1.tar.gz (208kB); 		100% |################################| 215kB 2.8MB/s ; 		Complete output from command python setup.py egg_info:; 		Traceback (most recent call last):; 		 File ""<string>"", line 1, in <module>; 		 File ""/private/tmp/pip-build-cx2i4lbu/scanpy/setup.py"", line 39, in <module>; 			readme = readme_f.read(); 		 File ""/Users/kp9/anaconda3/lib/python3.6/encodings/ascii.py"", line 26, in decode; 			return codecs.ascii_decode(input, self.errors)[0]; 		UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); 	; 		----------------------------------------; 	Command ""python setup.py egg_info"" failed with error code 1 in /private/tmp/pip-build-cx2i4lbu/scanpy/. The offender seems to be the stylised README file, so I downloaded the source code, got rid of it, and proceeded with the installation. I'm unsure how representative the following encountered issues are of an ideal pip installation, but I figured I'd bring them to your attention anyway just in case they're relevant:. - h5py crashed out on account of not having hdf5 available. This was remedied via `brew install hdf5`, and it seems like the most likely of these issues to affect other users.; - The installer ignored my 2.1.0 setup of matplotlib, tried to install 2.0.0 in some weird way and crashed out. Installing 2.0.0 via pip (absolutely painlessly, mind you - what was that weird installer that crashed the thing out?) allowed the setup to proceed past this point. This might be an isolated incident, but it seemed weird enough to alert you of just in case.; - As is, louvain crashes immediately and uninformatively when attempts are made to pip it in. Installing from the GitHub source code still works fine though. I'll notify the louvain team of this situation, but this may be of relevan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49:160,Down,Downloading,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49,4,"['Down', 'down', 'error']","['Downloading', 'downloaded', 'error', 'errors']"
Availability,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092:452,error,error,452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092,1,['error'],['error']
Availability,"Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue?. Attached error. Any suggestions? ; Thanks!. <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769,3,['error'],['error']
Availability,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values.; I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1287#issuecomment-706185841:225,avail,available,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287#issuecomment-706185841,1,['avail'],['available']
Availability,"Hello,. my issue is similar to the ones above, so I hope you can help me with that. I tried to read in some sample data from a liver cell database ([Liver Cell Atlas](https://www.livercellatlas.org/download.php)) with the function sc.read_10x_mtx. When I pass in the data just like that, I get a KeyError: 1. ; I adjusted the file to have two more columns (with numbers 1:x as gene IDs and a feature types column with ""Gene Expression"" in all rows) , but then I get the following Error: ValueError: Length of passed value for var_names is 31054, but this AnnData has shape: (389056, 31053). I think this is because the function treats the column names as values, but I don’t know why. When I look at the features file with pandas, it is displayed correctly. Any suggestions? Thanks a lot in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1551477163:198,down,download,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1551477163,2,"['Error', 'down']","['Error', 'download']"
Availability,"Hello,; I am also getting the ""'tuple' object has no attribute 'tocsr'"" error and appreciate your help with that. I am using the latest scanpy and numpy:. scanpy==1.4.4.post1; numpy==1.18.2. The full command and error:; ```; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps=15); sc.pp.neighbors(adata_pp); sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5); ```. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-13-50ed2ff29926> in <module>; 4 sc.pp.log1p(adata_pp); 5 sc.pp.pca(adata_pp, n_comps=15); ----> 6 sc.pp.neighbors(adata_pp); 7 sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5). /Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. /Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611248366:72,error,error,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611248366,2,['error'],['error']
Availability,"Hello,; I am now facing a problem of failure in computing neighbours when using scanpy or scvelo; when I tried to use the . `sc.pp.neighbors(labelled, n_neighbors=5, n_pcs=4)`; or; `scv.pp.moments(raw, n_pcs=30, n_neighbors=30)`; it will always reports that. ```pytb; `computing neighbors; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-37-db298150880d> in <module>; ----> 1 scv.pp.moments(raw, n_pcs=30, n_neighbors=30). ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/moments.py in moments(data, n_neighbors, n_pcs, mode, method, use_rep, use_highly_variable, copy); 62 ; 63 if n_neighbors is not None and n_neighbors > get_n_neighs(adata):; ---> 64 neighbors(; 65 adata,; 66 n_neighbors=n_neighbors,. ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/neighbors.py in neighbors(adata, n_neighbors, n_pcs, use_rep, use_highly_variable, knn, random_state, method, metric, metric_kwds, num_threads, copy); 161 warnings.simplefilter(""ignore""); 162 neighbors = Neighbors(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:37,failure,failure,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,4,"['error', 'failure']","['errors', 'failure']"
Availability,"Hello,; I am trying to use the wrapper class and I am getting error; RRuntimeError: Error in `[.data.frame`(meta.data, , ii, drop = FALSE) : ; undefined columns selected; Could you please suggest me what should I do; Its on line ro.r('seurat_obj = as.Seurat(adata, counts=""X"",data=NULL)'); Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-982525338:62,error,error,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-982525338,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hello,; I've gotten scanpy working on my local computer, but for memory reasons I need to move to our server (linux). I am running into the same errors as above - any advice is appreciated!. Skipping optional fixer: buffer; Skipping optional fixer: idioms; Skipping optional fixer: set_literal; Skipping optional fixer: ws_comma; running build_ext; Cannot find the C core of igraph on this system using pkg-config.; We will now try to download and compile the C core from scratch.; Version number of the C core: 0.7.1.post6; We will also try: 0.7.1; ; Version 0.7.1.post6 of the C core of igraph is not found among the nightly builds.; Use the --c-core-version switch to try a different version.; ; Could not download and compile the C core of igraph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-518220318:145,error,errors,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-518220318,3,"['down', 'error']","['download', 'errors']"
Availability,"Hello,; This command (sc.logging.print_versions()) gives me the error pasted below:; AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-19-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246,1,['error'],['error']
Availability,"Hello,; When I call 'dpt_scatter' with the groups parameter I get the following error:; NameError: name 'names' is not defined. It looks like this is from line 230 in scanpy/plotting/ann_data.py and the 'names' variable just doesn't exist.; I'm assuming it should just be 'groups'?. Thanks,; Sarah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32,1,['error'],['error']
Availability,"Hello,; it's me again, really thanks for your kindly reply before.; when I analyze my own data using `sc.tl.dpt` with default `n_branches`, it worked well, but when I set `n_branches` more than 0, it occurred an error:; ```no root cell found, no computation of pseudotime; --> To enable computation of pseudotime, pass the index or expression vector; of a root cell. Either add; adata.add['iroot'] = root_cell_index; or (robust to subsampling); adata.var['xroot'] = adata.X[root_cell_index, :]; where ""root_cell_index"" is the integer index of the root cell, or; adata.var['xroot'] = adata[root_cell_name, :].X; where ""root_cell_name"" is the name (a string) of the root cell.; perform Diffusion Pseudotime analysis; using ""X_pca"" for building graph; using stored data graph with n_neighbors = 30 and spectrum; [ 1. 0.9944264293 0.9934666753 0.9925051928 0.9899699688; 0.9893597364 0.9855745435 0.9840251803 0.981688261 0.9806631804]; detect 1 branching; do not consider groups with less than 2742 points for splitting; branching 1: split group 0; WARNING: detected group with only [] cells. ValueError Traceback (most recent call last); <ipython-input-3-b1749d943ac4> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', 'sc.tl.dpt(adata_corrected,n_jobs=48,n_pcs=30,allow_kendall_tau_shift=False,n_branchings=1)\nsc.logging.print_memory_usage()'). /public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self, magic_name, line, cell); 2113 magic_arg_s = self.var_expand(line, stack_depth); 2114 with self.builtin_trap:; -> 2115 result = fn(magic_arg_s, cell); 2116 return result; 2117 . <decorator-gen-59> in time(self, line, cell, local_ns). /public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k); 186 # but it's overkill for just that one bit of state.; 187 def magic_deco(arg):; --> 188 call = lambda f, *a, **k: f(*a, **k); 189 ; 190 if callable(arg):. /pu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33:212,error,error,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33,2,"['error', 'robust']","['error', 'robust']"
Availability,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,10,['error'],"['error', 'errors']"
Availability,"Hello. I tried umap visualization by:. ```; sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None); sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0); sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'); ```; But the cells can't separate well; ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version; ```; anndata 0.7.5; scanpy 1.6.1; ```. I tried another small dataset with `scanpy` using the same parameters as before:; ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper); ```. Now the original `umap` package can do down dimension very well:; ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason?; Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386:942,down,down,942,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386,2,['down'],['down']
Availability,"Hello.; I need some help with this issue. when I run this line, I got an error. . ```py; sc.pl.paga(; adata,; threshold=0, ; solid_edges='connectivities_tree',; dashed_edges='connectivities', ; root='neoblast 1',; layout='rt_circular',; node_size_scale=0.5,; node_size_power=0.9,; max_edge_width=0.7,; fontsize=3.5,; ); ```. ![error](https://user-images.githubusercontent.com/48261734/63892645-beda1800-c9ad-11e9-8f04-f13a5b7a8812.jpg). thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909,2,['error'],['error']
Availability,"Here is the summary:; * `_set_default_colors_for_categorical_obs()` moved from scatterplots to _utils. No modifications; * `_set_colors_for_categorical_obs()` moved from scatterplots to _utils. No modifications; * `_validate_palette()` function added, extracting the relevant code from `scatterplots.py:_get_color_values()`; * `adjust_palette()` was removed as this functionality is replicated to some extent by `_set_default_colors_for_categorical_obs()`; * `add_colors_for_categorical_sample_annotation()` was simplified by using the above functions. FYI: the error from `sc.pl.paga` that I had was caused because the expected output of `adjust_palette()` was `Cycler` but the function actually returned the original type of `palette` which could be `ListedColorMap`, `cabc.Sequence` or `Cycler`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/869#issuecomment-540517150:562,error,error,562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869#issuecomment-540517150,2,['error'],['error']
Availability,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb; Initial shape: 737280x28002; After min_genes: 5128x28002; After max_genes: 1431x28002; Traceback (most recent call last):; File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>; sc.pp.filter_genes(adata, min_cells=3); File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes; adata.var['n_cells'] = number; File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item; value = self._sanitize_column(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column; value = _sanitize_index(value, self.index, copy=False); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index; raise ValueError('Length of values does not match length of ' 'index'); ValueError: Length of values does not match length of index; ```. Note that this same error displays on both of the following lines:. ```python; sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_genes(adata, max_cells=1000); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317:1133,error,error,1133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317,2,['error'],['error']
Availability,"Here's a link to the docs [https://scanpy.readthedocs.io/](), it's also available at the top of the github repo. EDIT: Whoops, posted some wrong info about how 10x pre v3 datasets are read before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-480108879:72,avail,available,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-480108879,1,['avail'],['available']
Availability,"Here's some initial distribution plots for comparison:. Legend: ; - red lines are 0.5% and 99.5% quantiles, a trick used in some cytof papers to deal with extreme outliers (believed to be technical artifacts); here, I simply use it to move the bulk of the data in visible range for the first two plots; while the values are merely a heuristic, the spirit of it follows nonparametric statistics so is pretty reliable in practice. ### raw (ADT counts):; ![image](https://user-images.githubusercontent.com/20694664/83345454-4956fb80-a2e1-11ea-8ae7-e13dfcc10cac.png). ### geometric mean (as used in Issac's notebook); ![image](https://user-images.githubusercontent.com/20694664/83345468-6f7c9b80-a2e1-11ea-8a42-acad50bfb66b.png). seems to only changes the scale, not the shape, so unless I made an error in implementation... it's probably not useful. ### simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![im",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:407,reliab,reliable,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,4,"['error', 'reliab']","['error', 'reliable']"
Availability,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:713,down,down-weighted,713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720,2,"['down', 'robust']","['down-weighted', 'robust']"
Availability,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-244-764977f87ce6> in <module>; ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'); 2 sc.pp.pca(ad_sub); 3 sc.pp.neighbors(ad_sub); 4 sc.tl.umap(ad_sub); 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'; ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-708677512:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-708677512,2,['error'],['error']
Availability,"Hey @chris-rands,. This is a really interesting topic. Sorry in advance for the wordy reply... You are absolutely correct that log transformation removes the perfect comparison of relative expression values that mean normalization provides. Aside from CPM normalization (as provided by `sc.pp.normalize_total()`) not being a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:655,down,downstream,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['down'],['downstream']
Availability,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:203,robust,robust,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027,3,"['down', 'error', 'robust']","['downstream', 'error', 'robust']"
Availability,"Hey @giovp & @ivirshup,; hope you had a good start into 2022! I was getting a twitter request recently asking about when this PR will be merged - are there any news on the timeline yet?. For the PR itself I made suggestions for the few remaining points (see my previous post) - just ping me here if you have feedback on that or if there is anything else to do!. Looking forward to wrap this up :); Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1030169133:283,ping,ping,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1030169133,2,['ping'],['ping']
Availability,"Hey @gokceneraslan,. I'm surprised at how you describe the contents of `adata.var['highly_variable']` when `batch_key` is set. I wrote a function that does pretty much exactly the same thing building upon use of `batch_key` for our data integration benchmarking, as I thought this wasn't available in scanpy. I recall looking through the code and thinking this was missing. Maybe we can compare functions for that to see if we're doing exactly the same thing or not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714:288,avail,available,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714,1,['avail'],['available']
Availability,"Hey! Here's the downsample function I wrote... you may want to change things like defaults or how it does the inplace operation. Best,. Malte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/99:16,down,downsample,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/99,1,['down'],['downsample']
Availability,"Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:; ```; adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0); adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'); ```. and I get this error:; ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-8-463060c90a0b> in <module>(); ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 630 X_col = adata.raw[:, key].X; 631 else:; --> 632 X_col = adata[:, key].X; 633 obs_df[key] = X_col; 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index); 1303 def __getitem__(self, index):; 1304 """"""Returns a sliced view of the object.""""""; -> 1305 return self._getitem_view(index); 1306 ; 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index); 1306 ; 1307 def _getitem_view(self, index):; -> 1308 oidx, vidx = self._normalize_indices(index); 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index); 1283 obs, var = super(AnnData, self)._unpack_index(index); 1284 obs = _normalize_index(obs, self.obs_names); -> 1285 var = _normalize_index(var, self.var_names); 1286 return obs, var; 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names); 261 return slice(start, stop, step); 262 elif isinstance(index, (int, str)):; --> 263 return name_idx(index); 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):; 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i); 248 raise IndexError(; 249 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375,2,['error'],['error']
Availability,"Hey! Just to chime in, I believe plotting functions also expect categoricals and I've had errors from other functions as well about obs columns not being categorical. I think that was `rank_genes_groups`, but I'm not sure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-800937743:90,error,errors,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747#issuecomment-800937743,1,['error'],['errors']
Availability,"Hey!. Here's the downsample function I wrote to downsample count matrices. Now the function is also loaded via the api. Best,. Malte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100:17,down,downsample,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100,2,['down'],['downsample']
Availability,"Hey!. I have recently gotten a quite deeply clinically phenotyped dataset and have been pondering how the metadata should best be stored in an anndata object. It feels redundant to duplicate a label for every cell from the same patient. Instead, one could save patient-level data in `adata.uns` and then have a function that links categories in an obs column to e.g., keys in a dict in `adata.uns`. This would save quite a lot of space in anndata objects if you have a lot of clinical metadata. I'm thinking of this as a hidden function that plotting functions could use instead of just looking for `.obs` columns to plot data. This may be somewhat linked to #619.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/658:168,redundant,redundant,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658,1,['redundant'],['redundant']
Availability,"Hey!. I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```; import pandas as pd; #pd.set_option(""display.max_columns"", None); import numpy as np; import anndata; import scanpy as sc. %store -r df. adata = anndata.AnnData(df); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata); sc.pl.paga(adata, plot=False); sc.tl.umap(adata, init_pos='paga'); ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```; AttributeError Traceback (most recent call last); <ipython-input-7-7cfb2fb3103e> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'); 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 141 import umap; 142 ; --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):; 144 ; 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'; ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978,2,['error'],['error']
Availability,Hey!. I think this is probably related to https://github.com/theislab/anndata2ri/issues/63. Maybe try downgrading your `anndata2ri` version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866769550:102,down,downgrading,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866769550,1,['down'],['downgrading']
Availability,"Hey!. Scanpy does not seem to work correctly together with scikit-learn 0.21.1.; When running the PBMC clustering tutorial (https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb), the produced UMAP plots look very different to the reference.; ![wrong_umap](https://user-images.githubusercontent.com/50872326/58096076-92577880-7bd4-11e9-9383-dda48c4efeac.png). By downgrading scikit-learn to 0.20.0, everything works fine.; The problem seems to arise already at the computation of the neighborhood graph, as the clustering is also different.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/654:379,down,downgrading,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654,1,['down'],['downgrading']
Availability,"Hey!. We do it as they do in Seurat. See [here](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), available through the [examples page](http://scanpy.readthedocs.io/en/latest/examples.html):; ```; adata = adata[adata.obs['percent_mito'] < 0.05, :]; ```; in Box 8. Does this help you or do you need more?. Best,; lex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/122#issuecomment-381551334:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122#issuecomment-381551334,1,['avail'],['available']
Availability,"Hey!; > * What methods/ tools?; I am mainly thinking about normalization and data integration methods. For example scran pooling, sctransform, scNorm, Seurat data integration, LIGER... etc. I have most of those already... But anyone is welcome to contribute for anything they regularly use. > * How would you handle R depencies?; So far I've been ignoring this problem and just assuming people have an R environment installed that has the relevant packages. You could just stick a `require(package)` in the function called by `rpy2` and then if would give you an `R` error you can interpret. The plan would be to make this a set of convenience functions, but not a cleanly installable module I guess... I'm not sure how you could get any python setup to install R dependencies for you... > * And (probably hard and definitely not necessary at first) could we use [arrow](https://arrow.apache.org/docs/python/) to speed up data transfer?; This looks interesting... but I don't entirely understand it... you'd have to have a a separate data structure that can move been languages, and be interpreted as an R data structure or `AnnData` depending on where it's used? Most methods are designed to run on a particular class of object. How would this help if you always have to convert to that type of object? So far I've just been using `anndata2ri` to ensure we have an `SCE` object which can be converted to other `R` data structures.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256:567,error,error,567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256,1,['error'],['error']
Availability,"Hey!; I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:; ``` ---------------------------------------------------------------------------; PackageNotFoundError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>; 25 __version__ = get_versions()['version']; 26 ; ---> 27 check_versions(); 28 del get_versions, check_versions; 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(); 38 ; 39 anndata_version = version(""anndata""); ---> 40 umap_version = version(""umap-learn""); 41 ; 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package); 103 ""Version"" metadata key.; 104 """"""; --> 105 return distribution(package).version; 106 ; 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package); 84 :return: A ``Distribution`` instance (or subclass thereof).; 85 """"""; ---> 86 return Distribution.from_name(package); 87 ; 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name); 50 return resolved; 51 else:; ---> 52 raise PackageNotFoundError(name); 53 ; 54 @staticmethod. PackageNotFoundError: umap-learn ; ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf; Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739,1,['error'],['error']
Availability,"Hey!; Using the latest verisons of scanpy and anndata, I have tried reproducing this via:; ```; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts = 10); sc.pp.filter_cells(adata, min_counts = 10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True); adata = adata[:, adata.var[""highly_variable""]]; sc.pp.scale(adata); ```. and I don't get an error. Could you reproduce this error with one of the datasets in `sc.datasets`? That way I could try to reproduce your error. Also, which version of anndata and scanpy are you on?. Other than that, you don't need the line `adata = adata[:, adata.var[""highly_variable""]]` if you use `subset=True` in the `sc.pp.highly_variable_genes()` call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738#issuecomment-511205979:451,error,error,451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738#issuecomment-511205979,3,['error'],['error']
Availability,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,2,['error'],"['error', 'errors']"
Availability,"Hey, sorry for being slow here. upon looking into this again, it is the case that `read_10x_mtx` has to make strong assumptions on the files being generated by Cell Ranger. This is also reflected in the filenames this software outputs. Is there a widely used processing pipeline which does not adhere to this file naming?; If yes, scanpy should indeed be able to deal with this;; If no, custom workflows would actually be more reliably dealt with by using a small custom reading script as suggested by @flying-sheep above:. > Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:; > ; > https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341; > ; > Took me 3 minutes:; > ; > ```python; > samples = []; > for sample in range(1, 10):; > s = read(; > path / f'{sample}.matrix.mtx',; > cache=cache,; > cache_compression=cache_compression,; > ).T; > genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); > s.var_names = genes[0]; > s.var['gene_symbols'] = genes[1].values; > s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; > samples.append(s); > adata = AnnData.concatenate(samples); > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694:427,reliab,reliably,427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694,1,['reliab'],['reliably']
Availability,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:122,error,error,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631,4,['error'],['error']
Availability,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]); sc.pl.violin(adata, keys='n_counts', groupby='louvain'); ```. Yielding; ```; ValueError: The palette dictionary is missing keys: {'11'}; ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066525588:232,error,error,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066525588,1,['error'],['error']
Availability,"Hey,. I just stumbled into an issue with scanpy.; If I have an gene or cell annotation that is not 1-dimensional (I store ERCCs as a M x 92 float matrix in col_attrs), it generates an error:; ""Exception: Data must be 1-dimensional"". However, it is allowed by the loompy nomenclature to have multiple dimensions. ; And actually loompy package accepts it. Could it be corrected, so it can be accepted as a valid Loom file/annotation?. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/507:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507,1,['error'],['error']
Availability,"Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python; import scanpy.api as sc; from scipy import sparse; A = sparse.rand(100, 100, 0.1, ""csr""). # This works; sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error; sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))); ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-13-f65606c38b22> in <module>; ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 750 g = sns.clustermap(df, row_colors=row_colors, **kwds); 751 else:; --> 752 g = sns.clustermap(df, **kwds); 753 show = settings.autoshow if show is None else show; 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1299 row_cluster=row_cluster, col_cluster=col_cluster,; 1300 row_linkage=row_linkage, col_linkage=col_linkage,; -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws); 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws; 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,; -> 1128 row_linkage=row_linkage, col_linkage=col_linkage); 1129 try:; 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage); 1019 self.dendrogram_row = dendrogram(; 1020 self.data2d, metric=metric, method=method, label=False, axis=0,; -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage); 10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,2,['error'],['error']
Availability,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:160,error,error,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998,1,['error'],['error']
Availability,"Hey,; thanks a lot for raising this @Kiliankleemann! And thanks a lot for showing the Version details, big help here. I'll look into this, for the moment it appears that for the violin plot; - indeed as @JacquesFGD mentioned it seems that using seaborn-0.13.0 raises this error when setting `multi_panel=True`: the plot obtainable from `multi_panel=False` seems to work.; - as @bbimber noted, using seaborn-0.12.2 seems to work, also with the `multi_panel=True` option. For urgent violin plots, either of these two options should produce them. Will get back to this asap.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854,1,['error'],['error']
Availability,"Hey. I also thought about the intersection but didn't implement it as the default output for two reasons. . 1) it can be too harsh, especially if there is some biological variation between batches. When we sort the genes based on in how many batches they're detected as HVG and on mean normalized dispersion, there is still a chance for the user to catch such ""biological"" genes with a high n_top_genes value. . 2) Output of highly_variable_genes should be consistent regardless of batch_key option. So n_top_genes and mean/dispersion cutoff flavors should still work the same way. I feel like using the intersection directly as the output violates that. However, making `'highly_variable': np.nansum` part available in adata.var is a good idea. Then users can manually make the selection more stringent by selecting genes where this value == nbatches.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437:707,avail,available,707,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437,1,['avail'],['available']
Availability,"Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py; import numpy as np; import pandas as pd; import scanpy as sc; import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; print(adata). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(); ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance.; Cheers. ```pytb; > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 ; ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad; AnnData object with n_obs × n_vars = 2700 × 32738 ; var: 'gene_ids'. Traceback (most recent call last):; File ""test.py"", line 23, in <module>; sc.pp.filter_cells(adata, min_genes=200); File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells; adata._inplace_subset_obs(cell_subset); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs; adata_subset = self[index].copy(); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__; return self._getitem_view(inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734:321,error,errors,321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734,1,['error'],['errors']
Availability,"Hi - excellent software, thanks! - . but I do have a problem. If i load a disk backed dataset, I cannot run `sc.tl.score_genes`. Given these two sets:; ```py; ad = sc.read_h5ad('scdataset.h5ad', backed='r+'); ad2 = sc.read_h5ad('scdataset.h5ad'); ```; and; ```py; random_genes = list(ad.var_names.to_series().sample(100)); ```; this works perfectly:; ```py; sc.tl.score_genes(ad2, random, score_name=""random100"", random_state=42); ```; but, this:; ```py; sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42); ```; yields the following error:; ```pytb; -----------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-113-9cb28e089b25> in <module>; ----> 1 sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 90 else:; 91 obs_avg = pd.Series(; ---> 92 np.nanmean(_adata[:, gene_pool].X, axis=0), index=gene_pool) # average expression of genes; 93 ; 94 obs_avg = obs_avg[np.isfinite(obs_avg)] # Sometimes (and I don't know how) missing data may be there, with nansfor. <__array_function__ internals> in nanmean(*args, **kwargs). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in nanmean(a, axis, dtype, out, keepdims); 949 cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims); 950 tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims); --> 951 avg = _divide_by_count(tot, cnt, out=out); 952 ; 953 isbad = (cnt == 0). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in _divide_by_count(a, b, out); 216 else:; 217 if out is None:; --> 218 return a.dtype.type(a / b); 219 else:; 220 # This is questionable, but currently a numpy scalar can. ValueError: setting an array element with a sequence.; ```. thanks; Mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/883:553,error,error,553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883,2,"['error', 'mask']","['error', 'mask']"
Availability,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203:187,error,error,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203,1,['error'],['error']
Availability,"Hi @Celine-075,. constructing the neighborhood graph is not guaranteed to be reproducible; * across different machines; * across different package versions; * with different number of CPU threads available to your session. (see also https://github.com/scverse/scanpy/issues/2014). If all of these things are constant between your two versions, then it's a bug. . Also: are you sure the clustering has actually changed (by comparing the cell barcodes)? Or is it just the UMAP that looks differently, but the clusters are the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2020630719:196,avail,available,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2956#issuecomment-2020630719,1,['avail'],['available']
Availability,"Hi @FADHLyemen,. You can export the raw count table (before calculating the percentage) into R for downstream analysis using `edgeR`. You can follow the following link to find further information: https://bioconductor.org/books/release/OSCA/multi-sample-comparisons.html#differential-abundance. Regards,; Mikhael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745:99,down,downstream,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745,1,['down'],['downstream']
Availability,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. ; 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713:702,robust,robust,702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713,1,['robust'],['robust']
Availability,"Hi @JayalalKJ ,; as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial; It's best if you open an issue there and directly address maintainers of that repo. ; Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo.; Hope this is helpful",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857,2,['error'],['error']
Availability,"Hi @JonathanShor,. you don't need to create a custom API. One point of Scanpy is to provide convenient access via `anndata` to many single-cell packages around. The only thing needed for that is to provide a very simple interface like [this](https://github.com/theislab/scanpy/blob/master/scanpy/tools/phate.py#L8-L145) or [this](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/mnn_correct.py#L4-L104) or several of the other tools... Simply click on the GitHub links in the Scanpy docs... If your package works reliably, both the restrictions you mention should in principle not prevent adding your package. Of course, in the future, we want all elements of Scanpy to scale to millions of cells, not just the core tools. But for a lot of people, it's right now helpful to have a large number of tools available also for relatively small datasets. The only problem is to avoid cluttering the Scanpy API with virtually any tool there is. Tools in the API should have passed a certain quality check. Doublet detection is a difficult problem. Already last autumn, we played around with @swolock 's tool but didn't end up using it - it was good, but in our situation, it didn't seem to apply (are you eventually going to distribute a package for it @swolock ?). I myself quickly wrote a tool, too, but it didn't work well. Just yesterday, [this](https://www.biorxiv.org/content/early/2018/06/20/352484) appeared. Then there is also [this](https://www.biorxiv.org/content/early/2018/04/04/234872) on ""empty cell detection"". There are more tools out there, I think... What I mean is: computationally detecting doublets is still something where the field has not agreed on a consensus. Just like batch correction. Therefore, I would not add a tool `tl.doublet_detection` or `tl.detect_doublets` to the API at this stage. There are two options. Either we create a `.beta` module of the API for tools that don't even have a preprint and add your tool and similar cases in the future there. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409:532,reliab,reliably,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409,4,"['avail', 'reliab']","['available', 'reliably']"
Availability,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you!. > Hi, @awnimo , sorry for the delay.; > It seems that this PR breaks test_harmony_timeseries.py. I get; > ; > ```; > E ValueError: 'time_points' column does not contain Categorical data; > ; > ../../external/tl/_harmony_timeseries.py:140: ValueError; > ```; > ; > On master the test works fine.; > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388,1,['error'],['error']
Availability,"Hi @Koncopd, my data are indeed already normalised. @fidelram I generated the data merging a few datasets using ```bbknn```. But when I tried on a single sample, I got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445151260:177,error,error,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445151260,1,['error'],['error']
Availability,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665580053:300,avail,available,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665580053,2,"['avail', 'down']","['available', 'downloaded']"
Availability,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:349,down,downstream,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766,1,['down'],['downstream']
Availability,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:800,avail,available,800,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560,1,['avail'],['available']
Availability,"Hi @LuckyMD,. Thank you for your rapid reply!; In mnnCorrect's paper, the authors claimed that ComBat cannot be applied to some single-cell RNA sequencing data, since there are always multiple different cell types in each dataset, how do you think about that? ; Maybe, ComBat cannot handle well with the cases where different cell types are influenced by the batch effect in different ways or levels.; I am afraid that batch effects are not accurately corrected, and I am still puzzled about which method may give better results, i.e., calculating marker genes basing on batch-corrected data or including batch as a covariate in the raw data. (Is there any available paper discussing this problem?). In addition, I will check `adata.var` soon. Thanks,; BP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502557529:657,avail,available,657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502557529,1,['avail'],['available']
Availability,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:436,error,error,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089,1,['error'],['error']
Availability,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460#issuecomment-718760332:298,error,error,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460#issuecomment-718760332,1,['error'],['error']
Availability,"Hi @VladimirShitov . Thank you for the help (and the information about leiden vs UMAP). I think the code provided shows something slightly different. You are plotting False vs True here, but we would want something like False vs all. So, the True violin plot would be a little different. Regardless, I am just going to down this route :D",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460:319,down,down,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460,1,['down'],['down']
Availability,"Hi @Zethson ,; The reason why we introduced flavors here is that we wanted the traditional implementation to be present in case anyone wanted to use it. We just introduced our implementation as a faster alternative to the already available one. In case replacing the code is required, we can do that as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339:230,avail,available,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339,1,['avail'],['available']
Availability,"Hi @Zethson! Thanks for your reply. However, I get the same errors when pulling it from conda-forge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2000#issuecomment-920976313:60,error,errors,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000#issuecomment-920976313,1,['error'],['errors']
Availability,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293#issuecomment-702387945:122,down,downgrade,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293#issuecomment-702387945,3,"['down', 'error', 'ping']","['downgrade', 'error', 'ping']"
Availability,"Hi @aopisco ! @falexwolf I ran into the same problem but got everything to work by deleting all the unnecessary items in adata.uns. ```py; keep = ['neighbors', ]; keys = list(adata.uns.keys()); for key in keys:; if key not in keep:; del adata.uns[key]; ```; I don't get errors anymore but I fear that this might cause other problems I'm currently unaware of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-513808772:270,error,errors,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-513808772,1,['error'],['errors']
Availability,"Hi @cartal, it wouldn't be very hard to export to a 10x h5 file, but I'd need to write a custom function for it. Why is it needed? Does 10x offer any downstream analysis that you'd want to use on the data? I thought there are none, hence there is only `sc.read_10x_h5` and no `sc.write_10x_h5`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-422093244:150,down,downstream,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-422093244,1,['down'],['downstream']
Availability,"Hi @chris-rands . It would help to have the whole error traceback here to be able to diagnose this a bit better. @jorvis Did you find the solution to your issue, and if so could you post it here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-520159182:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520159182,1,['error'],['error']
Availability,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:1553,avail,available,1553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946,1,['avail'],['available']
Availability,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:620,error,error,620,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124,4,"['down', 'error']","['downloaded', 'error']"
Availability,"Hi @falexwolf, thanks for the solution you provided above for reading multiple files. I tried it and it worked when I had just 2 files. I am trying the same code with 23 files and I am getting an error message in the concatenation step. Any idea on how to fix this ? Thanks. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-20-662b857d9182> in <module>; 12 adatas.obs['cell_names'] = pd.read_csv(path + sample + 'barcodes.tsv.gz', header=None)[0].values; 13 ; ---> 14 adata = adatas[0].concatenate(adatas[1:]). /Applications/anaconda3/lib/python3.7/site-packages/anndata/core/anndata.py in concatenate(self, join, batch_key, batch_categories, index_unique, *adatas); 1908 ; 1909 if any_sparse:; -> 1910 sparse_format = all_adatas[0].X.getformat(); 1911 X = X.asformat(sparse_format); 1912 . AttributeError: 'numpy.ndarray' object has no attribute 'getformat'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-602964900:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-602964900,1,['error'],['error']
Availability,"Hi @falexwolf, yes I will be making my method available. A [rough version](https://github.com/swolock/woublet) is already on github, and I also played around with adding it to my [scanpy fork](https://github.com/swolock/scanpy) (though not the right way -- I added it to `tl` rather than `pp`). I'll hopefully clean it up and release something more official when I have the chance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424:46,avail,available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424,1,['avail'],['available']
Availability,"Hi @fidelram ,. Thanks for the response.; I think either or both would be great. Excuse my ignorance, what's the efficient to interact with scanpy, I am guessing `annData` ? If `annData` I am again guessing that the object can be efficiently made given the CSR/CSC sparse matrix or is there already a support to import other binary matrix formats ?. Currently alevin dumps [EDS](https://github.com/COMBINE-lab/EDS) (a binary matrix format), and I wrote a small Rust library to convert it to other formats (h5, csv, mtx) and found EDS is faster to load and uses less memory, at least in R. We have a support of EDS in R world through Mike Love's awesome `tximport` package. Since scanpy provides great support and efficient implementation of various single-cell analyses for the python world, I'd love to make EDS import and alevin interaction for downstream processing as efficient as possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/856#issuecomment-538028764:847,down,downstream,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/856#issuecomment-538028764,1,['down'],['downstream']
Availability,"Hi @fidelram ,. When I try to use . ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain'); ```; I get this heatmap. . ![louv1](https://user-images.githubusercontent.com/11874103/54995344-d2c8ba80-4fc6-11e9-84fe-4f659915293d.png). But as soon as I add ```standard_scale='var'```:. ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'); ```. I get the following error. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-24-4ac38158d4d0> in <module>; ----> 1 plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'). [...]/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. [...]/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1804 RuntimeWarning, stacklevel=2); -> 1805 return func(ax, *args, **kwargs); 1806 ; 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. [...]/lib/python3.6/site-packages/matplotlib/axes/_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5762 kwargs.setdefault('snap', False); 5763 ; -> 5764 collection = mcoll.PolyCollection(verts, **kwargs); 5765 ; 5766 collection.set_alpha(alpha). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). [...]/lib/python3.6/site-packages/matplotlib/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/559:410,error,error,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/559,1,['error'],['error']
Availability,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:287,error,error,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,2,['error'],['error']
Availability,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----; anndata 0.9.2; scanpy 1.10.2; -----; PIL 9.5.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; bottleneck 1.3.6; cffi 1.15.0; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.5.1; decorator 4.4.2; defusedxml 0.7.1; dill 0.3.8; dot_parser NA; entrypoints 0.4; executing 0.8.3; fasteners 0.18; google NA; h5py 3.8.0; igraph 0.10.8; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.4.0; jupyter_server 1.18.1; kiwisolver 1.4.2; legacy_api_wrap NA; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; msgpack 1.0.5; natsort 8.4.0; numba 0.59.0; numcodecs 0.12.1; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 2.1.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.23.0; prompt_toolkit 3.0.20; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynvml NA; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.11.2; seaborn 0.13.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.3.2; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.12.2; toolz 0.11.2; torch 2.2.0+cu121; torchgen NA; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xxhash NA; yaml 6.0; zarr 2.15.0; zipp NA; zmq 22.3.0; zoneinfo NA; zope NA; -----; IPython 8.4.0; jupyter_client 7.1.2; jupyter_core 4.10.0; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]; Linux-3.10.0-1160.99.1.e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344:154,error,error,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344,1,['error'],['error']
Availability,"Hi @genecell,. We have a review paper on current best-practices in scRNA-seq analysis which is coming out soon in Molecular Systems Biology that discusses this a bit. The issue with batch correction in scRNA-seq data isn't that batch affects different cell types differently, but rather that if cell type compositions change between batches, then transcriptional differences between the cell types that differ between the batches confound the technical batch effect estimation. So you end up correcting for more than just the technical effect. This means that you can use Combat if the cell type compositions are expected to be similar between batches. Indeed, ComBat is shown to outperform MNN for simple batch correction scenarios ([kBet paper](http://www.nature.com/articles/s41592-018-0254-1)). Inspite of the above argument, the better way to do things is definitely to include batch as a covariate. That way you don't underestimate your background variance. In the case of marker gene detection, this is not quite so problematic as:; 1. It is an easy problem, as cell-type differences tend to be very pronounced so you should always detect a signal even with non-optimal methods.; 2. The p-values you calculate from marker gene detection are inflated anyway and therefore not meaningful. We discuss the above points in our manuscript. I'm not aware whether using corrected data for differential expression testing is discussed anywhere else though. If you email me, I could forward you a copy of the manuscript, but it should be available in MSB in the next weeks. The issue with inflated p-values is also discussed is a few other places like [here](https://www.biorxiv.org/content/early/2018/11/05/463265).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404:1535,avail,available,1535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404,2,['avail'],['available']
Availability,"Hi @giovp! The test data is too large, it’ll take scanpy a long time to clone once this is in `master`. The way we fix it is that we replace the data and then merge our changes into commit bb70446 (creating a new commit from the two and eliminating any trace of the big dataset). For reference, the test data `filtered_feature_bc_matrix.h5` is <100kb. I’d say you find the smallest of the 10x example datasets, reduce it so the (non-image) data is <100kb all in all, and delete the hires pic. The code should work if there’s only the lores pic anyway, right?. An alternative would be to mark our tests as “internet” tests and dynamically download the data, but I think it’s better to always run the spatial tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661:638,down,download,638,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661,1,['down'],['download']
Availability,"Hi @giovp,; no worries, I hope you had a good TAC meeting! And thanks a lot for picking this up again, fixing the docs and also for starting the new issue on batch integration. I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. If there is anything I should look into, let me know - I have some time for this next week!; Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277,1,['error'],['error']
Availability,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:599,down,downstream,599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594,2,['down'],['downstream']
Availability,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862:34,avail,available,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862,1,['avail'],['available']
Availability,"Hi @hyjforesight!. As mentioned in the paper, plotting corrected data is definitely the way forward. I'm not sure about regressing out all of these biological covariates (like regressing out MT fraction). In general, it can be quite informative to find that you have different MT gene expression between clusters. This can highlight different respiratory (and maybe metabolic) activity as well as data quality differences. Otherwise, feel free to just ignore the MT genes by masking them from the analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012982205:475,mask,masking,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012982205,1,['mask'],['masking']
Availability,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2136745993:341,avail,available,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2136745993,1,['avail'],['available']
Availability,"Hi @ivirshup , I replaced the one test image that was causing a failure, as you suggested. (And I checked to make sure the image makes sense... it does...) I think this should do it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743:64,failure,failure,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743,1,['failure'],['failure']
Availability,"Hi @ivirshup ,; It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903:190,down,downloading,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903,1,['down'],['downloading']
Availability,"Hi @ivirshup ,; Thanks for your help.; Versions:; ```; In [1]: import numba; In [2]: numba.__version__; Out[2]: '0.45.0'; ```; I had to downgrade the original numba version in order to MNN_correct to work according to a Stackoverflow post.; Now I updated anndata through conda:; ```conda update anndata```; And ran this code (minus highly variable gene calculation):; ```; adataCombat = sc.read_h5ad(results_file); #Run combat:; # sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); sc.pp.neighbors(adataCombat, n_pcs =50); ```; with even worse output:; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled be",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656:136,down,downgrade,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656,1,['down'],['downgrade']
Availability,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:503,error,error,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613,1,['error'],['error']
Availability,"Hi @ivirshup, it used to work 6 months ago. As discussed in https://github.com/saezlab/omnipath/issues/54#issuecomment-1950265944, it seems it was an error with the package `requests_cache`. Installing the latest version from GitHub solves the issue so I'll close this then, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269,1,['error'],['error']
Availability,"Hi @john-jiangyong,. The error is that your covariate you group by should be a categorical, while it is not at the moment. You could run:; `adata.obs[‘seurat_clusters’] = adata.obs[‘seurat_clusters’].astype(‘category’)` To turn the covariate into a categorical. Note the code above might not be 100% correct as i’m typing from my phone and haven’t verified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1414#issuecomment-692506550:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414#issuecomment-692506550,1,['error'],['error']
Availability,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665549817:252,down,downloaded,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665549817,3,['down'],"['download', 'downloaded', 'downstream']"
Availability,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`?. In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1452#issuecomment-707656885:381,error,error,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452#issuecomment-707656885,1,['error'],['error']
Availability,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-706060782:100,avail,available,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-706060782,2,['avail'],['available']
Availability,"Hi Alex!. Sorry for this long delay, I just forgot completely.; Maybe I wasn't clear enough in my original post, here is where the issue lies:; ; When I run . ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', groups = 'all'); ```. everything is fine and I get my desired result. However, when I just change the reference setting. ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', reference='CA', groups = 'all'); ```. then I get the following error. ```pytb; 100 groups_order = [str(n) for n in groups_order]; 101 if reference != 'rest' and reference not in set(groups_order):; --> 102 groups_order += [reference]; 103 if (reference != 'rest'; 104 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list; ```. I absolutely understand how to solve this - as you said, I can just use the tutorial call and select groups explicilty. ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', reference='CA', groups = ['OPC', 'Granule']); ```. and then it works again. I was just wondering whether this is the desired behavior - most users will leave the `groups` attribute at it's default setting when they change the `reference` attribute and wonder why it does not work - at least that was my idea. Maybe I am wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/346#issuecomment-445219624:473,error,error,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346#issuecomment-445219624,2,['error'],['error']
Availability,"Hi Alex!; Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. ; Thanks a lot,; Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33#issuecomment-324831221:96,down,downstream,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33#issuecomment-324831221,2,"['down', 'error']","['downstream', 'error']"
Availability,"Hi Alex, . Here is an interesting bug with scanpy. For developers, it is useful to be able to reload a previously imported module within the environment containing useful variables and data for testing (a sample scRNA dataset) after changing scanpy's source code. However, scanpy cannot be reloaded. This means that to test, one has to stop the kernel, restart, reload all of the data needed for a plot and then test a plotting function that was just modified (for instance). . Here is a way to demonstrate the reload failure easily:; 1. open utils.py and add the print statement to track the descend_classes_and_funcs() function. ```py; #utils.py; def annotate_doc_types(mod: ModuleType, root: str):; for c_or_f in descend_classes_and_funcs(mod, root):; print(c_or_f) #added line to track descend_classes_and_funcs() function--TR; c_or_f.getdoc = partial(getdoc, c_or_f); ```. 2. open ipython. ```py; import scanpy as sc; # prints out a bunch of function names from the descend_classes_and_funcs() function. import importlib; importlib.reload(sc); # endless loop of function names from the descend_classes_and_funcs() function; # due to recursive yield statement; ```. So what is the purpose of this function? And can it be altered to allow reload? It is called when __init__.py is run by sc.annotate_doc_types(sys.modules[__name__], 'scanpy'). . ```py; #utils.py. def descend_classes_and_funcs(mod: ModuleType, root: str):; for obj in vars(mod).values():; if not getattr(obj, '__module__', getattr(obj, '__qualname__', getattr(obj, '__name__', ''))).startswith(root):; continue; if isinstance(obj, Callable):; yield obj; if isinstance(obj, type):; yield from (m for m in vars(obj).values() if isinstance(m, Callable)); elif isinstance(obj, ModuleType):; yield from descend_classes_and_funcs(obj, root); ```. _________________________________________________________. It is possible to remove the scanpy manually by:. ```py; import sys; sys.modules.pop('scanpy'); ```. and then import scanpy from scr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/468:518,failure,failure,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468,1,['failure'],['failure']
Availability,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,1,['error'],['error']
Availability,"Hi Alex, thank you for this amazing package. I would like to use it for my analysis, but I cannot figure it out why I'm getting this error when I try to include more annotation on my samples. ; Basically, I was following your example here: . import pandas as pd; anno = pd.read_csv(filename_sample_annotation); adata.obs['cell_groups'] = anno['cell_groups'] . However, when I tried with my cvs file, I got Nan for each row and I don't understand. ; The pd data frame is fine, but then the data.var['key'] = NaN NaN NaN ... everywhere..; I post here my code: . **import pandas as pd. anno = pd.read_csv(path+'sample_anno.csv',header=0); anno.head(); adata.var['pools']= anno['pools']; adata.var**; ![updated_adata var](https://user-images.githubusercontent.com/20638667/35852492-59e9806c-0b2b-11e8-94e2-103c18792cbb.png); ![anno_dataframe](https://user-images.githubusercontent.com/20638667/35852504-5f5a04d6-0b2b-11e8-9c91-0e0d61da3810.png). Thank you in advance, . Elisabetta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74:133,error,error,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74,1,['error'],['error']
Availability,"Hi Alex,. Below is the error I get. Thank you for looking at this. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-12-4fad8adf5d00> in <module>; ----> 1 sc.pl.pca(adata, color='CD3D'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in pca(adata, **kwargs); 148 If `show==False` a `matplotlib.Axis` or a list of it.; 149 """"""; --> 150 return plot_scatter(adata, basis='pca', **kwargs); 151 ; 152 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 275 color_vector, categorical = _get_color_values(adata, value_to_plot,; 276 groups=groups, palette=palette,; --> 277 use_raw=use_raw); 278 ; 279 # check if higher value points should be plot on top. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 658 # check if value to plot is in var; 659 elif use_raw is False and value_to_plot in adata.var_names:; --> 660 color_vector = adata[:, value_to_plot].X; 661 ; 662 elif use_raw is True and value_to_plot in adata.raw.var_names:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1307 def __getitem__(self, index):; 1308 """"""Returns a sliced view of the object.""""""; -> 1309 return self._getitem_view(index); 1310 ; 1311 def _getitem_view(self, index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index); 1311 def _getitem_view(self, index):; 1312 oidx, vidx = self._normalize_indices(index); -> 1313 return AnnData(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317,1,['error'],['error']
Availability,"Hi Alex,. UMAP throws an error if I use `scanpy.tl.ump` with initial positions from `sc.tl.paga`. Based on the error (see below) I thought it was a problem of UMAP itself. However, the error is not thrown when called without initial positions from paga. Here is the output / error:. ```pytb; sc.tl.umap(adata, init_pos='paga'). computing UMAP; using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-35-924452b37e5b> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy); 137 neigh_params.get('metric', 'euclidean'),; 138 neigh_params.get('metric_kwds', {}),; --> 139 verbose=max(0, verbosity-3)); 140 adata.obsm['X_umap'] = X_umap # annotate samples with UMAP coordinates; 141 logg.info(' finished', time=True, end=' ' if _settings_verbosity_greater_or_equal_than(3) else '\n'). /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,4,['error'],['error']
Availability,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:200,error,error,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004,2,['error'],['error']
Availability,"Hi Brian,; Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-726776364:153,error,error,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-726776364,1,['error'],['error']
Availability,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513:198,down,downgrade,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513,1,['down'],['downgrade']
Availability,"Hi Guys, . this it perhaps rather a question than issue, ; Is there a way to export raw data in csv format? If I do this ; `adata.write_csvs(""filename"", skip_data=False)` . it works perfectly fine . but with ; `adata.raw.write_csvs(""filename"", skip_data=False)`. I get this error; `AttributeError: 'Raw' object has no attribute 'write_csvs'`. Thanks,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506,1,['error'],['error']
Availability,"Hi I am having a similar issue where I would like to set the tick locations on the colorbar. Using similar code as above. ```; ax = sc.pl.tsne(adata, color = 'gene', show=False); fig = plt.gcf(); cbar_ax = fig.axes[-1]; cbar_ax.set_yticks([0,1]); ```; I get the following error 'UserWarning: Use the colorbar set_ticks() method instead'. How can I access the colorbar specifically?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918,1,['error'],['error']
Availability,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io; Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. ; I have a non zarr data format. . ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2458530172:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2458530172,2,"['Down', 'error']","['Downloads', 'error']"
Availability,"Hi I had this problem as well with 1.6.0 it was triggered by scanpy's test code. ```; scanpy.api (unittest.loader._FailedTest) ... ERROR. ======================================================================; ERROR: scanpy.api (unittest.loader._FailedTest); ----------------------------------------------------------------------; ImportError: Failed to import test module: scanpy.api; Traceback (most recent call last):; File ""/usr/lib/python3.9/unittest/loader.py"", line 470, in _find_test_path; package = self._get_module_from_name(name); File ""/usr/lib/python3.9/unittest/loader.py"", line 377, in _get_module_from_name; __import__(name); File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/plotting/_anndata.py). ----------------------------------------------------------------------; Ran 1 test in 0.000s. ```. I ended up with this patch to get the tests to run successfully.; ```; --- a/scanpy/api/pl.py; +++ b/scanpy/api/pl.py; @@ -1,4 +1,7 @@; -from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; +from ..plotting._anndata import scatter, violin, ranking, clustermap, heatmap, tracksplot; +from ..plotting._stacked_violin import stacked_violin; +from ..plotting._dotplot import dotplot; +from ..plotting._matrixplot import matrixplot; ; from ..plotting._preprocessing import filter_genes_dispersion, highly_variable_genes; ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952:131,ERROR,ERROR,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952,2,['ERROR'],['ERROR']
Availability,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:572,mainten,maintenance,572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693,1,['mainten'],['maintenance']
Availability,"Hi Isaac, I have a related question: does your expression atlas; downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476540482:65,down,downloader,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476540482,1,['down'],['downloader']
Availability,"Hi Isaac,. When I try to set n_comps equal to 2 (trying to do a diffmap in 2; components), I get an error message saying that it must be greater than 2.; I was wondering why?. On Sun, Jul 7, 2019 at 4:25 AM Isaac Virshup <notifications@github.com>; wrote:. > I'm not sure what you're asking about here. Could you provide a little; > more context?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/675?email_source=notifications&email_token=AKIOHVNZFKCE63C4KLO45KTP6GSAPA5CNFSM4HSIFHXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZLG7PQ#issuecomment-508981182>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AKIOHVL7254C36JSP374JOTP6GSAPANCNFSM4HSIFHXA>; > .; >; -- ; Harvard-MIT MD-PhD Student; G1, Biophysics; Lander Lab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047,1,['error'],['error']
Availability,"Hi Issac,; Thank you for looking into this. I tried downgrading to python 3.7 but the; error still persists. Best,; Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>; wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda; > environment with conda list --export? I'd like to see if I can recreate; > with your environment.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>; > .; >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620631436:52,down,downgrading,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620631436,2,"['down', 'error']","['downgrading', 'error']"
Availability,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/501#issuecomment-479507574:363,error,error,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501#issuecomment-479507574,1,['error'],['error']
Availability,"Hi Malte and Isaac, many thanks for this! Ah, yes that other issue was; opened after I opened this one. I did search for the error message before I; opened the ticket, but I didn't search again while the ticket was open. The easiest workaround for me is simply to not use .raw anymore, for a; pipeline, it's not really needed anyways. Yes, I can see why it's important for file backed data, I just cannot see a; use case for file backed mode either. Any useful operations on file backed; data will be too slow anyways for practical use, and anyone can get a; high-RAM machine these days on Amazon for a few hours, so I've always; wondered file backed mode exists. (sidenote: File backed data is again a; feature that sounds rather complicated to implement. As a user I love; libraries that are small, stable and don't change a lot, especially for; very foundational things like anndata. I guess it's a matter of development; philosophy here). Also, yes, it's because I don't use scanpy interactively; that I don't see the use case for views. anyhow, thanks again, also for all your work on Scanpy!. On Wed, Jul 31, 2019 at 6:27 AM Isaac Virshup <notifications@github.com>; wrote:. > I've just spent a while trying to replicate, before realizing I've seen; > this issue before over on AnnData (theislab/anndata#182; > <https://github.com/theislab/anndata/issues/182>). I've got some good and; > bad news about this. It's fixed on master, but that fix is slated to be; > release in v0.7, which has intentionally breaking changes.; >; > I find views very useful when dealing with large datasets interactively.; > They're also important for file backed data, since copies are extremely; > expensive in that case.; >; > Unlike numpy, AnnData objects should always return a view when subset. If; > you'd like to get copies, you could add a .copy() to the end of your; > subsetting statement.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578,2,['error'],['error']
Availability,"Hi Michael:. Thanks for your suggestion, I run the tutorial without changing anything: https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb, ; ![image](https://user-images.githubusercontent.com/33963919/209399067-2287268f-a77c-4f12-ba5b-d56e4370b2f2.png). My `scanpy` can't do down dimension correctly in the `pbmc3k` data.; ![image](https://user-images.githubusercontent.com/33963919/209398837-d2f77dfa-5855-4bf7-9c7d-33625909af09.png); Can you please let me know what is wrong?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613:292,down,down,292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613,1,['down'],['down']
Availability,"Hi Raphaël!. Thanks!. What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error?. Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431,2,['error'],['error']
Availability,"Hi Scanpy team,. A potentially silly question. I'm having problems changing vmax in sc.pl.scatter. I want to set 'dpt_pseudotime' vmax to 0.5, similar to how vmax and vmin can be changed, for example, in sc.pl.umap. I tried the following:. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', color='dpt_pseudotime', size=5, use_raw=False, ; color_map='RdYlBu_r', vmax=0.5). But get the following error:. ![image](https://user-images.githubusercontent.com/49629901/66955933-64fee180-f031-11e9-90c2-0f12a392786b.png). I read in the scanpy.pl.scatter documentation that kwargs can be used to set vmax. I tried this approach, but got the same result as above:. kwargs={'vmax':0.5}. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', ; color='dpt_pseudotime', size=5, use_raw=False, color_map='RdYlBu_r', **kwargs). I tried to find a solution online with no success. Any help/suggestions will be appreciated. P.S: This is my first post and I'm a huge fan of your package. Keep up the great work!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/875:428,error,error,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/875,1,['error'],['error']
Availability,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap?. I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed?. Thank you for your kind help. Best regards,. Lirong. 获取 Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; 发件人: Sergei R. <notifications@github.com>; 发送时间: Wednesday, April 22, 2020 12:44:36 PM; 收件人: theislab/scanpy <scanpy@noreply.github.com>; 抄送: plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>; 主题: Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> .; Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1.; You can also install scanpy from github where it is fixed or just wait for a new scanpy release. ―; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861:285,error,error,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861,1,['error'],['error']
Availability,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)); * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579:187,robust,robust,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579,4,['robust'],['robust']
Availability,"Hi Sidney,. Thanks for the pull request. igraph and louvain are kind of heavy dependencies (e.g. takes long time to compile them and they're not easily available via PyPI for all platforms etc.), this is why they are excluded from requirements file. It's written in the [installation document](https://scanpy.readthedocs.io/en/latest/installation.html) that these need to be installed manually. Also, there should be proper error messages stating that these must be installed separately when their functionality is needed for a function in scanpy and cannot be found. Did you get any other error regarding these packages?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101:152,avail,available,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101,3,"['avail', 'error']","['available', 'error']"
Availability,"Hi Thank you for getting back to me. I updated it and now when I try to import scanpy as sc I get the following error:. LookupError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 89 ; ---> 90 __version__ = get_version(root="".."", relative_to=__file__); 91 del get_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in get_version(root, version_scheme, local_scheme, write_to, write_to_template, relative_to, tag_regex, fallback_version, fallback_root, parse, git_describe_command); 142 config = Configuration(**locals()); --> 143 return _get_version(config); 144 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _get_version(config); 146 def _get_version(config):; --> 147 parsed_version = _do_parse(config); 148 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _do_parse(config); 117 ""https://github.com/user/proj/archive/master.zip ""; --> 118 ""use git+https://github.com/user/proj.git#egg=proj"" % config.absolute_root; 119 ). LookupError: setuptools-scm was unable to detect version for '/Users/kabitabaral/miniconda3/envs/scanpy/lib/python3.6/site-packages'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,1,['error'],['error']
Availability,"Hi [gmoore5](https://github.com/gmoore5),. I assume this might be too late for you, but hopefully it's still useful for someone searching for this error. I could resolve this by:; - Restarting the kernel; - Setting the directory using `sc.settings.figdir = ""path/to/folder/""` (instead of sc._settings.ScanpyConfig.figdir = 'path/to/folder/')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981#issuecomment-1082447079:147,error,error,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981#issuecomment-1082447079,1,['error'],['error']
Availability,"Hi all!. I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882:309,down,downstream,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882,1,['down'],['downstream']
Availability,"Hi all!; I want to use ingest after BBKNN but it gives an error related to the metric.; If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1122:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122,1,['error'],['error']
Availability,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073#issuecomment-2147646580:45,echo,echo,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073#issuecomment-2147646580,1,['echo'],['echo']
Availability,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,2,['error'],"['error', 'errors']"
Availability,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1739:389,down,downstream,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739,1,['down'],['downstream']
Availability,"Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2; scanpy = 1.7.1. Does anyone encounter similar issue?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696:177,error,error,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi all,; I'm having a trouble in running a code: ; sc.tl.louvain(adata); So, when I try to run the code, it has an error saying that; ERROR: Failed building wheel for louvain; I tried to install louvain in anaconda prompt, and I can't install it.; When I use:; pip install louvain; to install louvain, I have an error that . ```pytb; ERROR: Command errored out with exit status 1:; 'c:\users\prince and jacky\anaconda3\python.exe' \; -u \; -c '; import sys, setuptools, tokenize; sys.argv[0] = "".../louvain/setup.py""; __file__="".../louvain/setup.py""; f=getattr(tokenize, ""open"", open)(__file__); code=f.read().replace(""\r\n"", ""\n""); f.close(); exec(compile(code, __file__, ""exec"")); ' \; install \; --record '.../install-record.txt' \; --single-version-externally-managed \; --compile; Check the logs for full command output.; ```. I also tried to install using different codes such as:. ```bash; conda install -c conda-forge louvain; ```. There's an error saying that:; PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786,7,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error', 'errored']"
Availability,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hi all:. it seems there is a problem on the batch correction with bbknn. It gives an error at the compute_connectivities_umap() step of bbknn. Version of packages:. ```; scanpy==1.4.2 anndata==0.6.19 umap==0.3.8 numpy==1.15.4 scipy==1.2.1; pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Cmds:. ```py; import scanpy.external as sce; sce.pp.bbknn(adata, batch_key='sample', copy=False); ```. Error info:. ```pytb; sce.pp.bbknn(adata, batch_key='sample', copy=False); computing batch balanced neighbors; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-34-5b7ebd13c9e6> in <module>; 1 # Correct; 2 #sc.pp.pca(adata, n_comps=50, svd_solver='arpack'); ----> 3 sce.pp.bbknn(adata, batch_key='sample', copy=False, n_pcs=15). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 except ImportError:; 83 raise ImportError('Please install bbknn: `pip install bbknn`.'); ---> 84 return bbknn(**params, **kwargs). ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 215 batch_list = adata.obs[batch_key].values; 216 #call BBKNN proper; --> 217 bbknn_out = bbknn_pca_matrix(pca=pca,batch_list=batch_list,save_knn=save_knn,**kwargs); 218 #optionally save knn_indices; 219 if save_knn:. ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn_pca_matrix(pca, batch_list, neighbors_within_batch, n_pcs, trim, approx, n_trees, use_faiss, metric, bandwidth, local_connectivity, save_knn); 272 	dist, cnts = compute_connectivities_umap(knn_indices, knn_distances, knn_indices.shape[0], ; 273 knn_indices.shape[1], bandwidth=bandwidth,; --> 274 											 local_connectivity=local_connectivity); 275 #optional trimming; 276 if trim:. TypeError: compute_connectivities_umap() got an unexpected keyword argument 'bandwidth'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744:461,down,downstream,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744,1,['down'],['downstream']
Availability,"Hi everyone,; I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Failed building wheel for scanpy; Running setup.py clean for scanpy; Failed to build scanpy; Installing collected packages: scanpy, decorator; Running setup.py install for scanpy ... error; Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:; running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; creating build/lib/scanpy/tools; copying scanpy/tools/dpt.py -> build/lib/scanpy/tools; copying scanpy/tools/paga.py -> build/lib/scanpy/tools; copying scanpy/tools/louvain.py -> build/lib/scanpy/tools; copying scanpy/tools/_utils.py -> build/lib/scanpy/tools; copying scanpy/tools/pca.py -> build/lib/scanpy/tools; copying scanpy/tools/umap.py -> build/lib/scanpy/tools; copying scanpy/tools/sim.py -> build/lib/scanpy/tools; copying scanpy/tools/tsne.py -> build/lib/scanpy/tools; copying scanpy/tools/__init__.py -> build/lib/scanpy/tools; copyi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,2,['error'],['error']
Availability,"Hi guys,. I am getting the following error after running this:. ```py; sc.pl.dotplot(adata, marker_genes1, groupby='louvain'); ```; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-138-e642551f77de> in <module>(); ----> 1 sc.pl.dotplot(adata, marker_genes1, groupby='louvain'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, color_map, dot_max, dot_min, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1350 if isinstance(var_names, str):; 1351 var_names = [var_names]; -> 1352 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 1353 ; 1354 # for if category defined by groupby (if any) compute for each var_name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 495 ; 496 def __getitem__(self, index):; --> 497 oidx, vidx = self._normalize_indices(index); 498 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 499 else: X = self._adata.file['raw.X'][oidx, vidx]. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_indices(self, packed_index); 523 obs, var = super()._unpack_index(packed_index); 524 obs = _normalize_index(obs, self._adata.obs_names); --> 525 var = _normalize_index(var, self.var_names); 526 return obs, var; 527 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_index(index, names);",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,"Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:307,error,error,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,2,['error'],['error']
Availability,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,2,['error'],['error']
Availability,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/924:460,error,error,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924,1,['error'],['error']
Availability,"Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips?. ```; ad.X = ad.obsm['raw_data'].copy(); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1817:141,recover,recover,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817,1,['recover'],['recover']
Availability,"Hi scanpy team,; I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment; ```; loompy 2.0.15 <pip>; python 3.6.6 h5001a0f_0 conda-forge; anndata 0.6.11 <pip>; scanpy 1.3.2 <pip>; ```; Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr; ```; import scanpy.api as sc ; sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-2-3e86e297513a> in <module>; 1 import scanpy.api as sc; ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names); 142 filename = fspath(filename) # allow passing pathlib.Path objects; 143 from loompy import connect; --> 144 with connect(filename, 'r') as lc:; 145 ; 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version); 1151 Note: if validation is requested, an exception is raised if validation fails.; 1152 	""""""; -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version); 82 lv = loompy.LoomValidator(version=spec_version); 83 if not lv.validate(filename):; ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); 85 ; 86 self._file = h5py.File(filename, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/320:476,error,error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320,1,['error'],['error']
Availability,"Hi there - random question, but for some reason, after applying this plotting solution, it specifically then leads to an error being thrown when the adata object is written (I double checked, and this doesn't happen if this `scv.pl.scatter` command isn't called). . `--> 103 write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs)`. `TypeError: Can't implicitly convert non-string objects to strings`. Is something stored in the object that is specific to this here, that can lead to an AnnData write error? The issue relates to the .obs column, and I can certainly save the adata object if not running this plotting command. I also checked the dtypes of the obs columns, and there doesn't seem to be anything out of the ordinary there either. Any help would be appreciated, it took me some time to figure out this was causing the issue! (and it's a bit frustrating to not be able to save an object just from running a plot command)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-1862227440:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-1862227440,2,['error'],['error']
Availability,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1108:404,error,error,404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108,1,['error'],['error']
Availability,"Hi there!. I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; > Collecting package metadata (repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: - ; > Found conflicts! Looking for incompatible packages.; > This can take several minutes. Press CTRL-C to abort.; > failed ; > ; > UnsatisfiableError: The following specifications were found to be incompatible with each other:; > ; > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:; > ; > - feature:/linux-64::__glibc==2.31=0; > - feature:|@/linux-64::__glibc==2.31=0; > ; > Your installed version is: 2.31",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859:193,error,error,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859,2,"['Avail', 'error']","['Available', 'error']"
Availability,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:136,error,error,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140,3,['error'],['error']
Availability,"Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'); TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File; x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData; file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'; exec(open(wget.download(file_url)).read()); adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435,3,"['down', 'error']","['download', 'error']"
Availability,"Hi there,. I was trying do dig down to understand the problem in #559 , and I found out that in my ```plotting/_anndata.py``` [these lines](https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/plotting/_anndata.py#L828-L837) and all the ones related to ```standard_scale``` are missing. So I created a new conda environment and tried to install a new version of scanpy, but this did not solve the issue (i.e. the problem is not with my old environment) as these lines are still missing. . When I tried to replace the file and re-run my heatmap I got a different error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); <ipython-input-5-49e0357ed731> in <module>; ----> 1 sc.pl.matrixplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True, standard_scale='var'). /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show, save, **kwds); 1644 var_names=var_names,; 1645 var_group_labels=var_group_labels,; -> 1646 var_group_positions=var_group_positions); 1647 ; 1648 var_group_labels = dendro_data['var_group_labels']. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions); 2332 """"""; 2333 ; -> 2334 key = _get_dendrogram_key(adata, dendrogram, groupby); 2335 ; 2336 dendro_info = adata.uns[key]. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2406 ; 2407 if dendrogram_key not in adata.uns:; -> 2408 from ..tools._dendrogram import dendrogram; 2409 logg.warn(""dendrogram data not found (using key={}). Running `sc.tl.den",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560:31,down,down,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560,2,"['down', 'error']","['down', 'error']"
Availability,"Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this?. Thank you!. **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391:88,error,error,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391,1,['error'],['error']
Availability,"Hi there,; stumbled on this by chance when debugging a similar problem - though I'd share my gained insight:. As @LuckyMD already pointed out [here](https://github.com/theislab/scanpy/issues/435#issuecomment-475722334), the root of the problem is feeding `np.int64` into `sc.preprocessing.log1p`. More specifically, the problem occurs in `log1p_array` [here](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318). When specifying `out` in `np.log1p`, the input types need to be castable. However, `np.log1p` returns `np.floatX` (type code double precision `'d'`) which cannot be cast to `np.int64` (type code long integer `'l'`). The error is reproducible with this small snippet of code:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); np.log1p(x=a, out=a); ```. The error can be prevented like this:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); a = np.log1p(x=a); ```. In the case of `scanpy`, this would mean replacing [this](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318) line of code by `X = np.log1p(X)`. The drawback being that the operation is no longer `inplace`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659:699,error,error,699,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659,2,['error'],['error']
Availability,"Hi there,; using `sc.read(filename, ext='txt')` I get the following irrelevant warning:; `WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].; WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].`; (filename is `GSE136689_Counts_Matrix_AllCells_E8.5_E9.0_E9.5.txt`). digging in the error is raised by the `readwrite` module's function `is_valid_filename(filename)`, that checks the extensions regardless of the 'ext' parameter the `sc.read` function gets, and if it passes it sends it to `_read`. inside the `_read` function, there is a second call to `is_valid_filename`, which raises the second warning (with exactly the same text). seeing as this is the process, i don't get why even have the `ext` parameter, because currently it seams like it is only used to indicate when someone uses an unsupported extension; ; #### Versions. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; PyQt5 NA; appnope 0.1.3; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.05.18.1; cffi 1.15.0; chardet 4.0.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.05.0; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fastcluster 1.1.26; fsspec 2022.3.0; gprofiler 1.0.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.17.0; kiwisolver 1.4.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.0; numpy 1.21.5; packaging 21.3; pandas 1.4.0; parso 0.8.3; pexpect 4.8.0; phyloproc NA; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2288:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288,1,['error'],['error']
Availability,"Hi there. Everytime I run the code _sc.pp.neighbors_ the kernel dies. Unfortunately, there is no error message or error code. It just dies while computing neighbors. Other scanpy codes like _sc.pp.filter_cells_ and _sc.pp.filter_genes_ work without a problem. I'm using:. - windows 10 64-bit 24 gb ram; - python 3.8.5 in jupyter notebook; - numpy 1.19.4; - scanpy 1.6.0. Is there someone who would be able to solve this issue?; Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567,2,['error'],['error']
Availability,"Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:; ----------------------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-54-c0d016811ded> in <module>(); ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames; /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(); 5 import numpy as np; 6 from numpy.polynomial.hermite_e import HermiteE; ----> 7 from scipy.misc import factorial; 8 from scipy.stats import rv_continuous; 9 import scipy.special as special. ImportError: cannot import name 'factorial'; ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687:211,error,error,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687,1,['error'],['error']
Availability,"Hi to all, thanks for your interest in glmpca. I have been thinking of doing a python package now that the R package is finished and it would be an honor to have it included in scanpy. Can you give me a sense of how urgently you would need the package (ie what is the typical release cycle)? Also let me note a few caveats about the method:; * It does not handle zero inflation (which ZINB-WAVE does). However, we argue in our paper that despite large numbers of zeros, UMI data are not zero-inflated. We do not make any claim about the appropriateness of the glmpca model for non-UMI data (eg Smart-Seq read counts), which may actually be zero-inflated, although you could certainly run it with eg the negative binomial likelihood.; * glmpca is an alternative to PCA but not necessarily a replacement to PCA. For example, it is at least 10x slower than PCA and we are still working on the big data implementation for sparse matrices (in other words, we assume you can load the data matrix in dense form, which can be limiting).; * We describe a fast approximation to GLM-PCA in the paper which involves transforming raw counts to either Pearson or deviance residuals from a null model then applying standard PCA to that. This approach is just as fast as PCA as long as the null model can be computed in closed-form, which is what we have implemented here: https://github.com/willtownes/scrna2019/blob/master/util/functions.R#L164 . The idea is similar to the sctransform approach used by seurat, but the computation is simpler and faster.; * We also provide a deviance-based gene filtering method which is an alternative to using highly variable genes. This and the residuals functions will be available as an R package on bioconductor. I look forward to collaborating with you all to help make these methods available to a wider community!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230:1695,avail,available,1695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230,4,['avail'],['available']
Availability,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480:111,avail,available,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480,2,['avail'],['available']
Availability,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733,1,['error'],['error']
Availability,"Hi! Thanks for using scanpy!. The error is in [`anndata`](https://github.com/theislab/anndata) so filing a bug there would be more fitting. I did it for you: https://github.com/theislab/anndata/issues/23. ---. Lastly, please do ```` ```pytb ```` for your python tracebacks blocks so we get syntax highlighting:. > ````markdown; > I also get the error when I try to use it with jupyter notebook:; > ; > ```pytb; > import scanpy.api as sc; > ; > Traceback (most recent call last):; > ; > File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-> packages/IPython/core/interactiveshell.py"", line 2910, in run_code; > exec(code_obj, self.user_global_ns, self.user_ns); > ; > […]; > ; > SyntaxError: invalid syntax; > ```; > ````. This would look like this:. > I also get the error when I try to use it with jupyter notebook:; > ; > ```pytb; > import scanpy.api as sc; > ; > Traceback (most recent call last):; > ; > File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; > exec(code_obj, self.user_global_ns, self.user_ns); > ; > […]; > ; > SyntaxError: invalid syntax; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/160#issuecomment-391972041:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160#issuecomment-391972041,3,['error'],['error']
Availability,"Hi!. I have tried using the tutorial for basic spatial analysis available in the docs.; Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```; sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",; groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],; alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only.; values = values.replace(values.categories.difference(groups), np.nan); ```; The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2362:64,avail,available,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362,1,['avail'],['available']
Availability,"Hi!. It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316:239,avail,available,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316,1,['avail'],['available']
Availability,"Hi!; As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb; >>> import scanpy; ...; File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in; import tables; File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in; from .file import File, open_file, copy_file; File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in; from . import hdf5extension; ImportError: DLL load failed: The specified procedure could not be found.; ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454:275,error,error,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454,2,"['Down', 'error']","['Downgrading', 'error']"
Availability,"Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R?; ; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/348:83,error,errors,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348,1,['error'],['errors']
Availability,"Hi, . Actually that's not what I've experienced - if you compare with default rank_genes_groups test you get genes with positive **and** negative logFC, which means that the test reports both upregulated and downregulated genes in that comparison, but again, it's not symmetric - please try on a test dataset for yourself.. Also if I take lists produced by A vs B comparison and B vs A and filter the genes by a common adjusted p-value cutoff (0.05 let's say) I would get lists of different sizes, so all of that makes me think that the tests are not symmetric/two-sided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259:208,down,downregulated,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259,1,['down'],['downregulated']
Availability,"Hi, . I have an issue with the standard_scale ='var' function.; Whenever I try to make any plot and scaling the data from 0 to 1 with the standard_scale = 'var' function I get the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-432-bef389f3fd99> in <module>; ----> 1 gs = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', dendrogram=True, standard_scale='var'). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\plotting\_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\__init__.py in inner(ax, data, *args, **kwargs); 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1809 RuntimeWarning, stacklevel=2); -> 1810 return func(ax, *args, **kwargs); 1811 ; 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\axes\_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5773 kwargs.setdefault('snap', False); 5774 ; -> 5775 collection = mcoll.PolyCollection(verts, **kwargs); 5776 ; 5777 collection.set_alpha(alpha). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565,1,['error'],['error']
Availability,"Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/768:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768,1,['error'],['error']
Availability,"Hi, . I just stumbled upon the same error, maybe due to the installation method.; Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase); at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,; Raphaël",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312,1,['error'],['error']
Availability,"Hi, . I tried to run `sc.tl.highly_variable_genes` with `flavor=CellRanger` and `n_top_genes = 2000`. I obtained the following error:; ```pytb; /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 280 n_top_genes=n_top_genes,; 281 n_bins=n_bins,; --> 282 flavor=flavor,; 283 ); 284 . /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 141 dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]; 142 dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower; --> 143 disp_cut_off = dispersion_norm[n_top_genes-1]; 144 gene_subset = np.nan_to_num(df['dispersions_norm'].values) >= disp_cut_off; 145 logg.debug(. IndexError: index 1999 is out of bounds for axis 0 with size 1898; ```. I run scanpy in Python 3.7 (linux machine) with the following versions:; ```; scanpy==1.4.5.dev114+gd69832a anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. I suggest to check if `n_top_genes` is larger than `len(dispersion_norm)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/834:127,error,error,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/834,1,['error'],['error']
Availability,"Hi, . I updated the pipeline to use [this singularity container](https://github.com/icbi-lab/borst2021/releases/download/containers-0.2.0/vanderburg_edger.sif). The problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481:112,down,download,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481,1,['down'],['download']
Availability,"Hi, . I'm using your package tl.diffmap in my analysis, and I'm having some difficulties. I have a dataframe I have converted into an anndata object adata. I run the following lines to prepare it for tl.diffmap:. `pp.pca(adata,n_comps=50)`; `pp.neighbors(adata, knn = False, method = 'gauss', n_neighbors = 20)`. I then perform the diffmap:. `tl.diffmap(adata, n_comps = 3)`. and I get the following error:. ![Screen Shot 2019-05-15 at 6 11 47 PM](https://user-images.githubusercontent.com/43049941/58586913-25725d00-822a-11e9-930a-9165efdf60f9.png). I am not sure what I am doing incorrectly here, and I was hoping you could help!. Furthermore, I was wondering why n_comps must be greater than 2?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/668:400,error,error,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/668,1,['error'],['error']
Availability,"Hi, . I've been getting the same error when trying to use `sc.pp.normalize_total` after `sc.pp.downsample_counts.` Normalize total returns a CSR sparse matrix of type `<class 'numpy.int64'>`, which then causes `sc.pp.normalize_total` to error. Not sure where the correct `dtype` should take place.; 	; ```python; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.pp.downsample_counts(pbmc, counts_per_cell=500); sc.pp.normalize_total(pbmc, target_sum=1e4); ```. Here's the traceback:. ```pytb; Normalizing counts per cell. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-136-3305b6c650f4> in <module>; 2 pbmc.X = pbmc.raw.X; 3 sc.pp.downsample_counts(pbmc, counts_per_cell=500); ----> 4 sc.pp.normalize_total(pbmc, target_sum=1e4). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layers, layer_norm, inplace); 166 adata.obs[key_added] = counts_per_cell; 167 if hasattr(adata.X, '__itruediv__'):; --> 168 _normalize_data(adata.X, counts_per_cell, target_sum); 169 else:; 170 adata.X = _normalize_data(adata.X, counts_per_cell, target_sum, copy=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in _normalize_data(X, counts, after, copy); 14 after = np.median(counts[counts>0]) if after is None else after; 15 counts += (counts == 0); ---> 16 counts /= after; 17 if issparse(X):; 18 sparsefuncs.inplace_row_scale(X, 1/counts). TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```. ```; >>> pbmc.X; <700x765 sparse matrix of type '<class 'numpy.int64'>'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417,2,['error'],['error']
Availability,"Hi, . Im using scanpy 1.4.2 to analyze my data, using the following command:. `sc.pp.highly_variable_genes(heart_cmc, flavor = 'cell_ranger', n_top_genes = 1000)`. However, instead of getting 1000 HVG, it reports 1488 HVG. Similar thing happens with higher numbers of HVG (e.g. `n_top_genes = 2000` returns 1999). The scaling then fails with a following error:; _ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported._. Any suggestions on how to fix it? When I dont specify n_top_genes, the thing runs without problems.; Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/662:354,error,error,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/662,1,['error'],['error']
Availability,"Hi, . Thanks for the awesome tool!. May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, ; Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1510:260,error,error,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510,1,['error'],['error']
Availability,"Hi, . Thanks for the quick reply!. I'm attaching the output for `combined_bbknn.obs['scNym']`:. ![Screenshot 2021-03-01 at 11 09 39](https://user-images.githubusercontent.com/3297906/109489440-ca187300-7a7e-11eb-943d-270c0273c3fc.png). This is really weird. When I tested it on my macbook I created a new environment and the problem persisted. However, there I downgraded to `scanpy==1.6` as well, the problem persisted, but the `NA`s weren't there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150:361,down,downgraded,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150,1,['down'],['downgraded']
Availability,"Hi, . is there a possibility to calculate _downregulated_ genes between two clusters? In the function `tl.rank_genes_groups()` I did not find such option though it should be possible with the Wilcoxon test. Afaik in `Seurat.FindMarkers()` there is an option `only.pos` for the Wilcoxon test (https://www.rdocumentation.org/packages/Seurat/versions/3.0.0/topics/FindMarkers).; Following another discussion here about DEG I tried to switch to MAST to get around that but it seems to be available only through R (https://github.com/RGLab/MAST/issues/102). Also Wilcoxon did reasonable well in a recent paper (https://www.nature.com/articles/nmeth.4612).. . Thanks!; Tilo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625:484,avail,available,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625,1,['avail'],['available']
Availability,"Hi, ; I am following the example _robustness.ipynb_ and I get the errors ; _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_; when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it?. Many thanks,; Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/110:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110,1,['error'],['errors']
Availability,"Hi, ; I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : ; `Exception: Genome GRCm38 does not exist in this file.`; But I'm sure it's this genome string in my file. . Reading the same file with ; `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`; I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ???; Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/132:51,error,errors,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132,2,['error'],"['error', 'errors']"
Availability,"Hi, ; I'm having similar issues in using sc.tl.ingest(adata, adata_ref, obs='louvain').; I have updated my Scanpy 1.4.6 and anndata to 0.7.1.; I'm getting the following error message.; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-71-27e22cc8f823> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 119 ; 120 for method in embedding_method:; --> 121 ing.map_embedding(method); 122 ; 123 if obs is not None:. ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method); 407 """"""; 408 if method == 'umap':; --> 409 self._obsm['X_umap'] = self._umap_transform(); 410 elif method == 'pca':; 411 self._obsm['X_pca'] = self._pca(). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _umap_transform(self); 396 ; 397 def _umap_transform(self):; --> 398 return self._umap.transform(self._obsm['rep']); 399 ; 400 def map_embedding(self, method):. ~/opt/anaconda3/lib/python3.7/site-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. Appreciate your comments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541,1,['error'],['error']
Availability,"Hi, ; That was from my own datasets, but I also used the data from here, https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1906.ipynb, and got the same error. ```; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_list; ```. ```; [View of AnnData object with n_obs × n_vars = 2267 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1976 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1663 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 2356 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 2422 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1773 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts']; ```. ```; import mnnpy; corrected = mnnpy.mnn_correct(*adata_list, batch_key=""sample""); ```. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-35-7ad830fcd907> in <module>; 1 import mnnpy; ----> 2 corrected = mnnpy.mnn_correct(*a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367#issuecomment-674176537:218,error,error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367#issuecomment-674176537,1,['error'],['error']
Availability,"Hi, @GeoffSCollins ! To do that, you need to add new columns to `adata.obs` table. A column should contain one value (e.g. `True`) for the group of interest and another value (e.g. `False`) for all the other groups. This is how you can create such columns for each of the values of column `leiden`:. ```python; import pandas as pd. adata.obs = pd.concat([; adata.obs,; pd.get_dummies(adata.obs[""leiden""], prefix=""is_cell_type"").astype(bool).astype(""category""),; ], axis=1); ```. Then you can build a violin plot:. ```python; sc.pl.violin(adata, keys=""total_counts"", groupby=""is_cell_type_NK""); ```; ![download-8](https://user-images.githubusercontent.com/35199218/236865939-768d759a-a581-4ba9-acb9-0104cbf16efd.png). I hope this is useful! Also, a small note: ""UMAP cluster"" is not a correct term. Clusters are obtained completely independently of UMAP by running leiden clustering algorithm. UMAP is just a nice visualisation (which is, however, built ignorant of cluster information).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107:601,down,download-,601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107,1,['down'],['download-']
Availability,"Hi, @brianpenghe .; The current version of scanpy is 1.8.1, it is hard to check the errors for the version which is 1.5 year old (1.5.0). Could you try updating scanpy and checking if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1990#issuecomment-916371848:84,error,errors,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990#issuecomment-916371848,2,['error'],"['error', 'errors']"
Availability,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:480,down,downregulation,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246,1,['down'],['downregulation']
Availability,"Hi, @vikram0010 .; Downgrading umap to 0.39 should help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-623084047:19,Down,Downgrading,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-623084047,1,['Down'],['Downgrading']
Availability,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by ; `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`; and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646:927,avail,available,927,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646,1,['avail'],['available']
Availability,"Hi, I am also still receiving this error!. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-141-e471c5e20fbd> in <module>; > ----> 1 sc.tl.rank_genes_groups(adata, 'louvain_05',n_genes=100,method=""wilcoxon"",use_raw=False); > ; > e:\programs\python\python38\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, layer, **kwds); > 398 mean_rest, var_rest = _get_mean_var(X[mask_rest]); > 399 ; > --> 400 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; > 401 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); > 402 scores[np.isnan(scores)] = 0; > ; > ValueError: math domain error. How can I deal with it? I though it was a bug that is fixed now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022,2,['error'],['error']
Availability,"Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!. Ubuntu 18.04; Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280,1,['error'],['error']
Availability,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448,1,['error'],['error']
Availability,"Hi, I am using anndata 0.6.21 and scanpy 1.4.3; I executed this code:; ```; sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]; ```. and I got this error:; `AssertionError: Don’t call _normalize_index with non-categorical/string names; `; Can you help me?. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747,1,['error'],['error']
Availability,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error.; ```; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers; File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32""; ValueError: high is out of bounds for int32; ```; I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283,1,['error'],['error']
Availability,"Hi, I don’t see any errors in your example. Can you please specify what you expected to happen and how what happened differs from that?. Also please provide code as text (in a Markdown code block), not as images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1903490064:20,error,errors,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1903490064,1,['error'],['errors']
Availability,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-534443201:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-534443201,1,['error'],['error']
Availability,"Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---; ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-92-a8f4e965724c> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 607 for col in test_obj.stats.columns.levels[0]:; 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(; --> 609 index=False, column_dtypes=dtypes[col]; 610 ); 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'; ```; I was wondering that its associate with my pandas version? or other issues?; my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1478:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478,1,['error'],['error']
Availability,"Hi, I have downgrade my numab version to 0.51, it works",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-812989390:11,down,downgrade,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-812989390,1,['down'],['downgrade']
Availability,"Hi, I have fixed the issue.; It appears that adding, subtracting or dividing numpy.ndarrays with scipy.sparse matrices returns a numpy.matrix. numpy_array /= scipy_sparse_matrix, This command changed the type of numpy_array to numpy.matrix which caused downstream problems. So, you have to transfer the matrix to sparse format again for downstream analysis.; I used the command 'adata.X = scipy.sparse.csr_matrix(adata.X) ' after dividing the measured counts by the size factor.; So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293:253,down,downstream,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293,2,['down'],['downstream']
Availability,"Hi, I hit this error when trying to filter genes.; A minimal working example is included below. Any help appreciated. ```; def paul15_raw():; filename = 'data/paul15/paul15.h5'; backup_url = 'http://falexwolf.de/data/paul15.h5'; adata = sc.read(filename, 'data.debatched', backup_url=backup_url); # each row has to correspond to a sample, therefore transpose ; adata = adata.transpose() # cluster assocations identified by Paul et al.; clusters = sc.read(filename, 'cluster.id', return_dict=True)['X'].flatten(); # names reflecting the cell type identifications from the paper; cell_types = {i: 'Ery' for i in range(1, 7)}; cell_types[7] = 'MEP'; cell_types[8] = 'Mk'; cell_types[9] = 'GMP'; cell_types[10] = 'GMP'; cell_types[11] = 'DC'; cell_types[12] = 'Baso'; cell_types[13] = 'Baso'; cell_types[14] = 'Mo'; cell_types[15] = 'Mo'; cell_types[16] = 'Neu'; cell_types[17] = 'Neu'; cell_types[18] = 'Eos'; cell_types[19] = 'Other'; adata.smp['paul15_clusters'] = [str(i) + cell_types[i] for i in clusters.astype(int)]; infogenes_names = sc.read(filename, 'info.genes_strings', return_dict=True)['X']; # just keep the first of the two equivalent names per gene ; adata.var_names = np.array([gn.split(';')[0] for gn in adata.var_names]); # remove 10 corrupted gene names ; infogenes_names = np.intersect1d(infogenes_names, adata.var_names); # restrict the data to the 3461 informative genes ; adata = adata[:, infogenes_names]; adata.add['iroot'] = np.flatnonzero(adata.smp['paul15_clusters'] == '7MEP')[0]; return adata; ; adata = paul15_raw(); afilter = sc.pp.recipe_zheng17(adata, n_top_genes=1000, zero_center=True, plot=True, copy=True); ```. or ; ```; afilter = sc.pp.filter_genes_dispersion(adata, n_top_genes=1000); ```. both fail with ; ```AttributeError: 'Series' object has no attribute 'is_dtype_equal'```; when computing the dispersion norm (line 207, simple.py); ```; 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs; --> 208 - disp_mean_bin[df['mea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34,1,['error'],['error']
Availability,"Hi, I hit this error:. AttributeError Traceback (most recent call last); <ipython-input-3-282f1d56354f> in <module>(); ----> 1 sc.pp.magic(adata, verbose=2). c:\scanpy\scanpy\scanpy\preprocessing\magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 148 # replace data with smoothed data; 149 adata.raw = adata; --> 150 adata.X = X_magic.X; 151 ; 152 if copy:. AttributeError: 'numpy.ndarray' object has no attribute 'X'. I fixed it by changing line 150 from adata.X = X_magic.X; to adata.X = X_magic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/206:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/206,1,['error'],['error']
Availability,"Hi, I just wanted to bring this back up again because I've been logging some of the issue's I've encountered. It seems we're at a bit of a philosophical divide, so perhaps it's best for me to just register which use cases I have that AnnData / scanpy are personally causing me friction:. Instead of pasting all errors, I'm just going to paste code blocks I wish worked. Note, these are actual use cases I have regularly encountered. **1. Cannot pass AnnData to numpy or sklearn operators**. ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; from sklearn import decomposition, cluster. data = np.random.normal(size=(100,10)); adata = sc.AnnData(data). # All of the following raise errors; np.sqrt(adata); adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]. adata.obsm['X_PCA'] = decomposition.PCA(2).fit_transform(adata); ```; To answer the question above, I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:311,error,errors,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,2,['error'],['errors']
Availability,"Hi, I know this issue has been previously opened but I am still unable to resolve this problem. Any help would be great.; ---------------------------------------; I am new to Scanpy and I followed this tutorial link below.; https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_01_qc.html. Its a great tutorial and everything is working till I start the following code:-. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). The error I receive is; -----------------------------------------------; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:200: RuntimeWarning: overflow encountered in expm1; X = np.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/Shamini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242:492,error,error,492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242,1,['error'],['error']
Availability,"Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/196:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196,1,['error'],['error']
Availability,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[7], line 13; 11 key = get_second_to_last_split(path); 12 print(key); ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True); 15 # Create unique cell identifiers; 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs); 34 """"""; 35 Read *10x Genomics* Visium formatted dataset.; 36 ; (...); 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata.; 65 """""" # noqa: E501; 66 path = Path(path); ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs); 69 if not load_images:; 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3113#issuecomment-2406243805:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113#issuecomment-2406243805,2,['error'],['error']
Availability,"Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you!. `View of AnnData object with n_obs × n_vars = 1358 × 1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2423:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423,1,['error'],['error']
Availability,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:1006,error,errors,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['error'],['errors']
Availability,"Hi, I was just trying to use the package but it seems that somebody is working on the master branch right now. Would it be possible to set up a development branch and maybe add a few tags for the working versions so that people could download a particular release instead of an in-progress master branch? I also noticed that the notebooks disappeared right after I cloned the repository. It seems like there are some big changes going on, so sorry if the timing for this issue is not right and you are just cleaning up the repository.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7:234,down,download,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7,1,['down'],['download']
Availability,"Hi, I was trying to use the most recent version but saw this error in 1.4.5 and above. ```; scanpy==1.4.5 anndata==0.7rc2 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0rc1 python-igraph==0.7.1; ```. ```; adata = sc.datasets.pbmc3k(); sc.pp.calculate_qc_metrics(adata, inplace=True); ```; output:; ```; ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-5-0d8cf2779f18> in <module>; 1 adata = sc.datasets.pbmc3k(); ----> 2 sc.pp.calculate_qc_metrics(adata, inplace=True). ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below.; Any idea of what is happening?. ```pytb; >>> filter_result = sc.pp.filter_genes_dispersion(; ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5); Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion; disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]; File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__; setitem(key, value); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem; self._where(~key, value, inplace=True); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where; level=level, fill_value=np.nan); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align; broadcast_axis=broadcast_axis); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align; fill_axis=fill_axis); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series; return_indexers=True); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join; return_indexers=return_indexers); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic; ridx = self._left_indexer_unique(sv, ov); File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object; ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158,1,['error'],['error']
Availability,"Hi, I've recently been searching for the functionalities listed above and came across this issue from 2020. Are there any updates on when these functions might potentially be available? :) Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913:175,avail,available,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913,1,['avail'],['available']
Availability,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of; cellranger, we use 10X generate the library. Follow your; recommended tutorial, I can't small size it. Do you have any other; suggestions? The code is: adata = sc.read_10x_mtx(; 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',; cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 于2020年6月5日周五 上午2:31写道：. > The idea behind a self contained example is to give me something that I; > can run on my machine. Ideally you'd be able to put something together with; > randomly generated data that still gave this error. If that's difficult,; > you could keep removing elements from your data until you find the minimal; > object that can reproduce this. Here is a good blog post on how to do this; > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>.; >; > Right now, I'm unable to reproduce the error you're seeing. Do you think; > you could try and create an example you could share with me? This could; > even be sharing your data as an h5ad file.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-640293437:649,error,error,649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-640293437,2,['error'],['error']
Availability,"Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483:13,avail,available,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483,2,['avail'],['available']
Availability,"Hi, can you please create an issue with a minimal reproducible example?. Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb; > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`; > |; > 266 | try:; > 267 | pca_.partial_fit(chunk); > 268 | except:; > | ^^^^^^ E722; > 269 | continue; > |; > ```; > ; > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084:668,error,error,668,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084,1,['error'],['error']
Availability,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664,4,['error'],['error']
Availability,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261#issuecomment-2376233635:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261#issuecomment-2376233635,4,['error'],['error']
Availability,"Hi, please provide the data you use, otherwise this is not reproducible:. ```pytb; FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488:265,error,error,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488,1,['error'],['error']
Availability,"Hi, sorry for the delay, sure,. I have my adata object and let's say a key 'group' in the annotation that can either be A or B for each cell, and then I do:; sc.tl.rank_genes_groups(adata, groupby='group', n_genes=1000). As a result, from the object attributes I can get the tables of DE genes, so I get a table for group A vs rest (which is only group B in this case) and for group B vs rest (which is only group A). Both of these lists contain both upregulated and downregulated DE genes, but are not symmetrical. Let me know if this is unclear. . Thank you. . Sincerely, ; Anna Arutyunyan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-555278819:467,down,downregulated,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-555278819,1,['down'],['downregulated']
Availability,"Hi, thanks again for your interest in GLM-PCA. We welcome its inclusion in scanpy, but some caveats are that it is about 10x slower than PCA and we are still working to improve its numerical stability and ability to handle sparse data matrices. . With that in mind, we have put together an implementation of [Pearson and deviance residuals](https://github.com/kstreet13/scry/blob/master/R/nullResiduals.R) as an approximation to GLM-PCA via the [scry R package](https://github.com/kstreet13/scry). These residuals, based on binomial and poisson approximation to multinomial, can be computed in closed form so they are computationally as fast as log-transforming. The sctransform method uses a negative binomial likelihood which doesn't have a closed form solution and is more complicated to implement (although we do recomment it from a statistical validity standpoint). . In addition to the null residuals, the scry package has an implementation of [feature selection via deviance](https://github.com/kstreet13/scry/blob/master/R/featureSelection.R), which may also be of interest as an alternative to highly variable genes. This is also a closed form computation. Both the feature selection and null residuals functions allow adjusting for categorical batch labels. I do hope to implement both of these in python eventually but it's pretty far down my to-do list. Given the functions are fairly simple, I welcome anyone to go ahead and copy them into python if they find it potentially useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190:1346,down,down,1346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190,2,['down'],['down']
Availability,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2165:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165,3,['error'],['error']
Availability,"Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ?; It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-660090356:184,ping,pinging,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-660090356,1,['ping'],['pinging']
Availability,"Hi, thanks for your answer. How do you remove a graph slot from a Seurat object? When I try, I get this error:; ```; > dataset@graphs <- NULL; Error in (function (cl, name, valueClass) : ; assignment of an object of class “NULL” is not valid for @‘graphs’ in an object of class “Seurat”; is(value, ""list"") is not TRUE; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```python; adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2189:185,error,errors,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189,1,['error'],['errors']
Availability,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884:49,down,downgrade,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884,2,"['down', 'error']","['downgrade', 'error']"
Availability,"Hi, was it just fixed? If I clone right now, will I not have to downgrade scipy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656337276:64,down,downgrade,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656337276,1,['down'],['downgrade']
Availability,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed.; For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033480485:360,down,download,360,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033480485,1,['down'],['download']
Availability,"Hi, when importing a loom file I get the following error. ```; >>> import scanpy.api as sc; >>> adata = sc.read_loom('/path/to/loom_file.loom'); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py"", line 186, in read_loom; dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 672, in __init__; filename=filename, filemode=filemode); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 850, in _init_as_actual; ['obs_names', 'row_names', 'smp_names']); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 287, in _gen_dataframe; columns=[k for k in anno.keys() if k != index_name]); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py"", line 392, in __init__; mgr = init_dict(data, index, columns, dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 212, in init_dict; return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 56, in arrays_to_mgr; arrays = _homogenize(arrays, index, dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 277, in _homogenize; raise_cast_failure=False); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 658, in sanitize_array; raise Exception('Data must be 1-dimensional'); Exception: Data must be 1-dimensional; ```. Does anybody knows the reason why?; Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/649:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/649,1,['error'],['error']
Availability,"Hi,. Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; 3. Your data may have been pre-processed to take out mitochondrial genes. I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639#issuecomment-491470751:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491470751,1,['error'],['error']
Availability,"Hi,. Check your `sc.pp.pca()` results. This is normally the origin of the differences. If you use `svd_solver='arpack'` it's more reproducible between systems (and more robust in general), but there will still be some differences due to the underlying numeric libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/681#issuecomment-499118751:169,robust,robust,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681#issuecomment-499118751,1,['robust'],['robust']
Availability,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:523,error,error,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720,1,['error'],['error']
Availability,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6?. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883,1,['error'],['error']
Availability,"Hi,. I am getting an error when loading my loom files, which did not happen before and I am not capable of understanding the error output to try to fix it. . ![screen shot 2018-08-29 at 10 58 23](https://user-images.githubusercontent.com/42487820/44760841-9b527680-ab7b-11e8-9e85-0d0235cee6db.png). Your help will be much appreciated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247,2,['error'],['error']
Availability,"Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/431:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431,2,['error'],['error']
Availability,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:347,ERROR,ERROR,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,2,"['ERROR', 'error']","['ERROR', 'errored']"
Availability,"Hi,. I am testing `pl.scatter` and it seems that:; - `color` cannot be a list (contrary to what the documentation mentions); - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311:157,error,error,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311,1,['error'],['error']
Availability,"Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. No problem, but if I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> adata.write('anndata.h5ad'); >>> adata = sc.read_h5ad('anndata.h5ad'); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. then I got the error:. ```; Traceback (most recent call last):; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin; orient='vertical', scale=scale, ax=ax, **kwds); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot; color, palette, saturation); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables; raise ValueError(err); ValueError: Could not interpret input 'variable'; ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/318:637,error,error,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318,1,['error'],['error']
Availability,"Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function; 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/310:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310,1,['error'],['error']
Availability,"Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):; File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>; sc.pl.umap(adata); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap; return embedding(adata, 'umap', **kwargs); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding; data_points, components_list = _get_data_points(adata, basis, projection, components); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points; f""Could not find entry in `obsm` for '{basis}'.\n""; KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata; Out[34]: ; AnnData object with n_obs × n_vars = 1858 × 366 ; obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'; var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; uns: 'log1p', 'pca', 'neighbors', 'leiden'; obsm: 'X_pca'; varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1095:199,error,error,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095,1,['error'],['error']
Availability,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009:340,down,downstream,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009,1,['down'],['downstream']
Availability,"Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`.; I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```; Traceback (most recent call last):; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path; idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__; return self._getitem_column(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column; return self._get_item_cache(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache; values = self._data.get(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get; loc = self.items.get_loc(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328:288,error,error,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328,1,['error'],['error']
Availability,"Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:; *** multi-threaded process forked ***; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188; 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x0000000102ac30e6 call_function + 491; 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747; ```. Here's what I was running to cause that:. ```python; import numpy as np; import scanpy.api as sc; from anndata import AnnData; from scipy.sparse import random. adata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182:573,fault,fault,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182,1,['fault'],['fault']
Availability,"Hi,. I get the same error that OP posted. I have the latest versions of both scanpy and anndata. When I run it locally on my Jupyter notebook there is no error and it works but when I run it on Jupyter lab I get that error. How should I go about fixing this ?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-1159774050:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-1159774050,3,['error'],['error']
Availability,"Hi,. I have been Scanpy for a short time and I find it really great!; However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types.; When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```; ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 374 adata.uns[key_added]['names'] = np.rec.fromarrays(; 375 [n for n in rankings_gene_names],; --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]); 377; 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 632 # populate the record array (makes a copy); 633 for i in range(len(arrayList)):; --> 634 _array[_names[i]] = arrayList[i]; 635; 636 return _array. ValueError: setting an array element with a sequence; ```. Do you have any idea of what could cause this error?. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365:324,error,error,324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365,2,['error'],['error']
Availability,"Hi,. I have found that using `sc.api.tl.score_genes()` gives the following error if I input a single gene as gene list:; ```; computing score 'score'; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-27-526dfa387800> in <module>(); ----> 1 sc.tl.score_genes(adata=adata,gene_list= genes). ~/Documents/Python/scanpy/scanpy/tools/score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy); 96 gene_list = list(gene_list); 97 ; ---> 98 score = np.mean(adata[:, gene_list].X, axis=1) - np.mean(adata[:, control_genes].X, axis=1); 99 adata.obs[score_name] = pd.Series(np.array(score).ravel(), index=adata.obs_names); 100 . ~/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py in mean(a, axis, dtype, out, keepdims); 2904 pass; 2905 else:; -> 2906 return mean(axis=axis, dtype=dtype, out=out, **kwargs); 2907 ; 2908 return _methods._mean(a, axis=axis, dtype=dtype,. ~/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py in _mean(a, axis, dtype, out, keepdims); 55 ; 56 is_float16_result = False; ---> 57 rcount = _count_reduce_items(arr, axis); 58 # Make this warning show up first; 59 if rcount == 0:. ~/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py in _count_reduce_items(arr, axis); 48 items = 1; 49 for ax in axis:; ---> 50 items *= arr.shape[ax]; 51 return items; 52 . IndexError: tuple index out of range; ```; I suggest that you include a check for the length of the input `gene_list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/105:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/105,1,['error'],['error']
Availability,"Hi,. I have modified version 1.4, but i think git only allow latest version to; fork. Is there any other simple way, so that i can share my code for Scanpy; version 1.4. Thanks,; Khalid. On Sat, May 4, 2019 at 2:26 AM Philipp A. <notifications@github.com> wrote:. > seems like you did something wrong. the commit you added (74540cc; > <https://github.com/theislab/scanpy/commit/74540cc133ca9cfe0744ca9d3b250454a76a9c4d>); > reverts a lot of changes we made since.; >; > i assume you just copied all your code over the current master branch, and; > not the version of the master branch as it was when you made the changes.; >; > you need to find the version of scanpy that you downloaded before you made; > your changes and modify that one to have just the changes you want to; > commit. otherwise we have no idea what your actual changes are.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630#issuecomment-489194292>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOBLBVFOZLO23ZCULELPTR7U3ANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397:676,down,downloaded,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397,2,['down'],['downloaded']
Availability,"Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.; pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168:170,error,error,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168,1,['error'],['error']
Availability,"Hi,. I'm trying to follow the [Dahlin18 PAGA tutorial](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:322,error,error,322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['error'],['error']
Availability,"Hi,. I'm using AGA to build global trajectories on neuronal differentiation datasets. It works well on small subsets of data (only progenitors or only neurons), but produces spurious trajectories between clusters that cannot be explained (progenitors --> inhibitory neurons --> excitatory neurons, rather than progenitors --> excitatory neurons). I'm thinking that part of this may be due to noise/outliers in the dataset. . From the paper (Supplementary Note 3.2), it looks like the connectivity between two partitions are calculated as the minimum distance between all pairs of points, which is prone to outliers. . > Taking the minimum is independent of the specific shape of a partition but is prone to outliers: it is only a viable option as the distance measure d itself is highly robust being computed as an average over all random walks on the graph. . Are there alternative ways to calculate connectivities that are more robust to outliers? (e.g. other connectivity metrics or something like Endpoint Supervision in Slingshot (https://doi.org/10.1101/128843) to avoid connecting endpoints from different lineages.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/96:787,robust,robust,787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96,2,['robust'],['robust']
Availability,"Hi,. I'm working with pseudocounts data (kallisto/alevin/salomon output). I think they are called ""pseudocount"": if a read is assigned to two regions (genes) , a probability is assigned (e.g. gene1=0.2, gene2=0.8). Nevertheless, they can still considered counts and so it would be cool to use the `highly_variable_genes flavour=seuratv3` . ; I added an additional argument in case users would like to enforce this, as it was similarly done/discussed in https://github.com/theislab/scvelo/issues/190. Would like to hear what you guys think, pinging @adamgayoso (thanks for the great overleaf doc! )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642:540,ping,pinging,540,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642,1,['ping'],['pinging']
Availability,"Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful).; Can I do similar things in scanpy? Thanks!. I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:; ```; ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings.; ```; I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,; BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691:440,error,error,440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691,1,['error'],['error']
Availability,"Hi,. Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/647#issuecomment-492964767:129,error,error,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-492964767,1,['error'],['error']
Availability,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2563:201,Ping,Pinging,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563,1,['Ping'],['Pinging']
Availability,"Hi,. The issues I was mostly running into were that when saving the anndata; variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this; action. So, I had to either remove pheno_jaccard_ig from the anndata object; and then save it as h5ad or convert it to a sparse matrix. This also; happened with a few other functions I tried on the anndata object, and I; kept getting the error ""this function is not compatible with COO matrix; format"", always talking about pheno_jaccard_ig. Therefore, since a sparse; matrix object does not have any problems with the functions I was running; on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes; sense to circumvent any of those issues I was getting before. I hope this makes sense.; Thank you,; Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>; wrote:. > Hi,; >; > could you please provide more details? What issues did you run into?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180:389,error,error,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180,1,['error'],['error']
Availability,"Hi,. This bug report may be better placed in the single-cell-tutorial repo as you're having issues with how the tools are chained. A few things to check:; - Are you using sparse matrices in your data?; - are the size factors you get all real numbers (not `NaN`)?. I've seen this error before... just can't remember what the issue was. I think it was sparse matrices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641#issuecomment-491765979:279,error,error,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491765979,1,['error'],['error']
Availability,"Hi,. This might have to do with scipy 1.3.0. If you downgrade to 1.2.1 this should work for the moment. Scipy 1.3.0 compatibility is being fixed atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695#issuecomment-503465544:52,down,downgrade,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695#issuecomment-503465544,2,['down'],['downgrade']
Availability,"Hi,. To have a depth understanding, I wanted to set the resolution high for louvain clustering, but now I cannot merge subclusters. When I try to rename the categories with same cluster name, it gives an error about not having unique names. Yet, I could not find a functional merge_clusters function. Is there anyone having the same issue as me? I would appreciate any help. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/925:204,error,error,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/925,1,['error'],['error']
Availability,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618,2,['error'],['error']
Availability,"Hi,. When I ran; ```; import scanpy.api as sc; ```; I met this error:; ```; 19 from scipy import sparse; 20 from scipy.sparse import issparse; ---> 21 from scipy.sparse.sputils import IndexMixin; 22 from natsort import natsorted; 23 . ImportError: cannot import name 'IndexMixin'; ```; Is there any requirements for the version of scipy?. Thanks in advance,; BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643,1,['error'],['error']
Availability,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:483,down,down-regulated,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464,1,['down'],['down-regulated']
Availability,"Hi,. please format your code and the error.; Also, please provide a more in depth description. What were you trying to do? A minimal example helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-882743129:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-882743129,1,['error'],['error']
Availability,"Hi,. thanks for the input and the nice description. Agree that this would be nice to have within scanpy itself. And agree, as you’ve shown in your example, that this should be the case when setting `copy=True`. I have set up a draft PR for the moment, with a suggestion where the error message especially persists when `copy=False`; I’d suggest to keep it this way:. - Overwriting the backed file seems not to be the expected behaviour to me; - Writing a new file for backing would occur in a rather hidden manner, confusing the user or even unexpectedly further fill the disk at worst over time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054:280,error,error,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054,1,['error'],['error']
Availability,"Hi,; I am getting the following error when trying to plot my spatial data. ```py; with mpl.rc_context({'axes.facecolor': 'black',; 'figure.figsize': [4.5, 5]}):; ; sc.pl.spatial(slide, cmap='magma',; color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; ncols=3, size=1.3, ; img_key='hires',; # limit color scale at 99.2% quantile of cell abundance; vmin=0, vmax='p99.2' ; ); ```. ```pytb; TypeError Traceback (most recent call last); Cell In[11], line 14; 10 # plot in spatial coordinates; 11 with mpl.rc_context({'axes.facecolor': 'black',; 12 'figure.figsize': [4.5, 5]}):; ---> 14 sc.pl.spatial(slide, cmap='magma',; 15 # show first 8 cell types; 16 color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; 17 ncols=3, size=1.3, ; 18 img_key=None,; 19 # limit color scale at 99.2% quantile of cell abundance; 20 vmin=0, vmax='p99.2' ; 21 ). File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:993, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 990 cmap_img = None; 991 circle_radius = size * scale_factor * spot_size * 0.5; --> 993 axs = embedding(; 994 adata,; 995 basis=basis,; 996 scale_factor=scale_factor,; 997 size=circle_radius,; 998 na_color=na_color,; 999 show=False,; 1000 save=False,; 1001 **kwargs,; 1002 ); 1003 if not isinstance(axs, list):; 1004 axs = [axs]. File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:169, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499,1,['error'],['error']
Availability,"Hi,; I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:; ```python; sc.pl.pca_variance_ratio(adata_h, log=True, save=True); ```; Result:; ```; /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log; if log: scores = np.log(scores). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-48cc676a34cc> in <module>(); 1 # log is natural logarithm; ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save); 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}.; 158 """"""; --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log); 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save); 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show); 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]); 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,; --> 557 (1.05 if score_max > 0 else 0.95) * score_max); 558 if show == False: return gs; 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs); 1588 if not args and not kwargs:; 1589 return ax.get_ylim(); -> 1590 ret = ax.set_ylim(*args, **kwargs); 1591 return ret; 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw); 3455 bottom, top = bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:123,error,error,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,1,['error'],['error']
Availability,"Hi,; I am trying to run the full 1.3M 10X mouse cell dataset (using the 1M_neurons_filtered_gene_bc_matrices_h5.h5 file from 10X website).; I have 126GB RAM and Intel® Xeon(R) W-2123 CPU @ 3.60GHz × 8 which is above the requirements you mention needed to run the full cluster.py method without subsampling. (https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells); I get a memory error at the normalization and filter_genes_dispersion stage, should i modify the code in anyway? (without subsampling); Thanks,Shobi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511:415,error,error,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511,1,['error'],['error']
Availability,"Hi,; I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter.; However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); in ; 1 #%%; ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 283 """"""; --> 284 return plot_scatter(adata, 'umap', **kwargs); 285 ; 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 191 if projection == '3d':; 192 cax = ax.scatter(; --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],; 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2; ```. I was able to plot in 3d by changing it to the following method signature:; ```python; > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']); ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/677:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677,1,['error'],['error']
Availability,"Hi,; I converted the obs and values in string and it worked.; Thanks. On Mon, 29 Jul 2019 at 06:59, Isaac Virshup <notifications@github.com>; wrote:. > Hi. I just tried running that, and wasn't able to reproduce that error.; > Here's what I ran:; >; > import scanpy as sc; >; > adata = sc.datasets.pbmc3k(); > sc.pp.filter_genes(adata, min_counts=1); > sc.pp.log1p(adata); > sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); > sc.pl.highly_variable_genes(adata); > adata = adata[:, adata.var['highly_variable']]; >; > Could you update to the latest releases (scanpy 1.4.4, anndata 0.6.22); > and try that?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/747?email_source=notifications&email_token=ACPDY4U77PLSKFM4ZNQRBYLQBZ2LBA5CNFSM4IG2HWJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD27SWAA#issuecomment-515844864>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACPDY4VLMX7TXWMWLRDBTPLQBZ2LBANCNFSM4IG2HWJQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061:217,error,error,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061,1,['error'],['error']
Availability,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1468:40,error,error,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468,2,['error'],['error']
Availability,"Hi,; I encountered a wired problem when I run UMAP with min_dist=0.1; `sc.tl.pca(adata_f,n_comps=250)`; `adata_f.obsm['X_pca'] *= -1 `; `sc.pp.neighbors(adata_f, n_neighbors=10)`; `scv.pp.moments(adata_f,renormalize=True,mode='connectivities')`; `sc.tl.umap(adata_f,min_dist=0.1)`; error is about produce NaN, and then I checked `adata_f.obs['X_umap']`, all NaN in array.; However, when I use min_dist=0.2, everything seems well. ; Could you help me to figure it out? Thank you~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/257:282,error,error,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/257,1,['error'],['error']
Availability,"Hi,; I tried to set the y-axis limit, but failed with the error:. >>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False); >>> for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; AttributeError: 'str' object has no attribute 'set_ylim'. I use scanpy 1.8.1.; Do you have any idea? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921089934:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921089934,1,['error'],['error']
Availability,"Hi,; I was reading some mtx file from here: ; https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`; `AnnData object with n_obs × n_vars = 25052 × 606606; ` ; `sc.__version__`; `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. ; That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>; ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1761:96,down,downloads,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761,1,['down'],['downloads']
Availability,"Hi,; I was trying to run the quick example described in the magic api cmd using datasets.paul15 but it keeps on giving me the same error. See below the code I used and the error it gives. . import numpy as np; import pandas as pd; import scanpy.api as sc; import matplotlib.pyplot as pl; import phate; import magic. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; sc.logging.print_version_and_date(); # we will soon provide an update with more recent dependencies; sc.logging.print_versions_dependencies_numerics(). Running Scanpy 1.2.2+72.gbc6661c on 2018-07-18 19:40.; Dependencies: anndata==0.6.5 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . adata = sc.datasets.paul15(). WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical. sc.pp.normalize_per_cell(adata); sc.pp.sqrt(adata); adata_magic = sc.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); adata_magic.shape. computing PHATE. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-79-129f35d34dbd> in <module>(); 2 sc.pp.normalize_per_cell(adata); 3 sc.pp.sqrt(adata); ----> 4 adata_magic = sc.pp.magic(adata.X, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); 5 adata_magic.shape. ~/software/scanpy/scanpy/preprocessing/magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 131 n_jobs=n_jobs,; 132 verbose=verbose,; --> 133 **kwargs).fit_transform(adata,; 134 genes=name_list); 135 logg.info(' finished', time=True,. TypeError: 'module' object is not callable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,3,['error'],"['error', 'errors']"
Availability,"Hi,; I'm attempting to run scvelo on my scanpy processed 10x data.; Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file.; I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'.; I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo).; My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/342:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342,2,['error'],['error']
Availability,"Hi,; I'm encountering an error when trying to write result file, after perform cell cycle score.; After normalizing, I import cell cycle file and perform the score:. `cc_genes=[gene.strip() for gene in open('[my_cell_cycle_genes]')]; s_genes=[g for g in cc_genes[:43] if g in adata.var_names]; g2m_genes=[g for g in cc_genes[43:] if g in adata.var_names]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes); `. The field 'phase' of the obs. matrix is of type object:; `adata.obs.phase.dtypes; dtype('O')`. When I write the annData object, I got the error:; `adata.write(results_file); ... storing 'phase' as categorical; TypeError: Categorical is not ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one`. and now the field 'phase' is categorical:; `adata.obs.phase.dtypes; CategoricalDtype(categories=['G1', 'G2M', 'S'], ordered=False)`. I can modify it as suggested, but it's converted into categorical when writing file again.; Following my version packages:; `sc.logging.print_versions(); scanpy==1.4.2 anndata==0.6.17 umap==0.3.7 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1`. My annData, also on a subset of variables, is too big to attach here, but I could send you by email if you need it. Thanks a lot!; Raffaella",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/645:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/645,2,['error'],['error']
Availability,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/840:294,error,errors,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840,1,['error'],['errors']
Availability,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578:61,down,downstream,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578,1,['down'],['downstream']
Availability,"Hi,; More of a request than an issue. I am trying to replicate FindVariableFeatures with option selection.method = ""vst"" in seurat by using highly_variable_genes function in scanpy,i went through the documentation but could not find this option,is it available and am i missing something or is it not implemented yet. It would be nice to have this option. Thank you; Sasi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/497:251,avail,available,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/497,1,['avail'],['available']
Availability,Hi. I can’t copy/paste/run the above code sample. There’s nowhere you define `adata`. Please add some code that uses some builtin dataset or so and reproduces the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367#issuecomment-673941590:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367#issuecomment-673941590,1,['error'],['error']
Availability,"Hi. I just tried running that, and wasn't able to reproduce that error. Here's what I ran:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); sc.pl.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; ```. Could you update to the latest releases (scanpy `1.4.4`, anndata `0.6.22`) and try that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864,1,['error'],['error']
Availability,"Hi. I'm struggling with the same issue that is not resolved with the suggestions above (using other scipy version==1.2.1). I have scanpy==1.6.0 and scipy==1.5.2 in my environment. I am using Ubuntu in Windows. And when I import scanpy in jupyter notebook, I get the error:. **`ImportError: cannot import name 'IndexMixin' from 'scipy.sparse.sputils' (/home/levinbioinformatics/anaconda3/envs/scgen-env/lib/python3.7/site-packages/scipy/sparse/sputils.py)`**. Please advise!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-691921390:266,error,error,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-691921390,1,['error'],['error']
Availability,"Hi. Please see below for the minimal script used. Thanks!. ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; import matplotlib.pyplot as plt; from pathlib import Path. scv.settings.set_figure_params('scvelo'). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.autosave = True; sc.settings.autoshow = False; sc.set_figure_params(scanpy=True, dpi=80, dpi_save=160, frameon=False, vector_friendly=False, format='pdf'). adata = sc.read_loom(""./Velocyto_comb.loom""). sc.pp.filter_cells(adata, min_genes=1000); sc.pp.filter_genes(adata, min_cells=10). print('\nDoing initial filtering...\nKeeping', len(adata.obs_names), 'cells and', len(adata.var_names), 'genes.\n'). mito_genes = adata.var_names.str.startswith('MT-'); # Calculate the percent of genes derived from mito vs genome; # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing); adata.obs['percent_mito'] = np.sum(; 	adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; # add the total counts per cell as observations-annotation to adata; adata.obs['n_counts'] = adata.X.sum(axis=1).A1. sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],; 			 jitter=0.4, multi_panel=True, save = '_preFiltering_plot.pdf', show = False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-478651835:294,error,errors,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478651835,1,['error'],['errors']
Availability,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:409,error,error,409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability,"Hi; I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:; AttributeError Traceback (most recent call last); <ipython-input-187-32c3eda3cdc8> in <module>; ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr); 687 return self.getnnz(); 688 else:; --> 689 raise AttributeError(attr + "" not found""); 690 ; 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found; Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/760:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760,2,['error'],['error']
Availability,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220:267,error,error,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220,1,['error'],['error']
Availability,"Hi; Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:; ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png); Can I modify the y axis limits? I'm sorry I haven't find the parameters yet.; And when I try to use `use_raw=False`, I got error:; `ValueError: Data must be 1-dimensional`; `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`; And my code:; `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`; and my version:; `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer!; Best,; Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1766:410,error,error,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766,1,['error'],['error']
Availability,"Hia everyone, this should actually make`hatch test -i deps=min` work even on Macbooks. Maybe there’s a way to put the constraint file inside of the venv, then it’ll survive reboots on Linux. I tagged you all because I thought you might be interested in this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3337:173,reboot,reboots,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3337,1,['reboot'],['reboots']
Availability,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type; ```; import psutil; psutil.process_iter(); ```; does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821,2,['error'],['error']
Availability,"Hm, PyTorch 1.12.1 doesn’t seem to be available, otherwise I was able to install all package versions you specified. I created an attempt at a reproducer here, but it just runs in less than a second for me: https://github.com/flying-sheep/scanpy-2531. No idea how to further debug this. Looks like you’re on macOS. one of the new M1 or M2 ones?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107:38,avail,available,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107,1,['avail'],['available']
Availability,"Hm, but it looks like https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html should be reproducible with the default settings. In what you describe, only pca, louvain and umap have stochastic elements all of which set a default seed in the function call. I have never observed issues with reproducibility there. Can we narrow it down to score_genes? Or do you think it's somewhere else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-431367763:349,down,down,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-431367763,1,['down'],['down']
Availability,"Hm, looking at the errors, they don't seem to be really related to the changes in this PR, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484:19,error,errors,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484,1,['error'],['errors']
Availability,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:136,avail,available,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216,2,['avail'],['available']
Availability,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb; ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7'].; ```. PS: The error is raised by the following. ```py; if (reference != 'rest' ; and reference not in set(adata.obs[group_by].cat.categories)): ; raise ValueError('reference = {} needs to be one of group_by = {}.' ; .format(reference, ; adata.obs[group_by].cat.categories.tolist())); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/94#issuecomment-369132536:357,error,error,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94#issuecomment-369132536,2,['error'],['error']
Availability,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:930,ERROR,ERROR,930,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"Hm, this is really strange. Sorry about this. The docker image might be out-of-date now - you compiled, @flying-sheep, what do you think?. But you shouldn't need the docker image to exactly reproduce the results. Which versions do you run?. The latest version of the tutorial says; ```; scanpy==1.0.2 anndata==0.5.8 numpy==1.14.1 scipy==1.0.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Your error is a Pandas error - do you run an older or more recent version of Pandas that might cause the problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-390636495:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-390636495,4,['error'],['error']
Availability,"Hm. the conda package doesn’t list availability for windows: https://anaconda.org/bioconda/scanpy, just “conda install linux-64 v1.3.7, osx-64 v1.3.7”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888:35,avail,availability,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888,1,['avail'],['availability']
Availability,"Hmm, that sounds like the code is trying to do something like `['a', 'b'] * 1.5`, i.e. repeating a sequence by multiplying. But the line the error points to looks correct: `np.multiply` should try to do element-wise multiplication as intended. Please create a minimal reproducible example. We don’t know what in `slide` causes the bug because we don’t know what it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574,1,['error'],['error']
Availability,"Hmm, weird that it didn't fail against master. Also that I forgot to back port the nice plot errors to 1.7.x. TODO: https://github.com/theislab/scanpy/pull/1587#issuecomment-787808128",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1699#issuecomment-787809506:93,error,errors,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1699#issuecomment-787809506,1,['error'],['errors']
Availability,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python; adata = adata.copy(); ```. right before `normalize_total` and see if that works?. ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991,2,['error'],['error']
Availability,"Hmm... you are right, that should also create an error by the above logic. It does look like this check is done for the case that `adata.n_vars < n_comps` here:; https://github.com/theislab/scanpy/blob/be1a0555252cfd97b9d00f51dc5fbab462588da0/scanpy/preprocessing/_simple.py#L472-L477. I'm not sure why that wasn't also done for `n_obs`. @Koncopd you made this fix at the time... any reason for not also checking `adata.n_obs` in the same way? Could quickly add a check for `adata.n_obs` unless there is a reason not to @ivirshup, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795,1,['error'],['error']
Availability,"Hmm...I must admit I don't understand why a ""view"" exists. Views are often tricky to get right, especially in a complex datastructure like anndata. They also slow down processing, especially if users may not be aware that the object they have is a view of something else. I don't see a good use case for views in my pipeline at least. Is there a way to switch off all views in anndata and just return a copy when slicing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062:163,down,down,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062,1,['down'],['down']
Availability,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813:70,failure,failures,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813,1,['failure'],['failures']
Availability,Hmmm. I am getting this error with scipy 1.4.1. New install of phenograph so I don't have an older version to roll back to. Hopefully they fix this soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883,1,['error'],['error']
Availability,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208,1,['error'],['error']
Availability,"Hopefully last update on this PR. What I did:; - I noticed a regression on the method `rank_genes_groups_violin`, therefore I reverted back the code to the original one and I added an additional method `genes_groups_violin` which should be used if we want to pass the list of genes directly to the violin plot. The code is just a POC, but maybe it can be integrated; - Within the same method `rank_genes_groups_violin`, I found a bug: the ax variable was overwritten for each group (I don't know if it gave you error before). In my case, all the plots were merged into a single figure, every one on top of the previous ones; - Additionally, the parameters `gene_symbols` and `computed_distribution` were not defined within the method `rank_genes_groups_violin`. I added a default parameter (`None`) for `gene_symbols`, since it was defined in the docstring. With `computed_distribution` I didn't know what you wanted to do so I temporarily commented the line that used it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636:511,error,error,511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636,1,['error'],['error']
Availability,"How about MultiIndex?; ```python; df = adata.var.reset_index().set_index(['gene_ids', 'index']); adata2 = sc.AnnData(X = adata.X, var = df); ```. user can subset genes based on:; ```python; genes = ['CD69', 'CD44', 'CXCR5']; idx = adata2.var.index.get_level_values('index').isin(genes); adata2[:,idx]; ```. Seems to initialize ok but throws an issue with `get.py` line 139 when trying to plot with `sc.pl.violin`:; ```python; genes2 = adata2[:,idx].var.index; sc.pl.violin(adata2, genes2). ## error; gene_names = pd.Series(adata.var_names, index=adata.var_names); ```; `initializing a Series from a MultiIndex is not supported`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1719#issuecomment-793798821:493,error,error,493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719#issuecomment-793798821,1,['error'],['error']
Availability,"How about a `check_values` argument which defaults to `True`, and replacing the error with a warning like:. ""Your data doesn't appear to be have integer values, but this method expects raw count data. Proceed with caution."". `check_values` is nice and generic, and could be used in other functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-777188844:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-777188844,1,['error'],['error']
Availability,How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. Could also use `scverse.org` for permanent URIs?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805:12,down,download,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805,2,['down'],['download']
Availability,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:421,error,error,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,2,['error'],['error']
Availability,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1901:52,down,downregulated,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901,4,['down'],"['down', 'downregulated']"
Availability,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936:23,Error,Error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936,1,['Error'],['Error']
Availability,How to show the downregulated marker genes by sc.pl.rank_genes_groups?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2052:16,down,downregulated,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052,1,['down'],['downregulated']
Availability,"How? As said, they’re just for people and IDEs. Scanpy doesn’t use them. It doesn’t throw errors in case something doesn’t fit. We could use https://pypi.org/project/typecheck-decorator/ to throw errors when something is passed that doesn’t fit the annotations. However, doing so has a performance hit and requires flawless annotations (because if the annotations were wrong, that *would* start suddenly throwing errors). I’m just adding type annotations to improve user friendliness by being more clear what functions accept, and because it makes writing documentation easier.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441252542:90,error,errors,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441252542,6,['error'],['errors']
Availability,"Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:. * If you upgrade scipy, do you still run into this error?; * Could you get the version info from an environment where you've only imported scanpy and run this command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166:203,error,error,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166,1,['error'],['error']
Availability,"I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date).; Let me know if you are interested in merging it, and if the code style is acceptable for this library.; I was unsure on how to test it, in case do you have any suggestions?. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141:147,error,error-prone,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141,1,['error'],['error-prone']
Availability,"I addressed some of the points in your review already and will finish latest on Monday :). > > tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; > > tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..); > ; > yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough smile ).; > another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. Sounds good, thanks for the input! I will prepare some tests early next week.; ; > on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it. I think that would be really nice - I'd very happy prepare to some examples if everyone agrees that this would be useful to have :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998:276,error,errors,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998,2,"['error', 'robust']","['errors', 'robust']"
Availability,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040,5,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-748161925:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-748161925,1,['error'],['error']
Availability,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png); ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/757#issuecomment-542159460:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757#issuecomment-542159460,1,['error'],['error']
Availability,I also have encountered this same error when trying to use sc.pl.violin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413,1,['error'],['error']
Availability,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning; > ; > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756:132,failure,failure,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756,1,['failure'],['failure']
Availability,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-469746553:214,error,error,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469746553,1,['error'],['error']
Availability,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252:51,Down,Downgrading,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252,1,['Down'],['Downgrading']
Availability,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735,1,['error'],['error']
Availability,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861,1,['error'],['error']
Availability,"I am also experiencing this issue. Running the following code:; ```; import pandas as pd; import scanpy as sc; import anndata. print(pd.__version__); print(sc.__version__); print(anndata.__version__); adata = sc.datasets.pbmc68k_reduced(); adata.obs[""single_cat""] = 1; adata.obs['single_cat'] = pd.Categorical(adata.obs['single_cat']); adata.write('/tmp/adata.h5ad'); sc.read('/tmp/adata.h5ad'); ```. Returns this error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-adde38d13544> in <module>; ----> 1 sc.read('/tmp/adata.h5ad'). /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 500 if not backed:; 501 f.close(); --> 502 return AnnData._args_from_dict(d); 503 ; 504 . /usr/local/anaconda3/envs/d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409:414,error,error,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409,1,['error'],['error']
Availability,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561,1,['error'],['error']
Availability,"I am also getting the error when running. sc.pp.neighbors(). AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. I tried pip uninstall numba and pip install numba==0.52.0 and numba==0.51.0, but nothing works. I had umap-learn 0.4.6, and updating it resolved the issue for me:; conda install -c conda-forge umap-learn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309,2,['error'],['error']
Availability,I am also running into the same error. Thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252#issuecomment-421671797:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252#issuecomment-421671797,1,['error'],['error']
Availability,"I am also unable to install scanpy on mac OS. I tried using python 3.8.x . 3.7.x and 3.6.x. ```; (base) $ conda activate SCA. (SCA) $ conda --version; conda 4.8.2. (SCA) $ python --version; Python 3.6.10 :: Anaconda, Inc. (SCA) $ conda install -c bioconda scanpy; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \ ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112:679,Avail,Available,679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112,1,['Avail'],['Available']
Availability,I am attaching reduced files. I could reproduce the error with this dataset. Color names are `colors_dataset.txt` file. Note that python script is renamed to `.py.txt` . There was an error in `paga` related plotting function as well. . [R_pca_seurat.txt](https://github.com/theislab/scanpy/files/2455948/R_pca_seurat.txt); [R_annotation.txt](https://github.com/theislab/scanpy/files/2455949/R_annotation.txt); [colors_dataset.txt](https://github.com/theislab/scanpy/files/2455950/colors_dataset.txt); [planaria.py.txt](https://github.com/theislab/scanpy/files/2455953/planaria.py.txt),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-427822048:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-427822048,2,['error'],['error']
Availability,I am encountering the same error. Have you fixed it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090,1,['error'],['error']
Availability,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:664,error,error,664,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['error'],['error']
Availability,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,4,"['Error', 'error']","['Error', 'error']"
Availability,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:428,error,error,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,2,"['down', 'error']","['down', 'error']"
Availability,"I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets.; I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb; LinAlgError Traceback (most recent call last); in ; ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 95; ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)); 97 # now actually compute the dispersion; 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other); 226; 227 def pow(self, other):; --> 228 return matrix_power(self, other); 229; 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603; 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216; 217 def _assertFinite(*arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:386,error,error,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,1,['error'],['error']
Availability,I am getting an error elsewhere that I want to revise before submitting a final version. Hopefully tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-460068606:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-460068606,1,['error'],['error']
Availability,"I am getting the same error in a much more basic setting:; ```; paul=sc.datasets.paul15(); sc.pl.scatter(paul, x=paul.var_names[0], y=paul.var_names[1]); ```; ...; > TypeError: object of type 'numpy.int64' has no len()",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-434297999:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-434297999,1,['error'],['error']
Availability,I am getting the same error. > Exception: Data must be 1-dimensional,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487687285:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487687285,1,['error'],['error']
Availability,"I am getting this error when I run scanpy.pp.neighbors(adata); As far as I know, I have the latest packages mentioned here.; anndata 0.7.6 pypi_0 pypi; louvain 0.7.0 py38h9dedd22_1 conda-forge; pandas 1.1.3 py38hb1e8313_0; python-igraph 0.9.1 py38h3dab7cd_0 conda-forge; scanpy 1.7.2 pypi_0 pypi; scikit-learn 0.23.2 py38h959d312_0; scipy 1.6.3 py38h431c0a8_0 conda-forge; statsmodels 0.12.0 py38haf1e3a3_0; umap-learn 0.5.1 py38h50d1736_0 conda-forge. Is there probably another package that is outdated?. **EDIT: Not sure what module I updated but now it works. I use 'conda update --all' and others to do that.** . thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994,2,['error'],['error']
Availability,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919,2,['error'],['error']
Availability,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840:244,error,errors,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840,1,['error'],['errors']
Availability,"I am more and more convinced about having a single package for the reasons @adamgayoso mentioned. To address a few concerns from above: . ---. > > Who manages the sub-packages?; > ; > Scverse (also it's one package not many). We are talking about 5-15 readers that have been touched a handful of times in 4-5 years. I don't think this is a complicated package to maintain. Agree that one person needs to take the lead on releases (probably very infrequent). Scverse core developers could take turns (e.g. every 6 months) in being ""lead maintainer"", i.e. in charge of releases and first-responders to issues (delegating them to the most appropriate people). This has the additional advantage that everything needs to be documented to a point that there can't be a single point of failure. . ---. > Also it's nice when you install a package call a function and it works, less nice to have to start mucking around with dependencies. ```; pip install scio[all]; ```. could be broadly advertised in the README. Packages could still use the slimmer version, e.g. in scirpy, I could depend on ; `scio[vdj]`. . ---. > I think there are formats where there isn't one obvious ""right way"" to represent them as an AnnData object (e.g. visium), so having a canonical reading/ writing function is difficult. I think we should aim at having one obvious ""right way"" to represent something with AnnData and MuData. A common `scio` package could be a way to achieve that. . > I know squidpy will be changing its representation and I think muon should have changes to the ATAC representation. Also muon and scvi-tools read in different things from 10x atac data. A solution to that would be versioned schemata. E.g. whatever squidpy uses now is the ""spatial schema `v1`"". When we come up with a better way it becomes the ""spatial schema `v2`"". Old schemata will be deprecated but can stick around for a while. If a schema is experimental and subject to active changes it can be `v0.1`. . ```python; scio.spatial.read_vis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261:779,failure,failure,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261,1,['failure'],['failure']
Availability,"I am not so sure, but you may get that error when the matrix contains columns of only ceros. Did you do any filtering of the data before?. Fidel Ramírez . > Am 24.07.2018 um 07:51 schrieb Alex Wolf <notifications@github.com>:; > ; > Can you try running with n_jobs=1?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/212#issuecomment-407333853:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/212#issuecomment-407333853,1,['error'],['error']
Availability,"I am not sure if it has been already addressed.; This should fix the following import error of scanpy from master, due to missing `__init__.py` in external. Probably a more clean solution would be to wrap the import for external in a try/except block. ```python; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); in ; ----> 1 import scanpy as sc; 2 sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); 3 sc.settings.set_figure_params(dpi=200) # low dpi (dots per inch) yields small inline figures; 4 sc.settings.figdir = out('fig_supp'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/__init__.py in ; 31 from . import preprocessing as pp; 32 from . import plotting as pl; ---> 33 from . import datasets, logging, queries, settings, external; 34 ; 35 from anndata import AnnData. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/__init__.py in ; ----> 1 from . import tl; 2 from . import pl; 3 from . import pp; 4 ; 5 from .. import _exporting as exporting. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/tl.py in ; 2 from ..tools._phate import phate; 3 from ..tools._phenograph import phenograph; ----> 4 from ._tools._palantir import palantir. ModuleNotFoundError: No module named 'scanpy.external._tools'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585,2,['error'],"['error', 'errors']"
Availability,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-654493614:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-654493614,1,['error'],['error']
Availability,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,2,['error'],['error']
Availability,"I am running into the same issue and unfortunately running the steps as described here https://github.com/theislab/scanpy/issues/1567#issuecomment-968181500 does not solve my problem. My kernel systematically dies when I run `sc.pp.neighbors` (even with only 1,000 cells). What I am also confused about is that this used to work - I am guessing I updated a package somewhere that broke everything but I cannot identify what. This is my config:; - MacBook Pro (13-inch, M1, 2020) - macOS Big Sur 11.5.2; - python 3.8.8; - numpy 1.20.0; - numba 0.51.2; - umap-learn 0.5.2. I have tried running the following code in Jupyter and then in a script to see if I could get more info on the bug:; ```; unhealthy_cells = sc.read_h5ad(""path/to/file""). unhealthy_cells.layers[""counts""] = unhealthy_cells.X.copy(). sc.pp.normalize_total(unhealthy_cells,target_sum=10000). sc.pp.log1p(unhealthy_cells). sc.pp.scale(unhealthy_cells). sc.tl.pca(unhealthy_cells). sc.pp.neighbors(unhealthy_cells); ```; When I run it as a python script, I get the following error when getting to `sc.pp.neighbors` (everything else works): ; `zsh: illegal hardware instruction`. Is there anything I could do? ; Thank you for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927:1040,error,error,1040,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927,2,['error'],['error']
Availability,I am still getting the file not found error because when downloading it's lacking the `gz` extension. Will manually change but sharing so you are aware! @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470,2,"['down', 'error']","['downloading', 'error']"
Availability,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544,1,['error'],['error']
Availability,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-531248281:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-531248281,1,['error'],['error']
Availability,"I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/778:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778,1,['error'],['error']
Availability,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1028:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028,2,['error'],['error']
Availability,"I am trying to follow this tutorial ; https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html,; but some error just happened in the initial QC stage.; After running:; mito_genes = adata.var_names.str.startswith('MT-'); adata.obs['percent_mito'] = np.sum(; adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; and plot the violinplot,; I just get this graph; ![percent_mito](https://user-images.githubusercontent.com/41959955/57546005-6ba47100-738e-11e9-8cb6-c6a18b89f8dd.png). I felt somthing wrong and checked this:; __________________________________________________________________________________________________; [In] np.sum(adata.obs); [Out] n_genes 14918559.0; **percent_mito 0.0**; dtype: float64. __________________________________________________________________________________________________; It seems that scanpy just didn't recognized the mitogene or removed it, but there's nothing wrong when I used Seurat. I have no idea where the error is located and need your help. Thanks in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639,2,['error'],['error']
Availability,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138,2,['error'],['error']
Availability,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,3,"['Error', 'error']","['Error', 'error']"
Availability,"I am trying to toy with the krumsiek11 model, but the ```sc.tl.sim``` call seems to ignore parameters and always uses the parameters from the ```krumsiek11_params.txt``` file. In particular, running:. ```; adam_krumsiek11 = sc.tl.sim('krumsiek11'); adam_krumsiek11_2 = sc.tl.sim('krumsiek11', nrRealizations = 1, seed = 1665487); sc.pl.sim(adam_krumsiek11 ); sc.pl.sim(adam_krumsiek11_2); ```; produces two exactly identical figures with 4 realizations. I also tried to set ```read_params_from_file = False``` (this is not documented at http://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.sim.html but seemed relevant). However, running; ```; adam_krumsiek11 = sc.tl.sim('krumsiek11', nrRealizations = 1, read_params_from_file = False); sc.pl.sim(adam_krumsiek11); ```; results in ```IndexError```; and running ; ```; adam_krumsiek11 = sc.tl.sim('krumsiek11', nrRealizations = 1, tmax = 800, read_params_from_file = False); sc.pl.sim(adam_krumsiek11); ```; avoids the error, but gives the exact same figure as the first code segment. Maybe I am not understanding correctly, how the function should work? (in which case this would be a documentation issue) Or is there really something wrong?. Thanks for any hints.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/52:973,error,error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52,1,['error'],['error']
Availability,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-670191957:52,down,downgrade,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-670191957,1,['down'],['downgrade']
Availability,"I am using a sampling technique, which samples few rows without descreasing; performance. So speed is more than 10X time faster for larger dataset with; similar accuracy. On Tue, May 21, 2019 at 3:37 AM MalteDLuecken <notifications@github.com>; wrote:. > I'm not sure I entirely understand what the weights are based on. I'm; > trying to understand when you would suggest someone use your approach. Why; > do you give one cell a weight of 125? With this type of weight distribution; > you are basically manually changing the marker gene calculation focusing; > nearly only on a single cell. That seems strange to me.; >; > I'm trying to understand the need for scanpy to support weighted; > observations. At the moment I don't see when you would want to differently; > weight the observations... I'm familiar with using weights if I have some; > form of measurement error or uncertainty between samples. I don't really; > see how that holds here. Do you weight the cells based on some kind of; > quality score?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4EI2YTU53XEGMJI3PWL4XZA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZ3LJA#issuecomment-494122404>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOFRJXHAWVT6W4YKY63PWL4XZANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913:866,error,error,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913,1,['error'],['error']
Availability,"I assume I'm missing something here, but when I try a simple example of plotting a gene dispersion I get two plots 'normalized' and 'not normalized' version in Jupyter, but when I use the save argument to sc.pl.filter_genes_dispersion() I get an image with only one of these. Screenshot attached. Just in case, I tried also passing the multi_panel argument but that caused an error. . Also, is it no possible to specify the path where the files should be stored when using the save arguments to the plotting methods? I want to point to a directory where it should place them, but it seems ""./figures/"" is hard-coded and you can only modify the end of that. Thanks. The attached screenshot shows the dual image within Jupyter, but only the single plot which appears in the PNG file exported. ![screenshot from 2018-01-30 12-34-56](https://user-images.githubusercontent.com/330899/35584410-945d7bb6-05ba-11e8-89fc-14f615a9c6a6.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/73:376,error,error,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73,1,['error'],['error']
Availability,I believe @fidelram isn't super available for scanpy stuff until next month. I figured we could talk about this then.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1649#issuecomment-802501619:32,avail,available,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1649#issuecomment-802501619,1,['avail'],['available']
Availability,"I believe it is, pinging @Koncopd who probably knows more about it. If this is desired behaviour, we could close this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1211#issuecomment-702374955:17,ping,pinging,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211#issuecomment-702374955,1,['ping'],['pinging']
Availability,"I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes!. ```; from scipy.stats import entropy; groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']); entropies = []; for mask in groups_masks:; X_mask = tiss.X[mask].todense(); x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True); x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)); entropies.append(entropy(x_probs)); entropies; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/367:470,mask,mask,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367,2,['mask'],['mask']
Availability,"I can do that. I have a pickled object that I can share with you (how?).; Here is how you reproduce the error:; ```; import scanpy.api as sc; import pickle. # Load the object; with open(""example.pkl"",""rb"") as handle:; adata = pickle.load(handle). # Run Scanpy; sc.tl.rank_genes_groups(adata,groupby=""celltype""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440420960:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440420960,1,['error'],['error']
Availability,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:6,recover,recover,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555,4,"['down', 'recover']","['downgrading', 'recover']"
Availability,"I can reproduce, this is the error that I get:; ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2041118729:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2041118729,1,['error'],['error']
Availability,"I can't seem to plot the labels in the margin or on the data when plotting a t-SNE with louvain_groups labels. I am loosely following the scanpy seurat tutorial code with my own data at:; https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb. When running:. `sc.pl.tsne(adata_bc, size=28, color='louvain_groups', legend_loc='on_data', legend_fontsize=12, legend_fontweight='bold')`. I get the error:. > anaconda3/lib/python3.6/site-packages/matplotlib/legend.py:326: UserWarning: Unrecognized location ""on_data"". Falling back on ""best""; valid locations are; > 	best; > 	upper right; > 	upper left; > 	lower left; > 	lower right; > 	right; > 	center left; > 	center right; > 	lower center; > 	upper center; > 	center; > ; > six.iterkeys(self.codes)))). putting the legend on the data or in the margin does not seem possible. I am using matplotlib version 2.0.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88,1,['error'],['error']
Availability,"I copied your code to a google colabs instance and ran into a Type Error similar to the one above:; https://colab.research.google.com/drive/1LYxOAuNqaJHGfRjNjyluUHk9BFsmkWa4?usp=sharing . Error message:; ```; TypeError Traceback (most recent call last); <ipython-input-3-9abce68d1753> in <module>(); 4 sc.tl.dpt(adata); 5 sc.tl.paga(adata, groups='paul15_clusters'); ----> 6 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). 5 frames; /usr/local/lib/python3.6/dist-packages/matplotlib/image.py in set_data(self, A); 697 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 698 raise TypeError(""Invalid shape {} for image data""; --> 699 .format(self._A.shape)); 700 ; 701 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```. Versions: ; ```; scanpy==1.7.0 ; anndata==0.7.5 ; umap==0.5.0 ; numpy==1.19.5 ; scipy==1.4.1 ; pandas==1.1.5 ; scikit-learn==0.22.2.post1 ; statsmodels==0.10.2 ; python-igraph==0.8.3 ; leidenalg==0.8.3; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-778212671:67,Error,Error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-778212671,2,['Error'],['Error']
Availability,"I definitely don't define the consensus, but I normally prefer FDR correction. It makes a bit more sense to me to correct for a false discovery rate, rather than a test-based error, if you are only interested in the rejected null hypotheses. . They also test for FDR control in a [recent comparison of differential testing methods](http://www.nature.com/doifinder/10.1038/nmeth.4612).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213:175,error,error,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213,1,['error'],['error']
Availability,"I did a little more looking into this, and think I see what's going on. If you set the host, it sends a query to the host to make sure it's real. If it doesn't get a 200 response, it silently fails and does not set the host. Every time I've checked, `www.ensembl.org` returns some `30*` code, which is a redirect, and would successfully fill any query anyways. `asia.ensembl.org` might have actually been down when I was checking, but it might be worth updating the docs that this probably won't work with `www.ensembl.org`. Also I'm pretty sure setting the host at instantiation would never work, cause I don't see it happening in their `__init__` function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-419692328:405,down,down,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-419692328,1,['down'],['down']
Availability,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:629,error,error,629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645,2,['error'],['error']
Availability,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909#issuecomment-1188988922:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909#issuecomment-1188988922,1,['error'],['error']
Availability,"I don't feel well adding a large dataset to the repository. Adding something subsampled and rather low-dimensional would be fine. Alternatively, you could also just add a dataset that is automatically downloaded: as [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L104-L106) or [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L142-L144). As both travis and readthedocs will cache this, it should be a viable solution that avoids bloating the repository with several MB of data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287:201,down,downloaded,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287,1,['down'],['downloaded']
Availability,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'); ```. throws the above error message. But if I use. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')); ```. if works as expected. Also you can manually assign a color list as :. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[; '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', ; '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', ; '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', ; '#F2F3F4'; ]); ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1641632885:318,error,error,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1641632885,1,['error'],['error']
Availability,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/963:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963,2,['error'],['error']
Availability,I don't know what is happening with the new matplotlib but I had to increase the tolerance for the image comparison in order for the tests to pass. Locally I noticed small differences in the margins and axis labels. Also I noticed that running a single test is different than running several tests at once. This probably has to do with some internal matplotlib parameters that are modified. . At least the tests are passing now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432:81,toler,tolerance,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432,1,['toler'],['tolerance']
Availability,"I don't like codacy, it's really flaky with its checks (e.g. errors appear and disappear at random). That's why we disabled it in the first place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/648#issuecomment-815457252:61,error,errors,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/648#issuecomment-815457252,1,['error'],['errors']
Availability,"I don't need to manually pass size with `edgecolor='none'`. I'll see if I can replicate in a conda environment, and then try to cut down the example a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/293#issuecomment-429227670:132,down,down,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293#issuecomment-429227670,1,['down'],['down']
Availability,"I don't remember getting these errors before. Are you not getting them now, and did you get them before?. Also, where did the images in the repo get generated?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-432047736:31,error,errors,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-432047736,1,['error'],['errors']
Availability,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852:164,error,error,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852,1,['error'],['error']
Availability,"I don’t consider it breaking. If I understod you right, the only change in behavior are that not specifying a genome works now in cases where there’s only one. No longer throwing an error is a perfectly fine change!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441,1,['error'],['error']
Availability,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257:2,down,downloaded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257,1,['down'],['downloaded']
Availability,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:2,down,downloaded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,4,['down'],"['download', 'downloaded']"
Availability,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:; scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]; https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt; [ipynb]; https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620365477:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620365477,2,['error'],['error']
Availability,"I encounter this same problem, if I call `sc.pp.log1p(x)` before culate hvg with seurat3, the error is gone, it have correlation with the adata.X is sparse or dense in my view.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1825#issuecomment-1140150507:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825#issuecomment-1140150507,1,['error'],['error']
Availability,"I encountered the following error when trying to save data to h5ad file:. ```; ... storing 'run' as categorical; ... storing 'batch' as categorical; ... storing 'dis_stat' as categorical; ... storing 'org_day' as categorical; ... storing 'louvain' as categorical; ... storing 'louvain_1' as categorical; ... storing 'louvain_2' as categorical; ... storing 'split_cell_type' as categorical; ... storing 'split_major_cell_type' as categorical; ... storing 'phase' as categorical; ... storing 'split_major_cell_type2' as categorical; ... storing 'feature_types-190111-3' as categorical; ... storing 'feature_types-190111-4' as categorical; ... storing 'feature_types-190111-5' as categorical; ... storing 'feature_types-190111-6' as categorical; ... storing 'feature_types-190111-7' as categorical; ... storing 'feature_types-190111-8' as categorical; ... storing 'feature_types-180418-4' as categorical; ... storing 'feature_types-180418-5' as categorical; ... storing 'feature_types-180418-6' as categorical; ... storing 'feature_types-180418-7' as categorical; ... storing 'feature_types-180905-3' as categorical; ... storing 'feature_types-180905-4' as categorical; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-72-19c7ca58c3a2> in <module>; ----> 1 df_dev.write_h5ad('2019-03-04_OTUD6B_dev_sig.h5'). /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in write_h5ad(self, filename, compression, compression_opts, force_dense); 1951 ; 1952 _write_h5ad(filename, self, compression=compression,; -> 1953 compression_opts=compression_opts, force_dense=force_dense); 1954 ; 1955 if self.isbacked:. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/anndata/readwrite/write.py in _write_h5ad(filename, adata, force_dense, **kwargs); 217 if not dirname.is_dir():; 218 dirname.mkdir(parents=True, exist_ok=True); --> 219 d = adata._to_dict_fixed_wid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['error'],['error']
Availability,"I encountered the same error (KeyError: 1) when trying to load the .mtx file with scanpy.read_10x_mtx(). After several unsuccessful attempts at renaming the columns and indices in the 'genes.tsv' file in different ways, I found a workaround that worked for me:. 1. Import the .mtx file separately using scanpy.read_mtx().; 2. Convert the imported data to a pandas DataFrame using .to_df().; 3. Manually name the columns and indices using the 'barcodes.tsv' and 'features.tsv' files, respectively. This approach allowed me to bypass the KeyError and successfully load the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-2133703888:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-2133703888,1,['error'],['error']
Availability,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:348,error,error,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846,1,['error'],['error']
Availability,"I encountered this error when using data with a relatively small number of cells (~2,600). I have not encountered this error with my previous data with more cells (>10,000). ![sc pp scale_error](https://user-images.githubusercontent.com/35155633/34744836-6f325a80-f586-11e7-963f-34d14c1e1399.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/64:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64,2,['error'],['error']
Availability,I figure out this error by myself.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003#issuecomment-920879255:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003#issuecomment-920879255,1,['error'],['error']
Availability,"I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. ; By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; ```; conda create -n scanpy_env; conda activate scanpy_env; conda install numpy=1.19; conda install seaborn scikit-learn statsmodels numba pytables; conda install -c conda-forge python-igraph leidenalg; pip install scanpy==1.8.1; ```; Now I can run `sc.pp.highly_variable_genes()` with no problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116:43,down,downloading,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116,2,['down'],['downloading']
Availability,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1239#issuecomment-631872010:111,down,downstream,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239#issuecomment-631872010,1,['down'],['downstream']
Availability,I found that running the function 'tl.rank_genes_groups' gives the error the following error message:; UnboundLocalError: local variable 'adata_comp' referenced before assignment. ![scanpy api tl rank_genes_groups_error](https://user-images.githubusercontent.com/35155633/34642043-0191dce0-f305-11e7-847f-37b1ff34a77d.png),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/63:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63,2,['error'],['error']
Availability,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using?. ```python; adata = adata.concatenate(; list(slides.values()),; batch_key=""sample"",; uns_merge=""unique"",; batch_categories=list(sample_data['sample_name'].values), ; index_unique=None; ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-4-fe8a54a66c17> in <module>; 40 uns_merge=""unique"",; 41 batch_categories=list(sample_data['sample_name'].values),; ---> 42 index_unique=None; 43 ); 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014,1,['error'],['error']
Availability,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916,3,"['Error', 'error', 'toler']","['Error', 'error', 'tolerance']"
Availability,I get an identical error as @hemantgujar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546,1,['error'],['error']
Availability,"I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:; `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-66-fc1479c238f7> in <module>(); 9 plt.show(); 10 ; ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'); 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'); 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax); 162 show=show,; 163 save=save,; --> 164 ax=ax); 165 ; 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax); 281 ax=None):; 282 """"""See docstring of scatter.""""""; --> 283 sanitize_anndata(adata); 284 if legend_loc not in VALID_LEGENDLOCS:; 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata); 481 # backwards compat... remove this in the future; 482 def sanitize_anndata(adata):; --> 483 adata._sanitize(); 484 ; 485 . ~/anndata/anndata/base.py in _sanitize(self); 1284 if len(c.categories) < len(c):; 1285 df[key] = c; -> 1286 df[key].cat.categories = df[key].cat.categories.ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166,2,['error'],['error']
Availability,"I get same error as @KabitaBaral1 after updating to scanp==1.4.6, namely: `AttributeError: module 'cairo' has no attribute 'version_info'` also see the issue #1166",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-614331672:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-614331672,1,['error'],['error']
Availability,"I get the error below when trying to run the following:. `>>> sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon')`. ```bash; C:\Users\myuser\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py:298: RuntimeWarning: overflow encountered in long_scalars; (n_active * m_active * (n_active + m_active + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-160-dd19114ff660> in <module>; 1 #adata.obs['groups'] = ['group 1'= ['0'], 'group 2'= ['5','16','19','30']]; ----> 2 sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon') # wilcoxon-rank-sum/mann-whitney u test, the default of Seurat. ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 296 ; 297 scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; --> 298 (n_active * m_active * (n_active + m_active + 1) / 12)); 299 scores[np.isnan(scores)] = 0; 300 pvals = 2 * stats.distributions.norm.sf(np.abs(scores)). ValueError: math domain error; ```. Here `adata` is real data from our lab, not the tutorial data. Have been trying to replicate the cluster analysis tutorial. All previous steps work fine. Interestingly, if I remove group '5' from the list of groups it works. Also, this error only happens with the `wilcoxon` method, not with `t-test`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530,3,['error'],['error']
Availability,"I get the following error when I tun dotplot:. ```pytb; ValueError Traceback (most recent call last); <ipython-input-54-afab88c299fa> in <module>(); ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds); 409 ; 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,; --> 411 groupby=groupby, key=key, show=show, save=save, **kwds); 412 ; 413 . /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 291 ; 292 # sum(list, []) is used to flatten the gene list; --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); 294 ; 295 if plot_type == 'dotplot':. /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in <listcomp>(.0); 291 ; 292 # sum(list, []) is used to flatten the gene list; --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); 294 ; 295 if plot_type == 'dotplot':. ValueError: no field of name MYL2; ```. Do we need to store marker genes within the adata object?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/502:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502,1,['error'],['error']
Availability,"I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names.; ```; File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter; ax=ax); File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs; c = adata.raw.obs_vector(key, layer=layers[2]); TypeError: obs_vector() got an unexpected keyword argument 'layer'; ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py; ``` python; # coloring according to gene expression; elif (use_raw; and adata.raw is not None; and key in adata.raw.var_names):; c = adata.raw.obs_vector(key); elif key in adata.var_names:; c = adata.raw.obs_vector(key, layer=layers[2]); ```; Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/762:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762,1,['error'],['error']
Availability,"I got an error doing `pip3 install -e .`:. > clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/usr/local/opt/openssl/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/include/python3.6m -c scanpy/cython/utils_cy.c -o build/temp.macosx-10.11-x86_64-3.6/scanpy/cython/utils_cy.o; > scanpy/cython/utils_cy.c:435:10: fatal error: 'numpy/arrayobject.h' file not found; > #include ""numpy/arrayobject.h""; > ^; > 1 error generated.; > error: command 'clang' failed with exit status 1; > ; > ----------------------------------------; > Command ""/usr/local/opt/python3/bin/python3.6 -c ""import setuptools, tokenize;__file__='/Users/jyhung/Documents/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" develop --no-deps"" failed with error code 1. It worked after I installed cython: `pip3 install cython`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,5,['error'],['error']
Availability,"I got similar error when I was trying to use .h5 file from cellbender output. I have multiome data. . ```pytb; `>>> adata = scanpy.read_10x_h5(""/sc/arion/projects/hmDNAmap/snHeroin/analysis/ARC_TD005235-354/outs/cellbender/cb_feature_bc_matrix_filtered.h5"", gex_only=False)`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 183, in read_10x_h5; adata = _read_v3_10x_h5(filename, start=start); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidena",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572,1,['error'],['error']
Availability,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1; But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-559832485:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-559832485,2,['error'],['error']
Availability,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650:65,error,errors,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650,1,['error'],['errors']
Availability,I guess it has to do with the dependency on `scipy`. Downgrading to a previous setup of packages did the trick for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-690967045:53,Down,Downgrading,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-690967045,1,['Down'],['Downgrading']
Availability,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1355#issuecomment-668515906:19,down,down,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355#issuecomment-668515906,1,['down'],['down']
Availability,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py; import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython; ```; Convert adata_p and adata_g to R objects. ```r; ro.globalenv['r_adata_p'] = adata_p; ro.globalenv['r_adata_g'] = adata_g; ```. ```r; %%R -w 800 -h 400 -u px. library(Seurat); library(viridis); library(viridisLite); library(ggplot2); library(cowplot). df_poor= data.frame(; total_counts = colData(r_adata_p)$total_counts,; n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_p)$pct_counts_mt; ). df_good= data.frame(; total_counts = colData(r_adata_g)$total_counts,; n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_g)$pct_counts_mt; ). #head(df); # Create a scatter plot using ggplot2; p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""good (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). p2 + g2; ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085:263,ERROR,ERROR,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085,1,['ERROR'],['ERROR']
Availability,"I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558,1,['error'],['error']
Availability,"I had this error in the past. Try with a different mirror, you can look them from [here](http://www.ensembl.org/info/about/mirrors.html). For example, I usually use `useast.ensembl.org`. Hope it helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-416231775:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-416231775,1,['error'],['error']
Availability,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113,1,['error'],['error']
Availability,"I have a dataset for which I have an observation that is only available for some cells. When I make a scatter plot that I color code for this observation not all cells are plotted:; ```python; import random; import scanpy as sc. adata = sc.datasets.blobs(); adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1] . sc.tl.pca(adata); sc.pl.pca(adata, color='property', size=50); ```; While this should plot 10 cells it only shows one cell:; ![image](https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png); I can get the plot I want by filtering cells first:; ```python; sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50); ```; ![image](https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png); Would you agree that scanpy should plot all cells that have a valid observation?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536:62,avail,available,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536,1,['avail'],['available']
Availability,"I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory.; Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1977:137,error,errors,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977,1,['error'],['errors']
Availability,"I have a loom file created from Seurat object by using as.loom function in Seurat3. After closing the file with $close.all(), I'm trying to read loom file by read_loom function in scanpy, but I have this error:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-aed61d3d5eef> in <module>; 1 import scanpy as sc; ----> 2 a = sc.read_loom('brain10x.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype); 156 ; 157 if X_name not in lc.layers.keys(): X_name = ''; --> 158 X = lc.layers[X_name].sparse().T.tocsr() if sparse else lc.layers[X_name][()].T; 159 ; 160 layers = OrderedDict(). /opt/conda/lib/python3.7/site-packages/loompy/loom_layer.py in sparse(self, rows, cols); 109 col: List[np.ndarray] = []; 110 i = 0; --> 111 for (ix, selection, view) in self.ds.scan(items=cols, axis=1, layers=[self.name]):; 112 if rows is not None:; 113 vals = view.layers[self.name][rows, :]. /opt/conda/lib/python3.7/site-packages/loompy/loompy.py in scan(self, items, axis, layers, key, batch_size); 597 for key, layer in vals.items():; 598 lm[key] = loompy.MemoryLoomLayer(key, layer); --> 599 view = loompy.LoomView(lm, self.ra[ordering], self.ca[ix + selection], self.row_graphs[ordering], self.col_graphs[ix + selection], filename=self.filename, file_attrs=self.attrs); 600 yield (ix, ix + selection, view); 601 ix += cols_per_chunk. /opt/conda/lib/python3.7/site-packages/loompy/graph_manager.py in __getitem__(self, thing); 96 if type(thing) is slice or type(thing) is np.ndarray or type(thing) is int:; 97 gm = GraphManager(None, axis=self.axis); ---> 98 for key, g in self.items():; 99 # Slice the graph matrix properly without making it dense; 100 (a, b, w) = (g.row, g.col, g.data). /opt/conda/lib/python3.7/site-packages/loompy/graph_manager.py in items(self); 55 def items(self) -> Iterable[Tuple[str, sparse.coo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598:204,error,error,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598,1,['error'],['error']
Availability,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053:218,Error,Error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:242,fault,fault,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128,3,"['error', 'fault']","['error', 'errors', 'fault']"
Availability,"I have also encountered this error, but specifically in the scanpy tutorial outlined [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). That should make reproducibility easier. The error occurs under the _Finding Marker Genes_ heading, specifically the following line:. ```py; sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,3,['error'],['error']
Availability,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-519000488:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-519000488,1,['error'],['error']
Availability,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:315,error,error,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201,3,['error'],['error']
Availability,"I have an error when trying this function for my data:. ```; sc.pl.highest_expr_genes(adata); ```; results in. ```; filtered out 14139 cells that have less than 1 counts; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-1f5b130b9d4e> in <module>(); ----> 1 sc.pl.highest_expr_genes(adata). /usr/local/lib/python3.6/site-packages/scanpy-1.2.2+90.g47c579f-py3.6.egg/scanpy/plotting/qc.py in highest_expr_genes(adata, n_top, save, show, ax, **kwargs); 41 ; 42 # identify the genes with the highest mean; ---> 43 dat.var['mean_percent'] = dat.X.mean(axis=0).A1; 44 ; 45 top = dat.var.sort_values('mean_percent', ascending=False).index[:n_top]. AttributeError: 'numpy.ndarray' object has no attribute 'A1'; ```. It is not critical, but I wonder why this error happens. I have the most recent version from github. Maybe I'm not transforming my data to a certain format properly? Didn't find this documented anyway. However, a lot of other analysis that I do via Scanpy works for me, so generally the data is read and processed correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/220:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/220,2,['error'],['error']
Availability,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103#issuecomment-2217913872:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103#issuecomment-2217913872,1,['error'],['error']
Availability,"I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::; ```; sc.tl.ingest(bdata,; lungreference,obs='new_celltype'; ); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); /tmp/ipykernel_875/1088574315.py in <module>; 2 print(transgene); 3 bdata=adata[adata.obs.treatment==transgene]; ----> 4 sc.tl.ingest(bdata,; 5 lungreference,obs='new_celltype'; 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 128 ; 129 for method in embedd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2406:93,Error,Error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406,1,['Error'],['Error']
Availability,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1513#issuecomment-839597935:384,down,down,384,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513#issuecomment-839597935,1,['down'],['down']
Availability,"I have followed these instructions to install scanpy into my miniconda environment:; [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:; ```; Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44); [GCC 7.2.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy.api as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; >>>; ```. I also get the error when I try to use it with jupyter notebook:. ```; import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>; import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/160:225,error,error,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160,2,['error'],['error']
Availability,"I have larger number of cells than 50. but sc.tl.pca(adata, use_highly_variable_genes = False) resolved my error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432#issuecomment-499145170:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-499145170,1,['error'],['error']
Availability,"I have problem installing and importing scrublet on windows please can you help me; Here is my code !pip install scrublet; PackagesNotFoundError: The following packages are not available from current channels:. - annoy. Current channels:. - https://conda.anaconda.org/conda-forge/win-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/win-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/win-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://repo.anaconda.com/pkgs/msys2/win-64; - https://repo.anaconda.com/pkgs/msys2/noarch; - https://conda.anaconda.org/pytorch/win-64; - https://conda.anaconda.org/pytorch/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org/. and use the search bar at the top of the page.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194:177,avail,available,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194,1,['avail'],['available']
Availability,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575,2,['error'],['error']
Availability,"I have some issues runnign tSNE with `sc.tsne(adata)`. It seems to work on the `moignard15` data set but running the same code with my data set results in the following error. ```; compute tSNE; preprocess using PCA with 50 PCs; --> avoid this by setting n_pcs = 0; 0:00:02.013 - compute PCA with n_comps = 50; 0:00:00.162 - finished; ---------------------------------------------------------------------------; UnboundLocalError Traceback (most recent call last); <ipython-input-5-ea03cbb426c5> in <module>(); ----> 1 sc.tsne(adata). /opt/conda/lib/python3.6/site-packages/scanpy/tools/tsne.py in tsne(adata, random_state, n_pcs, perplexity); 59 sett.m(0, 'preprocess using PCA with', n_pcs, 'PCs'); 60 sett.m(0, '--> avoid this by setting n_pcs = 0'); ---> 61 X = pca(adata.X, random_state=random_state, n_comps=n_pcs); 62 adata['X_pca'] = X; 63 else:. /opt/conda/lib/python3.6/site-packages/scanpy/tools/pca.py in pca(adata_or_X, n_comps, zero_center, svd_solver, random_state); 60 zero_center, svd_solver,; 61 random_state=random_state); ---> 62 adata['X_pca'] = X_pca; 63 if isadata:; 64 return adata. UnboundLocalError: local variable 'adata' referenced before assignment; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/10:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/10,1,['error'],['error']
Availability,"I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python; fig, ax = plt.subplots(1,3, figsize=(20,6)); sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False); sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False); sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False); plt.tight_layout(pad=3.0); plt.show(); ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158:511,down,download,511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158,1,['down'],['download']
Availability,"I have the same error on scanpy 1.9.5, seaborn 0.13.0, the error seems to be specific to 'multi_panel = True' and produces 3 empty graphs that all inherit the ""n_genes_by_counts"" x-label instead of the proper one.; The same graph is produced normally with 'multi_panel = False'. `sc.pl.violin(full_adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_MT'], multi_panel=True, stripplot=False)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779,2,['error'],['error']
Availability,I have the same problem. Didn't expect it is due to the anndata package. ; Downgrade anndata to 0.10.2 solve this problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600:75,Down,Downgrade,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600,1,['Down'],['Downgrade']
Availability,I have this exact error!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229,1,['error'],['error']
Availability,"I have tried using latest version of anndata(0.16.9), still got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493672904:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493672904,1,['error'],['error']
Availability,I hope everybody had a good New Year break! Just pinging @ivirshup again because I think it'd be great to move forward with this. Also wanted to ping @falexwolf as I know he did a lot of work on dim reduction etc. Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-757850250:49,ping,pinging,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-757850250,2,['ping'],"['ping', 'pinging']"
Availability,"I hve to clarify: I tried out the fix provided above from @flying-sheep and it does the job for me, but the error persists on the `master` branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-778184917:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-778184917,1,['error'],['error']
Availability,"I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:1346,avail,available,1346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,2,['avail'],['available']
Availability,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1896:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896,2,['error'],['error']
Availability,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978:52,Error,Error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978,1,['Error'],['Error']
Availability,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125,1,['error'],['error']
Availability,"I just got the same error with a similar situation. . I get umap coordinates from a collaborator, which I store in `adata.obs`. Before the last update this worked:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class')`; Now, this produces a `IndexError: Key ""UMAP1"" is not valid observation/variable name/index.` error. Now I need to run this for the same plot:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class', use_raw=False)`. These covariates are all in `adata.obs.keys()`. It seems that `use_raw` is taking precendence over `x` and `y` being from `adata.obs`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351,2,['error'],['error']
Availability,I just had another thought... it seems like this might have to do with the initial `sc.tl.paga()` call. There you get a runtime warning about overflow in long scalars. Maybe check if you get any meaningful output in `adata.uns['paga/connectivities']` or `adata.uns['paga/connectivities_tree']`. It might just be all `nan` in there due to the above errors. Could it be that you have a 32-bit windows version and the code is trying to use 64-bit floats? Maybe that's the overflow error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534977199:348,error,errors,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534977199,2,['error'],"['error', 'errors']"
Availability,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515#issuecomment-469460276:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469460276,1,['error'],['error']
Availability,I just had the same issue because I downgraded my matplotlib elsewhere.; So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045:36,down,downgraded,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045,1,['down'],['downgraded']
Availability,"I just have scanpy 0.2.7 and am trying to produce bpmc3 results. BUT right at the beginning (sc.read()) the following error! I will appreciate your help.; thanks. `--------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-ef7315cdb8ff> in <module>(); 2 filename_genes = '/ifs/projects/proj077/backup/public_data/scanpy_tutorials_data/PBMC3K/filtered_gene_bc_matrices/hg19/genes.tsv'; 3 filename_barcodes = '/ifs/projects/proj077/backup/public_data/scanpy_tutorials_data/PBMC3K/filtered_gene_bc_matrices/hg19/barcodes.tsv'; ----> 4 adata = sc.read(filename_data, cache=True).transpose(); 5 adata.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; 6 adata.smp_names = np.genfromtxt(filename_barcodes, dtype=str). /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in read(filename_or_filekey, sheet, ext, delimiter, first_column_names, backup_url, return_dict, cache); 73 if is_filename(filename_or_filekey):; 74 data = read_file(filename_or_filekey, sheet, ext, delimiter,; ---> 75 first_column_names, backup_url, cache); 76 if isinstance(data, dict):; 77 return data if return_dict else AnnData(data). /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in read_file(filename, sheet, ext, delimiter, first_column_names, backup_url, cache); 364 os.makedirs(os.path.dirname(filename_cache)); 365 # write for faster reading when calling the next time; --> 366 write_dict_to_file(filename_cache, ddata, sett.file_format_data); 367 return ddata; 368 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in write_dict_to_file(filename, d, ext); 771 d_write[key] = value; 772 # now open the file; --> 773 wait_until_file_unused(filename) # thread-safe writing; 774 if ext == 'h5':; 775 with h5py.File(filename, 'w') as f:. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in wait_until_file_unused(filenam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35:118,error,error,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35,1,['error'],['error']
Availability,"I just noticed that the reply I sent Saturday bounced due to ‘unknown error’. I thought I should provide an update in case other Windows users encounter something similar. After identifying the correct version of the several on the link below, I noticed that it was also necessary to install Pycairo. I then found I needed to install the Louvain algorithm to resolve the issue. The vtraag website indicates this algorithm has been superseded by the Leiden algorithm, which I installed with no problem. Thanks much for your reply within hours, on a weekend no less. From: Koncopd [mailto:notifications@github.com]; Sent: Saturday, May 25, 2019 2:15 PM; To: theislab/scanpy <scanpy@noreply.github.com>; Cc: Moos, Malcolm <Malcolm.Moos@fda.hhs.gov>; Mention <mention@noreply.github.com>; Subject: Re: [theislab/scanpy] igraph problems (#138). @RicedeKrispy<https://github.com/RicedeKrispy>; Hi, if you are using Windows, you can try to install python-igraph from the wheel here; https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/138?email_source=notifications&email_token=AMEIEFZ2OGJSDDXGY4TRK4TPXF62HA5CNFSM4E5ZJQRKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWHWUII#issuecomment-495938081>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMEIEFZFWYPQB7BP5HHCM23PXF62HANCNFSM4E5ZJQRA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611:70,error,error,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611,1,['error'],['error']
Availability,"I just saw on zulip that some of the functions in codaplot could be helpful here, sorry for the late reply. I'll post some more details on what is available in the package here tomorrow :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664,1,['avail'],['available']
Availability,"I just stumbled upon a similar bug using SciKit Learn. It's not ScanPy, but this issue is the only result Google returned when I looked up my error. Here's my crash log:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 000000010ddfb000-000000010ddfd000 [ 8K] r-x/rwx SM=COW /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff4fb578e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff24844c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff24844a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001104e3f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001104e3527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x00000001104a9b27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x00000001104aeabf array_matrixproduct + 191; 7 org.python.python 	0x000000010de4712e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x000000010dead0e6 call_function + 491; 9 org.python.python 	0x000000010dea5621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x000000010dead866 _PyEval_EvalCodeWithName + 1747; ```. It's not very useful as it's the same as the OP's, but it might help shifting the blame to a common dependency of SciKit Learn and ScanPy (like BLAS having an issue with macOS' Grand Central Dispatch).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214,2,"['error', 'fault']","['error', 'fault']"
Availability,"I just tried; ```python; import scanpy.api as sc; sc.queries.mitochondrial_genes('www.ensembl.org', 'strange_organism'); ```; I would expect scanpy complains that it does not know `'strange_organism'`, but I get the error ; ```python; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-13-6a41b361ab41> in <module>(); 1 import scanpy.api as sc; ----> 2 sc.queries.mitochondrial_genes('www.ensembl.org', 'drerio'). ~/software/scanpy/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 34 s.add_attribute_to_xml('mgi_symbol'); 35 else:; ---> 36 logg.msg('organism ', str(org), ' is unavailable', v=4, no_indent=True); 37 return None; 38 s.add_attribute_to_xml('chromosome_name'). NameError: name 'logg' is not defined; ```; It seems to me like `queries/__init__.py` misses an `from .. import logging as logg` statement. Would maybe also make sense to show the the message that an organism is not available at verbosity level 1 instead of 4?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/258:216,error,error,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/258,2,"['avail', 'error']","['available', 'error']"
Availability,"I just updated scanpy and reran a script which is now giving different outputs. The clustering has changed slightly, and that has downstream effects on the results. The first place I noticed a difference is where the results of `sc.pp.filter_genes_dispersion()` are plotted. . In scanpy version 1.2.2+73.g1812406 and AnnData version 0.6.4 I get the following output:; ![screen shot 2018-08-28 at 14 05 53](https://user-images.githubusercontent.com/13019956/44722232-bade9600-aacc-11e8-88c6-3f4c17fd4e07.png). And with scanpy version 1.2.2+166.g6c1daba with Anndata version 0.6.9, I get higher dispersions:; ![screen shot 2018-08-28 at 14 06 15](https://user-images.githubusercontent.com/13019956/44722316-fda06e00-aacc-11e8-940f-1295b36eacf6.png). Previous results look the same, and the only two scanpy functions that were run in between were `sc.pp.log1p()` and `sc.pp.filter_genes_dispersion()`. I also ran ComBat, but that was not updated and can't really have changed on my system. I see sc.pp.log1p was changed in between, but it doesn't seem to have been anything can could have changed this... Or was there a change to the plotting that may have changed the plots I see?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246:130,down,downstream,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246,1,['down'],['downstream']
Availability,"I know this is a bit specific, but the current sc.pl.rank_genes_groups() and sc.pl.rank_genes_groups_violin() have a 'gene_symbols' argument to allow display based on other columns in .var. For example, if I have this in Var:. ```; Var columns:; gene_symbol; index ; ENSMUSG00000000001 Gnai3; ENSMUSG00000000028 Cdc45; ENSMUSG00000000031 H19; ENSMUSG00000000037 Scml2; ENSMUSG00000000049 Apoh; ```. I can just pass 'gene_symbol' as the column I want to be used for any/all displays instead of the ensembl ID all the time. It would be great if something like this were consistently available anywhere gene labels were needed in the plotting functions. Perhaps the common argument would be better called 'display_label' or something like that instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/646#issuecomment-493156408:581,avail,available,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-493156408,1,['avail'],['available']
Availability,"I like @flying-sheep's very last solution. To enable this for truly large-scale data and AnnData's that are backed on disk we need a much more efficient transposition implementation, which will probably need to return a view. That's problematic as it will break backwards compat (`.T` returns a copy these days). But it's good as it will allow adding fields to `.var`. @LuckyMD: At the time, when you mentioned that you wanted to plot over genes in scatter, I was fine with with having the scatter wrapper and assuming no ambiguity in obs and var keys. Now, I'd advocate for @flying-sheep's solution. Of course, we'll maintain the feature in `pl.scatter` when refactoring its code (a lot of it became redundant after fidel introduced the completely rewritten scatter plots).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742:701,redundant,redundant,701,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742,1,['redundant'],['redundant']
Availability,"I like that CI for notebooks!. Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1305#issuecomment-661712907:246,error,error,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305#issuecomment-661712907,3,['error'],['error']
Availability,"I like that this method is fairly simple, and could have a meaningful cutoff, but I think I'd like more evidence of it's usefulness before thinking about including it. I have two main points of concern:. * Are there examples of this method being used outside of the glmPCA paper? I would at least like to know that reasonable results can be found downstream of this.; * In the glmPCA paper, the identified genes are highly correlated (~1) with highly expressed genes, and lowly correlated (~.3 with highly variable gene selection. While I'm not sure which highly variable gene method they compared against, should the low correlation with common practice give us pause?. <img width=""784"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/112927072-2515b680-9160-11eb-967a-373536aad6d1.png"">. @giovp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1765#issuecomment-809874884:347,down,downstream,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765#issuecomment-809874884,2,['down'],['downstream']
Availability,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2106927009:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2106927009,1,['error'],['error']
Availability,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`; * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example; * If `norm` is passed along at the same time, an error should be thrown; * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748422767:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748422767,1,['error'],['error']
Availability,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-519397103:98,toler,tolerance,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-519397103,1,['toler'],['tolerance']
Availability,"I managed to get past the error by adding; ```; RUN locale-gen en_US.UTF-8; ENV LC_ALL en_US.UTF-8; ```; to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep!. EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559,2,['error'],['error']
Availability,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:; This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial; ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules).; For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below.; ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276:312,down,download-,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276,2,['down'],['download-']
Availability,"I mean, @vtraag is is the person I’d believe when asked which algorithm is superior, so we could. 1. add `sc.tl.leiden` as an alternative that doesn’t have a flavour argument.; 2. make `leidenalg` a dependency and `louvain-igraph` an optional one.; 3. when calling `sc.tl.louvain` (no matter the flavor used), emit a ``DeprecationWarning('We recommend to use `sc.tool.leiden` instead. Refer to its documentation for details')``. This meets the following goals:. - education: people will learn why we recommend the new function; - ease of use: no weird errors pop up suddenly; - reproducibility: If `louvain-igraph` is installed, the code works exactly as before (with an added warning), else it crashes. we could do the following within `sc.tl.louvain` to help users:. ```py; try:; import louvain; except ImportError:; raise ImportError(; 'The package “louvain-igraph“ is not installed. '; 'Try using `sc.tl.leiden` in case you do not need '; 'to reproduce results produced using `sc.tl.louvain`'; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831:552,error,errors,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831,2,['error'],['errors']
Availability,"I meet this problem last days, I uninstall the python-igraph package and reinstall it. then the error disappear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/961#issuecomment-620301726:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961#issuecomment-620301726,1,['error'],['error']
Availability,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211:57,reboot,reboot,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211,2,"['error', 'reboot']","['error', 'reboot']"
Availability,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1475:285,error,errors,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475,1,['error'],['errors']
Availability,I ran into the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432#issuecomment-498925141:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-498925141,1,['error'],['error']
Availability,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```; ```; sc.pp.highly_variable_genes(; adata,; layer=""counts"",; flavor=""seurat_v3"",; n_top_genes=num_hvgs,; batch_key='sex_cell_subtype',; span=0.5; ); ```; <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-1521864773:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-1521864773,2,['error'],['error']
Availability,"I ran your code snippet multiple times on my end and I got the same results each time. Is this true for you as well? If both you and your partner can generate the same results consistently each time, then it is strange that your results disagree with each other... Some followup questions I have:; 1) Are ALL packages the same version? (Packages like Numba, scipy, sklearn, etc. should also be the same version to remove that as a potential source of variability); 2) Are you guys using the same operating system? ; 3) Can you run UMAP directly on the randomly generated matrix to see if your embeddings are the same? If they are, UMAP is likely not at fault.; 4) If you perturb your nearest neighbor matrix by adding noise to the edges such that the total edge weight differs by ~0.001 between perturbations, can you recreate the big differences in the UMAP projection? Small differences in the edge weights of the nearest neighbor graph CAN lead to huge differences in the UMAP projection if the graph has no inherent structure (which should be the case for randomly generated data).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009#issuecomment-578310404:653,fault,fault,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009#issuecomment-578310404,1,['fault'],['fault']
Availability,I read some forum threads saying that we need to downgrade matplotlib,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094#issuecomment-629808985:49,down,downgrade,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094#issuecomment-629808985,1,['down'],['downgrade']
Availability,I recently had a discussion with @LisaSikkema about how much you can overshoot here. The suggestion was made to use 100 PCs. Can we robustly compute that many or do the numerical methods break down when too little variance is represented by a PC? I recall @falexwolf mentioning this at some point.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-590110278:132,robust,robustly,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-590110278,2,"['down', 'robust']","['down', 'robustly']"
Availability,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111,1,['error'],['error']
Availability,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-782180615:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-782180615,1,['error'],['error']
Availability,"I see no reason why the possibility shouldn't exist to run the weighted version on the full graph. I'm still curious about the quality of the outcome though. Using protein-protein interaction data, I've noticed that similarity scores perform worse than using network neighbourhoods based on cutoffs to cluster data (this does not have to be the case for scRNA-seq of course). In the latter case you require cells to be each others nearest neighbours to create dense network regions, rather than highly similar transcriptomes based on one calculation of similarity. I would have thought the cutoff approach is more robust to changing similarity metrics as well. It's definitely worth testing this though. Maybe I'm just too skeptical of similarity metrics over all. @fidelram do you have labels on your data where you could verify the quality of those two partitions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676:614,robust,robust,614,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676,1,['robust'],['robust']
Availability,I skimmed through the code only briefly yesterday but I think the problem might be that both `x` and `y` need to be specified: The error message seems to indicate so and the two lines seemingly responsible for the problem are the only ones where `x` and `y` are **not** both specified. I'll have a closer look at it in a bit.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1420#issuecomment-694079984:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420#issuecomment-694079984,1,['error'],['error']
Availability,"I still get the same error with `useast`. ```python; sc.queries.mitochondrial_genes(""useast.ensembl.org"", ""hsapiens""); ```; <details>; <summary>The output and traceback</summary>. ```python; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; ---------------------------------------------------------------------------; EmptyDataError Traceback (most recent call last); <ipython-input-4-66c3fcd14dab> in <module>(); ----> 1 sc.queries.mitochondrial_genes(""useast.ensembl.org"", ""hsapiens""). ~/github/scanpy/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 40 ; 41 # parsing mitochondrial gene symbols; ---> 42 res = pd.read_csv(StringIO(s.query(xml)), sep='\t', header=None); 43 res.columns = ['symbol', 'chromosome_name']; 44 res = res.dropna(). /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision); 676 skip_blank_lines=skip_blank_lines); 677 ; --> 678 return _read(filepath_or_buffer, kwds); 679 ; 680 parser_f.__name__ = name. /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in _read(filepath_or_buffer, kwds); 438 ; 439 # Create the parser.; --> 440 parser = TextFileReader(file",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067,1,['error'],['error']
Availability,"I still had the same error with `scanpy` 1.4.5, in my case updating `anndata` solved the issue, but now I've hit the slow concatenation problem https://github.com/theislab/anndata/issues/303",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-580322693:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-580322693,1,['error'],['error']
Availability,I stumbled across the same error with scanpy==1.4.5.1 anndata==0.7.1 umap==0.4.2. Did not quite understand the solution for this issue. What should I do?. Best wishes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627825582:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-627825582,1,['error'],['error']
Availability,"I think I find the reason. When run sc.tl.louvain(adata), louvain_colors will be saved in adata.uns, sc.pl.paga will use louvain_colors. But, when run sc.tl.louvain(adata) again with another resolution and then rerun sc.tl.paga, louvain_colors will not be updated, and the error occurs!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112:273,error,error,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112,1,['error'],['error']
Availability,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165:55,error,error,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165,2,['error'],['error']
Availability,"I think `pandas` provides a good template for the question of `np.min(adata)`. `np.min(df)` gives the minimum value stored in the dataframe, not the minimum value in the `Index` (aka `obs`) or `Columns` (aka `var`). Given `AnnData` is basically a way of storing data and metadata associated with both the rows and columns of that data, it goes without saying (in my opinion at least) that numerical methods applied to `adata` should be applied to `adata.X`. Re: slicing, I think it makes sense to have explicit slicing for one or the other (i.e. `loc` and `iloc`) and then a default slicing (i.e. `adata['Cell A',:]`) which takes both position-based and name-based slicing if the two are unambiguous. It wouldn't be hard to include a check that says if the names are a) integers and b) not simply a RangeIndex (ie names and positions are the same) then throw a warning or an error asking the user to specify which of name or position they want.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584144674:875,error,error,875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-584144674,2,['error'],['error']
Availability,"I think an error should be thrown, thus the user can figure out what to do. ; @nh3 I don't understand the part about the `different summarization`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/926#issuecomment-555494385:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/926#issuecomment-555494385,1,['error'],['error']
Availability,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609:313,down,down,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609,1,['down'],['down']
Availability,"I think it would be nice to start small, then gradually add to this. I'd nominate `black` as the first step, then using `pre-commit` on CI, then adding more tools. I like `black` for a starting place since we can just run it over both dev and stable branches and be confident in nothing breaking. For anything that requires more manual intervention, I think we'll have to wait until close to a new stable branch being cut so we don't have to worry about conflicts during backports. I had also thought `isort` could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (*imperative programming strikes again!*). <details>; <summary> Some initial settings for `isort` </summary>. ```toml; [tool.isort]; profile = ""black""; multi_line_output = 3; skip = ""scanpy/__init__.py""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-777223132:625,error,errors,625,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-777223132,1,['error'],['errors']
Availability,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/805#issuecomment-528244541:80,avail,available,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805#issuecomment-528244541,1,['avail'],['available']
Availability,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there.; 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788:289,avail,available,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788,2,['avail'],['available']
Availability,"I think saying discrete was redundant with independent, in that each component should correspond to a signal in the data. > And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I'm not sure how to interpret it. I know that if I run an analysis on the same dataset with 20 components I get more independent ones. My impression is the ""failure modes"" of linear decompositions like this are not well characterized. > It feels strange to generally say that ICA is better as higher dimensions. I probably wouldn't say this. I think there are different use cases, and ICA components may be easier to interpret than PCA components. I was also just at a talk by Elana Fertig (who knows much more about this kind of thing than I do) where one of the take aways was ""different decompositions for different use-cases"". I think I'll still use PCA for clustering and generating UMAPs. > while at lower dimensions there is redundant information compared to PCA. I'd note that there is no order to ICA components.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393:28,redundant,redundant,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393,3,"['failure', 'redundant']","['failure', 'redundant']"
Availability,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:101,redundant,redundant,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880,1,['redundant'],['redundant']
Availability,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst; Classes used for these plots:. .. autosummary::; :toctree: . pl._dotplot.DotPlot; ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-651513742:350,error,errors,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-651513742,1,['error'],['errors']
Availability,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-655334219:398,error,errors,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-655334219,1,['error'],['errors']
Availability,"I think the plotting parameter would make a lot of sense. We should take a few things into account though when determining defaults here.; 1. Not all methods have log fold changes (`'logreg'` for example); 2. Ordering based on log FC will be different than based on the scoring (lowly expressed genes will typically have higher logFC). I'm not sure how meaningful the plot would then be...; 3. We initially didn't have any fold changes or p-values at all, partially because the marker gene DE test setup is ill-defined. You test gene in two groups where the groups are defined based on the genes you test... that will generate inflated p-values. Hence it might be a good idea to only consider the test as a way to order genes rather than a robust statistical test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335:740,robust,robust,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335,1,['robust'],['robust']
Availability,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks.; code. ```; x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'; Train_name = 'Baron'; Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'; Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata); all_adata = all_adata.concatenate(test_adata); ```. error; ```; AnnData object with n_obs × n_vars = 2133 × 22757; AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>; File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate; out.var.columns.str.extract(pat, expand=False); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__; accessor_obj = self._accessor(obj); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__; self._inferred_dtype = self._validate(data); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate; raise AttributeError(""Can only use .str accessor with string values!""); AttributeError: Can only use .str accessor with string values!; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404,2,['error'],['error']
Availability,"I think the spring export function currently fails because it only checks whether each column in `adata.obs` is a pandas categorical variable (`not is_categorical(adata.obs[obs_name])`) and, if not, assumes it's a continuous variable and then tries to join a str with an integer. . If you look at your file `data.obs` contains a number of categorical variables that are currently numpy objects; ```pytb; data.obs.dtypes; ClusterID int32; ClusterName object; RNA_snn_res_0_5 object; nCount_RNA float32; nFeature_RNA int32; orig_ident object; percent_mt float32; seurat_clusters object; louvain category; dtype: object; ```. As a quick fix, I think you can do something like this:; ```python; adata = data.copy(); obj_cols = adata.obs.columns[adata.obs.dtypes == np.object]; adata.obs[obj_cols] = adata.obs[obj_cols].astype('category') ; sce.exporting.spring_project(adata, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); ```; Not sure what's the best way to fix it for the future: check for other dtypes or uses f-strings to avoid the str concatenation errors?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431:1070,error,errors,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431,1,['error'],['errors']
Availability,"I think there's definitely room for more plotting libraries in the ecosystem, but have some doubts about whether all needs can be met by one library. I personally use `seaborn`/ `matplotlib`, `bokeh`, `datashader`, and `altair` for different cases. I also think making a good plotting API is exceedingly difficult, especially if you target both high and low level use cases. I would note that the plotting code in scanpy feels like some of the most maintenance intensive code in the library. > provides helper functions for handling colors, saving figures, etc. We can do a bit more of this here. But of course, much of it would end up being `matplotlib` specific. > encourages a consistent plotting API (e.g. by defining abstract base classes). I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on `seaborn` plotting classes more heavily here, potentially contributing features upstream. Here's one example https://github.com/mwaskom/seaborn/issues/2487 of a feature which could fit the `AnnData` data model nicely. > there is quite some duplicated code in the plotting section. We'd definitely like to reduce the amount of duplicated code, which is what drove the addition of `sc.get`. This seems to be working out internally, if slowly. > All the scanpy helper functions for plotting (e.g. savefig_or_show, _set_color_for_categorical_obs etc.) are private scanpy functions. I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is `_set_color_for_categorical_obs`, which I'd also like to make accessible through `sc.get`. Adding `groupby` support to `anndata` would help a lot here too (https://github.com/theislab/anndata/issues/556). `save_fig_or_show` is something that I don't think we should export, and may need a rework (#1508).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749:449,mainten,maintenance,449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749,1,['mainten'],['maintenance']
Availability,"I think this is currently bugged by: https://github.com/numba/numba/issues/6774. It's a weird bug: some code just doesn't execute, unless I swap out a `prange` with a `range`, in which case it errors. Unless I add an expression that does nothing. Then it can work, except it's doing the expensive computation again 🤯. It looks like this won't be solved by the next numba release, so working around it will be necessary for timely inclusion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783:193,error,errors,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783,1,['error'],['errors']
Availability,"I think this looks good and simple enough. Could you please fix the CI errors?. Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py?. The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-534438279:71,error,errors,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830#issuecomment-534438279,2,['error'],['errors']
Availability,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:308,avail,available,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704,1,['avail'],['available']
Availability,"I think this more of an enhancement than a bug, though an error message saying we don't have a way to color by boolean values would be more clear. What would you expect this to look like? Which styling options apply here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-777891088:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-777891088,2,['error'],['error']
Availability,"I think this problem may cause by `seaborn`!. The following code should reproduce the error:. ```; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-863089065:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-863089065,1,['error'],['error']
Availability,"I think we should introduce a standardized “mask” argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A’],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells’,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234:44,mask,mask,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234,6,['mask'],"['mask', 'masks']"
Availability,"I think you have some variables which are the same for all samples. This leads to a division by zero error, which numba is not handling gracefully or mentioning. Here's how to find those values:. ```python; np.where((adata.X[[0], :] == adata.X).all(axis=0)); ```. I believe if you filter these out, this should work. I'm not sure if there is a correct value for Morans I or Gearys C in this case. Should we error?. --------------------. Numba bug report: https://github.com/numba/numba/issues/6976",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-826743830:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-826743830,2,['error'],['error']
Availability,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:401,avail,available,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491,1,['avail'],['available']
Availability,"I thought it was breaking due to a couple behavior changes:. One case where the results would be different is the call `sc.read_10x_h5(h5pth)`, where the file at `h5pth` is a legacy formatted file which contains `mm10` and `hg38` genomes. Prior to this PR, only the `mm10` genome would be read in. Now, an error is thrown. . If the file had the `v3` format (also containing two genomes), now values for features from both genomes would be read in, instead of just `mm10`. Even better than removing an error, previously `v3` files would get all the vars filtered out and not throw an error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024:306,error,error,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024,3,['error'],['error']
Availability,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:568,robust,robust,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694,1,['robust'],['robust']
Availability,"I tried debug by myself and this is what I found at the break point: when the color represented by RGB values, such as `[array([0.29803922, 0.44705882, 0.69019608]), array([0.86666667, 0.51764706, 0.32156863]), array([0.33333333, 0.65882353, 0.40784314]), array([0.76862745, 0.30588235, 0.32156863])]`, it throws error. It may also cause by the default setting of `seaborn`. Since you have fixed it in #1886 , this problem should be fixed too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-864689573:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-864689573,1,['error'],['error']
Availability,I tried downgrading umap-learn to 0.4.6 but then sc.pp.neighbors won't work. I've been using scanpy 1.5.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-909192114:8,down,downgrading,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-909192114,2,['down'],['downgrading']
Availability,"I tried import .loom file generate from Seurat into scanpy for drawing heatmap.; There is a gene ""CD34"", when I draw in R, it reported as ""Warning: Could not find CD34 in the default search locations, found in RNA assay instead"". but still work.; While in scanpy, it showed the following error: KeyError: ""Values ['CD34'], from ..., are not valid obs/ var names or indices.""; How can I fix it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406:288,error,error,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406,1,['error'],['error']
Availability,"I tried running https://github.com/theislab/scanpy_usage/blob/master/170501_moignard15/moignard15.ipynb and got this error:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/networkx/classes/graph.py in neighbors(self, n); 1058 try:; -> 1059 return list(self.adj[n]); 1060 except KeyError:. KeyError: None. During handling of the above exception, another exception occurred:. NetworkXError Traceback (most recent call last); <ipython-input-11-f3d9663e2b3b> in <module>(); 1 adata.add['dpt_groups_names'] = ['undecided/endothelial', 'endothelial', 'erythrocytes', 'trunk'] # optional; ----> 2 sc.pl.dpt(adata, color=['dpt_pseudotime', 'dpt_groups', 'exp_groups'], legendloc='upper left'). ~/Documents/scanpy/scanpy/plotting/__init__.py in dpt(adata, basis, color, names, comps, cont, layout, legendloc, cmap, pal, right_margin, size, titles, show); 385 if not isinstance(color, list): colors = color.split(','); 386 else: colors = color; --> 387 if 'dpt_groups' in colors: dpt_tree(adata, show=False); 388 dpt_timeseries(adata, cmap=cmap, show=show); 389 . ~/Documents/scanpy/scanpy/plotting/__init__.py in dpt_tree(adata, root, colors, names, show, fontsize); 463 if name in sett._ignore_categories: colors[iname] = 'grey'; 464 G = nx.Graph(adata.add['dpt_groups_adjacency']); --> 465 pos = utils.hierarchy_pos(G, root); 466 fig = pl.figure(figsize=(5, 5)); 467 ax = pl.axes([0, 0, 1, 1], frameon=False). ~/Documents/scanpy/scanpy/plotting/utils.py in hierarchy_pos(G, root, levels, width, height); 455 ; 456 if levels is None:; --> 457 levels = make_levels({}); 458 else:; 459 levels = {l: {TOTAL: levels[l], CURRENT: 0} for l in levels}. ~/Documents/scanpy/scanpy/plotting/utils.py in make_levels(levels, node, currentLevel, parent); 434 levels[currentLevel] = {TOTAL: 0, CURRENT: 0}; 435 levels[currentLevel][TOTAL] += 1; --> 436 neighbors = G.neighbors(node); 437 if parent is not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/24:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/24,1,['error'],['error']
Availability,I tried to install louvain through conda; `conda install -c vtraag louvain`; but got error message:; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain; - python-igraph[version='>=0.7.1.0']. However I could install it by; `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks!; [https://scanpy.readthedocs.io/en/latest/installation.html](url),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/143:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143,2,"['avail', 'error']","['available', 'error']"
Availability,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:215,error,error,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184,2,['error'],['error']
Availability,"I try to use `sc.pl.pca` selecting components. According to the documentation the following should work:. ```python; import scanpy.api as sc; sc.logging.print_versions(); adata = sc.datasets.blobs(); sc.tl.pca(adata); sc.pl.pca(adata, components=['1,2', '2,3']); ```. However, I get an error. The output of the code above is:. ```python; scanpy==0+unknown anndata==0.6.9 numpy==1.14.5 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ... storing 'blobs' as categorical. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-4cd21e9edf25> in <module>(); 3 adata = sc.datasets.blobs(); 4 sc.tl.pca(adata); ----> 5 sc.pl.pca(adata, components=['1,2', '2,3']). ~/software/scanpy/scanpy/plotting/tools/__init__.py in pca(adata, color, use_raw, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save, ax); 114 title=title,; 115 show=False,; --> 116 save=False, ax=ax); 117 utils.savefig_or_show('pca_scatter', show=show, save=save); 118 if show == False: return axs. ~/software/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 110 show=show,; 111 save=save,; --> 112 ax=ax); 113 elif x is not None and y is not None:; 114 if ((x in adata.obs.keys() or x in adata.var.index). ~/software/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 291 if components is None: components = '1,2' if '2d' in projection els",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/254:286,error,error,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/254,1,['error'],['error']
Availability,I updated it to python 3.6.8 and it gets past that error point. ; Thank you very much for all your help.; Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325,1,['error'],['error']
Availability,"I updated release notes and added a test for this specific case. I did not write many tests before, so I looked at the other tests and tried to stick to what I saw there. I noted something unexpected when writing the test: When used `np.mean` and `np.var(.., ddof=1)` to compare against the test failed because some of the variances were off. The current version of the test uses `sc.pp._utils._get_mean_var()` (thats what `highly_variable_genes()` uses internally...), and does not fail.. Is it ok to use that instead? Is it expected that numpy and `_get_mean_var()` are slightly different here?. Test code with numpy ground truth:; ```; def test_seurat_v3_mean_var_output_with_batchkey_vs_numpy():; pbmc = sc.datasets.pbmc3k(); pbmc.var_names_make_unique(); n_cells = pbmc.shape[0]; batch = np.zeros((n_cells), dtype=int); batch[1500:] = 1; pbmc.obs[""batch""] = batch. true_mean = np.mean(pbmc.X.toarray(), axis=0); true_var = np.var(pbmc.X.toarray(), axis=0, ddof=1). result_df = sc.pp.highly_variable_genes(; pbmc, batch_key='batch', flavor='seurat_v3', n_top_genes=4000, inplace=False; ); np.testing.assert_allclose(true_mean, result_df['means'], rtol=2e-05, atol=2e-05); np.testing.assert_allclose(true_var, result_df['variances'], rtol=2e-05, atol=2e-05); ```; Test output:; ```; E AssertionError: ; E Not equal to tolerance rtol=2e-05, atol=2e-05; E ; E Mismatched elements: 172 / 32738 (0.525%); E Max absolute difference: 0.01117667; E Max relative difference: 0.00013328; E x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32); E y: array([0., 0., 0., ..., 0., 0., 0.]). tests/test_highly_variable_genes.py:279: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072:1321,toler,tolerance,1321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072,1,['toler'],['tolerance']
Availability,I updated to 1.3.3 but the error still persists. One important thing I didnt mention before: I am running python/scanpy on a Windows machine. @Donovan-CG do you also use Windows?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820,1,['error'],['error']
Availability,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265:71,Error,Error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265,1,['Error'],['Error']
Availability,I upgraded loompy and scanpy as well but now I am getting an other error. ![screen shot 2018-08-29 at 19 21 34](https://user-images.githubusercontent.com/42487820/44782019-db881800-abc0-11e8-8948-90aa0b0c20a1.png). ![screen shot 2018-08-29 at 19 14 14](https://user-images.githubusercontent.com/42487820/44782040-eb076100-abc0-11e8-961e-75b4ba0c8ec7.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663,1,['error'],['error']
Availability,"I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/353:189,down,downstream,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353,1,['down'],['downstream']
Availability,"I want to split AnnData after tl.diffmap according to each cell's library. But it appears that row-slicing AnnData after diffmap, dpt, or louvain gives the error message `AttributeError: 'AnnData' object has no attribute '_n_obs'`. But AnnData.X and AnnData.obs can be sliced. Could you please give me advice?. ```py; >>> adata = sc.read_10x_h5('filtered_gene_bc_matrices_h5.h5', 'mm10'); >>> scanpy.api.tl.diffmap(adata); >>> adata_diffmap[:, 0]; View of AnnData object with n_obs × n_vars = 5000 × 1; >>> adata_diffmap[0, :] ; AttributeError: 'AnnData' object has no attribute '_n_obs'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/62:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/62,1,['error'],['error']
Availability,"I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me?. _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2442:300,reliab,reliably,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442,1,['reliab'],['reliably']
Availability,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1344,robust,robust,1344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638,2,['robust'],['robust']
Availability,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156:51,failure,failures,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156,1,['failure'],['failures']
Availability,"I was referring to both the instability and what i understood to mean non-robustness to different datasets. But it seems a ""use case"" is an analytical step here, rather than a particular dataset to be analysed. That makes it a lot better, and it means there is work to be done but a general best practice conclusion would be reachable. . In that case it's only the instability of the algorithm that is the issue per dataset. And in the case where you're doing exploratory analysis for a new dataset, you don't typically have a validation dataset, which makes this pretty challenging for end users of the method. Enrichment could be a way forward I guess... I'm not the biggest fan of using enrichment results as a measure for success though. Enrichment results still require quite a bit of interpretation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107:74,robust,robustness,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107,1,['robust'],['robustness']
Availability,"I was running Scanpy 1.4.5.1 on Jupyter Notebook; My matplotlib version is 3.1.3. I ran paga using these commands:; ```; sc.tl.paga(bdata,groups='leiden'); sc.pl.paga(bdata, plot=False); sc.pl.paga(bdata); ````. The third command gave me this error:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-65-5027c99fe1bd> in <module>; ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227,1,['error'],['error']
Availability,"I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2318:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318,1,['error'],['error']
Availability,"I was running this:; `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`; Which gave me this error:; ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_30806/3135920018.py in <module>; ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the; 587 # structure of the gene_names dataFrame; --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values; 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values; 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1161 ; 1162 # fall thru to straight lookup; -> 1163 self._validate_key(key, axis); 1164 return self._get_label(key, axis=axis); 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis); 970 # boolean not in slice and with boolean index; 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):; --> 972 raise KeyError(; 973 f""{key}: boolean label can not be used without a boolean index""; 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```; Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1990:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990,1,['error'],['error']
Availability,"I was trying to subset my dataset based on multiple louvain cluster IDs but it seems to only be possible with one cluster ID at a time. At least I'm getting the following error. `NotImplementedError: Slicing with two indices at the same time is not yet implemented. As a workaround, do row and column slicing succesively.`. I'm still new to python and scanpy but would there be a workaround or fix to this? To ease the process I'v inserted what I want to do. `adata_subset = adata[adata.obs['louvain'] == '2', '3']`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/225:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/225,1,['error'],['error']
Availability,"I was wondering if plotting could be facilitated and made more consistent across ; the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem; * provides helper functions for handling colors, saving figures, etc. ; * encourages a consistent plotting API (e.g. by defining abstract base classes); * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:; * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:; - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. ; - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db); - scvelo has its own `scatter`; * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). ; * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832:608,mainten,maintenance,608,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832,1,['mainten'],['maintenance']
Availability,"I will check. Meanwhile, I realized that some errors were introduced in the latest plotting functions, thus I started working in a list of tests to avoid those problems in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780:46,error,errors,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780,1,['error'],['errors']
Availability,"I will close the issue for now, as based on the provided information and the discussion so far, it seems that the question has been addressed and hopefully resolved :). However, please don't hesitate to start user questions on [scverse discourse](https://discourse.scverse.org/), or software & maintenance releated things here. Or reopen the issue if you think I missed your point!. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821#issuecomment-1951935265:294,mainten,maintenance,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821#issuecomment-1951935265,1,['mainten'],['maintenance']
Availability,"I will close this issue because there is an external solution available. We may think about integrating this specific plot into Scanpy at some point, but I don't see it happening anytime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449:62,avail,available,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449,1,['avail'],['available']
Availability,"I wonder for datasets whose umap results looking like this:; ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1976:348,error,error,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976,1,['error'],['error']
Availability,"I would agree the results of `sc.pp.filter_genes(..., inplace=False)` are not the most intuitive. Instead of returning a filtered anndata, it returns which cells would have been filtered and the stats which were used to make this decision. This is documented under the `Returns` section for these functions. What you might want is. ```python; mask, _ = sc.pp.filter_cells(adata, min_genes=200, inplace=False); a = adata[mask].copy(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2030#issuecomment-993648137:343,mask,mask,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030#issuecomment-993648137,4,['mask'],['mask']
Availability,"I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-116-e09d49f2528c> in <module>; ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs); 27 If `show==False` a `matplotlib.Axis` or a list of it.; 28 """"""; ---> 29 return plot_scatter(adata, basis='umap', **kwargs); 30 ; 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 275 color_vector, categorical = _get_color_values(adata, value_to_plot,; 276 groups=groups, palette=palette,; --> 277 use_raw=use_raw); 278 ; 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 665 raise ValueError(""The passed `color` {} is not a valid observation annotation ""; 666 ""or variable name. Valid observation annotation keys are: {}""; --> 667 .format(value_to_plot, adata.obs.columns)); 668 ; 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455:379,error,error,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455,1,['error'],['error']
Availability,"I would probably just pass those through with kwargs. At the moment, I'm not sure I would include this within scanpy, since it's fairly easy for users to do on their own and I'm not sure many people would want to use it. Using a mask to just scale a subset of the data could fit under a possible `mask` keyword argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522:229,mask,mask,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522,2,['mask'],['mask']
Availability,"I'd be up for all of the numbered ones. IIRC, I had some issues with the trailing whitespace/ end of file fixers and some binary files/ csvs in the test suite. I'm a bit worried about false positives with `check-large-files`, but so long as it's easy to allow certain things (e.g. intentionally added test data) it should be fine. In terms of breaking these things down into small tasks/ PRs how about: (1), (2, 3), (4, 5)?. `prettier` looks a bit heavy and like it's targeting a lot of stuff we don't use, so you'd have to make a good case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143:365,down,down,365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143,1,['down'],['down']
Availability,"I'd like to bump the version requirement down a bit, since it seems like it's not that uncommon to pin `map-learn` lower than 0.5.5: https://github.com/search?q=%2F%5B%22%27%5D%3Fumap-learn%5B%22%27%5D%3F%5B%3D%3E%3C%5D%2B%2F&type=code. The cellxgene one is worrying",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1957629969:41,down,down,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1957629969,2,['down'],['down']
Availability,"I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/142:199,down,downstream,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142,2,['down'],['downstream']
Availability,"I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774:197,down,downgrading,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774,1,['down'],['downgrading']
Availability,"I'm adding that expression atlas downloader now (#489), and wondering where the files should go. `pbmc68k_reduced` and `toggleswitch` put the datasets relative to where scanpy is installed (via `__file__`). All other functions place the data relative to where the python process was started. While I like not storing the same files all over a filesystem, I'm not sure in the `scanpy` installation directory is the right place to be storing data. Thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558:33,down,downloader,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558,1,['down'],['downloader']
Availability,"I'm also getting a separate error:; ""simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'""; When I run scanpy.tl.umap. Not sure if this is related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508,1,['error'],['error']
Availability,"I'm also getting this list error, but @brianpenghe 's suggestion of using `swap_axes=True` also seems to have fixed the problem. At least it shows a plot now, although not sure if its correct yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-471151481:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471151481,1,['error'],['error']
Availability,"I'm also seeing the same error when using `sc.ppl.scatter`:; `sc.pl.scatter(adata, color='louvain', basis=""umap"", palette=""tab20"")`. ![image](https://user-images.githubusercontent.com/7407663/47046149-80a38380-d162-11e8-9865-6548c7e9454d.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-430393368:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-430393368,1,['error'],['error']
Availability,"I'm also suddenly having this problem with ""ValueError: Length of values (1) does not match length of index()"" for certain Scanpy functions like `sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac')` and numpy functions `adata.obs['log_counts'] = np.log(adata.obs['n_counts'])`. The error is not due to a problem with my adata file because it reproduces with datasets that were previously error-free.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522:291,error,error,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522,2,['error'],"['error', 'error-free']"
Availability,"I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. ; `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:; `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/106:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106,4,"['error', 'redundant']","['error', 'redundant']"
Availability,"I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```; /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors); 1768 ; 1769 if k <= 0 or k >= min(n, m):; -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)); 1771 ; 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066); ```; Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/331:864,error,error,864,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331,1,['error'],['error']
Availability,"I'm getting an error loading scanpy (#739 ), and it points to the line you moved about deferring loading of umap-learn. . When I revert back to commit abf95c645828e29edf5a7a27b05d9397f3c36f65 (the commit a couple before this), it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-511887782:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-511887782,2,['error'],['error']
Availability,"I'm getting the same error from RStudio with reticulate:. From the console:. ```; py_install('scanpy'); Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... done. # All requested packages already installed. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - scanpy. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. Error: one or more Python packages failed to install [error code 1]; ```. If I switch to the terminal and try `pip` or `conda` I get:. ```; pip install scanpy; ```. ```; Requirement already satisfied: scanpy in /home/tsundoku/anaconda3/lib/python3.7/site-packages (1.4.5.post2); Requirement already satisfied: setuptools-scm in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (3.3.3); Requirement already satisfied: scipy>=1.3 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (1.3.2); Requirement already satisfied: pandas>=0.21 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.25.3); Requirement already satisfied: packaging in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (19.2); Requirement already satisfied: natsort in /home/tsundoku/anacond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,4,"['avail', 'error']","['available', 'error']"
Availability,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284,1,['error'],['error']
Availability,"I'm getting this too. This could be a problem with numpy's random: ; https://github.com/DLR-RM/stable-baselines3/issues/1579 ; https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py; Line 185 ; `part = g.community_leiden(**clustering_args)`. calls the following. community.py; Line 442; ```; membership, quality = GraphBase.community_leiden(; graph,; edge_weights=weights,; node_weights=node_weights,; resolution=resolution,; normalize_resolution=(objective_function == ""modularity""),; beta=beta,; initial_membership=initial_membership,; n_iterations=n_iterations,; ); ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**; Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575:818,error,error,818,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575,2,['error'],['error']
Availability,"I'm having some trouble debugging whatever is going wrong with the notebook tests here. I get the same results if I run `pytest` on my machine, but don't get a failure if I run the code manually. Additionally, I don't get an error (the `abort`) if I *only* run the notebook tests (`pytest -k ""test_pbmc3k""`). Pretty sure the error is happening on the call to louvain in the notebook tests – an `assert False` fails the tests, one after gives current result – but I can't reproduce the abort interactively. Any idea what's going on/ how I can get a more helpful error message here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136:160,failure,failure,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136,4,"['error', 'failure']","['error', 'failure']"
Availability,"I'm having some trouble getting the mitochondrial gene query to not throw an error. Here's an example:. ```python; import scanpy.api as sc; sc.queries.mitochondrial_genes(host=""www.ensembl.org"", org=""hsapiens""); ```; <details>; <summary>The output and traceback</summary>. ```python; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; ---------------------------------------------------------------------------; EmptyDataError Traceback (most recent call last); <ipython-input-14-a6967c88fd61> in <module>(); ----> 1 sc.queries.mitochondrial_genes(host=""www.ensembl.org"", org=""hsapiens""). /usr/local/lib/python3.6/site-packages/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 40 ; 41 # parsing mitochondrial gene symbols; ---> 42 res = pd.read_csv(StringIO(s.query(xml)), sep='\t', header=None); 43 res.columns = ['symbol', 'chromosome_name']; 44 res = res.dropna(). /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision); 676 skip_blank_lines=skip_blank_lines); 677 ; --> 678 return _read(filepath_or_buffer, kwds); 679 ; 680 parser_f.__name__ = name. /usr/local/lib/python3.6/site-packages/pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242,1,['error'],['error']
Availability,"I'm having some trouble reproducing this. Can you provide a complete example that reproduces this. I need to be able to recreate the data that causes this error for you locally. On my end, this works:. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", method=""wilcoxon""); sc.tl.filter_rank_genes_groups(; pbmc,; min_fold_change=1,; min_in_group_fraction=0.25,; max_out_group_fraction=0.5,; use_raw=False,; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-782792403:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-782792403,1,['error'],['error']
Availability,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:; ```; In [23]: adata.write(""cellxgene.h5ad"") ; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-23-33b15d710f71> in <module>; ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense); 2222 compression=compression,; 2223 compression_opts=compression_opts,; -> 2224 force_dense=force_dense,; 2225 ); 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs); 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs); 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs); ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs); 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs); 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs); 103 if key in f:; 104 del f[key]; --> 105 _write_method(type(value))(f, key, value, dataset_kwargs); 106 ; 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 204 for sub_key, sub_value in value.items():; --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs); 206 ; 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs); 103 if key in f:; 104 del f[key",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526,4,"['down', 'error']","['downgrade', 'error']"
Availability,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. ; The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264:173,fault,fault,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264,1,['fault'],['fault']
Availability,I'm having this issue where I read in and merge multiple anndata's with concat. I can't run any of the plotting functions because I get this error. I tried to convert all object/string obs to categorical (except obs names) but I can't really get around it at all.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-1696555861:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-1696555861,1,['error'],['error']
Availability,I'm having trouble reproducing this error. Could you share what versions you have installed (ideally also try updating these to the latest releases) and see if you can replicate the issue on one of the datasets in `sc.datasets`?. I think you should probably do differential expression plots using the same values you used to compute the differential expression in most cases.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525,1,['error'],['error']
Availability,"I'm not sure I agree with your interpretation of your total degree plot. To me, increasing `k` is meant to have the effect of densifying the network, and thus obtaining a lower resolution view of the manifold. It is somewhat analogous to choosing a lower resolution value for `leiden` or `louvain` clustering. What you see is that in the weighted case, the overall degree does not really increase (thus possibly neither does the overall density), so that increasing `k` may have little effect on clustering at all. This is the most I can get from this plot... as density is really about local changes and not the global degree increase. But I would still ask whether it is a good thing that increasing `k` has little effect? Does increasing `k` then change the clustering results (in the weighed case?). I wonder if the observation that you find smaller clusters better in the weighted case is robust. That would suggest that weights can counteract resolution limit issues, which would be very interesting...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485700014:894,robust,robust,894,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485700014,1,['robust'],['robust']
Availability,I'm not sure I entirely understand what the weights are based on. I'm trying to understand when you would suggest someone use your approach. Why do you give one cell a weight of 125? With this type of weight distribution you are basically manually changing the marker gene calculation focusing nearly only on a single cell. That seems strange to me. I'm trying to understand the need for scanpy to support weighted observations. At the moment I don't see when you would want to differently weight the observations... I'm familiar with using weights if I have some form of measurement error or uncertainty between samples. I don't really see how that holds here. Do you weight the cells based on some kind of quality score?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494122404:584,error,error,584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494122404,1,['error'],['error']
Availability,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "")",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,"I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing?; Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sp; import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2381:500,down,downstream,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381,1,['down'],['downstream']
