quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability," 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'genome'; ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA; on highly variable genes; with n_comps=30; finished (0:01:25); computing neighbors; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:04); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:18); running Leiden clustering; finished: found 23 clusters and added; 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04); ```; But when I check my anndata, none present. As such if I try to generate a umap image I get the following error; ```; AnnData object with n_obs × n_vars = 28752 × 22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'; uns: 'genome', 'log1p', 'hvg'; ```. ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; ```pytb; raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm""; ```. #### Versions. <details>. [-----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.2.0; PyQt5 NA; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330:1527,error,error,1527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330,1,['error'],['error']
Availability, 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23127,mask,mask-,23127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_re,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22717,mask,mask-,22717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1988,ERROR,ERROR,1988,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:2656,error,error,2656,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability, (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2517,ERROR,ERROR,2517,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key); 125 ; 126 key = com._apply_if_callable(key, self.obj); --> 127 return self._getitem_axis(key, axis=axis); 128 ; 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1106 return self._get_loc(key, axis=axis); 1107 ; -> 1108 return self._get_label(key, axis=axis); 1109 ; 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis); 143 raise IndexingError('no slices here, handle elsewhere'); 144 ; --> 145 return self.obj._xs(label, axis=axis); 146 ; 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level); 2342 drop_level=drop_level); 2343 else:; -> 2344 loc = self.index.get_loc(key); 2345 ; 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2525 return self._engine.get_loc(key); 2526 except KeyError:; -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2528 ; 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, ; Olivia**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109:2309,toler,tolerance,2309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109,3,['toler'],['tolerance']
Availability," 678 colors = ['dpt_pseudotime']; --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']; 680 if color is not None: colors = color; 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key); 2137 return self._getitem_multilevel(key); 2138 else:; -> 2139 return self._getitem_column(key); 2140 ; 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2144 # get column; 2145 if self.columns.is_unique:; -> 2146 return self._get_item_cache(key); 2147 ; 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 1840 res = cache.get(item); 1841 if res is None:; -> 1842 values = self._data.get(item); 1843 res = self._box_item_values(item, values); 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath); 3841 ; 3842 if not isna(item):; -> 3843 loc = self.items.get_loc(item); 3844 else:; 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2525 return self._engine.get_loc(key); 2526 except KeyError:; -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2528 ; 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'; ```. ---; scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:3024,toler,tolerance,3024,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,3,['toler'],['tolerance']
Availability," 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 255 # ]; 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):; --> 257 color_source_vector = _get_color_source_vector(; 258 adata,; 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1165 ] # TODO: Throw helpful error if this doesn't work; 1166 if use_raw and value_to_plot not in adata.obs.columns:; -> 1167 values = adata.raw.obs_vector(value_to_plot); 1168 else:; 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:2691,error,error,2691,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,1,['error'],['error']
Availability," = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver=""arpack""); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50); sc.tl.leiden(adata, resolution=1.0); sc.tl.paga(adata, groups=""leiden""); sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]); adata.uns['iroot']=0; sc.tl.dpt(adata). import matplotlib.pyplot as plt; fig,ax=plt.subplots(1,1,figsize=(7,1)); path_data = sc.pl.paga_path(; adata,; [4, 5],; [""Elane""],; ax=ax,; show_node_names=False,; ytick_fontsize=12,; return_data=True,; #n_avg=1,; color_map=""Greys"",; groups_key=""leiden"",; color_maps_annotations={""dpt_pseudotime"": ""viridis""}; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[1], line 15; 13 import matplotlib.pyplot as plt; 14 fig,ax=plt.subplots(1,1,figsize=(7,1)); ---> 15 path_data = sc.pl.paga_path(; 16 adata,; 17 [4, 5],; 18 [""Elane""],; 19 ax=ax,; 20 show_node_names=False,; 21 ytick_fontsize=12,; 22 return_data=True,; 23 #n_avg=1,; 24 color_map=""Greys"",; 25 groups_key=""leiden"",; 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}; 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:1446,Error,Error,1446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['Error'],['Error']
Availability," A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/.virtualenvs/pytorch_latest/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078:1381,ERROR,ERROR,1381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078,1,['ERROR'],['ERROR']
Availability," Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). To avoid this complication I rewrote the Zheng17 recipe to do all the NumPy array computations and then construct an Anndata representation at the end,; to take advantage of Dask's deferred processing of lazy values. (See https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L115 for the code.). With this change, running on the 1M neurons dataset with 64 cores `scipy.sparse` takes 334s, while Dask with `scipy.sparse` takes 138s, a 2.4x speedup. That's a significant speedup, but I'm not sure that it justifies the code overhead. I'd be interested to hear what others think. . ### Other notes. #### Code; See this branch: https://github.com/theislab/scanpy/compare/master...tomwhite:sparse-dask. #### CuPy and GPUs; I also wrote a [wrapper](https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/sparsearray/_cupy_sparse.py) around the GPU equivalent of `scipy.sparse`, [`cupyx.scipy.sparse`](https://docs-cupy.chainer.org/en/stable/reference/sparse.html). Many operations work, however `cupyx.scipy.sparse` has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:; * `multiply` - not implemented by `cupyx.scipy.sparse.csr.csr_matrix`; * `mean` - no method on `cupyx.scipy.sparse.csr.csr_matrix` (note that it does have `sum`); * column subset not supported, e.g. `xs[:, 1:3]` (note that row subset is); * boolean indexing, i.e. `xs[:, subset]`, where `subset` is e.g. `np.array([True, False, True, False, True])`; note this fails for rows too. #### NumPy 1.16 vs NumPy 1.17; I used NumPy 1.16 for the above experiments. However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921:3294,down,down,3294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921,1,['down'],['down']
Availability, ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2862,ERROR,ERROR,2862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. **The problem is the error in importing gene names both when using id and when using symbolic labeling. All genes have the same name. if you use `anndata=0.10.3` instead of `anndata=0.10.4`, then everything works correctly.**. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib; import seaborn as sns. path='<path_to_files>'. adata = sc.read_10x_mtx(; path, ; var_names='gene_symbols', ; cache=True). adata.var_names_make_unique(). adata.var; ```. ### Error output. ```pycon; >>> # then anndata=0.10.4; >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. ### Expected. ```pycon; >>> # then anndata=0.10.3; >>> print(adata.var); gene_ids feature_types; 4933401J01Rik ENSMUSG00000102693 Gene Expression; Gm26206 ENSMUSG00000064842 Gene Expression; Xkr4 ENSMUSG00000051951 Gene Expression; Gm18956 ENSMUSG00000102851 Gene Expression; Gm37180 ENSMUSG00000103377 Gene Expression; ... ... ...; mt-Nd6 ENSMUSG00000064368 Gene Expression; mt-Te ENS",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:7240,Error,Error,7240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['Error'],['Error']
Availability," I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:943,error,error,943,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,3,"['ERROR', 'error']","['ERROR', 'error', 'errored']"
Availability, ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9412,ERROR,ERROR,9412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," In certain combinations of `groupby` variables, some valuese get lost. . I wasn't able to make a minimal reproducible example, but I obfuscated the `obs` table of my real data and can share it here: ; https://www.dropbox.com/scl/fi/jsbrb2ulki7mmih2242kc/adata_aggregate_bug.h5ad?rlkey=qczuaf2v5vlwb00zyuxmzjkix&dl=1. ### Minimal code sample. ```python; >>> test_adata = sc.read_h5ad(""adata_aggregate_bug.h5ad""). >>> test_adata.obs[""patient_id""].nunique(); 69. >>> test_adata.obs.isnull().sum(); patient_id 0; timepoint 0; external_batch_id 0; dtype: int64. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 15. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69; ```. ### Error output. ```pytb; So only if using all three variables, some patient IDs are lost. I don't see why this would be happening.; ```. ### Versions. <details>. ```; Package Version Editable project location; ------------------------- --------------- -------------------------------------------------------------------------------------------------------------------------; aiohttp 3.9.3; aiosignal 1.3.1; anndata 0.10.5.post1; anyio 4.3.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array_api_compat 1.5; arrow 1.3.0; asciitree 0.3.3; asttokens 2.4.1; async-lru 2.0.4; async-timeout 4.0.3; attrs 23.2.0; Babel 2.14.0; beautifulsoup4 4.12.3; bleach 6.1.0; bokeh 3.3.4; branca 0.7.1; Brotli 1.1.0; cached-property 1.5.2; cachetools 5.3.3; certifi 2024.2.2; cffi 1.16.0; charset-normalizer 3.3.2; click 8.1.7; click-plugins 1.1.1; cligj 0.7.2; cloudpickle 3.0.0; colorama 0.4.6; colorcet 3.1.0; comm 0.2.1; confluent-kafka 1.9.2; contourpy 1.2.0; cubinlinker 0.3.0; cucim 24.2.0; cuda-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964:1368,Error,Error,1368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964,1,['Error'],['Error']
Availability," This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 32",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:1496,error,error,1496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability," \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/cat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2444,down,downcast,2444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['down'],['downcast']
Availability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3679,Toler,Tolerance,3679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,"['Error', 'Toler']","['Error', 'Tolerance']"
Availability," `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2365:1647,Down,Download,1647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365,1,['Down'],['Download']
Availability," ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782:1389,error,error,1389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782,1,['error'],['error']
Availability," a year ago for various reasons (see below). Meanwhile, the following two functions can maybe direcly imported from UMAP, if not, we could make a PR there or use pynndescent?; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. There is a chance that this can also be solved with an import from UMAP.; https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. As just discussed, @Koncopd, can you look into this and make a PR that gets rid of the umap legacy code?. Thank you so much!; Alex. PS: Just wrote an explanation for the reasons why I intorduced the duplicated code in the first place.; > The duplicated code in Scanpy came about as I wanted to very quickly move forward with a version 1.0 of Scanpy about a year ago. UMAP was just becoming available on GitHub and there wasn’t even a preprint, I think. It changed very quickly and there were dramatic bugs every now and then. Nonetheless it was clear that it’s a major improvement over existing solutions, both in terms of computational performance, quality of the result and ease of installation and use. I wanted to achieve two things: (i) I had to rewrite some parts of UMAP so that I could decompose it a neighbors computing and a dedicated embedding step; you know that in Scanpy, the neighborhood graph is used for many other things other than for the embedding (clustering and trajectory inference). I also added the Gaussian kernel solution that I had before switching to a “UMAP backend” for `pp.neighbors`; which was needed so that results for DPT could be reproduced. All of this would have been quite a discussion with Leland. Until we would have had settled on the “Scanpy needs” that certainly weren’t aligned with the development of an independent young package, PRs would have been integrated ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522:1068,avail,available,1068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522,1,['avail'],['available']
Availability," adata.var_names.str.startswith('mt'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'); sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the follow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:1736,error,error,1736,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['error'],['error']
Availability," are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Basically I am creating a stacked violin plot that uses a list of marker genes for the ""var_names"" argument. But whenever I create the plot, it has extra whitespace at the top of the plot where the marker gene labels should go. This is very evident when you add a figure title, which gets place above the padding whitespace. I have not really found a way around this, and am currently looking through the scanpy internal code to see if there is some padding setting that I can undo. If there is a workaround to this or some option that I am missing I would like to know. Thanks!. ### Minimal code sample. ```py; # I have an AnnData object that has undergone the Seurat analysis. I named the Leiden clustering output ""spatial_clusters"" since I was testing a spatial dataset read in via spatialdata then converted to AnnData with ""spatialdata_io.experimental.to_legacy_anndata"". marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. sc.pl.stacked_violin(adata, marker_genes, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). ### COMPARISON TO MARKER GENES WITH LABELS; marker_genes = {""IHC"": [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1""], ""Random"": [""Sox2""]}. sc.pl.stacked_violin(adata, marker_genes, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). ```. ### Error output. Will post in the next comment on this thread. Seems I cannot drag-n-drop images into this block. ### Versions. <details>. I am including relevant package versions. Can provide more if needed. Python 3.12.7. ```; anndata==0.10.6; matplotlib==3.9.0; pandas==2.2.1; scanpy-1.10.3; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3320:1730,Error,Error,1730,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320,1,['Error'],['Error']
Availability," as_heatmap:; 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 245 timeseries_as_heatmap(; 246 adata.X[adata.obs[""dpt_order_indices""].values],; 247 var_names=adata.var_names,; 248 highlights_x=adata.uns[""dpt_changepoints""],; 249 color_map=color_map,; 250 ); 251 else:; 252 # plot time series as gene expression vs time; 253 timeseries(; 254 adata.X[adata.obs[""dpt_order_indices""].values],; 255 var_names=adata.var_names,; (...); 258 marker=marker,; 259 ). File D:\anaconda\Lib\site-packages\scanpy\plotting\_utils.py:227, in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 223 x_new[:, _hold:] = X[:, hold:]; 225 _, ax = plt.subplots(figsize=(1.5 * 4, 2 * 4)); 226 img = ax.imshow(; --> 227 np.array(X, dtype=np.float_),; 228 aspect=""auto"",; 229 interpolation=""nearest"",; 230 cmap=color_map,; 231 ); 232 plt.colorbar(img, shrink=0.5); 233 plt.yticks(range(X.shape[0]), var_names). ValueError: setting an array element with a sequence.; ```. Error in dpt_groups_pseudotime:. ```pytb; ValueError Traceback (most recent call last); Cell In[91], line 1; ----> 1 sc.pl.dpt_groups_pseudotime(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:276, in dpt_groups_pseudotime(adata, color_map, palette, show, save, marker); 274 """"""Plot groups and pseudotime.""""""; 275 _, (ax_grp, ax_ord) = plt.subplots(2, 1); --> 276 timeseries_subplot(; 277 adata.obs[""dpt_groups""].cat.codes,; 278 time=adata.obs[""dpt_order""].values,; 279 color=np.asarray(adata.obs[""dpt_groups""]),; 280 highlights_x=adata.uns[""dpt_changepoints""],; 281 ylabel=""dpt groups"",; 282 yticks=(;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:2635,Error,Error,2635,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,1,['Error'],['Error']
Availability," checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I'm getting an OSerror when reading in visium data because my folder only has tissue_positions.csv. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs/spatial/tissue_positions_list.csv'. This is caused by a change in SpaceRanger output - as seen here:. tissue_positions.csv: This text file contains a table with rows that correspond to spots. From Space Ranger v2.0 onwards this file, which was previously named tissue_positions_list.csv, is renamed and includes a header column. . I think the code would be best fixed by an or check for either file name. . ### Minimal code sample. ```python; adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); Cell In[2], line 6; 4 #path = '/bgfs/alee/LO_LAB/General/Lab_Data/20240510_Neil_SpatialSequencing_AgePatients/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS19-10502/outs'; 5 path = '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2024_Neil/SpaceRanger_OUT/MWS-7945/outs'; ----> 6 adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/SpatialSequencing/lib/python3.8/site-packages/scanpy/readwrite.py:392, in read_visium(path, genome, count_file, library_id, load_images, source_image_path); 387 logg.warning(; 388 f""You seem to be missing an image file.\n""; 389 f""Could not find '{f}'.""; 390 ); 391 else:; --> 392 raise OSError(f""Could not find '{f}'""); 394 adata.uns[""spatial""][library_id][""images""] = dict(); 395 for res in [""hires"", ""lowres""]:. OSError: Could not find '/bgfs/alee/shared/alee_rfe4_wam30/Lee_Visium_GEX-PEX_2_2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3085:1055,Error,Error,1055,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085,1,['Error'],['Error']
Availability," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/884:1562,error,error,1562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884,1,['error'],['error']
Availability," conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2730:1022,Error,Error,1022,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730,1,['Error'],['Error']
Availability," data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2381:1946,error,error,1946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381,1,['error'],['error']
Availability," data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2210,down,downcast,2210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,2,['down'],['downcast']
Availability," dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isn’t great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setupto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2744:1648,Error,Error,1648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744,1,['Error'],['Error']
Availability, from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14569,mask,mask-,14569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability, from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residua,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16474,mask,mask-,16474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability," has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hello - II noticed that shuffling the var table leads to shuffled gene names in the differential expression table which is misleading. I believe this is an unintended bug. ### Minimal code sample. ```python; import scanpy as sc. sc.tl.rank_genes_groups( rna_ann, ; 'celltypes',; key_added = 'wilcoxon',; reference = 'PT',; layer = 'data',; method='wilcoxon',; pts = True ). diff_exp1 = sc.get.rank_genes_groups_df( rna_ann, ; group = 'aPT', ; key = 'wilcoxon', ). rna_ann.var = rna_ann.var.sort_values( by = [ 'nCount' ],; ascending = False ). sc.tl.rank_genes_groups( rna_ann, ; 'celltypes',; key_added = 'wilcoxon2',; reference = 'PT',; layer = 'data',; method='wilcoxon',; pts = True ). diff_exp2 = sc.get.rank_genes_groups_df( rna_ann, ; group = 'aPT', ; key = 'wilcoxon2', ); ```. ### Error output. In the output, the numerical values are the same and in the same order in both diff_exp1 and diff_exp2. However, the gene names in the 'names' column are shuffled in diff_exp2 leading to incorrect conclusions. I added screenshots of both tables in the versions section of this issue. <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 34 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/32005bb5-1fe0-4e96-a612-647e8abd4b05"">; <img width=""686"" alt=""Screen Shot 2024-06-13 at 10 51 26 AM"" src=""https://github.com/scverse/scanpy/assets/47502214/8b90e1a4-d2d4-47ca-9778-a368525851dc"">. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.1; -----; PIL 9.2.0; anyio NA; argcomplete NA; arrow 1.3.0; asciitree NA; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.13.0; backcall 0.2.0; bamnostic NA; brotli 1.0.9; certifi 2024.06.02; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3.3.0; cloudpickle 3.0.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3106:1079,Error,Error,1079,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106,1,['Error'],['Error']
Availability, import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2295,ERROR,ERROR,2295,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability," issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Trying to store normalised values in a layer 'normalised', then plot from that layer with sc.pl.highest_expr_genes(). But the function fails with the layer parameter. ### Minimal code sample. ```py; import numpy as np; import pandas as pd; import anndata as ad. # Create a small data matrix; data = np.random.rand(10, 5). # Create observation (cell) and variable (gene) annotations; obs = pd.DataFrame(index=[f'Cell_{i}' for i in range(data.shape[0])]); var = pd.DataFrame(index=[f'Gene_{i}' for i in range(data.shape[1])]). # Create the AnnData object; adata = ad.AnnData(X=data, obs=obs, var=var). # Test layer call function; adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test; sc.pl.highest_expr_genes(adata, layer='normalised'); ```. ### Error output. ```pytb; Output exceeds the size limit. Open the full output data in a text editor; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[32], line 17; 15 # Test layer call function; 16 adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test; ---> 17 sc.pl.highest_expr_genes(adata, layer='normalised'); 19 # Test layer call function; 20 adata.layers['normalised'] = adata.X # not doing any manipulation of X at the moment to test. File c:\Users\U062951\Miniconda3\envs\imc_ome_v1_spatial\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File c:\Users\U062",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3318:1073,Error,Error,1073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318,1,['Error'],['Error']
Availability," making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):; <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):; <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(); ```. ### Error output. ```pytb; (Error output is a bad plot, included in the description above.); ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; IPython 8.13.2; PIL 10.0.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.10.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; dot_parser NA; entrypoints 0.4; exceptiongroup 1.1.1; executing 1.2.0; fasteners 0.17.3; flytekitplugins NA; gmpy2 2.1.2; google NA; h5py 3.8.0; icu 2.11; igraph 0.11.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.8.3; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; natsort 8.3.1; numba 0.59.1; numcodecs 0.11.0; numexpr 2.7.3; numpy 1.26.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; plotly 5.14.1; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062:1932,Error,Error,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062,1,['Error'],['Error']
Availability," matplotlib; >>> import seaborn as sns; >>> !ls -lh ./H004/; -rwxrwxrwx. 1 nikolay nikolay 49K Mar 25 2021 barcodes.tsv.gz; -rwxrwxrwx. 1 nikolay nikolay 424K Mar 25 2021 features.tsv.gz; -rwxrwxrwx. 1 nikolay nikolay 101M Mar 25 2021 matrix.mtx.gz; >>> adata = sc.read_10x_mtx(; ... './H004/', ; ... var_names='gene_symbols', ; ... cache=True); >>> adata.var_names_make_unique(); >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. **The problem is the error in importing gene names both when using id and when using symbolic labeling. All genes have the same name. if you use `anndata=0.10.3` instead of `anndata=0.10.4`, then everything works correctly.**. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib; import seaborn as sns. path='<path_to_files>'. adata = sc.read_10x_mtx(; path, ; var_names='gene_symbols', ; cache=True). adata.var_names_make_unique(). adata.var; ```. ### Error output. ```pycon; >>> # then anndata=0.10.4; >>> print(adata.var); gene_ids feature_types; Gm26206 ENSMUSG00000064842 Gene Expression; Gm26206-1 ENSMUSG00000064842 Gene Expression; Gm26206-2 ENSMUSG00000064842 Gene Expression; Gm26206-3 ENSMUSG00000064842 Gene Expression; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:6744,error,error,6744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['error'],['error']
Availability," mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error output. ```pytb; mtx is parse=False. Rescaled with my_scale_function:; True; Rescaled with scanpy:; False. Original matrix:; [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01; -2.09179729e-01 -5.31203270e-01]; [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01; -3.13310266e-01 -5.96654296e-01]; [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01; -1.70931697e-01 1.37899971e+00]; ...; [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02; -1.61111996e-01 2.04149699e+00]; [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03; -1.35240912e-01 -4.82111037e-01]; [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02; -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:; [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01; -2.0917973e-01 -5.3120327e-01]; [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01; -3.1331027e-01 -5.9665430e-01]; [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629:1993,Error,Error,1993,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629,1,['Error'],['Error']
Availability," more predictability at the expense of backwards compatibility*? Especially the “euclidean” condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'` … ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean “connectivity method”. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (“build a symmetric mask”, …) *not covered, but also the logic shouldn’t have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umap’s `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we don’t actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2536:1890,mask,mask,1890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536,1,['mask'],['mask']
Availability," n_bins, flavor, subset, inplace, batch_key, check_values); 425 span=span,; 426 subset=subset,; --> 427 inplace=inplace,; 428 ); 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 ); 66 ; ---> 67 df['means'], df['variances'] = _get_mean_var(X); 68 ; 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis); 6 def _get_mean_var(X, *, axis=0):; 7 if sparse.issparse(X):; ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis); 9 else:; 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1995:2362,error,error,2362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995,1,['error'],['error']
Availability," nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.6.0; igraph 0.9.8; joblib 1.1.0; kiwisolv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:2181,error,error,2181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124:1167,error,error,1167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124,2,"['Error', 'error']","['Error', 'error']"
Availability," on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose); 216 projection=projection,; 217 sparse_pca=sparse_pca,; --> 218 verbose=verbose,; 219 ); 220 . ~/anaconda3/lib/py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157:1083,Error,Error,1083,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157,1,['Error'],['Error']
Availability, print(prot.X); ```; Output; ```; before; [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165; -0.05565361]; [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884; 0.03547253]; [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176; -0.05032819]; ...; [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771; -0.01558504]; [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814; 0.0116325 ]; [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189; 0.02879048]]; after; [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232; -0.03857614]; [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566; 0.02458768]; [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355; -0.03488484]; ...; [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253; -0.01080273]; [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221; 0.00806304]; [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191; 0.01995604]]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.20.2; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.39.1; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.0; s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2668:1814,Error,Error,1814,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668,1,['Error'],['Error']
Availability," pyproject.toml; testpaths: scanpy; plugins: nunit-1.0.6, mock-3.12.0; [1mcollecting ... [0mcollected 1474 items. scanpy/_utils/compute/is_constant.py::scanpy._utils.compute.is_constant.is_constant [32mPASSED[0m[32m [ 0%][0m; scanpy/datasets/_ebi_expression_atlas.py::scanpy.datasets._ebi_expression_atlas.ebi_expression_atlas [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pl.py::scanpy.external.pl.phate [33mSKIPPED[0m (needs modul...)[32m [ 0%][0m; scanpy/external/pp/_bbknn.py::scanpy.external.pp._bbknn.bbknn [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_harmony_integrate.py::scanpy.external.pp._harmony_integrate.harmony_integrate [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_hashsolo.py::scanpy.external.pp._hashsolo.hashsolo [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_magic.py::scanpy.external.pp._magic.magic [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_scanorama_integrate.py::scanpy.external.pp._scanorama_integrate.scanorama_integrate Fatal Python error: Illegal instruction. Thread 0x00007f00347c4640 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 316 in wait; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 581 in wait; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/tqdm/_monitor.py"", line 60 in run; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 980 in _bootstrap_inner; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 937 in _bootstrap. Current thread 0x00007f004e08eb80 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 522 in nn_approx; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 590 in fill_table; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanorama/scanorama.py"", line 631 in find_ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:1789,error,error,1789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,1,['error'],['error']
Availability," run_command; self.distribution.run_command(command); File ""/cluster/software/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/cluster/software/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/cluster/software/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/cluster/software/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/scratch/tmp/pip-build-g14yf1xi/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 65, in __getattr__; self.data_files = self._get_data_files(); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 79, in _get_data_files; return list(map(self._get_pkg_data_files, self.packages or ())); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files; for file in self.find_data_files(package, src_dir); File ""/cluster/software/lib/python3.6/site-packages/setuptools/command/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: must be str, not list; ```. </details>. I have never had this error message before and Google can't find anything. . Debugging this a bit, it happens because in this line in build_py.py:. ```py; globs = (self.package_data.get('', []); + self.package_data.get(package, [])); ```. package is ""scanpy"" and the first part before the + is `""*.txt""` and the second part after the + is `[]`. This is Python 3.6.0a1 and pip 9.0.1 on Centos 6.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:8469,error,error,8469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['error'],['error']
Availability," save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ---------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3134,toler,tolerance,3134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,['toler'],['tolerance']
Availability," scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,; ```; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Minimal code sample. ```python. import scanpy as sc; import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25); adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],; jitter=0.4, multi_panel=True, save=""_before_QC.pdf""); ```. ### Error output. ```pytb; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata); Detected doublet rate = 1.7%; Estimated detectable doublet fraction = 41.1%; Overall doublet rate:; 	Expected = 6.0%; 	Estimated = 4.1%; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.; adata.obs[obs_metrics.columns] = obs_metrics; WARNING: saving figure to file figures/violin_before_QC.pdf; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight; self._figure.tight_layout(*args, **kwargs); /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI bac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2627:1175,Error,Error,1175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627,1,['Error'],['Error']
Availability," scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:1098,error,error,1098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability," strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1616,error,error,1616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability," the left (fig. 1); sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) # see the tb (if there's only 1 category, in the group, it doesn't crash). a.X[:16, :] = 10 + np.random.RandomState(42).normal(size=(16, 50)); a.X[16:32, :] = -10 + np.random.RandomState(42).normal(size=(16, 50)); a.obs['foo'].iloc[:16, :] = 0; a.obs['foo'].iloc[16:32, :] = 1; a.obs['foo'].iloc[32:, :] = 2; # wrong label-color mapping; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 2; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 3. # but not when there are colors in `.uns; a.uns['foo_colors'] = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 4; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 5; # xlabels are not centered + horizntal lines are slightly shifted downwards (really have to zoom in); sc.pl.heatmap(a, var_names=a.var_names, groupby=""foo"", swap_axes=False, figsize=(50, 50)); ```; If you look closely (e.g. between fig. 2 and fig.3, or fig. 4 and fig. 5), the within group order is also broken. ```pytb; TypeError Traceback (most recent call last); <ipython-input-56-f1ba710dac43> in <module>; 9 ; 10 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=None, swap_axes=True) # is shifted to the left (fig. 1); ---> 11 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) ; 12 ; 13 a.X[:16, :] = 0. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1220 groupby_cmap,; 1221 norm,; -> 1222 ) = _plot_categories_as_colorblocks(; 1223 groupby_ax, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591:1825,down,downwards,1825,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591,1,['down'],['downwards']
Availability,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169:4381,error,error,4381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169,1,['error'],['error']
Availability,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361:14,fault,fault,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361,2,"['Error', 'fault']","['Error', 'fault']"
Availability,"""cell_ranger""'); --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 255 if sz == 0:; 256 raise ValueError(""Cannot cut empty array""); --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)); 259 mn, mx = (mi + 0.0 for mi in rng); 261 if np.isinf(mn) or np.isinf(mx):; 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds); 145 result = alt(values, axis=axis, skipna=skipna, **kwds); 146 else:; --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds); 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs); 401 if datetimelike and mask is None:; 402 mask = isna(values); --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs); 406 if datetimelike:; 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask); 1086 if values.size == 0:; 1087 return _na_for_min_count(values, axis); -> 1089 values, mask = _get_values(; 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask; 1091 ); 1092 result = getattr(values, meth)(axis); 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask); 314 if datetimelike or _na_ok_dtype(dtype):; 315 values = values.copy(); --> 316 np.putmask(values, mask, fill_value); 317 else:; 318 # np.where will promote if needed; 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:11076,mask,mask,11076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,5,['mask'],['mask']
Availability,"""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dodge,; 2935 gap=gap,; 2936 split=split,; 2937 color=color,; 2938 fill=fill,; 2939 linecolor=linecolor,; 2940 linewidth=linewidth,; 2941 inner=inner,; 2942 density_norm=density_norm,; 2943 common_norm=common_norm,; 2944 kde_kws=kde_kws,; 2945 inner_kws=inner_kws,; 2946 plot_kws=plot_kws,; 2947 ); 2949 elif kind == ""boxen"":; 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws); 1151 legend_artist = _get_patch_legend_artist(fill); 1152 common_kws = {**plot_kws, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:1589,error,errorbar,1589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['error'],['errorbar']
Availability,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I have two different datasets, both with raw counts. After using the function `sc.pp.normalize_total` and `sc.pp.log1p` and plotting the data with UMAP coordinates, there is no gene expression in cells coming from one of the datasets. I did the analysis separately (without concatenating) and the same happens. . I thought that maybe is a problem with the data type, but when I checked this, both anndatas.X were np.float32 and sparse.csr_matrixes ( #1612 ). Also, I made sure the anndata matrix related to the problematic dataset has acceptable values and they are not zeros. Any idea about this problem?. ### Minimal code sample. ```python; sc.pp.normalize_total(adata); sc.pp.log1p(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 9.1.0; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; cycler 0.10.0; cython_runtime NA; dask 2022.8.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.4; fastjsonschema NA; fsspec 2022.7.1; google NA; h5py 3.4.0; idna 3.3; igraph 0.9.6; ipykernel 6.4.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.38.0; louvain 0.7.0; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; mpmath 1.3.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.55.1; numexpr 2.7.3; numpy 1.21.6; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2556:998,Error,Error,998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556,1,['Error'],['Error']
Availability,"# What happened?. Hi!. I am new to scanpy and I am facing some trouble reading my data in an appropriate way. I noticed that anndata objects in memory require roughly 4x the space they require on disk, so working with large datasets (>50GB on disk) is prohibitive in most scenarios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:1257,down,downloading,1257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['down'],['downloading']
Availability,"# a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 Please use .at[] or .iat[] accessors.; 910 ; --> 911 Parameters; 912 ----------; 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 -------; 952 series : Series; --> 953 If label is contained, will be reference to calling Series,; 954 otherwise a new object; 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4344 ; 4345 elif not is_list_like(value):; -> 4346 new_data = self._data.fillna(value=value, limit=limit,; 4347 inplace=inplace,; 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4357 return self._constructor(new_data).__finalize__(self); 4358 ; -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):; 4360 """"""; 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 # in which case we are going to conform to the passed Categorical; 502 new_target = np.asarray(new_target); --> 503 if is_categorical_dtype(target):; 504 new_target = target._shallow_copy(new_target, name=self.name); 505 else:. ValueError: cannot reindex with a non-unique indexer. **; ```; The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450:1821,down,downcast,1821,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450,2,['down'],['downcast']
Availability,"## Description. Running the scanpy tests locally (see system information and package versions below), I noticed the test `scanpy/tests/test_plotting.py::test_paga` sometimes failing due to `AssertionError: Error: Image files did not match` but passing on a consecutive run. Did anyone encounter similar problems or does anyone know why this is happening?. ### Failure message. ```bash; >>> pytest scanpy/tests/test_plotting.py; scanpy/tests/test_plotting.py .............................................x............F.... [100%]. =========================================================================================================== FAILURES ============================================================================================================; ___________________________________________________________________________________________________________ test_paga ___________________________________________________________________________________________________________. image_comparer = <function make_comparer at 0x7fbce4ade8c0>. def test_paga(image_comparer):; # Sometimes things shift a pixel or so, resulting in diffs up to ~27; # The 1px-edges aren’t that good actually as they’re ignored at this tol …; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); ; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.paga(pbmc, groups='bulk_labels'); ; common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; # delete bulk_labels_colors to test the creation of color list by paga; del pbmc.uns['bulk_labels_colors']; sc.pl.paga(pbmc, **common); save_and_compare_images('master_paga'); ; sc.pl.paga(pbmc, color='CST3', **common); save_and_compare_images('master_paga_continuous'); ; pbmc.obs['cool_feature'] = pbmc[:, 'CST3'].X.squeeze(); sc.pl.paga(pbmc, color='cool_feature', **common); save_and_compare_images('master_paga_continuous_obs'); ; sc.pl.paga(pbmc, color=['CST3', 'GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:206,Error,Error,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,3,"['Error', 'FAILURE', 'Failure']","['Error', 'FAILURES', 'Failure']"
Availability,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439,1,['error'],['error']
Availability,"## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1921:161,error,error,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921,1,['error'],['error']
Availability,"## Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have a bunch of matrix.mtx, barcode.tsv and genes.tsv. When I want to read in the files with:; `data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True)`. I get the following error:; `FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'`. The thing is that the file exist here:; ![kép](https://github.com/user-attachments/assets/a3ee8f51-833d-4adb-ab9f-f6ff5b19387f). I have changed the *genes.tsv.gz file's name to *features.tsv.gz but still got the same error. Here is the full error log:; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], [line 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/Pipe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:866,error,error,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['error']
Availability,"### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**; - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**; - Subset of genes defined by `var_names` is now used. **In addition:**; - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix.; - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis).; - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`; - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct.; - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2384:613,down,downstream,613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384,2,"['down', 'error']","['downstream', 'error']"
Availability,"### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); cats = pbmc.obs[""louvain""].cat.categories; genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]); ```. ```pytb; ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-580bb69f9615> in <module>; ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:343,error,errors,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python; This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',; 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',; 'NKT', 'NK_0', 'NK_1', 'NK_2',; 'ncMo', 'cMo', 'DC_1', 'DC_2', 'MΦ_1', 'MΦ_2',; 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True); ```; ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005:1270,Error,Error,1270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. (extracted from #3167). Utilizing the murine hematopoietic progenitors from [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480), as well as the regev_lab_cell_cycle_genes.txt, one issue is apparent. Currently the code doesn’t produce the expected number of bins of equal or approximately equal size. Bin 24 is empty when n_bins = 25.; ![current_hist](https://github.com/user-attachments/assets/35e5d1a4-fdd0-406e-a2f9-1b53efacc8fa). ### The current ranking system code within score_genes(); ```py; n_items = int(np.round(len(obs_avg) / (n_bins - 1))); obs_cut = obs_avg.rank(method=""min"") // n_items; ```. ### The modified code in #3167; ```py; obs_avg.sort_values(ascending=True, inplace=True); n_items = int(np.ceil(len(obs_avg) / (n_bins))); rank = np.repeat(np.arange(n_bins), n_items)[:len(obs_avg)]; obs_cut = pd.Series(rank, index=obs_avg.index); ```. The modified code performs as expected producing 25 bins containing approximately equal number of genes. The last bin can have up to 24 less than expected because the total number of genes is not perfectly divisible by 25.; ![modified_hist](https://github.com/user-attachments/assets/6ced8eec-b56b-4642-a33c-71acaee98369). ### Minimal code sample. ```python; TODO; ```. ### Error output. _No response_. ### Versions. <details>. ```; Python 3.10.12 ; scanpy==1.10.2 anndata==0.10.8 umap==0.5.6 numpy==1.26.4 scipy==1.14.0 pandas==2.2.2 scikit-learn==1.5.0 statsmodels==0.14.2 igraph==0.11.6 louvain==0.8.2 pynndescent==0.5.13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3168:1541,Error,Error,1541,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3168,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. (extracted from https://github.com/scverse/scanpy/pull/3167). The code fails completely when the gene set has zero expression in some cells. The data used to illustrate this problem is located here: [test_data.h5ad](https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/test_data.h5ad) . Since relatively few genes are typically selected for measurement, this will be a common occurrence.; ![hist](https://github.com/user-attachments/assets/d578327b-6cf8-4c8f-b3c9-01744f35832b). If the expression data is **scaled** the problem is more intrusive since it occurs in the middle of the expression range. The bins with no genes give a Nan result.; ![hist2](https://github.com/user-attachments/assets/81946f65-2673-427e-b540-46303224544a). The proposed code modification in #3167 has no problem with this data set, either scaled or unscaled.; ![image](https://github.com/user-attachments/assets/6273b44b-7def-4fb4-b410-3de67416f5db). ### Minimal code sample. ```python; TODO; ```. ### Error output. _No response_. ### Versions. <details>. ```; Python 3.10.12 ; scanpy==1.10.2 anndata==0.10.8 umap==0.5.6 numpy==1.26.4 scipy==1.14.0 pandas==2.2.2 scikit-learn==1.5.0 statsmodels==0.14.2 igraph==0.11.6 louvain==0.8.2 pynndescent==0.5.13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3169:1281,Error,Error,1281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3169,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # start from scratch; del adata.obs[""louvain""]; adata.uns = {}; adata_ref.uns = {}. # example code for ingest function:; sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs=""louvain""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[11], line 23; 21 sc.pp.neighbors(adata_ref); 22 sc.tl.umap(adata_ref); ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:520,error,error,520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,2,['error'],"['error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Dear scanpy teams, research fellows,; I downloaded some scRNA-seq data from https://zenodo.org/records/3357167,; and when I was tring to use `anndata.AnnData.concatenate` to combine two read count data(I checked their dimensions and the result were `Baron_human: [2133,22758]` and `Segerstolpe: [8569,17500]` which means they certainly have different annotated genes), I got below error. Could u help. many thanks!!. ### Minimal code sample. ```python; all_adata = anndata.AnnData.concatenate(train_adata,test_adata); ```. ### Error output. ```pytb; File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate; raise AttributeError(""Can only use .str accessor with string values!""); AttributeError: Can only use .str accessor with string values!; ```. ### Versions. <details>. ```; >>> scanpy.logging.print_versions(); -----; anndata 0.8.0; scanpy 1.9.3; -----; CIForm NA; PIL 9.1.0; astunparse 1.6.3; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.11.0; igraph 0.10.4; joblib 1.2.0; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.3.1; nt NA; numba 0.56.4; numpy 1.23.5; opt_einsum v3.3.0; packaging 21.3; pandas 2.2.3; plotly 5.13.1; psutil 5.9.4; pyparsing 3.0.9; pytz 2022.1; scipy 1.10.0; session_info 1.0.0; six 1.16.0; sklearn 1.2.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 1.13.1+cpu; tqdm 4.64.1; typing_extensions NA; yaml 6.0; zoneinfo NA; zope NA; -----; Python 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; -----; Session information updated at 2024",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261:329,down,downloaded,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261,3,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi!. I am new to scanpy and I am facing some trouble reading my data in an appropriate way. I noticed that anndata objects in memory require roughly 4x the space they require on disk, so working with large datasets (>50GB on disk) is prohibitive in most scenarios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:947,mask,mask,947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['mask'],['mask']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, I am running the Scrublet function to remove doublets.; the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540.; [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python; # 240520鳞癌，不用; # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # 240520 去掉癌旁，只用癌; lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'); lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'); # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:830,error,error,830,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, I recently started using scanpy and python. I am running into the following error. Any help is much appreciated. ![image](https://github.com/user-attachments/assets/76e1c619-a764-45ac-a475-4bad342854b1). ### Minimal code sample. ```python; sc.pl.umap(adata,color =[""leiden""]); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.6; -----; PIL 9.5.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; bottleneck 1.3.6; cffi 1.15.0; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.5.1; decorator 4.4.2; defusedxml 0.7.1; dill 0.3.8; dot_parser NA; entrypoints 0.4; executing 0.8.3; fasteners 0.18; get_annotations NA; google NA; h5py 3.8.0; igraph 0.10.8; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.4.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; msgpack 1.0.5; natsort 8.4.0; numba 0.59.0; numcodecs 0.12.1; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.23.0; prompt_toolkit 3.0.20; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynvml NA; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.11.2; seaborn 0.13.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.3.2; sphinxcontrib NA; stack_data 0.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215:369,error,error,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I am using Rstudio as the only means available by my institution through slurm to do single cell analysis. and the plots using scanpy are messed up. i tried different parameters. I am not sure if this issue is related to rstudio or i am doing something wrong. . ### Minimal code sample. ```python; sc.pl.umap(; sample,; color=[""supercluster_term""],; legend_loc=""right margin"", # or choose the location you prefer; legend_fontsize=5, # Adjust font size if needed; frameon=True,; title=[""Provided cell type""],; ); ```. ### Error output. _No response_. ### Versions. -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; absl NA; array_api_compat 1.4.1; attr 23.2.0; chex 0.1.85; contextlib2 NA; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; docrep 0.3.2; etils 1.5.2; exceptiongroup 1.2.0; flax 0.8.1; fsspec 2024.2.0; h5py 3.10.0; igraph 0.10.8; importlib_resources NA; jax 0.4.25; jaxlib 0.4.25; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; lightning 2.1.4; lightning_utilities 0.10.1; llvmlite 0.42.0; louvain 0.8.1; markupsafe 2.1.5; matplotlib 3.8.3; ml_collections NA; ml_dtypes 0.3.2; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.8; mudata 0.2.3; multipledispatch 0.6.0; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; numpyro 0.14.0; opt_einsum v3.3.0; optax 0.2.1; packaging 23.2; pandas 2.2.1; pkg_resources NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.1.2; pyro 1.9.0; pytz 2024.1; rich NA; rpycall NA; rpytools NA; scipy 1.12.0; scvi 1.1.2; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; skmisc 0.3.1; sympy 1.12; texttable 1.7.0; threadpoolctl 3.3.0; toolz 0.12.1; torch 2.2.1+cu121; torchgen NA; torchmetrics 1.3.1; tqdm 4.66.2; typing_extensions NA; umap ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2955:326,avail,available,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2955,2,"['Error', 'avail']","['Error', 'available']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have a bunch of matrix.mtx, barcode.tsv and genes.tsv. When I want to read in the files with:; `data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True)`. I get the following error:; `FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'`. The thing is that the file exist here:; ![kép](https://github.com/user-attachments/assets/a3ee8f51-833d-4adb-ab9f-f6ff5b19387f). I have changed the *genes.tsv.gz file's name to *features.tsv.gz but still got the same error. Here is the full error log:; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], [line 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/Pip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:512,error,error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have an AnnData object, and I try to slice it with . `adata[adata.obs.Phenotype == 'CON']`. But I get an error: . ```; AssertionError: Don’t call _normalize_index with non-categorical/string names; ```. Curiously, `adata.obs[adata.obs.Phenotype == 'CON']` works just fine. . I verified that both `adata.obs.index` and `(adata.obs.Phenotype == 'CON').index` are both regular Int64Indexes. . What might be going wrong? . I noticed a similar issue in the past (xref https://github.com/scverse/scanpy/issues/747) but the solutions listed didn't work for me. . ### Minimal code sample. ```python; `adata[adata.obs.Phenotype == 'CON']`; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy version 1.9.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2979:396,error,error,396,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2979,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I tried to run the code below on a Windows laptop and received the error (also below). I've tried uninstalling and reinstalling igraph, leidenalg, and scanpy. I tried running the code with flavor=""leidenalg"" and got the same/basically the same error. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"", ; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[159], line 1; ----> 1 sc.tl.leiden( #So leidan is identifying and coloring clusters for you, but not changing the shape of the graph.; 2 adata, #lets just pretend that I understand what each of those things mean; 3 resolution=0.9,; 4 random_state=0,; 5 flavor=""igraph"", #did pip install leidenalg and started receiving the no flavor keyword error; https://github.com/scverse/scanpy/issues/350 indicates this is to be expected, but https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.leiden.html indicates it should have it ; 6 n_iterations=2,; 7 directed=False,; 8 ). File ~\miniconda3\Lib\site-packages\scanpy\tools\_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 msg = 'In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph\'s implementation.'; 143 _utils.warn_once(msg, FutureWarning, stacklevel=3); --> 144 except ImportError:; 145 raise ImportError(; 146 ""Please install the leiden algorithm: `conda i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I was running a basic workflow with 3k PBMC and at the step sc.pl.stacked_violin got Attribute error below. ### Minimal code sample. ```python; sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90); ```. ### Error output. ```pytb; --------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[51], line 1; ----> 1 sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90);. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_stacked_violin.py:825, in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 823 if return_fig:; 824 return vp; --> 825 vp.make_figure(); 826 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 827 show = settings.autoshow if show is None else show. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/scanpy/plotting/_baseplot_class.py:792, in BasePlot.make_figure(self); 789 return_ax_dict[""gene_gr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3140:384,error,error,384,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. In #3048 we started raising errors for functions that don’t support backed mode, but seems like a tutorial used `dendrogram` in backed mode: https://scverse-tutorials.readthedocs.io/en/latest/notebooks/scverse_data_backed.html. ![grafik](https://github.com/user-attachments/assets/0317c570-0af8-4c5e-8f3f-7831335763af). That was probably a mistake and the data just got loaded to memory, but since `dendrogram` can be reimplemented using `.get.aggregate`, we should do that!. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.filename = ""test.h5ad""; sc.pl.dotplot(adata, [""FCN1""], groupby=""index"", dendrogram=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.pl.dotplot(mdata[""rna""], var_names=[""CD2""], groupby=""leiden"", figsize=(10, 3), dendrogram=True, swap_axes=True). File ~/.local/share/hatch/env/virtual/scverse-tutorials/_YRPCeuX/basic-scrna/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/.local/share/hatch/env/virtual/scverse-tutorials/_YRPCeuX/basic-scrna/lib/python3.12/site-packages/scanpy/plotting/_dotplot.py:1046, in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3199:317,error,errors,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3199,2,"['Error', 'error']","['Error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python; sc.datasets.pbmc3k(); pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'); pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'); pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")); sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AxisError Traceback (most recent call last); Cell In[8], line 3; 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'); 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")); ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 312 if isinstance(qc_vars, str):; 313 qc_vars = [qc_vars]; --> 315 obs_metrics = describe_obs(; 316 adata,; 317 expr_type=expr_type,; 318 var_type=var_type,; 319 qc_vars=qc_vars,; 320 percent_top=percent_top,; 321 inplace=inplace,; 322 X=X,; 323 log1p=log1p,; 324 ); 325 var_metrics = describe_var(; 326 adata,; 327 expr_type=expr_type,; (...); 331 log1p=log1p,; 332 ); 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, lay",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3004:827,Error,Error,827,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. On import, I'm getting:; `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python; import scanpy; ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3071:440,Error,Error,440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. On version 1.10.1 & manuals for v.1.10.x:. [If None, mpl.rcParams[""axes.prop_cycle""] is used unless the categorical variable already has colors stored in adata.uns[""{var}_colors""]. If provided, values of adata.uns[""{var}_colors""] will be set.](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pl.embedding.html). ![image](https://github.com/user-attachments/assets/9d6f328b-3afb-41c5-92ca-0a75bec6ce2c). ### Minimal code sample. Here I have an anndata with a categorical obs variable and having {var}_colors in uns; still, mpl.rcParams[""axes.prop_cycle""] is used:. ```python; ## the type of data.obs['study']: category. Name: study, Length: 48256, dtype: category; Categories (2, object): ['NatGenet', 'HongProj']. data.uns['study_colors']; -> array(['#ff7f0e', '#17becf'], dtype=object); sc.pl.embeddings(data, 'anyembedding', 'study'); ->; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy==1.10.1 anndata==0.8.0 umap==0.5.5 numpy==1.26.3 scipy==1.11.4 pandas==1.5.3 scikit-learn==1.4.0 statsmodels==0.14.0 igraph==0.10.3 pynndescent==0.5.8; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3193:1152,Error,Error,1152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3193,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Python compiler of Pandas is giving Future Warning that in line:; disp_grouped = df.groupby(""mean_bin"")[""dispersions""] ; at \preprocessing\_highly_variable_genes.py:226; Gives this warning:; ""The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning."". ### Minimal code sample. ```python; disp_grouped = df.groupby(""mean_bin"", observed=False)[""dispersions""]; ```. ### Error output. ```pytb; \scanpy\preprocessing\_highly_variable_genes.py:226: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.; ```. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.9.0; hypergeom_ufunc NA; igraph 0.11.4; invgauss_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.0; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; nt NA; numba 0.59.0; numpy 1.26.4; packaging 23.1; pandas 2.2.1; psutil 5.9.8; pyparsing 3.0.9; pythoncom NA; pytz 2023.3.post1; pywin32_system32 NA; pywintypes NA; scipy 1.11.4; session_info 1.0.0; setuptools 68.2.2; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; texttable 1.7.0; threadpoolctl 2.2.0; torch 2.2.1; torchgen NA; tqdm 4.65.0; typing_extensions NA; wcwidth 0.2.13; win32api NA; win32com NA; yaml ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2967:819,Error,Error,819,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2967,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python; pip install zappy; pytest scanpy/tests/test_preprocessing_distributed.py; ```. ### Error output. ```pytb; ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):; > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_normalization.py:240: in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; scanpy/preprocessing/_normalization.py:49: in _normalize_data; return axis_mul_or_truediv(; /usr/lib/python3.12/functools.py:909: in wrapper;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3087:606,Error,Error,606,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Thanks a lot, I am new to scanpy. https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html; why scale is not here,which is needed in traditional sc-rna seq. ```; sc.pp.normalize_total(adata, inplace=True); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=""seurat"", n_top_genes=2000); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ); ```. ### Minimal code sample. ```python; sc.pp.normalize_total(adata, inplace=True); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=""seurat"", n_top_genes=2000); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ); ```; ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.3; scanpy 1.9.8; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963:1111,Error,Error,1111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Thanks a lot; when I read docs in ; https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering-2017.html (legacy, used pp.scale); https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html#nearest-neighbor-graph-constuction-and-visualization ( not used pp.scale). so does it mean in scanpy, not matther single-cell rna-seq or spatial data, both not need the pp.scale. ### Minimal code sample. ```python; no code; ```. ### Error output. _No response_. ### Versions. <details>. ```; [; <img width=""968"" alt=""Snipaste_2024-06-04_22-02-31"" src=""https://github.com/scverse/scanpy/assets/50854682/6c232732-bbc9-47b2-8f44-5ccbe63cd891"">; ](url); ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3095:734,Error,Error,734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python; sc.tl.umap(adata, maxiter=50); ```. ### Error output. ```pytb; computing UMAP; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies ; [0.01180801 0.01616286 0.01491355]; not reaching the requested tolerance 1e-08.; Use iteration 19 instead with accuracy ; 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies ; [0.0114102 0.01466 0.01555016]; not reaching the requested tolerance 1e-08.; eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (1:07:21); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0; prompt_toolkit 3.0.38; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3139:469,Error,Error,469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:363,error,error,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,7,"['down', 'error']","['down', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I use `sc.pl.dotplot` to show the markers betwween different clusters, in tutorials it shows the dendrogram but in prcatice it not. This caused me a great obstacle in observing. How should I slove it? Thanks!; ![output](https://github.com/user-attachments/assets/c980ed28-0192-4956-bc2a-4a75a32d126f). ### Minimal code sample. ```python; sc.tl.dendrogram(adata, groupby='leiden', key_added='dendrogram_leiden'); #%%; sc.pl.dotplot(adata, marker_genes, groupby=""leiden"", standard_scale=""var"", dendrogram='dendrogram_leiden'); #%%; ```. ### Error output. _No response_. ### Versions. <details>. ```; scanpy 1.10.2; python 3.12.4; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3201:833,Error,Error,833,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When running highly_variable_genes with batch_key input, and the data contains batch with only one sample (due to earlier filtering) the computation failed, returning ""division by zero"" error. ; The expected behavior is to ignore this batch (a single sample). ### Minimal code sample. ```python; #Create dummy anndata with batch key. Batch 3 contains 1 sample.; test_ad = ad.AnnData(X=np.random.randn(10,100), ; obs=pd.DataFrame({'batch':pd.Categorical([1,1,1,1,2,2,2,2,2,3])})); #This works fine; sc.pp.highly_variable_genes(test_ad). #This returns division by zero error; #sc.pp.highly_variable_genes(test_ad, batch_key='batch'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ZeroDivisionError Traceback (most recent call last); Cell In[41], line 11; 9 with warnings.catch_warnings(): #ignore future_warning in groupby; 10 warnings.simplefilter(action='ignore', category=FutureWarning); ---> 11 sc.pp.highly_variable_genes(adata_ct, batch_key='sample_id', n_top_genes=hvg_count); 12 sc.pl.highly_variable_genes(adata_ct). File ~/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:469, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 465 filt = filter_genes(adata_subset, min_cells=1, inplace=False)[0]; 467 adata_subset = adata_subset[:, filt]; --> 469 hvg = _highly_variable_genes_single_batch(; 470 adata_subset,; 471 layer=layer,; 472 min_disp=min_disp,; 473 max_disp=max_disp,; 474 min_mean=min_mean,; 475 max_mean=max_mean,; 476 n_top_genes=n_top_genes,; 477 n_bins=n_bins,; 478 flavor=flavor,; 479 ); 481 # ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103:475,error,error,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When running sc.pp.neighbors, I get the following error:. `api_export.__init__() got an unexpected keyword argument 'metaclass'`. ### Minimal code sample. ```python; sc.pp.neighbors(adata); ```. ### Error output. ```pytb; `api_export.__init__() got an unexpected keyword argument 'metaclass'`; ```. ### Versions. Latest version of scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3143:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. ```; /opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/ehrapy/plot/_scanpy_pl_api.py:606: in <module>; scale: Literal[""area"", ""count"", ""width""] = StackedViolin.DEFAULT_SCALE,; E AttributeError: type object 'StackedViolin' has no attribute 'DEFAULT_SCALE'; ```. ### Minimal code sample. ```python; `import scanpy as sc`; ```. ### Error output. _No response_. ### Versions. Latest main -> pre-release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2899:636,Error,Error,636,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2899,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. `sc.tl.dpt` was successfully done. But when I want to plot the result of dpt,the error comes out. ### Minimal code sample. ```python; sc.tl.dpt(a1,n_branchings=2); sc.pl.dpt_groups_pseudotime(a1); sc.pl.dpt_timeseries(a1); ```. ### Error output. Error in dpt_timeseries:. ```pytb; WARNING: Plotting more than 100 genes might take some while, consider selecting only highly variable genes, for example.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a real number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); Cell In[85], line 1; ----> 1 sc.pl.dpt_timeseries(a1). File D:\anaconda\Lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File D:\anaconda\Lib\site-packages\scanpy\plotting\_tools\__init__.py:245, in dpt_timeseries(adata, color_map, show, save, as_heatmap, marker); 242 # only if number of genes is not too high; 243 if as_heatmap:; 244 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 245 timeseries_as_heatmap(; 246 adata.X[adata.obs[""dpt_order_indices""].values],; 247 var_names=adata.var_names,; 248 highlights_x=adata.uns[""dpt_changepoints""],; 249 color_map=color_map,; 250 ); 251 else:; 252 # plot time series as gene expression vs time; 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:370,error,error,370,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,3,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. i have a trouble when i run neighbors. ### Minimal code sample. ```python; sc.pp.neighbors(adata); ```. ### Error output. ```pytb; computing neighbors; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'; Exception ignored in: 'scipy.sparse.csgraph._traversal._connected_components_undirected'; Traceback (most recent call last):; File ""/data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/scanpy/neighbors/__init__.py"", line 406, in __init__; self._connected_components = connected_components(self._connectivities); ValueError: Buffer dtype mismatch, expected 'ITYPE_t' but got 'long'; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:29:05); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141:397,Error,Error,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669:422,error,error-in-highly-variable-gene-selection,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669,3,"['Error', 'error']","['Error', 'error', 'error-in-highly-variable-gene-selection']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. After upgrading annData to 0.10.4 I tried to read in some Visium data with read_10x_mtx(); The resulting table only had one variable (/gene/column), and had it over and over again. ### Minimal code sample. ```python; S = scanpy.read_10x_mtx(mydata); ```. ### Error output. ```pytb; /home/lhw/pkgs/mambaforge/envs/env2/lib/python3.11/site-packages/anndata/_core/anndata.py:1908: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""). In [6]: S.var_names; Out[6]: ; Index(['NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L',; 'NOC2L', 'NOC2L',; ...; 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L', 'NOC2L',; 'NOC2L', 'NOC2L'],; dtype='object', length=18085). To test, I ran in another environment with scanpy 1.9.6 but annData 0.10.3.; Below are the results:. In [4]: S = scanpy.read_10x_mtx(mydata). In [5]: S.var_names; Out[5]: ; Index(['SAMD11', 'NOC2L', 'KLHL17', 'PLEKHN1', 'PERM1', 'HES4', 'ISG15',; 'AGRN', 'RNF223', 'C1orf159',; ...; 'MT-ND2', 'MT-CO2', 'MT-ATP6', 'MT-CO3', 'MT-ND3', 'MT-ND4L', 'MT-ND4',; 'MT-ND5', 'MT-ND6', 'MT-CYB'],; dtype='object', length=18085); ```. ### Versions; Scanpy 1.9.6; annData 0.10.3 works, annData 0.10.4 does not; <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2825:550,Error,Error,550,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2825,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2675:407,error,error,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello,. With the new scanpy version `1.9.7` I'm not able to plot embeddings such as UMAPs when using numpy `1.23` (it's probably also true for other ""old"" versions of numpy). Note that I can't update numpy to a newer version because of other packages I'm using, but `1.23` is more recent that what scanpy requires anyway (i.e., `numpy>=1.17.0`). For instance, the `spatialdata` library requires `numpy<=1.23.4` because of `xarray-spatial`: thus, it seems that the latest version of `scanpy` is not compatible with `spatialdata` (cc @LucaMarconato for information). The error seems to be due to this commit in `_validate_palette`: https://github.com/scverse/scanpy/commit/d1fe8da28ab4865b6c2b3d9cd151a8186f148844 (@flying-sheep). ### Minimal code sample. ```python; # Just plotting a dummy UMAP. import anndata; import pandas as pd; import numpy as np; import scanpy as sc. n_obs = 10. adata = anndata.AnnData(; X=np.random.randint(0, 5, size=(n_obs, 8)),; obs=pd.DataFrame({; ""cell_type"": np.random.choice([""A"", ""B"", ""C""], size=n_obs)},; index=[str(i) for i in range(n_obs)]; ),; ). sc.pp.neighbors(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""cell_type""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); Cell In[6], line 1; ----> 1 sc.pl.umap(adata, color=""cell_type""). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:674, in umap(adata, **kwargs); 615 @_wraps_plot_scatter; 616 @_doc_params(; 617 adata_color_etc=doc_adata_color_etc,; (...); 621 ); 622 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:; 623 """"""\; 624 Scatter plot in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830:860,error,error,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi all. I was having issues generating rank gene groups. The error is as below. When I used the ""Manuscript_Identity"" group, I got such error message, but when I used another group ""CellType_Category"", it worked. These two groups are in the same type. Could you tell me how to fix it?; Look forward to your response, thanks a lot!. ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata_sc, groupby=""Manuscript_Identity"", use_raw=False). adata_sc.obs['CellType_Category'].cat.categories; Index(['Endothelial', 'Epithelial', 'Lymphoid', 'Multiplet', 'Myeloid',; 'Stromal'],; dtype='object'); adata_sc.obs['Manuscript_Identity'].cat.categories; Index(['ATI', 'ATII', 'Aberrant_Basaloid', 'B', 'B_Plasma', 'Basal',; 'Ciliated', 'Club', 'DC_Langerhans', 'DC_Mature', 'Fibroblast',; 'Goblet', 'ILC_A', 'ILC_B', 'Ionocyte', 'Lymphatic', 'Macrophage',; 'Macrophage_Alveolar', 'Mast', 'Mesothelial', 'Multiplet',; 'Myofibroblast', 'NK', 'PNEC', 'Pericyte', 'SMC', 'T', 'T_Cytotoxic',; 'T_Regulatory', 'VE_Arterial', 'VE_Capillary_A', 'VE_Capillary_B',; 'VE_Peribronchial', 'VE_Venous', 'cDC1', 'cDC2', 'cMonocyte',; 'ncMonocyte', 'pDC'],; dtype='object'); ```. ### Error output. ```pytb; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 592, in rank_genes_groups; test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 106, in __i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:352,error,error,352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:458,error,error,458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I was trying to extract gene expression mean values per Subject, so I have a dataframe with genes in columns, subjects in rows, and the mean values of the expression. . To obtain the mean values for each Subject for the selected genes, I ran the following command:; `adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0))`. Having a look at the expression of genes in a specific Subject, it looks like this:. ![image](https://github.com/scverse/scanpy/assets/94078098/f9d7443c-3837-4054-b930-4864d07f9434). However, the mean expression value for NTM is 0. and for CRYAB is 1.56, what it doesn't make sense with the heatmap plot. Am I doing wrong in the extraction of mean values?. Thanks!. ### Minimal code sample. ```python; adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0)); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2740:1149,Error,Error,1149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2740,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am following the tutorial but everytime I try to run a violin plot the kernel crashes, this doesnt happen with other seaborn graphs. I have tried updating packeges, changing environment, etc, etc & nothing works any help would be great !!. ![image](https://github.com/scverse/scanpy/assets/127498480/b5cc12b1-00af-4919-abd0-7ea99b72cade). ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd; import numpy as np; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(; 'data/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`; adata; sc.pl.highest_expr_genes(adata, n_top=20, ); sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0-4, multi_panel=True); ```. ### Error output. ```pytb; Kernel Restarting; The kernel for Tests/scanpytutorial/Untitled.ipynb appears to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840:769,error,errors,769,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840,1,['error'],['errors']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:570,Error,Error,570,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:587,error,error,587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: ; upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names; result = pd.DataFrame(; {group + '_' + key: results[key][group]; for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []; for i in groups:; group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]; group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}); group['group'] = i; de_results.append(group); de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True); de_results; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2628:1719,Error,Error,1719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I expect `<code/>`, not `<cite/>`. ![grafik](https://github.com/scverse/scanpy/assets/291575/0874f428-c7a6-495f-9451-502afdc28c13). It has nothing to do with our custom the following, I checked:. 1. scanpydoc; 2. our custom `cite` extension. I assume it’s MyST breaking `default_role`. ### Minimal code sample. ```markdown; Params; ------; foo; 	x `y` z; ```. ### Error output. ```html; <dt>foo; <dd>x <cite>y</cite> z; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2829:655,Error,Error,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2829,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:720,error,error,720,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2564:418,error,error,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564,3,"['Error', 'down', 'error']","['Error', 'downgrade', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just copied the code of official example, and changed the path to my own documents. But it seems that it doesn't work. One folder of the total containing ""barcodes"", ""features"" and ""matrix"" has been attached below and the entire raw data comes from here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE139324. ### Minimal code sample. ```python; import scanpy as sc. path = r'RAW'; adata = sc.read_10x_mtx('RAW/HD PBMC_1/',var_names='gene_symbols', cache=True) ; adata.var_names_make_unique(); sc.pp.filter_cells(adata, min_genes=200) ; sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; IndexError: index (2444) out of range; ```. ### Versions. <details>. ```. ```. </details>. [HD PBMC_1.zip](https://github.com/scverse/scanpy/files/13404294/HD.PBMC_1.zip); ![2](https://github.com/scverse/scanpy/assets/147734739/0db8909d-84e4-41c5-8beb-09480d7adc3a)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2759:886,Error,Error,886,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2759,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2542:327,error,error,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I'm encountering an error when running the sc.pl.rank_genes_groups_heatmap function in the scanpy package. The error message is ""Linkage 'Z' contains negative distances."" What could be causing this error and how can I fix it?. ### Minimal code sample. ```python; sc.pl.rank_genes_groups_heatmap(adata, n_genes=10, groupby='clusters',show_gene_labels=True,save='cluster.markers.heatmap.svg'); ```. ### Error output. ```pytb; sc.pl.rank_genes_groups_heatmap(adata, n_genes=10, groupby=cluster,show_gene_labels=True,save=(id+'_processed.top10.cluster.markers.heatmap.svg')); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 673, in rank_genes_groups_heatmap; return _rank_genes_groups_plot(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 592, in _rank_genes_groups_plot; return heatmap(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1087, in heatmap; dendro_data = _reorder_categories_after_dendrogram(; File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 2134, in _reorder_categories_after_dendrogram; key = _get_dendrogram_key(adata, dendrogram, groupby); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 2236, in _get_dendrogram_key; dendrogram(adata, groupby, key_added=dendrogram_key); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py"", line 143, in dendrogram; dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True); File ""/opt/conda/envs/st/lib/python3.8/site-packages/scipy/cluster/hierarchy.py"", line 3301, in dendrogram; is_valid_linkage(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804:311,error,error,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804,4,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I'm trying to use `sc.pl.spatial` with the dataset that is available on 10X Visium with the sample ID `CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma`. I can open and do some basic QC just fine, but when I try to plot, I get the error `TypeError: can't multiply sequence by non-int of type 'float`. ### Minimal code sample. ```python; import scanpy as sc; import anndata as an; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as plt; import seaborn as sns; import scanorama. sc.set_figure_params(facecolor=""white"", figsize=(8, 8)); sc.settings.verbosity = 3. # Loading dataset; adata = sc.read_visium(; path=r""\external"",; count_file=""CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5"",; load_images=True,; source_image_path=r""\spatial"",; ). adata.var_names_make_unique(). # Quality control; adata.var[""mito""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(; adata, qc_vars=[""mito""], percent_top=None, log1p=False, inplace=True; ); sc.pl.spatial(adata); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""\scanpy\plotting\_tools\scatterplots.py"", line 1002, in spatial; File ""\plotting\_tools\scatterplots.py"", line 391, in embedding; # if user did not set alpha, set alpha to 0.7; File ""\scanpy\plotting\_utils.py"", line 1107, in circles; if scale_factor != 1.0:; TypeError: can't multiply sequence by non-int of type 'float'; ```; The json file on the spatial folder with the scale factors is as follows:. ```json; {; ""regist_target_img_scalef"": 0.16836435,; ""tissue_hires_scalef"": 0.056121446,; ""tissue_lowres_scalef"": 0.016836435,; ""fiducial_diamet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778:350,avail,available,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778,2,"['avail', 'error']","['available', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2570:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:427,avail,available,427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,2,"['Error', 'avail']","['Error', 'available']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In scanpy version 1.9.3. ### Minimal code sample. ```python; adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2565:602,Error,Error,602,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:418,Error,Error,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:331,error,error,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2730:498,error,error,498,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730,1,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2747:594,Error,Error,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The `read_10x_mtx()` function does not work due to the update of the anndata package to 0.10.4 (January 14, 2024); (?Error reading the file *features.tsv.gz*). The launch was carried out on the following data: ; https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5733023. You can also download files using my google drive:; https://drive.google.com/drive/folders/1p6ilbsJX_cYZb4HG0OSbLHAwQObqmncW?usp=sharing. # **My actions**:. 1) I have installed the latest version of `scanpy=1.9.6` using conda:; ```console; $ conda --version; conda 23.10.0; $ conda install scanpy; # Channels:; # - conda-forge; # - bioconda; # - defaults; # Platform: linux-64. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.4 pyhd8ed1ab_0 conda-forge; array-api-compat 1.4 pyhd8ed1ab_0 conda-forge; brotli 1.1.0 hd590300_1 conda-forge; brotli-bin 1.1.0 hd590300_1 conda-forge; bzip2 1.0.8 hd590300_5 conda-forge; c-ares 1.25.0 hd590300_0 conda-forge; ca-certificates 2023.11.17 hbcca054_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.11.17 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; contourpy 1.2.0 py311h9547e67_0 conda-forge; cycler 0.12.1 pyhd8ed1ab_0 conda-forge; exceptiongroup 1.2.0 pyhd8ed1ab_2 conda-forge; fonttools 4.47.2 py311h459d7ec_0 conda-forge; freetype 2.12.1 h267a509_2 conda-forge; get-annotations 0.1.2 pyhd8ed1ab_0 conda-forge; h5py 3.10.0 nompi_py311hebc2b07_101 conda-forge; hdf5 1.14.3 nompi_h4f84152_100 conda-forge; icu 73.2 h59595ed_0 conda-forge; joblib 1.3.2 pyhd8ed1ab_0 conda-forge; keyutils 1.6.1 h166bdaf_0 conda-forge; kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:408,Error,Error,408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,2,"['Error', 'down']","['Error', 'download']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:333,Error,Error,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,4,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I install scanpy==1.9.6 with pip (anndata==0.10.4), something wrong and adata.X.nnz is 0.; I changed the version of anndata to 0.9.2, it works normal. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(my_sample, # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=False) # write a cache file for faster subsequent reading; # sc.pl.highest_expr_genes(adata, n_top=20, ); adata.X.nnz; ```. ### Error output. _No response_. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.5; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; bottleneck 1.3.5; cffi 1.16.0; comm 0.1.2; cycler 0.12.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 4.4.2; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; hurry NA; ipykernel 6.25.0; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.7; numpy 1.26.0; packaging 23.2; pandas 1.5.3; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydev",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2822:584,error,errors,584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2822,1,['error'],['errors']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization ; After 1 runs, maximum modularity is Q = 0.794615; After 16 runs, maximum modularity is Q = 0.796318; Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python; from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)); phenograph = external.tl.phenograph ; cluster_ph = phenograph(df.values, k=60, method='leiden')[0]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.4; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; functions NA; google NA; h5py 3.9.0; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.3.2; jupyter_server 1.18.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1rc1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; plotly 5.14.1; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.11.2; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2653:874,Error,Error,874,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to produce a violin plot using `pl.rank_genes_groups_violin()` of the ranked genes and passing `gene_symbols=""gene_symbols""` I get a `KeyError`. However `pl.rank_genes_groups()` works fine with the option `gene_symbols=""gene_symbols""` and the same `adata` object. ### Minimal code sample. ```python; sc.pl.rank_genes_groups_violin(; adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; ); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[258], line 1; ----> 1 sc.pl.rank_genes_groups_violin(; 2 adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; 3 ). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/plotting/_tools/__init__.py:1157, in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 1155 if isinstance(_gene_names, np.ndarray):; 1156 _gene_names = _gene_names.tolist(); -> 1157 df = obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols); 1158 new_gene_names = df.columns; 1159 df['hue'] = adata.obs[groups_key].astype(str).values. File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/get/get.py:272, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 269 else:; 270 alias_index = None; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,; 275 ""obs"",; 276 keys,; 277 alias_index=alias_index,; 278 use_raw=use_raw,; 279 ); 281 # Make df; 282 df = pd.DataFrame(index=adata.obs_names). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2540:728,Error,Error,728,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2540,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using sc.pl.highest_expr_genes, seaborn throws a FutureWarning. Specifically:. envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead. ### Minimal code sample. ```python; sc.pl.highest_expr_genes(adata, n_top=20, ); ```. ### Error output. ```pytb; envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; asttokens NA; backcall 0.2.0; comm 0.1.2; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 0.8.3; h5py 3.10.0; ipykernel 6.25.0; jedi 0.18.1; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 23.1; pandas 2.1.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.1.1; pytz 2023.3.post1; scipy 1.11.3; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; stack_data 0.2.0; statsmodels 0.14.0; threadpoolctl 3.2.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.7.1; umap 0.5.4; wcwidth 0.2.5; zmq 25.1.0; -----; IPython 8.15.0; jupyter_client 8.6.0; jupyter_core 5.5.0; ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2755:672,Error,Error,672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2755,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ﻿﻿; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:394,error,error,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. hello, why dose my code ""sc.pp.filter_genes(adata, min_cells=3)"" error after running ""sc.pp.filter_cells(adata, min_genes=200)""?. ### Minimal code sample. ```python; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; ERROR:. /root/anaconda3/envs/c2s/lib/python3.11/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; /root/anaconda3/envs/c2s/lib/python3.11/site-packages/anndata/_core/views.py:79: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; ____________________________________________________________________________________________________; AND the process is out of memory. [17371499.406473] Out of memory: Killed process 465550 (python) total-vm:132596812kB, anon-rss:129055148kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:253640kB oom_score_adj:0; ```. ### Versions. <details>; scanpy 1.9.5; python 3.11.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2754:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure.; The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error; Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,; then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`; It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python; adata: any anndata; markers: gene list include in var_names; group: obs key; celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(; 	adata, markers, group, show=False, swap_axes=True,; 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,; ); ```. ### Error output. ```pytb; K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:856,Error,Error,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python; See `test_scrublet_data` under `anndata_dev`; ```. ### Error output. ```pytb; E AssertionError: ; E Not equal to tolerance rtol=1e-15, atol=1e-15; E ; E Mismatched elements: 1 / 200 (0.5%); E Max absolute difference: 0.0126501664; E Max relative difference: 0.1823112224; E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,; E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,; E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,...; E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,; E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,; E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,...; ```. ### Versions. <details>. ```; Package Version; ----------------- -------------------------; anndata 0.11.0.dev114+g105f354; annoy 1.17.3; scipy 1.13.0; scprep 1.1.0; seaborn 0.13.2; session-info 1.0.0; setuptools 69.5.1; setuptools-scm 8.1.0; six 1.16.0; sniffio 1.3.1; sortedcontainers 2.4.0; sparse 0.16.0a6; statsmodels 0.14.2; stdlib-list 0.10.0; tasklogger 1.2.0; tblib 3.0.0; texttable 1.7.0; textual 0.60.1; threadpoolctl 3.5.0; tifffile 2024.5.10; toolz 0.12.1; tornado 6.4; tqdm 4.66.4; typing-extensions 4.12.0rc1; tzdata 2024.1; uc-micro-py 1.0.3; umap-learn 0.5.6; urllib3 2.2.1; uv 0.1.44; virtualenv 20.26.2; wrapt 1.16.0; zarr 2.18.1; zi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3068:577,error,errors,577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068,3,"['Error', 'error', 'toler']","['Error', 'errors', 'tolerance']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Function Rank_genes_groups() does not return a figure -> returns None type; Cannot get Figure via plt.gcf(), plt.gca(). Potential Fix:; https://github.com/scverse/scanpy/blob/main/src/scanpy/plotting/_tools/__init__.py; Line 485: cann be extended to the following as in other functions below:; ```; savefig_or_show(f""{key}_"", show=show, save=save); show = settings.autoshow if show is None else show; if show:; return None; return ax; ```. ### Minimal code sample. ```python; fig = sc.pl.rank_genes_groups(adata, show=False); type(fig); #NoneType; plt.gca() -> empty axes; plt.gcf() -> empty figure; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.8; scanpy 1.10.2; -----; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3205:898,Error,Error,898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. HVG can produce more than the number of genes asked for as highly variable. This occurs on these two datasets:. ```; wget https://datasets.cellxgene.cziscience.com/e00ab1f4-28cd-497d-b889-94d45840f423.h5ad; ```. ### Minimal code sample. ```python; import scanpy as sc. adata1 = sc.read('e00ab1f4-28cd-497d-b889-94d45840f423.h5ad'). sc.pp.normalize_total(adata1, target_sum=1e4). sc.pp.log1p(adata1). n_top_gene = 10000; sc.pp.highly_variable_genes(adata1, n_top_genes = n_top_gene). hvg_system1 = set(adata1.var[adata1.var['highly_variable']].index); assert len(hvg_system1) == n_top_gene, f""found {len(hvg_system1)} instead of {n_top_gene}"". ```. ### Error output. ```pytb; AssertionError Traceback (most recent call last); Cell In[12], line 1; ----> 1 assert len(hvg_system1) == n_top_gene, f""found {len(hvg_system1)} instead of {n_top_gene}"". AssertionError: found 13355 instead of 10000; ```. ### Versions. <details>. ```; import scanpy; scanpy.logging.print_versions(); -----; anndata 0.10.8; scanpy 1.10.0rc2.dev85+gb918a23e; -----; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157:941,Error,Error,941,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi,. Thanks a lot for helping!; I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""); AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks!. Best,; B. ### Minimal code sample. ```python; sc.pp.scrublet(adata, batch_key=""lib_prep""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); /tmp/ipykernel_54187/3500521297.py in <module>; ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; backcall 0.2.0; cffi 1.14.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; exceptiongroup 1.2.0; get_annotations NA; google NA; h5py 3.10.0; importlib_resources NA; ipykernel 6.2.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.2; matplotlib_inline NA; mpl_toolkits NA; mudata 0.2.3; muon 0.1.6; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 21.0; pandas 2.1.3; parso 0.8.2; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.11; pyparsing 2.4.7; pytz 2023.3.post1; scipy 1.11.4; scrublet NA; seaborn 0.12.2; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.3.2; statsmodels 0.14.0; storemagic NA; threadpoolctl 3.2.0; torch 1.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3026:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi,; since statsmodels 0.14, perfect separation no longer raises an error but a warning (see [function doc here](https://www.statsmodels.org/stable/generated/statsmodels.genmod.generalized_linear_model.GLM.html#statsmodels-genmod-generalized-linear-model-glm)). Because scanpy currently only catches the now-outdated error (instead of catch the warning), users may see many warnings from `regress_out` when no perfect separation exists (see usage in scanpy [here](https://github.com/scverse/scanpy/blob/main/src/scanpy/preprocessing/_simple.py#L759-L761)). It seems to follow on the heels of [this issue](https://github.com/statsmodels/statsmodels/issues/2680) in statsmodels. I propose to implement that the warning is caught just as the errors were being caught.; Cheers,; Jesko. ### Minimal code sample. ```python; import anndata as ad; import scanpy as sc; import numpy as np; import pandas as pd; adata = ad.AnnData(np.array([[0,0,1,1]]).T, obs=pd.DataFrame({""a"":[0,0,1,1]})); sc.pp.regress_out(adata, ""a""); ```. ### Error output. ```pytb; .../statsmodels/genmod/generalized_linear_model.py:1257: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified; warnings.warn(msg, category=PerfectSeparationWarning); ```. ### Versions. <details>. ```; anndata 0.10.4; scanpy 1.9.6; statsmodels 0.14.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3260:357,error,error,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3260,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have always had a question: do I need to scale my adata before running sc.tl.score_genes?. ### Minimal code sample. ```python; sc.tl.score_genes_cell_cycle(adata_hvg, layers='scaled', s_genes=s_genes, g2m_genes=g2m_genes); ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3080:523,Error,Error,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3080,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Leiden and Louvain clustering params are not saved to matching `key_added` key in `uns` dictionary but are ovewritten to hardcoded key instead. One use case is that a user may want to run Leiden/Louvain clustering multiple times with different resolutions / parameters. One may specify different keys to store results under. However, if you do so, the metadata for the parameterization of the clustering algorithms are overwritten because the lines below do not respect the user provided `key_added` parameter. I think the desired behavior is to store data under `adata.uns[key_added][""params""]`. I think I've found the pertinent lines below. Happy to submit a PR if maintainers agree :D.; - https://github.com/scverse/scanpy/blob/91ea0fbb03392795d1506d297d4b4847c646db04/scanpy/tools/_leiden.py#L206; - https://github.com/scverse/scanpy/blob/91ea0fbb03392795d1506d297d4b4847c646db04/scanpy/tools/_louvain.py#L259. ### Minimal code sample. ```python; sc.tl.leiden(adata, resolution=0.8, key_added=""leiden_0.8""); assert ""leiden_0.8"" not in adata.uns; params = adata.uns[""leiden""] . sc.tl.leiden(adata, resolution=1.2, key_added=""leiden_1.2""); assert ""leiden_1.2"" not in adata.uns; overwritten_params = adata.uns[""leiden""] ; assert params == overwritten_params # should fail; ```. ### Error output. _No response_. ### Versions. <details>; Confirmed that params are overwritten in source in main branch. (see permalinks); </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2887:1572,Error,Error,1572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2887,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Shouldn't max Value for `scale` and zero_center also clip the negative values?. ### Minimal code sample. ```python; bdata = sc.datasets.pbmc3k(); sc.pp.scale(bdata,max_value= 1); print(bdata.X.min(),bdata.X.max()); ```. ### Error output. ```pytb; -2.62718 1.0. shouldn't this be -1,1; ```. ### Versions. scanpy build from github main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2912:513,Error,Error,513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2912,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. The column label and color is wrong after using 'swap_axes=True'; ![lyz1](https://github.com/user-attachments/assets/1783ed72-a9ad-457a-afdf-bf6f10fd766f); ![lyz2](https://github.com/user-attachments/assets/3c819376-ba09-49b4-a645-aa8e7b1bf3a9). ### Minimal code sample. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon',tie_correct=True,pts=True,key_added='wilcoxon'); sc.pl.rank_genes_groups_stacked_violin(adata, n_genes=5, key=""wilcoxon"", groupby=""bulk_labels""); sc.pl.rank_genes_groups_stacked_violin(adata, n_genes=5, key=""wilcoxon"", groupby=""bulk_labels"",swap_axes=True); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.2.0; attrs 23.2.0; babel 2.14.0; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; google NA; h5py 3.11.0; idna 3.7; igraph 0.11.4; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.0; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numpy 1.26.4; nvfuser NA; opt_einsum v3.3.0; overrides NA; packaging 24.0; pandas 1.5.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3152:962,Error,Error,962,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3152,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks!. ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python; sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[37], line 1; ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax); 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""); 161 if (; 162 (x in adata.obs.keys() or x in var_index); 163 and (y in adata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102:763,Error,Error,763,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When reading docs from the readthedocs website, clicking the ""source"" link will navigate to the wrong spot. I think the structure was changed slightly in a commit since these were updated. The locations are still obtainable by manually walking the tree, but they are no longer what is pointed to in those [source] links. I am happy to try my hand at a fix, I just need some direction in terms of whether this is would be helpful, and how the docs are updated. ; This is where I am navigated to when i click the link for scanpy.pp.calculate_qc_metrics.; <img width=""690"" alt=""image"" src=""https://github.com/user-attachments/assets/1cd8f7ba-a54b-49c4-9f00-a19633d5e606"">. ### Minimal code sample. ```python; no code, UI fix.; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3219:1022,Error,Error,1022,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3219,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:402,down,downstream,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['down'],['downstream']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. aggregate throws error when aggregating `obsm` or `varm`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean"", obsm=""X_umap""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[3], line 1; ----> 1 sc.get.aggregate(pbmc, by=""louvain"", func=""mean"", obsm=""X_umap""). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/functools.py:909, in singledispatch.<locals>.wrapper(*args, **kw); 905 if not args:; 906 raise TypeError(f'{funcname} requires at least '; 907 '1 positional argument'); --> 909 return dispatch(args[0].__class__)(*args, **kw). File /mnt/workspace/repos/scanpy/scanpy/get/_aggregated.py:272, in aggregate(adata, by, func, axis, mask, dof, layer, obsm, varm); 264 # Actual computation; 265 layers = aggregate(; 266 data,; 267 by=categorical,; (...); 270 dof=dof,; 271 ); --> 272 result = AnnData(; 273 layers=layers,; 274 obs=new_label_df,; 275 var=getattr(adata, ""var"" if axis == 0 else ""obs""),; 276 ); 278 if axis == 1:; 279 return result.T. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:271, in AnnData.__init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, obsp, varp, oidx, vidx); 269 self._init_as_view(X, oidx, vidx); 270 else:; --> 271 self._init_as_actual(; 272 X=X,; 273 obs=obs,; 274 var=var,; 275 uns=uns,; 276 obsm=obsm,; 277 varm=varm,; 278 raw=raw,; 279 layers=layers,; 280 dtype=dtype,; 281 shape=shape,; 282 obsp=obsp,; 283 varp=varp,; 284 filename=filename,; 285 fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:306,error,error,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. cc: @Intron7 . The array types returned for the various aggregations in `sc.get.aggregate` are different (see example). This can lead to somewhat confusing behavior downstream, especially while we are using the sparse matrix classes. I would suggest we default to a dense result and consider adding an argument `array_type` that determines the type of the arrays added to `layers`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(). aggregated = sc.get.aggregate(adata, ""louvain"", [""sum"", ""count_nonzero""]); type(aggregated.layers[""sum""]); # numpy.ndarray. type(aggregated.layers[""count_nonzero""]); # scipy.sparse._csr.csr_matrix; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.10.0.dev315+gf6d5ac94; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.1; dateutil 2.8.2; decorator 5.1.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.11.3; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.41.1; markupsafe 2.1.4; matplotlib 3.8.2; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.9.0; prompt_toolkit 3.0.43; psutil 5.9.8; ptyprocess 0.7.0; pure_eval 0.2.2; pygments 2.17.2; pyparsing 3.1.1; pytz 2023.4; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.0; sparse 0.15.1; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.1; toolz 0.12.1; traitlets 5.14.1; wcwidth 0.2.13; yaml 6.0.1; zarr 2.16.1; zipp NA; -----; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2892:454,down,downstream,454,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2892,2,"['Error', 'down']","['Error', 'downstream']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. was running the standard pipeline on some data and when i run; `sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False) `; it spits out infinite lines of ignored exceptions. it does not actually crash the kernel, but does bog it down and causes everything to to take much more time than necesarry. ; I am working in a conda env on a Win 10 , 64bit, x64 system; the problem also occurs using the pbmc3k dataset. ### Minimal code sample. ```python; # example with own data, but same happens with pbmc3k data; sc.pp.filter_cells(em_adata, min_genes=200); sc.pp.filter_genes(em_adata, min_cells=3); em_adata.shape; # [out] -> (42753, 21636). sc.pp.calculate_qc_metrics(em_adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True); em_adata.obs[""outlier_mt""] = em_adata.obs.pct_counts_mt > 15; em_adata.obs[""outlier_total""] = em_adata.obs.total_counts > 30000; em_adata.obs[""outlier_ngenes""] = em_adata.obs.n_genes_by_counts > 6000; em_adata = em_adata[~em_adata.obs[""outlier_mt""], :]; em_adata = em_adata[~em_adata.obs[""outlier_total""], :]; em_adata = em_adata[~em_adata.obs[""outlier_ngenes""], :]; sc.pp.filter_genes(em_adata,min_cells=1). sc.pp.scrublet(em_adata); em_adata.layers['counts'] = em_adata.X.copy(); sc.pp.normalize_total(em_adata); sc.pp.log1p(em_adata); sc.pp.highly_variable_genes(em_adata,flavor='seurat'); sc.pl.highly_variable_genes(em_adata); em_adata = em_adata[:, em_adata.var[""highly_variable""]]; em_adata.shape; # [out] -> (41749, 1425); sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```. ### Error output. ```pytb; Exception i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969:549,down,down,549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969,1,['down'],['down']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. 导入scanpy1.9.1时，matplotlib在3.7版本以下然后发生元类错误. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>; from util import *; File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>; import scanpy as sc; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>; from . import plotting as pl; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>; from ._anndata import (; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>; from . import _utils; File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. 进程已结束,退出代码1; ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029:398,Error,Error,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. ![image](https://github.com/scverse/scanpy/assets/43333475/08fe247f-bd56-4b6c-b9e5-5a69499e7b44). Hi, I intend to use n_top_gene to determine the number of hvgs I intend to have, but I met such errors. I used to meet this error previously, but no effective solutions. . Could you please double check it? Thanks. ### Minimal code sample. ![image](https://github.com/scverse/scanpy/assets/43333475/08fe247f-bd56-4b6c-b9e5-5a69499e7b44). ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>. anndata 0.9.2; scanpy 1.9.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819:485,error,errors,485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819,3,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2629:691,down,down,691,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629,1,['down'],['down']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi!. My recent PR (https://github.com/scverse/scanpy/pull/2772) made me realize that `.getnnz(axis=xx)` is used in several places in the codebase. From the Scipy docs for sparse arrays:; > Deprecated since version 1.11.0: This method will be removed in SciPy 1.13.0. Use X.nnz instead. The axis argument will no longer be supported; please let us know if you still need this functionality. From what I understand, sparse *matrices* should be fine. Can we assume that an AnnData contains a sparse matrix and not a sparse array? If not, it may be good to do one or more of the following:; - Preventively put scipy < 1.13 in the requirements; - Signal to Scipy that the `axis` argument is important to this widely used package. Pinging @dschult again for that; - At some point move to `.nnz`. Best,. GJ. (edited because I originally confused `csr_array` and `csr_matrix`). ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; latest; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2773:1016,Ping,Pinging,1016,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2773,2,"['Error', 'Ping']","['Error', 'Pinging']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with ; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this?. ### Minimal code sample. ```python; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48; ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2634:414,down,download,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634,2,"['Error', 'down']","['Error', 'download']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. N/A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2609:684,Error,Error,684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:514,error,errored,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,2,"['Error', 'error']","['Error', 'errored']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was trying to install `scanpy=1.9.6` using conda in a `python=3.9` environment that had 1.9.5 working with `seaborn=0.13`.; Conda raised a solving issue due to ; `package scanpy-1.9.6-pyhd8ed1ab_0 requires seaborn !=0.13.0, but none of the providers can be installed`; I tried the second build (1ab_1) and the error stayed:; ` package scanpy-1.9.6-pyhd8ed1ab_1 requires seaborn !=0.13.0, but none of the providers can be installed`. I checked github and saw that the dependency in `pyproject.toml` is `""seaborn>=0.13.0""` but when i checked the conda package's `index.json` i saw `""seaborn !=0.13.0""`. The discrepancy between the dependencies is unclear. the full `index.json`:; ```json; {; ""arch"": null,; ""build"": ""pyhd8ed1ab_1"",; ""build_number"": 1,; ""depends"": [; ""anndata >=0.7.4"",; ""get-annotations"",; ""h5py >=3"",; ""joblib"",; ""matplotlib-base >=3.6"",; ""natsort"",; ""networkx >=2.3"",; ""numba >=0.41"",; ""numpy >=1.17"",; ""packaging"",; ""pandas >=1.1.1,!=2.1.2"",; ""patsy"",; ""python >=3.8"",; ""scikit-learn >=0.24"",; ""scipy >=1.4"",; ""seaborn !=0.13.0"",; ""session-info"",; ""statsmodels >=0.11"",; ""tqdm"",; ""umap-learn >=0.3.10""; ],; ""license"": ""BSD-3-Clause"",; ""license_family"": ""BSD"",; ""name"": ""scanpy"",; ""noarch"": ""python"",; ""platform"": null,; ""subdir"": ""noarch"",; ""timestamp"": 1699376683854,; ""version"": ""1.9.6""; }; ```. ### Minimal code sample. ```python; conda create -n test ""python=3.9"" ""scanpy=1.9.6"" ""seaborn=0.13"" -c conda-forge; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2791:603,error,error,603,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2562:785,Error,Error,785,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Many different calls in scanpy emit warnings that are currently suppressed by our testing framework (I think). . ### Minimal code sample. I discovered this unrelatedly by editing the notebooks, see for example: https://github.com/scverse/scanpy-tutorials/blob/master/spatial/integration-scanorama.ipynb. @flying-sheep mentioned that the scanpy tests filter out warnings and indeed you can reproduce these by e.g.,:; ```sh; pytest -W error::FutureWarning -n auto scanpy/tests/test_plotting.py; ```. ### Error output. - [x] `…/scanpy/plotting/_tools/scatterplots.py:401:`. > UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored. - [x] `…/scanpy/plotting/_tools/__init__.py:1269:`. > FutureWarning: The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect. ; > `_ax = sns.violinplot(`. - [x] `…/scanpy/preprocessing/_simple.py:274:`. > ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; > `adata.var[""n_cells""] = number`. - [x] `…/scanpy/plotting/_stacked_violin.py:503: FutureWarning:`. > Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect. ; > `row_ax = sns.violinplot(`. ### Versions. <details>. ```; -----; anndata 0.10.4; scanpy 1.10.0.dev191+gf7f5d5c6; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cffi 1.16.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.0; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jedi 0.19.1; jinja2 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2839:724,error,error,724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2839,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Running the highly_variable_genes function produced an error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[101], line 2; 1 # Identify highly-variable genes and plot; ----> 2 sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:440, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2547:346,error,error,346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why it’s happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2688:796,Error,Error,796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688,2,"['Error', 'FAILURE']","['Error', 'FAILURES']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The test suite keeps failing with a segfault on the `python=3.9` build. I haven't been able to reproduce locally. Interestingly, I haven't seen it error when I rerun the check. It looks like this always happens during the call to `nn_approx`. ### Minimal code sample. ```python; NA; ```. ### Error output. ```pytb; platform linux -- Python 3.9.18, pytest-8.0.1, pluggy-1.4.0 -- /opt/hostedtoolcache/Python/3.9.18/x64/bin/python; cachedir: .pytest_cache; rootdir: /home/vsts/work/1/s; configfile: pyproject.toml; testpaths: scanpy; plugins: nunit-1.0.6, mock-3.12.0; [1mcollecting ... [0mcollected 1474 items. scanpy/_utils/compute/is_constant.py::scanpy._utils.compute.is_constant.is_constant [32mPASSED[0m[32m [ 0%][0m; scanpy/datasets/_ebi_expression_atlas.py::scanpy.datasets._ebi_expression_atlas.ebi_expression_atlas [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pl.py::scanpy.external.pl.phate [33mSKIPPED[0m (needs modul...)[32m [ 0%][0m; scanpy/external/pp/_bbknn.py::scanpy.external.pp._bbknn.bbknn [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_harmony_integrate.py::scanpy.external.pp._harmony_integrate.harmony_integrate [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_hashsolo.py::scanpy.external.pp._hashsolo.hashsolo [33mSKIPPED[0m[32m [ 0%][0m; scanpy/external/pp/_magic.py::scanpy.external.pp._magic.magic [32mPASSED[0m[32m [ 0%][0m; scanpy/external/pp/_scanorama_integrate.py::scanpy.external.pp._scanorama_integrate.scanorama_integrate Fatal Python error: Illegal instruction. Thread 0x00007f00347c4640 (most recent call first):; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/threading.py"", line 316 in wait; File ""/opt/hostedtoolcache/Python/3.9.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python; sc.tl.filter_rank_genes_groups; sc.tl.filter_rank_genes_groups; Both default use; ```. ### Error output. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /; ```. ### Versions. anndata: 0.9.2; scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2666:653,Error,Error,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When reading the `tissue_positions.csv` file generated by SpaceRanger v2.0 or later, `read_visium` reads the header from the second row (with `header=1`), while it should read from the first row instead (with `header=0`). ### Minimal code sample. ```python; positions = pd.read_csv(; files['tissue_positions_file'],; header=0 if tissue_positions_file.name == ""tissue_positions.csv"" else None,; index_col=0,; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.2; scanpy 1.10.0.dev157+g9b7f6032; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2746:711,Error,Error,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2746,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running the tests with pytest<=8, the doctest for `scanpy.preprocessing._simple.filter_cells` errors in a way I can't quite figure out how to fix. . I think what's happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most rec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:390,error,errors,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,3,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2506:359,error,errors,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506,3,"['avail', 'error']","['available', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using `sc.queries.biomart_annotations`, it still generates the file `.pybiomart.sqlite` even when `use_cache=False` is used. To me this is a problem because the generated hidden file interferes with `Omnipath` and makes it crash. It used to be the case that `use_cache` used to work but not anymore. . Thank you for your time. ### Minimal code sample. ```python; import scanpy as sc. annot = sc.queries.biomart_annotations(; 'hsapiens',; ['ensembl_gene_id', 'external_gene_name'],; use_cache=False; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.8; -----; PIL 10.2.0; asttokens NA; attr 23.1.0; attrs 23.1.0; brotli 1.1.0; cattr NA; cattrs NA; certifi 2023.11.17; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; executing 2.0.1; future 0.18.3; h5py 3.10.0; idna 3.4; igraph 0.11.2; ipykernel 6.26.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.4; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 3.11.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 15.0.0; pybiomart 0.2.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.1.1; pytz 2024.1; requests 2.31.0; requests_cache 1.1.1; scipy 1.11.3; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; socks 1.7.1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.2.0; tornado 6.3.3; traitlets 5.13.0; typing_extensions NA; url_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861:807,Error,Error,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When working on one of the notebooks in `spatialdata-notebooks` I noticed that for `library_id` in `scatterplots.py` the type hints are inconsistent. Specifically here it is indicated to be either `Empty` or `str`:. https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L921. While here the type hint includes `None`:; https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L1287. I think the case should be that None should be included. Very minor, but just noticed it so I thought to open an issue. ### Minimal code sample. ```python; NA; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asciitree NA; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nt NA; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; packaging 23.1; pandas 1.5.3; psutil 5.9.5; pyarrow 12.0.0; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywintypes NA; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; win32api NA; win32com NA; yaml 6.0; zarr 2.14.2; zipp NA; zoneinfo NA; -----; Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:51:25) [MSC v.1934 64 bit (AMD64)]; Windows-10-10.0.22621-SP0. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2539:970,Error,Error,970,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2539,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When you print something in the search bar on the [documentation website](https://scanpy.readthedocs.io/en/stable/index.html), sometimes suggested links are broken. See the example for `sc.pl.umap` below. Using google, I was able to find a correct page. Here is the correct and the broken link:; - Broken: https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.umap.html#scanpy-pl-umap; - Correct: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html#scanpy-pl-umap. The difference is in latest/stable part. I tried searching for other functions as well, but did not notice any pattern. Here are some other links from search suggestion that are broken:; - https://scanpy.readthedocs.io/en/latest/generated/scanpy.external.tl.phenograph.html; - https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.rank_genes_groups_dotplot.html; - Same for other visualizations of rank_genes_group. `tl.rank_genes_groups` works, though. And a related issue. Why doesn't scanpy have a custom 404 page? 😄 . ### Minimal code sample. Here's an example with looking for umap plot:; - Search suggests a page:; ; <img width=""514"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/35199218/893b7a60-d30d-40a2-bc8f-0fbb46b25ce0"">. - First link (to the tool) is correct, but by clicking on the second one (for plotting) user gets 404:. <img width=""907"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/35199218/f56fefd4-ec7c-4afc-953a-96a5832b848c"">. ### Error output. _No response_. ### Versions. I was at the ""stable"" version on the website. Current scanpy version is 1.9.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2763:1765,Error,Error,1765,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2763,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. `@doctest_needs` decorator causes test failures on scanpy import in anndata test suite. https://dev.azure.com/scverse/anndata/_build/results?buildId=5802&view=logs&jobId=0497d03e-5796-547f-cc56-989f8152a63c&j=0497d03e-5796-547f-cc56-989f8152a63c&t=ea3acdad-0250-5b8b-a1da-6cd02463cf17. ### Minimal code sample. ```python; NA; ```. ### Error output. ```pytb; else:; enum_member = enum_class._new_member_(enum_class, *args); if not hasattr(enum_member, '_value_'):; if enum_class._member_type_ is object:; enum_member._value_ = value; else:; try:; enum_member._value_ = enum_class._member_type_(*args); except Exception as exc:; new_exc = TypeError(; '_value_ not set in __new__, unable to create it'; ); new_exc.__cause__ = exc; > raise new_exc; E TypeError: _value_ not set in __new__, unable to create it; ```. ### Versions. <details>. ```; See anndata test failure; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2878:330,failure,failures,330,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2878,3,"['Error', 'failure']","['Error', 'failure', 'failures']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hello scanpy!; First time, please let me know what to fix about my question asking!; When running sc.pp.highly_variable_genes I get this error; ""ImportError: Please install skmisc package via `pip install --user scikit-misc ""; I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['error'],['error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I'm trying to read in visium data with antibody capture data but for some reason the antibody capture data is not registering. Is there something I'm doing wrong? I couldn't find documentation on how to do this. Although I do see the antibody capture data in the web_summary.html. However read_10x_mtx method works directly on the folder, is there a way to add gex_only functionality to the read_visium function? . ### Minimal code sample. ```python; print(key); adata = sc.read_visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True, ); print(adata); ; # Separate RNA and protein data; rna_data = adata[:, adata.var['feature_types'] == 'Gene Expression']; protein_data = adata[:, adata.var['feature_types'] == 'Antibody Capture']; ; # Verify the separated data; print(""RNA data shape:"", rna_data.shape); print(""Protein data shape:"", protein_data.shape); ```. ### Error output. ```pytb; MWS22-14789. AnnData object with n_obs × n_vars = 2256 × 18085; obs: 'in_tissue', 'array_row', 'array_col'; var: 'gene_ids', 'feature_types', 'genome', 'isotype_control', 'normalized', 'pattern', 'read', 'secondary_name', 'sequence'; uns: 'spatial'; obsm: 'spatial'; RNA data shape: (2256, 18085); Protein data shape: (2256, 0); ```. ### Versions. <details>. ```; 1.10.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3113:1172,Error,Error,1172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Tried to run this function:; sc.tl.leiden(test, resolution = 0.1, restrict_to = ('leiden', ['5'])). and instead it is subsetting cluster 5 into over 400 new subsets, even with my resolution set to 0.1. I've also tried different resolutions and none of them work, it ignores the resolution altogether. ; ![leiden](https://github.com/scverse/scanpy/assets/88872118/7fa7114e-d8ae-4e91-94b6-ece1f9505594). ### Minimal code sample. ```python; sc.tl.leiden(test, resolution = 0.1, restrict_to = ('leiden', ['5'])); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.0.1; appnope 0.1.2; asttokens NA; attr 23.1.0; bottleneck 1.3.5; brotli NA; celltypist 1.6.2; certifi 2023.11.17; cffi 1.16.0; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2022.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; dill 0.3.7; docrep 0.3.2; entrypoints 0.4; exceptiongroup 1.2.0; executing 0.8.3; fsspec 2023.10.0; h5py 3.7.0; idna 3.4; igraph 0.10.8; inflect NA; ipykernel 6.28.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.3; joblib 1.3.2; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.7; numpy 1.26.3; omnipath 1.0.8; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prompt_toolkit 3.0.43; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pyda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906:807,Error,Error,807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; np.random.seed(0). # Get AnnData; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X.copy().tocsr(); adata.obs[""Age""] = np.random.randint(0, 6, (2700,)); adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess; sc.pp.filter_genes(adata, min_counts = 10); sc.pp.normalize_total(adata); sc.pp.log1p(adata). # Subset = False; ad_nosub = adata.copy(); sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards; ad_nosub_subbed = ad_nosub.copy(); ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True; ad_sub = adata.copy(); sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True); ```. ### Error output. ```pytb; >>> # As expected; >>> print(np.sum(ad_nosub.var[""highly_variable""])); 1000; >>> ; >>> # As expected; >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])); 1000; >>> ; >>> # Not as expected; >>> print(np.sum(ad_sub.var[""highly_variable""])); 101; ```. ### Versions. <details>. ``` bash; → conda list | grep scanpy; scanpy 1.10.1 pyhd8ed1ab_0 conda-forge. → conda list | grep anndata; anndata 0.10.7 pyhd8ed1ab_0 conda-forge; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3027:1469,Error,Error,1469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. `sc.tl.ingest` uses `pkg_version('anndata')`, which errors out using the latest version of `anndata`. ### Minimal code sample. ```python; from scanpy._compat import pkg_version; pkg_version(""anndata""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ----> 1 pkg_version(""anndata""). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/scanpy/_compat.py:80, in pkg_version(package); 76 @cache; 77 def pkg_version(package):; 78 from importlib.metadata import version as v; ---> 80 return version.parse(v(package)). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:52, in parse(version); 43 def parse(version: str) -> ""Version"":; 44 """"""Parse the given version string.; 45 ; 46 >>> parse('1.0.dev1'); ref='/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:0'>0</a>;32m (...); 50 :raises InvalidVersion: When the version string is not a valid version.; 51 """"""; ---> 52 return Version(version). File /opt/saturncloud/envs/saturn/lib/python3.9/site-packages/packaging/version.py:195, in Version.__init__(self, version); 184 """"""Initialize a Version object.; 185 ; 186 :param version:; ...; --> 195 match = self._regex.search(version); 196 if not match:; 197 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.10.0; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cairo 1.23.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; colorlog NA; comm 0.1.4; cupy 12.2.0; cupy_backends NA; cupyx NA; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978:341,error,errors,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978,2,"['Error', 'error']","['Error', 'errors']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python; sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'); ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2670:712,Error,Error,712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The exception happened when try to run scanpy `highly_variable_genes` with sparse dataset loaded in backed mode. ### Minimal code sample. ```python; # read backed; adata = anndata.read_h5ad(file_path, backed='r'); X = adata.raw.X if adata.raw is not None else adata.X; # dataset must be sparse there; print(issparse(X[0])); # calculate dispersions; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, inplace=False); ```; True; ```. ### Error output. ```pytb; loop of ufunc does not support argument 0 of type SparseDataset which has no callable expm1 method!; ```. goes from https://github.com/scverse/scanpy/blob/bc349b999be62196aa51b59db6e2daa37f428322/scanpy/preprocessing/_highly_variable_genes.py#L206. ### Versions. <details>. ```; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.3.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; igraph 0.10.2; ipykernel 6.17.1; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.0; llvmlite 0.39.1; louvain 0.8.0; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; numba 0.56.4; numpy 1.23.5; packaging 21.3; pandas 1.2.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.4; plotly 5.11.0; prompt_toolkit 3.0.33; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.6; scipy 1.9.3; session_info 1.0.0; setuptools 62.3.2; sitecustomize NA; six 1.16.0; sklearn 1.1.3; stack_data 0.6.1; texttable 1.6.6; threadpoolctl 3.1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2764:754,Error,Error,754,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2764,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2665:804,Error,Error,804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi, . Apologies if I've missed this addressed somewhere else, however I would like to save my figured to a defined directory. It doesn't seem I can do that without first changing the current working directory outside the line of code. What is the best way to save my plot to a specific directory without having to change it each time using os.chdir? . I have seen this [issue](https://github.com/scverse/scanpy/issues/1508#issue-750736685) from 2 years ago but wondered if any changes have been made since. ### Minimal code sample. ```; output_dir_fig = ""chosen/path/to/directory""; sc.pl.highest_expr_genes(adata, n_top=10, save= f""{output_dir_fig}/highest_expr_genes.png""). ```. ### Error output. ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[85], line 1; ----> 1 sc.pl.highest_expr_genes(adata, n_top=10, save= f""{output_dir_fig}/highest_expr_genes.png""). File /opt/anaconda3/envs/scanpy/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /opt/anaconda3/envs/scanpy/lib/python3.11/site-packages/scanpy/plotting/_qc.py:105, in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 103 ax.set_xscale(""log""); 104 show = settings.autoshow if show is None else show; --> 105 _utils.savefig_or_show(""highest_expr_genes"", show=show, save=save); 106 if show:; 107 retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3276:973,Error,Error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276,1,['Error'],['Error']
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hi; I am trying to read in my Visium HD file which is in non-zarr format. ; Here is the error that I get. . ### Minimal code sample. from spatialdata_io import visium_hd; import spatialdata as sd. path_read ='...'; sdata= visium_hd(path_read). ### Error output. Its says the dataset_id needs to be specified, but there isn't a dataset_id in my folder. ; I tried specifying dataset_id=""None"" or just blank or some possible names from my parent folder that could be it. ; But it does not read it. . ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3341:377,error,error,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3341,2,"['Error', 'error']","['Error', 'error']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I have non zarr format Visium HD data. ; I tried reading it with sdata = visium_hd(path_read). it keeps asking me for a dataset_id which is not there in the feature_slice file name or my folder. ; Nonetheless, I kept setting it to None or """" or other possible dataset id values. I cannot find any tech support on the error either. . (I also tried specifying the file path to the different binned folders). ### Minimal code sample. path_read = '/Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs'; sdata = visium_hd(path_read). ### Error output. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:606,error,error,606,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,3,"['Down', 'Error', 'error']","['Downloads', 'Error', 'error']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. There are a few instances where the input for `sc.get.obs_df` could be described better to avoid some edge cases that don't throw errors (or throw cryptic errors). . 1. The param descriptions say that `obsm_keys` expects a [Tuple of (key, column)](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L240-L241), but this gives an error:; ```py; adata = sc.datasets.pbmc3k_processed(); sc.get.obs_df(adata, obsm_keys = ('X_pca', 1)); ``` ; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[15], line 1; ----> 1 sc.get.obs_df(adata, obsm_keys = ('X_pca', 1)). File /oak/stanford/groups/pritch/users/emma/miniforge3/envs/perturb-vs-tissue-env/lib/python3.10/site-packages/scanpy/get/get.py:328, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 325 if keys:; 326 df = df[keys]; --> 328 for k, idx in obsm_keys:; 329 added_k = f""{k}-{idx}""; 330 val = adata.obsm[k]. ValueError: too many values to unpack (expected 2); ```; The function works if you pass a list of Tuples:; ```; sc.get.obs_df(adata, obsm_keys = [('X_pca', 1)]); ```; So perhaps the parameter descriptions should say `List of Tuples of (key, column)`? Or the case of extracting a single column should be handled. . 2. The input for the `keys` is described as [""keys""](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L238-L239), but if you pass only one key as a string, the function returns a `pd.Series` instead of a `pd.DataFrame`. This is not a massive problem, unless you also pass something to `obsm_keys`. When you do that, the function",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3310:419,error,errors,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310,3,['error'],"['error', 'errors']"
Availability,"### Please make sure these conditions are met. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we tried to compute QC metrics for our dataset we got this error (see title). Produced by the X.eliminate_zeros() call. We also traced the error back to genes that have only zeros in them, which would remove these columns and thus change the shape of the matrix. When we removed these genes the error vanished and the program ran successfully. ### Minimal code sample. sc.pp.calculate_qc_metrics(; raw_data, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, log1p=True; ). ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.9; scanpy 1.10.3; -----; PIL 10.4.0; asttokens NA; charset_normalizer 3.4.0; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.5; decorator 5.1.1; executing 2.1.0; h5py 3.11.0; ipykernel 6.29.5; jedi 0.19.1; joblib 1.4.2; kiwisolver 1.4.7; legacy_api_wrap NA; llvmlite 0.43.0; matplotlib 3.9.2; matplotlib_inline 0.1.7; mpl_toolkits NA; natsort 8.4.0; numba 0.60.0; numpy 2.0.2; packaging 24.1; pandas 2.2.3; parso 0.8.4; pickleshare 0.7.5; platformdirs 4.3.6; prompt_toolkit 3.0.47; psutil 6.0.0; pure_eval 0.2.3; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.18.0; pyparsing 3.1.4; pytz 2024.1; scipy 1.14.1; session_info 1.0.0; six 1.16.0; sklearn 1.5.2; stack_data 0.6.2; threadpoolctl 3.5.0; tornado 6.4.1; traitlets 5.14.3; vscode NA; wcwidth 0.2.13; yaml 6.0.2; zmq 26.2.0; -----; IPython 8.27.0; jupyter_client 8.6.3; jupyter_core 5.7.2; -----; Python 3.12.6 | packaged by conda-forge | (main, Sep 22 2024, 14:16:49) [GCC 13.3.0]; Linux-5.15.0-122-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-10-30 08:33. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3331:353,error,error,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331,4,"['Error', 'error']","['Error', 'error']"
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Currently sc.pp.subsample does not allow for sampling with replacement. When n_obs is provided, and it is larger than the size of the adata object, an error message from numpy.random.choice is given.; ""obs_indices = np.random.choice(old_n_obs, size=new_n_obs, replace=False)"". It seems like replace is automatically set to False. It would be great if sc.pp.subsample provided a paramater to change the np.random.choice's 'replace' parameter to True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2854:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2854,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3054:403,robust,robust,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054,2,['robust'],['robust']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. It’s basically unmaintained: https://github.com/airspeed-velocity/asv/issues/1219. In https://github.com/scverse/scanpy/pull/3031, I ran into https://github.com/airspeed-velocity/asv/issues/966 which seems to make it almost unusable for our purposes. We need `setup` to run reliably.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3052:436,reliab,reliably,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052,1,['reliab'],['reliably']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. On the recommendation of the library authors, we should change the default leiden backend to `igraph` (https://github.com/scverse/scanpy/issues/1053) now that this has been made available in https://github.com/scverse/scanpy/pull/2815). At the same time, we should change the number of default iterations. Right now, we iterate until convergence. This can be very slow, especially for large datasets. We should probably just stick with the default of the underlying library (which is 2).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2865:340,avail,available,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2865,1,['avail'],['available']
Availability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. ```; /home/zeth/miniconda3/envs/pertpy/lib/python3.11/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.; warnings.warn(; ```. They raise warnings in downstream frameworks. Some are catching the Futurewarning, but some are not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2795:416,down,downstream,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2795,1,['down'],['downstream']
Availability,### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. currently `pp.scale` with a `mask_obs` with a sparse matrix and with `zero_center== False` takes a really long time to update the sparse matrix. This also takes up a lot of memory because of the parity calculations. I would suggest a numba kernel that just swaps out the data. This works really well for rapids-singlecell and greatly improves performance and reduces the memory overhead.; I would open a PR with this kernel. ------; Performance for 90k cells and 25k genes:; without mask:; CPU 645 ms | GPU 37 ms | 20x; with mask:; CPU 22 s | GPU 50 ms | 460x,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2941:645,mask,mask,645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2941,2,['mask'],['mask']
Availability,"### What kind of feature would you like to request?. Additional function parameters. ### Please describe your wishes. All the plotting functions in the `pl.rank_genes_groups_<plot-type>` group are able to pass additional keywords to their parent plot type for extra tuning, apart from `pl.rank_genes_groups_violin`. Was this by design, or is it an omission? If the latter, I'm happy to work on a PR to fix it (I found myself today wanting to pass `log=True`, only to get an error).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2954:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2954,1,['error'],['error']
Availability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hello Scanpy team!. In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2630:405,avail,available,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630,1,['avail'],['available']
Availability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667:444,error,error,444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667,1,['error'],['error']
Availability,"### 📄 `_make_forest_dict()` in `scanpy/neighbors/__init__.py`. 📈 Performance improved by **`77%`** (**`0.77x` faster**). ⏱️ Runtime went down from **`5670.84μs`** to **`3195.82μs`**; ### Explanation and details. I have used `numpy.array` and `numpy.concatenate` for your sizes and dat object which are much faster than `numpy.fromiter` and assignation respectively, especially when dealing with a large dataset. The sizes of your data_list are computed only once and used where needed. Which results in runtime improvements compared to previous code, where data sizes were computed multiple times in different parts of the code. ### Correctness verification. The new optimized code was tested for correctness. The results are listed below. #### ✅ 8 Passed − 🌀 Generated Regression Tests; <details>; <summary>(click to show generated tests)</summary>. ```python; # imports; import numpy as np; import pytest. # function to test; # (The function definition is omitted as it was provided in the original prompt). # helper class to create mock trees with properties; class MockTree:; def __init__(self, hyperplanes, offsets, children, indices):; self.hyperplanes = np.array(hyperplanes); self.offsets = np.array(offsets); self.children = np.array(children); self.indices = np.array(indices). # unit tests. # Test with a single tree with one-dimensional properties; def test_single_tree_one_dimensional():; tree = MockTree(hyperplanes=[1, 2], offsets=[3], children=[4, 5], indices=[6, 7]); forest = [tree]; result = _make_forest_dict(forest); assert result[""hyperplanes""][""start""][0] == 0; assert result[""offsets""][""start""][0] == 0; assert np.array_equal(result[""hyperplanes""][""data""], tree.hyperplanes); assert np.array_equal(result[""offsets""][""data""], tree.offsets). # Test with multiple trees with two-dimensional properties; def test_multiple_trees_two_dimensional():; tree1 = MockTree(hyperplanes=[[1, 2], [3, 4]], offsets=[5, 6], children=[[7, 8], [9, 10]], indices=[[11, 12], [13, 14]]); tree2 = Moc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2971:137,down,down,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2971,1,['down'],['down']
Availability,"#### Problem; File `tissue_positions_list.csv` not found when running `sc.read_visium`; This issue was caused by the file name change by `spaceranger`. . #### Solution; Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem; The following error messages appeared when running `sc.pl.spatial`:; ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [4], line 1; ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1000 cmap_img = None; 1001 circle_radius = size * scale_factor * spot_size * 0.5; -> 1003 axs = embedding(; 1004 adata,; 1005 basis=basis,; 1006 scale_factor=scale_factor,; 1007 size=circle_radius,; 1008 na_color=na_color,; 1009 show=False,; 1010 save=False,; 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):; 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 389 # if user did not set alpha, set alpha to 0.7; 390 kwargs['alpha'] = 0.7 if alpha is None else alpha; --> 392 cax = scatter(; 393 coords[:, 0],; 394 coords[:, 1],; 395 marker=""."",; 396 c=color_vector,; 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; 399 **kwargs,; 400 ); 402 # remo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2345:309,error,error,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345,1,['error'],['error']
Availability,"#**Here is an example:** . adata.var.ix['Wfdc18']; result: ; gene_ids ENSMUSG00000000983; n_cells 2411; Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); filter_result = sc.pp.filter_genes_dispersion(; adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]; adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2524 try:; -> 2525 return self._engine.get_loc(key); 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-53-fb4aad8315fd> in <module>(); 1 print (adata.var.ix['Wfdc18']); ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key); 125 ; 126 key = com._apply_if_callable(key, self.obj); --> 127 return self._getitem_axis(key, axis=axis); 128 ; 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1106 return self._get_loc(key, axis=axis); 1107 ; -> 1108 return self._get_label(key, axis=axis); 1109 ; 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis); 143 raise IndexingError('no slices here, handle elsewhere'); 144 ; --> 145 return self.obj._xs(label, axis=axis); 146 ; 147 def _get_loc(self, key, axis=None):. /usr/local/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109:552,toler,tolerance,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109,1,['toler'],['tolerance']
Availability,' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12476,mask,mask-,12476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9937,mask,mask-,9937,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4362,toler,tolerance,4362,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:4007,down,downgrade,4007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,1,['down'],['downgrade']
Availability,(feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048:16,error,errors,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048,1,['error'],['errors']
Availability,"(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4205,toler,tolerance,4205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1. Google Colab version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:3420,Error,Error,3420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['Error'],['Error']
Availability,"); 733 ; 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4595,error,error,4595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args); [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:; [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs); [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):; --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/); ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:3757,Error,Error,3757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,2,['Error'],['Error']
Availability,* Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`); * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32; * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released; * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724,1,['error'],['error']
Availability,* fixed vmin/vmax for categorical data #800 ; * added error message when vmin is not valid to point out how to format it; * updated test to cover categorical data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/804:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/804,1,['error'],['error']
Availability,"* installing the master branch via `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git` fails:. ```; UPDATING build/lib.linux-x86_64-3.5/None; error: [Errno 2] No such file or directory: 'build/lib.linux-x86_64-3.5/None'; ```; ; maybe `_version.py` returns `None` instead of a version string for the master branch. * installing the tag works: `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git@0.0` but the installed version will be `0.1`, not `0.0` as the tag says (i’m not sure 0.0 is a legal version anyway)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/15:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15,1,['error'],['error']
Availability,**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2104:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2104,1,['error'],['error']
Availability,", **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:8087,error,error,8087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['error']
Availability,", **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:7288,error,errors,7288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,", engine, **kwds); 1617 self.options[""has_index_names""] = kwds[""has_index_names""]; 1619 self.handles: IOHandles | None = None; -> 1620 self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); 1878 if ""b"" not in mode:; 1879 mode += ""b""; -> 1880 self.handles = get_handle(; 1881 f,; 1882 mode,; 1883 encoding=self.options.get(""encoding"", None),; 1884 compression=self.options.get(""compression"", None),; 1885 memory_map=self.options.get(""memory_map"", False),; 1886 is_text=is_text,; 1887 errors=self.options.get(""encoding_errors"", ""strict""),; 1888 storage_options=self.options.get(""storage_options"", None),; 1889 ); 1890 assert self.handles is not None; 1891 f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); 761 if compression == ""gzip"":; 762 if isinstance(handle, str):; 763 # error: Incompatible types in assignment (expression has type; 764 # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> 765 handle = gzip.GzipFile( # type: ignore[assignment]; 766 filename=handle,; 767 mode=ioargs.mode,; 768 **compression_args,; 769 ); 770 else:; 771 handle = gzip.GzipFile(; 772 # No overload variant of ""GzipFile"" matches argument types; 773 # ""Union[str, BaseBuffer]"", ""str"", ""Dict[str, Any]""; (...); 776 **compression_args,; 777 ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__(self, filename, mode, compresslevel, fileobj, mtime); 190 mode += 'b'; 191 if fileobj is None:; --> 192 fileobj = self.myfileobj = builtins.open(filename, mode or 'rb'); 193 if filename is None:; 194 filename = getattr(fileobj, 'name', ''). FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'; ```. ### Versions. <details>. ```; '1.10.2'; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:24141,error,errors,24141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,2,['error'],"['error', 'errors']"
Availability,", which gives scanpy users an obvious advantage. . I've learned so much using this package and it has allowed me to display my data in a simple and intuitive way. Truly, from the bottom of my heart, thank you, this package is awesome and I deeply appreciate all the work the scanpy team and Theis lab has put into it. . With that said, I find myself wanting to do things with scanpy that aren't currently supported. . (1) Clustering cells based on a restricted set of genes as opposed to principle components: I understand that this is a biased approach, but I find myself wanting to do this to explore datasets and how genes vary together. I believe it would aid in understanding data topology to reduce the dimensionality of the dataset by looking at a subset of key genes that are picked by an expert who has domain knowledge. I think this is best integrated with a separate sc.pp.neighbors-like function that uses a gene list, as opposed to PCs. Integration into downstream plotting can be done with separate functions that have a similar name (sc.tl.umap_genelist or sc.tl.umap_sparse; sc.tl.paga_genelist or sc.tl.paga_sparse). . I envision that this would also be a nice stepping stone towards multi-modal analysis with CITE-seq. . (2) I want to use PAGA and UMAP to display my CytOF data as well as integrate scRNA-seq/CytOF data together. I saw a pre-print on bioRxiv that indicated that you are working on this aspect of PAGA/scanpy. This was very exciting to me and I am glad that this is being developed. Is it possible to access the current version of this software? . I think that major partitions identified with CytOF or scRNA-seq can be linked together providing a coarse-grained mechanism to demonstrate how heterogeneity identified with each technique relates to each other based on a given experimental time point. . (3) Histogram integration in the plotting api for QC metrics would be helpful. While scatter plots and violin plots are effective, I find myself wanting to make cut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510:1383,down,downstream,1383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510,1,['down'],['downstream']
Availability,",; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15879,error,errors,15879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,",; obs=pd.DataFrame(; {""celltype"": list(chain(repeat(""a"", 10), repeat(""b"", 10)))},; index=[f""cell{i}"" for i in range(a.shape[0])]; ),; var=pd.DataFrame(index=[f""gene{i}"" for i in range(a.shape[1])]),; ). # Running differential expression with t-test:. sc.tl.rank_genes_groups(adata, groupby=""celltype""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This seems wrong. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""t-test""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1., 1., 1.]) # This also seems wrong. # Checking to make sure I'm not forgetting something obvious; print(stats.ttest_ind([0,0,0,0,0], [5,5,5,5,5])); # Ttest_indResult(statistic=-inf, pvalue=0.0) # This seems right. # Wilcoxon seems fine:. sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""wilcoxon""); print(adata.uns[""rank_genes_groups""][""pvals""][""a""]); # array([1.57052284e-04, 1.00000000e+00, 1.00000000e+00]) # This seems right; ```. `""logreg""` on the other hand, throws an error:. ```python; sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""); <ipython-input-7-29e46f287a31> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby=""celltype"", method=""logreg""). ~/github/scanpy/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 397 adata.uns[key_added]['scores'] = np.rec.fromarrays(; 398 [n for n in rankings_gene_scores],; --> 399 dtype=[(rn, 'float32') for rn in groups_order_save]); 400 adata.uns[key_added]['names'] = np.rec.fromarrays(; 401 [n for n in rankings_gene_names],. /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 615 # Determine shape from data-type.; 616 if len(descr) != len(arrayList):; --> 617 raise ValueError(""mismatch between the number of fields ""; 618 ""and the number of arrays""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620:1409,error,error,1409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620,1,['error'],['error']
Availability,"- . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). ```pytb; [Paste the error output produced by the above code here]; ```; C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1742:860,error,error,860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742,1,['error'],['error']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.umap(adata); sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']); sc.tl.leiden(adata); sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb; The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this?; ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2471:594,down,downloaded,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471,1,['down'],['downloaded']
Availability,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1660:705,Error,Error,705,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660,2,['Error'],['Error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy. ---; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ...; ...; test_data = sc.pp.regress_out(test_data,['n_count'], copy=True); sc.pp.scale(test_data); sc.tl.pca(test_data,n_comps=30, use_highly_variable=True); sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical; OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8; and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2404:944,error,errors,944,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404,1,['error'],['errors']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,; I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; InvalidIndexError Traceback (most recent call last); <ipython-input-54-668f41c58e57> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 231 ctrl_size ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:560,down,downloaded,560,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,2,"['down', 'error']","['downloaded', 'error']"
Availability,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1481:542,error,error,542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481,2,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## save command; adata.write(folder + ""before_regression.h5ad""); ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795:589,error,error,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello everyone, I am trying to calculate cell cycle score for my mouse data and encountering this error. I have already converted the gene name to upper case letters to read from the cell cycle genes. please help me to resolve this issue. Thank you very much. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens); ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-63-57c51b3902c0> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens). ~\anaconda3\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599:512,error,error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I just use the function sc.pp.downsample_counts() to downsample the data, but after that I can't see any output from the Spyder IPython console.; ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import scanpy as sc; import h5py. data = h5py.File('10X_PBMC.h5'). x = np.array(data['X']); adata = sc.AnnData(x). sc.pp.downsample_counts(adata, counts_per_cell=1000). ```pytb; [Paste the error output produced by the above code here]; ```; after I run the above code, there isn;t any error.; But when I key in 'adata' or any other thing in the Spyder IPython console, it just shows:. /anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:448: DeprecationWarning: `input_splitter` is deprecated since IPython 7.0, prefer `input_transformer_manager`.; status, indent_spaces = self.shell.input_splitter.check_complete(code). and there is nothing about the output I want.; After that, my console can’t output anything, unless I exit Spyder and re-enter. ### Versions; Python 3.7.0; Scanpy 1.4.3; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1368:467,down,downsample,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1368,3,"['down', 'error']","['downsample', 'error']"
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1); ```. ```pytb; TypeError Traceback (most recent call last); <ipython-input-17-15b8850a67a5> in <module>; 1 #New dot plot (12 weeks feature genes); ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 151 # 1. compute fraction of cells having value > expression_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932:479,error,error,479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,; I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3); ; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-73-a5a2e6833485> in <module>(); 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 205 neigh_params.get('metric', 'euclidean'),; 206 neigh_params.get('metric_kwds', {}),; --> 207 verbose=settings.verbosity > 3,; 208 ); 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose); 1037 random_state,; 1038 metric=metric,; -> 1039 metric_kwds=metric_kwds,; 1040 ); 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1989:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1675:660,ping,pinging,660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675,1,['ping'],['pinging']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]; pd.set_option(""display.max_colwidth"", 800); first_enrichment_results.iloc[:50,:]; plot_enrich(first_enrichment_results); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-28-72ef52261ce6> in <module>; ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save); 75 fig = plt.gcf(); 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]); ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes); 78 cbar.ax.set_yticklabels(ticks_labs); 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw); 2341 'panchor']; 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2344 ; 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003:355,error,error,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; How can I export umap location csv file（Barcodes，X,Y）from AnnData object after sc.tl.umap？; thanks; ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2171:643,error,error,643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171,1,['error'],['error']
Availability,"- [ ] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi Scanpy,; I noticed the error was kind of mnnpy related and after checking the issues there and updating two suggested packages, still getting the error. . ```python; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""); ```. ```pytb; Performing cosine normalization...; Starting MNN correct iteration. Reference batch: 0; Step 1 of 4: processing batch 1; Looking for MNNs...; Computing correction vectors...; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-49-f894e9f745f6> in <module>; ----> 1 adata_mnn, _, _ = sc.external.pp.mnn_correct(*adata_list, batch_key=""sample""). /projects/da_workspace/Users/amoussavi/Software/Anaconda_python3/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 152 save_raw=save_raw,; 153 n_jobs=n_jobs,; --> 154 **kwargs,; 155 ); 156 return datas, mnn_list, angle_list. /Anaconda_python3/lib/python3.7/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367:514,error,error,514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367,2,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2380:648,error,error,648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101; obs: 'n_genes_by_counts', 'total_counts'; var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'log1p', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```; This is the command that leads to error:; ```python; sc.pp.neighbors(adata ); ```; ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-79-c7d46fa554b4> in <module>; ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 792 X = pairwise_distances(X, metric=metric, **metric_kwds); 793 metric = 'precomputed'; --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(; 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds; 796 ). ~/.local/lib/python3.8/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472:788,error,error,788,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up?. **(1) when I do:** ; sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,; save = '_test2.png'; ). I get an AttributeError: 'str' object has no attribute 'mkdir'; ; **(2) when I do:**; sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,; save = '_test2.png'; ); then nothing happens there is no error and the directory doesn't actually change. ```python; sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,; save = '_test2.png'; ). ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-fd106b753fe2> in <module>; ----> 1 sc.pl.umap(Tgd,; 2 save = '_test2.png'; 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:982,error,error,982,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['error'],['error']
Availability,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2178:598,down,downloaded,598,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178,2,"['down', 'error']","['downloaded', 'errors']"
Availability,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2306:265,error,errors,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306,2,['error'],"['error', 'errors']"
Availability,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2001:740,Error,Error,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001,1,['Error'],['Error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python; sc.pp.highly_variable_genes(; adata,; flavor = ""seurat_v3"",; n_top_genes = 7000,; layer = ""counts"",; batch_key = ""combined"",; subset = True; ); ```. I get the following error:. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-3748de5bacdc> in <module>; 5 layer = ""counts"",; 6 batch_key = ""combined"",; ----> 7 subset = True; 8 ); 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 420 span=span,; 421 subset=subset,; --> 422 inplace=inplace,; 423 ); 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504:623,error,error,623,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:488,Down,Download,488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,2,['Down'],"['Download', 'Downloads']"
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:673,down,downstream,673,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['down'],['downstream']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalizatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2377:690,error,error,690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377,2,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:966,down,downstream,966,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['down'],['downstream']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I also tried 'log1p = False' and produced the other error. Thank you. . ```python; sc.pp.calculate_qc_metrics(adata); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 294, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 111, in describe_obs; obs_metrics[f""log1p_total_{expr_type}""] = np.log1p(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (35255); >; ```. `sc.pp.calculate_qc_metrics(adata, log1p = False)`. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 995, in __repr__; self.to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 1131, in to_string; return fmt.DataFrameRenderer(formatter).to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1053, in to_string; string = string_formatter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008:281,error,error,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to cluster a manifold of around 100K cells computed from scVI using the `leiden` ; algorithm as follows: . ``` ; sc.tl.leiden(adata_latent, resolution = 1, random_state = 1786); ```; This works fine:. ```; running Leiden clustering; Trying to set attribute `.obs` of view, copying.; finished: found 17 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:07:14); ```. However, when I inspect the object where I just ran `leiden`, I can't see the `leiden` labels in `adata.obs`. ; Instead, it seems to be located in `adata.uns`. . ```; AnnData object with n_obs × n_vars = 106774 × 50; obs: 'percent_mito', 'n_genes', 'n_counts'; uns: 'neighbors', 'umap', 'sampleID_colors', 'batch_colors', 'status_colors', 'leiden'; obsm: 'X_umap'; obsp: 'distances', 'connectivities'; ```. I have tried to downgrade `leidenalg` but there is no change. Do you have an idea what may be happening? . #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.1 scipy==1.5.2 pandas==1.1.1 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.8.2 louvain==0.7.0 leidenalg==0.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1410:1063,down,downgrade,1063,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1410,1,['down'],['downgrade']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:298,down,down,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['down'],['down']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2109:371,error,error,371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[‘resolution_parameter’] = resolution; 143 # clustering proper; → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[‘weights’] = weights; —> 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'); ```. ```pytb; [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2487:583,error,error,583,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487,1,['error'],['error']
Availability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello !. I'm not sure whether this is a bug or it is enforced intentionally but even though users can use the kwargs to pass on to `sc.pl.embedding` any additional argument for `matplotlib.pyplot.scatter()`, trying to change the marker style doesn't work. As you can see below, the marker style is hardcoded in `sc.pl.embedding` to always be ""."" thus raising an error when trying to use another marker style due to `scatter()` being fed with the keyword argument `marker` multiple times.; Best,. Jules. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import anndata. adata = anndata.AnnData(X=np.random.rand(1000, 20)); sc.pp.neighbors(adata); sc.tl.umap(adata, min_dist=0.2); sc.pl.umap(adata,show=True, marker=""^""); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_10129/876858932.py in <module>; 5 sc.pp.neighbors(adata); 6 sc.tl.umap(adata, min_dist=0.2); ----> 7 sc.pl.umap(adata,show=True, marker=""^""). ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2122:776,error,error,776,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122,1,['error'],['error']
Availability,- [X] Tests included or not required because it's minor; - [x] Release notes not necessary because it's minor. I'm pretty sure that we've had this warning for a looooong time and it keeps showing up in a lot of downstream packages. People are either aware of it now or don't care (with the latter probably being more likely ^_^).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798:211,down,downstream,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798,1,['down'],['downstream']
Availability,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467:460,error,error,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467,2,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns; However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works; ```. random_indices=np.random.permutation(adatas['Human'].obs_names); sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',; color=['CellType'],hspace=0.9); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-48-8a1d75e9b375> in <module>; 2 np.random.seed(0); 3 random_indices=np.random.permutation(adatas['Human'].obs_names); ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',; 5 color=['Batch','Region','Condition', 'Grade', ; 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 250 groups=groups,; 251 ); --> 252 color_vector, categorical = _color_vector(; 253 adata,; 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2401:350,error,error,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2034:311,error,error,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1486:527,error,error,527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to ingest a CITEseq dataset into another clustered dataset. These datasets have different numbers of cells but I ran neighbors(n_neighbors=30) for both prior to running umap. I have confirmed that both datasets have the same variable names and the same number of variable names (38). Both objects look identical when a call adata.var. . I receive the error: ""all input arrays must have the same shape"". . ```; sc.pp.neighbors(CODEX_sub, n_neighbors=30) ; sc.tl.umap(CODEX_sub); sc.pp.neighbors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085:594,error,error,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085,1,['error'],['error']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2282:1297,Avail,Available,1297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282,1,['Avail'],['Available']
Availability,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python; # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ); ```. ```pytb; [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-f7d35408db0b> in <module>; ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 671 tl.dendrogram; 672 """"""; --> 673 return _rank_genes_groups_plot(; 674 adata,; 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 590 from .._anndata import heatmap; 591 ; --> 592 return heatmap(; 593 adata,; 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2357:301,error,error,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208:414,error,error,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208,3,"['Error', 'error']","['Error', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```when I run ; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb; [Paste the error output produced by the above code here]; ```; Traceback (most recent call last):; File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:745,error,error,745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1590:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:311,Down,Downgrading,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['Down'],['Downgrading']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,3,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though; # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue; # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks; ```. ```pytb; [---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-2f4062a9e25b> in <module>; ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype); 46 Numpy data type.; 47 """"""; ---> 48 return read_text(filename, delimiter, first_column_names, dtype); 49 ; 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype); 323 else:; 324 with filename.open() as f:; --> 325 return _read_text(f, delimiter, first_column_names, dtype); 326 ; 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype); 386 first_column_names = True; 387 row_names.append(line_list[0]); --> 388 data.append(np.array(line_list[1:], dtype=dtype)); 389 else:; 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1838:570,error,errors,570,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838,1,['error'],['errors']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2321:794,error,error,794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:655,error,errors,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 # 绘制 PCA 图; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:556,error,error,556,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,2,"['error', 'toler']","['error', 'tolerance']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1556:506,error,error,506,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556,2,"['down', 'error']","['downgraded', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2383:1688,error,error,1688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078:519,error,error,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2389:487,down,downstream,487,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389,1,['down'],['downstream']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python; healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'); ```. I calculated qc metrics with this command.; ```python; sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True); ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") ; ```; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_1314047/3602867448.py in <module>; ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1009 show=False,; 1010 save=False,; -> 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:437,error,error,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:345,error,errors,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,2,['error'],"['error', 'errors']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2137:936,error,error,936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey!. I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors.; Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`; ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-39-d43e888a7389> in <module>; ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850:329,error,error,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850,2,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am following all the steps from the PBMC3k tutorial (https://scanpy.readthedocs.io/en/latest/tutorials/pbmc3k.html).; I ran the wilcoxon method for finding marker genes and saved the object to a .h5ad file, after which I reloaded the object from the file and the log1p dict appears to be empty for some reason. I checked the object before saving it to the file and it had the 'base' key whereas after loading it back it was missing, causing the error below. . ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read(results_file); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2497:676,error,error,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2236:422,error,error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. If there are very few genes some of the bins in `sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger"")` can contain a single gene leading to `NaN` values in the normalized expression vector which are removed here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L261. If after this filtering the dispersion vector is shorter then than `n_top_genes` there is an indexing error when selecting the dispersion cutoff here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L268. There should probably be a check (with a warning) when this happens. ### Minimal code sample (that we can copy&paste without having any data). ```python; import anndata; import numpy as np; import scanpy as sc. adata = anndata.AnnData(np.random.poisson(2, (100, 30))); sc.pp.normalize_total(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger""); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 268, in _highly_variable_genes_single_batch; disp_cut_off = dispersion_norm[n_top_genes - 1]; IndexError: index 29 is out of bounds for axis 0 with size 21; ```. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.1.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2230:698,error,error,698,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2230,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2491:264,error,error,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:289,error,error,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python; # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'); adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:; adata.var_names_make_unique(); print(adata.uns[""name""], "": data shape"", adata.shape); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:; adata.var['mt'] = adata.var_names.str.startswith('mt-'); sc.pp.calculate_qc_metrics(; adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:; print(adata.uns[""name""], "":""); sc.pl.violin(; adata,; [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],; jitter =0.4,; multi_panel=True,; ); ```. ```pytb; zfish_Control :; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>; 1 for adata in adata_control:; 2 print(adata.uns[""name""], "":""); ----> 3 sc.pl.violin(; 4 adata,; 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 779 ); 780 else:; --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2305:338,error,error,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello; This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:; ```; #use this; sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'); ```. Error:. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-16-30381f660d76> in <module>; 1 #use this; ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 659 tl.dendrogram; 660 """"""; --> 661 return _rank_genes_groups_plot(; 662 adata,; 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1941:737,Error,Error,737,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941,1,['Error'],['Error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1661:522,error,error,522,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, after clustering I am trying to use heatmap to visualize the marker gene but got below error:; could anyone help, many thanks.; ```python; ax = sc.pl.heatmap(adata,marker_genes_dict,groupby='louvain_r1',save=""0.png""); ```. ```pytb; KeyError: ""Values ['CD79A'], from ['CD79A', 'MS4A1', 'CD3D', 'CD8A', 'CD8B', 'GNLY', 'NKG7', 'CST3', 'LYZ', 'FCGR3A', 'FCER1A'], are not valid obs/ var names or indices."". ```. #### Versions. <details>; anndata 0.7.5; scanpy 1.6.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2068:318,error,error,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2068,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2443:332,error,error,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443,4,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python; #remove all ribosomal genes; malat1 = adata1.var_names.str.startswith('MALAT1'); ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")); # we need to redefine the mito_genes since they were first ; # calculated on the full object before removing low expressed genes.; mito_genes = adata1.var_names.str.startswith('MT-'); hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1); remove = np.add(remove, hb_genes); keep = np.invert(remove). adata3 = adata1[:,keep]. adata3; ```. #### Versions; anndata 0.8.0; scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.; self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2428:814,error,error,814,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: ; celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video; hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python; # Your code here; celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'); celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']; celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'); hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']; hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-25-5f4cc5c2e544> in <module>; 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:472,down,download,472,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,2,['down'],['download']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ------it is easy for v1.9.1 out of memory.; I have the same data(200000x20000), the RAM of my compute is 64 GB, and the v1.8 can cope it easy, but the v1.9.1 is easy to occur the memoryError from the sc.read('./xxx.h5ad'). **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); sc.read('./xxx.h5ad'); ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions; v1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; ![image](https://user-images.githubusercontent.com/50618480/170998448-db4300d9-54f0-4f03-b2be-7f6880006b29.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2266:783,error,error,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2465:358,error,error,358,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465,4,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239:603,error,error,603,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; categories_order=['0','1','9','8','2','5','4','7','3','6']; sc.pl.tracksplot(adata,markers,groupby='leiden',vmax=3,categories_order=categories_order); ```. ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/50618480/166931336-26e4431a-7bdb-41b4-a575-69aa5e9ef948.png); I can not get the order as ['0','1','9','8','2','5','4','7','3','6']; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2250:675,error,error,675,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/; ├── cli.py; ├── _compat.py; ├── datasets; ├── experimental; ├── external; ├── get; ├── __init__.py; ├── logging.py; ├── __main__.py; ├── _metadata.py; ├── metrics; ├── neighbors; ├── plotting; ├── preprocessing; ├── __pycache__; ├── queries; ├── readwrite.py; ├── _settings.py; ├── sim_models; ├── tools; └── _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2378:1014,error,error,1014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378,2,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1967:610,error,error,610,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2144:627,error,error,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124:822,error,error,822,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246:258,down,download,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246,2,"['down', 'error']","['download', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1437:380,error,error,380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073:926,error,error,926,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2343:904,error,error,904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143:500,error,error,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143,3,"['down', 'error']","['downloaded', 'error']"
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 41",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782:266,error,error,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782,1,['error'],['error']
Availability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:248,error,error,248,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,3,['error'],['error']
Availability,"- [√] I have checked that this issue has not already been reported.; - [√] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; small bug report:; https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py; line 538 wrong error raised when `use_raw=True`; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is not None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; Second `not` should be removed ,Corrected codes should be; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions; this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1929:380,error,error,380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929,1,['error'],['error']
Availability,"- [✔ ] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2057:622,error,error,622,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057,1,['error'],['error']
Availability,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2095:626,error,errors,626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095,1,['error'],['errors']
Availability,"----------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 3114 else:; 3115 # set column; -> 3116 self._set_item(key, value); 3117 ; 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 3188 """"""; 3189 ; -> 3190 self._ensure_valid_index(value); 3191 value = self._sanitize_column(key, value); 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:1968,error,error,1968,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,1,['error'],['error']
Availability,"-------------------; ValueError Traceback (most recent call last); <ipython-input-2-15436b6f0954> in <module>; 3 ; 4 adata = sc.datasets.krumsiek11(); ----> 5 sc.pl.clustermap(adata, obs_keys='cell_type'). ~/Code/scanpy/scanpy/plotting/_anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 777 adata.uns[obs_keys + '_colors'])); 778 row_colors = adata.obs[obs_keys].map(lut); --> 779 g = sns.clustermap(df, row_colors=row_colors, **kwds); 780 else:; 781 g = sns.clustermap(df, **kwds). ~/Code/seaborn/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:1272,mask,mask,1272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['mask'],['mask']
Availability,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332:78,error,error,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332,3,['error'],['error']
Availability,"---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable); 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience!. ```python; adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:750,error,error,750,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,"-packages/scipy/spatial/distance.py in pdist(X, metric, *args, **kwargs); 1932 if metric_name is not None:; 1933 X, typ, kwargs = _validate_pdist_input(X, m, n,; -> 1934 metric_name, **kwargs); 1935 ; 1936 # get pdist wrapper. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _validate_pdist_input(X, m, n, metric_name, **kwargs); 287 typ = types[types.index(X.dtype)] if X.dtype in types else types[0]; 288 # validate data; --> 289 X = _convert_to_type(X, out_type=typ); 290 ; 291 # validate kwargs. /usr/local/lib/python3.6/site-packages/scipy/spatial/distance.py in _convert_to_type(X, out_type); 182 ; 183 def _convert_to_type(X, out_type):; --> 184 return np.ascontiguousarray(X, dtype=out_type); 185 ; 186 . /usr/local/lib/python3.6/site-packages/numpy/core/numeric.py in ascontiguousarray(a, dtype); 588 ; 589 """"""; --> 590 return array(a, dtype, copy=False, order='C', ndmin=1); 591 ; 592 . ValueError: setting an array element with a sequence.; ```. </details>. -------------------. I think this is happening because `pandas` doesn't like being passed a sparse array ([which can happen in `sc.pl.clustermap`](https://github.com/theislab/scanpy/blob/7de1f5159c91d6d2243bb7866d9495ee6747c750/scanpy/plotting/anndata.py#L741)):. ```python; import pandas as pd; adata = sc.AnnData(A) # from above; pd.DataFrame(A) # Throws error; pd.DataFrame(adata.X, index=adata.obs_name, columns=adata.var_name).head() # returns malformed dataframe; 0 ... 99; 0 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 1 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 2 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 3 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ...; 4 (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... ... (0, 9)\t0.76754415\n (0, 28)\t0.16313511\n ... [5 rows x 100 columns]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:4729,error,error,4729,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['error'],['error']
Availability,". - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1056,error,errors,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['errors']
Availability,". ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014:1360,avail,available,1360,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014,1,['avail'],['available']
Availability,". ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]; ```. ```; [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),; (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),; (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:6645,error,errors,6645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,1,['error'],['errors']
Availability,".0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4015,toler,tolerance,4015,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,".0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xlrd 2.0.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-11-26 11:30]. </details>; When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2371:5520,error,error,5520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371,1,['error'],['error']
Availability,".1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_O",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:5558,avail,available,5558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['avail'],['available']
Availability,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:3247,down,downgrading,3247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrading']
Availability,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter; raise SphinxWarning(location + "":"" + message); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState; ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```; make clean; make html; ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1057:3072,error,errors,3072,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057,2,['error'],"['error', 'errors']"
Availability,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916:2309,toler,tolerance,2309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916,2,['toler'],['tolerance']
Availability,.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown loc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17203,ERROR,ERROR,17203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normaliz,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12060,mask,mask-,12060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,".values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=None)[0]; 375 return adata. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __getitem__(self, key); 2686 return self._getitem_multilevel(key); 2687 else:; -> 2688 return self._getitem_column(key); 2689 ; 2690 def _getitem_column(self, key):. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _getitem_column(self, key); 2693 # get column; 2694 if self.columns.is_unique:; -> 2695 return self._get_item_cache(key); 2696 ; 2697 # duplicate columns & possible reduce dimensionality. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _get_item_cache(self, item); 2487 res = cache.get(item); 2488 if res is None:; -> 2489 values = self._data.get(item); 2490 res = self._box_item_values(item, values); 2491 cache[item] = res. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py in get(self, item, fastpath); 4113 ; 4114 if not isna(item):; -> 4115 loc = self.items.get_loc(item); 4116 else:; 4117 indexer = np.arange(len(self.items))[isna(self.items)]. /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3078 return self._engine.get_loc(key); 3079 except KeyError:; -> 3080 return self._engine.get_loc(self._maybe_cast_indexer(key)); 3081 ; 3082 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2; ```. Versions of all packages:. `scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.2 scipy==1.3.1 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1`. Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:3162,toler,tolerance,3162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,3,['toler'],['tolerance']
Availability,".violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:2025,toler,tolerance,2025,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['toler'],['tolerance']
Availability,".win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3000,error,error,3000,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability,"/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:8069,error,errors,8069,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run; _build_py.run(self); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:8181,error,error,8181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,1,['error'],['error']
Availability,/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cann,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3144,ERROR,ERROR,3144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"0 0.001387 0.043064; ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321; ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308; ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1796:5793,error,error,5793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796,1,['error'],['error']
Availability,0-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8992,ERROR,ERROR,8992,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"0/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; session_info 1.0.0; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 5.1.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1. IPython 7.9.0; jupyter_client 6.1.12; jupyter_core 4.11.1; notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]; Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>; ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332:4830,error,error,4830,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332,1,['error'],['error']
Availability,"00)`. I get this error (the error does not show up when I use the normalization command from `scanpy` instead of the normalization with size factors from `scran`):. ```; LinAlgError Traceback (most recent call last); <ipython-input-97-96c692867dde> in <module>; ----> 1 sc.preprocessing.highly_variable_genes(adultAll, n_top_genes=10000, flavor='cellranger'). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 101 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 102 ; --> 103 mean, var = materialize_as_ndarray(_get_mean_var(X)); 104 # now actually compute the dispersion; 105 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in __pow__(self, other); 226 ; 227 def __pow__(self, other):; --> 228 return matrix_power(self, other); 229 ; 230 def __ipow__(self, other):. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603 ; 604 try:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216 ; 217 def _assertFinite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. Do you have any hints? I am trying to find the error but so far I have been unsuccessful.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:2388,error,error,2388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,1,['error'],['error']
Availability,0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9202,ERROR,ERROR,9202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:2311,down,download,2311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['download']
Availability,"1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyObjCTools NA; anyio NA; appnope 0.1.3; argcomplete NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531:1820,Error,Error,1820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531,2,"['Error', 'error']","['Error', 'error']"
Availability,"125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:5398,error,error,5398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['error']
Availability,"13 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fssp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5813,error,error,5813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.; I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:1660,error,error,1660,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,1,['error'],['error']
Availability,2-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4439,ERROR,ERROR,4439,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"2.0.0->scanpy); Using cached python_dateutil-2.6.1-py2.py3-none-any.whl; Collecting pytz (from matplotlib==2.0.0->scanpy); Using cached pytz-2018.3-py2.py3-none-any.whl; Requirement already up-to-date: six>=1.10 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: numpy>=1.7.1 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scan; Requirement already up-to-date: patsy in /cluster/software/lib/python3.6/site-packages (from statsmodels->scanpy); Requirement already up-to-date: decorator>=4.1.0 in /cluster/software/lib/python3.6/site-packages (from networkx->scanpy); Installing collected packages: scanpy, python-dateutil, pytz; Running setup.py install for scanpy: started; Running setup.py install for scanpy: finished with status 'error'; Complete output from command /cluster/software/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/scratch/tmp/pip-build-g14yf1xi/scanpy/setup.py';; running install; running build; running build_py; creating build; creating build/lib.linux-x86_64-3.6; creating build/lib.linux-x86_64-3.6/scanpy; copying scanpy/settings.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/_version.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__init__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__main__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/readwrite.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/utils.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/exporting.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/logging.py -> build/lib.linux-x86_64-3.6/scanpy; creating build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/top_genes_visual.py -> build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/rcmod.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:2812,error,error,2812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['error'],['error']
Availability,"2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:3175,down,downgrade,3175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrade']
Availability,"2; - zlib=1.2.13; - zlib-ng=2.0.7; - zstd=1.5.2; - pip:; - absl-py==1.4.0; - astunparse==1.6.3; - bcbio-gff==0.7.0; - biopython==1.81; - cachetools==5.3.1; - click==8.1.7; - flatbuffers==23.5.26; - gast==0.4.0; - geoparse==2.0.3; - gffpandas==1.2.0; - google-auth==2.22.0; - google-auth-oauthlib==1.0.0; - google-pasta==0.2.0; - grpcio==1.57.0; - imageio==2.34.1; - keras==2.13.1; - lazy-loader==0.4; - libclang==16.0.6; - louvain==0.8.2; - markdown==3.4.4; - numpy==1.24.3; - oauthlib==3.2.2; - opt-einsum==3.3.0; - protobuf==4.24.1; - pyasn1==0.5.0; - pyasn1-modules==0.3.0; - requests-oauthlib==1.3.1; - rsa==4.9; - scikit-image==0.24.0; - tensorboard==2.13.0; - tensorboard-data-server==0.7.1; - tensorflow==2.13.0; - tensorflow-estimator==2.13.0; - tensorflow-macos==2.13.0; - termcolor==2.3.0; - tifffile==2024.6.18; - tqdm==4.66.1; - typing-extensions==4.5.0; - urllib3==1.26.16; - werkzeug==2.3.7; - wrapt==1.15.0; ```. ### Minimal code sample. ```python; sc.pp.scrublet(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; # Successful case; -----; anndata 0.10.5.post1; scanpy 1.10.1; -----; PIL 9.4.0; astunparse 1.6.3; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; dill 0.3.7; gmpy2 2.1.2; google NA; h5py 3.9.0; igraph 0.11.3; joblib 1.3.2; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.40.1; louvain 0.8.2; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.3; pkg_resources NA; plotly 5.16.1; psutil 5.9.5; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; sympy 1.12; texttable 1.7.0; threadpoolctl 3.2.0; torch 2.0.1; tqdm 4.66.2; typing_extensions NA; wcwidth 0.2.6; yaml 6.0.1; -----; Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]; macOS-14.3-arm64-arm-64bit; -----; Session information updated at 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3116:15553,Error,Error,15553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116,1,['Error'],['Error']
Availability,"3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:1989,error,error,1989,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,2,['error'],['error']
Availability,"3L ENSG00000127054 202 False 202 0.094815 ... 4.506987 2.955005 -2.372437e-10 0.460416 CPSF3L; ATAD3C ENSG00000215915 9 False 9 0.009259 ... 3.953486 4.352607 8.472988e-12 0.119465 ATAD3C; C1orf86 ENSG00000162585 501 False 501 0.227778 ... 2.713522 0.543183 3.389195e-10 0.685145 C1orf86; RER1 ENSG00000157916 608 False 608 0.298148 ... 3.447533 1.582528 7.696297e-11 0.736050 RER1; ... ... ... ... ... ... ... ... ... ... ... ...; ICOSLG ENSG00000160223 34 False 34 0.016667 ... 2.585818 1.652185 9.322493e-12 0.217672 ICOSLG; SUMO3 ENSG00000184900 570 False 570 0.292963 ... 4.046776 2.431045 -3.685750e-10 0.723121 SUMO3; SLC19A1 ENSG00000173638 31 False 31 0.018519 ... 3.234231 2.932458 -2.020969e-10 0.173017 SLC19A1; S100B ENSG00000160307 94 False 94 0.076667 ... 3.042992 1.078783 5.994639e-10 0.399946 S100B; PRMT2 ENSG00000160310 588 False 588 0.275926 ... 2.774169 0.629058 -6.100551e-10 0.762753 PRMT2. [1838 rows x 14 columns]; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; >>> adata.var['CD14']; Traceback (most recent call last):; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc; return self._engine.get_loc(key); File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'CD14'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/marcellp/Code/biomage/worker/venv/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__; indexer = self.columns.get_loc(key); File ""/Users/marce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338:2297,Error,Error,2297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338,1,['Error'],['Error']
Availability,3d UMAP memory error on ~1 million cells,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/710:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710,1,['error'],['error']
Availability,3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12684,mask,mask-,12684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```. I saw a relevant [issue](https://github.com/lmcinnes/umap/issues/179) on the umap package and ; even changed line 1138 in [umap_.py](https://github.com/lmcinnes/umap/blob/80f1247de0d60eb60d7222a3cdf9aef9452ab38e/umap/umap_.py) from `embedding` to `embedding..astype(np.float32, copy=True)`, but no success. Any idea?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:2140,error,errors,2140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,2,['error'],"['error', 'errors']"
Availability,"5-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]); ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python; marker_genes = ['PERM1', 'GAB3', 'G6PD']; combined_bbknn.var_names_make_unique(); sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'); ```; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-17-3392793686cd> in <module>; 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']; 2 combined_bbknn.var_names_make_unique(); ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 949 return dp; 950 else:; --> 951",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:2216,error,error,2216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"54-e62d5f8d460c> in <module>; ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1067:1481,error,errors,1481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067,1,['error'],['errors']
Availability,"5cac3.png). Now the code that doesn't work:; ```python; sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); #sc_ax1.get_legend().remove(); sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258:2460,error,error,2460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258,1,['error'],['error']
Availability,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:4322,down,downgrade,4322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,1,['down'],['downgrade']
Availability,"7 ; 10958 return set_function_name(stat_func, name, cls). /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/series.py in _reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds); 3613 # dispatch to ExtensionArray interface; 3614 if isinstance(delegate, ExtensionArray):; -> 3615 return delegate._reduce(name, skipna=skipna, **kwds); 3616 elif is_datetime64_dtype(delegate):; 3617 # use DatetimeIndex implementation to handle skipna correctly. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in _reduce(self, name, axis, skipna, **kwargs); 2179 msg = 'Categorical cannot perform the operation {op}'; 2180 raise TypeError(msg.format(op=name)); -> 2181 return func(**kwargs); 2182 ; 2183 def min(self, numeric_only=None, **kwargs):. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in max(self, numeric_only, **kwargs); 2222 max : the maximum of this `Categorical`; 2223 """"""; -> 2224 self.check_for_ordered('max'); 2225 if numeric_only:; 2226 good = self._codes != -1. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py in check_for_ordered(self, op); 1517 raise TypeError(""Categorical is not ordered for operation {op}\n""; 1518 ""you can use .as_ordered() to change the ""; -> 1519 ""Categorical to an ordered one\n"".format(op=op)); 1520 ; 1521 def _values_for_argsort(self):. TypeError: Categorical is not ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one; ```. I was confused for two reasons:; 1) All of my columns in obs are already converted to pandas ordered categorical data but they are still ""forced"" to be converted again into unordered categorical data;; 2) because the columns are now unordered categorical data , it raised the final error which I did not encounter in earlier versions. . Thanks in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:5010,error,error,5010,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['error'],['error']
Availability,"881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.pr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:2442,error,error,2442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['error']
Availability,"8a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/plotting/_qc.py#L100 it seems to also plot all the Categoricals that are not present in the `counts_top_genes` DataFrame. My temporary hack to fix this is to force my ""gene_symbols"" argument column to be a mixed-object dtype, which drops the Categoricals and renders the boxplot correctly; ```python; if 'gene_symbol' in adata.var.columns and adata.var['gene_symbol'].dtype.name != 'object':; adata.var['gene_symbol'] = adata.var['gene_symbol'].astype('object'); ```. ### Minimal code sample. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. sc.pl.highest_expr_genes(adata, n_top=20, gene_symbols='gene_symbol', show=True, save="".png""); ```. I also tried this with the same results. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. adata.var.index = adata.var.gene_symbol; sc.pl.highest_expr_genes(adata, n_top=20, show=True, save="".png""); ```. ### Error output. ![349265437-b0a6e963-5d56-40e6-9922-5e4a543c08cf](https://github.com/user-attachments/assets/478c6a20-817f-4e39-92a3-62f5c2a62ed0). Above is a boxplot from `sc.pl.highest_expr_genes` that shows all the Categorical genes in addition to the top-20 as specified in the function argument. <img width=""1077"" alt=""Screenshot 2024-07-17 at 1 23 27 PM"" src=""https://github.com/user-attachments/assets/cfbdb40d-57f5-4da6-bf69-b4f4f3c489cc"">. Above is the correct boxplot, after my hack was applied to force the adata.var.gene_symbols to be mixed-object datatype instead of Categorical. ### Versions. <details>. python-3-10-4. ```; aiohttp==3.8.3; anndata==0.10.6; biocode==0.10.0; biopython==1.79; cairosvg==2.7.1; dash-bio==1.0.2; #diffxpy==0.7.4; Flask==3.0.0; Flask-RESTful==0.3.9; gunicorn; h5py==3.10.0; itsdangerous==2.1.2 # See -> https://stackoverflow.com/a/71206978; jupyterlab==4.0.5; jupyter==1.0.0; kaleido==0.2.1; leidenalg==0.10.2; llvmlite==0.41.1; matplotlib==3.9.0; mod-wsgi==4.9.4;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3158:2097,Error,Error,2097,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3158,1,['Error'],['Error']
Availability,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:3497,down,downgrade,3497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['down'],['downgrade']
Availability,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1797:2925,error,errors,2925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797,2,['error'],['errors']
Availability,"; 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5042,error,error,5042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"; 669 min_disp=min_disp,; (...); 672 max_mean=max_mean,; 673 ); 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt2800",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:4719,avail,available,4719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['avail'],['available']
Availability,; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3812,ERROR,ERROR,3812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id); 1289 if library_id is _empty:; 1290 if len(spatial_mapping) > 1:; -> 1291 raise ValueError(; 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify.""; 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}""; 1294 ); 1295 elif len(spatial_mapping) == 1:; 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:; 	['1', '10', '100', '101', '102', '103', '104', '105', '106'...; ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow; in this SquidPy [tutorial](htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2486:1991,avail,available,1991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486,1,['avail'],['available']
Availability,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; The PR uses `1-correlation` as distance matrix to compute the dendrogram as suggested in #1288 and mentioned in https://github.com/theislab/squidpy/pull/236. I opted for the minimal changes to the code. Other solution would be to use `scipy.spatial.distance.pdist` that allows a larger number of distance metrics. I am open for a discussion on this topic (ping @michalk8),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1614:591,ping,ping,591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1614,1,['ping'],['ping']
Availability,"<!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2473:233,error,error,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. After I use function. ```py; adata = sc.read_visium(; './', count_file='V1_Human_Lymph_Node_filtered_feature_bc_matrix.h5',; genome=None, library_id=None, load_images=True,; ); ```. I use `sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True)` and got an error message:. ```pytb; RuntimeError Traceback (most recent call last); ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 744 try:; --> 745 yield; 746 except NumbaError as e:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 485 if isinstance(inst, _class):; --> 486 func(self, inst); 487 return. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _lower_parfor_parallel(lowerer, parfor); 239 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 240 bool(alias_map), index_var_typ, parfor.races); 241 finally:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\parfors\parfor_lowering.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1326 flags,; -> 1327 locals); 1328 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 666 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 667 lifted_from=lifted_from); 668 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 348 FixupArgs().run_pass(self.state); --> 349 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],"['error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. Hi,; I run scanpy in Python 3.7, matplotlib=3.1.1 - `sc.pl.paga_path` gives me the following error(s). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.dpt(adata); sc.tl.paga(adata, groups='paul15_clusters'); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1599 def inner(ax, *args, data=None, **kwargs):; 1600 if data is None:; -> 1601 return func(ax, *map(sanitize_sequence, args), **kwargs); 1602 ; 1603 bound = new_sig.bind(ax, *args, **kwargs). ~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->. Ingest tries to search for the metric used when neighbors was called. When this information is not available it fails. Is there a workaround for this? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc68k_reduced(); adata_ref = sc.datasets.pbmc3k_processed(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # add fake batch; adata_ref.obs['batch'] = pd.Categorical(np.random.choice(a=[0, 1, 2], size=adata_ref.shape[0])). sc.pp.pca(adata_ref); sc.external.pp.bbknn(adata_ref, batch_key='batch'); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; scanpy/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 283 dist_args = (); 284 ; --> 285 self._metric = neighbors['params']['metric']; 286 dist_func = named_distances[self._metric]; 287 . KeyError: 'metric'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev83+g5345a50.d20200506",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201:173,avail,available,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201,2,"['Error', 'avail']","['Error', 'available']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; # neighborhood graph of cells (determine optimal number of PCs here); sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); # compute UMAP; sc.tl.umap(adata); # tSNE; tsne = TSNE( n_jobs=20 ); adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ); adata.write( f_anndata_path ); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing neighbors; using 'X_pca' with n_pcs = 30; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-38-e2dd1fe70ab9> in <module>; 6 sc.settings.n_jobs = 15; 7 with parallel_backend('threading', n_jobs=20):; ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30); 9 ; 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154:518,Error,Error,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:238,error,error,238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,"['down', 'error']","['down', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1136:207,Error,Error,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... AttributeError: 'AnnData' object has no attribute 'obs_vector', when `pl.umap`, `pl.violin`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-41-ed9365d2081e> in <module>; ----> 1 sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],jitter=0.4, multi_panel=True). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 636 obs_df = get.obs_df(adata, keys=[groupby] + keys, use_raw=use_raw); 637 else:; --> 638 obs_df = get.obs_df(adata, keys=keys, use_raw=use_raw); 639 if groupby is None:; 640 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/anaconda3/envs/myenv/lib/python3.7/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 160 for k, l in zip(keys, lookup_keys):; 161 if not use_raw or k in adata.obs.columns:; --> 162 df[k] = adata.obs_vector(l, layer=layer); 163 else:; 164 df[k] = adata.raw.obs_vector(l). AttributeError: 'AnnData' object has no attribute 'obs_vector'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...scanpy==1.4.3 anndata==0.6.20 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.23.4 scikit-learn==0.21.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942:389,Error,Error,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am not sure it's bug or package error. I am getting Segmentation fault error with sc.pp.calculate_qc_metrics with my data. I tried running this on eg. data, and have the same error. I think this might be related to numba issue, but not sure. I did ran python debugger on the script, also attaching the output i got. ; [scanpylog.txt](https://github.com/theislab/scanpy/files/4567012/scanpylog.txt). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,7,"['error', 'fault']","['error', 'errors', 'fault']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 54",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; .../usr/local/lib/python3.6/site-packages/joblib/externals/loky/backend/semaphore_tracker.py:198: UserWarning: semaphore_tracker: There appear to be 6 leaked semaphores to clean up at shutdown; len(cache)). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...gene_trends = d.palantir.presults.compute_gene_trends(pr_res, ; ...: d.imp_df.iloc[:, 0:1000], ['RG']) ; ...: . ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...Segmentation fault (core dumped); ```; it made me out of the python environment.; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; Scanpy version: 1.4.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1223:520,Error,Error,520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1223,2,"['Error', 'fault']","['Error', 'fault']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...; ![image](https://user-images.githubusercontent.com/39158851/82787725-a09c3c80-9e99-11ea-9a09-94e43c114185.png); with adata like this:; ![image](https://user-images.githubusercontent.com/39158851/82787817-d6412580-9e99-11ea-9fc6-2866402b668e.png). and adata.X:; ![image](https://user-images.githubusercontent.com/39158851/82787794-cc1f2700-9e99-11ea-9957-a1b37cbd7881.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1246:581,Error,Error,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...Trying to use `adata.write()` to save a results file - running into the same issue over and over. I tried uninstalling and reinstall both scanpy as well as h5py. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; results_file = 'NG2019_MCF10A2.h5ad'; adata.write(results_file); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; OSError: Unable to create link (name already exists). Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'genes' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'raw/var' of <class 'h5py._hl.files.File'> from /.; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275:424,Error,Error,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275,4,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...When run bbknn on adata which has been calculated the pca, umap, and leiden, the AttributeError shows 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.umap(adata); ...; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:27); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:24); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:01:27). %%time; sc.external.pp.bbknn(adata, batch_key='batch'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; computing batch balanced neighbors; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-9-9b24f504f73c> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', ""sc.external.pp.bbknn(adata, batch_key='batch')""). 6 frames; <decorator-gen-60> in time(self, line, cell, local_ns). <timed eval> in <module>(). /usr/local/lib/python3.6/dist-packages/bbknn/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 63 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 64 ; ---> 65 return distances, connectivities.tocsr(); 66 ; 67 def create_tree(data,approx,metric,use_faiss,n_trees):. AttributeError: 'tuple' object has no attribute 'tocsr'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1249:833,Error,Error,833,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1249,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; ...when I did combat batch correction, it outputs errors. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # ComBat batch correction; sc.pp.combat(adata, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-5-350690ae55dc> in <module>; 1 # ComBat batch correction; ----> 2 sc.pp.combat(adata, key='sample'). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))); 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T); --> 268 bayesdata[batch_idxs] = numer / denom; 269 ; 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (23259,18243) (23259,15479) ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170:124,error,errors,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170,2,"['Error', 'error']","['Error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; After creating a fresh conda environment on Mac OS Mojave and starting to replicate the ""Analysis and visualization of spatial transcriptomics data"" tutorial, after running. ```python; adata = sc.datasets.visium_sge(); ```; I get ; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; FileNotFoundError: [Errno 2] No such file or directory: '/Users/lisa/data/V1_Breast_Cancer_Block_A_Section_1'; ```; I figured it is because the intermediate folder ""/data"" is missing as well - . ```python; sample_dir.mkdir(exist_ok=True); ```; in ```_download_visium_dataset()``` cannot create it, it would need the flag ```parents=True``` to do so (https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir). #### Versions:. scanpy==1.4.7.dev52+g590d4230 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1184:320,Error,Error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1184,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; After running ```sc.pp.combat(adata, key='sample')```, adata.X is full of NaNs and ```sc.pp.highly_variagle_genes(adata)``` fails. No issues (and no NaNs) if NOT running the combat correction. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.combat(adata, key='sample'); sc.pp.highly_variable_genes(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Found 3 genes with zero variance.; Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172:456,Error,Error,456,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172,2,"['Error', 'avail']","['Error', 'available']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; As requested [here ](https://github.com/theislab/scanpy/issues/1172#issuecomment-616818311). It might be of interest to inform the user about the problem or set Combat to ignore that cell/sample...thats for the experts to decide.; In this case scenario, Combat will complete the analysis and yield no errors. However, obviously, subsequent call to ```sc.highly_variable_genes()``` will result in disaster. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1175:375,error,errors,375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1175,3,"['Error', 'avail', 'error']","['Error', 'available', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Console outputs a long list of errors/warnings when running scanpy.pp.combat().; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataCombat = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164:105,error,errors,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164,2,"['Error', 'error']","['Error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; First of all, thank you for your great platform! . When I try to export a SPRING project I get the following error (it seems that the class NeighborsView is not defined; I have a 'neighbors' key in .uns): . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1260:183,error,error,183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Here is my use case: I run rank_genes_groups( ) with rankby_abs=True, as I want both upregulated and downregulated marker genes. Then I run filter_rank_genes_groups to set some thresholds, and all my downregulated genes disappear! . I see two possible solutions; 1) rankby_abs should be an argument for the filter_rank_genes_groups function as well; when rankby_abs=True, then min_fold_change should be interpreted as an absolute value threshold.; 2) filter_rank_genes_groups should follow the behavior of rank_genes_groups. This could be easily implemented if min_fold_change is always used as an absolute value threshold -- if there are only positive fold changes in the .uns['rank_genes_groups'] slot to begin with, only positive fold changes will be returned, and otherwise, both upregulated and downregulated genes will be returned.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1325:175,down,downregulated,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1325,3,['down'],['downregulated']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi I'm trying to run Louvain clustering but I'm getting a module not found error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-43-d2a2f7b009fa> in <module>; ----> 1 sc.tl.louvain(dge_E, flavor='vtraag', resolution=0.5). c:\users\jamie\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi Scanpy team,; I am trying to analyse CTE-seq data. At the nomalization step of the protein data, the attibute normalize_geometric is not recognize. Could this be a version issue?; Thank you for your help!. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.normalize_geometric(protein). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...AttributeError Traceback (most recent call last); <ipython-input-80-db93ca6d0f1d> in <module>; ----> 1 sc.pp.normalize_geometric(protein). AttributeError: module 'scanpy.preprocessing' has no attribute 'normalize_geometric'. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev30+g668b6776 anndata==0.7.1 umap==0.3.10 numpy==1.16.2 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1208:438,Error,Error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap.; I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this?. ////; import scanpy.external as sce. sam_obj = sce.tl.sam(adata); sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'); #does this change the umap? or do I need to make another call of tl.umap?. sc.pl.umap(sam_obj, color='Sample') ; ////; i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. import scanpy.external as sce; for adata in adatalist:; sam_obj = sce.tl.sam(adata); sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ... Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.016564277393631113; Iteration: 1, Convergence: 0.01278454723440345; Computing the UMAP embedding...; Elapsed time: 50.534051179885864 seconds; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-17-4514ae92b370> in <module>; 1 import scanpy.external as sce; 2 for adata in adatalist:; ----> 3 sam_obj = sce.tl.sam(adata); 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157:378,error,error,378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Hi,. not really a bug, more of a documentation issue: ; `sc.tl.rank_genes_groups` seems to expect log-transformed data (be it in `.X` or `.raw.X`).; To my knowledge this is **not mentioned in the docs**. I just ran into trouble and then found out via #671 and #517 . . It's not a problem for the p-values (if the data is not log-transformed it just does the t-test etc on the counts), but the resulting fold-changes are wrong (it essentially tries to undo the expected log-transform):; ```python; foldchanges = (np.expm1(mean_group) + 1e-9) / (np.expm1(mean_rest) + 1e-9); ```; I was totally unaware of this (been using scanpy for quite a while), especially since I usually store the plain raw counts in the `adata.raw` field, which is used *by default* in `rank_genes_groups`. We should at least mention it in the docstring, but these things are easy to overlook too...; Is there any way that scanpy records the transformations you've done to the data (and if the log is missing, just spits out an error in rank_genes_groups)?. Also, is there a ""best-practice"" guide of what data to store in which parts of the AnnData objects?; `.raw` and the `.layer` dont have a lot of documentation. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/967:1073,error,error,1073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/967,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; #what works:; marker_genes = ['NCAM1']; ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:; subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > 1.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/999:587,Error,Error,587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am trying to integrate data using ingest. I followed exactly the same steps and scripts as described in the scanpy tutorial. However, I got the error message that ‘UMAP’ object has no attribute ‘_input_distance_func’ every time when I ran the command of sc.tl.ingest(adata, adata_ref, obs=‘louvain’). I have the same problem even with using the example pbmc3k_processed and pbmc3k_processed as in the tutorial. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(); var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref). # problem occurs here; sc.tl.ingest(adata, adata_ref, obs='louvain'); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; AttributeError Traceback (most recent call last); <ipython-input-12-27e22cc8f823> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). 3 frames; /usr/local/lib/python3.6/dist-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181:220,error,error,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I am using scanpy with pyscenic. I am able to use tsne with rep ""X_pca"", but when I try to use a custom rep (X_aucell) to create a tsne plot, the kernel dies and Python also crashes. I can also use U-map with rep X_aucell. I have been able to use tsne with rep aucell on larger datasets in the past, so I have a hard time believing it's a memory issue. I'm really lost on what is causing this. I have restarted my computer and jupyter multiple times. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.tsne(adata, use_rep='X_aucell'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; computing tSNE; using the 'MulticoreTSNE' package by Ulyanov (2017). Kernel Restarting ; The kernel appears to have died. It will restart automatically; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1291:688,Error,Error,688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1291,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I have `pytorch` and `scanpy` installed inside a conda environment. When I want to import scanpy **after** torch, the import won't finish. The interesting part is that importing scanpy before torch is possible! For example, this code takes a long time and probably does not finish:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import torch; import scanpy; ```. But the following example works:. ```python; import scanpy; import torch; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 pytorch==1.1.0 torchvision==0.3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1286:589,Error,Error,589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1286,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>; switch_backend(rcParams[""backend""]); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__; plt.switch_backend(rcsetup._auto_backend_sentinel); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend; switch_backend(candidate); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166:209,error,error,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I installed the package by `pip install scanpy`. When I imported it, there was such an error. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/__init__.py"", line 36, in <module>; from . import tools as tl; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables; File ""/sibcb1/mxqianlab1/common/anaconda/envs/cnmf_env/lib/python3.6/site-packages/tables/__init__.py"", line 93, in <module>; from .utilsextension import (; ImportError: libblosc.so.1: cannot open shared object file: No such file or directory. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > version 1.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1284:161,error,error,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1284,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_cells(adata, min_counts=300); sc.pp.filter_genes(adata, min_counts=1); sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'); sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'); sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells; print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; True; False; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24.; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1083:721,Error,Error,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I was plotting the paga path, I got the error of TypeError: float() argument must be a string or a number, not 'csr_matrix'. I guess this might be related with the sparse format of adata.raw.X, because my codes works if I deleted adata.raw. What would be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 excep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I was using the sc.pl.rank_genes_groups_violinfunction and got the error:. ```; Exception Traceback (most recent call last); <ipython-input-195-8f87448845a3> in <module>; 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); ----> 2 sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=1). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 727 if issparse(X_col): X_col = X_col.toarray().flatten(); 728 new_gene_names.append(g); --> 729 df[g] = X_col; 730 df['hue'] = adata.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.queries.enrich([float('nan')]); ```; Output:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; AssertionError: query failed with error 500; ```. #### Versions:; ```; scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1043:1014,Error,Error,1014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated.; ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; scv.tl.umap(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-391fc8667646> in <module>; ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 125 start = logg.info('computing UMAP'); 126 ; --> 127 neighbors = NeighborsView(adata, neighbors_key); 128 ; 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key); 667 self._dists_key = self._neighbors_dict['distances_key']; 668 ; --> 669 if self._conns_key in adata.obsp:; 670 self._connectivities = adata.obsp[self._conns_key]; 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1125:341,Error,Error,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125,3,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. ; So if I issue; ```python; import scanpy as sc; import graph_tool.all as gt; ```; I get. ```python; ImportError: dlopen: cannot load any more object with static TLS ; ```; error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121:721,error,error,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; In the `sc.tl.dendrogram` module, I noticed that the correlation matrix was directly inputted into the `scipy.cluster.hierarchy.linkage`. That results in calculating the distance between samples by the Euclidean(X1_cor_with_others, X2_cor_with_others). Shouldn't the distance be the pure correlation value here? Please correct me if I didn't understand it correctly. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; The one I would perfer; ```python; df = 1-adata.uns['dendrogram_sample']['correlation_matrix']; data_linkage = hierarchy.linkage(ssd.squareform(; df); ...; ```; The one currently in sc.tl.dendrogram; ```python; data_linkage = hierarchy.linkage(adata.uns['dendrogram_sample']['correlation_matrix']); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1288:858,Error,Error,858,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`.; The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:; **Solution A**: Change requirements to `anndata>=0.7rc1`; **Solution B**: Add function to anndata:; ```python; def isview(self):; return self.is_view(); ```; I think solution B is preferable as it provides back-compatibility of anndata. ---; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; import scanpy as sc; adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-2-59eff31dcd22> in <module>; 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'); 2 import scanpy as sc; ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id); 368 ; 369 # read h5 file; --> 370 adata = read_10x_h5(files['counts']); 371 adata.var_names_make_unique(); 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only); 169 if gex_only:; 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]; --> 171 if adata.is_view:; 172 return adata.copy(); 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1027:178,error,error,178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Not able to install with conda and no info about the source of error.; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```bash; (scrna) $ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: | ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1190:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190,2,"['Avail', 'error']","['Available', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb; AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'); adata = adata.transpose(); adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values; adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...; **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1143:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; adataMNN = sc.read_h5ad(results_file); sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'); var_select = adataMNN.var.highly_variable_nbatches > 1; var_genesMNN = var_select.index[var_select]; datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]; sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167:162,error,error,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Running ```sc.pp.regress_out(adata, ['n_counts'])``` or in any other obs, it outputs error on the ""first guess"". I have used the function before with no problems. So I am not sure where the issue is now (I have updated to the latest version of Scanpy 2 days ago...but I dont know if it has anything to do with it). I have followed the steps in this [tutorial](https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb).; I must add that this ```adata``` object is a subset of all cells created by keeping only the cells that express the gene Crabp1, as follows:; ```adata = adata_full[adata_full.obs['Crabp1_cell'] == 'True']```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pp.regress_out(adata, ['n_counts']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pp.regress_out(adata, ['n_counts']); regressing out ['n_counts']; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/families/family.py:179: RuntimeWarning: invalid value encountered in true_divide; return np.sum(resid_dev * freq_weights * var_weights / scale); Traceback (most recent call last):. File ""<ipython-input-6-4693dee26417>"", line 1, in <module>; sc.pp.regress_out(adata, ['n_counts']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 841, in regress_out; res = list(map(_regress_out_chunk, tasks)). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 867, in _regress_out_chunk; result = sm.GLM(data_chunk[:, col_index], regres, family=sm.families.Gaussian()).fit(). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/statsmodels/genmod/generalized_linear_model.py"", line 1027, in fit; cov_kwds=cov_kwds, use_t=use_t, **kwargs). File ""/home/auesro/anaconda3/envs/Sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1171:159,error,error,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ##still working fine; sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names. pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); ##gives error; sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3169 try:; -> 3170 value = Series(value); 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 273 data = _sanitize_array(data, index, dtype, copy,; --> 274 raise_cast_failure=True); 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure); 4160 if isinstance(data, np.ndarray):; -> 4161 raise Exception('Data must be 1-dimensional'); 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-23-ccdbf8b7836c> in <module>; ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:139,error,errors,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,4,"['Error', 'error']","['Error', 'error', 'errors']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; The bug is just like the title of issue, _AttributeError: module 'scanpy' has no attribute 'anndata'_, for I just wanna to load a h5ad file from Tabula-Muris dataset; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. data = sc.anndata.read_h5ad(''tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'); ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):. File ""<ipython-input-91-67a79760d7cb>"", line 1, in <module>; sc.anndata.read_h5ad('tabula-muris-senis-facs-processed-official-annotations-Bladder.h5ad'). AttributeError: module 'scanpy' has no attribute 'anndata'; ```; #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.3 anndata==0.6.19 umap==0.3.10 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1322:487,Error,Error,487,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1322,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; The y-scale label on the right of the stacked_violin is missing in the version of 1.5.2.dev. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; sc.pl.stacked_violin(pbmc,marker_genes,groupby='louvain',row_palette='muted',figsize=(7,4),log=False); sc.logging.print_versions(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![download](https://user-images.githubusercontent.com/30639029/87759504-434ea880-c7c3-11ea-9c3a-b59e027ffeb6.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev123+g0cf308c anndata==0.7.3 umap==0.4.4 numpy==1.18.5 scipy==1.4.1 pandas==1.0.4 scikit-learn==0.23.1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1321:562,Error,Error,562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1321,2,"['Error', 'down']","['Error', 'download']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pip install git+https://github.com/theislab/scanpy.git@spatial; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Collecting git+https://github.com/theislab/scanpy.git@spatial; Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3; Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3; WARNING: Did not find branch or tag 'spatial', assuming revision or ref.; Running command git checkout -q spatial; error: pathspec 'spatial' did not match any file(s) known to git.; ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1104:145,error,error,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104,5,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error', 'errored']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Trying to make a violin plot adding the seaborn hue argument will result in ValueError.; In adata, 'timepoint' and 'replicate' are categorical adata.obs containing floats and ints, respectively. 'timepoint' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and 'replicate' the number of the replica (1, 2, 3). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'); Traceback (most recent call last):. File ""<ipython-input-5-756b321177a2>"", line 1, in <module>; sc.pl.violin(adata, 'n_genes', jitter=0.4, groupby = 'timepoint', stripplot=False, hue='replicate'). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 759, in violin; **kwds,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 2393, in violinplot; color, palette, saturation). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 559, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py"", line 152, in establish_variables; raise ValueError(err). ValueError: Could not interpret input 'replicate'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1174:626,Error,Error,626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1174,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:; ```; >>> sc.pl.umap(post_adata, color=['XKR4']); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap; return embedding(adata, 'umap', **kwargs); File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding; use_raw=use_raw, gene_symbols=gene_symbols,; File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values; values = adata.raw.obs_vector(value_to_plot); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector; idx = self._normalize_indices((slice(None), k)); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices; var = _normalize_index(var, self.var_names); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index; return name_idx(index); File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx; .format(i)); IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```; However, the gene XKR4 did exist in the var_names:; ```; >>> post_adata.var_names; Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',; 'OPRK1', 'NPBWR1',; ...; '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',; 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],; dtype='object', length=16249); ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```; >>> post_adata; AnnData object with n_obs × n_vars = 88291 × 16249; obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039:191,error,error,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039,1,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I use `sc.pp.log1p(adata)` and then `sc.pp.log1p(adata, layer='other')` it warns me that the data has already been logged even though I am logging a layer as opposed to adata.X. Would be nice to flag logging for each layer instead of when anything is logged. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); adata.layers['other'] = adata.X; sc.pp.log1p(adata, layer='other'); sc.pp.log1p(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; WARNING: adata.X seems to be already log-transformed.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.3 umap==0.3.10 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1333:611,Error,Error,611,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1333,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When I use the `scanpy.datasets.ebi_expression_atlas`, I got an error `HTTP Error 500: `. My python version is 3.6.10, and I also reproduced it on google colab. ; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,4,"['Down', 'Error', 'error']","['Downloaded', 'Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When i use umap with the parameter init_pos='paga', I got a strange result.; ![image](https://user-images.githubusercontent.com/20806068/68834273-5703b580-06f0-11ea-9d05-76a66ea9e943.png). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pl.umap(adata,color='louvain'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; no error; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.4 anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.3 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918:422,Error,Error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; When trying to get the obs_df or the var_df, the function throws an error when there is a single key. In this case it iterates through the letters in the given key and causes a KeyError. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```; pbmc = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(pbmc, keys=('HES4')); sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-60-663347265b80> in <module>; ----> 1 sc.get.var_df(pbmc, keys=('AAAGCCTGGCTAAC-1')). ~/.conda/envs/scvelo_updated/lib/python3.8/site-packages/scanpy/get.py in var_df(adata, keys, varm_keys, layer); 223 not_found.append(key); 224 if len(not_found) > 0:; --> 225 raise KeyError(; 226 f""Could not find keys '{not_found}' in columns of `adata.var` or""; 227 "" in `adata.obs_names`."". KeyError: ""Could not find keys '['A', 'A', 'A', 'G', 'C', 'C', 'T', 'G', 'G', 'C', 'T', 'A', 'A', 'C', '-', '1']' in columns of `adata.var` or in `adata.obs_names`.""; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1315:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315,2,"['Error', 'error']","['Error', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-125-322839e541fd> in <module>; ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 530 X = adata_comp.X; --> 531 X_pca = pca_.fit_transform(X); 532 ; 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032:133,down,downstream,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032,3,"['Error', 'down', 'error']","['Error', 'downstream', 'error']"
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; Yesterday I moved to a new server and I had to install miniconda3, Jupiter and all the necessary modules for my scRNA-seq analysis including scanpy. I can read fine an h5ad file and run various steps with scanpy and I can then save the object as an h5ad file and read it back without a problem. However, if I run the rank_genes_groups function, even though I can perfectly fine save my object as an h5ad file I get an error when I am attempting to read it back. I have to say that this exact piece of code used to work with my older modules before updating it. Also, some people seem to have spotted a similar error in the newest numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:492,error,error,492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,2,['error'],['error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; _ingest.py tries to import the UMAP function like so:; `from umap import UMAP`; I believe this is wrong, and it should be replaced with:; `from umap.umap_ import UMAP`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ImportError: cannot import name 'UMAP' from 'umap' (/opt/anaconda3/lib/python3.7/site-packages/umap/__init__.py); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1202:257,Error,Error,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; `wx` appears to be a missing scanpy dependancy linked to matplotlib when installing on macOS. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; >>> import scanpy as sc; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>; from . import plotting as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix; File ""/miniconda3/envs/path/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>; from matplotlib import pyplot as pl; File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2282, in <module>; switch_backend(rcParams[""backend""]); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend; backend_mod = importlib.import_module(backend_name); File ""/miniconda3/envs/path/lib/python3.7/importlib/__init__.py"", line 127, in import_module; return _bootstrap._gcd_import(name[level:], package, level); File ""/miniconda3/envs/path/lib/python3.7/site-packages/matplotlib/backends/backend_wxagg.py"", line 1, in <module>; import wx; ModuleNotFoundError: No module named 'wx'; ```. The solution is simple, install `wxPython` https://pypi.org/project/wxPython/. However, it would be nice if scanpy could handle this OS-specific dependancy. #### Versions:; The latest scanpy version (1.5.1) installed via conda- of course I cannot print the versions since the scanpy import fails, other details;. ```; >>> import sys; print(sys.version); 3.7.6 | p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1302:317,Error,Error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1302,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; here is the code for marker filter; I think the 3 condition need to be OR instead of AND; gene_names = gene_names[; (fraction_in_cluster_matrix > min_in_group_fraction) &; (fraction_out_cluster_matrix < max_out_group_fraction) &; (fold_change_matrix > min_fold_change); ]. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213:476,Error,Error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; sc.pl.tracksplot, produce a wrong highlight bar without brackets. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; pbmc = sc.datasets.pbmc68k_reduced(); marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']; ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain',; var_group_positions=[(0,2),(4,5)],var_group_labels=['set1','set2']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ![image](https://user-images.githubusercontent.com/30639029/83604801-9dedb700-a52b-11ea-9c32-fc35ea959d61.png). #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.4.7.dev136+g7f5c907 anndata==0.7.1 umap==0.4.1 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1265:512,Error,Error,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1265,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))); sc.pp.pca(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca; X_pca = pca_.fit_transform(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform; U, S, V = self._fit(X); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated; raise ValueError(""n_components=%r must be between 1 and ""; ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051:385,Error,Error,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051,1,['Error'],['Error']
Availability,"<!-- Please give a clear and concise description of what the bug is: -->; trying to run louvain clustering but got the error:. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-fe1390cdc24a> in <module>; ----> 1 sc.tl.louvain(adata, resolution=1.0). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 136 partition_kwargs[""weights""] = weights; 137 logg.info(' using the ""louvain"" package of Traag (2017)'); --> 138 louvain.set_rng_seed(random_state); 139 part = louvain.find_partition(; 140 g, partition_type,. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/louvain/functions.py in set_rng_seed(seed); 23 def set_rng_seed(seed):; 24 """""" Set seed for internal random number generator. """"""; ---> 25 _c_louvain._set_rng_seed(seed); 26 ; 27 def find_partition(graph, partition_type, initial_membership=None, weights=None, **kwargs):. AttributeError: module 'louvain._c_louvain' has no attribute '_set_rng_seed'; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.tl.louvain(adata, resolution=1.0); ```. Python 3.7. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one?; Can I have all them in my h5ad object and how to switch between them?; In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1875:537,down,downstream,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [✔] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm wondering whether it is possible to show the downregulated marker genes by sc.pl.rank_genes_groups() or other functions, so that we can export the gene list for further GSEA analysis?; I know sc.pl.rank_genes_groups_dotplot can show the downregulated genes by change n_genes to negative numbers, but it didn't work in sc.pl.rank_genes_groups().; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2052:533,down,downregulated,533,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052,2,['down'],['downregulated']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2107:704,avail,available,704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107,1,['avail'],['available']
Availability,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [✔] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hello Scanpy,; I'm not sure whether Scanpy already has this function. For example, if we have `query` and `ref` data, we can use `ingest` to map the `query` onto the embedding of `ref`. Then, we can get similar UMAPs between these 2 data and do downstream analysis (like scVelo) based on these 2 UMAPs (coding below). In this way, because the UMAP is similar, we can have a more clear answer about how different these 2 date is.; ```python; ref = sc.read('ref.h5ad'); query = sc.read('query.h5ad'); var_names = query.var_names.intersection(ref.var_names); query = query[:, var_names]; ref = ref[:, var_names]; sc.tl.ingest(adata=query, adata_ref=ref, obs='leiden'); sc.pl.umap(query, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False) # this step will generate new obs['leiden'] and obsm['X_umap'] for query, which is a similar embedding with ref. adata = sc.read_loom(filename='queryraw.loom'); adata.obs['leiden']=query.obs['leiden'] # copy ingested leiden to raw data; adata.obsm['X_umap']=query.obsm['X_umap'] # copy ingested X_umap to raw data; # then do scVelo on this adata by using this embedding.; ```. However, `ingest` doesn't remove the batch effect. `BBKNN` does. After `BBKNN`, both `query` and `ref` will have new UMAPs stored at the same obsm['X_umap']. I'm wondering whether it is possible to split these 2 UMAPs? For example, store `query` UMAP in obsm['X_query_umap'] and `ref` UMAP in obsm['X_ref_umap'] so that we can copy each into a raw data. ![image](https://user-images.git",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2123:719,down,downstream,719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2123,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; ...; It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1139:561,error,error,561,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1829:896,robust,robust,896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829,1,['robust'],['robust']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. When we visualize gene expression, range of colorbar can be different. ![image](https://user-images.githubusercontent.com/30337666/89102749-a6d10b00-d43e-11ea-99f7-0867f3c31d13.png). Usually, it's fine. But if we want to compare gene expression in control-treat experiment in single-cell level, sometimes this happens. ![image](https://user-images.githubusercontent.com/30337666/89102998-08927480-d441-11ea-9068-3d7f09ab26a3.png)![image](https://user-images.githubusercontent.com/30337666/89103003-1942ea80-d441-11ea-8a6f-091a6cd2f19b.png). It's hard for us to estimate up or down regulation of this gene in different group of cells because colors with same value in the two figures are not consistent. Plotting the two figures with same colorbar range can solve it. So, I want to know that are there parameters solving it in scanpy.pl.umap or some matplotlib methods that can be integrated with Scanpy?. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1352:1045,down,down,1045,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1352,1,['down'],['down']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi scanpy develovepers,. A rotation student asked me what is `sc.pl.umap` showing if `sc.tl.umap` was not computed beforehand. To which I don't have the answer since I have never done it. If you know the answer I'd like to know it, but most importantly, I think it would be nice to have an error message in the UMAP plotting function if UMAP has not been computed. Unless there were meaning and a reason to use `sc.pl.umap` without running `sc.tl.umap` previously, and it was designed that way purposely. I assume this would apply to other plotting functions too. Thanks!; Alejandro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460:764,error,error,764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460,1,['error'],['error']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2249:684,error,error,684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249,2,"['down', 'error']","['downsides', 'error']"
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: ; - Cluster cells based on endogenes; - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. ; I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:; ```; sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ?; ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1500:999,down,downstream,999,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500,1,['down'],['downstream']
Availability,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; When testing for differential genes among groups with `rank_genes_groups` function, two options are available for `reference`: `'rest'` or any other single group. It would be helpful to have the possibility to choose different groups as reference (`reference: Union[Literal['rest'], Iterable[str]] = 'rest'`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/984:569,avail,available,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/984,1,['avail'],['available']
Availability,"<!-- What kind of feature would you like to request? -->; How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)?; - [ +] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy?. Thank you very much in advance; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2448:332,avail,available,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448,1,['avail'],['available']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Only check the following box if you did not include release notes -->. ## TODO:. - [x] Fix tests; - [x] Figure out PCA test case with anndata 0.8.0; - [x] Add CI job; - [x] Rename CI job to be less similar to minimal dependencies, this will probably be `MinVer`; - [x] Bump anndata requirement back down to 0.7.3 (breaks dask tests); - Maybe 0.8 is low enough?; - [x] Bump pandas requirement back down to 1.5 (breaks grouped plots ordering). ## Some thoughts. * Sibling PR to: https://github.com/scverse/anndata/pull/1314; * Not completley sure what to do about plotting tests yet. Possible we just ignore any comparison failures, but ideally we could still know if these are broken.; * Metric consistency test failure is from https://github.com/scverse/scanpy/issues/2688; * Test updates in https://github.com/scverse/scanpy/pull/2705 (plus bumping one test a little lower) fixes it. <!-- Please check (“- [x]”) and fill in the following boxes -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816:538,down,down,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816,4,"['down', 'failure']","['down', 'failure', 'failures']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes # _no existing issue_; - [ ] Tests included or not required because: _No new tests_; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: _I did not write release notes_. Hi :). I am proposing a change that speeds up `filter_cells` (x1000 speedup) and `filter_genes` (x2 speedup) for CSR sparse matrices. On my personal machine for 1M cells, `sc.pp.filter_cells(adata, min_genes=xx)` runs in 1ms instead of 10s currently. The speedup should be even stronger on sparser modalities like ATAC. In spirit, this simply replaces `np.sum(X > 0, axis=axis)` with `X.getnnz(axis=axis)`, which is much more efficient. But the axis argument in `getnnz` in `csr_array` may be deprecated. I think it should still be fine with `csr_matrix`, but since I don't know for sure I manually implemented it for the CSR case as in https://github.com/scipy/scipy/issues/19405 . What do you think?. Regarding `getnnz`: Of course it would be nicer to be able to write `.getnnz(axis=axis)`, which extends beyond CSR to other sparse matrices. Can we assume that we're getting sparse matrices and not sparse arrays ?. Pinging @dschult from the Scipy issue liked above, who mentioned: . > I'm pretty sure that a reasonable and commonly occuring use-case would be enough to make the developers include this feature somehow. (edited because I confused `csr_array` and `csr_matrix`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2772:1467,Ping,Pinging,1467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772,1,['Ping'],['Pinging']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #1263; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`; * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`; * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values; - [ ] Test sort_order argument deprecation; - [ ] Add support for `pd.Series` array values.; - [ ] Maybe `list`s?; - [ ] ""How to"" or modify existing advanced plotting tutorial; - [ ] Tests for; - [ ] Categorical ordering; - [ ] None is same as `np.arange(N)`; - [ ] direct overlap + ordering is equivalent to masking; - [ ] Continuous ordering; - [ ] ""ascending"" is like `np.argsort(values)` and vice versa; - [ ] ""ascending"" is like ""descending"" for inverted values; - [ ] Check masking for both; - [ ] Errors; - [ ] For incorrectly sized input array; - [ ] incorrect non-array input; - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2998:1249,mask,masking,1249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998,3,"['Error', 'mask']","['Errors', 'masking']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because: n_components must be less or equal to the number of samples, otherwise it would throw an error, for example, ValueError: n_components=100 must be less or equal to the batch number of samples 40. This error usually happens on the last chunk of the partial_fit.; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:. For example, my adata.shape[0] is 1041 and I run IncrementalPCA `sc.tl.pca(adata, n_comps=100, chunked=True,chunk_size=1000)`, and I got an error: ValueError: n_components=100 must be less or equal to the batch number of samples 40 on scanpy/preprocessing/_pca.py:256",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3313:450,error,error,450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3313,3,['error'],['error']
Availability,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2757:399,failure,failure,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757,2,['failure'],['failure']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts I’m not 100% sure about removing are; - “When to make a pre-release” – I feel like “if UR unsure, make one of these” wasn’t helping here either, so maybe that should just be fleshed out as a section now we’re down a few sections; - “Check the file contents of the wheel” should probably go into “how to code review a PR that touches the build process”, and we don’t have any other guides on how to do code reviews, so …",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720:960,down,down,960,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720,1,['down'],['down']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~ – still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2705:808,toler,tolerances,808,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705,1,['toler'],['tolerances']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2836; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev change. Changes:; - Removes import-time change to globals:; 	- `matplotlib.testing:setup` should be called before each (plotting) test; 	- `sc.set_figure_params(dpi=40, color_map=""viridis"")` seems to be overwritten. When calling it inline, it messes up the figure params; 	- `sc.pl.set_rcParams_defaults()` is redundant, `setup` from above does that.; - Use workaround from https://github.com/pytest-dev/pytest/issues/11759#issuecomment-1888888146",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2838:799,redundant,redundant,799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2838,1,['redundant'],['redundant']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3051; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. TODO:. - [x] release notes; - [x] some added text explaining things; - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest; 2. run internet tests in CI; 1. add caching to CI; 2. make sure the dataset functions don’t download already-downloaded data; 3. validate cached data instead; 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060:880,down,download,880,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060,2,['down'],"['download', 'downloaded']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3226; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. An alternative would be to subclass `PCA`, but that would involve erroring out or reimplementing all of its options. Ideally #3267 would be merged first and this one integrated into its improved decision tree.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3263:552,error,erroring,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263,1,['error'],['erroring']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3260; - [x] Tests included or not required because: minor change to maintain compat with `statsmodels`>=14.0. Inspired by @mwaskom's [fix for seaborn](https://github.com/mwaskom/seaborn/pull/3356), which promotes the warning to an error and catches it (in this case with the same logic `scanpy` was using for prior versions of `statsmodels`).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275:544,error,error,544,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes error if the `log1p` dict doesn't have a `base` key. Fixes https://github.com/scverse/scanpy/issues/2497, fixes https://github.com/scverse/scanpy-tutorials/issues/65, fixes https://github.com/scverse/scanpy/issues/2181",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2546:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....); * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (“- [x]”) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2999:244,Error,Error,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999,1,['Error'],['Error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hi,; We are submitting PR for speed up of the _get_mean_var function. ; | | Time(sec)|; | -----------| ----- |; | Original | 18.49 |; | Updated | 3.97 |; | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge. ```py; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To redu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3099:783,Down,Downloading,783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Pandas was throwing a warning:. `FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.`. This fixes that warning. The fix is a little weird, but it's what pandas says to do. Pandas explanation of the new behaviour is [here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v2.1.0.html#new-implementation-of-dataframe-stack). Changes here:. `rank_genes_group_df`. * The sort order doesn't matter here since we sort again anyways; * `dropna=True` here actually doesn't drop null values from `filter_rank_genes_groups`. AFAICT, this doesn't change anything. `StackedViolin`. Here, we were already opting in to the future behaviour with `dropna=False`. ------. This also fixes a type signature for `sc.get.rank_genes_groups_df` and makes a better error reporting for a test I saw fail locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2864:1184,error,error,1184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2864,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python; if isinstance(arg1, AnnData) and arg1.isbacked:; raise NotImplementedErrror(...); ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #3004 and closes #2894; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048:260,error,errors,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048,1,['error'],['errors']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This adds the missing bibtex formatter from my review in #2901. Since this PR is necessary to productively work with the bibliography without making a mess, and y’all are on a hackathon, I’ll merge it without review. ## Content. - Replace frail line based inclusions like `:end-line: 32` with markers. If someone destroys a marker, the doc build will fail instead of containing a garbled mess.; - Moves the flit-centric dev docs to non-opinionated tooling; - Since there are no functional bib formatters that run within pre-commit (See https://github.com/ge-ne/bibtool/issues/58), we’re going to have to live with using our own. For that purpose, I took the last open source version of `betterbib` and trimmed it down a bit. Once there’s something better that we don’t have to maintain, we should use that. Companion PR: https://github.com/scverse/scanpy-tutorials/pull/103",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2983:947,down,down,947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2983,1,['down'],['down']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2590:1357,Mask,Mask,1357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590,1,['Mask'],['Mask']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1999:572,error,error,572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999,1,['error'],['error']
Availability,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061:812,Down,Downloading,812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2110:703,down,downstream,703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110,1,['down'],['downstream']
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2155:424,down,downsampling,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155,2,"['down', 'robust']","['downsampling', 'robustness']"
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, . I am hoping to open a pull request soon to add [CellO](https://www.cell.com/iscience/fulltext/S2589-0042(20)31110-X), a cell type classification tool, to Scanpy's external API. I notice that there currently are no cell type classification tools available in Scanpy's external API. . I am wondering if there is an explicit reason no cell type classifiers have been added to date? For example, I noticed some debate regarding how/whether to include expression imputation into Scanpy [https://github.com/theislab/scanpy/issues/189](https://github.com/theislab/scanpy/issues/189), and I just want to make sure there is no such reason why cell type classifiers have not been included yet. Thank you!. Matt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1631:428,avail,available,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1631,1,['avail'],['available']
Availability,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1908:330,down,down-sampled,330,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908,1,['down'],['down-sampled']
Availability,<details>; <summary> Errors look like: </summary>. ```; FAILED scanpy/tests/test_highly_variable_genes.py::test_runs - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_supports_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_batch_matches_batch - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[numpy_ndarray-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csr-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[scipy_csc-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-single] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_no_inplace[dask_array_dense-batched] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_highly_variable_genes.py::test_compare_to_upstream[seurat-hvg] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_pca.py::test_pca_sparse - ValueEr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:21,Error,Errors,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['Error'],['Errors']
Availability,"<details>; <summary> Traceback from readthedocs: </summary>. ```pytb; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build; self.write(docnames, list(updated_docnames), method); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write; self._write_serial(sorted(docnames)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial; self.write_doc(docname, doctree); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1057:310,avail,available,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057,3,"['avail', 'error']","['available', 'errors']"
Availability,"=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; biothings_client 0.3.0; brotli NA; cairo 1.23.0; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4229,down,down,4229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['down'],['down']
Availability,"===========================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:2844,toler,tolerance,2844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['toler'],['tolerance']
Availability,"> . Hi, @jlause . There's a issue when using `normalize_pearson_residuals`, it seems that we can't calculated the `log2foldchange` in `rank_genes_groups` will be failed. That's because `np.expm1` can't restore the `adata.X` after `normalize_pearson_residuals`. Could you solve this issue that completed the downstream currently?. <img width=""770"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/46667721/a8e64ab1-360d-43a2-a07b-a766049bcbcd"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2501:307,down,downstream,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2501,1,['down'],['downstream']
Availability,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. ; ### Minimal code sample. ```python. import scanpy; import numpy; > ; tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'); sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>; <summary> traceback </summary>. ```pytb; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160:468,error,error,468,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160,2,['error'],"['error', 'errors']"
Availability,"@Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb; ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------; running ingest; ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/tools/_ingest.py:270: in __init__; self._init_neighbors(adata); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 ; uns: 'neighbors', 'umap'; obsm: 'X_umap'. def _init_neighbors(self, adata):; from umap.distances import named_distances; > from umap.nndescent import (; make_initialisations,; make_initialized_nnd_search,; ); E ImportError: cannot import name 'make_ini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036:70,error,errors,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036,2,"['avail', 'error']","['available', 'errors']"
Availability,"@falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190; [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037; [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7; [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681; [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189:211,avail,available,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189,2,['avail'],['available']
Availability,"@fidelram @gokceneraslan I'm opening this issue to talk about the broken doc builds. Previously discussed in: https://github.com/theislab/scanpy/pull/1204#issuecomment-654765480 and https://github.com/theislab/scanpy/pull/1210#issuecomment-651510328. I'm able to see the errors, but that might be due to privileges for readthedocs. Are you able to look at any PR error logs?. Anyways, the docs fail with this traceback:. <details>; <summary> Traceback </summary>. ```. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204"" is shallow and may cause errors; warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)); /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/docs/conf.py:112: RemovedInSphinx40Warning: The app.add_stylesheet() is deprecated. Please use app.add_css_file() instead.; app.add_stylesheet('css/custom.css'). Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 280, in build_main; app.build(args.force_all, filenames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/application.py"", line 348, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307:271,error,errors,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307,4,['error'],"['error', 'errors']"
Availability,"@fidelram. Related to changes made in #794. . If a categorical column is passed in color, but maximum and minimum colors are passed as functions or strings, an error is thrown. It looks like the same error in each case. I think we just need some logic saying to only try and set vmin and vmax for numeric values. ## Example. Setup. ```python; import scanpy as sc; import numpy as np; from functools import partial. pbmc = sc.datasets.pbmc68k_reduced(); ```. Passing a function. ```python; sc.pl.umap(pbmc, color=[""bulk_labels"", ""HES4""], vmax=partial(np.quantile, q=0.99)); ```. <details>; <summary> Traceback </summary>. ```python; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); <ipython-input-13-83df06d6a2e8> in <module>; ----> 1 sc.pl.umap(pbmc, color=[""bulk_labels"",""HES4""], vmax=""p99""). ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 436 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 437 """"""; --> 438 return embedding(adata, 'umap', **kwargs); 439 ; 440 . ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 230 ; 231 # check vmin and vmax options; --> 232 kwargs['vmin'], kwargs['vmax'] = _get_vmin_vmax(vmin, vmax, count, color_vector); 233 ; 234 # make the scatter plot. ~/github/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_vmin_vmax(vmin, vmax, index, color_vector); 390 f""correct format for percentiles.""); 391 # interpret value of vmin/vmax as quantile with the following syntax 'p99.9'; --> 392 v_value = np.percentile(color_vector, q=float(v_value[1:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800:160,error,error,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800,2,['error'],['error']
Availability,"@flying-sheep @falexwolf ; ; [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about); * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1144:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144,4,['error'],['error']
Availability,"@flying-sheep I'm thinking we should switch to using conda-forge for distributing scanpy. Right now, we're having trouble maintaining the bioconda builds. We already use conda-forge for anndata, so I think it would reduce the maintenance burden to consolidate our build systems. Also, I find conda-forge's tooling and documentation much easier to follow. I've started setting up a conda-forge recipe, which has gone pretty well. However I'm running into one issue with the tests. It looks like we don't bundle the `conftest.py` file at our project root with the rest of scanpy. This leads to the flaky internet tests being run when the conda package is built. Not sure how to deal with this at the moment. Update: Also `test_regress_out_ordinal` seems to hang forever when testing the build.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1169:226,mainten,maintenance,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169,1,['mainten'],['maintenance']
Availability,"@flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. ; It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python; def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1109:194,error,errors,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109,1,['error'],['errors']
Availability,"@flying-sheep: After the recent changes I am getting the following error:. ```bash; /apps/scanpy/scanpy/logging.py in _settings_verbosity_greater_or_equal_than(v); 36 def _settings_verbosity_greater_or_equal_than(v):; 37 if isinstance(settings.verbosity, str):; ---> 38 settings_v = _VERBOSITY_LEVELS_FROM_STRINGS[settings.verbosity]; 39 else:; 40 settings_v = settings.verbosity; KeyError: 'warning'; ```. The problem is solved by setting the verbosity level. E.g. ```; sc.settings.verbosity = 3; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/496:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/496,1,['error'],['error']
Availability,"@scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['error'],['error']
Availability,"A frequent problem that I am faced with is to identify clusters using known lists of markers. I think that one existing approach is to first identify markers and then check if the known markers are among those identified markers. Also, I have used the `score_genes` function, originally used to identify cell cycle genes. However, I think that a more robust method is possible and probably I am just not aware of it. Does anyone has some experience with this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/290:351,robust,robust,351,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/290,1,['robust'],['robust']
Availability,A neighbors error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141,1,['error'],['error']
Availability,"A number of multithreaded functions and libraries we use default to `os.cpu_count()` number of threads. This is a problem when multiple processes are running in parallel, as is the case when using pytest-xdist. This oversubscription can lead to an increase in test time when multiple workers are used. This PR limits how many threads most libraries use via `threadpoolctl`, and scales this to the number of workers available on the host. I personally see improvements of ~10x when running with this setting on a server with 16 cores, using `-n auto`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843:415,avail,available,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843,1,['avail'],['available']
Availability,"AFAIK networkx and python-igraph do the same thing, only that python-igraph is faster. We also need python-igraph anyway for louvain and so on, so maybe it would be good to get rid of networkx. Downside: python-igraph and louvain-igraph is currently deliberately an optional dependency since it’s hard to install on windows. People need to build it themselves (A task that even I didn’t manage by now, and I got *many* things to compile!) or use Christoph Grohlke’s unofficial builds ([here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph) and [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#louvain-igraph))",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97:194,Down,Downside,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97,1,['Down'],['Downside']
Availability,"Adding an expression atlas downloader to `sc.datasets` (proposed in #489). I've punted on replacing where datasets are downloaded by just making it a variable in settings, since it seems contentious where datasets should be downloaded by default #558. @flying-sheep when I build the docs locally, the link to the expression atlas doesn't format properly on the main `API` page, but does on it's own page. Any ideas on if we can get that to work?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573:27,down,downloader,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573,3,['down'],"['downloaded', 'downloader']"
Availability,Adding use_raw=False create errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046,1,['error'],['errors']
Availability,"Addressing https://github.com/theislab/scanpy/issues/435#issuecomment-538776417. This PR does two things:. 1. `downsample_counts` will convert the resulting downsampled matrix back to the initial dtype by default.; 2. `normalize_total` will now work with integer matrices. I think 2 should definitely be the case. 1 does have a performance cost, but it's close to @falexwolf's [suggestion](https://github.com/theislab/scanpy/issues/435#issuecomment-475999342) and removes a minor foot-gun.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865:157,down,downsampled,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865,1,['down'],['downsampled']
Availability,"After running `rank_genes_groups` with 100 genes and 30 clusters, the `adata.uns['rank_genes_groups']['pvals_adj']` results in a `100x30` array of p-values. Each column is a cluster, so the first row has the top-scoring genes for each cluster. But if you look at the p-values, some of them are 1. And the p-values do not seem to increase as you go down the rows, but the scores do decrease as you go down the rows. . So if we want to just isolate marker genes that are statistically significant at some threshold, how do we do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/701:348,down,down,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701,2,['down'],['down']
Availability,"After studying the PAGA tutorial, I tried to apply it to my data (40,000 cells, 8,000 highly variable genes). I ran the following commands:; ```python; sc.pp.neighbors(adata_hvg); sc.tl.louvain(adata_hvg); sc.tl.draw_graph(adata_hvg); ```; Till here, everything works nicely, but then I try to get the PAGA representation:. ```python; sc.tl.paga(adata_hvg, groups=""louvain""); ```. This returns the following error:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-249-7cc787ba28f9> in <module>; ----> 1 sc.tl.paga(adata_hvg, groups=""louvain""). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in paga(adata, groups, use_rna_velocity, model, copy); 93 adata.uns['paga'] = {}; 94 if not use_rna_velocity:; ---> 95 paga.compute_connectivities(); 96 adata.uns['paga']['connectivities'] = paga.connectivities; 97 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in compute_connectivities(self); 127 def compute_connectivities(self):; 128 if self._model == 'v1.2':; --> 129 return self._compute_connectivities_v1_2(); 130 elif self._model == 'v1.0':; 131 return self._compute_connectivities_v1_0(). ~/miniconda3/envs/wot/lib/python3.6/site-packages/scanpy/tools/_paga.py in _compute_connectivities_v1_2(self); 161 if scaled_value > 1:; 162 scaled_value = 1; --> 163 connectivities[i, j] = scaled_value; 164 expected_n_edges[i, j] = expected_random_null; 165 # set attributes. ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/_index.py in __setitem__(self, key, x); 67 if x.size != 1:; 68 raise ValueError('Trying to assign a sequence to an item'); ---> 69 self._set_intXint(row, col, x.flat[0]); 70 return; 71 . ~/miniconda3/envs/wot/lib/python3.6/site-packages/scipy/sparse/compressed.py in _set_intXint(self, row, col, x); 795 def _set_intXint(self, row, col, x):; 796 i, j = self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695:408,error,error,408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695,1,['error'],['error']
Availability,"After updating scanpy to the v 1.3.2 I got this error when doing the subplots as in the ""PAGA for hematopoiesis in mouse"" tutorial:; _, axs = pl.subplots(ncols=6, figsize=(16, 30), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names_3, ; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=12,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); #data.to_csv('./write/paga_path_{}.csv'.format(descr)); #pl.savefig('./figures/paga_path.png'); pl.show(). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-8-c59dfbccf885> in <module>(); 16 title='{} path'.format(descr),; 17 return_data=True,; ---> 18 show=False); 19 #data.to_csv('./write/paga_path_{}.csv'.format(descr)); 20 #pl.savefig('./figures/paga_path.png'). ~\Anaconda3\lib\site-packages\scanpy\plotting\tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 932 idcs = idcs[idcs_group]; 933 if key in adata.obs_keys(): x += list(adata.obs[key].values[idcs]); --> 934 else: x += list(adata_X[:, key].X[idcs]); 935 if ikey == 0:; 936 groups += [group for i in range(len(idcs))]. ~\Anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1301 def __getitem__(self, index):; 1302 """"""Returns a sliced view of the object.""""""; -> 1303 return self._getitem_view(index); 1304 ; 1305 def _getitem_vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333,1,['error'],['error']
Availability,"An addendum to #442, now if you try to read a 10x file and pass a genome it doesn't have, the error tells you which file it was and the genomes it does have:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last). ... ValueError: Could not find genome 'not a genome' in 'scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5'. Available genomes are: ['hg19_chr21']; ```. Previous behavior:. ```python; In [1]: import scanpy as sc ; ...: sc.read_10x_h5(""scanpy/tests/_data/10x_data/1.2.0/filtered_gene_bc_matrices_h5.h5"", ""not a genome"") ; ---------------------------------------------------------------------------; NoSuchNodeError Traceback (most recent call last). ... Exception: Genome not a genome does not exist in this file.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/444:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444,2,"['Avail', 'error']","['Available', 'error']"
Availability,An error when running scanpy.pl.clustermap(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,AnnDataReadError: Above error raised while reading key '/X' of type from /.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,1,['error'],['error']
Availability,"Another error I get and have no idea how to solve is when using the Wilcoxon rank-sum for testing for differential gene expression:. `sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)`. ```; ranking genes. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-385-c2fa7bb8ea8d> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 352 ; 353 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 354 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 355 scores[np.isnan(scores)] = 0; 356 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. The logistic regression and t-test work fine.; I guess it is related to my data....",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566,2,['error'],['error']
Availability,"Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```; # ; # # Part of the error message that probably matters most; # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; *** multi-threaded process forked ***; crashed on child side of fork pre-exec. # ; # ; # ; ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/194:151,error,error,151,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194,2,"['error', 'fault']","['error', 'fault']"
Availability,"Are Louvain clustering results supposed to be reproducible? I ran the clustering on the 1.3 mln dataset, exactly following the code provided here https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py as follows:. ```; import scanpy.api as sc; sc.settings.verbosity = 2; adata = sc.read_10x_h5('1M_neurons_filtered_gene_bc_matrices_h5.h5') ; sc.pp.recipe_zheng17(adata) ; sc.pp.neighbors(adata) ; sc.tl.louvain(adata) ; adata.obs['louvain'].to_csv('clustering-scanpy.csv'); ```. This works fine and I get the clustering result that makes sense when visualized, however it differs quite strongly from the clustering result that Alex sent me some time ago (as I understood him, that were exactly the clustering results used for the visualisation in the Scanpy paper). My questions:; 1. Is re-running the above snippet supposed to give me the exact same results every time, or are there some random seeds used along the way?; 2. If yes, how can one modify the code to ensure reproducibility?; 3. Is there any way to modify the snippet to get the exact same results as shown here https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells and in the published Scanpy paper?; 4. If the answer to the previous question is no, could you make those results publicly available somewhere?. I noticed the following warning from `sc.pp.neighbors` that might be relevant:. > WARNING: You're trying to run this on 1000 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params.; Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.` This will likely become the Scanpy default in the future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325:1335,avail,available,1335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325,1,['avail'],['available']
Availability,"As noted in #1334, visium downloads were broken. Setting a header on downloads seems to fix them. This supersedes #1334 since that solution modifies global state around `urllib`, which is asking for trouble. This unfortunately means most of the method had to be reimplemented.; The new implementation is based on `urllib.requests.urlretrieve`, but with a modification to let us pass a header. I also included a couple minor fixes to existing dataset download stuff:. * We don't get a warning from using `@internet` test marker anymore; * One of the downloaded datasets changed, so the test got updated; * `_download` no longer creates all parent directories. That is handled upstream. @Mirkazemi @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:26,down,downloads,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,4,['down'],"['download', 'downloaded', 'downloads']"
Availability,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369,2,['error'],['error']
Availability,"At the stage of finding neighbors, my jupyter kept showing this error:; <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:; ```; OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; And it killed the kernel entirely. ; ```. I try to make this work by running this in Linux but it got killed again. ; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359,2,['error'],['error']
Availability,"AxisError was encountered while executing the regress_out function following the pbmc3k tutorial ; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; regressing out ['n_counts', 'percent_mito']; sparse input is densified and may lead to high memory use; ---------------------------------------------------------------------------; AxisError Traceback (most recent call last); <ipython-input-55-c0d016811ded> in <module>; ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy); 817 # split the adata.X matrix by columns in chunks of size n_chunk; 818 # (the last chunk could be of smaller size than the others); --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1); 820 if variable_is_categorical:; 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis); 782 ; 783 sub_arys = []; --> 784 sary = _nx.swapaxes(ary, axis, 0); 785 for i in range(Nsections):; 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2); 595 ; 596 """"""; --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2); 598 ; 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds); 56 bound = getattr(obj, method, None); 57 if bound is None:; ---> 58 return _wrapit(obj, method, *args, **kwds); 59 ; 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010:283,Error,Error,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010,1,['Error'],['Error']
Availability,Backport PR #1934 on branch 1.8.x (Fix use_raw error with sc.tl.rank_genes_groups),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935,1,['error'],['error']
Availability,Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935,1,['error'],['error']
Availability,Backport PR #2120 on branch 1.8.x (Fix colorbar mappable error for older matplotlib),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2159:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159,1,['error'],['error']
Availability,Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2159:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159,1,['error'],['error']
Availability,Backport PR #2209 on branch 1.9.x (Fix isinstance arg 2 must be a type error),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213:71,error,error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213,1,['error'],['error']
Availability,Backport PR #2209: Fix isinstance arg 2 must be a type error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213:55,error,error,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213,1,['error'],['error']
Availability,Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3072:35,error,errors,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072,2,['error'],['errors']
Availability,Backport PR #3069: Upload scrublet scores on test failure,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3242:50,failure,failure,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3242,2,['failure'],['failure']
Availability,Better 10x read errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/444:16,error,errors,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/444,1,['error'],['errors']
Availability,Bugfix: Failure due to cugraph api change in v0.16...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1494:8,Failure,Failure,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494,1,['Failure'],['Failure']
Availability,"CI runs that report coverage currently don't fail if the tests fail. This is because the way the coverage job is written swallows the error. I'm updating this use the same approach as anndata, which seems to be working.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2874:134,error,error,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2874,1,['error'],['error']
Availability,CPUDispatcher error with highly variable genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1995:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995,1,['error'],['error']
Availability,Calculate downregulated genes?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625:10,down,downregulated,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625,1,['down'],['downregulated']
Availability,"Calling `sc.get.obs_df()` without the `keys` parameter causes an error:. ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)]); ```. ```pytb; ~/scanpy/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 301 ; 302 # reorder columns to given order (including duplicates keys if present); --> 303 df = df[keys]; 304 for k, idx in obsm_keys:; 305 added_k = f""{k}-{idx}"". KeyError: (); ```. Also, if `keys` is not a list, the object returned is not a pandas dataframe but a Series object in which the last row is the obsm values. In other words, instead of adding a column to a dataframe with the obsm values, a row is added to a pandas Series. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)], keys='CST3'); ```; ```; index; AAAGCCTGGCTAAC-1 0.281; AAATTCGATGCACA-1 -0.176; AACACGTGGTCTTT-1 -0.818; AAGTGCACGTGCTA-1 -0.818; ACACGAACGGAGTG-1 0.854; ... ; TGTGAGTGCTTTAC-8 -0.069; TGTTACTGGCGATT-8 -0.818; TTCAGTACCGGGAA-8 -0.818; TTGAGGTGGAGAGC-8 0.428; X_umap-0 [-1.9918625454649166, -3.2486919412134108, -3....; Name: CST3, Length: 701, dtype: object; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1634:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1634,1,['error'],['error']
Availability,Calling `sc.get.obs_df` with `keys=adata.var_names` raises a value error since [here](https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/get/get.py#L303-L304) an Index object is used to re-order the dataframe. ; I think its a trivial fix to re-cast `keys` locally if an Index object is passed (aka `adata.var_names`) and could be nice for the user :),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2256:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256,1,['error'],['error']
Availability,"Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1985:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985,1,['error'],['error']
Availability,Cannot read Visium HD data using spatialdata-io (Recurrent error). Data is non-zarr format.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,1,['error'],['error']
Availability,Cannot write my anndata object to file. Already checked the other errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1572:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1572,1,['error'],['errors']
Availability,Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172,1,['error'],['error']
Availability,Combat processing errors/warnings in console,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164,1,['error'],['errors']
Availability,"Conda installation fails silently with no error. Installation command:; ```; conda install -c bioconda scanpy; ```. Output:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: / ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```. Increasing the verbosity did not help. Using older python version did not helpeither.. It looks like the metadata are not correct but I am not able to validate this. I tried miniconda anaconda clean installs and I had no luck whatsoever. Pip install works fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298,2,"['Avail', 'error']","['Available', 'error']"
Availability,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2323:394,down,downstream,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323,1,['down'],['downstream']
Availability,"Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python; import numpy as np; import scanpy as sc; import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))); sc.pp.neighbors(adata); sc.tl.louvain(adata); plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']); ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)); ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward?. In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030:465,error,error,465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030,1,['error'],['error']
Availability,"Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```; >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'); WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; ranking genes; consider 'louvain_resolution_3.0' groups:; with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups; method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics; for group_index, scores, pvals in generate_test_results:; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test; self._basic_stats(); File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats; self.means[imask], self.vars[imask] = _get_mean_var(X_mask); File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var; var *= X.shape[axis] / (X.shape[axis] - 1); ZeroDivisionError: division by zero; ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490:120,error,error,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490,1,['error'],['error']
Availability,"Cuts around 1 second off import of scanpy. ```sh; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭defer-seaborn ; python3 -c ""import scanpy"" 3.36s user 0.61s system 104% cpu 3.801 total; isaac@Mimir ~/github/scanpy$ git checkout master ✭defer-seaborn ; Switched to branch 'master'; Your branch is up to date with 'upstream/master'.; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy"" ✭master ; python3 -c ""import scanpy"" 4.23s user 0.48s system 108% cpu 4.324 total; ```. I'd like to cut down import time even more, but I figure this is a good place to start.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/703:512,down,down,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/703,1,['down'],['down']
Availability,Dask update causing CI failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:23,failure,failures,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['failure'],['failures']
Availability,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnData’s shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnData’s shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:3235,error,error,3235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,Dataset maintenance,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1101:8,mainten,maintenance,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1101,1,['mainten'],['maintenance']
Availability,"Dear Theis lab,; I get the following error:; `ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (0,4) and requested shape (3255,4)`; when running `sc.pl.diffmap(adata, color='leiden', projection='3d', save='_diff_3d.pdf')`. I hope you guys can help me with this.; regards",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/829:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/829,1,['error'],['error']
Availability,"Dear all,. I had the following error when going through the PBMC3K tutorial. Everything was fine until I got to this step (Embedding the neighbourhood graph):. ```py; sc.tl.paga(adata); ```. which raises the following:. <details><summary>KeyError: 'louvain', Traceback:</summary>. ```pytb; running PAGA; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2656 try:; -> 2657 return self._engine.get_loc(key); 2658 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-31-5aa170e493c3> in <module>; ----> 1 sc.tl.paga(adata). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in paga(adata, groups, use_rna_velocity, model, copy); 92 adata.uns['paga'] = {}; 93 if not use_rna_velocity:; ---> 94 paga.compute_connectivities(); 95 adata.uns['paga']['connectivities'] = paga.connectivities; 96 adata.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self); 126 def compute_connectivities(self):; 127 if self._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,2,"['error', 'toler']","['error', 'tolerance']"
Availability,"Dear all; I would like to project my umap from scanpy in 3d but I have faced the following problem:. > ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (0,4) and requested shape (816,4). It's very strange because before I update some of my packages, I could run it it with no problem with the following packages:. > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1 . but after updating some of my packages it was not possible due to that error!. > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. Should I roll back to the previous version of annadata or scanpy? has anyone ran this feature with my package version with no problems?. Thanks a lot. Here are the packages I use",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/663:595,error,error,595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663,1,['error'],['error']
Availability,"Dear developers, . in an attempt to instal the latest version of scanpy from GitHub (Master branch), I receive the following error:. Traceback (most recent call last):; File ""/home/vladie/PycharmProjects/PY3/RPE_MYCN_10X.py"", line 4, in <module>; import scanpy.external as sce; File ""/usr/local/lib/python3.6/dist-packages/scanpy/__init__.py"", line 33, in <module>; from . import datasets, logging, queries, external; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/__init__.py"", line 1, in <module>; from . import tl; File ""/usr/local/lib/python3.6/dist-packages/scanpy/external/tl.py"", line 4, in <module>; from ._tools._palantir import palantir; ModuleNotFoundError: No module named 'scanpy.external._tools'. I would like to run palentir through Scanpy, is this already possible ? ; Kind regards,; Vladie0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601,1,['error'],['error']
Availability,"Dear, ; When I use sc.pl.paga(adata) to show my single cell data with 16 clusters, it works well. However, when I show another data with only 4 cluster, the following error occurs:. ValueError Traceback (most recent call last); ~/bin/miniconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs); 4226 valid_shape = False; -> 4227 raise ValueError; 4228 except ValueError:. ValueError: . During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-29-c0e8bf06937e> in <module>(); ----> 1 sc.pl.paga(adata,color=['louvain','ID']). ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, show, save, ax); 396 single_component=single_component,; 397 arrowsize=arrowsize,; --> 398 pos=pos); 399 if colorbars[icolor]:; 400 bottom = panel_pos[0][0]. ~/bin/miniconda3/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py in _paga_graph(adata, ax, layout, layout_kwds, init_pos, solid_edges, dashed_edges, transitions, threshold, root, colors, labels, fontsize, fontweight, text_kwds, node_size_scale, node_size_power, edge_width_scale, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, cax, colorbar, use_raw, cb_kwds, single_component, arrowsize, random_state); 746 sct = ax.scatter(; 747 pos_array[:, 0], pos_array[:, 1],; --> 748 c=colors, edgecolors='face', s=groups_sizes, cmap=cmap); 749 if fontsize is None:; 750 fontsize = rcParams['legend.fontsize']. ~/bin/miniconda3/lib/pytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381,1,['error'],['error']
Availability,"Dear,; When I Calculate qc metrics for visualization according to the example in https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.calculate_qc_metrics.html#scanpy.pp.calculate_qc_metrics:. ```py; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.calculate_qc_metrics(adata, inplace=True); >>> sns.jointplot(adata.obs, ""log1p_total_counts"", ""log1p_n_genes_by_counts"", kind=""hex""); ```. The following error occurred:; AttributeError: 'str' object has no attribute 'get'; It seems that sns.jointplot are not compatible well with adata.obs, anybody who can help me ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/499:398,error,error,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/499,1,['error'],['error']
Availability,"Dears; Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb; sc_adata=sc.read_loom(sc_input,sparse = True); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom; obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs; if v.ndim > 1 and v.shape[1] > 1:; AttributeError: 'NoneType' object has no attribute 'ndim' ; ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2461:86,Error,Error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461,1,['Error'],['Error']
Availability,"Default: lzf. see theislab/anndata#123. To review without being bogged down with whitespace changes, check: https://github.com/theislab/scanpy/pull/847/files?w=1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/847:71,down,down,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847,1,['down'],['down']
Availability,Dendrogram error - symmetry,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2357:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357,1,['error'],['error']
Availability,Dendrogram returns an error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2125:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125,1,['error'],['error']
Availability,"Does `scanpy==1.5.1` support multiple sections in one adata object? If I concatenate several anndata object I can't plot even with `sc.pl.spatial(img_key=None)`. Try concatenating 3 mouse brain adata object and plotting:; ```python; adata = adata1.concatenate([obj2, obj3], index_unique=None); sc.pl.spatial(adata[adata.obs[""sample""]==adata.obs[""sample""].unique()[0], :], ; color=[""Rorb"", ""Vip""], img_key=None,; vmin=0, cmap='magma',; gene_symbols='SYMBOL'); ```. This is the error I get:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-9-8c84185773ec> in <module>; 6 color=[""Rorb"", ""Vip""], img_key=None,; 7 vmin=0, cmap='magma', #vmax=3.8,; ----> 8 gene_symbols='SYMBOL'; 9 ). /nfs/team283/vk7/software/miniconda3farm5/envs/cellpymc/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, img_key, library_id, crop_coord, alpha_img, bw, size, **kwargs); 765 """"""; 766 if library_id is _empty:; --> 767 library_id = next((i for i in adata.uns['spatial'].keys())); 768 else:; 769 if library_id not in adata.uns['spatial'].keys():. KeyError: 'spatial'; ```. #### Versions:; scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254:476,error,error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254,1,['error'],['error']
Availability,Don’t error if n_top_genes > n_var,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/835:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/835,1,['error'],['error']
Availability,"Dotplot / Matrixplot Bug/Suggestion [Key Error] Because ""var_group_labels"" & ""categories_order"" using the same variable (memory), mostly happened when ""swap_axes=True""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:41,Error,Error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,1,['Error'],['Error']
Availability,Download header,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344:0,Down,Download,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344,1,['Down'],['Download']
Availability,Downsample branch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100,1,['Down'],['Downsample']
Availability,Downsample improvements,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/602:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/602,1,['Down'],['Downsample']
Availability,Downsample total counts,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/474:0,Down,Downsample,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474,1,['Down'],['Downsample']
Availability,"Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python; import scanpy as sc; from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000); adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) ; sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1096:0,Down,Downstream,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096,1,['Down'],['Downstream']
Availability,"Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 104 if adata.isview: # we shouldn't need this here...; 105 adata._init_as_actual(adata.copy()); --> 106 neighbors = Neighbors(adata); 107 neighbors.compute_neighbors(; 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs); 527 self._number_connected_components = self._connected_components[0]; 528 if 'X_diffmap' in adata.obsm_keys():; --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata); 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata); 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata); 395 return np.r_[1, adata.uns['diffmap_evals']]; 396 else:; --> 397 return adata.uns['diffmap_evals']; 398 ; 399 . KeyError: 'diffmap_evals'; ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1021:334,avail,available,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021,1,['avail'],['available']
Availability,"E.g. matplotlib is only necessary when plotting, and for e.g. Docker images, it would be useful to have a slim scanpy core. An idea would be to do it like Jupyter:. - A `scanpy-core` PyPI package with just the essentials.; - A `scanpy` metapackage, which depends on `scanpy-core` and most (or all) of the optional dependencies. Users doing `pip install scanpy` will get the full package, with no annoying runtime errors, and packagers needing flexibility get `scanpy-core` and can slim everything down as needed. cc @hensing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/59:413,error,errors,413,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/59,2,"['down', 'error']","['down', 'errors']"
Availability,"Env:; * Ubuntu 16.04; * python 3.7; * pandas 0.25.0; * scanpy 1.4.4.post1. I have an AnnData object called `adata`. The maximum value in the count matrix `adata.X` is 3701. When I do; `sc.pp.highly_variable_genes(adata)`. I get the following error; ```; /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scipy/sparse/data.py:132: RuntimeWarning: invalid value encountered in expm1; result = op(self._deduped_data()); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: overflow encountered in log1p; mean = np.log1p(mean); /home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:86: RuntimeWarning: invalid value encountered in log1p; mean = np.log1p(mean); Traceback (most recent call last):; File ""../../scvi/scvi_adata.py"", line 75, in <module>; sc.pp.highly_variable_genes(adata); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 257, in highly_variable_genes; flavor=flavor); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 92, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File ""/home/sfleming/anaconda3/envs/scvi/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763,1,['error'],['error']
Availability,Error When Saving File as .h5ad with adata.write,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['Error'],['Error']
Availability,Error after normalization with scran,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,1,['Error'],['Error']
Availability,Error at the cell cycle score calculation step,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,1,['Error'],['Error']
Availability,Error calculating neighbors on sparse array with cosine metric,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1096:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096,1,['Error'],['Error']
Availability,Error exporting adata using sc.export_to.spring_project,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1510:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510,1,['Error'],['Error']
Availability,Error filtering 'Boolean index not valid',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/768:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768,1,['Error'],['Error']
Availability,Error in `sc.tl.umap`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579,1,['Error'],['Error']
Availability,Error in cell cycle score calculation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2156:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156,1,['Error'],['Error']
Availability,Error in importing scanpy when using scvi-tools,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2542:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542,1,['Error'],['Error']
Availability,Error in normalize_total with scanpy 1.9,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2210:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210,1,['Error'],['Error']
Availability,Error in pca_loadings when components > 5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/431:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431,1,['Error'],['Error']
Availability,Error in running scrublet,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['Error'],['Error']
Availability,Error in sc.pl.rank_genes_groups_heatmap: The truth value of a Index is ambiguous.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313,1,['Error'],['Error']
Availability,Error in sc.pp.highly_varaible_genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509,1,['Error'],['Error']
Availability,Error in sc.pp.highly_variable_genes function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193,1,['Error'],['Error']
Availability,Error in sc.tl.dendrogram: The truth value of a Index is ambiguous.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300,1,['Error'],['Error']
Availability,Error in tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/63:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63,1,['Error'],['Error']
Availability,Error installing scanpy through pip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,1,['Error'],['Error']
Availability,Error message in tl.diffmap / why n_comps must be > 2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/668:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/668,1,['Error'],['Error']
Availability,Error occurred when ReadH5AD('~/pca.h5ad') function from seurat3.1 taking scanpy(v1.4.6) h5ad file as inputting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198,1,['Error'],['Error']
Availability,Error pip installing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,1,['Error'],['Error']
Availability,Error plotting the graph,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208,1,['Error'],['Error']
Availability,Error related to verbosity,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/496:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/496,1,['Error'],['Error']
Availability,Error running example notebook,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/24:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/24,1,['Error'],['Error']
Availability,Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,Error using rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365,1,['Error'],['Error']
Availability,Error when filtering: AttributeError: 'Series' object has no attribute 'is_dtype_equal',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34,1,['Error'],['Error']
Availability,Error when plotting PAGA,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/483:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/483,1,['Error'],['Error']
Availability,Error when repeating the tutorial for diffusion map in v1.9.1 scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2254:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254,1,['Error'],['Error']
Availability,Error when writing to h5ad,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['Error'],['Error']
Availability,Error while reading h5ad file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,1,['Error'],['Error']
Availability,Error while using the read_10x_mtx() function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,1,['Error'],['Error']
Availability,Error with gene ontology enrichment analysis,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003,1,['Error'],['Error']
Availability,Error with sc.pl.highest_expr_genes() ; 'SparseDataset' object has no attribute 'sum',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,1,['Error'],['Error']
Availability,Error with scanpy.api.pl.highest_expr_genes(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/220:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/220,1,['Error'],['Error']
Availability,Every piece of redundant code we delete is one we don’t have to maintain.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/556:15,redundant,redundant,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/556,1,['redundant'],['redundant']
Availability,Exit with an error if sc.pl.pca_loadings is called with indices < 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/803:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/803,1,['error'],['error']
Availability,FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'; ```. ### Minimal code sample. ```python; pip install scipy==1.14.0rc1; pytest; ```. ### Error output. _No response_. ### Versions. <details>. ```; + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba); + annoy==1.17.3; + anyio==4.4.0; + array-api-compat==1.7.1; + pillow==10.3.0; + platformdirs==4.2.2; + pluggy==1.5.0; + pre-commit==3.7.1; + profimp==0.1.0; + psutil==5.9.8; + pyarrow==16.1.0; + pygments==2.18.0; + pygsp==0.5.1; + pynndescent==0.5.12; + pyparsing==3.1.2; + pytest==8.2.1; + pytest-cov==5.0.0; + pytest-memray==1.6.0; + pytest-mock==3.14.0; + pytest-nunit==1.0.7; + pytest-xdist==3.6.1; + python-dateutil==2.9.0.post0; + pytz==2024.1; + pyyaml==6.0.1; + rich==13.7.1; + scanorama==1.7.4; + scanpy==1.10.2.dev25+gf5a62eee (from file:///home/vsts/work/1/s); + scikit-image==0.23.2; + scikit-learn==1.5.0; + scikit-misc==0.3.1; + scipy==1.14.0rc1; + scprep==1.1.0; + seaborn==0.13.2; + session-info==1.0.0; + setuptools==70.0.0; + setuptools-scm==8.1.0; + six==1.16.0; + sniffio==1.3.1; + sortedcontainers==2.4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3083:1725,Error,Error,1725,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083,1,['Error'],['Error']
Availability,"False):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 441 # TODO: Pull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:4672,error,error,4672,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['error']
Availability,"First of all congratulations for the awesome package, intuitive and works great. Just a suggestion if you have time to implement ridgeplots or joyplots like the ones available now in Seurat. They are useful to present several distributions in a compact (and attractive) way. Seems possible through the seaborn kdeplot functions (https://seaborn.pydata.org/examples/kde_joyplot.html). Just a suggestion, so feel free to close to issue at any point!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/84:166,avail,available,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/84,1,['avail'],['available']
Availability,"First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```; mamba create -yn scanpy-dev ""python=3.12""; conda activate scanpy-dev; pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster; conda deactivate scanpy-dev; conda activate scanpy-dev; pytest -n auto; ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```; pip install dask-expr; pytest -n auto; ```. <details>; <summary> Failures </summary>. ```; FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable; FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,2,"['Failure', 'error']","['Failures', 'error']"
Availability,"Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1087:147,error,error,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087,1,['error'],['error']
Availability,Fix all the various test failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3124:25,failure,failures,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3124,1,['failure'],['failures']
Availability,Fix clustermap error due to fillna call in seaborn.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['error'],['error']
Availability,Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120,1,['error'],['error']
Availability,Fix download path of pbmc3k_processed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472:4,down,download,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472,1,['down'],['download']
Availability,Fix ebi downloads,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1102:8,down,downloads,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102,1,['down'],['downloads']
Availability,Fix error formatting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2263:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2263,1,['error'],['error']
Availability,Fix isinstance arg 2 must be a type error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2209:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209,1,['error'],['error']
Availability,Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1934:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1934,1,['error'],['error']
Availability,Fixes #1395. It looks like this code was originally added for dealing with the automatic flattening of `X` when indices had length 1. I also made it an error if there were no genes to score. Arguably it should be an error if any of the passed genes are missing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398:152,error,error,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398,2,['error'],['error']
Availability,"Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/155:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155,1,['error'],['error']
Availability,"Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test; 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case).; 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1548:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548,1,['error'],['error']
Availability,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1898:386,error,errors,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898,2,['error'],"['error', 'errors']"
Availability,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1893:88,error,error,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893,1,['error'],['error']
Availability,"Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2466:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466,1,['error'],['error']
Availability,"Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS; - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst; Compute distances and connectivities of neighbors. Parameters; ----------; n_neighbors; Use this number of nearest neighbors.; knn; Restrict result to `n_neighbors` nearest neighbors.; {n_pcs}; {use_rep}. Returns; -------; Writes sparse graph attributes `.distances` and `.connectivities`.; Also writes `.knn_indices` and `.knn_distances` if; `write_knn_indices==True`.; ```. <p align=center>↓↓↓</p>. ```rst; Compute distances and connectivities of neighbors.; Parameters; ----------; n_neighbors : int, optional (default: 30); Use this number of nearest neighbors.; knn : bool, optional (default: True); Restrict result to `n_neighbors` nearest neighbors.; n_pcs : `int` or `None`, optional (default: `None`); Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`.; use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`); Use the indicated representation. If `None`, the representation is chosen; automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used.; If 'X_pca' is not present, it's computed with default parameters.; Returns; -------; Writes sparse graph attributes `.distances` and `.connectivities`.; Also writes `.knn_indices` and `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192:401,avail,available,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192,1,['avail'],['available']
Availability,"Fixes #767. This is a work in progress PR adding ICA as a dimensionality reduction method. Some points:. This is faster and works with larger data than the sklearn version – entirely due to the whitening step. sklearn uses `np.linalg.svd` for whitening, which causes errors about using 32 bit lapack for large datasets since we use 32 bit floats and is slow (but exact). I've swapped that with the arpack svd. I may try and upstream this in the future, but there are a number of open PRs about ICA that I'd like to wait for a bit on: https://github.com/scikit-learn/scikit-learn/pull/11860, https://github.com/scikit-learn/scikit-learn/issues/13056. As a benchmark, I was able to compute 40 dimensions of an ICA on 50k cells (tabula muris) and 7.5k highly variable genes in about a minute (59.3s) on my laptop. As a comparison (for a smaller dataset – 10k PBMCs) here are two pair grid plots showing cell embeddings on ten components compared with the top ten components of a PCA. <details>; <summary> PCA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899041-0c9f5b80-13b5-11ea-973f-81d4c27fe3b1.png). </details>. <details>; <summary> ICA </summary>. ![image](https://user-images.githubusercontent.com/8238804/69899077-7cade180-13b5-11ea-9a0b-023868553181.png). </details>. Things left to do:. - [ ] Look into numerical stability; - [ ] Figure out if I should be be scaling the whitening matrix differently; - [ ] More in depth comparison of results with sklearn based ICA; - [ ] Documentation; - [ ] Share `_choose_obs_rep` with `sc.metrics` PR. Once this is done, I'd like to also add sklearns NMF.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941:267,error,errors,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941,1,['error'],['errors']
Availability,"Fixes #993. This is an approximate implementation of the Seurat v3 hvg method. The only difference should be the use of lowess instead of loess (which is not available in python as far as I know). This method takes the UMI counts as input. The way HVGs from batches are merged is also different from the other flavors. As such, I didn't see a straightforward way to integrate this in the existing HVG code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182:158,avail,available,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182,1,['avail'],['available']
Availability,Fixes scanpy import error on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585,1,['error'],['error']
Availability,Fixes the current test failures. I could also do a simpler version where I just rechunk in one way instead of adding parameters here.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3162:23,failure,failures,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162,1,['failure'],['failures']
Availability,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2421:123,error,error,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421,2,['error'],['error']
Availability,"Follow up to #703, this should take import times down another second. It does add a dependency, but that dependency will be in the stdlib from 3.8+. After this it looks like the next biggest contributors to import times are caused by `numba` (which would be hard to factor out) and `sklearn.metrics`, but these are on a smaller scale. Evidence of speedup:. ```sh; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭master ; python3 -c ""import scanpy as sc"" 3.10s user 0.41s system 116% cpu 3.010 total; isaac@Mimir ~/github/scanpy$ git checkout defer-umap ✹ ✭master ; Switched to branch 'defer-umap'; Your branch is up to date with 'origin/defer-umap'.; isaac@Mimir ~/github/scanpy$ time python3 -c ""import scanpy as sc"" ✹ ✭defer-umap ; python3 -c ""import scanpy as sc"" 2.18s user 0.42s system 131% cpu 1.981 total; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704:49,down,down,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704,1,['down'],['down']
Availability,"Follow up to https://github.com/scverse/scanpy/pull/3275#pullrequestreview-2392213666. I think that this woulda worked regardless because the `try` will define it initially anyways. However, it's best practice to only have code that can error in the `try` statement. I'll allow myself to skip a release note etc because this is minor and there hasn't been a release yet with this fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3315:237,error,error,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315,1,['error'],['error']
Availability,Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets.; This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506:159,avail,available,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506,1,['avail'],['available']
Availability,"Following up on #242. Here's my solution to the current queries being pretty unreliable for me (due to issue with bioservices module). It's all a pretty thin wrapper around `pybiomart`, which has a nice API and is well tested but has maintenance issues. . Currently I've replaced the `gene_coordinates` query with a more generic `biomart_annotations` – the example covers the functionality of `gene_coordinates`. I'm debating how to add tests given that they're network based (could fail when nothing is wrong with the code) and can take a while.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467:234,mainten,maintenance,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467,1,['mainten'],['maintenance']
Availability,"For incremental PCA: `sc.tl.pca(adata, n_comps=ndim, chunked=True)`; sometimes, the number of samples for the last chunk is smaller than ndim, an error would be throw:; ```pytb; File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/pym3c/clustering.py:377, in run_dimension_reduction(***failed resolving arguments***); 375 if not downsample or obs_chunk_size > downsample or adata.n_obs < downsample:; 376 logger.info(f""Running IncrementalPCA without downsampling""); --> 377 sc.tl.pca(adata, n_comps=ndim, chunked=True,; 378 chunk_size=obs_chunk_size); 379 else: # downsample; 380 logger.info(f""Running IncrementalPCA with downsample = {downsample}""). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py:255, in pca(***failed resolving arguments***); 253 for chunk, _, _ in adata_comp.chunked_X(chunk_size):; 254 chunk = chunk.toarray() if issparse(chunk) else chunk; --> 255 pca_.partial_fit(chunk); 257 for chunk, start, end in adata_comp.chunked_X(chunk_size):; 258 chunk = chunk.toarray() if issparse(chunk) else chunk. File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/base.py:1473, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs); 1466 estimator._validate_params(); 1468 with config_context(; 1469 skip_parameter_validation=(; 1470 prefer_skip_nested_validation or global_skip_validation; 1471 ); 1472 ):; -> 1473 return fit_method(estimator, *args, **kwargs). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/decomposition/_incremental_pca.py:304, in IncrementalPCA.partial_fit(self, X, y, check_input); 298 raise ValueError(; 299 ""n_components=%r invalid for n_features=%d, need ""; 300 ""more rows than columns for IncrementalPCA ""; 301 ""processing"" % (self.n_components, n_features); 302 ); 303 elif not self.n_components <= n_samples:; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227:146,error,error,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227,8,"['down', 'error']","['downsample', 'downsampling', 'error']"
Availability,"GATA2'], **common); save_and_compare_images('master_paga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:2924,toler,tolerance,2924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['toler'],['tolerance']
Availability,Gene filtering using sparse matrix error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1354:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1354,1,['error'],['error']
Availability,Get errors when performing sc.pp.highly_variable_genes!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:4,error,errors,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,1,['error'],['errors']
Availability,Getting Error Variable names are not unique when using .read_10x_h5 function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/534:8,Error,Error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/534,1,['Error'],['Error']
Availability,Getting errors when loading loom files,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247:8,error,errors,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247,1,['error'],['errors']
Availability,"Getting the error: ""numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)"" when running sc.tl.umap with init_pos='paga'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,2,['error'],"['error', 'errors']"
Availability,"Getting the following error with the latest version of scanpy:. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-24-7f6e74b434f4> in <module>; ----> 1 sc.tl.louvain(adata, resolution=0.2, key_added='louvain_r0.2', random_state=10); 2 sc.tl.louvain(adata, resolution=0.1, key_added='louvain_r0.1', random_state=10). ~/xconda/newconda/envs/cpumode/lib/python3.6/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1369:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1369,1,['error'],['error']
Availability,Github install error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482,1,['error'],['error']
Availability,"Good Evening,. My goal here is to get either a Gene barcode or dense matrix from a .h5 file from 10x. I'm currently trying to use the .read_10x_h5() function to help me achieve this. To my understanding I just need to input the file name into the function. When I run my code (See below), I get an error stating that ""Variable names are not unique. To make them unique, call `.var_names_make_unique`."" From the documentation I don't see a way that I can call .var_names_make_unique(). Is there some preprocessing that I'm missing?. ```python; user_input = input(""Enter the path of your file: ""); def convert_h5_to_adata(filename):; filename = str(filename); if os.access(filename, os.R_OK):; sc.read_10x_h5(filename); return; convert_h5_to_adata(user_input); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/534:298,error,error,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/534,1,['error'],['error']
Availability,"Good day!. I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. . <img width=""749"" alt=""Screenshot 2019-07-27 at 12 49 49"" src=""https://user-images.githubusercontent.com/37718031/61993507-06971800-b06d-11e9-815e-acf667f818a5.png"">; <img width=""730"" alt=""Screenshot 2019-07-27 at 12 41 58"" src=""https://user-images.githubusercontent.com/37718031/61993416-edda3280-b06b-11e9-9a4f-7d4a1259cd47.png"">. This happens in the first loop to load all the datasets. If I run only one dataset the same error `(unsupported operand type(s) for +: 'int' and 'str')` showed up when I plot some data quality summary plots:. For instance:; `p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac')`; `adata = adata[adata.obs['mt_frac'] < 0.2]; print('Number of cells after MT filter: {:d}'.format(adata.n_obs))`; `sc.pp.filter_cells(adata, min_genes = 700); print('Number of cells after gene filter: {:d}'.format(adata.n_obs))`. I am using data generated by 10x V3 and CellRanger v3.0.2. I really do not know where the problem is. . I really appreciate any advice/help to solve this issue. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/751:689,error,error,689,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751,1,['error'],['error']
Availability,"Great work! . Python (64bit) throws a memory error when projecting ~1 million cells into 3D UMAP with 40 features (PCs). I suppose that matrix products are super big, but I'm performing it on 256G RAM.; Is there a way to decrease memory usage?; I would appreciate your advice!; Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/710:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/710,1,['error'],['error']
Availability,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702:177,down,downgrades,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702,1,['down'],['downgrades']
Availability,"Haven't done much investigation into why, but the [Fly Cell Atlas](https://flycellatlas.org) head dataset (10x, Stringent, H5AD) causes `sc.tl.embedding_density` to error when `groupby=""annotation_broad_extrapolated""`. ```python; import scanpy as sc; # Warning: 2.5gb; !wget -O s_fca_biohub_head_10x.h5ad https://cloud.flycellatlas.org/index.php/s/LAEybPc2HZnpzKs/download. adata = sc.read_h5ad(""s_fca_biohub_head_10x.h5ad""); sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""); ```. <details>; <summary> traceback </summary>. ```pytb; /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py:563: RuntimeWarning: Degrees of freedom <= 0 for slice; self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,; /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide; c *= np.true_divide(1, fact); /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply; c *= np.true_divide(1, fact); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_4569/1429565136.py in <module>; ----> 1 sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""). ~/github/scanpy/scanpy/tools/_embedding_density.py in embedding_density(adata, basis, groupby, key_added, components); 164 embed_y = adata.obsm[f'X_{basis}'][cat_mask, components[1]]; 165 ; --> 166 dens_embed = _calc_density(embed_x, embed_y); 167 density_values[cat_mask] = dens_embed; 168 . ~/github/scanpy/scanpy/tools/_embedding_density.py in _calc_density(x, y); 19 # Calculate the point density; 20 xy = np.vstack([x, y]); ---> 21 z = gaussian_kde(xy)(xy); 22 ; 23 min_z = np.min(z). /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,2,"['down', 'error']","['download', 'error']"
Availability,"Hej all,. I am using a backed dataset because, when I run the umap scatterplot, the RAM go pretty much crazy on our server. When I use not-backed data, I can do UMAP scatterplots without any problem apart from the memory usage. But now that the data is backed, when running the following:; ```; sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5); ```. I get an error message that seems related to the `h5py` package. Here is the whole trace back. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-a78575d924b7> in <module>; 24 if len(markers) > 0:; 25 print(""Expression plots of "", names, "" markers: "", markers); ---> 26 sc.plotting.tools.scatterplots.umap(all_data_flt_clst, color=markers, cmap=""Blues"", ncols=5); 27 ; 28 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs); 27 If `show==False` a `matplotlib.Axis` or a list of it.; 28 """"""; ---> 29 return plot_scatter(adata, basis='umap', **kwargs); 30 ; 31 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 280 if sort_order is True and value_to_plot is not None and categorical is False:; 281 order = np.argsort(color_vector); --> 282 color_vector = color_vector[order]; 283 _data_points = data_points[component_idx][order, :]; 284 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 474 ; 475 # Perform the dataspace selection.; --> 476 selectio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/440:403,error,error,403,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440,1,['error'],['error']
Availability,"Hej all. it seems there is a problem on the batch correction with bbknn. It gives an error at the pca step of bbknn, but I have problem understanding if this is due to the bbknn package itself or the wrapper of scanpy around it, or if it is due to my data, even though it worked when I used it previously. ```python; sc.external.pp.bbknn(all_data_flt, batch_key='batch', n_pcs=15,); ```. gives the error. ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-23-a9dd619ada2e> in <module>; 1 #sc.neighbors.neighbors(all_data_flt, n_neighbors=40, n_pcs=15); ----> 2 sc.external.pp.bbknn(all_data_flt, n_pcs=15); 3 #sc.tools.umap(all_data_flt). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 params = locals(); 83 kwargs = params.pop('kwargs'); ---> 84 return bbknn(**params, **kwargs). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 215 batch_list = adata.obs[batch_key].values; 216 #call BBKNN proper; --> 217 bbknn_out = bbknn_pca_matrix(pca=pca,batch_list=batch_list,save_knn=save_knn,**kwargs); 218 #optionally save knn_indices; 219 if save_knn:. TypeError: bbknn_pca_matrix() got an unexpected keyword argument 'bbknn'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/514:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514,2,['error'],['error']
Availability,"Hej,. I have been trying to plot the ranked gene groups with a dotplot in this way. ```; sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, layer='imputed') ; ```. or from non-raw data; ```; sc.plotting.tools.rank_genes_groups_dotplot(all_data_flt_clst, n_genes=5, save='.pdf', groupby='batch', dendrogram=False, use_raw=False) ; ```. I get an error regarding the index names of the genes. Other commands for plotting gene rank groups (such as heatmap) show the same problem. The error goes as follows:; ```; KeyError: 'Indices ""[\'PRM2\', \'ACAP1\', \'SPEM1\', \'SPATA3\', \'C10orf62\', \'TNP1\', \'MIR193BHG\', \'PRM1\', \'CCDC179\', \'AC007557.1\', \'SPACA1\', \'ERICH2\', \'RP11-360D2.1\', \'TIPARP-AS1\', \'GS1-124K5.4\', \'DCN\', \'C1S\', \'SERPING1\', \'C1R\', \'SERPINF1\', \'GAGE2A\', \'PTMA\', \'HMGB1\', \'VCX2\', \'ERP29\', \'ZCWPW1\', \'SMC1B\', \'DPH7\', \'SCML1\', \'CLSPN\', \'CSAD\', \'C1QBP\', \'DNAJB6\', \'TCF3\', \'RRBP1\', \'HSP90AA1\', \'TMED10\', \'ART3\', \'BUB1\', \'KRBOX1\', \'B2M\', \'IFITM3\', \'GNG11\', \'IFITM2\', \'IFI27\', \'TYROBP\', \'S100A4\', \'FCER1G\', \'CD163\', \'CYBA\', \'CALD1\', \'IGFBP7\', \'TIMP3\', \'PTGDS\', \'TSHZ2\', \'MT-ND3\', \'MT-ND1\', \'MT-ND2\', \'MT-ATP6\', \'MT-ND4\', \'MT-ND1\', \'HMGN5\', \'MT-ND3\', \'ALDH1A1\', \'MT-ATP6\']"" contain invalid observation/variables names/indices.'; ```. I checked the var_names and obs_names of my object, but they seem totally fine. Do you have any ideas about the origin of the problem? I can post the backtracking of the error if needed :). Cheers,; Samuele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/438:415,error,error,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438,3,['error'],['error']
Availability,"Hej. I have been looking at the single-cell-tutorial repository and tried the `scran` normalization with `R`.; After calculating the size factors in `scran`, I use them to normalize cell-wise my data matrix following the tutorial commands:. ```; adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); ```; When I look for highly expressed genes with. `sc.preprocessing.highly_variable_genes(adata, n_top_genes=5000)`. I get this error (the error does not show up when I use the normalization command from `scanpy` instead of the normalization with size factors from `scran`):. ```; LinAlgError Traceback (most recent call last); <ipython-input-97-96c692867dde> in <module>; ----> 1 sc.preprocessing.highly_variable_genes(adultAll, n_top_genes=10000, flavor='cellranger'). ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 101 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 102 ; --> 103 mean, var = materialize_as_ndarray(_get_mean_var(X)); 104 # now actually compute the dispersion; 105 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in __pow__(self, other); 226 ; 227 def __pow__(self, other):; --> 228 return matrix_power(self, other); 229 ; 230 def __ipow__(self, other):. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603 ;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641,2,['error'],['error']
Availability,"Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py; >>> import os; >>> # p = os.path.join( ""path to outs location""); >>> print(p); ""path to outs location""; >>> print(os.path.exists(p)); True; >>> ad = sc.read_visium(p); ```. ```pytb; Traceback (most recent call last):. Cell In[6], line 1; ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium; raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'; ```. ### Session/scanpy info:; Software versions; Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]; IPython 8.10.0; OS Windows 10 10.0.22621 SP0; scanpy 1.9.3; Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2488:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488,1,['error'],['error']
Availability,"Hello Scanpy,; When I add parameter use_raw=False into sc.tl.rank_genes_groups() and sc.pl.rank_genes_groups_violin(), it generates errors as below.; ![image](https://user-images.githubusercontent.com/75048821/140627341-b0c08fbd-53b1-4ed8-b12d-9be71a65a6a5.png); ![image](https://user-images.githubusercontent.com/75048821/140627351-09708fcd-39ea-4602-8609-eca85ea6b843.png); ![image](https://user-images.githubusercontent.com/75048821/140627356-7faf0462-c852-436e-b69d-22f337dabae6.png). Another question is that, we shouldn't use the adata.raw for plotting becase the adata.raw doesn't regress out the mito gene expressions, should we?. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046:132,error,errors,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046,1,['error'],['errors']
Availability,"Hello Team,; I'm using the **sc.pp.downsample_counts** function on my adata in hopes of downsampling it to match that of another dataset. Running the function doesn't give any errors or seem to fail but when I check the total counts, there seems to be no change. . I'm wondering if there is a problem with my application or there is more going on. `sc.pp.downsample_counts(adata, total_counts=6900, random_state=0, replace=False, copy=False)`. My average total counts before and after running the function is 10000.; Any inputs would be greatly appreciated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2131:88,down,downsampling,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131,2,"['down', 'error']","['downsampling', 'errors']"
Availability,"Hello all,; For these 2 functions,; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; the authors make `inplace=True` as default. Because I want to tranfer the output into an variable, I change these functions to; ```python; a=sc.pp.filter_cells(adata, min_genes=200, inplace=False); sc.pp.filter_genes(a, min_cells=3, inplace=False); ```; but it creates errors and the output of a is NoType:; ```python; aceback (most recent call last):; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py”, line 3343, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File “”, line 2, in; sc.pp.filter_genes(a, min_cells=3, inplace=False) # exclude genes only expressed in <3 cells; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\scanpy\preprocessing_simple.py”, line 259, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ```. Does anybody know why inplace=False doesn’t work?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2030:391,error,errors,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030,1,['error'],['errors']
Availability,"Hello everyone !. I would like to use a custom distance when trying to compute the neighbors graph with `scanpy.pp.neighbors`.; So let's suppose I have a pre-existing distance matrix somewhere, and I just want to use it in the graph generation. Currently, I am getting an error when exceeding 4096 observations in my AnnData object.; I do not have such error when directly using the`umap` python package. ### Full error; ```bash; Traceback (most recent call last):; File ""/home/paul/Documents/Curie/Immunopeptidomics/minimal_bug_scanpy.py"", line 72, in <module>; sc.pp.neighbors(xd,; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,3,['error'],['error']
Availability,"Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:541,error,error,541,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,2,"['Avail', 'error']","['Available', 'error']"
Availability,"Hello!. I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: ; ```; sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations; plt.show(); plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric; sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters; sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'); plt.show(); plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric; sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification; sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'); plt.show(); plt.clf(); ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177:1290,down,down,1290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177,1,['down'],['down']
Availability,"Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error?. Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2156:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156,2,['error'],['error']
Availability,"Hello, . I am using scanpy rank genes groups, and rank genes group filter for differential expression analysis after using a classifier. I often receive errors because statistics cannot be calculated on these types of low count groups. The workaround I have found is to drop these cells from the adata object, and then continue with differential expression. Is there an existing solution for this that is better? Could we consider adding this as a flag to the function call? What I have in mind is a flag like ""ignore_low = True"". The flag would operate by taking the passed adata object, applying the 2 cell filtration internally, and performing differential expression as normal on this internal object. It would then append the relevant uns categories to the original adata object before exiting. The threshold could even be passable to make this more general. . What do we think? Is this too niche for this scale of a repository? In principle, I think that forcing these observations to be dropped is not best practice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3118:153,error,errors,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118,1,['error'],['errors']
Availability,"Hello, . I am using scanpy version 1.4 from bioconda. I am running one of the examples from the code to query datasets - . ```; import scanpy as sc. pbmc = sc.datasets.pbmc3k(); print(pbmc); plotdf = sc.get.obs_df(; pbmc,; keys=[""CD8B"", ""n_genes""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); plotdf.plot.scatter(""X_umap0"", ""X_umap1"", c=""CD8B""); ```. the library can read the dataset but errors out saying `scanpy` has no attribute `get`. I even tried . ```File ""test.py"", line 2, in <module>; from scanpy.get import obs_df; ModuleNotFoundError: No module named 'scanpy.get'; ```. Did the API change for any of this ? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/851:390,error,errors,390,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851,1,['error'],['errors']
Availability,"Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions?. Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version; Scanpy version: 1.9.3; AnnData version: 0.9.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2489:369,error,error,369,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489,2,"['down', 'error']","['download', 'error']"
Availability,"Hello, . Whenever I try to plot gene expression I get the following KeyError, regardless of the gene/plotting function. I have confirmed that all genes I have tried do exist in adata.var_names. Id like to highlight that my adata object was created from h5ad converted from seurat. How can I check the keys? . Thank you!. Lucy. ---. ```python; sc.pl.draw_graph(myeloid, color=['SPP1']); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2645 try:; -> 2646 return self._engine.get_loc(key); 2647 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-94-440b32bde3cc> in <module>(); ----> 1 sc.pl.draw_graph(myeloid, color=['SPP1']). /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:627,toler,tolerance,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['toler'],['tolerance']
Availability,"Hello, I am trying to calculate highly variable genes from my data sets using the above code from the scanpy script published on github. I am facing this error. could someone please help me with this? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1560:154,error,error,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560,1,['error'],['error']
Availability,"Hello, I am trying to use the visualize marker genes tutorial to make some plots. I am importing scanpy in the new way (import scanpy as sc) as suggested in the tutorial but I am getting an error message:. AttributeError Traceback (most recent call last); <ipython-input-5-dfc1e4d9ed06> in <module>(); ----> 1 ax = sc.pl.correlation_matrix(adata, 'cell_types'). AttributeError: module 'scanpy.plotting' has no attribute 'correlation_matrix'. Here are the versions of all the packages I am using:; scanpy==1.4 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Am I missing something ?. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544,1,['error'],['error']
Availability,"Hello, I am unable to import scanpy and the error message shows below:. ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>; from .compute.is_constant import is_constant; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>; from numba import njit; ImportError: cannot import name 'njit' from 'numba' (unknown location)```; ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2438:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438,1,['error'],['error']
Availability,"Hello, everyone,. I am working om fly model. And I have met a problem when I was doing QC step use function pp.calculate_qc_metrics. I have got this error. Can anyone help me? Thanks. The code as follows: . ```python; adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-34-455e630e3278> in <module>; 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. ~\anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 51 return self._get_sliceXslice(row, col); 52 elif col.ndim == 1:; ---> 53 return self._get_sliceXarray(row, col); 54 raise IndexError('index results in >2 dimensions'); 55 elif row.ndim == 1:. ~\anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col); 314 ; 315 def _get_sliceXarray(self, row, col):; --> 316 return self._major_slice(row)._minor_index_fancy(col); 317 ; 318 def _get_arrayXint(self, row, col):. ~\anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx); 735 """"""; 736 idx_dtype = self.indices.dtype; --> 737 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259,1,['error'],['error']
Availability,"Hello,. I am a beginner in the bioinformatics field. I have been used scanpy for one year, and I really like it. But yesterday after I downloaded and installed the new developmental version from scanpy github, when I ran the first command ""import scanpy as sc"", it displayed errors :AttributeError: module 'tables' has no attribute 'which_lib_version'. I don't know how to deal with this error. Does the ""module 'tables' "" in the error message mean pytables? After I saw the message, I reinstalled both pytables and scanpy through conda channel. But the error is not fixed. I thus wish to get some suggestions. Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/853:135,down,downloaded,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853,5,"['down', 'error']","['downloaded', 'error', 'errors']"
Availability,"Hello,. I am having the same issue as issue #1246 but my version of scipy being used with scanpy is not updating. I don't know if this is related to my using an ubuntu server or what's causing this but I was wondering if there is a workaround to make scanpy use a more updated version? I have scipy 1.4.1 installed when I check the version but for some reason scanpy is using 1.01 and I don't know how to change this. I'm a bit new to python so I'm sorry if this is a novice question. I appreciate any help you can offer. I am using an ubuntu server running python 3.6 with the following versions:; sc.logging.print_versions() ; scanpy==1.5.1 anndata==0.7.3 umap==0.4-dev numpy==1.15.0 scipy==1.0.1 pandas==0.23.3 scikit-learn==0.23.1 statsmodels==0.11.1. This is the error message:. ```pytb; computing tSNE; WARNING: You’re trying to run this on 16872 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; computing PCA; with n_comps=50; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-65-c244be664e51> in <module>(); ----> 1 sc.tl.tsne(adata, n_pcs = 50); 2 # UMAP, first with neighbor calculation; 3 sc.pp.neighbors(adata, n_pcs = 50, n_neighbors = 20); 4 sc.tl.umap(adata). ~/.local/lib/python3.6/site-packages/scanpy/tools/_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy); 78 start = logg.info('computing tSNE'); 79 adata = adata.copy() if copy else adata; ---> 80 X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs); 81 # params for sklearn; 82 params_sklearn = dict(. ~/.local/lib/python3.6/site-packages/scanpy/tools/_utils.py in _choose_representation(adata, use_rep, n_pcs, silent); 41 'Falling back to preprocessing with `sc.pp.pca` and default params.'; 42 ); ---> 43 X = pca(adata.X); 44 adata.obsm['X_pca'] = X[:, :n_pcs]; 45 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252:768,error,error,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252,1,['error'],['error']
Availability,"Hello,. I am trying to use the SAM algorithm in my single-cell analysis. I run the SAM function like so:. ```py; sam_obj = sce.tl.sam(adata,inplace=True); ```. The function runs fine and appears to finish training however it crashes when computing the UMAP with the following error:. ```pytb; TypeError: a bytes-like object is required, not 'list'; ```. I'm not sure where this problem is coming from and I have spent the past day installing different versions of python and other dependencies to see if that solves the issue. Maybe naive but I know conda can sometimes be behind in their updates. I installed scanpy following the anaconda instructions here: https://scanpy.readthedocs.io/en/stable/installation.html; And I installed sam-algorithm using pip. Below is the entire output from the function call above. Below this I have included the output of ""conda list"" in case this information is helpful. . Any help would be greatly appreciated. Thank you, Hasan. ```pytb; Self-assembling manifold; Running SAM; RUNNING SAM; Iteration: 0, Convergence: 0.6008695832027542; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 1, Convergence: 0.3743130193917588; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; self.adata.uns[""neighbors""][""connectivities""] = EDM; Iteration: 2, Convergence: 0.029142717058066172; /wynton/home/state/alkhairohr/miniconda3/envs/python_env/lib/python3.6/site-packages/samalg/__init__.py:1165: FutureWarning: This location for 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293:276,error,error,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293,1,['error'],['error']
Availability,"Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.umap(adata, init_pos='paga', method='rapids'); ```. ```pytb; WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1837:227,error,error,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837,1,['error'],['error']
Availability,"Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side.; Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz; > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2161:246,down,download,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161,1,['down'],['download']
Availability,"Hello,. I'm trying out the Graph abstraction and I get this error:; ```; SetKeyError Traceback (most recent call last); <ipython-input-12-928a85d4478e> in <module>(); ----> 1 sc.tl.tsne(adata); 2 sc.tl.draw_graph(adata, random_state=5) # random_state just makes a cosmetic change; 3 sc.write('krumsiek11_blobs', adata). ~/Downloads/scanpy/scanpy/tools/tsne.py in tsne(adata, n_pcs, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, recompute_pca, n_jobs, copy); 108 X_tsne = tsne.fit_transform(X); 109 # update AnnData instance; --> 110 adata.smp['X_tsne'] = X_tsne # annotate samples with tSNE coordinates; 111 logg.info(' finished', t=True, end=' '); 112 logg.info('and added\n'. ~/Downloads/scanpy/scanpy/data_structs/ann_data.py in __setitem__(self, keys, values); 382 # TODO: need to reallocate memory; 383 # or allow storing objects, or use pd.dataframes; --> 384 raise SetKeyError(k, v.dtype, self.dtype[k]); 385 super(BoundStructArray, self).__setitem__(k, v); 386 . SetKeyError: Currently you cannot implicitly reallocate memory:; Setting the array for key X_tsne001of002 with dtype float64 requires too much memory, you should init AnnData with a large enough data type from the beginning.; Probably you try to assign a string of length 8 although the array can only store strings of length 4.; ```. I'm using the latest git version of scanpy.; Any ideas?; Best wishes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/40:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/40,3,"['Down', 'error']","['Downloads', 'error']"
Availability,"Hello,. I've tried setting up your package via pip, as instructed. This crashed out very quickly:. 	mib111492i:~ kp9$ pip install scanpy; 	Collecting scanpy; 	 Downloading scanpy-0.2.9.1.tar.gz (208kB); 		100% |################################| 215kB 2.8MB/s ; 		Complete output from command python setup.py egg_info:; 		Traceback (most recent call last):; 		 File ""<string>"", line 1, in <module>; 		 File ""/private/tmp/pip-build-cx2i4lbu/scanpy/setup.py"", line 39, in <module>; 			readme = readme_f.read(); 		 File ""/Users/kp9/anaconda3/lib/python3.6/encodings/ascii.py"", line 26, in decode; 			return codecs.ascii_decode(input, self.errors)[0]; 		UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); 	; 		----------------------------------------; 	Command ""python setup.py egg_info"" failed with error code 1 in /private/tmp/pip-build-cx2i4lbu/scanpy/. The offender seems to be the stylised README file, so I downloaded the source code, got rid of it, and proceeded with the installation. I'm unsure how representative the following encountered issues are of an ideal pip installation, but I figured I'd bring them to your attention anyway just in case they're relevant:. - h5py crashed out on account of not having hdf5 available. This was remedied via `brew install hdf5`, and it seems like the most likely of these issues to affect other users.; - The installer ignored my 2.1.0 setup of matplotlib, tried to install 2.0.0 in some weird way and crashed out. Installing 2.0.0 via pip (absolutely painlessly, mind you - what was that weird installer that crashed the thing out?) allowed the setup to proceed past this point. This might be an isolated incident, but it seemed weird enough to alert you of just in case.; - As is, louvain crashes immediately and uninformatively when attempts are made to pip it in. Installing from the GitHub source code still works fine though. I'll notify the louvain team of this situation, but this may be of relevan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49:160,Down,Downloading,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49,4,"['Down', 'down', 'error']","['Downloading', 'downloaded', 'error', 'errors']"
Availability,"Hello,. Thank you for developing and maintaining such a useful tool!; I'm trying to integrate two data sets, they're replicates of the same condition. . ```; var_names = adata_002.var_names.intersection(adata_003.var_names); adata_002 = adata_002[:, var_names]; adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002); sc.pp.neighbors(adata_002); sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'); ```. And I got the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-42-b3f5427509ba> in <module>; ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'; ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092:452,error,error,452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092,1,['error'],['error']
Availability,"Hello,. Trying to use sc.tl.umap with initial positions from sc.tl.paga. Seems an error with UMAP from the error log. But it is only called when calling paga positions, UMAP works otherwise. I do see https://github.com/theislab/scanpy/issues/666, and https://github.com/lmcinnes/umap/pull/262, but I am already running scanpy 1.4.4 and umap 0.3.9 so I don't understand how to solve the issue?. Attached error. Any suggestions? ; Thanks!. <img width=""575"" alt=""Screen Shot 2019-08-05 at 19 02 18"" src=""https://user-images.githubusercontent.com/20108378/62485139-c560df80-b7b3-11e9-8333-7e511c263a79.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769,3,['error'],['error']
Availability,"Hello,; When I call 'dpt_scatter' with the groups parameter I get the following error:; NameError: name 'names' is not defined. It looks like this is from line 230 in scanpy/plotting/ann_data.py and the 'names' variable just doesn't exist.; I'm assuming it should just be 'groups'?. Thanks,; Sarah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32,1,['error'],['error']
Availability,"Hello,; it's me again, really thanks for your kindly reply before.; when I analyze my own data using `sc.tl.dpt` with default `n_branches`, it worked well, but when I set `n_branches` more than 0, it occurred an error:; ```no root cell found, no computation of pseudotime; --> To enable computation of pseudotime, pass the index or expression vector; of a root cell. Either add; adata.add['iroot'] = root_cell_index; or (robust to subsampling); adata.var['xroot'] = adata.X[root_cell_index, :]; where ""root_cell_index"" is the integer index of the root cell, or; adata.var['xroot'] = adata[root_cell_name, :].X; where ""root_cell_name"" is the name (a string) of the root cell.; perform Diffusion Pseudotime analysis; using ""X_pca"" for building graph; using stored data graph with n_neighbors = 30 and spectrum; [ 1. 0.9944264293 0.9934666753 0.9925051928 0.9899699688; 0.9893597364 0.9855745435 0.9840251803 0.981688261 0.9806631804]; detect 1 branching; do not consider groups with less than 2742 points for splitting; branching 1: split group 0; WARNING: detected group with only [] cells. ValueError Traceback (most recent call last); <ipython-input-3-b1749d943ac4> in <module>(); ----> 1 get_ipython().run_cell_magic('time', '', 'sc.tl.dpt(adata_corrected,n_jobs=48,n_pcs=30,allow_kendall_tau_shift=False,n_branchings=1)\nsc.logging.print_memory_usage()'). /public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self, magic_name, line, cell); 2113 magic_arg_s = self.var_expand(line, stack_depth); 2114 with self.builtin_trap:; -> 2115 result = fn(magic_arg_s, cell); 2116 return result; 2117 . <decorator-gen-59> in time(self, line, cell, local_ns). /public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/IPython/core/magic.py in <lambda>(f, *a, **k); 186 # but it's overkill for just that one bit of state.; 187 def magic_deco(arg):; --> 188 call = lambda f, *a, **k: f(*a, **k); 189 ; 190 if callable(arg):. /pu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33:212,error,error,212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33,2,"['error', 'robust']","['error', 'robust']"
Availability,"Hello. I tried umap visualization by:. ```; sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None); sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0); sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'); ```; But the cells can't separate well; ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version; ```; anndata 0.7.5; scanpy 1.6.1; ```. I tried another small dataset with `scanpy` using the same parameters as before:; ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper); ```. Now the original `umap` package can do down dimension very well:; ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason?; Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386:942,down,down,942,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386,2,['down'],['down']
Availability,"Hello.; I need some help with this issue. when I run this line, I got an error. . ```py; sc.pl.paga(; adata,; threshold=0, ; solid_edges='connectivities_tree',; dashed_edges='connectivities', ; root='neoblast 1',; layout='rt_circular',; node_size_scale=0.5,; node_size_power=0.9,; max_edge_width=0.7,; fontsize=3.5,; ); ```. ![error](https://user-images.githubusercontent.com/48261734/63892645-beda1800-c9ad-11e9-8f04-f13a5b7a8812.jpg). thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909,2,['error'],['error']
Availability,"Hey! Here's the downsample function I wrote... you may want to change things like defaults or how it does the inplace operation. Best,. Malte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/99:16,down,downsample,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/99,1,['down'],['downsample']
Availability,"Hey! I thought plotting `.var` columns in `sc.pl.violin()` worked previously (and the error message seems to suggest this as well). I am doing the following:; ```; adata_counts.var['dropout_per_gene'] = (adata_counts.X > 0).mean(0); adata_counts.obs['dropout_per_cell'] = (adata_counts.X > 0).mean(1). sc.pl.violin(adata_counts, keys='dropout_per_gene'); ```. and I get this error:; ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-8-463060c90a0b> in <module>(); ----> 1 sc.pl.violin(adata_counts, keys='dropout_per_gene'). ~/scanpy/scanpy/plotting/anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, scale, order, multi_panel, show, xlabel, rotation, save, ax, **kwds); 630 X_col = adata.raw[:, key].X; 631 else:; --> 632 X_col = adata[:, key].X; 633 obs_df[key] = X_col; 634 if groupby is None:. ~/anndata/anndata/base.py in __getitem__(self, index); 1303 def __getitem__(self, index):; 1304 """"""Returns a sliced view of the object.""""""; -> 1305 return self._getitem_view(index); 1306 ; 1307 def _getitem_view(self, index):. ~/anndata/anndata/base.py in _getitem_view(self, index); 1306 ; 1307 def _getitem_view(self, index):; -> 1308 oidx, vidx = self._normalize_indices(index); 1309 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1310 . ~/anndata/anndata/base.py in _normalize_indices(self, index); 1283 obs, var = super(AnnData, self)._unpack_index(index); 1284 obs = _normalize_index(obs, self.obs_names); -> 1285 var = _normalize_index(var, self.var_names); 1286 return obs, var; 1287 . ~/anndata/anndata/base.py in _normalize_index(index, names); 261 return slice(start, stop, step); 262 elif isinstance(index, (int, str)):; --> 263 return name_idx(index); 264 elif isinstance(index, (Sequence, np.ndarray, pd.Index)):; 265 # here, we replaced the implementation based on name_idx with this. ~/anndata/anndata/base.py in name_idx(i); 248 raise IndexError(; 249 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375,2,['error'],['error']
Availability,"Hey!. Here's the downsample function I wrote to downsample count matrices. Now the function is also loaded via the api. Best,. Malte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100:17,down,downsample,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100,2,['down'],['downsample']
Availability,"Hey!. I have recently gotten a quite deeply clinically phenotyped dataset and have been pondering how the metadata should best be stored in an anndata object. It feels redundant to duplicate a label for every cell from the same patient. Instead, one could save patient-level data in `adata.uns` and then have a function that links categories in an obs column to e.g., keys in a dict in `adata.uns`. This would save quite a lot of space in anndata objects if you have a lot of clinical metadata. I'm thinking of this as a hidden function that plotting functions could use instead of just looking for `.obs` columns to plot data. This may be somewhat linked to #619.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/658:168,redundant,redundant,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658,1,['redundant'],['redundant']
Availability,"Hey!. I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```; import pandas as pd; #pd.set_option(""display.max_columns"", None); import numpy as np; import anndata; import scanpy as sc. %store -r df. adata = anndata.AnnData(df); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata); sc.pl.paga(adata, plot=False); sc.tl.umap(adata, init_pos='paga'); ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```; AttributeError Traceback (most recent call last); <ipython-input-7-7cfb2fb3103e> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'); 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 141 import umap; 142 ; --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):; 144 ; 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'; ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978,2,['error'],['error']
Availability,"Hey!. Scanpy does not seem to work correctly together with scikit-learn 0.21.1.; When running the PBMC clustering tutorial (https://github.com/theislab/scanpy-tutorials/blob/master/pbmc3k.ipynb), the produced UMAP plots look very different to the reference.; ![wrong_umap](https://user-images.githubusercontent.com/50872326/58096076-92577880-7bd4-11e9-9383-dda48c4efeac.png). By downgrading scikit-learn to 0.20.0, everything works fine.; The problem seems to arise already at the computation of the neighborhood graph, as the clustering is also different.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/654:379,down,downgrading,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654,1,['down'],['downgrading']
Availability,"Hey!; I just updated to latest master branch and I can no longer load scanpy. `import scanpy as sc` gives me the error:; ``` ---------------------------------------------------------------------------; PackageNotFoundError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. ~/new_scanpy/scanpy/scanpy/__init__.py in <module>; 25 __version__ = get_versions()['version']; 26 ; ---> 27 check_versions(); 28 del get_versions, check_versions; 29 . ~/new_scanpy/scanpy/scanpy/utils.py in check_versions(); 38 ; 39 anndata_version = version(""anndata""); ---> 40 umap_version = version(""umap-learn""); 41 ; 42 if anndata_version < LooseVersion('0.6.10'):. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in version(package); 103 ""Version"" metadata key.; 104 """"""; --> 105 return distribution(package).version; 106 ; 107 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in distribution(package); 84 :return: A ``Distribution`` instance (or subclass thereof).; 85 """"""; ---> 86 return Distribution.from_name(package); 87 ; 88 . ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/importlib_metadata/api.py in from_name(cls, name); 50 return resolved; 51 else:; ---> 52 raise PackageNotFoundError(name); 53 ; 54 @staticmethod. PackageNotFoundError: umap-learn ; ```. I have `umap-learn` 0.3.9 installed. . Scanpy version: 1.4.3+115.g1aecabf; Anndata version: 0.6.22rc1. It seems to work with umap-learn 0.3.8, scanpy 1.4.3+105.gc748b35. and anndata 0.6.22.post1+1.g8dcc3cd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739,1,['error'],['error']
Availability,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,2,['error'],"['error', 'errors']"
Availability,"Hey,. I just stumbled into an issue with scanpy.; If I have an gene or cell annotation that is not 1-dimensional (I store ERCCs as a M x 92 float matrix in col_attrs), it generates an error:; ""Exception: Data must be 1-dimensional"". However, it is allowed by the loompy nomenclature to have multiple dimensions. ; And actually loompy package accepts it. Could it be corrected, so it can be accepted as a valid Loom file/annotation?. Thanks in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/507:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507,1,['error'],['error']
Availability,"Hey,. Was just trying to plot a cluster map when I ran into an error:. ```python; import scanpy.api as sc; from scipy import sparse; A = sparse.rand(100, 100, 0.1, ""csr""). # This works; sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error; sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))); ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-13-f65606c38b22> in <module>; ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 750 g = sns.clustermap(df, row_colors=row_colors, **kwds); 751 else:; --> 752 g = sns.clustermap(df, **kwds); 753 show = settings.autoshow if show is None else show; 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1299 row_cluster=row_cluster, col_cluster=col_cluster,; 1300 row_linkage=row_linkage, col_linkage=col_linkage,; -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws); 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws; 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,; -> 1128 row_linkage=row_linkage, col_linkage=col_linkage); 1129 try:; 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage); 1019 self.dendrogram_row = dendrogram(; 1020 self.data2d, metric=metric, method=method, label=False, axis=0,; -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage); 10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,2,['error'],['error']
Availability,"Heya,. I have been trying to get scanpy loaded and a simple example up and running. . I tried following the "" Clustering 3K PBMCs Following a Seurat Tutorial"" by trying to execute the following code:. ```py; import numpy as np; import pandas as pd; import scanpy as sc; import pdb. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(). results_file = './write/pbmc3k.h5ad' # the file that will store the analysis result. sc.settings.set_figure_params(dpi=80). adata = sc.read_10x_mtx( 'filtered_gene_bc_matrices/hg19/', var_names='gene_symbols', cache=True) . adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; print(adata). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). pdb.set_trace(); ```. It sadly spits out the following output (see below), it seems like a mismatch of data structures somewhere inside the code. Or I hope I am trying to run an out of date example file. Thanks for all your help in advance.; Cheers. ```pytb; > scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 ; ... reading from cache file cache/filtered_gene_bc_matrices-hg19-matrix.h5ad; AnnData object with n_obs × n_vars = 2700 × 32738 ; var: 'gene_ids'. Traceback (most recent call last):; File ""test.py"", line 23, in <module>; sc.pp.filter_cells(adata, min_genes=200); File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py"", line 126, in filter_cells; adata._inplace_subset_obs(cell_subset); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1372, in _inplace_subset_obs; adata_subset = self[index].copy(); File ""/Users/Person/Library/Python/3.6/lib/python/site-packages/anndata-0.6.22.post1-py3.6.egg/anndata/core/anndata.py"", line 1230, in __getitem__; return self._getitem_view(inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734:321,error,errors,321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734,1,['error'],['errors']
Availability,"Hi - excellent software, thanks! - . but I do have a problem. If i load a disk backed dataset, I cannot run `sc.tl.score_genes`. Given these two sets:; ```py; ad = sc.read_h5ad('scdataset.h5ad', backed='r+'); ad2 = sc.read_h5ad('scdataset.h5ad'); ```; and; ```py; random_genes = list(ad.var_names.to_series().sample(100)); ```; this works perfectly:; ```py; sc.tl.score_genes(ad2, random, score_name=""random100"", random_state=42); ```; but, this:; ```py; sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42); ```; yields the following error:; ```pytb; -----------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-113-9cb28e089b25> in <module>; ----> 1 sc.tl.score_genes(ad, random, score_name=""random100"", random_state=42). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 90 else:; 91 obs_avg = pd.Series(; ---> 92 np.nanmean(_adata[:, gene_pool].X, axis=0), index=gene_pool) # average expression of genes; 93 ; 94 obs_avg = obs_avg[np.isfinite(obs_avg)] # Sometimes (and I don't know how) missing data may be there, with nansfor. <__array_function__ internals> in nanmean(*args, **kwargs). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in nanmean(a, axis, dtype, out, keepdims); 949 cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims); 950 tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims); --> 951 avg = _divide_by_count(tot, cnt, out=out); 952 ; 953 isbad = (cnt == 0). ~/.pyenv/versions/mfpy372/lib/python3.7/site-packages/numpy/lib/nanfunctions.py in _divide_by_count(a, b, out); 216 else:; 217 if out is None:; --> 218 return a.dtype.type(a / b); 219 else:; 220 # This is questionable, but currently a numpy scalar can. ValueError: setting an array element with a sequence.; ```. thanks; Mark",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/883:553,error,error,553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883,2,"['error', 'mask']","['error', 'mask']"
Availability,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203:187,error,error,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203,1,['error'],['error']
Availability,"Hi @fidelram ,. When I try to use . ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain'); ```; I get this heatmap. . ![louv1](https://user-images.githubusercontent.com/11874103/54995344-d2c8ba80-4fc6-11e9-84fe-4f659915293d.png). But as soon as I add ```standard_scale='var'```:. ```; plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'); ```. I get the following error. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-24-4ac38158d4d0> in <module>; ----> 1 plt = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', standard_scale='var'). [...]/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. [...]/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1803 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1804 RuntimeWarning, stacklevel=2); -> 1805 return func(ax, *args, **kwargs); 1806 ; 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. [...]/lib/python3.6/site-packages/matplotlib/axes/_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5762 kwargs.setdefault('snap', False); 5763 ; -> 5764 collection = mcoll.PolyCollection(verts, **kwargs); 5765 ; 5766 collection.set_alpha(alpha). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). [...]/lib/python3.6/site-packages/matplotlib/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/559:410,error,error,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/559,1,['error'],['error']
Availability,"Hi Alex, . Here is an interesting bug with scanpy. For developers, it is useful to be able to reload a previously imported module within the environment containing useful variables and data for testing (a sample scRNA dataset) after changing scanpy's source code. However, scanpy cannot be reloaded. This means that to test, one has to stop the kernel, restart, reload all of the data needed for a plot and then test a plotting function that was just modified (for instance). . Here is a way to demonstrate the reload failure easily:; 1. open utils.py and add the print statement to track the descend_classes_and_funcs() function. ```py; #utils.py; def annotate_doc_types(mod: ModuleType, root: str):; for c_or_f in descend_classes_and_funcs(mod, root):; print(c_or_f) #added line to track descend_classes_and_funcs() function--TR; c_or_f.getdoc = partial(getdoc, c_or_f); ```. 2. open ipython. ```py; import scanpy as sc; # prints out a bunch of function names from the descend_classes_and_funcs() function. import importlib; importlib.reload(sc); # endless loop of function names from the descend_classes_and_funcs() function; # due to recursive yield statement; ```. So what is the purpose of this function? And can it be altered to allow reload? It is called when __init__.py is run by sc.annotate_doc_types(sys.modules[__name__], 'scanpy'). . ```py; #utils.py. def descend_classes_and_funcs(mod: ModuleType, root: str):; for obj in vars(mod).values():; if not getattr(obj, '__module__', getattr(obj, '__qualname__', getattr(obj, '__name__', ''))).startswith(root):; continue; if isinstance(obj, Callable):; yield obj; if isinstance(obj, type):; yield from (m for m in vars(obj).values() if isinstance(m, Callable)); elif isinstance(obj, ModuleType):; yield from descend_classes_and_funcs(obj, root); ```. _________________________________________________________. It is possible to remove the scanpy manually by:. ```py; import sys; sys.modules.pop('scanpy'); ```. and then import scanpy from scr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/468:518,failure,failure,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468,1,['failure'],['failure']
Availability,"Hi Alex, thank you for this amazing package. I would like to use it for my analysis, but I cannot figure it out why I'm getting this error when I try to include more annotation on my samples. ; Basically, I was following your example here: . import pandas as pd; anno = pd.read_csv(filename_sample_annotation); adata.obs['cell_groups'] = anno['cell_groups'] . However, when I tried with my cvs file, I got Nan for each row and I don't understand. ; The pd data frame is fine, but then the data.var['key'] = NaN NaN NaN ... everywhere..; I post here my code: . **import pandas as pd. anno = pd.read_csv(path+'sample_anno.csv',header=0); anno.head(); adata.var['pools']= anno['pools']; adata.var**; ![updated_adata var](https://user-images.githubusercontent.com/20638667/35852492-59e9806c-0b2b-11e8-94e2-103c18792cbb.png); ![anno_dataframe](https://user-images.githubusercontent.com/20638667/35852504-5f5a04d6-0b2b-11e8-9c91-0e0d61da3810.png). Thank you in advance, . Elisabetta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74:133,error,error,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74,1,['error'],['error']
Availability,"Hi Alex,. UMAP throws an error if I use `scanpy.tl.ump` with initial positions from `sc.tl.paga`. Based on the error (see below) I thought it was a problem of UMAP itself. However, the error is not thrown when called without initial positions from paga. Here is the output / error:. ```pytb; sc.tl.umap(adata, init_pos='paga'). computing UMAP; using 'X_pca' with n_pcs = 50. ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-35-924452b37e5b> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy); 137 neigh_params.get('metric', 'euclidean'),; 138 neigh_params.get('metric_kwds', {}),; --> 139 verbose=max(0, verbosity-3)); 140 adata.obsm['X_umap'] = X_umap # annotate samples with UMAP coordinates; 141 logg.info(' finished', time=True, end=' ' if _settings_verbosity_greater_or_equal_than(3) else '\n'). /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,4,['error'],['error']
Availability,"Hi Guys, . this it perhaps rather a question than issue, ; Is there a way to export raw data in csv format? If I do this ; `adata.write_csvs(""filename"", skip_data=False)` . it works perfectly fine . but with ; `adata.raw.write_csvs(""filename"", skip_data=False)`. I get this error; `AttributeError: 'Raw' object has no attribute 'write_csvs'`. Thanks,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506,1,['error'],['error']
Availability,"Hi Scanpy team,. A potentially silly question. I'm having problems changing vmax in sc.pl.scatter. I want to set 'dpt_pseudotime' vmax to 0.5, similar to how vmax and vmin can be changed, for example, in sc.pl.umap. I tried the following:. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', color='dpt_pseudotime', size=5, use_raw=False, ; color_map='RdYlBu_r', vmax=0.5). But get the following error:. ![image](https://user-images.githubusercontent.com/49629901/66955933-64fee180-f031-11e9-90c2-0f12a392786b.png). I read in the scanpy.pl.scatter documentation that kwargs can be used to set vmax. I tried this approach, but got the same result as above:. kwargs={'vmax':0.5}. with axes_style({'axes.grid': False}):; sc.pl.scatter(adata_0_1, x='Vim', y='Lyz2', ; color='dpt_pseudotime', size=5, use_raw=False, color_map='RdYlBu_r', **kwargs). I tried to find a solution online with no success. Any help/suggestions will be appreciated. P.S: This is my first post and I'm a huge fan of your package. Keep up the great work!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/875:428,error,error,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/875,1,['error'],['error']
Availability,"Hi all!; I want to use ingest after BBKNN but it gives an error related to the metric.; If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1122:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122,1,['error'],['error']
Availability,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,2,['error'],"['error', 'errors']"
Availability,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1739:389,down,downstream,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739,1,['down'],['downstream']
Availability,"Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2; scanpy = 1.7.1. Does anyone encounter similar issue?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696:177,error,error,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Hi all,; I'm having a trouble in running a code: ; sc.tl.louvain(adata); So, when I try to run the code, it has an error saying that; ERROR: Failed building wheel for louvain; I tried to install louvain in anaconda prompt, and I can't install it.; When I use:; pip install louvain; to install louvain, I have an error that . ```pytb; ERROR: Command errored out with exit status 1:; 'c:\users\prince and jacky\anaconda3\python.exe' \; -u \; -c '; import sys, setuptools, tokenize; sys.argv[0] = "".../louvain/setup.py""; __file__="".../louvain/setup.py""; f=getattr(tokenize, ""open"", open)(__file__); code=f.read().replace(""\r\n"", ""\n""); f.close(); exec(compile(code, __file__, ""exec"")); ' \; install \; --record '.../install-record.txt' \; --single-version-externally-managed \; --compile; Check the logs for full command output.; ```. I also tried to install using different codes such as:. ```bash; conda install -c conda-forge louvain; ```. There's an error saying that:; PackagesNotFoundError: The following packages are not available from current channels:. - louvain. Can anyone help me with solving this issue? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/786:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786,7,"['ERROR', 'avail', 'error']","['ERROR', 'available', 'error', 'errored']"
Availability,"Hi all,; Thanks to develop the great tools for singlecell analysis.; <!-- Please give a clear and concise description of what the bug is: -->; The h5ad file was generated by scanpy workflow using function write.h5ad(), nevertheless, ; as of taking the outputed file h5ad of scanpy as file imported Seurat package using ReadH5AD triggerred error like below:; Error in file [[""obs""]] []: objects of category 'environment' cannot take a subset; What happen in this situation? ; and how to fix it?; any advices would be grateful; <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; Python 3.8.2 ; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy 1.4.6; >",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1198:339,error,error,339,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hi all:. it seems there is a problem on the batch correction with bbknn. It gives an error at the compute_connectivities_umap() step of bbknn. Version of packages:. ```; scanpy==1.4.2 anndata==0.6.19 umap==0.3.8 numpy==1.15.4 scipy==1.2.1; pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Cmds:. ```py; import scanpy.external as sce; sce.pp.bbknn(adata, batch_key='sample', copy=False); ```. Error info:. ```pytb; sce.pp.bbknn(adata, batch_key='sample', copy=False); computing batch balanced neighbors; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-34-5b7ebd13c9e6> in <module>; 1 # Correct; 2 #sc.pp.pca(adata, n_comps=50, svd_solver='arpack'); ----> 3 sce.pp.bbknn(adata, batch_key='sample', copy=False, n_pcs=15). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/_bbknn.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 82 except ImportError:; 83 raise ImportError('Please install bbknn: `pip install bbknn`.'); ---> 84 return bbknn(**params, **kwargs). ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn(adata, batch_key, save_knn, copy, **kwargs); 215 batch_list = adata.obs[batch_key].values; 216 #call BBKNN proper; --> 217 bbknn_out = bbknn_pca_matrix(pca=pca,batch_list=batch_list,save_knn=save_knn,**kwargs); 218 #optionally save knn_indices; 219 if save_knn:. ~/miniconda3/lib/python3.6/site-packages/bbknn/__init__.py in bbknn_pca_matrix(pca, batch_list, neighbors_within_batch, n_pcs, trim, approx, n_trees, use_faiss, metric, bandwidth, local_connectivity, save_knn); 272 	dist, cnts = compute_connectivities_umap(knn_indices, knn_distances, knn_indices.shape[0], ; 273 knn_indices.shape[1], bandwidth=bandwidth,; --> 274 											 local_connectivity=local_connectivity); 275 #optional trimming; 276 if trim:. TypeError: compute_connectivities_umap() got an unexpected keyword argument 'bandwidth'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744:461,down,downstream,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744,1,['down'],['downstream']
Availability,"Hi everyone,; I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files; TypeError: must be str, not list. ----------------------------------------; Failed building wheel for scanpy; Running setup.py clean for scanpy; Failed to build scanpy; Installing collected packages: scanpy, decorator; Running setup.py install for scanpy ... error; Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:; running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; creating build/lib/scanpy/tools; copying scanpy/tools/dpt.py -> build/lib/scanpy/tools; copying scanpy/tools/paga.py -> build/lib/scanpy/tools; copying scanpy/tools/louvain.py -> build/lib/scanpy/tools; copying scanpy/tools/_utils.py -> build/lib/scanpy/tools; copying scanpy/tools/pca.py -> build/lib/scanpy/tools; copying scanpy/tools/umap.py -> build/lib/scanpy/tools; copying scanpy/tools/sim.py -> build/lib/scanpy/tools; copying scanpy/tools/tsne.py -> build/lib/scanpy/tools; copying scanpy/tools/__init__.py -> build/lib/scanpy/tools; copyi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,2,['error'],['error']
Availability,"Hi guys,. I am getting the following error after running this:. ```py; sc.pl.dotplot(adata, marker_genes1, groupby='louvain'); ```; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-138-e642551f77de> in <module>(); ----> 1 sc.pl.dotplot(adata, marker_genes1, groupby='louvain'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, color_map, dot_max, dot_min, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1350 if isinstance(var_names, str):; 1351 var_names = [var_names]; -> 1352 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 1353 ; 1354 # for if category defined by groupby (if any) compute for each var_name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 495 ; 496 def __getitem__(self, index):; --> 497 oidx, vidx = self._normalize_indices(index); 498 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 499 else: X = self._adata.file['raw.X'][oidx, vidx]. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_indices(self, packed_index); 523 obs, var = super()._unpack_index(packed_index); 524 obs = _normalize_index(obs, self._adata.obs_names); --> 525 var = _normalize_index(var, self.var_names); 526 return obs, var; 527 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_index(index, names);",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,"Hi guys,. Sorry I am new to github, I just posted this a comment on a closed thread (#530) and wasn't sure if that would be seen or not so I am just posting it up in as a new issue, just in case. I am having trouble running the rank_gene_groups test using wilcoxon, every time I try it throws a math domain error. I think this might be a duplicate of #566. As with the OP in #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:307,error,error,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,2,['error'],['error']
Availability,"Hi guys,; I am trying to open a .loom file from : http://scope.aertslab.org/#/53d2bb24-9335-48d4-b874-eab05dd8c690/Aerts_Fly_AdultBrain_Filtered_57k.loom/gene. I can open the .loom file by:. ```py; loom_object = loompy.connect('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. However i would like to open it with scanpy by:. ```py; loom_file = sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom', validate=False); ```. and i get the following error:. ```pytb; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-26-3a0e0ee3248f> in <module>(); ----> 1 loom_file=sc.read_loom('Aerts_Fly_AdultBrain_Filtered_57k.loom',validate=False). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\readwrite\read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/924:460,error,error,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924,1,['error'],['error']
Availability,"Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips?. ```; ad.X = ad.obsm['raw_data'].copy(); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1817:141,recover,recover,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817,1,['recover'],['recover']
Availability,"Hi scanpy team,; I am having trouble reading in a loom file using `read_loom`. I started a jupyter lab session in a conda environment and tried to read in a loom file from http://scope.aertslab.org/#/Bernard_Thienpont , under the User Uploaded -> Uncategorized tab (Thienpont_T-cell_v4_R_fixed.loom). Here are the relevant parts of my conda environment; ```; loompy 2.0.15 <pip>; python 3.6.6 h5001a0f_0 conda-forge; anndata 0.6.11 <pip>; scanpy 1.3.2 <pip>; ```; Here is the error below, I don't know if this is an issue with the latest loompy version? Thanks so much for any help! -Orr; ```; import scanpy.api as sc ; sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-2-3e86e297513a> in <module>; 1 import scanpy.api as sc; ----> 2 sc.read_loom('./Thienpont_T-cell_v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names); 142 filename = fspath(filename) # allow passing pathlib.Path objects; 143 from loompy import connect; --> 144 with connect(filename, 'r') as lc:; 145 ; 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version); 1151 Note: if validation is requested, an exception is raised if validation fails.; 1152 	""""""; -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version); 82 lv = loompy.LoomValidator(version=spec_version); 83 if not lv.validate(filename):; ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); 85 ; 86 self._file = h5py.File(filename, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/320:476,error,error,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320,1,['error'],['error']
Availability,"Hi there! Thanks for adding the ingest method to scanpy!; I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```; KeyError Traceback (most recent call last); <ipython-input-22-a805d117788e> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 115 labeling_method = labeling_method * len(obs); 116 ; --> 117 ing = Ingest(adata_ref); 118 ing.fit(adata); 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata); 268 ; 269 if 'neighbors' in adata.uns:; --> 270 self._init_neighbors(adata); 271 ; 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata); 229 else:; 230 dist_args = (); --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]; 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args); 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```; I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1108:404,error,error,404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108,1,['error'],['error']
Availability,"Hi there,. I seem to have trouble analyzing a dataset. https://www.dropbox.com/s/og5lw42chh2qujm/Trial_data1.csv?dl=0. If I run sc.pp.log1p (adata), I get the following error. . TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''. I could normalize it on my own and say if I do a PCA analysis and try to plot the results, I get the following error. sc.pl.pca(adata, color = 'DAPI'); TypeError: object of type 'numpy.int64' has no len(). If I plot it without the color, it does work though. . Below is how I go from CSV to AnnData. # Read File; x = pd.read_csv('Trial_data1.csv', delimiter=',', index_col=0). # Convert to AnnData; file_url = 'https://raw.githubusercontent.com/ajitjohnson/Jupyter-Notebooks/master/py_scripts/mi_pp_anndata.py'; exec(open(wget.download(file_url)).read()); adata = mi_pp_anndata (x). Any help is appreciated. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435,3,"['down', 'error']","['download', 'error']"
Availability,"Hi there,. I was trying do dig down to understand the problem in #559 , and I found out that in my ```plotting/_anndata.py``` [these lines](https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/plotting/_anndata.py#L828-L837) and all the ones related to ```standard_scale``` are missing. So I created a new conda environment and tried to install a new version of scanpy, but this did not solve the issue (i.e. the problem is not with my old environment) as these lines are still missing. . When I tried to replace the file and re-run my heatmap I got a different error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); <ipython-input-5-49e0357ed731> in <module>; ----> 1 sc.pl.matrixplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True, standard_scale='var'). /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show, save, **kwds); 1644 var_names=var_names,; 1645 var_group_labels=var_group_labels,; -> 1646 var_group_positions=var_group_positions); 1647 ; 1648 var_group_labels = dendro_data['var_group_labels']. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions); 2332 """"""; 2333 ; -> 2334 key = _get_dendrogram_key(adata, dendrogram, groupby); 2335 ; 2336 dendro_info = adata.uns[key]. /anaconda3/envs/test/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2406 ; 2407 if dendrogram_key not in adata.uns:; -> 2408 from ..tools._dendrogram import dendrogram; 2409 logg.warn(""dendrogram data not found (using key={}). Running `sc.tl.den",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560:31,down,down,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560,2,"['down', 'error']","['down', 'error']"
Availability,"Hi there,. While running ```sc.pp.highly_variable_genes(adata.X)``` I got the following error:. ```AttributeError: X not found```. I then ran ```sc.pp.highly_variable_genes(adata)``` and got the following:. ```ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]). You can drop duplicate edges by setting the duplicates kwarg ```. The older ```sc.pp.filter_genes_dispersion(adata.X)``` works fine. Do you know how to fix this?. Thank you!. **Info**: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391:88,error,error,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391,1,['error'],['error']
Availability,"Hi there,; using `sc.read(filename, ext='txt')` I get the following irrelevant warning:; `WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].; WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].`; (filename is `GSE136689_Counts_Matrix_AllCells_E8.5_E9.0_E9.5.txt`). digging in the error is raised by the `readwrite` module's function `is_valid_filename(filename)`, that checks the extensions regardless of the 'ext' parameter the `sc.read` function gets, and if it passes it sends it to `_read`. inside the `_read` function, there is a second call to `is_valid_filename`, which raises the second warning (with exactly the same text). seeing as this is the process, i don't get why even have the `ext` parameter, because currently it seams like it is only used to indicate when someone uses an unsupported extension; ; #### Versions. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; PyQt5 NA; appnope 0.1.3; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.05.18.1; cffi 1.15.0; chardet 4.0.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.05.0; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fastcluster 1.1.26; fsspec 2022.3.0; gprofiler 1.0.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.17.0; kiwisolver 1.4.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.0; numpy 1.21.5; packaging 21.3; pandas 1.4.0; parso 0.8.3; pexpect 4.8.0; phyloproc NA; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2288:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288,1,['error'],['error']
Availability,"Hi there. Everytime I run the code _sc.pp.neighbors_ the kernel dies. Unfortunately, there is no error message or error code. It just dies while computing neighbors. Other scanpy codes like _sc.pp.filter_cells_ and _sc.pp.filter_genes_ work without a problem. I'm using:. - windows 10 64-bit 24 gb ram; - python 3.8.5 in jupyter notebook; - numpy 1.19.4; - scanpy 1.6.0. Is there someone who would be able to solve this issue?; Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567,2,['error'],['error']
Availability,"Hi there. Love the package. I was working in a google colab notebook, and installed scanpy as 'pip install scanpy'. Then when using the method: sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). I got this error:; ----------------------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-54-c0d016811ded> in <module>(); ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). 5 frames; /usr/local/lib/python3.6/dist-packages/statsmodels/distributions/edgeworth.py in <module>(); 5 import numpy as np; 6 from numpy.polynomial.hermite_e import HermiteE; ----> 7 from scipy.misc import factorial; 8 from scipy.stats import rv_continuous; 9 import scipy.special as special. ImportError: cannot import name 'factorial'; ----------------------------------------------------------------------------------------. Seems that scipy.misc.factorial is depreciated and is now under scipy.special.factorial. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687:211,error,error,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687,1,['error'],['error']
Availability,"Hi!. I have tried using the tutorial for basic spatial analysis available in the docs.; Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```; sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",; groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],; alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only.; values = values.replace(values.categories.difference(groups), np.nan); ```; The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2362:64,avail,available,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362,1,['avail'],['available']
Availability,"Hi!; As someone else posted on [stackoverflow](https://stackoverflow.com/questions/54366505/importerror-dll-load-failed-while-file-is-in-working-directory/54441575#54441575), there seem to be problems with the tables dependencies for windows users resulting in the following error when importing scanpy:. ```pytb; >>> import scanpy; ...; File ""C:\Miniconda3\envs\py36\lib\site-packages\scanpy\readwrite.py"", line 9, in; import tables; File ""C:\Miniconda3\envs\py36\lib\site-packages\tables__init__.py"", line 131, in; from .file import File, open_file, copy_file; File ""C:\Miniconda3\envs\py36\lib\site-packages\tables\file.py"", line 35, in; from . import hdf5extension; ImportError: DLL load failed: The specified procedure could not be found.; ```. I've also posted an answer suggestion there. Maybe you could require h5py to have a fixed older version like 2.8 to avoid this problem for other windows users. Downgrading to that version worked for me.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454:275,error,error,275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454,2,"['Down', 'error']","['Downgrading', 'error']"
Availability,"Hi, . **Issue**: When I try to use the multipanel option, the command runs without errors but the plot never shows up:. `sc.pl.violin(adata, keys = ['IL10', 'IFNG', 'CD3G'], multi_panel = None, groupby=None)`. **Question**: Is there a way to split the violin plots form the sc.pl.violin() into a specific number of rows? Similar to the `ncols=` in R?; ; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/348:83,error,errors,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348,1,['error'],['errors']
Availability,"Hi, . I have an issue with the standard_scale ='var' function.; Whenever I try to make any plot and scaling the data from 0 to 1 with the standard_scale = 'var' function I get the following error:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-432-bef389f3fd99> in <module>; ----> 1 gs = sc.pl.matrixplot(adata, marker_genes, groupby='louvain', dendrogram=True, standard_scale='var'). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\scanpy\plotting\_anndata.py in matrixplot(adata, var_names, groupby, use_raw, log, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, show, save, **kwds); 1683 _plot_dendrogram(dendro_ax, adata, ticks=y_ticks); 1684 ; -> 1685 pc = matrix_ax.pcolor(mean_obs, edgecolor='gray', **kwds); 1686 ; 1687 # invert y axis to show categories ordered from top to bottom. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\__init__.py in inner(ax, data, *args, **kwargs); 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),; 1809 RuntimeWarning, stacklevel=2); -> 1810 return func(ax, *args, **kwargs); 1811 ; 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\axes\_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5773 kwargs.setdefault('snap', False); 5774 ; -> 5775 collection = mcoll.PolyCollection(verts, **kwargs); 5776 ; 5777 collection.set_alpha(alpha). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). ~\AppData\Local\conda\conda\envs\Scanpy\lib\site-packages\matplotlib\collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565,1,['error'],['error']
Availability,"Hi, . I have been trying to apply filters to an object within `scanpy` and I got the following error (See attachment). . Do you have an idea of what's going on? . ![image](https://user-images.githubusercontent.com/3297906/62468966-2aeea500-b78f-11e9-809f-ab0c0c22b0b7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/768:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768,1,['error'],['error']
Availability,"Hi, . I tried to run `sc.tl.highly_variable_genes` with `flavor=CellRanger` and `n_top_genes = 2000`. I obtained the following error:; ```pytb; /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 280 n_top_genes=n_top_genes,; 281 n_bins=n_bins,; --> 282 flavor=flavor,; 283 ); 284 . /home/miniconda3/envs/dev/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 141 dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]; 142 dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower; --> 143 disp_cut_off = dispersion_norm[n_top_genes-1]; 144 gene_subset = np.nan_to_num(df['dispersions_norm'].values) >= disp_cut_off; 145 logg.debug(. IndexError: index 1999 is out of bounds for axis 0 with size 1898; ```. I run scanpy in Python 3.7 (linux machine) with the following versions:; ```; scanpy==1.4.5.dev114+gd69832a anndata==0.6.22.post1 umap==0.3.9 numpy==1.17.0 scipy==1.3.0 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```. I suggest to check if `n_top_genes` is larger than `len(dispersion_norm)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/834:127,error,error,127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/834,1,['error'],['error']
Availability,"Hi, . I'm using your package tl.diffmap in my analysis, and I'm having some difficulties. I have a dataframe I have converted into an anndata object adata. I run the following lines to prepare it for tl.diffmap:. `pp.pca(adata,n_comps=50)`; `pp.neighbors(adata, knn = False, method = 'gauss', n_neighbors = 20)`. I then perform the diffmap:. `tl.diffmap(adata, n_comps = 3)`. and I get the following error:. ![Screen Shot 2019-05-15 at 6 11 47 PM](https://user-images.githubusercontent.com/43049941/58586913-25725d00-822a-11e9-930a-9165efdf60f9.png). I am not sure what I am doing incorrectly here, and I was hoping you could help!. Furthermore, I was wondering why n_comps must be greater than 2?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/668:400,error,error,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/668,1,['error'],['error']
Availability,"Hi, . Im using scanpy 1.4.2 to analyze my data, using the following command:. `sc.pp.highly_variable_genes(heart_cmc, flavor = 'cell_ranger', n_top_genes = 1000)`. However, instead of getting 1000 HVG, it reports 1488 HVG. Similar thing happens with higher numbers of HVG (e.g. `n_top_genes = 2000` returns 1999). The scaling then fails with a following error:; _ValueError: The first guess on the deviance function returned a nan. This could be a boundary problem and should be reported._. Any suggestions on how to fix it? When I dont specify n_top_genes, the thing runs without problems.; Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/662:354,error,error,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/662,1,['error'],['error']
Availability,"Hi, . Thanks for the awesome tool!. May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, ; Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1510:260,error,error,260,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510,1,['error'],['error']
Availability,"Hi, . is there a possibility to calculate _downregulated_ genes between two clusters? In the function `tl.rank_genes_groups()` I did not find such option though it should be possible with the Wilcoxon test. Afaik in `Seurat.FindMarkers()` there is an option `only.pos` for the Wilcoxon test (https://www.rdocumentation.org/packages/Seurat/versions/3.0.0/topics/FindMarkers).; Following another discussion here about DEG I tried to switch to MAST to get around that but it seems to be available only through R (https://github.com/RGLab/MAST/issues/102). Also Wilcoxon did reasonable well in a recent paper (https://www.nature.com/articles/nmeth.4612).. . Thanks!; Tilo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625:484,avail,available,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625,1,['avail'],['available']
Availability,"Hi, ; I am following the example _robustness.ipynb_ and I get the errors ; _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_; when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it?. Many thanks,; Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/110:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110,1,['error'],['errors']
Availability,"Hi, ; I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : ; `Exception: Genome GRCm38 does not exist in this file.`; But I'm sure it's this genome string in my file. . Reading the same file with ; `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`; I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ???; Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/132:51,error,errors,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132,2,['error'],"['error', 'errors']"
Availability,"Hi, I am reproducing this tutorial https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb. the line sc.pp.neighbors(adata) produces the following error:. Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!. Ubuntu 18.04; Python 3.6.6. scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . Can you help me? Thank You",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280,1,['error'],['error']
Availability,"Hi, I am using anndata 0.6.21 and scanpy 1.4.3; I executed this code:; ```; sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata = adata[:, adata.var['highly_variable']]; ```. and I got this error:; `AssertionError: Don’t call _normalize_index with non-categorical/string names; `; Can you help me?. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747,1,['error'],['error']
Availability,"Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---; ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-92-a8f4e965724c> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 607 for col in test_obj.stats.columns.levels[0]:; 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(; --> 609 index=False, column_dtypes=dtypes[col]; 610 ); 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'; ```; I was wondering that its associate with my pandas version? or other issues?; my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1478:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478,1,['error'],['error']
Availability,"Hi, I hit this error when trying to filter genes.; A minimal working example is included below. Any help appreciated. ```; def paul15_raw():; filename = 'data/paul15/paul15.h5'; backup_url = 'http://falexwolf.de/data/paul15.h5'; adata = sc.read(filename, 'data.debatched', backup_url=backup_url); # each row has to correspond to a sample, therefore transpose ; adata = adata.transpose() # cluster assocations identified by Paul et al.; clusters = sc.read(filename, 'cluster.id', return_dict=True)['X'].flatten(); # names reflecting the cell type identifications from the paper; cell_types = {i: 'Ery' for i in range(1, 7)}; cell_types[7] = 'MEP'; cell_types[8] = 'Mk'; cell_types[9] = 'GMP'; cell_types[10] = 'GMP'; cell_types[11] = 'DC'; cell_types[12] = 'Baso'; cell_types[13] = 'Baso'; cell_types[14] = 'Mo'; cell_types[15] = 'Mo'; cell_types[16] = 'Neu'; cell_types[17] = 'Neu'; cell_types[18] = 'Eos'; cell_types[19] = 'Other'; adata.smp['paul15_clusters'] = [str(i) + cell_types[i] for i in clusters.astype(int)]; infogenes_names = sc.read(filename, 'info.genes_strings', return_dict=True)['X']; # just keep the first of the two equivalent names per gene ; adata.var_names = np.array([gn.split(';')[0] for gn in adata.var_names]); # remove 10 corrupted gene names ; infogenes_names = np.intersect1d(infogenes_names, adata.var_names); # restrict the data to the 3461 informative genes ; adata = adata[:, infogenes_names]; adata.add['iroot'] = np.flatnonzero(adata.smp['paul15_clusters'] == '7MEP')[0]; return adata; ; adata = paul15_raw(); afilter = sc.pp.recipe_zheng17(adata, n_top_genes=1000, zero_center=True, plot=True, copy=True); ```. or ; ```; afilter = sc.pp.filter_genes_dispersion(adata, n_top_genes=1000); ```. both fail with ; ```AttributeError: 'Series' object has no attribute 'is_dtype_equal'```; when computing the dispersion norm (line 207, simple.py); ```; 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs; --> 208 - disp_mean_bin[df['mea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34,1,['error'],['error']
Availability,"Hi, I hit this error:. AttributeError Traceback (most recent call last); <ipython-input-3-282f1d56354f> in <module>(); ----> 1 sc.pp.magic(adata, verbose=2). c:\scanpy\scanpy\scanpy\preprocessing\magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 148 # replace data with smoothed data; 149 adata.raw = adata; --> 150 adata.X = X_magic.X; 151 ; 152 if copy:. AttributeError: 'numpy.ndarray' object has no attribute 'X'. I fixed it by changing line 150 from adata.X = X_magic.X; to adata.X = X_magic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/206:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/206,1,['error'],['error']
Availability,"Hi, I know this issue has been previously opened but I am still unable to resolve this problem. Any help would be great.; ---------------------------------------; I am new to Scanpy and I followed this tutorial link below.; https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_01_qc.html. Its a great tutorial and everything is working till I start the following code:-. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). The error I receive is; -----------------------------------------------; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:200: RuntimeWarning: overflow encountered in expm1; X = np.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/Shamini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242:492,error,error,492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242,1,['error'],['error']
Availability,"Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/196:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196,1,['error'],['error']
Availability,"Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you!. `View of AnnData object with n_obs × n_vars = 1358 × 1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2423:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423,1,['error'],['error']
Availability,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:1006,error,errors,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['error'],['errors']
Availability,"Hi, I was just trying to use the package but it seems that somebody is working on the master branch right now. Would it be possible to set up a development branch and maybe add a few tags for the working versions so that people could download a particular release instead of an in-progress master branch? I also noticed that the notebooks disappeared right after I cloned the repository. It seems like there are some big changes going on, so sorry if the timing for this issue is not right and you are just cleaning up the repository.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7:234,down,download,234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7,1,['down'],['download']
Availability,"Hi, I was trying to use the most recent version but saw this error in 1.4.5 and above. ```; scanpy==1.4.5 anndata==0.7rc2 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0rc1 python-igraph==0.7.1; ```. ```; adata = sc.datasets.pbmc3k(); sc.pp.calculate_qc_metrics(adata, inplace=True); ```; output:; ```; ---------------------------------------------------------------------------; TypingError Traceback (most recent call last); <ipython-input-5-0d8cf2779f18> in <module>; 1 adata = sc.datasets.pbmc3k(); ----> 2 sc.pp.calculate_qc_metrics(adata, inplace=True). ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below.; Any idea of what is happening?. ```pytb; >>> filter_result = sc.pp.filter_genes_dispersion(; ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5); Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion; disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]; File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__; setitem(key, value); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem; self._where(~key, value, inplace=True); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where; level=level, fill_value=np.nan); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align; broadcast_axis=broadcast_axis); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align; fill_axis=fill_axis); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series; return_indexers=True); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join; return_indexers=return_indexers); File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic; ridx = self._left_indexer_unique(sv, ov); File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object; ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158,1,['error'],['error']
Availability,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2165:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165,3,['error'],['error']
Availability,"Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```python; adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2189:185,error,errors,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189,1,['error'],['errors']
Availability,"Hi, when importing a loom file I get the following error. ```; >>> import scanpy.api as sc; >>> adata = sc.read_loom('/path/to/loom_file.loom'); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py"", line 186, in read_loom; dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 672, in __init__; filename=filename, filemode=filemode); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 850, in _init_as_actual; ['obs_names', 'row_names', 'smp_names']); File ""/opt/conda/lib/python3.7/site-packages/anndata/base.py"", line 287, in _gen_dataframe; columns=[k for k in anno.keys() if k != index_name]); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py"", line 392, in __init__; mgr = init_dict(data, index, columns, dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 212, in init_dict; return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 56, in arrays_to_mgr; arrays = _homogenize(arrays, index, dtype); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 277, in _homogenize; raise_cast_failure=False); File ""/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 658, in sanitize_array; raise Exception('Data must be 1-dimensional'); Exception: Data must be 1-dimensional; ```. Does anybody knows the reason why?; Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/649:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/649,1,['error'],['error']
Availability,"Hi,. I am getting an error when loading my loom files, which did not happen before and I am not capable of understanding the error output to try to fix it. . ![screen shot 2018-08-29 at 10 58 23](https://user-images.githubusercontent.com/42487820/44760841-9b527680-ab7b-11e8-9e85-0d0235cee6db.png). Your help will be much appreciated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247,2,['error'],['error']
Availability,"Hi,. I am getting an error when the list of components is greater than 5 in `sc.pl.pca_loadings`. The error is a NamedError, `NameError: name 'count' is not defined`, coming from [this line](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L554).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/431:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/431,2,['error'],['error']
Availability,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:347,ERROR,ERROR,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,2,"['ERROR', 'error']","['ERROR', 'errored']"
Availability,"Hi,. I am testing `pl.scatter` and it seems that:; - `color` cannot be a list (contrary to what the documentation mentions); - `components='all'` raises the error: `ValueError: invalid literal for int() with base 10: 'all'`. Any idea how to fix that?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311:157,error,error,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311,1,['error'],['error']
Availability,"Hi,. I am testing `sc.pl.stacked_violin` and I had an issue with running it on an AnnData variable that is imported from a `h5ad` file. I explain. If I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. No problem, but if I run:. ```; >>> import scanpy.api as sc; >>> adata = sc.datasets.krumsiek11(); >>> adata.write('anndata.h5ad'); >>> adata = sc.read_h5ad('anndata.h5ad'); >>> sc.pl.stacked_violin(adata, adata.var_names, 'cell_type', use_raw=False, color='blue', show=False); ```. then I got the error:. ```; Traceback (most recent call last):; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/anndata.py"", line 896, in stacked_violin; orient='vertical', scale=scale, ax=ax, **kwds); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 2387, in violinplot; color, palette, saturation); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 562, in __init__; self.establish_variables(x, y, hue, data, orient, order, hue_order); File ""/miniconda3/envs/scanpy/lib/python3.6/site-packages/seaborn/categorical.py"", line 155, in establish_variables; raise ValueError(err); ValueError: Could not interpret input 'variable'; ```. I tested it with versions 1.3.1 and 1.3.2, installed with bioconda. Any idea?. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/318:637,error,error,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/318,1,['error'],['error']
Availability,"Hi,. I am testing the `scanpy.api.tl.sandbag` and `scanpy.api.tl.cyclone` functions, after installing the latest version of `pypairs`. . 1. I got an error: `TypeError: 'module' object is not callable`. It seems that it could be solved by calling `pypairs.cyclone.cyclone` or `pypairs.sandbag.sandbag`. 2. In `sandbag`: the argument `fraction` is not used to call the `pypairs` `sandbag` function; 3. In `cyclone` and `sandbag`, `gene_names` and `sample_names` should not be `None`. I can fix these issues in a PR. Bérénice",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/310:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/310,1,['error'],['error']
Availability,"Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):; File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>; sc.pl.umap(adata); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap; return embedding(adata, 'umap', **kwargs); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding; data_points, components_list = _get_data_points(adata, basis, projection, components); File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points; f""Could not find entry in `obsm` for '{basis}'.\n""; KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata; Out[34]: ; AnnData object with n_obs × n_vars = 1858 × 366 ; obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'; var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; uns: 'log1p', 'pca', 'neighbors', 'leiden'; obsm: 'X_pca'; varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1095:199,error,error,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095,1,['error'],['error']
Availability,"Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`; - `umap-learn==0.3.10`; - `leidenalg==0.7.0`; - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```; seed = 10; np.random.seed(seed); a = np.random.rand(100, 100); b = np.random.rand(100, 100); print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']); sc.tl.pca(adata); sce.pp.bbknn(adata, metric='angular'); sc.tl.umap(adata, random_state=seed); sc.tl.leiden(adata, resolution=0.5, random_state=seed); sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3); print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(); sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed); sc.tl.umap(adata_neigh, random_state=seed); sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed); sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3); print(adata_neigh.uns['neighbors']['connectivities'].sum()); ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):; Mine;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009:340,down,downstream,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009,1,['down'],['downstream']
Availability,"Hi,. I am writing the Galaxy integration for `pl.paga_path`. From the documentation, I understand that if we can provide an annotation (other than `dpt_pseudotime`) that are keys of `adata.obs`.; I tested with a dataset in which `dpt_pseudotime` is not a key of `adata.obs` and I got the error:. ```; Traceback (most recent call last):; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/scanpy/plotting/tools/paga.py"", line 930, in paga_path; idcs_group = np.argsort(adata.obs['dpt_pseudotime'].values[; File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2688, in __getitem__; return self._getitem_column(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/frame.py"", line 2695, in _getitem_column; return self._get_item_cache(key); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/generic.py"", line 2489, in _get_item_cache; values = self._data.get(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/internals.py"", line 4115, in get; loc = self.items.get_loc(item); File ""/miniconda3/envs/mulled-v1-9b7030900b5a2e199b0cdbb5894abd70134735de4070acfe326d220bc105c4a2/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3080, in get_loc; return self._engine.get_loc(self._maybe_cast_indexer(key)); File ""pandas/_libs/index.pyx"", line 140, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1492, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 1500, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328:288,error,error,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328,1,['error'],['error']
Availability,"Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:; *** multi-threaded process forked ***; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188; 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x0000000102ac30e6 call_function + 491; 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747; ```. Here's what I was running to cause that:. ```python; import numpy as np; import scanpy.api as sc; from anndata import AnnData; from scipy.sparse import random. adata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182:573,fault,fault,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182,1,['fault'],['fault']
Availability,"Hi,. I have been Scanpy for a short time and I find it really great!; However, I tried recently to use it for differential expression using rank_genes_groups and I could not make it work. I have a single-cell RNA-seq dataset with cell types.; When running `rank_genes_groups(adata, groupby=""celltype"")`, I get the following error:. ```; ~/.py3Env/lib/python3.5/site-packages/scanpy/tools/rank_genes_groups.py` in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 374 adata.uns[key_added]['names'] = np.rec.fromarrays(; 375 [n for n in rankings_gene_names],; --> 376 dtype=[(rn, 'U50') for rn in groups_order_save]); 377; 378 if method in {'t-test', 't-test_overestim_var', 'wilcoxon'}:. ~/.py3Env/lib/python3.5/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder); 632 # populate the record array (makes a copy); 633 for i in range(len(arrayList)):; --> 634 _array[_names[i]] = arrayList[i]; 635; 636 return _array. ValueError: setting an array element with a sequence; ```. Do you have any idea of what could cause this error?. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365:324,error,error,324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365,2,['error'],['error']
Availability,"Hi,. I have found that using `sc.api.tl.score_genes()` gives the following error if I input a single gene as gene list:; ```; computing score 'score'; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-27-526dfa387800> in <module>(); ----> 1 sc.tl.score_genes(adata=adata,gene_list= genes). ~/Documents/Python/scanpy/scanpy/tools/score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy); 96 gene_list = list(gene_list); 97 ; ---> 98 score = np.mean(adata[:, gene_list].X, axis=1) - np.mean(adata[:, control_genes].X, axis=1); 99 adata.obs[score_name] = pd.Series(np.array(score).ravel(), index=adata.obs_names); 100 . ~/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py in mean(a, axis, dtype, out, keepdims); 2904 pass; 2905 else:; -> 2906 return mean(axis=axis, dtype=dtype, out=out, **kwargs); 2907 ; 2908 return _methods._mean(a, axis=axis, dtype=dtype,. ~/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py in _mean(a, axis, dtype, out, keepdims); 55 ; 56 is_float16_result = False; ---> 57 rcount = _count_reduce_items(arr, axis); 58 # Make this warning show up first; 59 if rcount == 0:. ~/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py in _count_reduce_items(arr, axis); 48 items = 1; 49 for ax in axis:; ---> 50 items *= arr.shape[ax]; 51 return items; 52 . IndexError: tuple index out of range; ```; I suggest that you include a check for the length of the input `gene_list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/105:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/105,1,['error'],['error']
Availability,"Hi,. I usually get good result from scanpy and paga previously but have no idea why right now I could not plot any paga plot by function sc.pl.paga. It always comes with error (shown below) and separate plots:. C:\Users\Lin\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py:848: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.; pie_axs.append(pl.axes([xa, ya, pie_size * ax_len_x, pie_size * ax_len_y], frameon=False)). ![下載 (1)](https://user-images.githubusercontent.com/57272642/79533367-a7879200-8045-11ea-8a66-e48927b526a4.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168:170,error,error,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168,1,['error'],['error']
Availability,"Hi,. I'm trying to follow the [Dahlin18 PAGA tutorial](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:322,error,error,322,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['error'],['error']
Availability,"Hi,. I'm using AGA to build global trajectories on neuronal differentiation datasets. It works well on small subsets of data (only progenitors or only neurons), but produces spurious trajectories between clusters that cannot be explained (progenitors --> inhibitory neurons --> excitatory neurons, rather than progenitors --> excitatory neurons). I'm thinking that part of this may be due to noise/outliers in the dataset. . From the paper (Supplementary Note 3.2), it looks like the connectivity between two partitions are calculated as the minimum distance between all pairs of points, which is prone to outliers. . > Taking the minimum is independent of the specific shape of a partition but is prone to outliers: it is only a viable option as the distance measure d itself is highly robust being computed as an average over all random walks on the graph. . Are there alternative ways to calculate connectivities that are more robust to outliers? (e.g. other connectivity metrics or something like Endpoint Supervision in Slingshot (https://doi.org/10.1101/128843) to avoid connecting endpoints from different lineages.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/96:787,robust,robust,787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96,2,['robust'],['robust']
Availability,"Hi,. I'm working with pseudocounts data (kallisto/alevin/salomon output). I think they are called ""pseudocount"": if a read is assigned to two regions (genes) , a probability is assigned (e.g. gene1=0.2, gene2=0.8). Nevertheless, they can still considered counts and so it would be cool to use the `highly_variable_genes flavour=seuratv3` . ; I added an additional argument in case users would like to enforce this, as it was similarly done/discussed in https://github.com/theislab/scvelo/issues/190. Would like to hear what you guys think, pinging @adamgayoso (thanks for the great overleaf doc! )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642:540,ping,pinging,540,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642,1,['ping'],['pinging']
Availability,"Hi,. In scran's findMarkers(), users can set batch as the 'block' in the model, so marker identification will not be influenced by batch effect (https://rdrr.io/bioc/scran/man/findMarkers.html, I found this really useful).; Can I do similar things in scanpy? Thanks!. I tried using [anndata2ri](https://github.com/theislab/anndata2ri) to convert anndata to SingleCellExperiment, so as to still use scran's findMarker(), but always got this error:; ```; ValueError: Converting pandas ""Category"" series to R factor is only possible when categories are strings.; ```; I have checked several columns in my adata.obs, but cannot find the cause. Thanks in advance,; BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691:440,error,error,440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691,1,['error'],['error']
Availability,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2563:201,Ping,Pinging,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563,1,['Ping'],['Pinging']
Availability,"Hi,. To have a depth understanding, I wanted to set the resolution high for louvain clustering, but now I cannot merge subclusters. When I try to rename the categories with same cluster name, it gives an error about not having unique names. Yet, I could not find a functional merge_clusters function. Is there anyone having the same issue as me? I would appreciate any help. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/925:204,error,error,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/925,1,['error'],['error']
Availability,"Hi,. When I ran; ```; import scanpy.api as sc; ```; I met this error:; ```; 19 from scipy import sparse; 20 from scipy.sparse import issparse; ---> 21 from scipy.sparse.sputils import IndexMixin; 22 from natsort import natsorted; 23 . ImportError: cannot import name 'IndexMixin'; ```; Is there any requirements for the version of scipy?. Thanks in advance,; BP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643,1,['error'],['error']
Availability,"Hi,; I am getting the following error when trying to plot my spatial data. ```py; with mpl.rc_context({'axes.facecolor': 'black',; 'figure.figsize': [4.5, 5]}):; ; sc.pl.spatial(slide, cmap='magma',; color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; ncols=3, size=1.3, ; img_key='hires',; # limit color scale at 99.2% quantile of cell abundance; vmin=0, vmax='p99.2' ; ); ```. ```pytb; TypeError Traceback (most recent call last); Cell In[11], line 14; 10 # plot in spatial coordinates; 11 with mpl.rc_context({'axes.facecolor': 'black',; 12 'figure.figsize': [4.5, 5]}):; ---> 14 sc.pl.spatial(slide, cmap='magma',; 15 # show first 8 cell types; 16 color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; 17 ncols=3, size=1.3, ; 18 img_key=None,; 19 # limit color scale at 99.2% quantile of cell abundance; 20 vmin=0, vmax='p99.2' ; 21 ). File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:993, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 990 cmap_img = None; 991 circle_radius = size * scale_factor * spot_size * 0.5; --> 993 axs = embedding(; 994 adata,; 995 basis=basis,; 996 scale_factor=scale_factor,; 997 size=circle_radius,; 998 na_color=na_color,; 999 show=False,; 1000 save=False,; 1001 **kwargs,; 1002 ); 1003 if not isinstance(axs, list):; 1004 axs = [axs]. File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:169, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499,1,['error'],['error']
Availability,"Hi,; I am trying to evaluate a PCA on a dataset with a very low number of Principal Components. I am getting the following error when trying to plot the PCA:; ```python; sc.pl.pca_variance_ratio(adata_h, log=True, save=True); ```; Result:; ```; /Users/user/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py:530: RuntimeWarning: divide by zero encountered in log; if log: scores = np.log(scores). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-48cc676a34cc> in <module>(); 1 # log is natural logarithm; ----> 2 sc.pl.pca_variance_ratio(adata_h, log=True, save=True). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca_variance_ratio(adata, log, show, save); 157 default filename. Infer the filetype if ending on {{'.pdf', '.png', '.svg'}}.; 158 """"""; --> 159 ranking(adata, 'uns', 'variance_ratio', dictionary='pca', labels='PC', log=log); 160 utils.savefig_or_show('pca_variance_ratio', show=show, save=save); 161 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/anndata.py in ranking(adata, attr, keys, dictionary, indices, labels, color, n_points, log, show); 555 score_min, score_max = np.min(score[indices]), np.max(score[indices]); 556 pl.ylim((0.95 if score_min > 0 else 1.05) * score_min,; --> 557 (1.05 if score_max > 0 else 0.95) * score_max); 558 if show == False: return gs; 559 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/pyplot.py in ylim(*args, **kwargs); 1588 if not args and not kwargs:; 1589 return ax.get_ylim(); -> 1590 ret = ax.set_ylim(*args, **kwargs); 1591 return ret; 1592 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_base.py in set_ylim(self, bottom, top, emit, auto, **kw); 3455 bottom, top = bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:123,error,error,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,1,['error'],['error']
Availability,"Hi,; I am trying to run the full 1.3M 10X mouse cell dataset (using the 1M_neurons_filtered_gene_bc_matrices_h5.h5 file from 10X website).; I have 126GB RAM and Intel® Xeon(R) W-2123 CPU @ 3.60GHz × 8 which is above the requirements you mention needed to run the full cluster.py method without subsampling. (https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells); I get a memory error at the normalization and filter_genes_dispersion stage, should i modify the code in anyway? (without subsampling); Thanks,Shobi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511:415,error,error,415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511,1,['error'],['error']
Availability,"Hi,; I am using umap in 3d. I want to plot all 3 components, so I use the `components='all'` parameter.; However, I get this error:. ```python. > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); in ; 1 #%%; ----> 2 sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components='all'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 282 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 283 """"""; --> 284 return plot_scatter(adata, 'umap', **kwargs); 285 ; 286 . ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 191 if projection == '3d':; 192 cax = ax.scatter(; --> 193 _data_points[:, 0], _data_points[:, 1], _data_points[:, 2],; 194 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; 195 **kwargs,. IndexError: index 2 is out of bounds for axis 1 with size 2; ```. I was able to plot in 3d by changing it to the following method signature:; ```python; > sc.pl.umap(adata_g, color=[key_added], cmap='viridis', projection='3d', components=['1,2,3']); ```. Probably the documentation should be updated.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/677:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/677,1,['error'],['error']
Availability,"Hi,; I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them.; ```; >>> import scanpy as sc; D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.; data = yaml.load(f.read()) or {}; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>; from . import tools as tl; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>; from ._sim import sim; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>; import tables; File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>; from .utilsextension import (; ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version); 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1468:40,error,error,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468,2,['error'],['error']
Availability,"Hi,; I encountered a wired problem when I run UMAP with min_dist=0.1; `sc.tl.pca(adata_f,n_comps=250)`; `adata_f.obsm['X_pca'] *= -1 `; `sc.pp.neighbors(adata_f, n_neighbors=10)`; `scv.pp.moments(adata_f,renormalize=True,mode='connectivities')`; `sc.tl.umap(adata_f,min_dist=0.1)`; error is about produce NaN, and then I checked `adata_f.obs['X_umap']`, all NaN in array.; However, when I use min_dist=0.2, everything seems well. ; Could you help me to figure it out? Thank you~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/257:282,error,error,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/257,1,['error'],['error']
Availability,"Hi,; I was reading some mtx file from here: ; https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`; `AnnData object with n_obs × n_vars = 25052 × 606606; ` ; `sc.__version__`; `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. ; That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>; ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1761:96,down,downloads,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761,1,['down'],['downloads']
Availability,"Hi,; I was trying to run the quick example described in the magic api cmd using datasets.paul15 but it keeps on giving me the same error. See below the code I used and the error it gives. . import numpy as np; import pandas as pd; import scanpy.api as sc; import matplotlib.pyplot as pl; import phate; import magic. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; sc.logging.print_version_and_date(); # we will soon provide an update with more recent dependencies; sc.logging.print_versions_dependencies_numerics(). Running Scanpy 1.2.2+72.gbc6661c on 2018-07-18 19:40.; Dependencies: anndata==0.6.5 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . adata = sc.datasets.paul15(). WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical. sc.pp.normalize_per_cell(adata); sc.pp.sqrt(adata); adata_magic = sc.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); adata_magic.shape. computing PHATE. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-79-129f35d34dbd> in <module>(); 2 sc.pp.normalize_per_cell(adata); 3 sc.pp.sqrt(adata); ----> 4 adata_magic = sc.pp.magic(adata.X, name_list=['Mpo', 'Klf1', 'Ifitm1'], k=5); 5 adata_magic.shape. ~/software/scanpy/scanpy/preprocessing/magic.py in magic(adata, name_list, k, a, t, n_pca, knn_dist, random_state, n_jobs, verbose, copy, **kwargs); 131 n_jobs=n_jobs,; 132 verbose=verbose,; --> 133 **kwargs).fit_transform(adata,; 134 genes=name_list); 135 logg.info(' finished', time=True,. TypeError: 'module' object is not callable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,3,['error'],"['error', 'errors']"
Availability,"Hi,; I'm attempting to run scvelo on my scanpy processed 10x data.; Initially I provided the .h5ad file from scanpy as the input file for scvelo but ran into error KeyError: 'unspliced', I'm assuming unspliced data can't be found and also that ""adata.layers"" doesn't exist in my scanpy processed .h5ad file.; I also attempted providing the unprocessed data directly into scvelo but again came up with the error KeyError: 'unspliced'.; I've attempted adata.layers.keys() which returns odict_keys([]) and scv.pp.show_proportions(adata) which returns Abundance of []: []. (Currently running version 1.3.2 of scanpy and 0.1.11 of scvelo).; My adata file doesn't seem to contain adata.layers information, is there a way to add this information via scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/342:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/342,2,['error'],['error']
Availability,"Hi,; I'm encountering an error when trying to write result file, after perform cell cycle score.; After normalizing, I import cell cycle file and perform the score:. `cc_genes=[gene.strip() for gene in open('[my_cell_cycle_genes]')]; s_genes=[g for g in cc_genes[:43] if g in adata.var_names]; g2m_genes=[g for g in cc_genes[43:] if g in adata.var_names]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes); `. The field 'phase' of the obs. matrix is of type object:; `adata.obs.phase.dtypes; dtype('O')`. When I write the annData object, I got the error:; `adata.write(results_file); ... storing 'phase' as categorical; TypeError: Categorical is not ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one`. and now the field 'phase' is categorical:; `adata.obs.phase.dtypes; CategoricalDtype(categories=['G1', 'G2M', 'S'], ordered=False)`. I can modify it as suggested, but it's converted into categorical when writing file again.; Following my version packages:; `sc.logging.print_versions(); scanpy==1.4.2 anndata==0.6.17 umap==0.3.7 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1`. My annData, also on a subset of variables, is too big to attach here, but I could send you by email if you need it. Thanks a lot!; Raffaella",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/645:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/645,2,['error'],['error']
Availability,"Hi,; I'm using the version from the main branch ```scanpy==1.4.5.dev104+g1a5defb```, and got some warnings at start up:; ```py; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); ```. ```; /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function annotate_doc_types at 0x2ac365a5f200>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function matrix at 0x2ac36c882950>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries at 0x2ac36c897830>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_subplot at 0x2ac36c8977a0>; warnings.warn(f""Found an util with public name: {obj}""); /home/gzhang/packages/anaconda3/envs/monocle3/lib/python3.7/site-packages/scanpy/_utils.py:132: UserWarning: Found an util with public name: <function timeseries_as_heatmap at 0x2ac36c8978c0>; warnings.warn(f""Found an util with public name: {obj}""); ```. ```; scanpy==1.4.5.dev104+g1a5defb anndata==0.6.22.post1 umap==0.3.10 numpy==1.16.4 scipy==1.3.1 pandas==0.25.0 scikit-learn==0.21.2 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/840:294,error,errors,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/840,1,['error'],['errors']
Availability,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578:61,down,downstream,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578,1,['down'],['downstream']
Availability,"Hi,; More of a request than an issue. I am trying to replicate FindVariableFeatures with option selection.method = ""vst"" in seurat by using highly_variable_genes function in scanpy,i went through the documentation but could not find this option,is it available and am i missing something or is it not implemented yet. It would be nice to have this option. Thank you; Sasi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/497:251,avail,available,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/497,1,['avail'],['available']
Availability,"Hi.; I have a problem to install fa2 (pip install fa2) in windows 10 operating system and I am using python 3.7 version? . Using Conda env . **sc.tl.draw_graph(ds, init_pos='paga'),**; **drawing single-cell graph using layout 'fa'; WARNING: Package 'fa2' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:409,error,error,409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['error'],['error']
Availability,"Hi; I am trying to concatenate two anndata objects(adata = adata1.concatenate(adata3, join='inner')), but get an error message informing me that concatenate is not found. Any idea what might cause this behavior? Here is what I have installed:scanpy==1.4.3 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. and here is the error:; AttributeError Traceback (most recent call last); <ipython-input-187-32c3eda3cdc8> in <module>; ----> 1 adata = adata1.concatenate(adata3, join='inner'). ~/anaconda3/envs/scenv/lib/python3.6/site-packages/scipy/sparse/base.py in __getattr__(self, attr); 687 return self.getnnz(); 688 else:; --> 689 raise AttributeError(attr + "" not found""); 690 ; 691 def transpose(self, axes=None, copy=False):. AttributeError: concatenate not found; Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/760:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/760,2,['error'],['error']
Availability,Hi; I'm facing an installation issue. The issues are explained below; I got failed to install **louvain and bioconductor-rhdf5lib** from paga_project_environment.yml (See file contents below). Using Window 10 . > conda env create -f .\sc_tutorial_environment.yml** ; error **CondaEnvException: Pip failed**. Please find .yml file from here https://github.com/theislab/single-cell-tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220:267,error,error,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220,1,['error'],['error']
Availability,"Hi; Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:; ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png); Can I modify the y axis limits? I'm sorry I haven't find the parameters yet.; And when I try to use `use_raw=False`, I got error:; `ValueError: Data must be 1-dimensional`; `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`; And my code:; `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`; and my version:; `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer!; Best,; Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1766:410,error,error,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766,1,['error'],['error']
Availability,"Hia everyone, this should actually make`hatch test -i deps=min` work even on Macbooks. Maybe there’s a way to put the constraint file inside of the venv, then it’ll survive reboots on Linux. I tagged you all because I thought you might be interested in this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3337:173,reboot,reboots,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3337,1,['reboot'],['reboots']
Availability,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1901:52,down,downregulated,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901,4,['down'],"['down', 'downregulated']"
Availability,How to show the downregulated marker genes by sc.pl.rank_genes_groups?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2052:16,down,downregulated,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052,1,['down'],['downregulated']
Availability,"I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date).; Let me know if you are interested in merging it, and if the code style is acceptable for this library.; I was unsure on how to test it, in case do you have any suggestions?. Thanks,; Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141:147,error,error-prone,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141,1,['error'],['error-prone']
Availability,"I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,4,"['Error', 'error']","['Error', 'error']"
Availability,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:428,error,error,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,2,"['down', 'error']","['down', 'error']"
Availability,"I am following workflow of '_Best-practices in single-cell RNA-seq: a tutorial_' to analyze my single-cell sequencing data sets.; I have calculated the size factor using the scran package and did not perform the batch correction step as I have only one sample. Then, I intended to extract highly variable genes by using the function sc.pp.highly_variable_genes. Unfortunately, I got an error:. > LinAlgError: Last 2 dimensions of the array must be square. <details><summary>Traceback</summary>. ```pytb; LinAlgError Traceback (most recent call last); in ; ----> 1 sc.pp.highly_variable_genes(adata). ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 94 X = np.expm1(adata.X) if flavor == 'seurat' else adata.X; 95; ---> 96 mean, var = materialize_as_ndarray(_get_mean_var(X)); 97 # now actually compute the dispersion; 98 mean[mean == 0] = 1e-12 # set entries equal to zero to small value. ~/miniconda3/lib/python3.6/site-packages/scanpy/preprocessing/utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other); 226; 227 def pow(self, other):; --> 228 return matrix_power(self, other); 229; 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603; 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216; 217 def _assertFinite(*arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:386,error,error,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,1,['error'],['error']
Availability,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840:244,error,errors,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840,1,['error'],['errors']
Availability,"I am not sure if it has been already addressed.; This should fix the following import error of scanpy from master, due to missing `__init__.py` in external. Probably a more clean solution would be to wrap the import for external in a try/except block. ```python; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); in ; ----> 1 import scanpy as sc; 2 sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); 3 sc.settings.set_figure_params(dpi=200) # low dpi (dots per inch) yields small inline figures; 4 sc.settings.figdir = out('fig_supp'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/__init__.py in ; 31 from . import preprocessing as pp; 32 from . import plotting as pl; ---> 33 from . import datasets, logging, queries, settings, external; 34 ; 35 from anndata import AnnData. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/__init__.py in ; ----> 1 from . import tl; 2 from . import pl; 3 from . import pp; 4 ; 5 from .. import _exporting as exporting. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/scanpy/external/tl.py in ; 2 from ..tools._phate import phate; 3 from ..tools._phenograph import phenograph; ----> 4 from ._tools._palantir import palantir. ModuleNotFoundError: No module named 'scanpy.external._tools'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585,2,['error'],"['error', 'errors']"
Availability,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,2,['error'],['error']
Availability,"I am trying to access tSNE coordinates from a sliced AnnData object. `adata.obsm.X_tsne` works fine. But if I were to filter the AnnData object,`filtered_adata = adata[:, some_filter]`, and then run `filtered_adata.obsm.X_tsne`, I get the error `AttributeError: 'ArrayView' object has no attribute 'X_tsne'`. I can, however, access the coords with `filtered_adata.obsm['X_tsne']`. Is this desired behavior? I feel the API should be the same between the two.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/778:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778,1,['error'],['error']
Availability,"I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python; sc.tl.leiden(adata); ```; with error : . ```pytb; running Leiden clustering. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-46-a9ad6348435f> in <module>; ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs); 138 adata.obs[key_added] = pd.Categorical(; 139 values=groups.astype('U'),; --> 140 categories=natsorted(np.unique(groups).astype('U')),; 141 ); 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath); 383 ; 384 else:; --> 385 codes = _get_codes_for_values(values, dtype.categories); 386 ; 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories); 2574 _, cats = _get_data_algo(categories); 2575 t = hash_klass(len(cats)); -> 2576 t.map_locations(cats); 2577 return coerce_indexer_dtype(t.lookup(vals), cats); 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:; scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1028:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028,2,['error'],['error']
Availability,"I am trying to follow this tutorial ; https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html,; but some error just happened in the initial QC stage.; After running:; mito_genes = adata.var_names.str.startswith('MT-'); adata.obs['percent_mito'] = np.sum(; adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; and plot the violinplot,; I just get this graph; ![percent_mito](https://user-images.githubusercontent.com/41959955/57546005-6ba47100-738e-11e9-8cb6-c6a18b89f8dd.png). I felt somthing wrong and checked this:; __________________________________________________________________________________________________; [In] np.sum(adata.obs); [Out] n_genes 14918559.0; **percent_mito 0.0**; dtype: float64. __________________________________________________________________________________________________; It seems that scanpy just didn't recognized the mitogene or removed it, but there's nothing wrong when I used Seurat. I have no idea where the error is located and need your help. Thanks in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639,2,['error'],['error']
Availability,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138,2,['error'],['error']
Availability,"I am trying to load some datasets with `sc.read_h5ad(file_name)`. Frequently, I get the below error. When I re-run the code multiple times or at different times it sometimes works, but often I get the error (using the same code and data). This happens when reading different h5ad datasets (e.g. is not specific to one dataset). At all times there seems to be enough free RAM / similar amount of free RAM. This happens both when using jupyter-notebook and python without jn. Error:; ```pytb; ---------------------------------------------------------------------------; OSError Traceback (most recent call last); ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 505 if ""h5sparse_format"" in group.attrs: # Backwards compat; --> 506 return SparseDataset(group).to_memory(); 507 . ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_core/sparse_dataset.py in to_memory(self); 370 mtx = format_class(self.shape, dtype=self.dtype); --> 371 mtx.data = self.group[""data""][...]; 372 mtx.indices = self.group[""indices""][...]. h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args); 572 fspace = selection.id; --> 573 self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl); 574 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error messag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,3,"['Error', 'error']","['Error', 'error']"
Availability,"I am trying to toy with the krumsiek11 model, but the ```sc.tl.sim``` call seems to ignore parameters and always uses the parameters from the ```krumsiek11_params.txt``` file. In particular, running:. ```; adam_krumsiek11 = sc.tl.sim('krumsiek11'); adam_krumsiek11_2 = sc.tl.sim('krumsiek11', nrRealizations = 1, seed = 1665487); sc.pl.sim(adam_krumsiek11 ); sc.pl.sim(adam_krumsiek11_2); ```; produces two exactly identical figures with 4 realizations. I also tried to set ```read_params_from_file = False``` (this is not documented at http://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.sim.html but seemed relevant). However, running; ```; adam_krumsiek11 = sc.tl.sim('krumsiek11', nrRealizations = 1, read_params_from_file = False); sc.pl.sim(adam_krumsiek11); ```; results in ```IndexError```; and running ; ```; adam_krumsiek11 = sc.tl.sim('krumsiek11', nrRealizations = 1, tmax = 800, read_params_from_file = False); sc.pl.sim(adam_krumsiek11); ```; avoids the error, but gives the exact same figure as the first code segment. Maybe I am not understanding correctly, how the function should work? (in which case this would be a documentation issue) Or is there really something wrong?. Thanks for any hints.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/52:973,error,error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/52,1,['error'],['error']
Availability,"I assume I'm missing something here, but when I try a simple example of plotting a gene dispersion I get two plots 'normalized' and 'not normalized' version in Jupyter, but when I use the save argument to sc.pl.filter_genes_dispersion() I get an image with only one of these. Screenshot attached. Just in case, I tried also passing the multi_panel argument but that caused an error. . Also, is it no possible to specify the path where the files should be stored when using the save arguments to the plotting methods? I want to point to a directory where it should place them, but it seems ""./figures/"" is hard-coded and you can only modify the end of that. Thanks. The attached screenshot shows the dual image within Jupyter, but only the single plot which appears in the PNG file exported. ![screenshot from 2018-01-30 12-34-56](https://user-images.githubusercontent.com/330899/35584410-945d7bb6-05ba-11e8-89fc-14f615a9c6a6.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/73:376,error,error,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/73,1,['error'],['error']
Availability,"I calculated `sc.tl.paga(adata, groups='cell_ontology_class')` without problems but I couldn't run `sc.tl.paga_expression_entropies(adata)`. I've modified the original code and it now runs - if this looks good you can perhaps update the original code? also, if it doesn't let me know so I don't carry over the mistakes!. ```; from scipy.stats import entropy; groups_order, groups_masks = sc.utils.select_groups(tiss, key=tiss.uns['paga']['groups']); entropies = []; for mask in groups_masks:; X_mask = tiss.X[mask].todense(); x_median = np.nanmedian(X_mask, axis=1,overwrite_input=True); x_probs = (x_median - np.nanmin(x_median)) / (np.nanmax(x_median) - np.nanmin(x_median)); entropies.append(entropy(x_probs)); entropies; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/367:470,mask,mask,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/367,2,['mask'],['mask']
Availability,"I can't seem to plot the labels in the margin or on the data when plotting a t-SNE with louvain_groups labels. I am loosely following the scanpy seurat tutorial code with my own data at:; https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb. When running:. `sc.pl.tsne(adata_bc, size=28, color='louvain_groups', legend_loc='on_data', legend_fontsize=12, legend_fontweight='bold')`. I get the error:. > anaconda3/lib/python3.6/site-packages/matplotlib/legend.py:326: UserWarning: Unrecognized location ""on_data"". Falling back on ""best""; valid locations are; > 	best; > 	upper right; > 	upper left; > 	lower left; > 	lower right; > 	right; > 	center left; > 	center right; > 	lower center; > 	upper center; > 	center; > ; > six.iterkeys(self.codes)))). putting the legend on the data or in the margin does not seem possible. I am using matplotlib version 2.0.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88,1,['error'],['error']
Availability,"I don't know what changes caused this, but now there are 2 problems with test_preprocessing_distributed.py. When `adata_dist.X` is a dask array, `adata_dist.X.chunks` is `((2000, 2000, 2000, 2000, 2000), (1000,))`. It leads to an error in `adata.write_zarr(temp_store, chunks)` because zarr chunks should be a tuple with an integer entry per dimension, not a tuple of tuples. The second problem is that `adata_dist.X.to_zarr(temp_store.dir_path(""X""))` causes an error because there is already `'X'` in `temp_store`, it needs to be overwritten. This pr removes these problems but maybe logic of the function should be changed somehow instead of the test.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/963:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/963,2,['error'],['error']
Availability,"I encountered the following error when trying to save data to h5ad file:. ```; ... storing 'run' as categorical; ... storing 'batch' as categorical; ... storing 'dis_stat' as categorical; ... storing 'org_day' as categorical; ... storing 'louvain' as categorical; ... storing 'louvain_1' as categorical; ... storing 'louvain_2' as categorical; ... storing 'split_cell_type' as categorical; ... storing 'split_major_cell_type' as categorical; ... storing 'phase' as categorical; ... storing 'split_major_cell_type2' as categorical; ... storing 'feature_types-190111-3' as categorical; ... storing 'feature_types-190111-4' as categorical; ... storing 'feature_types-190111-5' as categorical; ... storing 'feature_types-190111-6' as categorical; ... storing 'feature_types-190111-7' as categorical; ... storing 'feature_types-190111-8' as categorical; ... storing 'feature_types-180418-4' as categorical; ... storing 'feature_types-180418-5' as categorical; ... storing 'feature_types-180418-6' as categorical; ... storing 'feature_types-180418-7' as categorical; ... storing 'feature_types-180905-3' as categorical; ... storing 'feature_types-180905-4' as categorical; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-72-19c7ca58c3a2> in <module>; ----> 1 df_dev.write_h5ad('2019-03-04_OTUD6B_dev_sig.h5'). /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in write_h5ad(self, filename, compression, compression_opts, force_dense); 1951 ; 1952 _write_h5ad(filename, self, compression=compression,; -> 1953 compression_opts=compression_opts, force_dense=force_dense); 1954 ; 1955 if self.isbacked:. /projects/ps-gleesonlab5/user/zhen/bin/anaconda3/lib/python3.6/site-packages/anndata/readwrite/write.py in _write_h5ad(filename, adata, force_dense, **kwargs); 217 if not dirname.is_dir():; 218 dirname.mkdir(parents=True, exist_ok=True); --> 219 d = adata._to_dict_fixed_wid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515,1,['error'],['error']
Availability,"I encountered this error when using data with a relatively small number of cells (~2,600). I have not encountered this error with my previous data with more cells (>10,000). ![sc pp scale_error](https://user-images.githubusercontent.com/35155633/34744836-6f325a80-f586-11e7-963f-34d14c1e1399.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/64:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64,2,['error'],['error']
Availability,I found that running the function 'tl.rank_genes_groups' gives the error the following error message:; UnboundLocalError: local variable 'adata_comp' referenced before assignment. ![scanpy api tl rank_genes_groups_error](https://user-images.githubusercontent.com/35155633/34642043-0191dce0-f305-11e7-847f-37b1ff34a77d.png),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/63:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/63,2,['error'],['error']
Availability,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916,3,"['Error', 'error', 'toler']","['Error', 'error', 'tolerance']"
Availability,"I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:; `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-66-fc1479c238f7> in <module>(); 9 plt.show(); 10 ; ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'); 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'); 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax); 162 show=show,; 163 save=save,; --> 164 ax=ax); 165 ; 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax); 281 ax=None):; 282 """"""See docstring of scatter.""""""; --> 283 sanitize_anndata(adata); 284 if legend_loc not in VALID_LEGENDLOCS:; 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata); 481 # backwards compat... remove this in the future; 482 def sanitize_anndata(adata):; --> 483 adata._sanitize(); 484 ; 485 . ~/anndata/anndata/base.py in _sanitize(self); 1284 if len(c.categories) < len(c):; 1285 df[key] = c; -> 1286 df[key].cat.categories = df[key].cat.categories.ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166,2,['error'],['error']
Availability,"I get the error below when trying to run the following:. `>>> sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon')`. ```bash; C:\Users\myuser\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py:298: RuntimeWarning: overflow encountered in long_scalars; (n_active * m_active * (n_active + m_active + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-160-dd19114ff660> in <module>; 1 #adata.obs['groups'] = ['group 1'= ['0'], 'group 2'= ['5','16','19','30']]; ----> 2 sc.tl.rank_genes_groups(adata, 'louvain', groups=['5','16','19','30'], reference='0', method='wilcoxon') # wilcoxon-rank-sum/mann-whitney u test, the default of Seurat. ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 296 ; 297 scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; --> 298 (n_active * m_active * (n_active + m_active + 1) / 12)); 299 scores[np.isnan(scores)] = 0; 300 pvals = 2 * stats.distributions.norm.sf(np.abs(scores)). ValueError: math domain error; ```. Here `adata` is real data from our lab, not the tutorial data. Have been trying to replicate the cluster analysis tutorial. All previous steps work fine. Interestingly, if I remove group '5' from the list of groups it works. Also, this error only happens with the `wilcoxon` method, not with `t-test`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530,3,['error'],['error']
Availability,"I get the following error when I tun dotplot:. ```pytb; ValueError Traceback (most recent call last); <ipython-input-54-afab88c299fa> in <module>(); ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds); 409 ; 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,; --> 411 groupby=groupby, key=key, show=show, save=save, **kwds); 412 ; 413 . /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 291 ; 292 # sum(list, []) is used to flatten the gene list; --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); 294 ; 295 if plot_type == 'dotplot':. /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/__init__.py in <listcomp>(.0); 291 ; 292 # sum(list, []) is used to flatten the gene list; --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); 294 ; 295 if plot_type == 'dotplot':. ValueError: no field of name MYL2; ```. Do we need to store marker genes within the adata object?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/502:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502,1,['error'],['error']
Availability,"I get the following error when trying to use sc.pl.scatter to plot gene expression, with use_raw=False. I am using sc.pl.scatter instead of sc.pl.umap, .tsne, etc., because of the need to use custom basis names.; ```; File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 118, in scatter; ax=ax); File ""/opt/Python/3.6.5/lib/python3.6/site-packages/scanpy/plotting/_anndata.py"", line 390, in _scatter_obs; c = adata.raw.obs_vector(key, layer=layers[2]); TypeError: obs_vector() got an unexpected keyword argument 'layer'; ```. The following snippet is copied from `_scatter_obs()` in /scanpy/plotting/_anndata.py; ``` python; # coloring according to gene expression; elif (use_raw; and adata.raw is not None; and key in adata.raw.var_names):; c = adata.raw.obs_vector(key); elif key in adata.var_names:; c = adata.raw.obs_vector(key, layer=layers[2]); ```; Should line 390 be c = adata.obs_vector(key, layer=layers[2]) since it is handling the case when use_raw==False and adata.raw.obs_vector does not take layer as argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/762:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762,1,['error'],['error']
Availability,"I got an error doing `pip3 install -e .`:. > clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/usr/local/include -I/usr/local/opt/openssl/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/include/python3.6m -c scanpy/cython/utils_cy.c -o build/temp.macosx-10.11-x86_64-3.6/scanpy/cython/utils_cy.o; > scanpy/cython/utils_cy.c:435:10: fatal error: 'numpy/arrayobject.h' file not found; > #include ""numpy/arrayobject.h""; > ^; > 1 error generated.; > error: command 'clang' failed with exit status 1; > ; > ----------------------------------------; > Command ""/usr/local/opt/python3/bin/python3.6 -c ""import setuptools, tokenize;__file__='/Users/jyhung/Documents/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" develop --no-deps"" failed with error code 1. It worked after I installed cython: `pip3 install cython`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/22:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/22,5,['error'],['error']
Availability,"I have a dataset for which I have an observation that is only available for some cells. When I make a scatter plot that I color code for this observation not all cells are plotted:; ```python; import random; import scanpy as sc. adata = sc.datasets.blobs(); adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1] . sc.tl.pca(adata); sc.pl.pca(adata, color='property', size=50); ```; While this should plot 10 cells it only shows one cell:; ![image](https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png); I can get the plot I want by filtering cells first:; ```python; sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50); ```; ![image](https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png); Would you agree that scanpy should plot all cells that have a valid observation?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536:62,avail,available,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536,1,['avail'],['available']
Availability,"I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory.; Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1977:137,error,errors,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977,1,['error'],['errors']
Availability,"I have a loom file created from Seurat object by using as.loom function in Seurat3. After closing the file with $close.all(), I'm trying to read loom file by read_loom function in scanpy, but I have this error:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-aed61d3d5eef> in <module>; 1 import scanpy as sc; ----> 2 a = sc.read_loom('brain10x.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype); 156 ; 157 if X_name not in lc.layers.keys(): X_name = ''; --> 158 X = lc.layers[X_name].sparse().T.tocsr() if sparse else lc.layers[X_name][()].T; 159 ; 160 layers = OrderedDict(). /opt/conda/lib/python3.7/site-packages/loompy/loom_layer.py in sparse(self, rows, cols); 109 col: List[np.ndarray] = []; 110 i = 0; --> 111 for (ix, selection, view) in self.ds.scan(items=cols, axis=1, layers=[self.name]):; 112 if rows is not None:; 113 vals = view.layers[self.name][rows, :]. /opt/conda/lib/python3.7/site-packages/loompy/loompy.py in scan(self, items, axis, layers, key, batch_size); 597 for key, layer in vals.items():; 598 lm[key] = loompy.MemoryLoomLayer(key, layer); --> 599 view = loompy.LoomView(lm, self.ra[ordering], self.ca[ix + selection], self.row_graphs[ordering], self.col_graphs[ix + selection], filename=self.filename, file_attrs=self.attrs); 600 yield (ix, ix + selection, view); 601 ix += cols_per_chunk. /opt/conda/lib/python3.7/site-packages/loompy/graph_manager.py in __getitem__(self, thing); 96 if type(thing) is slice or type(thing) is np.ndarray or type(thing) is int:; 97 gm = GraphManager(None, axis=self.axis); ---> 98 for key, g in self.items():; 99 # Slice the graph matrix properly without making it dense; 100 (a, b, w) = (g.row, g.col, g.data). /opt/conda/lib/python3.7/site-packages/loompy/graph_manager.py in items(self); 55 def items(self) -> Iterable[Tuple[str, sparse.coo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598:204,error,error,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598,1,['error'],['error']
Availability,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053:218,Error,Error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,"I have an error when trying this function for my data:. ```; sc.pl.highest_expr_genes(adata); ```; results in. ```; filtered out 14139 cells that have less than 1 counts; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-1f5b130b9d4e> in <module>(); ----> 1 sc.pl.highest_expr_genes(adata). /usr/local/lib/python3.6/site-packages/scanpy-1.2.2+90.g47c579f-py3.6.egg/scanpy/plotting/qc.py in highest_expr_genes(adata, n_top, save, show, ax, **kwargs); 41 ; 42 # identify the genes with the highest mean; ---> 43 dat.var['mean_percent'] = dat.X.mean(axis=0).A1; 44 ; 45 top = dat.var.sort_values('mean_percent', ascending=False).index[:n_top]. AttributeError: 'numpy.ndarray' object has no attribute 'A1'; ```. It is not critical, but I wonder why this error happens. I have the most recent version from github. Maybe I'm not transforming my data to a certain format properly? Didn't find this documented anyway. However, a lot of other analysis that I do via Scanpy works for me, so generally the data is read and processed correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/220:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/220,2,['error'],['error']
Availability,"I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::; ```; sc.tl.ingest(bdata,; lungreference,obs='new_celltype'; ); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); /tmp/ipykernel_875/1088574315.py in <module>; 2 print(transgene); 3 bdata=adata[adata.obs.treatment==transgene]; ----> 4 sc.tl.ingest(bdata,; 5 lungreference,obs='new_celltype'; 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 128 ; 129 for method in embedd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2406:93,Error,Error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406,1,['Error'],['Error']
Availability,"I have followed these instructions to install scanpy into my miniconda environment:; [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:; ```; Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44); [GCC 7.2.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy.api as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE; File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; >>>; ```. I also get the error when I try to use it with jupyter notebook:. ```; import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>; import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>; import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>; from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287; return f'Backing file manager of file {self._filename}.'; ^; SyntaxError: invalid syntax; ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/160:225,error,error,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160,2,['error'],['error']
Availability,"I have some issues runnign tSNE with `sc.tsne(adata)`. It seems to work on the `moignard15` data set but running the same code with my data set results in the following error. ```; compute tSNE; preprocess using PCA with 50 PCs; --> avoid this by setting n_pcs = 0; 0:00:02.013 - compute PCA with n_comps = 50; 0:00:00.162 - finished; ---------------------------------------------------------------------------; UnboundLocalError Traceback (most recent call last); <ipython-input-5-ea03cbb426c5> in <module>(); ----> 1 sc.tsne(adata). /opt/conda/lib/python3.6/site-packages/scanpy/tools/tsne.py in tsne(adata, random_state, n_pcs, perplexity); 59 sett.m(0, 'preprocess using PCA with', n_pcs, 'PCs'); 60 sett.m(0, '--> avoid this by setting n_pcs = 0'); ---> 61 X = pca(adata.X, random_state=random_state, n_comps=n_pcs); 62 adata['X_pca'] = X; 63 else:. /opt/conda/lib/python3.6/site-packages/scanpy/tools/pca.py in pca(adata_or_X, n_comps, zero_center, svd_solver, random_state); 60 zero_center, svd_solver,; 61 random_state=random_state); ---> 62 adata['X_pca'] = X_pca; 63 if isadata:; 64 return adata. UnboundLocalError: local variable 'adata' referenced before assignment; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/10:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/10,1,['error'],['error']
Availability,"I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python; fig, ax = plt.subplots(1,3, figsize=(20,6)); sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False); sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False); sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False); plt.tight_layout(pad=3.0); plt.show(); ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158:511,down,download,511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158,1,['down'],['download']
Availability,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1896:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896,2,['error'],['error']
Availability,"I just have scanpy 0.2.7 and am trying to produce bpmc3 results. BUT right at the beginning (sc.read()) the following error! I will appreciate your help.; thanks. `--------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-ef7315cdb8ff> in <module>(); 2 filename_genes = '/ifs/projects/proj077/backup/public_data/scanpy_tutorials_data/PBMC3K/filtered_gene_bc_matrices/hg19/genes.tsv'; 3 filename_barcodes = '/ifs/projects/proj077/backup/public_data/scanpy_tutorials_data/PBMC3K/filtered_gene_bc_matrices/hg19/barcodes.tsv'; ----> 4 adata = sc.read(filename_data, cache=True).transpose(); 5 adata.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; 6 adata.smp_names = np.genfromtxt(filename_barcodes, dtype=str). /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in read(filename_or_filekey, sheet, ext, delimiter, first_column_names, backup_url, return_dict, cache); 73 if is_filename(filename_or_filekey):; 74 data = read_file(filename_or_filekey, sheet, ext, delimiter,; ---> 75 first_column_names, backup_url, cache); 76 if isinstance(data, dict):; 77 return data if return_dict else AnnData(data). /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in read_file(filename, sheet, ext, delimiter, first_column_names, backup_url, cache); 364 os.makedirs(os.path.dirname(filename_cache)); 365 # write for faster reading when calling the next time; --> 366 write_dict_to_file(filename_cache, ddata, sett.file_format_data); 367 return ddata; 368 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in write_dict_to_file(filename, d, ext); 771 d_write[key] = value; 772 # now open the file; --> 773 wait_until_file_unused(filename) # thread-safe writing; 774 if ext == 'h5':; 775 with h5py.File(filename, 'w') as f:. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py in wait_until_file_unused(filenam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35:118,error,error,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35,1,['error'],['error']
Availability,"I just tried; ```python; import scanpy.api as sc; sc.queries.mitochondrial_genes('www.ensembl.org', 'strange_organism'); ```; I would expect scanpy complains that it does not know `'strange_organism'`, but I get the error ; ```python; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-13-6a41b361ab41> in <module>(); 1 import scanpy.api as sc; ----> 2 sc.queries.mitochondrial_genes('www.ensembl.org', 'drerio'). ~/software/scanpy/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 34 s.add_attribute_to_xml('mgi_symbol'); 35 else:; ---> 36 logg.msg('organism ', str(org), ' is unavailable', v=4, no_indent=True); 37 return None; 38 s.add_attribute_to_xml('chromosome_name'). NameError: name 'logg' is not defined; ```; It seems to me like `queries/__init__.py` misses an `from .. import logging as logg` statement. Would maybe also make sense to show the the message that an organism is not available at verbosity level 1 instead of 4?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/258:216,error,error,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/258,2,"['avail', 'error']","['available', 'error']"
Availability,"I just updated scanpy and reran a script which is now giving different outputs. The clustering has changed slightly, and that has downstream effects on the results. The first place I noticed a difference is where the results of `sc.pp.filter_genes_dispersion()` are plotted. . In scanpy version 1.2.2+73.g1812406 and AnnData version 0.6.4 I get the following output:; ![screen shot 2018-08-28 at 14 05 53](https://user-images.githubusercontent.com/13019956/44722232-bade9600-aacc-11e8-88c6-3f4c17fd4e07.png). And with scanpy version 1.2.2+166.g6c1daba with Anndata version 0.6.9, I get higher dispersions:; ![screen shot 2018-08-28 at 14 06 15](https://user-images.githubusercontent.com/13019956/44722316-fda06e00-aacc-11e8-940f-1295b36eacf6.png). Previous results look the same, and the only two scanpy functions that were run in between were `sc.pp.log1p()` and `sc.pp.filter_genes_dispersion()`. I also ran ComBat, but that was not updated and can't really have changed on my system. I see sc.pp.log1p was changed in between, but it doesn't seem to have been anything can could have changed this... Or was there a change to the plotting that may have changed the plots I see?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/246:130,down,downstream,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/246,1,['down'],['downstream']
Availability,"I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be; `; https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}; `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1475:285,error,errors,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475,1,['error'],['errors']
Availability,"I think we should introduce a standardized “mask” argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A’],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells’,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234:44,mask,mask,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234,6,['mask'],"['mask', 'masks']"
Availability,"I tried import .loom file generate from Seurat into scanpy for drawing heatmap.; There is a gene ""CD34"", when I draw in R, it reported as ""Warning: Could not find CD34 in the default search locations, found in RNA assay instead"". but still work.; While in scanpy, it showed the following error: KeyError: ""Values ['CD34'], from ..., are not valid obs/ var names or indices.""; How can I fix it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406:288,error,error,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406,1,['error'],['error']
Availability,"I tried running https://github.com/theislab/scanpy_usage/blob/master/170501_moignard15/moignard15.ipynb and got this error:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/networkx/classes/graph.py in neighbors(self, n); 1058 try:; -> 1059 return list(self.adj[n]); 1060 except KeyError:. KeyError: None. During handling of the above exception, another exception occurred:. NetworkXError Traceback (most recent call last); <ipython-input-11-f3d9663e2b3b> in <module>(); 1 adata.add['dpt_groups_names'] = ['undecided/endothelial', 'endothelial', 'erythrocytes', 'trunk'] # optional; ----> 2 sc.pl.dpt(adata, color=['dpt_pseudotime', 'dpt_groups', 'exp_groups'], legendloc='upper left'). ~/Documents/scanpy/scanpy/plotting/__init__.py in dpt(adata, basis, color, names, comps, cont, layout, legendloc, cmap, pal, right_margin, size, titles, show); 385 if not isinstance(color, list): colors = color.split(','); 386 else: colors = color; --> 387 if 'dpt_groups' in colors: dpt_tree(adata, show=False); 388 dpt_timeseries(adata, cmap=cmap, show=show); 389 . ~/Documents/scanpy/scanpy/plotting/__init__.py in dpt_tree(adata, root, colors, names, show, fontsize); 463 if name in sett._ignore_categories: colors[iname] = 'grey'; 464 G = nx.Graph(adata.add['dpt_groups_adjacency']); --> 465 pos = utils.hierarchy_pos(G, root); 466 fig = pl.figure(figsize=(5, 5)); 467 ax = pl.axes([0, 0, 1, 1], frameon=False). ~/Documents/scanpy/scanpy/plotting/utils.py in hierarchy_pos(G, root, levels, width, height); 455 ; 456 if levels is None:; --> 457 levels = make_levels({}); 458 else:; 459 levels = {l: {TOTAL: levels[l], CURRENT: 0} for l in levels}. ~/Documents/scanpy/scanpy/plotting/utils.py in make_levels(levels, node, currentLevel, parent); 434 levels[currentLevel] = {TOTAL: 0, CURRENT: 0}; 435 levels[currentLevel][TOTAL] += 1; --> 436 neighbors = G.neighbors(node); 437 if parent is not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/24:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/24,1,['error'],['error']
Availability,I tried to install louvain through conda; `conda install -c vtraag louvain`; but got error message:; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain; - python-igraph[version='>=0.7.1.0']. However I could install it by; `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks!; [https://scanpy.readthedocs.io/en/latest/installation.html](url),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/143:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143,2,"['avail', 'error']","['available', 'error']"
Availability,"I try to use `sc.pl.pca` selecting components. According to the documentation the following should work:. ```python; import scanpy.api as sc; sc.logging.print_versions(); adata = sc.datasets.blobs(); sc.tl.pca(adata); sc.pl.pca(adata, components=['1,2', '2,3']); ```. However, I get an error. The output of the code above is:. ```python; scanpy==0+unknown anndata==0.6.9 numpy==1.14.5 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ... storing 'blobs' as categorical. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-4cd21e9edf25> in <module>(); 3 adata = sc.datasets.blobs(); 4 sc.tl.pca(adata); ----> 5 sc.pl.pca(adata, components=['1,2', '2,3']). ~/software/scanpy/scanpy/plotting/tools/__init__.py in pca(adata, color, use_raw, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save, ax); 114 title=title,; 115 show=False,; --> 116 save=False, ax=ax); 117 utils.savefig_or_show('pca_scatter', show=show, save=save); 118 if show == False: return axs. ~/software/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 110 show=show,; 111 save=save,; --> 112 ax=ax); 113 elif x is not None and y is not None:; 114 if ((x in adata.obs.keys() or x in adata.var.index). ~/software/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 291 if components is None: components = '1,2' if '2d' in projection els",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/254:286,error,error,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/254,1,['error'],['error']
Availability,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265:71,Error,Error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265,1,['Error'],['Error']
Availability,"I want to remove mitochondrial genes from the data before normalization. I already have used mitochondrial genes to calculate ""pct_counts_mito"", but I don't want them to be in the data for downstream analysis. Is there a function to achieve this in scanpy.api? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/353:189,down,downstream,189,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/353,1,['down'],['downstream']
Availability,"I want to split AnnData after tl.diffmap according to each cell's library. But it appears that row-slicing AnnData after diffmap, dpt, or louvain gives the error message `AttributeError: 'AnnData' object has no attribute '_n_obs'`. But AnnData.X and AnnData.obs can be sliced. Could you please give me advice?. ```py; >>> adata = sc.read_10x_h5('filtered_gene_bc_matrices_h5.h5', 'mm10'); >>> scanpy.api.tl.diffmap(adata); >>> adata_diffmap[:, 0]; View of AnnData object with n_obs × n_vars = 5000 × 1; >>> adata_diffmap[0, :] ; AttributeError: 'AnnData' object has no attribute '_n_obs'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/62:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/62,1,['error'],['error']
Availability,"I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me?. _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2442:300,reliab,reliably,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442,1,['reliab'],['reliably']
Availability,"I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:; ```python; adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path); 877 except Exception:; 878 # Make sure file doesn’t exist half-downloaded; --> 879 path.unlink(missing_ok=True); 880 raise; 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ...; ```; `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082,4,"['Error', 'down', 'error']","['Error', 'downloaded', 'error']"
Availability,"I was running Scanpy 1.4.5.1 on Jupyter Notebook; My matplotlib version is 3.1.3. I ran paga using these commands:; ```; sc.tl.paga(bdata,groups='leiden'); sc.pl.paga(bdata, plot=False); sc.pl.paga(bdata); ````. The third command gave me this error:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-65-5027c99fe1bd> in <module>; ----> 1 sc.pl.paga(bdata). /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227,1,['error'],['error']
Availability,"I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2318:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318,1,['error'],['error']
Availability,"I was running this:; `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`; Which gave me this error:; ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_30806/3135920018.py in <module>; ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the; 587 # structure of the gene_names dataFrame; --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values; 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values; 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1161 ; 1162 # fall thru to straight lookup; -> 1163 self._validate_key(key, axis); 1164 return self._get_label(key, axis=axis); 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis); 970 # boolean not in slice and with boolean index; 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):; --> 972 raise KeyError(; 973 f""{key}: boolean label can not be used without a boolean index""; 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```; Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1990:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990,1,['error'],['error']
Availability,"I was trying to subset my dataset based on multiple louvain cluster IDs but it seems to only be possible with one cluster ID at a time. At least I'm getting the following error. `NotImplementedError: Slicing with two indices at the same time is not yet implemented. As a workaround, do row and column slicing succesively.`. I'm still new to python and scanpy but would there be a workaround or fix to this? To ease the process I'v inserted what I want to do. `adata_subset = adata[adata.obs['louvain'] == '2', '3']`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/225:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/225,1,['error'],['error']
Availability,"I was wondering if plotting could be facilitated and made more consistent across ; the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem; * provides helper functions for handling colors, saving figures, etc. ; * encourages a consistent plotting API (e.g. by defining abstract base classes); * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:; * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:; - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. ; - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db); - scvelo has its own `scatter`; * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). ; * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832:608,mainten,maintenance,608,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832,1,['mainten'],['maintenance']
Availability,"I wonder for datasets whose umap results looking like this:; ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1976:348,error,error,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976,1,['error'],['error']
Availability,"I would like to color the umap representation using gene expression values. For ease of use I'd like to display the Gene name instead of gene_id which are the adata.var_names in my case. Setting `gene_symbols = 'Symbol'` doesn't seem to work for me or I am using it the wrong way. When running `sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2'])`. I get the follwoing error message:. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-116-e09d49f2528c> in <module>; ----> 1 sc.pl.umap(adata, gene_symbols = 'Symbol', color = ['Tnnt2']). /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in umap(adata, **kwargs); 27 If `show==False` a `matplotlib.Axis` or a list of it.; 28 """"""; ---> 29 return plot_scatter(adata, basis='umap', **kwargs); 30 ; 31 . /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 275 color_vector, categorical = _get_color_values(adata, value_to_plot,; 276 groups=groups, palette=palette,; --> 277 use_raw=use_raw); 278 ; 279 # check if higher value points should be plot on top. /anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 665 raise ValueError(""The passed `color` {} is not a valid observation annotation ""; 666 ""or variable name. Valid observation annotation keys are: {}""; --> 667 .format(value_to_plot, adata.obs.columns)); 668 ; 669 return color_vector, categorical. ValueError: The passed `color` Tnnt2 is not a valid observation annotation or variable name. Valid observation annotat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455:379,error,error,379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455,1,['error'],['error']
Availability,"I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/142:199,down,downstream,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142,2,['down'],['downstream']
Availability,"I'm adding that expression atlas downloader now (#489), and wondering where the files should go. `pbmc68k_reduced` and `toggleswitch` put the datasets relative to where scanpy is installed (via `__file__`). All other functions place the data relative to where the python process was started. While I like not storing the same files all over a filesystem, I'm not sure in the `scanpy` installation directory is the right place to be storing data. Thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558:33,down,downloader,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558,1,['down'],['downloader']
Availability,"I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. ; `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:; `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/106:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106,4,"['error', 'redundant']","['error', 'redundant']"
Availability,"I'm doing the same pathway I've done on hundreds of datasets but this particular one fails when I try to calculate PCA with:. ```; /opt/Python-3.7.0/lib/python3.7/site-packages/scipy/sparse/linalg/eigen/arpack/arpack.py in svds(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors); 1768 ; 1769 if k <= 0 or k >= min(n, m):; -> 1770 raise ValueError(""k must be between 1 and min(A.shape), k={0}, A.shape={1}"".format(k, A.shape)); 1771 ; 1772 if isinstance(A, LinearOperator):. ValueError: k must be between 1 and min(A.shape), k=50, A.shape=(48, 2066); ```; Looking into this, I looped through adata.var['n_cells'] and no values were greater than 48, so I'm not sure why this is happening. Dropbox link with both the input test [H5AD file and notebook here](https://www.dropbox.com/sh/t2qb7ffz5msyc5e/AAD256Vs6HqLwNBjcBeCsGVGa?dl=0). Am I missing as simple error?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/331:864,error,error,864,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/331,1,['error'],['error']
Availability,"I'm having some trouble getting the mitochondrial gene query to not throw an error. Here's an example:. ```python; import scanpy.api as sc; sc.queries.mitochondrial_genes(host=""www.ensembl.org"", org=""hsapiens""); ```; <details>; <summary>The output and traceback</summary>. ```python; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; ---------------------------------------------------------------------------; EmptyDataError Traceback (most recent call last); <ipython-input-14-a6967c88fd61> in <module>(); ----> 1 sc.queries.mitochondrial_genes(host=""www.ensembl.org"", org=""hsapiens""). /usr/local/lib/python3.6/site-packages/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 40 ; 41 # parsing mitochondrial gene symbols; ---> 42 res = pd.read_csv(StringIO(s.query(xml)), sep='\t', header=None); 43 res.columns = ['symbol', 'chromosome_name']; 44 res = res.dropna(). /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision); 676 skip_blank_lines=skip_blank_lines); 677 ; --> 678 return _read(filepath_or_buffer, kwds); 679 ; 680 parser_f.__name__ = name. /usr/local/lib/python3.6/site-packages/pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242,1,['error'],['error']
Availability,"I'm not sure how to fix the following error ( ""IndexError: The shape of AnnData along this dimension does not match the Boolean index. AnnData index has shape (17143), whereas Boolean index has shape (5258,) "")",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,"I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing?; Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sp; import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2381:500,down,downstream,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381,1,['down'],['downstream']
Availability,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233:167,avail,available,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233,2,"['avail', 'down']","['available', 'downstream']"
Availability,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:33,down,downloaded,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,3,"['down', 'error', 'toler']","['downloaded', 'error', 'tolerance']"
Availability,"I'm trying to install scanpy through `pip install scanpy` but I'm getting this weird error; ```; $ pip install scanpy; Collecting scanpy; Downloading scanpy-0.2.9.1.tar.gz (208kB); Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-lbk_t73k/scanpy/setup.py"", line 39, in <module>; readme = readme_f.read(); File ""/opt/conda/lib/python3.6/encodings/ascii.py"", line 26, in decode; return codecs.ascii_decode(input, self.errors)[0]; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); ```. That's with pip version `9.0.1` and python 3.6. I'm getting similar errors for older versions of scanpy, including 0.2.1. Perhaps this is a bug in pip but I'm not sure, I installed a bunch of other unrelated packages without any issues.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,4,"['Down', 'error']","['Downloading', 'error', 'errors']"
Availability,"I'm trying to plot on a view of an on-disk AnnData object, and it throws an error. Not sure if this is meant to be a supported feature, but I gave it a go. Here's a little example to reproduce:. ```python; adata = sc.AnnData(X=np.random.binomial(100, .01, (100, 100))); adata.obs_names = adata.obs_names.astype(str); # Both these work; sc.pp.pca(adata); sc.pl.pca(adata[:, :5], color=""0""); adata.write(""tmp.h5ad""); adata_backed = sc.read(""tmp.h5ad"", backed=""r""); sc.pl.pca(adata_backed, color=""0"") # this works; sc.pl.pca(adata_backed[:, :5], color=""0"") # this throws an error; ```. <details>; <summary> traceback (pretty long) </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); h5py/_objects.pyx in h5py._objects.ObjectID.__dealloc__(). KeyError: 0. Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'; Traceback (most recent call last):; File ""h5py/_objects.pyx"", line 200, in h5py._objects.ObjectID.__dealloc__; KeyError: 0; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-255f06b48663> in <module>(); 1 adata_backed = sc.read(""tmp.h5ad"", backed=""r""); 2 sc.pl.pca(adata_backed, color=""0""); ----> 3 sc.pl.pca(adata_backed[:, :5], color=""0""). /usr/local/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca(adata, color, use_raw, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save, ax); 114 title=title,; 115 show=False,; --> 116 save=False, ax=ax); 117 utils.savefig_or_show('pca_scatter', show=show, save=save); 118 if show == False: return axs. /usr/local/lib/python3.6/site-packages/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263,2,['error'],['error']
Availability,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1222:334,Error,Error,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222,2,"['Error', 'error']","['Error', 'error']"
Availability,"I'm trying to take subgroups from the AnnData object as such:; `adata_1 = adata[adata.obs['louvain'] == '0']`; which works but if I want to get the inverse; `adata_1 = adata[adata.obs['louvain'] != '0']`; it sometimes throws this error only on the second line.; 'IndexError: index 8 is out of bounds for axis 0 with size 8'; After some debugging, it seems like this occurs when you try run louvain clustering at different resolutions (ie doing it more than once). . Is there something real elementary that I am missing here? Or is there a better way of doing what I need? Thanks, Kevin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833,1,['error'],['error']
Availability,"I'm using Scanpy with the following software versions:. python==3.7; scanpy==1.4.4; numpy==1.17.2; anndata==0.6.22.post1. on Ubuntu 18.04. I am able to save my AnnData object just fine with . ```py; sc.write(results_file, adata); ```; and to load it again with . ```py; adata = sc.read(results_file); ```. however if I save it after I run the command . ```py; sc.tl.rank_genes_groups(adata, 'louvain12_lab', method='wilcoxon'); ```. the AnnData object will save but when I try to reload it, I get an error message:. ```pytb; ValueError Traceback (most recent call last); <ipython-input-141-159082f1696f> in <module>; 1 results_file = os.path.join(adir, '{project}.count_{count}.gene_{gene}.mito_{mito}.HVGs_{nhvgs}.TPT.{log}.scale.TEST.h5ad'.format(project=project_name, count=count_thresh, gene=gene_thresh, mito=mitothresh, nhvgs=nhvgs, log=logstatus)); 2 print(results_file); ----> 3 adata = sc.read(results_file). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /opt/min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832:500,error,error,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832,1,['error'],['error']
Availability,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297,2,['error'],['error']
Availability,"I'm using scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 on Mac 10.12.6 with python 3.7.1; I'm trying to do a pca on a annData object; `sc.tl.pca(adata, svd_solver='arpack')`; and get the following error even after restarting the jupyter notebook:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-26-eb775d53dbfd> in <module>; ----> 1 sc.tl.pca(adata, svd_solver='arpack'). ~/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 504 ; 505 if data_is_AnnData:; --> 506 adata.obsm['X_pca'] = X_pca; 507 if use_highly_variable:; 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). ValueError: no field of name X_pca; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/504:297,error,error,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504,1,['error'],['error']
Availability,"I've been having some issues recently when trying to subset an anndata object after I save it to disk. Everything works perfectly, but after I save it to disk using `adata.write(filename, compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's relate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/884:503,error,error,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884,1,['error'],['error']
Availability,"I've been trying to export my data to SPRING using the external export feature. I do all my processing in Seurat and then export a loom file to be read in scanpy and export to SPRING. I've been however getting the below error. The notebook with the code and the loom file can be found here: https://github.com/tejas-j/seurat2spring. Is there a better way to achieve what I'm trying to do (data -> Seurat -> scanpy -> SPRING) . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-3b0044b18ade> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sce.exporting.spring_project(data, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); 4 print(time.time() - t0). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, overwrite); 157 # Write continuous colors; 158 continuous_extras['Uniform'] = np.zeros(E.shape[0]); --> 159 write_color_tracks(continuous_extras, subplot_dir / 'color_data_gene_sets.csv'); 160 ; 161 # Create and write a dictionary of color profiles to be used by the visualizer. ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in write_color_tracks(ctracks, fname); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in <listcomp>(.0); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). TypeError: must be real number, not numpy.str_; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889:220,error,error,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889,1,['error'],['error']
Availability,"I've tried running `sc.pp.neighbors` with only 1 feature, got the following error:. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-6-e652dbfa9fae> in <module>; 3 ; 4 adata = sc.datasets.paul15(); ----> 5 sc.pp.neighbors(adata[:, 0]). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 653 use_dense_distances = (metric == 'euclidean' and X.shape[0] < 8192) or knn == False; 654 if use_dense_distances:; --> 655 _distances = pairwise_distances(X, metric=metric, **metric_kwds); 656 knn_indices, knn_distances = get_indices_distances_from_dense_matrix(; 657 _distances, n_neighbors). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds); 1586 func = partial(distance.cdist, metric=metric, **kwds); 1587 ; -> 1588 return _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1589 ; 1590 . ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1204 ; 1205 if effective_n_jobs(n_jobs) == 1:; -> 1206 return func(X, Y, **kwds); 1207 ; 1208 # enforce a threading backend to prevent data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_dista",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/837:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837,1,['error'],['error']
Availability,"If I read a file with read_h5ad() and then process with . `sc.pp.filter_genes(adata, min_cells=int(foo)); `; Things work as intended. But if I change that read line to be read_h5ad(h5_path, backed='r') then when I attempt to filter I get this error instead:. ```; File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 228, in filter_genes:; else X > 0, axis=0):; TypeError: '>' not supported between instances of 'SparseDataset' and 'int'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/650:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650,1,['error'],['error']
Availability,"If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2351:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351,1,['error'],['error']
Availability,"If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1886:154,error,errors,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886,1,['error'],['errors']
Availability,"If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); pbmc.layers[""sparse""] = pbmc.raw.X; sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") ; ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-89244dc07987> in <module>; 3 pbmc = sc.datasets.pbmc68k_reduced(); 4 pbmc.layers[""sparse""] = pbmc.raw.X; ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 411 """"""; --> 412 return plot_scatter(adata, 'pca', **kwargs); 413 ; 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 199 _data_points[:, 0], _data_points[:, 1],; 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 201 **kwargs,; 202 ); 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1587 def inner(ax, *args, data=None, **kwargs):; 1588 if data is None:; -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs); 1590 ; 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/700:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700,1,['error'],['error']
Availability,"If you use `knn=False` to calculate neighbors, any choice of metric is ignored. [Here's the offending line of code.](https://github.com/theislab/scanpy/blob/6c1daba7448be72de84dec16a038fcaeda1636ad/scanpy/neighbors/__init__.py#L706). A quick example:. ```python; import scanpy.api as sc; import numpy as np. adata = sc.datasets.krumsiek11(); adata.obs_names_make_unique(); sc.pp.pca(adata) # To get rid of warnings; adata_eucl = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True); adata_spear = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True, metric=""correlation""). assert np.all(adata_eucl.uns[""neighbors""][""connectivities""] == adata_spear.uns[""neighbors""][""connectivities""]); ```. Additionally, I suspect this should throw an error:. ```python; sc.pp.neighbors(adata, method=""gauss"", knn=False, metric=""not a real metric""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/241:751,error,error,751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/241,1,['error'],['error']
Availability,Import error when old version of tqdm is installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1244:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244,1,['error'],['error']
Availability,Import error when running cyclone,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/655:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/655,1,['error'],['error']
Availability,ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_nor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20375,ERROR,ERROR,20375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5973,ERROR,ERROR,5973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"In a recent paper, we found the brute force KNN computation to become very expensive as the data sizes increase. I’ve noticed the kNN graph computed during the “neighbors” computation can be cached and reused when Umap-learn is called downstream but when Cuml UMAP is used, the kNN graph is recomputed each time. . In cuml 0.13 we added an optional `knn_graph` argument to umap’s training and inference methods to allow it to accept pre-computed kNN graph. This will allow the kNN graph to be computed once and reused when `n_neighbors` has not been changed. I think this would further accelerate the exploratory data analysis and visualization process with scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1279:235,down,downstream,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1279,1,['down'],['downstream']
Availability,"In some edge cases, the control gene selection retrieves the same gene(s) that are also in the gene_list used for scoring.; As a result, when the following line is called, we end up with an empty control gene set, causing the downstream error in #2153; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L173. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2153 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875:226,down,downstream,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875,2,"['down', 'error']","['downstream', 'error']"
Availability,"In the documentation (https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html) the figure given as an example for pl.violin does not match the actual output of pl.violin (rather, it's showing a stacked violin). If there's a more appropriate place for me to record errors in the documentation, please let me know. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1294:273,error,errors,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1294,1,['error'],['errors']
Availability,Ingest error when neighbors from bbknn,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201,1,['error'],['error']
Availability,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780:457,down,downstream,457,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780,1,['down'],['downstream']
Availability,Internal Server Error for queries.biomart_annotations,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1660:16,Error,Error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660,1,['Error'],['Error']
Availability,"Introduces a function to calculate marker gene overlaps between a reference set of marker genes provided as a dictionary, and data-derived marker genes as calculated by `sc.tl.rank_genes_groups()`. Currently implemented overlap functions are: overlap counts (with row or column normalization), overlap coefficient, and jaccard index. Still to do:; - write a test; - finish documentation; - allow p-value thresholding when available; - allow using top X marker genes rather than all calculated markers; - test that it works properly...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549:422,avail,available,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549,1,['avail'],['available']
Availability,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs × n_vars = 1493240 × 4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361,3,"['error', 'fault']","['error', 'fault']"
Availability,Is sctransform available ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068:15,avail,available,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068,1,['avail'],['available']
Availability,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1874:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874,3,['error'],['error']
Availability,"It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1910:300,error,error,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910,1,['error'],['error']
Availability,"It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:; `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:; scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/344:250,error,error,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344,1,['error'],['error']
Availability,"It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1497:223,error,error,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497,2,"['Error', 'error']","['Error', 'error']"
Availability,It’s less error prone and a nicer API. Fixes #563,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/564:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/564,1,['error'],['error']
Availability,Just a minor improvement. Now you can specify the total counts to downsample to on a per-cell basis by passing an array for `counts_per_cell`. This is so I don't have to split and merge an AnnData object when I want multiple distributions of counts per cell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/602:66,down,downsample,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/602,1,['down'],['downsample']
Availability,KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297,1,['error'],['error']
Availability,LED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2374,ERROR,ERROR,2374,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,LLVM ERROR: Symbol not found: __svml_sqrtf8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696:5,ERROR,ERROR,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696,1,['ERROR'],['ERROR']
Availability,Looks like there was a typo at the bottom of `scanpy/preprocessing/_dca.py` that was causing a parse error. This should fix it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/527:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/527,1,['error'],['error']
Availability,MAGIC in external causes test failures if its not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:30,failure,failures,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['failure'],['failures']
Availability,Make partition modularity available in adata.uns,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819:26,avail,available,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819,1,['avail'],['available']
Availability,Make plot_scatter() available to user,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617:20,avail,available,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617,1,['avail'],['available']
Availability,"Mask for pca, normalize_pearson_residuals_pca, scatterplot, scale",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272:0,Mask,Mask,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272,1,['Mask'],['Mask']
Availability,Math domain error in rank_genes_groups function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530,1,['error'],['error']
Availability,Math domain error when using the Wilcoxon rank-sum,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566,1,['error'],['error']
Availability,"Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/387:568,avail,available,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387,1,['avail'],['available']
Availability,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090:842,down,down,842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090,1,['down'],['down']
Availability,"Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```; import scanpy.api as sc; data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data); ```. Then this error happens:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-14-1f44700b9ea5> in <module>(); ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs); 104 def new_func(*args, **kwargs):; 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter; --> 106 warnings.warning(; 107 'Use {0} instead of {1}, {1} will be removed in the future.'; 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/394:43,recover,recover,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394,2,"['error', 'recover']","['error', 'recover']"
Availability,Memory error and Anndata error raised while using sc.read_h5ad,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,2,['error'],['error']
Availability,Minor Bug: scanpy.logging.print_versions() throws Key Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:54,Error,Error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,1,['Error'],['Error']
Availability,"Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb; ValueErrorTraceback (most recent call last); <ipython-input-823-4c11b9b62e6d> in <module>; ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 505 X = adata_comp.X; --> 506 X_pca = pca_.fit_transform(X); 507 ; 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 357 ; 358 """"""; --> 359 U, S, V = self._fit(X); 360 U = U[:, :self.n_components_]; 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 404 # Call different fits for either full or truncated SVD; 405 if self._fit_svd_solver == 'full':; --> 406 return self._fit_full(X, n_components); 407 elif self._fit_svd_solver in ['arpack', 'randomized']:; 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components); 423 ""min(n_samples, n_features)=%r with ""; 424 ""svd_solver='full'""; --> 425 % (n_components, min(n_samples, n_features))); 426 elif n_components >= 1:; 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432,1,['error'],['error']
Availability,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1987:340,error,error,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987,1,['error'],['error']
Availability,Neighbors.compute_transitions() with error 'AnnData' object has no attribute '_connectivities',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2109:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109,1,['error'],['error']
Availability,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105:361,Recover,Recover,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105,1,['Recover'],['Recover']
Availability,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1280:179,error,error,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Now if I intend to run ingest, I will get this error:; running ingest; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); 13 frames; <ipython-input-22-9176945aef7f> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 131 ; 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951,1,['error'],['error']
Availability,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931:57,avail,available,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931,5,"['avail', 'error']","['available', 'errors']"
Availability,Numba error in calculate_qc_metrics on a windows machine,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843,1,['error'],['error']
Availability,"On current master:. ```python; import scanpy as sc. a = sc.datasets.krumsiek11(); assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]; # True; ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1895:262,down,downstream,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895,1,['down'],['downstream']
Availability,Option for downloading tissue image for spatial visium dataset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506:11,down,downloading,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506,1,['down'],['downloading']
Availability,"Option to ignore ""nan"" with sc.pl.rank_genes_groups() and error while writing data to .h5ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1651:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1651,1,['error'],['error']
Availability,PAGA plotting error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/487:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/487,1,['error'],['error']
Availability,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151:307,Error,Error,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151,1,['Error'],['Error']
Availability,PR problem: docstring error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484,1,['error'],['error']
Availability,"PYTHON_VERSION variable is empty, so we actually pass `python=` in `conda create` so Travis always tests scanpy with latest Python in Conda distribution. Therefore Python 3.5 is actually never tested. Furthermore, conda switched to python 3.7, so now all test are run on Python 3.7. This is also the reason of weird HDF error message we get in tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/201:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/201,1,['error'],['error']
Availability,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we don’t internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2702:1113,error,error,1113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702,1,['error'],['error']
Availability,Passing a RandomState instance can cause failures to save,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:41,failure,failures,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,1,['failure'],['failures']
Availability,"Passing string or function to `vmax`, `vmin` when categorical in `color` throws error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800,1,['error'],['error']
Availability,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1546:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546,3,"['Ping', 'error']","['Ping', 'error']"
Availability,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088,1,['Ping'],['Ping']
Availability,Plotting UMAP in backed mode leads to error when setting color palettes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2401:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401,1,['error'],['error']
Availability,Plotting categorical data throws an error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850,1,['error'],['error']
Availability,Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1975:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975,1,['error'],['error']
Availability,Plotting error when NaN in the categorical column and there are repetitive colours,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2133:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2133,1,['error'],['error']
Availability,Plotting on view of backed anndata throws error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263,1,['error'],['error']
Availability,Plotting with using scanpy.pl gives attribute error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['error'],['error']
Availability,"Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python; In [1]: import scanpy.api as sc ; ...: sc.datasets.pbmc3k().var.head() ; Out[1]: ; gene_ids; index ; MIR1302-10 NaN; FAM138A NaN; OR4F5 NaN; RP11-34P13.7 NaN; RP11-34P13.8 NaN. In [2]: import h5py ; ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: ; ...: print(repr(f[""var""][:])) ; ...: ; array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,; (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],; dtype=[('index', 'S19'), ('gene_ids', 'i1')]); ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz ; ...; In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz; ...; In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() ; Out[5]: ; gene_ids; MIR1302-10 ENSG00000243485; FAM138A ENSG00000237613; OR4F5 ENSG00000186092; RP11-34P13.7 ENSG00000238009; RP11-34P13.8 ENSG00000239945; ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/428:747,down,download,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428,1,['down'],['download']
Availability,Potential error in scanpy.tl.rank_genes_groups?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2634:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634,1,['error'],['error']
Availability,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356:1001,down,down,1001,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356,1,['down'],['down']
Availability,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. it’s not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2595:102,avail,available,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595,1,['avail'],['available']
Availability,"Prepare 1.9.8, stop ignoring citation errors",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831,1,['error'],['errors']
Availability,Prevent error when no third point is found,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/266:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266,1,['error'],['error']
Availability,"Previously discussed in #240. A few things left to discuss:. ## Tests. These are pretty simple, ""this doesn't intrinsically throw an error"" type tests. Should the tests cover more than that? Should they be more thorough is checking arguments won't throw errors? I'm open to suggestions on other things that could be checked. Also, is there a place they'd be more appropriate?. ## Allowing storage of multiple network representations . I think this would also be a pretty simple addition, but wanted to check again before implementing it. I'm thinking of adding a `use_network` argument which would allow key access to network stored in the AnnData object – similar to the `use_rep` argument. @LuckyMD mentioned there might be some storage concerns here, though I think the user is ultimately responsible for size in this case. The value added here is different representations are useful for different analysis, and it'd be useful to not have to have two objects when the rest of the data would be shared. ## Allow more choice of partition method for `louvain-igraph` package. I'm not too fussed on this one. It's just that `""RBConfiguration""` is hard coded when other methods are available, and I'm not aware of a reason it would be the best choice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248:133,error,error,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248,3,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytest’s test files (`test_*.py` and `conftest.py`) aren’t Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225:566,error,error,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225,1,['error'],['error']
Availability,Random test failure of `test_plotting.py::test_paga`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:12,failure,failure,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['failure'],['failure']
Availability,Rank gene groups math error in windows,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061,1,['error'],['error']
Availability,Recipes with plotting option throw import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/153:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153,1,['error'],['error']
Availability,Reduce error potential from networkx (e.g. #1227),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1323:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323,1,['error'],['error']
Availability,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1806:79,down,down,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,Remove python 3.8 only code from download code,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1087:33,down,download,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087,1,['down'],['download']
Availability,"Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default; * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442:670,error,error,670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442,1,['error'],['error']
Availability,Rename mask parameters,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2857:7,mask,mask,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2857,1,['mask'],['mask']
Availability,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1062:1443,error,error,1443,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062,2,['error'],['error']
Availability,Require a minimum groupsize for marker detection to prevent division by zero errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490:77,error,errors,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490,1,['error'],['errors']
Availability,"Right now, when we do `sc.pl.pca_loadings(adata, components=range(5))` to plot first 5 components or even weirder things like `sc.pl.pca_loadings(adata, components=[-10, 0, 5])` the plotting function silently subtracts 1 and uses these as indices for `adata.varm['PCs']`. We can see in the plot title things like `PC-11`. It's confusing and error prone. This change throws an error if a PC index is invalid.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/803:341,error,error,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/803,2,['error'],['error']
Availability,"Running `sc.pl.paga(adata)` in v1.4 returns an error:; ```; Traceback (most recent call last):. File ""<ipython-input-412-3baa85828ec9>"", line 1, in <module>; sc.pl.paga(adata). File ""/path/to/scanpy/scanpy/plotting/_tools/paga.py"", line 445, in paga; adjacency_solid, layout=layout, random_state=random_state, init_pos=init_pos, layout_kwds=layout_kwds, adj_tree=adj_tree, root=root). UnboundLocalError: local variable 'adj_tree' referenced before assignment; ```. There is a conditional before the referenced line, which assigns value to `adj_tree`, and indeed, running these works fine:; ```; sc.pl.paga(adata, layout='rt'); sc.pl.paga(adata, layout='rt_circular'); sc.pl.paga(adata, layout='eq_tree'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/487:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/487,1,['error'],['error']
Availability,Running example with magics gives error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,1,['error'],['error']
Availability,"Running https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py on the latest released Scanpy (1.4.4.post1) gives a memory error:. ```; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; (0:01:39); running recipe zheng17; filtered out 3983 genes that are detectedin less than 1 counts; Killed; ```. This is running with 60GB of memory (n1-standard-16), but also occurs with 104GB (n1-highmem-16). It looks like there has been a regression somewhere since this used to run OK. I think the error may be happening in anndata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/811:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/811,2,['error'],['error']
Availability,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,Running scanpy on M1 apple silicon clashes with Numba errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:54,error,errors,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). ; for adata in adata_control:; adata.var[""mt""] = adata.var_names.str.startswith(""mt-""); sc.pp.calculate_qc_metrics(; adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True; ); I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2304:98,error,error,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304,1,['error'],['error']
Availability,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/846:102,down,down,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846,1,['down'],['down']
Availability,RuntimeError: libpng signaled error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852,1,['error'],['error']
Availability,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061,1,['error'],['error']
Availability,Scanpy docs are down?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1746:16,down,down,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1746,1,['down'],['down']
Availability,Scanpy import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138,1,['error'],['error']
Availability,"Scanpy vs. 1.3.6; installed using pip3; OSX 10.10.5; Jupyter lab. code:; `list_of_list_of_marker_genes = [mg1, mg2, mg3]; for mg in list_of_list_of_marker_genes:; sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90); print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run; sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then; 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405:549,error,error,549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405,2,"['Error', 'error']","['Error', 'error']"
Availability,Scanpy.pl.embedding throws error when projection='3d' and all values are the same for coloring,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability,Scatterplot with color for categorical value outputs attribute error about legend,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102,1,['error'],['error']
Availability,"Setting one root works well:; `sc.pl.paga(adata, layout='eq_tree', root=[9])`; Setting multiple roots returns an error: ; `TypeError: unhashable type: 'list'`; Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/128:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128,1,['error'],['error']
Availability,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1102:20,down,downloading,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102,2,['down'],"['downloaded', 'downloading']"
Availability,"Simple test case; ```; data = sc.read(""pbmc3k.h5ad""); logical_ar = data.var[""name""] == ""RER1""; df = data[:, logical_ar]; df.uns = data.uns # this causes an error ; ```. Causes this error; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-8b2cadedfe9b> in <module>(); 1 l = data.var[""name""] == ""RER1""; 2 df = data[:, l]; ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value); 987 # here, we directly generate the copy; 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)); --> 989 self._init_as_actual(adata); 990 self._uns = value; 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode); 816 self._varm = BoundRecArr(varm, self, 'varm'); 817 ; --> 818 self._check_dimensions(); 819 self._check_uniqueness(); 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key); 1692 raise ValueError('Observations annot. `obs` must have number of '; 1693 'rows of `X` ({}), but has {} rows.'; -> 1694 .format(self._n_obs, self._obs.shape[0])); 1695 if 'var' in key and len(self._var) != self._n_vars:; 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/323:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323,2,['error'],['error']
Availability,Simplification of _ranks in rang_genes_groups. Passing pandas index to scipy dendrogram now causes an error. This fixes the problem.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1290:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1290,1,['error'],['error']
Availability,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:960,error,error,960,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,1,['error'],['error']
Availability,"Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python; if plot:; from .. import plotting as pl # should not import at the top of the file; pl.filter_genes_dispersion(filter_result, log=True); ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python; In [1]: import numpy as np; ...: import pandas as pd; ...: import scanpy.api as sc; ...: ; ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; ...: sc.logging.print_versions(); /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; In [3]: sc.pp.recipe_zheng17(adata, plot=True); running recipe zheng17; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-c19f237f1c6e> in <module>(); ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy); 106 if plot:; 107 from .. import plotting as pl # should not import at the top of the file; --> 108 pl.filter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/153:106,error,error,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153,3,['error'],"['error', 'errors']"
Availability,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:149,failure,failure,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,1,['failure'],['failure']
Availability,"Sometimes, it can happen when downloading 10x files from e.g. GEO that they are not organized in; folders but instead, they have a sample-specific prefix. E.g. . ```console; sturm@zeus [SSH] processed % ll; total 156M; -rw-r--r-- 1 dbadmin dbadmin 29K May 21 2018 GSM3148575_BC09_TUMOR1_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148575_BC09_TUMOR1_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 34M May 21 2018 GSM3148575_BC09_TUMOR1_matrix.mtx.gz; -rw-r--r-- 1 dbadmin dbadmin 28K May 21 2018 GSM3148576_BC09_TUMOR2_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148576_BC09_TUMOR2_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 33M May 21 2018 GSM3148576_BC09_TUMOR2_matrix.mtx.gz; ```. This PR adds a keyword argument `prefix` to `read_10x_mtx` which enables to load these files ; without manual renaming and moving, e.g. ; ```python; adata = sc.read_10x_mtx(""path/to/files"", prefix=""GSM3148575_BC09_TUMOR1_""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1250:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250,1,['down'],['downloading']
Availability,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2470:501,down,downstream,501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470,2,['down'],['downstream']
Availability,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334:39,Error,Error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334,4,"['Error', 'down', 'error']","['Error', 'downloading', 'error']"
Availability,"Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master); --------|--------------------------|--------------; `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs; 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1022:475,Ping,Ping,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022,1,['Ping'],['Ping']
Availability,Test case failure with test_visium_default not having any visible data points,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048:10,failure,failure,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048,1,['failure'],['failure']
Availability,Test rtd failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1900:9,failure,failures,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900,1,['failure'],['failures']
Availability,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2425:197,avail,available,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425,1,['avail'],['available']
Availability,"Thanks for all the work in developing this package, it's truly fantastic. . I ran into what seems like a bug in the new plotting function sc.pl.rank_genes_groups_stacked_violin. It seems that when the ranked genes between 2 groups are similar (e.g. 'Tnf' is a highly ranked gene between two groups), then 'Tnf' is only plotted once on the first group, and any following groups with the same gene are truncated. You can see this in the toy example image I attached - when comparing groups M1 and M1+M2, 'Tnf' should be plotted for each group, but it is only plotted on group M1, therefore truncating group M2. When I plot the same data using rank_genes_groups_dotplot, this error doesn't happen and 'Tnf' is correctly plotted twice. I know this is a small bug that most people will probably not run across, but just in case you're comparing expression across similar groups this might be a useful fix. Thanks!. ![stacked_violin_global](https://user-images.githubusercontent.com/37122760/44924265-bd353000-ad18-11e8-84d0-a0136083dbdd.png). ![dotplot_global](https://user-images.githubusercontent.com/37122760/44924244-aa226000-ad18-11e8-9351-4b28d11a7ee5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252:673,error,error,673,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252,1,['error'],['error']
Availability,"Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing.; My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10。; I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,; but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors.; Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/276:337,error,errors,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276,4,['error'],['errors']
Availability,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053:577,avail,available,577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053,1,['avail'],['available']
Availability,"The PCA test `test_mask_defaults` only passed because of `float32` being to loose in some situation. When the mask randomly was `[True, True, True, True, True]` the test should have failed. Now the test works as intended.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2914:110,mask,mask,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2914,1,['mask'],['mask']
Availability,"The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1768:213,down,down,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768,2,"['down', 'error']","['down', 'error']"
Availability,"The docs for `sc.pl.scatter` say . > The palette can be a valid ListedColormap name ('Set2', 'tab20', …). but setting `palette` to a string throws an error. ```python; adata = sc.datasets.paul15(); sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""); ```. ```pytb; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-698-58a5366a0f70> in <module>; 1 adata = sc.datasets.paul15(); ----> 2 sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,"The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)); > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421,1,['error'],['error']
Availability,"The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1471:4,down,download,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471,2,['down'],"['download', 'downloaded']"
Availability,"The function of ""sc.pp.filter"" report an error ""index out of range"", why?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2759:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2759,1,['error'],['error']
Availability,The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472,2,"['down', 'error']","['download', 'error']"
Availability,"The test `test_marker_overlap` keeps failing on the travis build for python 3.5. This seems to happen on the first build from a PR, but if the build is restarted it passes. Given that my `n=3` for this, it could also be random. Grabbed the error log from #579 (build [1735.1](https://travis-ci.org/theislab/scanpy/jobs/514097606)):. ```; _____________________________ test_marker_overlap ______________________________; def test_marker_overlap():; # Test all overlap calculations on artificial data; test_data = sc.AnnData(X = np.ones((9,10))); test_data.uns['rank_genes_groups'] = dict(); test_data.uns['rank_genes_groups']['names'] = np.rec.fromarrays(; [['a', 'b','c','d','e'], ['a','f','g','h','i']]); test_data.uns['rank_genes_groups']['pvals_adj'] = np.rec.fromarrays(; [[0.001, 0.01, 0.02, 0.05, 0.6], [0.001, 0.01, 0.02, 0.05, 0.6]]); ; marker_genes = {'type 1':{'a','b','c'}, 'type 2':{'a','f','g'}}; ; t1 = sc.tl.marker_gene_overlap(test_data, marker_genes); t2 = sc.tl.marker_gene_overlap(test_data, marker_genes, normalize='reference'); t3 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='overlap_coef'); t4 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='jaccard'); t5 = sc.tl.marker_gene_overlap(test_data, marker_genes, top_n_markers=2); t6 = sc.tl.marker_gene_overlap(test_data, marker_genes, adj_pval_threshold=0.01); ; > assert t1.iloc[1,1] == 3.0; E assert 1.0 == 3.0; scanpy/tests/test_marker_gene_overlap.py:22: AssertionError; ```. Here's a [gist](https://gist.github.com/ivirshup/6965ebe2530c4eac67aebf41c3961959) of the full output. Any idea what's up @LuckyMD?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580,1,['error'],['error']
Availability,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892:269,ping,ping,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892,1,['ping'],['ping']
Availability,"The tests use `group` but the code handles `obs`. TODO: should `heatmap` be changed too? Its docs actually speak of “variables or observations” and not “variables or groups”. About the test changes:. Some time ago, matplotlib made a change to font rendering. Since we have such high tolerance when comparing plots, that didn’t affect our tests. But that also means that our tests are almost useless, since the actual qualitative difference in the test that _did_ change behavior due to my PR wasn’t caught. Therefore I lowered the tolerance, which meant I had to regenerate everything with the new font rendering. | Before | After |; |--------|--------|; | ![](https://raw.githubusercontent.com/scverse/scanpy/bd758395a669c31a6c9eaa9239750fde368d3ca7/tests/_images/stacked_violin_std_scale_group/expected.png) | ![](https://raw.githubusercontent.com/scverse/scanpy/c06bbc83218ee426fa54e681ab39c8006e1668c0/tests/_images/stacked_violin_std_scale_group/expected.png) |",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243:283,toler,tolerance,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243,2,['toler'],['tolerance']
Availability,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915:434,avail,available,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915,3,['avail'],['available']
Availability,This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me); - closes #1434 clarify qc metric and normalize total @havardtl; - closes #827 clarify diff component indexing @veghp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1680:63,Ping,Pinging,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680,1,['Ping'],['Pinging']
Availability,"This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON; pbmc = sc.datasets.pbmc68k_reduced(); ```; ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON; sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True); ```; ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/308:1023,avail,available,1023,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308,1,['avail'],['available']
Availability,"This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions hav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753:442,error,error-case-sensitive-drives-supported,442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753,1,['error'],['error-case-sensitive-drives-supported']
Availability,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2512:200,avail,available,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512,2,"['avail', 'down']","['available', 'download']"
Availability,"This PR is meant to get doc builds working again. I've added `setuptools_scm` and fixed a typo in the shared plotting docs. Read the docs seems to be working again, but I'm still getting this error locally:. ```; Warning, treated as error:; /Users/isaac/github/scanpy/docs/external/scanpy.external.exporting.cellbrowser.rst:2:duplicate object description of scanpy.external.exporting.cellbrowser, other instance in api/scanpy.external.exporting.cellbrowser, use :noindex: for one of them; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/802:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/802,2,['error'],['error']
Availability,This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655:115,down,downstream,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655,1,['down'],['downstream']
Availability,This PR resolves the issues with:. * error when the type of a category is not `str`; * inconsistent color assigned to categories; * white space ; * horizontal lines not well aligned. Missing. - [x] Tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1603:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1603,1,['error'],['error']
Availability,"This adds RAPIDS as an (experimental) option for running some of the graph algorithms on a GPU. Example usage is demonstrated here: https://github.com/tomwhite/scanpy_usage/tree/rapids-gpu/1909_rapids_gpu. In summary:. ```python; sc.pp.neighbors(adata, method='rapids'); sc.tl.louvain(adata, flavor='rapids'); sc.tl.umap(adata, method='rapids'); ```. Timings (on 130K samples):. | Step | CPU time (s) | GPU time (s) | Speedup |; | --------- | ------------ | ------------ | ------- |; | Neighbors | 47 | 15 | 3x |; | Louvain | 70 | 1 | 70x |; | UMAP | 186 | 15 | 12x |. Comments:; * In general the output figures are quite different for each of the algorithms compared to regular Scanpy. (See the figures in the link above.); * RAPIDS uses exact nearest neighbors (using https://github.com/facebookresearch/faiss I think), whereas the default NNDescent algorithm in Scanpy is approximate.; * Louvain community detection results in a different number of communities (28 vs 45). I'm not sure if it is possible to change the termination criteria or other parameters that would make the two outputs the same, or at least more similar.; * UMAP is different too, and in particular it is bunched in one corner. There are a few very small clusters in the opposite corner, which looks like it might be a bug.; * UMAP computes the nearest neighbors again from scratch - it can’t reuse the ones computed earlier since RAPIDS only exposes the fit/transform methods, and not `simplicial_set_embedding` that regular UMAP exposes.; * In general it would be useful to understand what random number generators each of the alternatives use, how they can be controlled, and what prospects there are for achieving identical output (if any).; * This is using RAPIDS version 0.7 since it is the version available on the Google Cloud image I used (https://cloud.google.com/deep-learning-vm/docs/images).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830:1780,avail,available,1780,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830,1,['avail'],['available']
Availability,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487:286,error,error,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487,1,['error'],['error']
Availability,This error appears when using DESC autoencoder (github: eleozzr/desc) under scanpy 1.4.4. This was not an issue with earlier versions of scanpy. Is there a work-around available?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/895:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895,2,"['avail', 'error']","['available', 'error']"
Availability,"This fixes #415, by allowing one to find variable genes using the `equal_frequency` option. It also adds and option to change the number of bins for cell ranger flavor. I originally tried to copy the implementation in Seurat, which would allow a test similar to what's already present for the `equal_width` implementation. However the Seurat code has an error:; ```R; else if (binning.method==""equal_frequency"") {; data_x_bin <- cut(x = gene.mean, breaks = c(-1,quantile(gene.mean[gene.mean>0],probs=seq(0,1,length.out=num.bin)))); }; ```; The `-1` in the code makes it such that there is always only one value in the first bin, which goes from -1 to the minimum value. Not sure why they have this, but then we get different answers since the Scanpy code in `highly_variable_genes` always makes bins that have only one gene significant (to correct the other error from Seurat that normally excludes these bins/genes, which often contain some highly-expressed genes). Additionally, the `cut` function in R sometimes returns bin edges with different rounding than the Seurat implementation since Seurat does not modify the default `dig.lab = 3`. In contrast, I believe pandas uses the actual cutoffs in the data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/572:354,error,error,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/572,2,['error'],['error']
Availability,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507:35,down,downloading,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507,3,['down'],"['download', 'downloaded', 'downloading']"
Availability,"This includes fixes for both #469 and #470 . #469 was a small indexing error. To fix #470, a `rankby_abs` check is included in the `logreg` section of the method that mirrors the `rankby_abs` checks in the other two methods. This PR additionally updates `select_groups` function in `scanpy/utils.py.` I was having some issues when the clusters that I was using were labelled by integers (i.e. when `adata.obs[key].cat.catagories.values.dtype` was some form of integer) AND when I was looking at a subset of the clusters (e.g. `groups=[0,1]`, not when `groups='all'`). At the start of the `rank_genes_groups` function, these cluster labels are converted into strings in the `groups_order` variable. In the `select_groups` function (line 667 of the original utils.py file), however, we call ; ``` ; np.where(adata.obs[key].cat.categories.values == name)[0][0]; ```; which fails with an error (since `name` is a string from `select_groups` and the elements of `adata.obs[key].cat.categories.values` are integers). Thus, this PR includes a check for the `dtype` of `adata.obs[key].cat.categories.values` - if it is numeric, we instead look at ; ``` ; np.where(adata.obs[key].cat.categories.values == float(name))[0][0]; ```. This error should only appear if the cluster labels are integers (since this is the only time that the cluster labels are converted to strings for `groups_order` in `rank_genes_groups`) but the above fix should also work if the cluster labels are any floating point numbers (just in case the `rank_genes_groups` is ever generalized in this way). ([Here](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.scalars.html) is a link to the numpy type hierarchy). Edit: added a line number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/471:71,error,error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/471,3,['error'],['error']
Availability,"This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required.; - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. ; - I've moved what was sensible to use Scanpy functions. ; - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476:1236,mainten,maintenance,1236,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476,1,['mainten'],['maintenance']
Availability,"This is a bit of a grab bag, but is mostly `io` related. This started out as me trying to learn some vscode git integration, but turns out it's not great at figuring out what lines changed. Apologies for any weird stuff in the commits. Main changes:. * I've made the tests for `sc.datasets` more thorough. Now they actually check the data looks kinda okay, rather than whether they throw an error.; * I've removed cache-ing in a few places; * The `read_10x_*` tests, where that definitely shouldn't have been happening; * In a couple of the `sc.datasets`. I'd be willing to go back on this, but we shouldn't let them use the cache during testing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/592:391,error,error,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/592,1,['error'],['error']
Availability,This is helpful for downloading datasets from the 10x website and generally fixes #1264.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1296:20,down,downloading,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296,1,['down'],['downloading']
Availability,"This is in an Ubuntu 16..04 Docker container:; ```; docker run --rm -it ubuntu:16.04; ```; Then I ran:; ```; apt-get update && apt-get install -y \; python3-pip \; python3-setuptools; python3-wheel. pip3 install scanpy; ```. I get the following output (after all of the dependencies are downloaded):. ```; warning: manifest_maker: standard file '-c' not found; ; reading manifest file 'scanpy.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'scanpy.egg-info/SOURCES.txt'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>; 'Topic :: Scientific/Engineering :: Visualization',; File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup; dist.run_commands(); File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands; self.run_command(cmd); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run; self.run_command('build'); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run; _build_py.run(self); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/usr/lib/python3/dist-packages/setuptools/command/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:287,down,downloaded,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,1,['down'],['downloaded']
Availability,"This issue just came up recently when I tried re-running an older notebook of mine. Whenever I try and run my code in Jupyter notebook and execute any cell that uses scanpy.tl.tsne my kernel crashes. When I try and execute the same code from the terminal I get ; `Segmentation fault: 11`. . This is the code I used to reproducibly get the error:; ```; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. <img width=""629"" alt=""Screenshot 2019-10-16 at 14 39 09"" src=""https://user-images.githubusercontent.com/15019107/66920007-c2d7fd00-f022-11e9-93d6-560305d1cc50.png"">. Any ideas what the issue could be and how I can fix this? The function used to work fine for me. I am running scanpy in the following version:; `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/874:277,fault,fault,277,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874,2,"['error', 'fault']","['error', 'fault']"
Availability,"This may be related to this issue:; https://github.com/theislab/scanpy/issues/918#issue-522668041. I was running:. `sc.tl.umap(bdata, init_pos='paga')`. But it gave me this error:. ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)); [2] During: typing of call at /usr/local/lib/python3.6/dist-packages/umap/umap_.py (795). File ""../../usr/local/lib/python3.6/dist-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/936:173,error,error,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936,1,['error'],['error']
Availability,"This pull request is same as https://github.com/scverse/scanpy/pull/3110 with allowed edits to maintainers. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec) |; | -- | -- |; | Original | 297 |; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284:758,Down,Downloading,758,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"This simplifies `top_segment_proportions_sparse_csr` by using improvements in numba which allow cacheing parallel code. A downside of this is it takes a really long time to compile on first run, which might be off-putting. Side note: I accidentally ran formatting before committing, so some other lines got changed too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844:122,down,downside,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844,1,['down'],['downside']
Availability,"This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2374:30,error,errors,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374,1,['error'],['errors']
Availability,"Tried to install via `$ pip3 install -e .` but returned this error:; ```; Obtaining file://path/to/scanpy_1.4/scanpy; Complete output from command python setup.py egg_info:; /path/to/miniconda3/envs/bio/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""path/to/scanpy/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""path/to/scanpy/scanpy/__init__.py"", line 26, in <module>; check_versions(); File ""path/to/scanpy/scanpy/utils.py"", line 38, in check_versions; .format(__version__, anndata.__version__)); NameError: name '__version__' is not defined. ----------------------------------------; Command ""python setup.py egg_info"" failed with error code 1 in path/to/scanpy/; ```; The variable `__version__` in line 38 in utils.py is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482,2,['error'],['error']
Availability,Try continuing on black error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1536:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536,1,['error'],['error']
Availability,Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1927:69,error,erroring,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927,1,['error'],['erroring']
Availability,Tutorial error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1742:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742,1,['error'],['error']
Availability,"Two major, and two minor, updates to qc metric calculation:. ## Tests run much faster now. `test_qc_metrics.py` used to take ~30 seconds, now takes ~2. These tests have been kinda slow for a while. This was mostly due to numba compilation. I was using `numba.njit(parallel=True)`, which cannot be cached so compilation occurred every time the tests ran. However, I expect most use cases only calculate QC metrics once in a session, and only for large datasets (at least 300,000 cells) is parallelization + compilation faster than performing the calculation in a single thread. Now a cached single threaded version is used unless the dataset is large. ## Can now calculate observation and variable metrics separately. Split the calculation of qc metrics into two functions for obs and var. These separate calls are now available as: `describe_obs` and `describe_var` after `pd.DataFrame.describe`. This is mostly to go along with my split-apply-combine experiments. In particular a use case like:. ```python; (adata; .groupby(obs=""leiden""); .apply(sc.pp.describe_var); .combine(...); ); ```. Where metrics like number of fraction of cells, mean expression, etc. are calculated within each group (useful for things like #562). ## Minor updates. * User can now choose to use expression from `layers` or `raw` instead of `adata.X`; * Doc updates 🤞 (am I polluting `sc.pp._docs.py` too much?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615:818,avail,available,818,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615,1,['avail'],['available']
Availability,UMAP: no available 'use_rep' parameter for tool.umap(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/689:9,avail,available,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689,1,['avail'],['available']
Availability,"Update to `downsample_counts` to allow downsampling total counts, similar to normalization by `cellranger aggr` (I'm pretty sure on this, there's a lot going on in their code). Additionally, enabled caching for the `numba`'d function, which cuts down on test time. As adding this feature meant renaming `target_counts` to `counts_per_cell`, this becomes a breaking change. Since it's breaking, I've also gone ahead and set `replace=False` by default as mentioned before (#340). Definitely willing to make changes. I've implemented this since I'm doing some integration work and figured it'd be nice to be able to try the basic `cellranger` strategy. Edit: The failing PAGA test occurs locally on master as well, but I don't think I broke that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/474:39,down,downsampling,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474,2,['down'],"['down', 'downsampling']"
Availability,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946:53,error,error,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946,2,"['error', 'fault']","['error', 'fault']"
Availability,Updating scanpy discourse links to point at scverse. Ping @adamgayoso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2177:53,Ping,Ping,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177,1,['Ping'],['Ping']
Availability,Upload scrublet scores on test failure,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3069:31,failure,failure,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069,1,['failure'],['failure']
Availability,Use tqdm instead of tqdm.auto when downloading datasets,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:35,down,downloading,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['downloading']
Availability,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:46,Avail,Available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,1,['Avail'],['Available']
Availability,"We had created this PR before https://github.com/scverse/scanpy/pull/3099. This one is the same PR with editing enabled for maintainers.; Hi,; We are submitting PR for speed up of the _get_mean_var function.; | | Time(sec) |; | -- | -- |; | Original | 18.49 |; | Updated | 3.97 |; | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge; ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; USE_FIRST_N_CELLS = 1300000; adata = adata[0:USE_FIRST_N_CELLS]; adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3280:680,Down,Downloading,680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3280,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"We have a weird temporary global variable called `sc.pl._utils._tmp_cluster_pos`. We use it for storing the positions of cluster centroids (actually the centroids of any categorical variable for any sort of embedding). The weird part is that it's set in scatterplot functions (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L468 and https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L809) and used only by `sc.pl.paga_compare` (https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L119). First, it's not obvious where paga_compare finds centroids (it was a mystery to me until recently). Second, the current design is error-prone (see a corner case https://github.com/theislab/scanpy/issues/686). Therefore, there should be a better place to store cluster centroids :). I'm not following the discussion about the future of AnnData, but maybe having something like `adata.uns['obs_category_leiden']` and storing colors and centroids in it e.g. `adata.uns['obs_category_leiden']['colors']` and `adata.uns['obs_category_leiden']['centroids']['X_umap']` would be more structured.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/938:711,error,error-prone,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/938,1,['error'],['error-prone']
Availability,"We have created this PR earlier https://github.com/scverse/scanpy/pull/3061. This one is the same PR with editing enabled for maintainers.; This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge.; ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; USE_FIRST_N_CELLS = 1300000; adata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3279:723,Down,Downloading,723,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279,2,"['Down', 'down']","['Downloading', 'download']"
Availability,We should make the `random_state` of `make_blobs` available through our `blobs` function. This would make it easier to generate random data for testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1429:50,avail,available,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429,1,['avail'],['available']
Availability,"We typically have some marker information in the form of an Excel sheet, pandas DataFrame, and eventually a Python dictionary. Using these as gene annotations in various plotting functions (not pl.rank_genes_groups_* family but the others) is a very common task and it looks awesome thanks to @fidelram's `var_group_*` parameters. It would be even more fantastic to be able to pass simple dict (e.g. the ones we already use in [Malte's marker_gene_overlap](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.marker_gene_overlap.html#scanpy.tl.marker_gene_overlap)) to plotting functions where `var_group_positions` and `var_group_labels` are populated automatically. . One caveat is that there might be genes covered by multiple keys, but this is similar to supplying overlapping `var_group_position`s in current api, which can exit with an error. I already have a function for that but it's absolutely super ugly. I can send a PR after tidying it up, but if anyone else wants to do it, it's perfectly fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/646:844,error,error,844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646,1,['error'],['error']
Availability,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2063:760,error,error,760,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063,1,['error'],['error']
Availability,What is the best way to recover raw count to adata.X,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1817:24,recover,recover,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817,1,['recover'],['recover']
Availability,"When I call `sc.pp.normalize_total(adata)` on a system that does not have Dask installed, I get the following error:. ```; AnnData object with n_obs × n_vars = 710 × 33538; obs: 'filter_with_counts', 'scrublet_doublet_score', 'filter_with_scrublet'; var: 'gene_ids', 'feature_types', 'genome', 'filter_with_counts'. File ""/viash_automount/home/rcannood/workspace/viash_temp//viash-run-normalize_total-ppLnd4"", line 32, in <module>; sc.pp.normalize_total(; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 200, in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 25, in _normalize_data; if isinstance(counts, DaskArray):; TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. The error was introduced in [9cb915](https://github.com/scverse/scanpy/commit/9cb915bee5bfe11f62ffb37c0405656aae4574f2#diff-34d549afa2b23d0b2066964a51f698d918398edffd38379a73d02390e31ae5e8R24). . This PR solves the issue by checking that DaskArray is not None, though I'm sure alternative solutions are also possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2209:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209,2,['error'],['error']
Availability,"When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb; 91 groups_order = [str(n) for n in groups_order]; 92 if reference != 'rest' and reference not in set(groups_order):; ---> 93 groups_order += [reference]; 94 if (reference != 'rest'; 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list; ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/346:116,error,error,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346,2,['error'],['error']
Availability,"When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183,1,['error'],['error']
Availability,"When I run:; ```; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; #batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. It finished in about 10 seconds. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.10.0.dev57+g08be4e9; -----; PIL 9.4.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; adjustText 0.8; anyio NA; arrow 1.2.3; arviz 0.15.0; asciitree NA; asttokens NA; astunparse 1.6.3; attr 22.2.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bokeh 2.4.3; brotli NA; captum 0.6.0; cellrank 1.5.1; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 2.1.1; chex 0.1.6; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.3.0; dask_image 2022.09.0; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; decoupler 1.4.0; defusedxml 0.7.1; dill 0.3.6; docrep 0.3.2; dot_parser NA; entrypoints 0.4; executing 1.2.0; fasteners 0.17.3; fastjsonschema NA; flatbuffers 23.1.21; flax 0.5.0; fqdn NA; fsspec 2023.1.0; gast NA; google NA; gseapy 1.0.4; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; imagecodecs 2023.1.23; imageio 2.26.0; invgauss_ufunc NA; ipykernel 6.21.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; isoduration NA; jax 0.4.10; jaxlib 0.4.10; jedi 0.18.2; jinja2 3.0.3; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.3.0; jupyterlab_server 2.19.0; keras 2.11.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.3; lightning_utilities 0.7.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.7.1; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; ml_collections NA; ml_dtypes 0.1.0; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.1; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2493:190,avail,available,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493,1,['avail'],['available']
Availability,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/855:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855,1,['error'],['error']
Availability,"When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,1,['error'],['error']
Availability,"When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:; TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2370:216,error,error,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370,1,['error'],['error']
Availability,"When exporting a SPRING project I get the following error (NameError: name 'NeighborsView' is not defined ). 16 days ago a bug issue was closed related to this ( #1260 ), however I still encounter the bug when using both Scanpy 1.5.1 or 1.5.0; . **Input**:; ```import time; t0 = time.time(); sc.external.exporting.spring_project(adata, './SPRING',; 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; custom_color_tracks=['total_counts']); print(time.time() - t0); ```. **Output**: ; ```Writing subplot to SPRING\all; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-59-9c683583ff59> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sc.external.exporting.spring_project(adata, './SPRING',; 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### AnnData: ; ```AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1285:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285,1,['error'],['error']
Availability,"When giving a plotting function the `gene_symbols` argument to specify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277:856,error,error,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029,1,['error'],['error']
Availability,"When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python; adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))); sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):; File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>; sc.preprocessing._qc.describe_obs(adata); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions; raise IndexError(""Positions outside range of features.""); IndexError: Positions outside range of features.; ```; (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:; - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section?; - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2346:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346,1,['error'],['error']
Availability,"When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: ; ```; ValueError: Data must be 1-dimensional; ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1888:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888,1,['error'],['error']
Availability,"When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:; https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```; np.array(['LOOONG','SHORT'],dtype='U5'); > array(['LOOON', 'SHORT'], dtype='<U5'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753:120,down,down,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753,1,['down'],['down']
Availability,"While I run 'sc.tl.louvain', this error raised and told me I should call 'jgraph'.; Is it necessary for me to change the package name of 'igraph'to 'jgraph' manually?. ```pytb; ---------------------------------------------------------------------------; DeprecationWarning Traceback (most recent call last); <ipython-input-191-71b705e00011> in <module>; ----> 1 sc.tl.louvain(ad_2). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 112 directed = False; 113 if not directed: logg.debug(' using the undirected graph'); --> 114 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 115 if use_weights:; 116 weights = np.array(g.es[""weight""]).astype(np.float64). /usr/local/lib/python3.6/dist-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 379 def get_igraph_from_adjacency(adjacency, directed=None):; 380 """"""Get igraph graph from adjacency matrix.""""""; --> 381 import igraph as ig; 382 sources, targets = adjacency.nonzero(); 383 weights = adjacency[sources, targets]. /usr/local/lib/python3.6/dist-packages/igraph/__init__.py in <module>; 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807,1,['error'],['error']
Availability,"While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575; But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663:493,avail,available,493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663,1,['avail'],['available']
Availability,"While testing my changes to dataset code, I saw that `sc.datasets.burczynski06()` raised the error:. ```python; ValueError: `X` needs to be of one of ndarray, MaskedArray, spmatrix, ZarrArray, ZappyArray, not <class 'dict'>.; ```. But it had a pretty easy fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/574:93,error,error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/574,2,"['Mask', 'error']","['MaskedArray', 'error']"
Availability,"While trying to cluster using phenograph I get the error below. Could you help me understand why this happens?; ```; >>adata1; AnnData object with n_obs × n_vars = 77969 × 18417; obs: 'Id', 'Donor', 'Sample', 'Method', 'Position', 'UMI.Count', 'Expressed.Genes', 'Percent.Mitochond.', 'Percent.Ribo', 'CellType', 'Sex', 'Age'; var: 'name'; uns: 'pca'; obsm: 'X_pca'; varm: 'PCs'. >>import scanpy.external as sce; >>result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). PhenoGraph clustering; Finding 100 nearest neighbors using minkowski metric and 'auto' algorithm; Neighbors computed in 67.26673102378845 seconds; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-22-2cf1719c59ce> in <module>; 1 import scanpy.external as sce; ----> 2 result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). /usr/local/lib/python3.8/site-packages/scanpy/external/tl/_phenograph.py in phenograph(data, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method); 143 ); 144 ; --> 145 communities, graph, Q = phenograph.cluster(; 146 data=data,; 147 k=k,. /usr/local/lib/python3.8/site-packages/phenograph/cluster.py in cluster(data, clustering_algo, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method, partition_type, resolution_parameter, n_iterations, use_weights, seed, **kargs); 243 ""Leiden completed in {} seconds"".format(time.time() - tic_), flush=True,; 244 ); --> 245 communities = np.asarray(communities.membership); 246 ; 247 print(""Sorting communities by size, please wait ..."", flush=True). /usr/local/lib/python3.8/site-packages/phenograph/core.py in neighbor_graph(kernel, kernelargs); 82 :return graph: n-by-n COO sparse matrix; 83 """"""; ---> 84 i, j, s = kernel(**kernelargs); 85 n, k = kernelargs[""idx""].shape; 86 graph = sp.coo_matrix((s, (i, j)), shape=(n, n)). /usr/local/lib/python3.8/site-packages/phenogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407,1,['error'],['error']
Availability,Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python; sc.tl.umap(adata, maxiter=50); ```. ### Error output. ```pytb; computing UMAP; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies ; [0.01180801 0.01616286 0.01491355]; not reaching the requested tolerance 1e-08.; Use iteration 19 instead with accuracy ; 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies ; [0.0114102 0.01466 0.01555016]; not reaching the requested tolerance 1e-08.; eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (1:07:21); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3139:1061,toler,tolerance,1061,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139,1,['toler'],['tolerance']
Availability,"[ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2188:1111,down,downgrade,1111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188,1,['down'],['downgrade']
Availability,"[ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1412:1081,error,error,1081,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412,1,['error'],['error']
Availability,[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4021,ERROR,ERROR,4021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:4860,error,error,4860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,4,"['ERROR', 'down', 'error']","['ERROR', 'downloads', 'error', 'errored']"
Availability,"\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 370 res = None; 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:; 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:9304,avail,available,9304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['avail'],['available']
Availability,"_3', 'ClusterMarkers_0_sub_30', 'ClusterMarkers_0_sub_31', 'ClusterMarkers_0_sub_32', 'ClusterMarkers_0_sub_33', 'ClusterMarkers_0_sub_34', 'ClusterMarkers_0_sub_35', 'ClusterMarkers_0_sub_36', 'ClusterMarkers_0_sub_37', 'ClusterMarkers_0_sub_38', 'ClusterMarkers_0_sub_39', 'ClusterMarkers_0_sub_4', 'ClusterMarkers_0_sub_40', 'ClusterMarkers_0_sub_41', 'ClusterMarkers_0_sub_42', 'ClusterMarkers_0_sub_43', 'ClusterMarkers_0_sub_44', 'ClusterMarkers_0_sub_45', 'ClusterMarkers_0_sub_46', 'ClusterMarkers_0_sub_47', 'ClusterMarkers_0_sub_48', 'ClusterMarkers_0_sub_49', 'ClusterMarkers_0_sub_5', 'ClusterMarkers_0_sub_50', 'ClusterMarkers_0_sub_51', 'ClusterMarkers_0_sub_52', 'ClusterMarkers_0_sub_53', 'ClusterMarkers_0_sub_54', 'ClusterMarkers_0_sub_55', 'ClusterMarkers_0_sub_56', 'ClusterMarkers_0_sub_57', 'ClusterMarkers_0_sub_58', 'ClusterMarkers_0_sub_59', 'ClusterMarkers_0_sub_6', 'ClusterMarkers_0_sub_60', 'ClusterMarkers_0_sub_61', 'ClusterMarkers_0_sub_62', 'ClusterMarkers_0_sub_63', 'ClusterMarkers_0_sub_64', 'ClusterMarkers_0_sub_65', 'ClusterMarkers_0_sub_66', 'ClusterMarkers_0_sub_67', 'ClusterMarkers_0_sub_68', 'ClusterMarkers_0_sub_69', 'ClusterMarkers_0_sub_7', 'ClusterMarkers_0_sub_70', 'ClusterMarkers_0_sub_71', 'ClusterMarkers_0_sub_72', 'ClusterMarkers_0_sub_8', 'ClusterMarkers_0_sub_9', 'ClusterMarkers_1', 'ClusterMarkers_2', 'ClusterMarkers_3', 'ClusterMarkers_4', 'ClusterMarkers_5', 'ClusterMarkers_6', 'ClusterMarkers_7', 'Regulons'; obsm: 'ClusterID'. This is from publicaly available data. so what i would like to do is plot their published tsne or umap and compare a few things from it. If I simply run sc.pl.tsne(loom_file, color=['louvain']) I get error msg: ValueError: no field of name X_tsne. This makes sense as there is not X_tsne on the object. How could I get pass this without re-clustering myself? At the moment I am only interested in pulling out 2 of their annotated clusters... if there is an easy way to do this via scanpy please let me know.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/933:2502,avail,available,2502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/933,2,"['avail', 'error']","['available', 'error']"
Availability,"_Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`!; > ; > The following code should reproduce the error:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. -------------------------------. On current release this errors:. <details>; <summary> </summary>. ```python; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-1-4c43dbe94eaf> in <module>; 4 ; 5 pbmc = sc.datasets.pbmc68k_reduced(); ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,2,['error'],"['error', 'errors']"
Availability,"_counts_mt""). sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=3). sc.pp.scrublet(adata, batch_key=""sample""). # Saving count data; adata.layers[""counts""] = adata.X.copy(). # Normalizing to median total counts; sc.pp.normalize_total(adata); # Logarithmize the data; sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key=""sample""); sc.pl.highly_variable_genes(adata). sc.tl.pca(adata). sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True). sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ). sc.pl.pca(; adata,; color=[""sample"", ""sample"", ""pct_counts_mt"", ""pct_counts_mt""],; dimensions=[(0, 1), (2, 3), (0, 1), (2, 3)],; ncols=2,; size=2,; ). sc.pp.neighbors(adata). sc.pl.umap(; adata,; color=""sample"",; # Setting a smaller point size to get prevent overlap; size=2,; ). ### runs forever:; sc.tl.leiden(adata, flavor=""igraph"", n_iterations=2); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'Val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228:2895,Error,Error,2895,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228,1,['Error'],['Error']
Availability,_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2898,ERROR,ERROR,2898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._he,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7478,ERROR,ERROR,7478,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24256,ERROR,ERROR,24256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - I,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8310,ERROR,ERROR,8310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs); --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs); 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:3042,error,error,3042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"_pass, internal_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53); ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160:7470,error,errors,7470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160,2,['error'],['errors']
Availability,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:3969,avail,available,3969,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,1,['avail'],['available']
Availability,_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13846,ERROR,ERROR,13846,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14681,ERROR,ERROR,14681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4862,ERROR,ERROR,4862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:3218,error,error,3218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,2,['error'],['error']
Availability,"_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1260:1289,Error,Error,1289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260,1,['Error'],['Error']
Availability,"_rank_genes_groups.py, gene names are trimmed down to 50 characters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753:46,down,down,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753,1,['down'],['down']
Availability,_scrublet_plots[scrublet] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_no_threshold] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_with_batches] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../..,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:3890,ERROR,ERROR,3890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"`_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>; <summary> possible solution </summary>. ```python; from numba import njit, prange; import numpy as np. @njit(parallel=True); def nanmean_lowlevel(data, indices, indptr, shape):; N, M = shape; sums = np.zeros(N, dtype=np.float64); nans = np.zeros(N, dtype=np.int64); for i in prange(N):; start = indptr[i]; stop = indptr[i+1]; window = data[start:stop]; n_nan = np.int64(0); i_sum = np.float64(0.); for j_val in window:; if np.isnan(j_val):; n_nan += 1; else:; i_sum += j_val; sums[i] = i_sum; nans[i] = n_nan; sums /= (M - nans); return sums; ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1894:757,error,error,757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894,1,['error'],['error']
Availability,"```; Python 3.9.15 (main, Nov 24 2022, 14:31:59) ; [GCC 11.2.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. - [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2445:1479,error,error,1479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445,1,['error'],['error']
Availability,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273:84,down,download,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273,2,"['avail', 'down']","['available', 'download']"
Availability,"```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean""); ```. ```; AnnData object with n_obs × n_vars = 11 × 765; obs: 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; layers: 'mean'; ```. ```python; sc.get.aggregate(adata.obsm[""X_umap""], by=adata.obs[""louvain""].array, func=""mean""); ```. ```; {'mean': array([[ -6.18019123, -6.12846152],; [ -3.10995685, 8.4991954 ],; [ 6.30307056, -2.15245383],; [ -4.72268065, -3.24033642],; [-11.94002487, -5.39480163],; [ -1.39242794, 6.6239316 ],; [ 4.3991326 , -0.16749119],; [ 4.847834 , -9.30549509],; [-10.41891144, -1.15700949],; [ -7.91249486, -4.06782072],; [ 1.12418592, -6.94506866]])}; ```. So it returns an `AnnData` when an `AnnData` is passed, but a dict when a less structured object is passed. This is probably because it's `singledispatched` under the hood, but IDK that this behaviour is great. I think it could make more sense for this to either:. * Always return an `AnnData`; * Throw an error if something other than an AnnData is passed in. A third option is that we document this behaviour, but I generally don't love it. There are other places that we do something like this, i.e. return a different type depending on the input. However, I feel like there's more of a loss of information here and less of an obvious return type. Maybe in future this could get a `return_type: type[AnnData] | type[Dict] | type[xr.Dataset] = AnnData` argument that controls what is returned?. WDYT @ilan-gold @Intron7?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2930:1054,error,error,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2930,1,['error'],['error']
Availability,"```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); pbmc.write(""tmp.h5ad'); ```. ```pytb; NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>; <summary> Full traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 187 try:; --> 188 return func(elem, key, val, *args, **kwargs); 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs); 144 raise NotImplementedError(; --> 145 f""Failed to write value for {key}, ""; 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:365,error,error,365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,1,['error'],['error']
Availability,"``python; print(sc.__version__); # 1.10.3. # Randomly select 1000 cell indices; selected_cells = np.random.choice(adata.obs.index, size=1000, replace=False); # Create a subset AnnData object; subset_adata = adata[selected_cells].copy(); subset_adata.write(save_fold + ""subset_adata.h5ad""). #subset_known_markers = dict(list(filtered_known_markers.items())[:2]); tmp = ['Isl1', 'Tcf21', 'Tlx1'] ; [gene for gene in tmp if gene in subset_adata.var_names] == tmp # True; tmp = ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2'] ; [gene for gene in tmp if gene in subset_adata.var_names] == tmp # True; subset_known_markers = {; 'Anterior cardiopharyngeal progenitors_Imaz2024': ['Isl1', 'Tcf21', 'Tlx1'], ; 'Cardiomyocytes FHF 1_Imaz2024': ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2']; }; ; tmp = sc.tl.score_genes(subset_adata, gene_list= subset_known_markers, copy=True ; #,use_raw=True ; #,n_bins = 150 , ctrl_size =100; ) # ctrl_size = 50 by default ; n_bins = 25 by default; ```. ### Error output. ```pytb; WARNING: genes are not in var_names and ignored: ['Anterior cardiopharyngeal progenitors_Imaz2024', 'Cardiomyocytes FHF 1_Imaz2024']; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/project/xyang2/anaconda/py38/lib/python3.8/site-packages/scanpy/tools/_score_genes.py"", line 115, in score_genes; raise ValueError(""No valid genes were passed for scoring.""); ValueError: No valid genes were passed for scoring.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.4.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2023.5.0; dateutil 2.9.0.post0; h5py 3.11.0; igraph 0.11.6; importlib_resources NA; jinja2 3.1.4; joblib 1.4.2; kiwisolver 1.4.7; leidenalg 0.10.2; llvmlite 0.41.1; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.7.5; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.6; numpy 1.24.4; packaging 24.1; pandas 2.0.3; psutil 6.0.0; pyarrow 17.0.0; pyparsing 3.1.4; pytz 2024.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3266:1581,Error,Error,1581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3266,1,['Error'],['Error']
Availability,"`anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/167:164,error,error,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167,1,['error'],['error']
Availability,`clustermap` with sparse matrix throwing value error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['error'],['error']
Availability,"`compute_neighbors` method of the Neighbors class has a nice option called `write_knn_indices` which saves kNN indices into the Neighbors object. But this object and its members are not accessible from sc.pp.neighbors since we don't save the reference to it. . Making the write_knn_indices option available from `sc.pp.neighbors` gives access to knn indices which provide additional information on top of connectivities and distances since these matrices are symmetrized. . With knn_indices one can do cool things like building a mutual kNN graph, e.g.:. ```python; import scipy.sparse as sp. lm = sp.lil_matrix((adata.n_obs, adata.n_obs)); lm.rows = adata.uns['neighbors']['knn_indices']; lm.data = np.ones_like(adata.uns['neighbors']['knn_indices']); lm = lm.tocsr(); lm.setdiag(0); lm.eliminate_zeros(); lm = lm.multiply(lm.T) # build mnn mask. adata.uns['neighbors']['distances'] = adata.uns['neighbors']['distances'].multiply(lm); adata.uns['neighbors']['connectivities'] = adata.uns['neighbors']['connectivities'].multiply(lm); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/820:297,avail,available,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820,2,"['avail', 'mask']","['available', 'mask']"
Availability,"`louvain` and `leiden` have a lot of redundant documentation. After having learned in #557, I could file a PR to deduplicate this. Would it be valid to shuffle the arguments in such a way that the shared documentation is grouped together? Otherwise, one would have to introduce many short strings and puzzle them together.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/570:37,redundant,redundant,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570,1,['redundant'],['redundant']
Availability,"`pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0 py39hca03da5_0 ; appnope 0.1.2 py39hca03da5_1001 ; argon2-cffi 21.3.0 pyhd3eb1b0_0 ; argon2-cffi-bindings 21.2.0 py39h1a28f6b_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5167,error,error,5167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['error'],['error']
Availability,`plot_scatter` throws error when sparse layers used for color,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/700:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700,1,['error'],['error']
Availability,`sc.datasets.paul15_raw()` fails with `attempted relative import beyond top-level package` error due to the wrong module path in `sc.utils.check_presence_download `. . Simply run `sc.datasets.paul15_raw()` or `sc.datasets.paul15()` to reproduce.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/67:91,error,error,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/67,1,['error'],['error']
Availability,`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2377:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377,1,['error'],['error']
Availability,"`sc.pl.clustermap` fails with an error:. ```python; import scanpy as sc; adata = sc.datasets.krumsiek11(); sc.pl.clustermap(adata, obs_keys='cell_type'); ```. Output:. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-2-15436b6f0954> in <module>; 3 ; 4 adata = sc.datasets.krumsiek11(); ----> 5 sc.pl.clustermap(adata, obs_keys='cell_type'). ~/Code/scanpy/scanpy/plotting/_anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 777 adata.uns[obs_keys + '_colors'])); 778 row_colors = adata.obs[obs_keys].map(lut); --> 779 g = sns.clustermap(df, row_colors=row_colors, **kwds); 780 else:; 781 g = sns.clustermap(df, **kwds). ~/Code/seaborn/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,4,"['error', 'mask']","['error', 'mask']"
Availability,`sc.pl.paga` was throwing and error when the color list in `.uns` was not previously set. While fixing the error I realized that some functionality was duplicated between legacy scatter plots and the embedding plots and removed the code duplication.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/869:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869,2,['error'],['error']
Availability,"`sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True)`. always get the error. ```; TypeError Traceback (most recent call last); <ipython-input-40-5bc1cab6ebf2> in <module>; ----> 1 sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True). ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_stacked_violin.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 717 return vp; 718 else:; --> 719 vp.make_figure(); 720 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 721 show = settings.autoshow if show is None else show. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in make_figure(self); 738 if self.legends_width > 0:; 739 legend_ax = self.fig.add_subplot(gs[0, 1]); --> 740 self._plot_legend(legend_ax, return_ax_dict, normalize); 741 ; 742 self.ax_dict = return_ax_dict. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 535 color_legend_ax = fig.add_subplot(legend_gs[1]); 536 ; --> 537 self._plot_colorbar(color_legend_ax, normalize); 538 return_ax_dict['color_legend_ax'] = color_legend_ax; 539 . ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_colorbar(self, color_legend_ax, normalize); 508 import matplotlib.colorbar; 509 ; --> 510 matplotlib.colorbar.Colorbar(; 511 color_legend_ax, orientation='horizontal', cmap=cmap, norm=normalize; 512 ). TypeError: __init__() missing 1 required positional argument: 'mappable'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118,1,['error'],['error']
Availability,"`scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362,1,['error'],['error']
Availability,"`twine check` is not great at telling you why it's failing. It would be easier to figure out what caused the break if we were continuously checking for this. Inspired by finding out that `authors` can't have new lines, via an error that says `long_description` can't have section headings (which definitely isn't true).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1585:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585,1,['error'],['error']
Availability,"a can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 try:; ---> 66 from skmisc.loess import loess; 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); Cell In[14], line 1; ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'); 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:1629,error,error,1629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"a.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 480 elif subarr.ndim > 1:; 481 if isinstance(data, np.ndarray):; --> 482 raise Exception(""Data must be 1-dimensional""); 483 else:; 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199:2440,Error,Error,2440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199,1,['Error'],['Error']
Availability,"a/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:5806,avail,available,5806,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['avail'],['available']
Availability,"a/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4609,down,downgraded,4609,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['down'],['downgraded']
Availability,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167:1804,error,error,1804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167,8,['error'],['error']
Availability,"a3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 233 palette=palette,; 234 use_raw=use_raw,; --> 235 gene_symbols=gene_symbols,; 236 ); 237 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1035 ] # TODO: Throw helpful error if this doesn't work; 1036 if use_raw and value_to_plot not in adata.obs.columns:; -> 1037 values = adata.raw.obs_vector(value_to_plot); 1038 else:; 1039 values = adata.obs_vector(value_to_plot, layer=layer). /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:2313,error,error,2313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['error'],['error']
Availability,"acked, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 542 return key, value; 543 ; --> 544 key, value = postprocess_reading(key, value); 545 d[key_write] = value; 546 return. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in postprocess_reading(key, value); 539 new_dtype = [((dt[0], 'U{}'.format(int(int(dt[1][2:])/4))); 540 if dt[1][1] == 'S' else dt) for dt in value.dtype.descr]; --> 541 value = value.astype(new_dtype); 542 return key, value; 543 . ValueError: invalid shape in fixed-type tuple.; ```. Any idea what is going on or what I can do to make it past this error? It only started happening after I updated my operating system to Ubuntu 18 and my Python to 3.7 and reinstalled scanpy from conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832:3652,error,error,3652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832,1,['error'],['error']
Availability,"aconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate; raise ArpackError(self.info, infodict=self.iterate_infodict); scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > ; <!-- Relevant screenshots -->. Thanks; Patrick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2473:2300,error,error,2300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473,1,['error'],['error']
Availability,"actual bug or me using the package wrong. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; from anndata import AnnData. p_value_threshold = 0.05; # Create a minimalistic AnnData object; data = np.random.rand(1000, 5) # 1000 cells, 5 genes; obs = pd.DataFrame(index=[f'cell{i}' for i in range(1000)]); var = pd.DataFrame(index=[f'gene{i}' for i in range(5)]); adata = AnnData(X=data, obs=obs, var=var). # Add a 'gene' column to obs to use as groupby; adata.obs['gene'] = np.random.choice(['sample0', 'sample1', 'sample2', 'sample3', 'sample4'], size=1000). # Define groups; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:1911,mask,mask,1911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,4,['mask'],['mask']
Availability,"adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:3862,toler,tolerance,3862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,1,['toler'],['tolerance']
Availability,add a mask argument,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234:6,mask,mask,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234,1,['mask'],['mask']
Availability,add robust installation instructions again,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1140:4,robust,robust,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140,1,['robust'],['robust']
Availability,added a downsample function to downsample the counts,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/99:8,down,downsample,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/99,2,['down'],['downsample']
Availability,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738,1,['error'],['error']
Availability,aggregate throws error when aggregating `obsm` or `varm`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,1,['error'],['error']
Availability,alize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13425,ERROR,ERROR,13425,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,alize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13217,ERROR,ERROR,13217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11539,ERROR,ERROR,11539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11964,ERROR,ERROR,11964,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6402,ERROR,ERROR,6402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11324,ERROR,ERROR,11324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11749,ERROR,ERROR,11749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15323,ERROR,ERROR,15323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18473,ERROR,ERROR,18473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,and fixed an error with plotting functions that I think I caused when I merged with master. I will set this PR as work in progress as I will be adding more tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207,1,['error'],['error']
Availability,anhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20548,ERROR,ERROR,20548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:1261,error,error,1261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,1,['error'],['error']
Availability,anpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10997,mask,mask-,10997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:1932,error,error,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,2,['error'],['error']
Availability,"are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:1034,Error,Error,1034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['Error'],['Error']
Availability,"args; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in fillna(self, value, method, limit); 1871 elif is_hashable(value):; 1872 if not isna(value) and value not in self.categories:; -> 1873 raise ValueError(""fill value must be in categories""); 1874 ; 1875 mask = codes == -1. ValueError: fill value must be in categories; ```. That's because `colors = colors.fillna('white')` line in the seaborn code is trying to add a new category to a categorical variable, which is not allowed in pandas. I simply converted the color categorical variable to numpy array and added tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:3652,mask,mask,3652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['mask'],['mask']
Availability,arson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkn,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22829,ERROR,ERROR,22829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3456 if self.columns.nlevels > 1:; 3457 return self._getitem_multilevel(key); -> 3458 indexer = self.columns.get_loc(key); 3459 if is_integer(indexer):; 3460 indexer = [indexer]. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 ; 3365 if is_scalar(key) and isna(key) and not self.hasnans:. KeyError: 1; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053:2455,toler,tolerance,2455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053,1,['toler'],['tolerance']
Availability,"as the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:6293,error,errors,6293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['error'],['errors']
Availability,"as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). ~\AppData\Local\Continuum\anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/924:2271,Mask,MaskedArray,2271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924,1,['Mask'],['MaskedArray']
Availability,"ase be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the clipping part of scaling function. ; | | Time(sec)|; | -----------| ----- |; | Original | 11.82 |; | Updated | 1.59 |; | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100:1047,Down,Downloading,1047,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100,1,['Down'],['Downloading']
Availability,"at this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I tried to run the code below on a Windows laptop and received the error (also below). I've tried uninstalling and reinstalling igraph, leidenalg, and scanpy. I tried running the code with flavor=""leidenalg"" and got the same/basically the same error. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"", ; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[159], line 1; ----> 1 sc.tl.leiden( #So leidan is identifying and coloring clusters for you, but not changing the shape of the graph.; 2 adata, #lets just pretend that I understand what each of those things mean; 3 resolution=0.9,; 4 random_state=0,; 5 flavor=""igraph"", #did pip install leidenalg and started receiving the no flavor keyword error; https://github.com/scverse/scanpy/issues/350 indicates this is to be expected, but https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.leiden.html indicates it should have it ; 6 n_iterations=2,; 7 directed=False,; 8 ). File ~\miniconda3\Lib\site-packages\scanpy\tools\_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 msg = 'In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph\'s implementation.'; 143 _utils.warn_once(msg, FutureWarning, stacklevel=3); --> 144 except ImportError:; 145 raise ImportError(; 146 ""Please install the leiden algorithm: `conda install -c conda-forge leidenalg` or `pip3 install leidenalg`.""; 147 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981:1116,error,error,1116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981,1,['error'],['error']
Availability,"atched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:6557,error,error,6557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['error'],['error']
Availability,"ategories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 ); 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'; ```. First, what's up with the printed error?. Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>; <summary> </summary>. ```python; -----; anndata 0.7.7.dev4+g49739eb; scanpy 1.9.0.dev7+g092376d2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:2142,error,error,2142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,1,['error'],['error']
Availability,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:4918,error,errors,4918,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,3,['error'],"['error', 'errors']"
Availability,b/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ############################################################################# | 100% ; libev-4.33 | 104 KB | ############################################################################# | 100% ; libnghttp2-1.46.0 | 680 KB | ############################################################################# | 100% ; libcurl-7.82.0 | 342 KB | ############################################################################# | 100% ; libssh2-1.10.0 | 233 KB | ###########################################################,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265:2132,Down,Downloading,2132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265,1,['Down'],['Downloading']
Availability,"b/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:1086,error,errors,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['error'],['errors']
Availability,bbknn error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632,1,['error'],['error']
Availability,"bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:2426,Error,Error,2426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,"bors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). ```; This outputs the following. ```; 0; 134513; 37696; 0 659; 1 605; 2 398; 3 352; 4 342; 5 174; 6 118; 7 41; 8 11; Name: leiden, dtype: int64; 0 527; 1 484; 2 398; 3 324; 4 320; 5 301; 6 174; 7 109; 8 52; 9 11; Name: leiden, dtype: int64. 0; 134127; 37278; 0 646; 1 617; 2 382; 3 362; 4 334; 5 173; 6 129; 7 46; 8 11; Name: leiden, dtype: int64; 0 646; 1 631; 2 408; 3 349; 4 334; 5 170; 6 106; 7 45; 8 11; Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions(). -->; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187:4253,Error,Error,4253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187,1,['Error'],['Error']
Availability,"bs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258:2488,Error,Error,2488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258,1,['Error'],['Error']
Availability,ca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6619,ERROR,ERROR,6619,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15751,ERROR,ERROR,15751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15965,ERROR,ERROR,15965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,calculate_qc_metrics error in scanpy 1.4.5 and above,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"canpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1412:1089,Error,Error,1089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412,1,['Error'],['Error']
Availability,"canpy/preprocessing/utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other); 226; 227 def pow(self, other):; --> 228 return matrix_power(self, other); 229; 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603; 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216; 217 def _assertFinite(*arrays):; ```. </details>. Versions of my modules:; scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py; adata.X /= adata.obs['size_factors'].values[:,None]; ```. This step transform the adata.X to a structure of matrix.; Before the adata.X is. ```; <6242x15065 sparse matrix of type '<class 'numpy.float32'>'; with 19234986 stored elements in Compressed Sparse Row format>; ```. But after performing this step, the adata.X is; This is my adata.X looks like right now:. ```py; matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],; [0. , 0. , 1.203, ..., 0. , 0. , 0. ],; [0. , 1.096, 0. , ..., 0. , 0. , 0. ],; ...,; [0. , 0. , 2.042, ..., 0. , 0. , 0. ],; [0. , 0. , 0. , ..., 0.926, 0. , 0. ],; [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),; ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response!; Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:2206,down,downgraded,2206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,2,"['down', 'error']","['downgraded', 'error']"
Availability,"cast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in fillna(self, value, method, limit); 1871 elif is_hashable(value):; 1872 if not isna(value) and value not in self.categories:; -> 1873 raise ValueError(""fill value must be in categories""); 1874 ; 1875 mask = codes == -1. ValueError: fill value must be in categories; ```. That's because `colors = colors.fillna('white')` line in the seaborn code is trying to add a new category to a categorical variable, which is not allowed in pandas. I simply converted the color categorical variable to n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2911,down,downcast,2911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,2,['down'],['downcast']
Availability,cation); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - Impo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2034,ERROR,ERROR,2034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ce.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:4377,error,errors,4377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"cell cycle**; The lower part of the plot shows regress out applied to the cell cycle (following [the scanpy tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb) and the 'alternative approach' described in the [seurat vignette](https://satijalab.org/seurat/cell_cycle_vignette.html#assign-cell-cycle-scores), i.e. I regressed out the difference between the G2M and S phase scores):; ```; adata.obs[""cell_cycle_diff""] = adata.obs[""S_score""] - adata.obs[""G2M_score""]; sc.pp.regress_out(adata, ['cell_cycle_diff']); ```; Like that, the differences between dividing and non-dividing cells should be preserved. ; Again, in the *Savas* dataset, after regressing out the cell cycle effects, G1 is correctly separated from G2M/S. In *Lambrechts*, there is no clear separation. Having eyeballed at the UMAP-plot (below) it seems that the cell-cycle labels correlate with the cell type (i.e. cancer cells and myeloid cells got the G1 label assigned more likely than T cells). . **What is 'best practice'?**; I quickly discussed this offline with @flying-sheep, and he encouraged me to create this issue. . * Is it just a problem with visualizing the first PC's and `regress_out` should be applied regardless; * Should `regress_out` be skipped and only applied in a more downstream step when focusing on a single cell type? ; * Are there any other situations where `regress_out` could do more harm than good? . **PCA plots before and after `regress_out`**; ![regress_out](https://user-images.githubusercontent.com/7051479/54083302-f088f500-4321-11e9-877a-1cbef6f4f489.png). **UMAP-plots**; The cell cycle label correlates with the cell type (other dataset, but to show what I mean): ; ![2019-03-10_11:20:31_384x234](https://user-images.githubusercontent.com/7051479/54083671-29779880-4327-11e9-94d6-9be34383b909.png); ![2019-03-10_11:25:30_428x231](https://user-images.githubusercontent.com/7051479/54083675-3a280e80-4327-11e9-954f-34ef1404961b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526:2507,down,downstream,2507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526,1,['down'],['downstream']
Availability,cloudpickle 3.0.0; colorama 0.4.6; colorlog NA; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; dragonnfruit 0.3.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; filelock 3.13.1; fqdn NA; fsspec 2024.3.1; goatools 1.3.11; google NA; h5py 3.10.0; hdf5plugin 4.4.0; idna 3.6; igraph 0.11.4; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 0.9.24; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.13.0; jupyterlab_server 2.25.4; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.6.2; mpl_toolkits NA; msgpack 1.0.8; mudata 0.2.3; muon 0.1.5; mygene 3.2.2; natsort 8.4.0; nbformat 5.10.3; networkx 3.2.1; numba 0.59.1; numexpr 2.9.0; numpy 1.26.4; optree 0.10.0; optuna 3.6.0; overrides NA; packaging 24.0; pandas 1.5.3; pandas_flavor NA; parso 0.8.3; patsy 0.5.6; pingouin 0.5.4; pkg_resources NA; platformdirs 4.2.0; plotly 5.20.0; prometheus_client NA; prompt_toolkit 3.0.43; psutil 5.9.8; pure_eval 0.2.2; pyBigWig 0.3.22; pyarrow 15.0.2; pychromvar 0.0.4; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 2.0.0; pyfaidx 0.8.1.1; pygments 2.17.2; pyjaspar 3.0.0; pynndescent 0.5.11; pyparsing 3.1.2; pysam 0.22.0; pythonjsonlogger NA; pytz 2024.1; ray 2.10.0; referencing NA; requests 2.31.0; requests_cache 1.2.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; rpds NA; scipy 1.12.0; seaborn 0.13.2; send2trash NA; session_info 1.0.0; setproctitle 1.2.2; simplejson 3.19.2; sitecustomize NA; six 1.16.0; sklearn 1.4.1.post1; sniffio 1.3.1; stack_data 0.6.3; statsmodels 0.14.1; swig_runtime_data4 NA; tabulate 0.9.0; tensorboard 2.16.2; texttable 1.7.0; threadpoolctl 3.4.0; torch 2.2.1+cu121; torchgen NA; tornado 6.4; tqdm 4.66.2; traitlets 5.14.2; typing_extensions N,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3014:3009,ping,pingouin,3009,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014,1,['ping'],['pingouin']
Availability,"code:. ```py; sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['13'], reference= '18' ). Error:; ValueError: reference = 18 needs to be one of group_by = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]; ```. I think the problem is the code comfuse str(18) and int(18). could you solve it? Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/94:97,Error,Error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94,1,['Error'],['Error']
Availability,"column to obs to use as groupby; adata.obs['gene'] = np.random.choice(['sample0', 'sample1', 'sample2', 'sample3', 'sample4'], size=1000). # Define groups; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA; apport_python_hook NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; cairo 1.20.1; certifi 2024.07.04; cffi 1.16.0; chardet 4.0.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.4; comm 0.2.2; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.8.0; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; gi 3.42.1; gio NA; glib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:2386,mask,mask,2386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,4,['mask'],['mask']
Availability,combat processing errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170,1,['error'],['errors']
Availability,"copy&paste without having any data). ```python; import scanpy; acc = ""E-MTAB-4888""; ad_df = scanpy.datasets.ebi_expression_atlas(acc); ```. ```pytb; File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response); [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:1419,error,error,1419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,1,['error'],['error']
Availability,"coxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!. _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:2302,error,error,2302,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"cs.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:1096,avail,available,1096,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,2,"['avail', 'error']","['available', 'error']"
Availability,"cted keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608:1395,error,error,1395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608,1,['error'],['error']
Availability,"d/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: Can't convert 'list' object to str implicitly; ; ----------------------------------------; Failed building wheel for scanpy; Running setup.py clean for scanpy; Running setup.py bdist_wheel for anndata ... done; Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367; Running setup.py bdist_wheel for networkx ... done; Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91; Successfully built anndata networkx; Failed to build scanpy; Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy; Running setup.py install for scanpy ... error; Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:; /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'; warnings.warn(msg); running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; creating build/lib/scanpy/preprocessing; copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing; copying scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:3388,error,error,3388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,1,['error'],['error']
Availability,"d; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:2782,down,downloads,2782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,2,"['ERROR', 'down']","['ERROR', 'downloads']"
Availability,"da3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `adata.X` to sparse matrix format, I have the following error:; ```python; adata.X = sci.sparse.csr_matrix(adata.X); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-29-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953:2982,error,error,2982,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953,1,['error'],['error']
Availability,"dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4310,ERROR,ERROR,4310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"data.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self); 126 def compute_connectivities(self):; 127 if self._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values); 144 ns = vc.sizes(); 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key); 2925 if self.columns.nlevels > 1:; 2926 return self._getitem_multilevel(key); -> 2927 indexer = self.columns.get_loc(key); 2928 if is_integer(indexer):; 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2657 return self._engine.get_loc(key); 2658 except KeyError:; -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'; ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:; ```; {'commit_hash': 'd774f565b',; 'commit_source': 'installation',; 'default_encoding': 'cp1252',; 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',; 'ipython_version': '7.4.0',; 'os_name': 'nt',; 'platform': 'Windows-10-10.0.1836",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:2405,toler,tolerance,2405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,1,['toler'],['tolerance']
Availability,"dding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1713,Error,Error,1713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['Error'],['Error']
Availability,"de (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the clipping part of scaling function. ; | | Time(sec)|; | -----------| ----- |; | Original | 11.82 |; | Updated | 1.59 |; | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100:1082,down,download,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100,1,['down'],['download']
Availability,"de is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:9140,avail,available,9140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['avail'],['available']
Availability,dimension flattening error when slicing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332,1,['error'],['error']
Availability,"dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:8135,error,error,8135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['error']
Availability,"do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):; <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):; <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(); ```. ### Error output. ```pytb; (Error output is a bad plot, included in the description above.); ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; IPython 8.13.2; PIL 10.0.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.10.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; dot_parser NA; entrypoints 0.4; exceptiongroup 1.1.1; executing 1.2.0; fasteners 0.17.3; flytekitplugins NA; gmpy2 2.1.2; google NA; h5py 3.8.0; icu 2.11; igraph 0.11.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.8.3; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; natsort 8.3.1; numba 0.59.1; numcodecs 0.11.0; numexpr 2.7.3; numpy 1.26.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; plotly 5.14.1; prompt_toolkit 3.0.38; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062:1908,Error,Error,1908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062,1,['Error'],['Error']
Availability,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946:2813,Error,Error,2813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946,5,"['Error', 'error', 'fault']","['Error', 'error', 'fault']"
Availability,documentation error for pl.violin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1294:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1294,1,['error'],['error']
Availability,dont think to csv is actually coded; to xlsx raises error: pandas.core.common.PandasError: DataFrame constructor not properly called!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/6:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/6,1,['error'],['error']
Availability,dtype fixes for downsample and normalization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865:16,down,downsample,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865,1,['down'],['downsample']
Availability,duals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9629,ERROR,ERROR,9629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,duals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12172,ERROR,ERROR,12172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,duals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16172,ERROR,ERROR,16172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"dx.query(test, k, epsilon); 472 ; 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1061 self._distance_func,; 1062 self.rng_state,; -> 1063 self.diversify_prob,; 1064 ); 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951:3164,error,errors,3164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951,1,['error'],['errors']
Availability,"e and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 try:; ---> 66 from skmisc.loess import loess; 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); Cell In[14], line 1; ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'); 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:1744,error,error,1744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"e conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. During preprocessing of concatenated adata file for scvi-based label transfer, processing fails when applying ""sc.pp.highly_variable_genes"" function with ""ValueError: b'Extrapolation not allowed with blending'"". ### Minimal code sample. ```python; aadata = aadata.concatenate(ref_data_WT). aadata.X; <15445x13343 sparse matrix of type '<class 'numpy.float64'>'; 	with 107849393 stored elements in Compressed Sparse Row format>. # pre-processing:; aadata.layers[""counts""] = aadata.X.copy(); sc.pp.normalize_total(aadata, target_sum=1e4); sc.pp.log1p(aadata); aadata.raw = aadata. sc.pp.highly_variable_genes(aadata, flavor = 'seurat_v3', n_top_genes=2000,; layer = ""counts"", batch_key=""batch"", subset = True)#, span =0.5; ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); Cell In[37], line 7; 4 sc.pp.log1p(aadata); 5 aadata.raw = aadata; ----> 7 sc.pp.highly_variable_genes(aadata, flavor = 'seurat_v3', n_top_genes=2000,; 8 layer = ""counts"", batch_key=""batch"", subset = True)#, span =0.5. File ~/mambaforge/envs/soupxEnv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:441, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 439 sig = signature(_highly_variable_genes_seurat_v3); 440 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 441 return _highly_variable_genes_seurat_v3(; 442 adata,; 443 layer=layer,; 444 n_top_genes=n_top_genes,; 445 batch_key=batch_key,; 446 check_values=check_values,; 447 span=span,; 448 subset=subset,; 449 inplace=inplace,; 450 ); 452 if batch_key is None:; 453 df = _highly_variable_genes_single_batch(; 454 adata,; 455 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853:1021,Error,Error,1021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853,1,['Error'],['Error']
Availability,"e error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df); 1226 if len(c.categories) >= len(c):; 1227 continue; ...; 1232 ""AnnData, not on this view. You might encounter this""; 1233 ""error message while copying or writing to disk.""; 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'; ```. ### Versions. <details>. ```; anndata 0.7.8; scanpy 1.9.3; -----; PIL 10.0.0; asttokens NA; backcall 0.2.0; clustergrammer2 0.18.0; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7.post1; decorator 5.1.1; executing 1.2.0; google NA; h5py 3.9.0; igraph 0.10.6; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; jedi 0.19.0; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.9.0; ...; Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:2925,error,error,2925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability,"e has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttoke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:1090,error,error,1090,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,1,['error'],['error']
Availability,"e, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:5049,error,error,5049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,['error'],['error']
Availability,"e, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Union etc. are not valid as type arguments; 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.; ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1067:2643,down,downgrading,2643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067,1,['down'],['downgrading']
Availability,"e/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1883) encoding=self.options.get(""encoding"", None),; [1884](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1884) compression=self.options.get(""compression"", None),; [1885](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1885) memory_map=self.options.get(""memory_map"", False),; [1886](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1886) is_text=is_text,; [1887](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:14807,error,errors,14807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,"e:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback); 129 value = type(); 130 try:; --> 131 self.gen.throw(type, value, traceback); 132 except StopIteration as exc:; 133 # Suppress StopIteration *unless* it's the same exception that; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 ; ; LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32; ; File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^; ; During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:9625,error,errors,9625,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"e=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; bottleneck 1.3.7; brotli 1.0.9; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 2.0.4; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.4; ipykernel 6.29.3; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.1; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_ser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:1629,Error,Error,1629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,1,['Error'],['Error']
Availability,"e[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24998,error,errors,24998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['error'],['errors']
Availability,"e[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 pypi_0 pypi; coverage 7.4.4 pypi_0 pypi; cycler 0.12.1 pypi_0 pypi; dask 2024.4.1 pypi_0 pypi; dask-expr 1.0.10 pypi_0 pypi; distlib 0.3.8 pypi_0 pypi; execnet 2.1.1 pypi_0 pypi; fasteners 0.19 pypi_0 pypi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:25115,failure,failures,25115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,2,['failure'],"['failure', 'failures']"
Availability,e] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1932,ERROR,ERROR,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"e_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 Please use .at[] or .iat[] accessors.; 910 ; --> 911 Parameters; 912 ----------; 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 -------; 952 series : Series; --> 953 If label is contained, will be reference to calling Series,; 954 otherwise a new object; 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4344 ; 4345 elif not is_list_like(value):; -> 4346 new_data = self._data.fillna(value=value, limit=limit,; 4347 inplace=inplace,; 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4357 return self._constructor(new_data).__finalize__(self); 4358 ; -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):; 4360 """"""; 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 # in which case we are going to conform to the passed Categorical; 502 new_target = np.asarray(new_target); --> 503 if is_categorical_dtype(target):; 504 new_target = target._shallow_copy(new_target, name=self.name); 505 else:. ValueError: cannot reindex with a non-unique indexer. **; ```; The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450:1965,toler,tolerance,1965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450,4,"['down', 'error', 'toler']","['downcast', 'error', 'tolerance']"
Availability,"e_list); 152 ; --> 153 X_list = _adata[:, gene_list].X; 154 if issparse(X_list):; 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance); 3170 if not self.is_unique:; 3171 raise InvalidIndexError(; -> 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ); 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:4141,toler,tolerance,4141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,1,['toler'],['tolerance']
Availability,e_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12588,ERROR,ERROR,12588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,e_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16586,ERROR,ERROR,16586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,e_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14895,ERROR,ERROR,14895,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"e_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 pypi_0 pypi; coverage 7.4.4 pypi_0 pypi; cycler 0.12.1 pypi_0 pypi; dask 2024.4.1 pypi_0 pypi; dask-expr 1.0.10 pypi_0 pypi; distlib 0.3.8 pypi_0 pypi; execnet 2.1.1 pypi_0 pypi; fasteners 0.19 pypi_0 pypi; filelock 3.13.3 pypi_0 pypi; fonttools 4.51.0 pypi_0 pypi; fsspec 2024.3.1 pypi_0 pypi; h5py 3.10.0 pypi_0 pypi; identify 2.5.35 pypi_0 pypi; igraph 0.11.4 pypi_0 pypi; imageio ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:25310,failure,failures,25310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['failure'],['failures']
Availability,e_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20721,ERROR,ERROR,20721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ection to initialize the face and edgecolors; 541 # just in case it is a scalarmappable with a colormap.; --> 542 self.update_scalarmappable(); 543 offsets = self.get_offsets(); 544 if len(offsets) > 0:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/collections.py:926, in Collection.update_scalarmappable(self); 924 # pcolormesh, scatter, maybe others flatten their _A; 925 self._alpha = self._alpha.reshape(self._A.shape); --> 926 self._mapped_colors = self.to_rgba(self._A, self._alpha); 928 if self._face_is_mapped:; 929 self._facecolors = self._mapped_colors. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/cm.py:359, in ScalarMappable.to_rgba(self, x, alpha, bytes, norm); 357 x = ma.asarray(x); 358 if norm:; --> 359 x = self.norm(x); 360 rgba = self.cmap(x, alpha=alpha, bytes=bytes); 361 return rgba. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/colors.py:1193, in Normalize.__call__(self, value, clip); 1191 result.fill(0) # Or should it be all masked? Or 0.5?; 1192 elif vmin > vmax:; -> 1193 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1194 else:; 1195 if clip:. ValueError: minvalue must be less than or equal to maxvalue. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/formatters.py:339, in BaseFormatter.__call__(self, obj); 337 pass; 338 else:; --> 339 return printer(obj); 340 # Finally look for special method names; 341 method = get_real_method(obj, self.print_method). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/pylabtools.py:151, in print_figure(fig, fmt, bbox_inches, base64, **kwargs); 148 from matplotlib.backend_bases import FigureCanvasBase; 149 FigureCanvasBase(fig); --> 151 fig.canvas.print_figure(bytes_io, **kw); 152 data = bytes_io.getvalue(); 153 if fmt == 'svg':. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:4820,mask,masked,4820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['mask'],['masked']
Availability,"elf, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:4261,error,errors,4261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,"elf._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values); 144 ns = vc.sizes(); 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key); 2925 if self.columns.nlevels > 1:; 2926 return self._getitem_multilevel(key); -> 2927 indexer = self.columns.get_loc(key); 2928 if is_integer(indexer):; 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2657 return self._engine.get_loc(key); 2658 except KeyError:; -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'; ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:; ```; {'commit_hash': 'd774f565b',; 'commit_source': 'installation',; 'default_encoding': 'cp1252',; 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',; 'ipython_version': '7.4.0',; 'os_name': 'nt',; 'platform': 'Windows-10-10.0.18362-SP0',; 'sys_executable': 'C:\\Anaconda\\python.exe',; 'sys_platform': 'win32',; 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '; '(AMD64)]'}; ```. Thank you very much for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:2601,toler,tolerance,2601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,2,['toler'],['tolerance']
Availability,"en reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post0; decorator 5.1.1; defusedxml 0.7.1; distutils 3.12.3; executing 2.0.1; h5py 3.11.0; igraph 0.11.5; j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:1086,down,downstream,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['down'],['downstream']
Availability,"en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|; | -----------| ----- |; | Original | 297|; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110:1141,Down,Downloading,1141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110,1,['Down'],['Downloading']
Availability,"ent destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4445,ERROR,ERROR,4445,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"ent values; 232 self.extract_function_arguments(); --> 233 entry_block_tail = self.lower_function_body(); 234 ; 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self); 257 bb = self.blkmap[offset]; 258 self.builder.position_at_end(bb); --> 259 self.lower_block(block); 260 self.post_lower(); 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:13109,error,errors,13109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,"ent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:3696,error,errors,3696,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,"er group ""CellType_Category"", it worked. These two groups are in the same type. Could you tell me how to fix it?; Look forward to your response, thanks a lot!. ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata_sc, groupby=""Manuscript_Identity"", use_raw=False). adata_sc.obs['CellType_Category'].cat.categories; Index(['Endothelial', 'Epithelial', 'Lymphoid', 'Multiplet', 'Myeloid',; 'Stromal'],; dtype='object'); adata_sc.obs['Manuscript_Identity'].cat.categories; Index(['ATI', 'ATII', 'Aberrant_Basaloid', 'B', 'B_Plasma', 'Basal',; 'Ciliated', 'Club', 'DC_Langerhans', 'DC_Mature', 'Fibroblast',; 'Goblet', 'ILC_A', 'ILC_B', 'Ionocyte', 'Lymphatic', 'Macrophage',; 'Macrophage_Alveolar', 'Mast', 'Mesothelial', 'Multiplet',; 'Myofibroblast', 'NK', 'PNEC', 'Pericyte', 'SMC', 'T', 'T_Cytotoxic',; 'T_Regulatory', 'VE_Arterial', 'VE_Capillary_A', 'VE_Capillary_B',; 'VE_Peribronchial', 'VE_Venous', 'cDC1', 'cDC2', 'cMonocyte',; 'ncMonocyte', 'pDC'],; dtype='object'); ```. ### Error output. ```pytb; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 592, in rank_genes_groups; test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 106, in __init__; raise ValueError(; ValueError: Could not calculate statistics for groups Ionocyte since they only contain one sample.; ```. ### Versions. <details>. ```; setuptools 69.0.3; shapely 2.0.2; six 1.16.0; skimage 0.20.0; sklearn 1.3.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.15; squidpy 1.3.1; stack_data 0.6.2; statsmodels 0.14.1; sympy 1.12; tangram 1.0.4; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tifffile 2023.12.9; tlz 0.12.0; toolz 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:1459,Error,Error,1459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,1,['Error'],['Error']
Availability,"er, after running a new embedding and clustering on `adata_sub`, I have noticed that I can plot genes that shouldn't be in `adata_sub` (but were in `adata`), and that when I run `sc.tl.rank_genes_groups` my results aren't restricted to my 990 genes of interest. I am guessing that I subsetted my data incorrectly (though, why would I have the correct shape?). ### Minimal code sample (that we can copy&paste without having any data). ```python; # subset adata to genes of interest; adata_sub = adata[:, [g in genes_list for g in adata.var_names]].copy(). # filter out cells that don't express any genes of interest; sc.pp.filter_cells(adata_sub, min_genes=1). # run new embedding and clustering; sc.pp.pca(adata_sub, n_comps=50, use_highly_variable=False, svd_solver='arpack'); sc.pp.neighbors(adata_sub); sc.tl.umap(adata_sub); sc.tl.leiden(adata_sub, key_added='leiden_sub'); ```. When I use `sc.pl.umap(adata_sub)` to plot expression of a gene that is _not_ one of my genes of interest, it is still plotted (I would expect an error telling me that the gene is not found in my `adata_sub` object). Similarly, the results of `sc.tl.rank_genes_groups(adata_sub, groupby='leiden_sub', key_added='rank_genes_sub', method='wilcoxon')` returns top ranked genes that are not (or should not be) in my `adata_sub` object. Thank you for any help/clarification as to what's going on!. #### Versions. <details>; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2019.11.28; cffi 1.14.6; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.4.3; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.4.0; idna 2.8; igraph 0.9.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.4; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2007:1713,error,error,1713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007,1,['error'],['error']
Availability,"er.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:4312,error,errors,4312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"erance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leavi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3917,Toler,Tolerance,3917,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['Toler'],['Tolerance']
Availability,"error as using ""sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/212:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/212,1,['error'],['error']
Availability,error in dpt_scatter when 'groups' parameter set,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32,1,['error'],['error']
Availability,error in readwrite.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3071:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071,1,['error'],['error']
Availability,error in sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,1,['error'],['error']
Availability,error in scanpy first tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158,1,['error'],['error']
Availability,error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1874:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874,1,['error'],['error']
Availability,"ersion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running the tests with pytest<=8, the doctest for `scanpy.preprocessing._simple.filter_cells` errors in a way I can't quite figure out how to fix. . I think what's happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most recent call last):; File ""/mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/doctest.py"", line 1353, in __run; exec(compile(example.source, filename, ""single"",; File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:1113,FAILURE,FAILURES,1113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,1,['FAILURE'],['FAILURES']
Availability,"escr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 397 if self.state.cr is not None:; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:5651,avail,available,5651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['avail'],['available']
Availability,"escription of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1318:1461,Error,Error,1461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318,1,['Error'],['Error']
Availability,esiduals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10899,ERROR,ERROR,10899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11109,ERROR,ERROR,11109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21988,ERROR,ERROR,21988,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._h,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22200,ERROR,ERROR,22200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22412,ERROR,ERROR,22412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (un,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22624,ERROR,ERROR,22624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,est_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2944,ERROR,ERROR,2944,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,est_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18217,ERROR,ERROR,18217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"et, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:2442,down,download,2442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['download']
Availability,"et_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5726,error,error,5726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"eturn a float; cosine = np.dot(A, B) / (norm(A) * norm(B)); return cosine; transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance); sc.pp.neighbors(adata, transformer=transformer,n_pcs=0); sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics; dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15); adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(; knn_indices = tmp[0],; knn_dists = tmp[1],; n_obs = dis_mat.shape[0],; n_neighbors = 15,; ); adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}; sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))); ```. ### Error output. ```pytb; num of clusters: 85; num of clusters: 170; num of clusters: 183; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.10.1; -----; IPython 8.22.2; PIL 10.2.0; asttokens NA; console_thrift NA; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; decorator 5.1.1; executing 2.0.1; h5py 3.10.0; igraph 0.11.4; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.1; numpy 1.26.4; packaging 24.0; pandas 2.2.1; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.42; psutil 5.9.0; pure_eval 0.2.2; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.1.2; pytz 2024.1; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.4.0; tqdm 4.66.2; traitlets 5.14.2; typing_extensions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3021:2452,Error,Error,2452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021,1,['Error'],['Error']
Availability,"eturn plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2105,down,downcast,2105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['down'],['downcast']
Availability,"eturn_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:6669,avail,available,6669,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['avail'],['available']
Availability,"eurat_v3(; 656 adata,; 657 flavor=flavor,; 658 layer=layer,; 659 n_top_genes=n_top_genes,; 660 batch_key=batch_key,; 661 check_values=check_values,; 662 span=span,; 663 subset=subset,; 664 inplace=inplace,; 665 ); 667 cutoff = _Cutoffs.validate(; 668 n_top_genes=n_top_genes,; 669 min_disp=min_disp,; (...); 672 max_mean=max_mean,; 673 ); 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:4409,error,error,4409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"ew weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'); pairs_set = list(set(pairs)); s = sorted(pairs_set); half = int((len(s)/2)); list1 = s[:half]; list2 = s[half:]; lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(); for i in lz_cluster_method:; sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method); result = adata.u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:1573,error,error,1573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"ewidth=self.linewidth). AttributeError: 'numpy.ndarray' object has no attribute 'fill_betweenx'; ```. #### Option 2: group with two keys, passing first of two axes. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, axes = plt.subplots(1, 2); sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes[0]); ```. No traceback, but the second axis is simply not plotted. <img width=""388"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453540-76f48a6b-8d22-40bd-86fe-435d0878deb3.png"">. #### Option 3: group with two keys, passing one axis. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, ax = plt.subplots(); sc.pl.violin(adata, keys=['CD8A', 'CD8B'], groupby=""group"", ax=ax); ```. No traceback, even though this should error. Plots just the first of the two keys. <img width=""377"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; idna 3.1; igraph 0.9.8; importlib_resources NA; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.4.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; nbformat 5.1.3; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packagi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2136:3991,error,error,3991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136,1,['error'],['error']
Availability,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472:6050,error,error,6050,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472,1,['error'],['error']
Availability,fix an error when figsize is given,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/546:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/546,1,['error'],['error']
Availability,fix scrublet test tolerance,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2103:18,toler,tolerance,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2103,1,['toler'],['tolerance']
Availability,"g exists on the main branch of scanpy. ### What happened?. I have non zarr format Visium HD data. ; I tried reading it with sdata = visium_hd(path_read). it keeps asking me for a dataset_id which is not there in the feature_slice file name or my folder. ; Nonetheless, I kept setting it to None or """" or other possible dataset id values. I cannot find any tech support on the error either. . (I also tried specifying the file path to the different binned folders). ### Minimal code sample. path_read = '/Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs'; sdata = visium_hd(path_read). ### Error output. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:2111,Down,Downloads,2111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,1,['Down'],['Downloads']
Availability,"ga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:2971,toler,tolerance,2971,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['toler'],['tolerance']
Availability,"ge, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, do",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:1892,down,downcast,1892,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,3,['down'],['downcast']
Availability,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:2934,error,error,2934,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,3,"['down', 'error']","['downloaded', 'error']"
Availability,get.obs_df and get.var_df produce an error when there is only 1 key,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1315:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315,1,['error'],['error']
Availability,getting an error in scanpy after 'successfully' installing it through anaconda prompt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587,1,['error'],['error']
Availability,"h, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5596,error,error,5596,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"hat this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botoc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:1056,ERROR,ERROR,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['ERROR'],['ERROR']
Availability,"have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2479:1006,Error,Error,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479,1,['Error'],['Error']
Availability,"hbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:2012,error,error,2012,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability,"he conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0 py39hca03da5_0 ; appnope 0.1.2 py39hca03da5_1001 ; argon2-cffi 21.3.0 pyhd3eb1b0_0 ; argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 ; arpack 3.9.1 nompi_h593882a_101 conda-forge; array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge; asttokens 2.0.5 pyhd3eb1b0_0 ; async-lru 2.0.4 py39hca03da5_0 ; attrs 23.1.0 py39hca03da5_0 ; babel 2.11.0 py39hca03da5_0 ; backcall 0.2.0 pyhd3eb1b0_0 ; beautifulsoup4 4.12.3 py39hca03da5_0 ; blas 1.0 openblas ; bleach 4.1.0 pyhd3eb1b0_0 ; blosc2 2.0.0 pypi_0 pypi; brotli 1.1.0 hb547adb_1 conda-forge; brotli-bin 1.1.0 hb547adb_1 conda-forge; brotli-python 1.0.9 py39h313beb8_8 ; bzip2 1.0.8 h80987f9_6 ; c-ares 1.28.1 h93a5062_0 conda-forge; ca-certificates 2024.7.4 hf0a4a13_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2024.6.2 py39hc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5901,Error,Error,5901,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['Error'],['Error']
Availability,"he version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 # For data is list-like, or Iterable (will consume into list); 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ); 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point; 345 index, columns = _get_axes(; 346 values.shape[0], values.shape[1], index=index, columns=columns; 347 ); --> 349 _check_values_indices_shape_match(values, index, columns); 351 if typ == ""array"":; 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns); 418 passed = val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:1745,error,error,1745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,"hecked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193:1054,down,downgrade,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193,1,['down'],['downgrade']
Availability,"hello, I am trying to use normalisation part of scanpy and encounter this error. I tried to install Louvain but it is not helping. could anyone please help me. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566,1,['error'],['error']
Availability,"hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much.; sc.pp.filter_genes(adata, min_counts = filter_min_counts); sc.pp.filter_cells(adata, min_counts = filter_min_counts); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True); adata = adata[:, adata.var[""highly_variable""]]; sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738:191,error,error,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738,2,['error'],['error']
Availability,"hi, ; I installed the scanpy-master , but when I type `scanpy --help` in bash the error occurred. I noticed that diffrank was replaced by rank_genes_groups, but I don't know how to fix it. ; ```; Traceback (most recent call last):; File ""/public/bioapps/ana/anaconda3/envs/python35/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==0+unknown', 'console_scripts', 'scanpy')(); File ""/public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/scanpy-0+unknown-py3.5-linux-x86_64.egg/scanpy/__main__.py"", line 278, in main; init_main_parser().print_help(); File ""/public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/scanpy-0+unknown-py3.5-linux-x86_64.egg/scanpy/__main__.py"", line 117, in init_main_parser; descr = 78*'-' + '\n' + getattr(tools, key).__doc__; AttributeError: module 'scanpy.api.tools' has no attribute 'diffrank'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/30:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30,1,['error'],['error']
Availability,highly variable genes + batch_key --> reciprocal condition number error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669,1,['error'],['error']
Availability,highly_variable_genes variance computation on dense matrix - Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/785:61,Error,Error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785,1,['Error'],['Error']
Availability,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103,1,['error'],['error']
Availability,"hold] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_with_batches] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4026,ERROR,ERROR,4026,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"hon-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:2761,error,error,2761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,"hon3.9/site-packages/_pytest/main.py"", line 273 in wrap_session; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/main.py"", line 320 in pytest_cmdline_main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_callers.py"", line 102 in _multicall; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_manager.py"", line 119 in _hookexec; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_hooks.py"", line 501 in __call__; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/config/__init__.py"", line 175 in main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/config/__init__.py"", line 198 in console_main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/bin/pytest"", line 8 in <module>; /home/vsts/work/_temp/1dc6f140-196e-4393-a84a-ebdaa5dcda61.sh: line 1: 1811 Illegal instruction (core dumped) pytest. ##[error]Bash exited with code '132'.; ##[section]Finishing: PyTest; ```. ### Versions. <details>. ```; anndata 0.10.5.post1; annoy 1.17.3; array_api_compat 1.4.1; asciitree 0.3.3; attrs 23.2.0; cfgv 3.4.0; click 8.1.7; cloudpickle 3.0.0; contourpy 1.2.0; coverage 7.4.1; cycler 0.12.1; dask 2024.2.0; dask-glm 0.3.2; dask-ml 2023.3.24; decorator 5.1.1; Deprecated 1.2.14; distlib 0.3.8; distributed 2024.2.0; exceptiongroup 1.2.0; fasteners 0.19; fbpca 1.0; filelock 3.13.1; fonttools 4.49.0; fsspec 2024.2.0; future 0.18.3; geosketch 1.2; get-annotations 0.1.2; graphtools 1.5.3; h5py 3.10.0; harmonypy 0.0.9; identify 2.5.35; igraph 0.11.4; imageio 2.34.0; importlib-metadata 7.0.1; importlib-resources 6.1.1; iniconfig 2.0.0; intervaltree 3.1.0; Jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; lazy_loader 0.3; legacy-api-wrap 1.4; leidenalg 0.10.2; llvmlite 0.42.0; locket 1.0.0; magic-impute 3.0.0; MarkupSafe 2.1.5; matplotlib 3.8.3; msgpack 1.0.7; multipledispatch 1.0.0; natsort 8.4.0; networkx 3.2.1; nodeenv 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:6837,error,error,6837,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,1,['error'],['error']
Availability,how does sc.queries.enrich handle up- and down-regulated genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1901:42,down,down-regulated,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901,1,['down'],['down-regulated']
Availability,"html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /tmp/ipykernel_134148/2515279522.py in <module>; 1 embedding_anterior = np.concatenate(integrated_anterior, axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143:1380,down,downloaded,1380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143,1,['down'],['downloaded']
Availability,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1996:305,down,downgrade,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996,1,['down'],['downgrade']
Availability,ial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2470:838,down,downsampled,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470,1,['down'],['downsampled']
Availability,iduals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10474,ERROR,ERROR,10474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper; raise type(e)(; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /; /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>; _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:4231,error,error,4231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['error'],['error']
Availability,"imal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:1774,FAILURE,FAILURES,1774,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['FAILURE'],['FAILURES']
Availability,import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/855:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855,1,['error'],['error']
Availability,"in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-17-f0b30fa7797a> in <module>; ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:3854,error,error,3854,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = call $12load_method.4(func=$12load_method.4, args=[], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5017); D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:8923,error,error,8923,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['error']
Availability,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1921:3600,avail,available,3600,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921,1,['avail'],['available']
Availability,"info using `.uns[""dendrogram_['groups']""]`; WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; Storing dendrogram info using `.uns['dendrogram_groups']`; ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1521:1688,down,down,1688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521,1,['down'],['down']
Availability,"ing up your package via pip, as instructed. This crashed out very quickly:. 	mib111492i:~ kp9$ pip install scanpy; 	Collecting scanpy; 	 Downloading scanpy-0.2.9.1.tar.gz (208kB); 		100% |################################| 215kB 2.8MB/s ; 		Complete output from command python setup.py egg_info:; 		Traceback (most recent call last):; 		 File ""<string>"", line 1, in <module>; 		 File ""/private/tmp/pip-build-cx2i4lbu/scanpy/setup.py"", line 39, in <module>; 			readme = readme_f.read(); 		 File ""/Users/kp9/anaconda3/lib/python3.6/encodings/ascii.py"", line 26, in decode; 			return codecs.ascii_decode(input, self.errors)[0]; 		UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); 	; 		----------------------------------------; 	Command ""python setup.py egg_info"" failed with error code 1 in /private/tmp/pip-build-cx2i4lbu/scanpy/. The offender seems to be the stylised README file, so I downloaded the source code, got rid of it, and proceeded with the installation. I'm unsure how representative the following encountered issues are of an ideal pip installation, but I figured I'd bring them to your attention anyway just in case they're relevant:. - h5py crashed out on account of not having hdf5 available. This was remedied via `brew install hdf5`, and it seems like the most likely of these issues to affect other users.; - The installer ignored my 2.1.0 setup of matplotlib, tried to install 2.0.0 in some weird way and crashed out. Installing 2.0.0 via pip (absolutely painlessly, mind you - what was that weird installer that crashed the thing out?) allowed the setup to proceed past this point. This might be an isolated incident, but it seemed weird enough to alert you of just in case.; - As is, louvain crashes immediately and uninformatively when attempts are made to pip it in. Installing from the GitHub source code still works fine though. I'll notify the louvain team of this situation, but this may be of relevance to you too. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49:1270,avail,available,1270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49,1,['avail'],['available']
Availability,ing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: canno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19845,ERROR,ERROR,19845,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ER,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2336,ERROR,ERROR,2336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # start from scratch; del adata.obs[""louvain""]; adata.uns = {}; adata_ref.uns = {}. # example code for ingest function:; sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs=""louvain""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[11], line 23; 21 sc.pp.neighbors(adata_ref); 22 sc.tl.umap(adata_ref); ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 138 labeling_method = labeling_method * len(obs); 140 ing = Ingest(adata_ref, neighbors_key); --> 141 ing.fit(adata); 143 for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:1317,Error,Error,1317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,1,['Error'],['Error']
Availability,int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8775,ERROR,ERROR,8775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ion); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_quer,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1877,ERROR,ERROR,1877,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ion, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:1829,error,error,1829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,"is doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 323 # make the scatter plot; 324 if projection == '3d':; --> 325 cax = ax.scatter(; 326 coords[:, 0],; 327 coords[:, 1],; 328 coords[:, 2],; 329 marker=""."",; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:1564,error,error,1564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability,"isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:5309,error,error,5309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,1,['error'],['error']
Availability,"ite-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . adata = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...'pca', 'rank_genes_groups', 'log1p'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'. def _subset_genes(; adata: AnnData,; *,; mean: NDArray[np.float64] | DaskArray,; dispersion_norm: NDArray[np.float64] | DaskArray,; cutoff: _Cutoffs | int,; ) -> NDArray[np.bool_] | DaskArray:; """"""Get boolean mask of genes with normalized dispersion in bounds.""""""; if isinstance(cutoff, _Cutoffs):; > dispersion_norm[np.isnan(dispersion_norm)] = 0 # similar to Seurat; E ValueError: assignment destination is read-only. scanpy/preprocessing/_highly_variable_genes.py:365: ValueError; ```. </details>. Dependencies are different, looks like a dask update and a pyarrow added dep. I suspect this has to do with the new dask-expr. ----. I can replicate locally by install the new dask, dask-expr, and pyarrow. ----. Importing dask.dataframe changes the settings for pandas somehow:. ```python; In [1]: import pandas as pd. In [2]: pd.DataFrame({""a"": [1,2,3, None]})[""a""].to_numpy().flags; Out[2]: ; C_CONTIGUOUS : True; F_CONTIGUOUS : True; OWNDATA : False; WRITEABLE : True; ALIGNED : True; WRITEBACKIFCOPY : False. In [3]: import dask.dataframe as ddf. In [4]: pd.DataFrame({""a"": [1,2,3, None]})[""a""].to_numpy().flags; Out[4]: ; C_CONTIGUOUS : True; F_CONTIGUOUS : True; OWNDATA : False; WRITEABLE : False; ALIGNED : T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:5900,mask,mask,5900,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['mask'],['mask']
Availability,"ite-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs); 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):; 1179 """"""; 1180 Parameters; 1181 ----------; (...); 1196 Forwarded to `.Collection`.; 1197 """"""; -> 1198 super().__init__(**kwargs); 1199 self.set_sizes(sizes); 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs); 203 self._offset_transform = offset_transform; 205 self._path_effects = None; --> 206 self._internal_update(kwargs); 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs); 1209 def _internal_update(self, kwargs):; 1210 """"""; 1211 Update artist properties without prenormalizing them, but generating; 1212 errors as if calling `set`.; 1213 ; 1214 The lack of prenormalization is to maintain backcompatibility.; 1215 """"""; -> 1216 return self._update_props(; 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument ""; 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt); 1188 func = getattr(self, f""set_{k}"", None); 1189 if not callable(func):; -> 1190 raise AttributeError(; 1191 errfmt.format(cls=type(self), prop_name=k)); 1192 ret.append(func(v)); 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'; ```. ### Versions. <details>. ```; numpy 1.26.4; pandas 2.2.2; scanpy 1.10.2; session_info 1.0.0; -----. PIL 10.3.0; anndata 0.10.8; anyio NA; arrow 1.3.0; asciitree NA; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.15.0; certifi 2024.06.02; cffi 1.16.0; charset_norma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3140:7792,error,errors,7792,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140,1,['error'],['errors']
Availability,"ite-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:2447,error,error,2447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,1,['error'],['error']
Availability,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:2891,error,error,2891,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,1,['error'],['error']
Availability,ize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12796,ERROR,ERROR,12796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13011,ERROR,ERROR,13011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_reci,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22922,mask,mask-,22922,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-floa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2634,ERROR,ERROR,2634,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"k(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(pe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:4911,error,error,4911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['error']
Availability,known location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21352,ERROR,ERROR,21352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,known location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `cli,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2670,ERROR,ERROR,2670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,late_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2751,ERROR,ERROR,2751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,latest version error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601,1,['error'],['error']
Availability,"lel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:1841,error,errors,1841,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['errors']
Availability,let_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2420,ERROR,ERROR,2420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,lization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23647,ERROR,ERROR,23647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"lize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:3752,toler,tolerance,3752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,2,['toler'],['tolerance']
Availability,lize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23034,ERROR,ERROR,23034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isn’t great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2744:1724,error,error,1724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744,2,['error'],['error']
Availability,loat32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7270,ERROR,ERROR,7270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 37",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4521,toler,tolerance,4521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"lon=epsilon; 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1054 ); 1055 else:; -> 1056 diversify_csr(; 1057 reverse_graph.indptr,; 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2406:3855,error,errors,3855,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406,1,['error'],['errors']
Availability,lpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2178,ERROR,ERROR,2178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"lt colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://github.com/theislab/scanpydoc/blob/875b441212830678cf9fc81c52f5af29bbb8715f/scanpydoc/elegant_typehints/formatting.py#L101-L107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1633:1592,down,downside,1592,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633,1,['down'],['downside']
Availability,m 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10572,mask,mask-,10572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,macOS matplotlib error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567,1,['error'],['error']
Availability,magic() error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/206:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/206,1,['error'],['error']
Availability,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I would expect that when you call sc.pp.highly_variable_genes on the same dataset and request the same number of genes, that you would get the same output. The below example suggests that this is not the case. . ### Minimal code sample. ```python; adata_sub = sc.read_h5ad(""your_favourite_object.h5ad""); n_genes = 1491; for i in range(10):; sc.pp.highly_variable_genes(adata_sub, n_top_genes=n_genes). unique_genes = list(adata_sub.var['highly_variable'][adata_sub.var['highly_variable'] == True].index). if i == 0:; all_unique = list(set(unique_genes)); print(f""total {len(all_unique)} unique genes""); else:; all_unique = list(set(all_unique+unique_genes)); print(f""total {len(all_unique)} unique genes""); ```. ### Error output. ```pytb; total 1491 unique genes; total 1814 unique genes; total 2042 unique genes; total 2163 unique genes; total 2237 unique genes; total 2305 unique genes; total 2356 unique genes; total 2401 unique genes; total 2437 unique genes; total 2453 unique genes; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2579:1007,Error,Error,1007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579,1,['Error'],['Error']
Availability,malization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23850,ERROR,ERROR,23850,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,mask parameter added to pca method in _pca.py ; test_pca_mask added to test_pca.py; Deprecation warning on use_highly_variable parameter added to test_deprecations.py. ### [rendered docs](https://icb-scanpy--2272.com.readthedocs.build/en/2272/generated/scanpy.pp.pca.html),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272:0,mask,mask,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272,1,['mask'],['mask']
Availability,"master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2321:1192,error,error,1192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321,1,['error'],['error']
Availability,"mc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity; >>> ; >>> # This",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:2431,error,errors,2431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"md64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-am",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3007,ERROR,ERROR,3007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,2,"['ERROR', 'error']","['ERROR', 'errored']"
Availability,me 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_de,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20023,ERROR,ERROR,20023,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"miniforge3/envs/perturb-vs-tissue-env/lib/python3.10/site-packages/scanpy/get/get.py:328, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 325 if keys:; 326 df = df[keys]; --> 328 for k, idx in obsm_keys:; 329 added_k = f""{k}-{idx}""; 330 val = adata.obsm[k]. ValueError: too many values to unpack (expected 2); ```; The function works if you pass a list of Tuples:; ```; sc.get.obs_df(adata, obsm_keys = [('X_pca', 1)]); ```; So perhaps the parameter descriptions should say `List of Tuples of (key, column)`? Or the case of extracting a single column should be handled. . 2. The input for the `keys` is described as [""keys""](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L238-L239), but if you pass only one key as a string, the function returns a `pd.Series` instead of a `pd.DataFrame`. This is not a massive problem, unless you also pass something to `obsm_keys`. When you do that, the function gives no error but the `obsm` column is concatenated as an extra row; Example:; ```py; sc.get.obs_df(adata, keys='louvain', obsm_keys = [('X_pca', 1)]); ```; ```pytb; index; AAACATACAACCAC-1 CD4 T cells; AAACATTGAGCTAC-1 B cells; AAACATTGATCAGC-1 CD4 T cells; AAACCGTGCTTCCG-1 CD14+ Monocytes; AAACCGTGTATGCG-1 NK cells; ... ; TTTCTACTGAGGCA-1 B cells; TTTCTACTTCCTCG-1 B cells; TTTGCATGAGAGGC-1 B cells; TTTGCATGCCTCAC-1 CD4 T cells; X_pca-1 [0.2577139, 7.4819846, -1.5836583, -1.3685299,...; Name: louvain, Length: 2639, dtype: object; ```; You get the expected output if you pass the keys as a List; ```py; sc.get.obs_df(adata, keys=['louvain'], obsm_keys = [('X_pca', 1)]); ```; Again, the quick fix would be to change the parameter description for `keys` to `List of keys`.; . ### Versions. <details>. ```; -----; anndata 0.10.8; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.15.0; brotli 1.1.0; certifi 2024.07.04; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3310:2011,error,error,2011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310,1,['error'],['error']
Availability,"mport UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:3851,error,errors,3851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,mportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5337,ERROR,ERROR,5337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ms to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608:1423,Error,Error,1423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608,1,['Error'],['Error']
Availability,"n highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:2545,error,error,2545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,2,['error'],['error']
Availability,"n reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I install scanpy==1.9.6 with pip (anndata==0.10.4), something wrong and adata.X.nnz is 0.; I changed the version of anndata to 0.9.2, it works normal. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(my_sample, # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=False) # write a cache file for faster subsequent reading; # sc.pl.highest_expr_genes(adata, n_top=20, ); adata.X.nnz; ```. ### Error output. _No response_. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.5; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; bottleneck 1.3.5; cffi 1.16.0; comm 0.1.2; cycler 0.12.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 4.4.2; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; hurry NA; ipykernel 6.25.0; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.7; numpy 1.26.0; packaging 23.2; pandas 1.5.3; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.11; pyparsing 3.0.9; pytz 2023.3.pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2822:1099,Error,Error,1099,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2822,1,['Error'],['Error']
Availability,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:4131,error,errors,4131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,2,['error'],"['error', 'errors']"
Availability,n residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: canno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6185,ERROR,ERROR,6185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"n the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post0; decorator 5.1.1; defusedxml 0.7.1; distutils 3.12.3; executing 2.0.1; h5py 3.11.0; igraph 0.11.5; jedi 0.19.1; jinja2 3.1.4; joblib 1.4.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; louvain 0.8.2; markupsafe 2.1.5; matplotlib 3.9.0; mpl_toolkits NA; msgpack 1.0.8; natsort 8.4.0; numba 0.59.1; numcodecs 0.12.1; numpy 1.26.4; packaging 24.0; pandas 2.2.2; parso 0.8.4; pkg_resources NA; prompt_toolkit 3.0.45; psutil 5.9.8; pure_eval 0.2.2; pyarrow 16.1.0; pygments 2.18.0; pyparsing 3.1.2; pytz 2024.1; scipy 1.13.1; session_info 1.0.0; setuptools 70.0.0; setuptools_scm NA; sitecustomize NA; six 1.16.0; sklearn 1.5.0; sparse 0.15.4; sphinxcontrib NA; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:1731,Error,Error,1731,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['Error'],['Error']
Availability,"n3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:6179,error,error,6179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"n3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-3-69925a75d466> in <module>; 1 #calcular e visualizar metricas de QC por estudo; ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), ; 3 percent_top=None, layer=None, use_raw=False, inplace=True,; 4 log1p=False, parallel=None); 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 304 X.eliminate_zeros(); 305 ; --> 306 obs_metrics = describe_obs(; 307 adata,; 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:3180,toler,tolerance,3180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['toler'],['tolerance']
Availability,"n; 4 from ._highly_variable_genes import highly_variable_genes; 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in; 4 from anndata import AnnData; 5; ----> 6 from . import _simple as pp; 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1797:1991,error,errors,1991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797,1,['error'],['errors']
Availability,n_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10049,ERROR,ERROR,10049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,n_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10259,ERROR,ERROR,10259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,n_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15109,ERROR,ERROR,15109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:3071,error,error,3071,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,2,['error'],['error']
Availability,"nal) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`; - Enabled `return_fig`; - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python; import scanpy as sc; import anndata as ad; import pandas as pd; import numpy as np. obs = pd.DataFrame(np.arange(100), ; columns=['a'], ; index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5); adata = ad.AnnData(X=X, obs=obs); sc.tl.pca(adata); sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca; ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]); KeyError: ''; ```. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev128+g616d5803; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.3; numpy 1.23.4; packaging 21.3; pandas 1.5.1; pkg_resources NA; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.3; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.1.3; threadpoolctl 3.1.0; typing_extensions NA; zoneinfo NA; -----; Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]; macOS-<redacted>-arm64-arm-64bit; -----; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2681:1197,Error,Error,1197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681,1,['Error'],['Error']
Availability,"name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:4053,error,error,4053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"narios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; h5py 3.10.0; igraph 0.11.4; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; packaging 23.2; pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:1542,Error,Error,1542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['Error'],['Error']
Availability,"nent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227:2591,down,downgrade,2591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227,1,['down'],['downgrade']
Availability,new AnnData `.is_view` causes error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151,1,['error'],['error']
Availability,"ng(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:2914,error,error,2914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,1,['error'],['error']
Availability,"niconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2122:2726,down,downgrade,2726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122,1,['down'],['downgrade']
Availability,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:1679,error,error,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,3,['error'],['error']
Availability,normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17811,ERROR,ERROR,17811,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14258,ERROR,ERROR,14258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14052,ERROR,ERROR,14052,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,nown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19661,ERROR,ERROR,19661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"npy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. aggregate throws error when aggregating `obsm` or `varm`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean"", obsm=""X_umap""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[3], line 1; ----> 1 sc.get.aggregate(pbmc, by=""louvain"", func=""mean"", obsm=""X_umap""). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/functools.py:909, in singledispatch.<locals>.wrapper(*args, **kw); 905 if not args:; 906 raise TypeError(f'{funcname} requires at least '; 907 '1 positional argument'); --> 909 return dispatch(args[0].__class__)(*args, **kw). File /mnt/workspace/repos/scanpy/scanpy/get/_aggregated.py:272, in aggregate(adata, by, func, axis, mask, dof, layer, obsm, varm); 264 # Actual computation; 265 layers = aggregate(; 266 data,; 267 by=categorical,; (...); 270 dof=dof,; 271 ); --> 272 result = AnnData(; 273 layers=layers,; 274 obs=new_label_df,; 275 var=getattr(adata, ""var"" if axis == 0 else ""obs""),; 276 ); 278 if axis == 1:; 279 return result.T. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:271, in AnnData.__init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, obsp, varp, oidx, vidx); 269 self._init_as_view(X, oidx, vidx); 270 else:; --> 271 self._init_as_actual(; 272 X=X,; 273 obs=obs,; 274 var=var,; 275 uns=uns,; 276 obsm=obsm,; 277 varm=varm,; 278 raw=raw,; 279 layers=layers,; 280 dtype=dtype,; 281 shape=shape,; 282 obsp=obsp,; 283 varp=varp,; 284 filename=filename,; 285 filemode=filemode,; 286 ). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:501, in AnnData._init_as_actual(self, X, obs, var, uns, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:1147,mask,mask,1147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,1,['mask'],['mask']
Availability,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:13071,error,error,13071,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,['error'],['error']
Availability,"number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return self._repopulate_pool_static(self._ctx, self.Process,; 304 self._processes,; 305 self._pool, self._inqueue,; 306 self._outqueue, self._initializer,; 307 self._initargs,; 308 self._maxtasksperchild,; 309 self._wrap_exception). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:326, in Pool._repopulate_pool_static(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception); 325 w.daemon = True; -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2506:1461,Error,Error,1461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506,1,['Error'],['Error']
Availability,"nvs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 255 if sz == 0:; 256 raise ValueError(""Cannot cut empty array""); --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)); 259 mn, mx = (mi + 0.0 for mi in rng); 261 if np.isinf(mn) or np.isinf(mx):; 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds); 145 result = alt(values, axis=axis, skipna=skipna, **kwds); 146 else:; --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds); 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs); 401 if datetimelike and mask is None:; 402 mask = isna(values); --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs); 406 if datetimelike:; 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask); 1086 if values.size == 0:; 1087 return _na_for_min_count(values, axis); -> 1089 values, mask = _get_values(; 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask; 1091 ); 1092 result = getattr(values, meth)(axis); 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask); 314 if datetimelike or _na_ok_dtype(dtype):; 315 values = values.copy(); --> 316 np.putmask(values, mask, fill_value); 317 else:; 318 # np.where will promote if needed; 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array; ```. ### Versions. <details>. ```; scanpy 1.10.1; numpy 1.26.0. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:11468,mask,mask,11468,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,8,['mask'],['mask']
Availability,oarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19094,ERROR,ERROR,19094,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,oat32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4230,ERROR,ERROR,4230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:13727,error,error,13727,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],['error']
Availability,"ocker pull dynverse/ti_paga_issue. # enter the container ; docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5; /code/example.sh /input.h5. # enter python; python; ```; Inside python; ```python; import dynclipy; task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc; import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts); sc.pp.recipe_zheng17(adata, n_top_genes=101); sc.tl.pca(adata, n_comps=50); sc.pp.neighbors(adata, n_neighbors=15); ```; Which generates the following warning:; ```; /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:; def fuzzy_simplicial_set(; <source elided>; if knn_indices is None or knn_dists is None:; knn_indices, knn_dists, _ = nearest_neighbors(; ^. @numba.jit(); /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. self.func_ir.loc)); /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/688:2481,error,errors,2481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688,1,['error'],['errors']
Availability,"of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure.; The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error; Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,; then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`; It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python; adata: any anndata; markers: gene list include in var_names; group: obs key; celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(; 	adata, markers, group, show=False, swap_axes=True,; 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,; ); ```. ### Error output. ```pytb; KeyError: ""['veryvery.'] not in index""; # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ); ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:1252,Error,Error,1252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,2,['Error'],['Error']
Availability,"ols/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds); 376 if self.stats is None:; 377 idx = pd.MultiIndex.from_tuples([(group_name, first_col)]); --> 378 self.stats = pd.DataFrame(columns=idx); 379 ; 380 if n_genes_user is not None:. /usr/local/lib/python3.8/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 433 ); 434 elif isinstance(data, dict):; --> 435 mgr = init_dict(data, index, columns, dtype=dtype); 436 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:3312,Mask,MaskedArray,3312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,1,['Mask'],['MaskedArray']
Availability,om 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21140,ERROR,ERROR,21140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,on.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17408,ERROR,ERROR,17408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,on_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12380,ERROR,ERROR,12380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,on_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.dat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16379,ERROR,ERROR,16379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"onfirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1068,error,error,1068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3249,toler,tolerance,3249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,"or: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4174,ERROR,ERROR,4174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,or: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20928,ERROR,ERROR,20928,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"orLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self); 271 bb = self.blkmap[offset]; 272 self.builder.position_at_end(bb); --> 273 self.lower_block(block); 274 ; 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:12521,error,errors,12521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,"ore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.11.1 python-igraph==0.9.6 pynndescent==0.5.4. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:1679,error,errors,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,2,"['Down', 'error']","['Downloads', 'errors']"
Availability,"orhood_enrichment; import schist as scs; with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4053,Error,Error,4053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['Error'],['Error']
Availability,"orkflow and speed up review.; -->; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|; | -----------| ----- |; | Original | 297|; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110:1176,down,download,1176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110,1,['down'],['download']
Availability,"ormalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24053,ERROR,ERROR,24053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ormalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16793,ERROR,ERROR,16793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ortError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2599,ERROR,ERROR,2599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ould be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295:1187,Error,Error,1187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295,1,['Error'],['Error']
Availability,"ow. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though!. /Alma. ### Minimal code sample. ```python; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['connectivities']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k; np.testing.assert_equal(nn,k); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; anyio NA; arrow 1.2.3; asciitree NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2587:2842,Error,Error,2842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587,1,['Error'],['Error']
Availability,"p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:1537,error,errors,1537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"p.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 262, in cut; raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. --------------------------------------------. Concerns:; 1. I am not sure if its the way I created the anndata that is causing this problem.; 2. I have already log_normalized my data object and I am not sure what else to do. ; 3. I have also read the GitHub issues and tried to fix the problems but I am unable to. ; 4. I am attaching my own code here, which is exactly the one found on the website above. The error code is in the last few lines of my script. Not sure if anything I am doing before is causing the problem. [scanpy.txt]; (https://github.com/scverse/scanpy/files/8536536/scanpy.txt). Thank you.; Regards,; Shamini A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242:2623,error,error,2623,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242,1,['error'],['error']
Availability,"p_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; markupsafe 2.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:2449,Error,Error,2449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16681,mask,mask-,16681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2464,ERROR,ERROR,2464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"pe({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 193 f""Above error raised while writing key {key!r} of {type(elem)}""; 194 f"" from {parent}.""; --> 195 ) from e; 196 ; 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:5342,error,error,5342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,2,['error'],['error']
Availability,pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7887,ERROR,ERROR,7887,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - Impor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8104,ERROR,ERROR,8104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python; import urllib.request; import scanpy as sc. # load the data; h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad""; urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") ; adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10; k=10; sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True); adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32); print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold; max_neighbors = np.max(adjacency.sum(axis=0)); print(f""Max neighbors={max_neighbors}""); ```. ### Error output. ```pytb; adjacency matrix (k=10) shape: (1011, 1011); Max neighbors=91; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.9.8; -----; Bio 1.83; MOODS NA; PIL 10.2.0; absl NA; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.2.0; attrs 23.2.0; babel 2.14.0; biothings_client 0.3.1; bpnetlite 0.6.0; cattr NA; cattrs NA; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.6; colorlog NA; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; dragonnfruit 0.3.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; filelock 3.13.1; fqdn NA; fsspec 2024.3.1; goatools 1.3.11; google NA; h5py 3.10.0; hdf5plugin 4.4.0; idna 3.6; igraph 0.11.4; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 0.9.24; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3014:1574,Error,Error,1574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014,1,['Error'],['Error']
Availability,port name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20200,ERROR,ERROR,20200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,portError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5761,ERROR,ERROR,5761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"port_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all?. ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921); - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1898:3929,avail,available,3929,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898,1,['avail'],['available']
Availability,"provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G', 'H',; 'I', 'J',; 'K', 'L']; adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].cat.rename_categories(new_cluster_names); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, threshold=0.03); sc.tl.draw_graph(adata, init_pos='paga'); sc.pl.draw_graph(adata, color=['seurat_clusters'], legend_loc='right margin'); adata.uns['iroot'] = np.flatnonzero(adata.obs['seurat_clusters'] == 'C')[0]; sc.tl.dpt(adata); adata.obs['dpt_pseudotime']; adata; sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']); ```pytb; [Paste the error output produced by the above code here]; ```; ![1634300003(1)](https://user-images.githubusercontent.com/92583306/137486504-8a01bfc7-cbdf-409f-a730-dfec94f8c4f7.png). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2015:2607,error,error,2607,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015,1,['error'],['error']
Availability,"ps; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA; apport_python_hook NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; cairo 1.20.1; certifi 2024.07.04; cffi 1.16.0; chardet 4.0.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.4; comm 0.2.2; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.8.0; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; gi 3.42.1; gio NA; glib NA; gobject NA; gtk NA; h5py 3.11.0; idna 3.3; igraph 0.11.5; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.2; json5 0.9.25;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:2627,Error,Error,2627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,1,['Error'],['Error']
Availability,psutil error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35,1,['error'],['error']
Availability,"py.api as sc; from scipy import sparse; A = sparse.rand(100, 100, 0.1, ""csr""). # This works; sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error; sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))); ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-13-f65606c38b22> in <module>; ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 750 g = sns.clustermap(df, row_colors=row_colors, **kwds); 751 else:; --> 752 g = sns.clustermap(df, **kwds); 753 show = settings.autoshow if show is None else show; 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1299 row_cluster=row_cluster, col_cluster=col_cluster,; 1300 row_linkage=row_linkage, col_linkage=col_linkage,; -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws); 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws; 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,; -> 1128 row_linkage=row_linkage, col_linkage=col_linkage); 1129 try:; 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage); 1019 self.dendrogram_row = dendrogram(; 1020 self.data2d, metric=metric, method=method, label=False, axis=0,; -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage); 1022 else:; 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:1105,mask,mask,1105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['mask'],['mask']
Availability,"py/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.14; psutil 5.8.0; ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4645,error,error,4645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"py:777) ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__(self, filename, mode, compresslevel, fileobj, mtime); [190](file:///C:/Program%20Files/Python312/Lib/gzip.py:190) mode += 'b'; [191](file:///C:/Program%20Files/Python312/Lib/gzip.py:191) if fileobj is None:; --> [192](file:///C:/Program%20Files/Python312/Lib/gzip.py:192) fileobj = self.myfileobj = builtins.open(filename, mode or 'rb'); [193](file:///C:/Program%20Files/Python312/Lib/gzip.py:193) if filename is None:; [194](file:///C:/Program%20Files/Python312/Lib/gzip.py:194) filename = getattr(fileobj, 'name', ''). FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'; ```. I have tried with other datasets which are originally named ad matrix, features and barcodes, and those are working properly. Any idea?. ### Minimal code sample. ```python; data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], line 1; ----> 1 data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); 2 data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:560, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 558 prefix = """" if prefix is None else prefix; 559 is_legacy = (path / f""{prefix}genes.tsv"").is_file(); --> 5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:19972,Error,Error,19972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Error'],['Error']
Availability,py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown lo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23444,ERROR,ERROR,23444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,pynndescent error when trying to use a custom metric with scanpy neghbors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability,"python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:6195,down,downgrade,6195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['down'],['downgrade']
Availability,"r branch of scanpy. ### What happened?. I'm trying to use `sc.pl.spatial` with the dataset that is available on 10X Visium with the sample ID `CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma`. I can open and do some basic QC just fine, but when I try to plot, I get the error `TypeError: can't multiply sequence by non-int of type 'float`. ### Minimal code sample. ```python; import scanpy as sc; import anndata as an; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as plt; import seaborn as sns; import scanorama. sc.set_figure_params(facecolor=""white"", figsize=(8, 8)); sc.settings.verbosity = 3. # Loading dataset; adata = sc.read_visium(; path=r""\external"",; count_file=""CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5"",; load_images=True,; source_image_path=r""\spatial"",; ). adata.var_names_make_unique(). # Quality control; adata.var[""mito""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(; adata, qc_vars=[""mito""], percent_top=None, log1p=False, inplace=True; ); sc.pl.spatial(adata); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""\scanpy\plotting\_tools\scatterplots.py"", line 1002, in spatial; File ""\plotting\_tools\scatterplots.py"", line 391, in embedding; # if user did not set alpha, set alpha to 0.7; File ""\scanpy\plotting\_utils.py"", line 1107, in circles; if scale_factor != 1.0:; TypeError: can't multiply sequence by non-int of type 'float'; ```; The json file on the spatial folder with the scale factors is as follows:. ```json; {; ""regist_target_img_scalef"": 0.16836435,; ""tissue_hires_scalef"": 0.056121446,; ""tissue_lowres_scalef"": 0.016836435,; ""fiducial_diameter_fullres"": 384.18505640709947,; ""spot_diameter_fullres"": 256.12337093806633; }; ```. `tissue_hires_scalef` is being passed as `scale_factor` variable and hence why it's throwing the error; ### Versions. <details>. ```; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778:1352,Error,Error,1352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778,2,"['Error', 'error']","['Error', 'error']"
Availability,"r: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:1054,Error,Error,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,1,['Error'],['Error']
Availability,"r: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:3962,error,error,3962,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"r['gene_symbol'].astype('object'); ```. ### Minimal code sample. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. sc.pl.highest_expr_genes(adata, n_top=20, gene_symbols='gene_symbol', show=True, save="".png""); ```. I also tried this with the same results. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. adata.var.index = adata.var.gene_symbol; sc.pl.highest_expr_genes(adata, n_top=20, show=True, save="".png""); ```. ### Error output. ![349265437-b0a6e963-5d56-40e6-9922-5e4a543c08cf](https://github.com/user-attachments/assets/478c6a20-817f-4e39-92a3-62f5c2a62ed0). Above is a boxplot from `sc.pl.highest_expr_genes` that shows all the Categorical genes in addition to the top-20 as specified in the function argument. <img width=""1077"" alt=""Screenshot 2024-07-17 at 1 23 27 PM"" src=""https://github.com/user-attachments/assets/cfbdb40d-57f5-4da6-bf69-b4f4f3c489cc"">. Above is the correct boxplot, after my hack was applied to force the adata.var.gene_symbols to be mixed-object datatype instead of Categorical. ### Versions. <details>. python-3-10-4. ```; aiohttp==3.8.3; anndata==0.10.6; biocode==0.10.0; biopython==1.79; cairosvg==2.7.1; dash-bio==1.0.2; #diffxpy==0.7.4; Flask==3.0.0; Flask-RESTful==0.3.9; gunicorn; h5py==3.10.0; itsdangerous==2.1.2 # See -> https://stackoverflow.com/a/71206978; jupyterlab==4.0.5; jupyter==1.0.0; kaleido==0.2.1; leidenalg==0.10.2; llvmlite==0.41.1; matplotlib==3.9.0; mod-wsgi==4.9.4; more_itertools==9.0.0; mysql-connector-python==8.4.0; numba==0.58.1; numexpr==2.8.4; numpy==1.26.0; opencv-python==4.5.5.64; openpyxl==3.1.5; pandas==2.2.1; Pillow==10.2.0; pika==1.3.1; plotly==5.6.0; python-dotenv==0.20.0; requests==2.31.0; rpy2==3.5.1 # 3.5.2 and up gives errors with rpy2py and py2rpy; sanic; scanpy==1.10.1; scikit-learn==1.0.2; scipy==1.11.04; seaborn==0.13.2; SQLAlchemy==1.4.32; tables==3.9.2 # Read hdf5 files into pandas; xlrd==1.2.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3158:3377,error,errors,3377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3158,1,['error'],['errors']
Availability,r_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6836,ERROR,ERROR,6836,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite; reraise(type(e), e, None); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:2809,error,errors,2809,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,1,['error'],['errors']
Availability,rams2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4648,ERROR,ERROR,4648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rank genes groups errors on less than 2 cells in a category,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3118:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118,1,['error'],['errors']
Availability,rank_genes_group error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467,1,['error'],['error']
Availability,rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1530:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530,1,['error'],['error']
Availability,"rating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:1515,Error,Error,1515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['Error'],['Error']
Availability,"rcent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent_top); 115 for i, n in enumerate(percent_top):; 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 377 mtx = csr_matrix(mtx); 378 return top_segment_proportions_sparse_csr(; --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 380 ); 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:6706,error,errors,6706,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,read_10x_h5 errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/132:12,error,errors,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132,1,['error'],['errors']
Availability,read_loom on HCA loom files returns error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,1,['error'],['error']
Availability,regress_out() error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1171:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171,1,['error'],['error']
Availability,"request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:1893,error,error,1893,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,1,['error'],['error']
Availability,residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - Import,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19279,ERROR,ERROR,19279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(; 'data/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`; adata; sc.pl.highest_expr_genes(adata, n_top=20, ); sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0-4, multi_panel=True); ```. ### Error output. ```pytb; Kernel Restarting; The kernel for Tests/scanpytutorial/Untitled.ipynb appears to have died. It will restart automatically.; ```. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; asttokens NA; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; exceptiongroup 1.2.0; executing 2.0.1; h5py 3.10.0; igraph 0.11.3; ipykernel 6.29.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.2; mpl_toolkits NA; natsort 8.4.0; nt NA; numba 0.59.0; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pickleshare 0.7.5; platformdirs 4.1.0; prompt_toolkit 3.0.42; psutil 5.9.8; pure_eval 0.2.2; pyarrow 15.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pyparsing 3.1.1; pythoncom NA; pytz 2023.4; pywin32_system32 NA; pywintypes NA; scipy 1.12.0; session_info 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840:1897,Error,Error,1897,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840,1,['Error'],['Error']
Availability,"return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:2645,error,error,2645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,"rgs); 5657 self.set_aspect(aspect); 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,; 5659 interpolation=interpolation, origin=origin,; 5660 extent=extent, filternorm=filternorm,; 5661 filterrad=filterrad, resample=resample,; 5662 interpolation_stage=interpolation_stage,; 5663 **kwargs); -> 5665 im.set_data(X); 5666 im.set_alpha(alpha); 5667 if im.get_clip_path() is None:; 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A); 706 self._A = self._A[:, :, 0]; 708 if not (self._A.ndim == 2; 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; --> 710 raise TypeError(""Invalid shape {} for image data""; 711 .format(self._A.shape)); 713 if self._A.ndim == 3:; 714 # If the input data has values outside the valid range (after; 715 # normalisation), we issue a warning and then clip X to the bounds; 716 # - otherwise casting wraps extreme values, hiding outliers and; 717 # making reliable interpretation impossible.; 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.10.1; -----; PIL 9.5.0; anyio NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.1.0; attrs 23.1.0; babel 2.13.0; backcall 0.2.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.0; fastjsonschema NA; fqdn NA; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.2; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.19.1; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.3; jupyterlab_server 2.25.0; kiwi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:5011,reliab,reliable,5011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['reliab'],['reliable']
Availability,rix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7053,ERROR,ERROR,7053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rmalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24667,ERROR,ERROR,24667,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rmalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13631,ERROR,ERROR,13631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rn AnnData(; 224 **{; 225 # This is covering up backwards compat in the anndata initializer; 226 # In most cases we should be able to call `func(elen[k])` instead; --> 227 k: read_dispatched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:6427,error,error,6427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['error'],['error']
Availability,"rn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032:2630,error,error,2630,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032,1,['error'],['error']
Availability,"ror output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:2344,error,errors,2344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['error'],['errors']
Availability,"rror: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . adata = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...'pca', 'rank_genes_groups', 'log1p'; ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4617,failure,failure,4617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['failure'],['failure']
Availability,"rs, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:1775,error,error,1775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,rt name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2132,ERROR,ERROR,2132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rt name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23332,mask,mask-,23332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,rtError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5549,ERROR,ERROR,5549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rue)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ﻿﻿; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:1345,Error,Error,1345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['Error'],['Error']
Availability,"s happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most recent call last):; File ""/mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/doctest.py"", line 1353, in __run; exec(compile(example.source, filename, ""single"",; File ""<doctest scanpy.preprocessing._simple.filter_cells[1]>"", line 1, in <module>; File ""/mnt/workspace/repos/scanpy/scanpy/datasets/_datasets.py"", line 109, in krumsiek11; adata = read(filename, first_column_names=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/mnt/workspace/mambafor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:1511,mask,mask,1511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,1,['mask'],['mask']
Availability,"s() on my gene expression data, I do get separate matrices for names, scores, pvals, and pvals_adj. However, the scores don't match the pvals. In other words, with decreasing pvals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What's the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [NOTE: This doesn't just depend on a specific type of clustering technique. Irrespective of whether I try the in-built Leiden clustering technique, or the Schit library, or even cluster the cells randomly, this issue keeps occuring--which makes me think it's ether a bug, or I don't quite understand how the score generation works, maybe both. I've provided a little code snipper below.]. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12243486/ClusterOneVsRest.csv). ### Minimal code sample. ```python; import pickle; import numpy as np; import pandas as pd; from PIL import Image; import glob; import matplotlib.pyplot as plt; from skimage.morphology import convex_hull_image; from skimage import data, img_as_float; from skimage.util import invert; from scipy.spatial import ConvexHull, convex_hull_plot_2d; from multiprocessing import Pool; i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:1315,down,down,1315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['down'],['down']
Availability,"s); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:5997,error,error,5997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"s, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:6803,error,errors,6803,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,"s/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:1651,error,errors,1651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['errors']
Availability,"s__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. I installed the latest version of scanpy 1.9.3 and python 3.9, my computer is MacBook Pro 2020. ### Minimal code sample. ```python; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. ### Error output. ```pytb; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. ### Versions. <details>. ```. ```. </details>; 1.9.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2949:1881,Error,Error,1881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2949,1,['Error'],['Error']
Availability,s_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7686,ERROR,ERROR,7686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,s_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18680,ERROR,ERROR,18680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,sc.datasets.ebi_expression_atlas errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082:33,error,errors,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082,1,['error'],['errors']
Availability,sc.datasets.ebi_expression_atlas http errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['errors']
Availability,sc.external.pp.scurblet normalization error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1957:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957,1,['error'],['error']
Availability,sc.get.obs_df() gives an error when `obsm_keys` is given and keys are not given,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1634:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1634,1,['error'],['error']
Availability,sc.pl.dotplot Keyvalue error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,sc.pl.dpt error if n_branchings=0 in sc.tl.dpt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,1,['error'],['error']
Availability,sc.pl.highest_expr_genes() with layer errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3318:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318,1,['error'],['errors']
Availability,sc.pl.matrixplot index error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,1,['error'],['error']
Availability,sc.pl.paga value error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381,1,['error'],['error']
Availability,sc.pl.paga_path error in dimensions of array passed to ax.imshow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['error'],['error']
Availability,sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1929:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929,1,['error'],['error']
Availability,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027:278,error,errors,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027,1,['error'],['errors']
Availability,sc.pl.umap error message if sc.tl.umap has not been computed.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460,1,['error'],['error']
Availability,sc.pl.violin throws error if adata does not have .raw,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1546:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546,1,['error'],['error']
Availability,sc.pp.calculate_qc_metrics Runtime Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:35,Error,Error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['Error'],['Error']
Availability,sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2304:57,Error,Error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304,1,['Error'],['Error']
Availability,sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3143:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143,1,['error'],['error']
Availability,sc.pp.regress_out segmentation fault Mac OS X 10.13.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/194:31,fault,fault,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194,1,['fault'],['fault']
Availability,sc.pp.scale and sc.pp.regress_out error on first run of copied object,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731,1,['error'],['error']
Availability,"sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get ; ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks!. sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731,2,['error'],['error']
Availability,sc.pp.scale(adata) generates NaN error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/64:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64,1,['error'],['error']
Availability,sc.tl.PAGA error: object of type 'numpy.float64' has no len(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695,1,['error'],['error']
Availability,sc.tl.dpt with error: detected group with only [] cells,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33,1,['error'],['error']
Availability,sc.tl.embedding_density errors when a category has one observation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:24,error,errors,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,1,['error'],['errors']
Availability,"sc.tl.leiden(adata,use_weights=False) ERROR; ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339:38,ERROR,ERROR,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339,1,['ERROR'],['ERROR']
Availability,"sc.tl.louvain() works fine in pandas==0.25.3; but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1017:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017,1,['error'],['error']
Availability,sc.tl.pca error: no field of name X_pca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/504:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504,1,['error'],['error']
Availability,sc.tl.rank_genes_groups return errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1478:31,error,errors,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478,1,['error'],['errors']
Availability,"sc.tl.umap error with init_pos=""paga""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769,1,['error'],['error']
Availability,"sc.tl.umap numba error when used with init_pos=""paga""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['error'],['error']
Availability,scale for sparse matrixes and mask,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2941:30,mask,mask,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2941,1,['mask'],['mask']
Availability,scanpy conda installation error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990,1,['error'],['error']
Availability,scanpy.pp.log1p with backed h5ad produces copy error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,1,['error'],['error']
Availability,scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_resid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16267,mask,mask-,16267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19476,ERROR,ERROR,19476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2217,ERROR,ERROR,2217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python ; B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(); sc.pp.scale(B); sc.tl.pca(B, svd_solver='arpack'); ```. Yet I encounter an error:; `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163,2,['error'],['error']
Availability,"scent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:3529,down,downgrade,3529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['down'],['downgrade']
Availability,"scverse/scanpy/assets/59059267/3dd49231-ed62-4b7f-be1d-a950714667fc"">. but when I change the type of adata.X to float, the value of adata.raw will be changed with adata.X, I get following result; ```py; import numpy as np; import pandas as pd; import anndata as ad; from scipy.sparse import csr_matrix; print(ad.__version__). mtx = np.array([[1.2,2.1,3.9],[2.01,3.99,4.23],[4.21,5.12,6.87],[0,20.12,100.96]]). adata = sc.AnnData(mtx); adata.raw = adata; print(adata); print(adata.X). sc.pp.normalize_total(adata,target_sum=1e4); sc.pp.log1p(adata); print(adata.X) . print(adata.raw.X[0:10,0:10]); ```; I get following result; <img width=""525"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/5eec641b-3542-471b-be22-51ef8e8f31a8"">. It sems strange for me? Shouldn't I save raw data for float data? Could you give some suggestions? My environment is; <img width=""647"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/2267345f-1a2b-4708-90f9-d1892adfb42f"">. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.1; scanpy 1.9.5; -----; CoreFoundation NA; Foundation NA; PIL 9.4.0; PyObjCTools NA; anyio NA; appnope 0.1.2; asttokens NA; attr 22.1.0; babel 2.11.0; backcall 0.2.0; bottleneck 1.3.5; brotli NA; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2748:1816,Error,Error,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748,1,['Error'],['Error']
Availability,"se make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:1004,Error,Error,1004,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['Error'],['Error']
Availability,"se:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:7327,error,errors,7327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,"sion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 pynndescent==0.5.10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:1813,error,error,1813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,1,['error'],['error']
Availability,sion; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. ### Expected. ```pycon; >>> # then anndata=0.10.3; >>> print(adata.var); gene_ids feature_types; 4933401J01Rik ENSMUSG00000102693 Gene Expression; Gm26206 ENSMUSG00000064842 Gene Expression; Xkr4 ENSMUSG00000051951 Gene Expression; Gm18956 ENSMUSG00000102851 Gene Expression; Gm37180 ENSMUSG00000103377 Gene Expression; ... ... ...; mt-Nd6 ENSMUSG00000064368 Gene Expression; mt-Te ENSMUSG00000064369 Gene Expression; mt-Cytb ENSMUSG00000064370 Gene Expression; mt-Tt ENSMUSG00000064371 Gene Expression; mt-Tp ENSMUSG00000064372 Gene Expression. [55450 rows x 2 columns]; ```. ### Versions. `import scanpy; scanpy.logging.print_versions()`. # **session with an error**. <Details>. ```; -----; anndata 0.10.4; scanpy 1.9.6; -----; PIL 10.2.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; brotli 1.1.0; certifi 2023.11.17; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.10.0; idna 3.6; ipykernel 6.28.0; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.20.0; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.12.4; jupyterlab_server 2.25.2; kiwisolver 1.4.5; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.58.1; numpy 1.26.3; overrides NA; packaging 23.2; pandas 2.1.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 4.1.0; prometheus_client NA; prompt_toolkit 3.0.42; psutil 5.9.7; ptyprocess 0.7.0; pure_eval,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:8520,error,error,8520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['error'],['error']
Availability,son_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10684,ERROR,ERROR,10684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,son_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5076,ERROR,ERROR,5076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,son_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21776,ERROR,ERROR,21776,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,spatial dataset download issue,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:16,down,download,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,1,['down'],['download']
Availability,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2057:1958,down,downregulated,1958,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057,1,['down'],['downregulated']
Availability,"st numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:1714,ERROR,ERROR,1714,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,1,['ERROR'],['ERROR']
Availability,"st_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24459,ERROR,ERROR,24459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,st_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8516,ERROR,ERROR,8516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,st_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2075,ERROR,ERROR,2075,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"stances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; jobli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:3631,error,error,3631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,1,['error'],['error']
Availability,"ster branch of scanpy. ---. I noticed that running the same single-cell analyses on different nodes of our HPC produces different results. ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014:1222,avail,available,1222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014,1,['avail'],['available']
Availability,subgrouping error?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833,1,['error'],['error']
Availability,"sue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:3011,error,error,3011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"t 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-15-2e1cefb9ad47> in <module>; ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 194 adata = adata.copy(); 195 else:; --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start); 197 return adata; 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start); 207 if not genome:; 208 if len(children) > 1:; --> 209 raise ValueError(; 210 f""'{filename}' contains more than one genome. For legacy 10x h5 ""; 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```. #### Versions. <details>. 1.8.2. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:3029,Avail,Available,3029,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,1,['Avail'],['Available']
Availability,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2328:2310,error,error,2310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328,1,['error'],['error']
Availability,"t having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bins_to_cuts(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered); 399 if len(unique_bins) < len(bins) and len(bins) != 2:; 400 if duplicates == ""raise"":; --> 401 raise ValueError(; 402 f""Bin edges must be unique: {repr(bins)}.\n""; 403 f""You can drop duplicate edges by setting the 'duplicates' kwarg"". ValueError: Bin edges must be unique: array([ -inf, 1.00000000e-12, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1560:1524,robust,robust,1524,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560,1,['robust'],['robust']
Availability,t import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2783,ERROR,ERROR,2783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"t of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:7812,error,errors,7812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,"t pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> 343 def sparse_alternative_jaccard(ind1, data1, ind2, data2):; 344 num_non_zero = arr_union(ind1, ind2).shape[0]; 345 num_equal = arr_intersect(ind1, ind2).shape[0]. ~/.local/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 216 with typeinfer.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:3863,error,errors,3863,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"t); <ipython-input-13-a0665160cba0> in <module>; 1 import anndata; ----> 2 import scanpy as sc; 3 import igraph; 4 ; 5 C6665_new = anndata.AnnData(C6665_encoded). ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\__init__.py in <module>; 30 # the actual API; 31 from ._settings import settings, Verbosity # start with settings as several tools are using it; ---> 32 from . import tools as tl; 33 from . import preprocessing as pp; 34 from . import plotting as pl. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\__init__.py in <module>; 8 from ._rank_genes_groups import rank_genes_groups, filter_rank_genes_groups; 9 from ._dpt import dpt; ---> 10 from ._leiden import leiden; 11 from ._louvain import louvain; 12 from ._sim import sim. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\_leiden.py in <module>; 13 ; 14 try:; ---> 15 from leidenalg.VertexPartition import MutableVertexPartition; 16 except ImportError:; 17 class MutableVertexPartition: pass. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\__init__.py in <module>; 33 not immediately available in :func:`leidenalg.find_partition`.; 34 """"""; ---> 35 from .functions import ALL_COMMS; 36 from .functions import ALL_NEIGH_COMMS; 37 from .functions import RAND_COMM. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\functions.py in <module>; 21 return graph.__graph_as_cobject(); 22 ; ---> 23 from .VertexPartition import *; 24 from .Optimiser import *; 25 . ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\VertexPartition.py in <module>; 6 PY3 = (sys.version > '3'); 7 ; ----> 8 class MutableVertexPartition(_ig.VertexClustering):; 9 """""" Contains a partition of graph, derives from :class:`ig.VertexClustering`.; 10 . AttributeError: module 'igraph' has no attribute 'VertexClustering'`. ```; I might be wrong, but looks like Scanpy is directly calling igraph.vertexclustering, while vertex clustering is a module under clustering. Shouldn't it be referred as ig.clustering.vertexclustering?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/961:1341,avail,available,1341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961,1,['avail'],['available']
Availability,"t, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 133 ; 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs; --> 135 datas, mnn_list, angle_list = mnn_correct(; 136 *datas,; 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 120 if var_subset is not None and set(adata_vars) == set(var_subset):; 121 var_subset = None; --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,; 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,; 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 176 new_batch_out = out_batches[target]; 177 print(' Looking for MNNs...'); --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,; 179 n_jobs=n_jobs); 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}; ---------------------------------------------------------------------------. ```. #### Versions; python 3.9. <details>; The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2436:3174,error,error,3174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436,1,['error'],['error']
Availability,"t.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run; _build_py.run(self); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__; self.data_files = self._get_data_files(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files; return list(map(self._get_pkg_data_files, self.packages or ())); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files; for file in self.find_data_files(package, src_dir); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: Can't convert 'list' object to str implicitly; ; ----------------------------------------; Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/; You are using pip version 8.1.1, however version 18.1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command.; ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:11778,error,error,11778,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,3,"['avail', 'error']","['available', 'error']"
Availability,t_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18014,ERROR,ERROR,18014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23239,ERROR,ERROR,23239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21564,ERROR,ERROR,21564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: can,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2718,ERROR,ERROR,2718,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"te that I can't update numpy to a newer version because of other packages I'm using, but `1.23` is more recent that what scanpy requires anyway (i.e., `numpy>=1.17.0`). For instance, the `spatialdata` library requires `numpy<=1.23.4` because of `xarray-spatial`: thus, it seems that the latest version of `scanpy` is not compatible with `spatialdata` (cc @LucaMarconato for information). The error seems to be due to this commit in `_validate_palette`: https://github.com/scverse/scanpy/commit/d1fe8da28ab4865b6c2b3d9cd151a8186f148844 (@flying-sheep). ### Minimal code sample. ```python; # Just plotting a dummy UMAP. import anndata; import pandas as pd; import numpy as np; import scanpy as sc. n_obs = 10. adata = anndata.AnnData(; X=np.random.randint(0, 5, size=(n_obs, 8)),; obs=pd.DataFrame({; ""cell_type"": np.random.choice([""A"", ""B"", ""C""], size=n_obs)},; index=[str(i) for i in range(n_obs)]; ),; ). sc.pp.neighbors(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""cell_type""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); Cell In[6], line 1; ----> 1 sc.pl.umap(adata, color=""cell_type""). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:674, in umap(adata, **kwargs); 615 @_wraps_plot_scatter; 616 @_doc_params(; 617 adata_color_etc=doc_adata_color_etc,; (...); 621 ); 622 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:; 623 """"""\; 624 Scatter plot in UMAP basis.; 625 ; (...); 672 tl.umap; 673 """"""; --> 674 return embedding(adata, 'umap', **kwargs). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830:1464,Error,Error,1464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830,1,['Error'],['Error']
Availability,"te_qc_metrics(em_adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True); em_adata.obs[""outlier_mt""] = em_adata.obs.pct_counts_mt > 15; em_adata.obs[""outlier_total""] = em_adata.obs.total_counts > 30000; em_adata.obs[""outlier_ngenes""] = em_adata.obs.n_genes_by_counts > 6000; em_adata = em_adata[~em_adata.obs[""outlier_mt""], :]; em_adata = em_adata[~em_adata.obs[""outlier_total""], :]; em_adata = em_adata[~em_adata.obs[""outlier_ngenes""], :]; sc.pp.filter_genes(em_adata,min_cells=1). sc.pp.scrublet(em_adata); em_adata.layers['counts'] = em_adata.X.copy(); sc.pp.normalize_total(em_adata); sc.pp.log1p(em_adata); sc.pp.highly_variable_genes(em_adata,flavor='seurat'); sc.pl.highly_variable_genes(em_adata); em_adata = em_adata[:, em_adata.var[""highly_variable""]]; em_adata.shape; # [out] -> (41749, 1425); sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; conda env:; # Name Version Build Channel; _r-mutex 1.0.0 anacondar_1; anndata 0.10.6 pypi_0 pypi; anyio 4.3.0 pypi_0 pypi; argon2-cffi 23.1.0 pypi_0 pypi; argon2-cffi-bindings 21.2.0 py311h2bbff1b_0; array-api-compat 1.5.1 pypi_0 pypi; arrow 1.3.0 pypi_0 pypi; asttokens 2.4.1 pypi_0 pypi; async-lru 2.0.4 py311haa95532_0; attrs 23.2.0 pypi_0 pypi; babel 2.14.0 pypi_0 pypi; beautifulsoup4 4.12.3 pypi_0 pypi; bleach 6.1.0 pypi_0 pypi; brotli-python 1.0.9 py311hd77b12b_7; bzip2 1.0.8 h2bbff1b_5; ca-certificates 2023.12.12 haa95532_0; certifi 2024.2.2 py311haa95532_0; cffi 1.16.0 py311h2bbff1b_0; charset-normalizer 3.3.2 pypi_0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969:1967,Error,Error,1967,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969,1,['Error'],['Error']
Availability,"ted.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. ; I find this issue really weird because categories_order works just fine when I am generating a dotplot.; Maybe I am missing something fundamental. ### Minimal code sample. ```python; ##code that does not reorder ( I tried both options 'order' and 'categories_order'; sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders; sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 19.0.0; PIL 10.0.0; apport_python_hook NA; backcall 0.2.0; certifi 2019.11.28; cffi 1.15.0; chardet 3.0.4; cloudpickle 2.2.1; colorama 0.4.3; colorcet 3.0.1; cryptography 2.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gseapy 1.0.5; h5py 3.7.0; idna 2.8; igraph 0.10.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.6.1; matplotlib_inline NA; more_itertools NA; mpl_toolkits NA; natsort 8.2.0; netifaces 0.10.4; numba 0.56.3; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.2; patsy 0.5.3; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.15.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pyarrow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2611:1106,Error,Error,1106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611,1,['Error'],['Error']
Availability,test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3349,ERROR,ERROR,3349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2549,ERROR,ERROR,2549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normali,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11637,mask,mask-,11637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16060,mask,mask-,16060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:1747,error,error,1747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['error'],['error']
Availability,"then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: ; ```; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). ; Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : ; `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python; #read the data; Data1_adata= sc.read_10x_mtx(; '/Data_1/filtered_feature_bc_matrix', ; var_names='gene_symbols', index); cache=True) ; #concatenate; adata = Data1_adata.concatenate(Data2_adata); # save raw counts in raw slot.; adata.raw = adata ; # normalize to depth 10 000; sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize; sc.pp.log1p(adata). #check adata.raw ; print(adata.raw.X[1:10,1:10]); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.0; -----; PIL 8.4.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; backcall 0.2.0; bottleneck 1.3.7; brotli NA; certifi 2024.02.02; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.2.0; dateutil 2.8.2; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.7.0; idna 3.6; igraph 0.11.4; importlib_resources NA; ipykernel 6.29.2; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.12.5; jupyterlab_server 2.25.3; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.40.0; louvain 0.8.0; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.8.0; matplotlib_inline ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073:1368,Error,Error,1368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073,1,['Error'],['Error']
Availability,"this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp; ---------------------------------------------------------------------------; View of AnnData object with n_obs × n_vars = 52078 × 6200; obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'; uns: 'spatial'; obsm: 'spatial', 'spatial_fov'; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2486:1194,error,error,1194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486,1,['error'],['error']
Availability,"this makes it possible to use `pip install` without installing numpy. it also includes automation for cython again, as currently the `python setup.py build_ext` command will never use cython, even if available. once the .pyx is changed and `build_ext` is executed, this now refreshes the `.c` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/38:200,avail,available,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38,1,['avail'],['available']
Availability,"thon3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:3556,toler,tolerance,3556,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['toler'],['tolerance']
Availability,"thon3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 . TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)); [2] During: typing of call at /opt/conda/lib/python3.7/site-packages/umap/umap_.py (776). File ""../../../opt/conda/lib/python3.7/site-packages/umap/umap_.py"", line 776:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new; ```. What I basically do from raw UMI counts:. 1. total counts normalization / logarithmization; 2. PCA, bbknn, louvain; 3. combat, HVG, PCA, UMAP (works well); 4. Paga (with louvain from 2., works well); 5. UMAP (with positions from 4., does not work). Any idea? Any further info needed?; Best,; Jens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:3089,error,errors,3089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,2,['error'],"['error', 'errors']"
Availability,"till read to memory, even in backed mode.; As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-pat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2365:1529,down,download,1529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365,1,['down'],['download']
Availability,ting._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2820,ERROR,ERROR,2820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,tion.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17613,ERROR,ERROR,17613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"tl.dpt with no branching events works:; ```; sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True); yields; performing Diffusion Pseudotime analysis; initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`; eigenvalues of transition matrix; [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917; 0.45321003 0.35327435 0.33786523 0.29598442]; finished (0:01:09.57) --> added; 'dpt_pseudotime', the pseudotime (adata.obs); ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0?. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2524 try:; -> 2525 return self._engine.get_loc(key); 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-102-eb7d1d859c99> in <module>(); ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save); 677 """"""; 678 colors = ['dpt_pseudotime']; --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']; 680 if color is not None: colors = color; 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:547,error,error,547,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,2,"['error', 'toler']","['error', 'tolerance']"
Availability,toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrubl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18887,ERROR,ERROR,18887,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"tput in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:1525,down,downloaded,1525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['down'],['downloaded']
Availability,"tribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:6088,error,error,6088,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"tructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),; (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),; (; ""master_paga_continuous_multiple"",; partial(sc.pl.paga, color=['CST3', 'GATA2']),; ),; (""master_paga_compare"", partial(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2459:1204,FAILURE,FAILURES,1204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459,1,['FAILURE'],['FAILURES']
Availability,try fixing h5py error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1113:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113,1,['error'],['error']
Availability,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:2157,error,error,2157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,4,"['Error', 'error']","['Error', 'error']"
Availability,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:2987,mask,masked,2987,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,5,"['error', 'mask']","['error', 'mask', 'masked']"
Availability,"ttps://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [766](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:766) filename=handle,; [767](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:767) mode=ioargs.mode,; [768](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:16485,error,error,16485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['error']
Availability,"tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:7793,error,errors,7793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,type error in scale_factor with sc.pl.spatial function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494,1,['error'],['error']
Availability,"type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:2588,error,error,2588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['error']
Availability,uals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9839,ERROR,ERROR,9839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,uals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15537,ERROR,ERROR,15537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2256,ERROR,ERROR,2256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"uce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 147 ; --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:1412,error,error,1412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"uces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:1465,Error,Error,1465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,1,['Error'],['Error']
Availability,"uested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, target",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:4842,error,errors,4842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307:2965,error,errors,2965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307,4,['error'],"['error', 'errors']"
Availability,"ule>; ----> 1 sc.tl.umap(adata, init_pos='paga'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy); 137 neigh_params.get('metric', 'euclidean'),; 138 neigh_params.get('metric_kwds', {}),; --> 139 verbose=max(0, verbosity-3)); 140 adata.obsm['X_umap'] = X_umap # annotate samples with UMAP coordinates; 141 logg.info(' finished', time=True, end=' ' if _settings_verbosity_greater_or_equal_than(3) else '\n'). /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 . TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)); [2] During: typing of call at /opt/conda/lib/python3.7/site-packages/umap/umap_.py (776). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:1571,error,errors,1571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['error'],['errors']
Availability,"ule>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/prepr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:2342,avail,available,2342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,1,['avail'],['available']
Availability,"ull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:4810,error,error,4810,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],['error']
Availability,"umap(adata, color, use_raw, edges, edges_width, edges_color, arrows, arrows_kwds, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, size, title, show, save, ax); 290 show=False,; 291 save=False,; --> 292 ax=ax); 293 if edges: utils.plot_edges(axs, adata, basis, edges_width, edges_color); 294 if arrows: utils.plot_arrows(axs, adata, basis, arrows_kwds). ~/software/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 104 show=show,; 105 save=save,; --> 106 ax=ax); 107 elif x is not None and y is not None:; 108 if ((x in adata.obs.keys() or x in adata.var.index). ~/software/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 409 raise ValueError('""' + name + '"" is invalid!'; 410 + ' specify valid name, one of '; --> 411 + str(adata.obs[key].cat.categories)); 412 else:; 413 iname = np.flatnonzero(adata.obs[key].cat.categories.values == name)[0]. ValueError: ""Z"" is invalid! specify valid name, one of Index(['Zero', '1', '2', '3', '4'], dtype='object'); ```; The last call `sc.pl.umap` gives and error but I would expect it to work. It seems that scanpy iterates over the string `'Zero'` in the last call of `sc.pl.umap`. Of course, it is easy to work around by explicitly passing a list with one element as in the second call, but it took me a while to figure this out. `sc.logging.print_versions()` prints `scanpy==1.2.2+96.g28f5034 anndata==0.6.4 numpy==1.15.0 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/231:2452,error,error,2452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/231,1,['error'],['error']
Availability,unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,1,['error'],['error']
Availability,"ure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. First, the argument is named ""percent""_top, suggesting a fraction in the range [0,1] or at a stretch [0, 100]. Second, the description starts with ""Which proportion"", again suggesting a fraction. But then, the description goes on to say that `percent_top=[50]` would use the 50 most expressed genes, NOT the 50% most expressed genes. So in the end, it's not a percentage but an absolute number. This is further supported by the fact that the default values are `(50, 100, 200, 500)`, which are clearly not percentages.; See: https://github.com/scverse/scanpy/blob/585f58c9e4dd82dd7809a831538c4e230b008818/scanpy/preprocessing/_qc.py#L237. ### Minimal code sample. ```python; # No code, issue is in documentation; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.4; scanpy 1.9.6; -----; PIL 10.0.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.13.1; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.2.0; comm 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.10.0; idna 3.4; igraph 0.10.8; ipykernel 6.27.1; ipython_genutils 0.2.0; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.20.0; jsonschema_specifications NA; jupyter_server 1.24.0; jupyterlab_server 2.25.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.7.2; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.58.1; numpy 1.25.2; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.9.0; platformdirs 4.1.0; plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2842:1013,Error,Error,1013,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2842,1,['Error'],['Error']
Availability,"ut_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:3379,error,error,3379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['error'],['error']
Availability,"ute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:5875,error,error,5875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names); 142 filename = fspath(filename) # allow passing pathlib.Path objects; 143 from loompy import connect; --> 144 with connect(filename, 'r') as lc:; 145 ; 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version); 1151 Note: if validation is requested, an exception is raised if validation fails.; 1152 	""""""; -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version); 82 lv = loompy.LoomValidator(version=spec_version); 83 if not lv.validate(filename):; ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); 85 ; 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('PRDM1_extende",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/320:1843,error,errors,1843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320,1,['error'],['errors']
Availability,"ve already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:1747,Error,Error,1747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,1,['Error'],['Error']
Availability,"ve confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:1130,error,error,1130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"ve no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:1394,error,error,1394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"vice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:974,Error,Error,974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,"['Error', 'error']","['Error', 'errors']"
Availability,"w, log, num_categories, color_map, dot_max, dot_min, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1350 if isinstance(var_names, str):; 1351 var_names = [var_names]; -> 1352 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 1353 ; 1354 # for if category defined by groupby (if any) compute for each var_name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 495 ; 496 def __getitem__(self, index):; --> 497 oidx, vidx = self._normalize_indices(index); 498 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 499 else: X = self._adata.file['raw.X'][oidx, vidx]. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_indices(self, packed_index); 523 obs, var = super()._unpack_index(packed_index); 524 obs = _normalize_index(obs, self._adata.obs_names); --> 525 var = _normalize_index(var, self.var_names); 526 return obs, var; 527 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_index(index, names); 268 raise KeyError(; 269 'Indices ""{}"" contain invalid observation/variables names/indices.'; --> 270 .format(index)); 271 return positions.values; 272 else:. KeyError: 'Indices ""[\'mamo\', \'mab21\', \'ChaT\', \'VGlut\']"" contain invalid observation/variables names/indices.'; ```. I do NOT get the error when I select to 'color' for either genes in the sc.pl.umap command. Moreover my adata contains all genes since the beggining so it is not subsetting anything. . All the help is appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:2302,error,error,2302,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,"when run sc.utils.sanitize_anndata(adata), it returns:; AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error?; the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2410:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410,1,['error'],['error']
Availability,"with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4095,error,error,4095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['error'],['error']
Availability,"x that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python; # Read the count matrix ; adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names; adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]; adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names; sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample; for sample in sample_list:; sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```; However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. ; ```pytb; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); Input In [5], in <cell line: 2>(); 1 # iterate through the sample names and create a new AnnData object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:1138,error,error,1138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,"y(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:3036,error,error,3036,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['error'],['error']
Availability,y/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportErr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3554,ERROR,ERROR,3554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,y::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16998,ERROR,ERROR,16998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"y_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'sample', 'group', 'disease_status', 'leiden'; var: 'gene_ids', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'log1p', 'pca', 'neighbors', 'umap', 'leiden', 'leiden_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'. ```. Ive tried to check whether the data is maybe different or something, but i dont see anything that could be causing these differences, could you please help trying to figure out why the leiden clustering suddenly produces different results? . ### Minimal code sample. ```python; sc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20); sc.tl.umap(adata); sc.tl.leiden(adata, resolution = 0.2) ; sc.pl.umap(adata, color='leiden'); ```. ### Error output. _No response_. ### Versions. <details>. ```; sc.logging.print_versions(); -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 9.4.0; PyQt5 NA; adjustText 1.0.4; asttokens NA; atomicwrites 1.4.1; bottleneck 1.3.5; brotli NA; bs4 4.12.2; certifi 2024.02.02; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.2.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; executing 2.0.1; gseapy 1.1.2; h5py 3.9.0; html5lib 1.1; idna 3.4; igraph 0.11.3; ipykernel 6.29.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.10.2; llvmlite 0.42.0; lxml 5.1.0; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; matplotlib_inline 0.1.6; mkl 2.4.1; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.4; numpy 1.24.3; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pickleshare 0.7.5; platformdirs 3.10.0; prompt_toolkit 3.0.42; psuti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956:2703,Error,Error,2703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2956,1,['Error'],['Error']
Availability,"ygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:2764,down,downgrading,2764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrading']
Availability,"ython\Python312\site-packages\pandas\io\parsers\readers.py:620, in _read(filepath_or_buffer, kwds); 617 _validate_names(kwds.get(""names"", None)); 619 # Create the parser.; --> 620 parser = TextFileReader(filepath_or_buffer, **kwds); 622 if chunksize or iterator:; 623 return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); 1617 self.options[""has_index_names""] = kwds[""has_index_names""]; 1619 self.handles: IOHandles | None = None; -> 1620 self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); 1878 if ""b"" not in mode:; 1879 mode += ""b""; -> 1880 self.handles = get_handle(; 1881 f,; 1882 mode,; 1883 encoding=self.options.get(""encoding"", None),; 1884 compression=self.options.get(""compression"", None),; 1885 memory_map=self.options.get(""memory_map"", False),; 1886 is_text=is_text,; 1887 errors=self.options.get(""encoding_errors"", ""strict""),; 1888 storage_options=self.options.get(""storage_options"", None),; 1889 ); 1890 assert self.handles is not None; 1891 f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); 761 if compression == ""gzip"":; 762 if isinstance(handle, str):; 763 # error: Incompatible types in assignment (expression has type; 764 # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> 765 handle = gzip.GzipFile( # type: ignore[assignment]; 766 filename=handle,; 767 mode=ioargs.mode,; 768 **compression_args,; 769 ); 770 else:; 771 handle = gzip.GzipFile(; 772 # No overload variant of ""GzipFile"" matches argument types; 773 # ""Union[str, BaseBuffer]"", ""str"", ""Dict[str, Any]""; (...); 776 **compression_args,; 777 ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:23789,error,errors,23789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,ze_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14473,ERROR,ERROR,14473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"细胞分析\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,; lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,; lung_ti_p4,lung_ts1_p4,lung_ts2_p4,; lung_P2, lung_P5, lung_P8, lung_P9,; lung_P13, lung_P16,; lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,; lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,; batch_categories = [""TI-P2"", ""TM-P2"",; ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',; ""TI-P4"",'TS1-P4','TS2-P4',; 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',; 'lung_P13', 'lung_P16',; 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',; 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],; join='outer'). print('Begin of post doublets removal and QC plot'); sc.pp.scrublet(alldata, n_neighbors=10); alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(); n1 = alldata.shape[0]; print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'); print(f'End of post doublets removal and QC plots.'); ```. ### Error output. ```pytb; Begin of post doublets removal and QC plot; Running Scrublet; normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts; warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00); WARNING: adata.X seems to be already log-transformed.; extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p; np.log1p(X, out=X). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[59], line 2; 1 print('Begin of post doublets removal and QC plot'); ----> 2 sc.pp.scrublet(alldata, n_neighbors=10); 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(); 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:6105,Error,Error,6105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['Error'],['Error']
Deployability," 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; lazy_loader NA; leidenalg 0.10.1; llvmlite 0.40.0; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; matplotlib_venn 0.11.9; mkl 2.4.0; mpl_toolkits NA; msgpack 1.0.5; multipledispatch 0.6.0; multiscale_spatial_image 0.11.2; mygene 3.2.2; natsort 7.1.1; nbinom_ufunc NA; neighborhood_enrichment NA; networkx 3.1; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; ome_zarr NA; openpyxl 3.1.2; packaging 23.0; pandas 2.0.3; param 1.13.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; pooch v1.4.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pyct 0.5.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygeos 0.14; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyproj 3.6.0; pytz 2022.7; pywt 1.4.1; requests 2.31.0; rich NA; rtree 1.0.1; schist v0.7.16; scipy 1.8.0; seaborn 0.12.2; session_info 1.0.0; setuptools 68.0.0; shapely 2.0.1; sip NA; six 1.16.0; skimage 0.20.0; sklearn 1.2.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.12; sphinxcontrib NA; spyder 5.4.3; spyder_kernels 2.4.3; spydercustomize NA; squidpy 1.3.0; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tifffile 2021.7.2; tlz 0.12.0; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; umap 0.5.3; urllib3 1.26.16; validators 0.20.0; wcwidth 0.2.5; wurlitzer 3.0.2; xarray 2022.12.0; xarray_dataclasses 1.6.0; xarray_schema 0.0.3; xrspatial 0.3.7; yaml 6.0; zarr 2.16.0; zipp NA; zmq 25.1.0; zoneinfo NA; zstandard 0.19.0; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:50:29) [Clang 14.0.6 ]; macOS-11.6-x86_64-i386-64bit; -----; Session information updated at 2023-08-02 20:20. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:7787,update,updated,7787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['update'],['updated']
Deployability," 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.8.0; jupyterlab_server 2.6.0; kiwisolver 1.2.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; nbinom_ufunc NA; numba 0.53.1; numcodecs 0.8.0; numexpr 2.7.2; numpy 1.21.0; packaging 20.9; pandas 1.2.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2020.1; requests 2.25.1; scanpy 1.9.0.dev7+g092376d2; scipy 1.7.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; snappy NA; sniffio 1.2.0; socks 1.7.1; sparse 0.12.0+21.gc96cc1a; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.6.0; terminado 0.8.3; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.61.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 1.1.0; yaml 5.3.1; zappy NA; zarr 2.8.3; zmq 19.0.2; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-07-01 15:01; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:4595,update,updated,4595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,1,['update'],['updated']
Deployability, 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0; importlib-metadata 6.8.0; importlib-resources 6.1.0; incremental 22.10.0; inflection 0.5.1; iniconfig 2.0.0; intake 0.7.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:5031,patch,patch,5031,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['patch'],['patch']
Deployability," 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs); 2261 orientation=orientation,; 2262 bbox_inches_restore=_bbox_inches_restore,; -> 2263 **kwargs); 2264 finally:; 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs); 515 ; 516 def print_png(self, filename_or_obj, *args, **kwargs):; --> 517 FigureCanvasAgg.draw(self); 518 renderer = self.get_renderer(); 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self); 435 # if toolbar:; 436 # toolbar.set_cursor(cursors.WAIT); --> 437 self.figure.draw(self.renderer); 438 # A GUI class may be need to update a window using this draw, so; 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs); 53 renderer.start_filter(); 54 ; ---> 55 return draw(artist, renderer, *args, **kwargs); 56 finally:; 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer); 1491 ; 1492 mimage._draw_list_compositing_images(; -> 1493 renderer, self, artists, self.suppressComposite); 1494 ; 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 139 if not_composite or not has_images:; 140 for a in artists:; --> 141 a.draw(renderer); 142 else:; 143 # Composite any adjacent images together. ~/.pyenv/versions/3.6.5/Py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:6741,update,update,6741,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,1,['update'],['update']
Deployability," 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:79) if len(args_all) <= n_positional:; ---> [80](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:80) return fn(*args_all, **kw); [82](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:82) args_pos: P.args; [83](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:83) args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:560, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); [558](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:1998,Pipeline,PipelineDevelope,1998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:4044,update,updated,4044,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['update'],['updated']
Deployability," ; 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. [...]/lib/python3.6/site-packages/matplotlib/axes/_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5762 kwargs.setdefault('snap', False); 5763 ; -> 5764 collection = mcoll.PolyCollection(verts, **kwargs); 5765 ; 5766 collection.set_alpha(alpha). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, offset_position, zorder, **kwargs); 164 ; 165 self._path_effects = None; --> 166 self.update(kwargs); 167 self._paths = None; 168 . [...]/lib/python3.6/site-packages/matplotlib/artist.py in update(self, props); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. [...]/lib/python3.6/site-packages/matplotlib/artist.py in <listcomp>(.0); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. [...]/lib/python3.6/site-packages/matplotlib/artist.py in _update_property(self, k, v); 910 func = getattr(self, 'set_' + k, None); 911 if not callable(func):; --> 912 raise AttributeError('Unknown property %s' % k); 913 return func(v); 914 . AttributeError: Unknown property standard_scale; ```; Any idea of why I'm getting this? . Package info:. ```; scanpy==1.4 anndata==0.6.18 numpy==1.16.2 scipy==1.2.0 pandas==0.24.1 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Thank you!. PS: this happens also when I just use the example data as in [here](https://scanpy-tutorials.readth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/559:2365,update,update,2365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/559,1,['update'],['update']
Deployability," <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; brotli 1.1.0; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.7; igraph 0.10.8; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.0; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; matplotlib_inline 0.1.7; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numpy 1.26.4; overrides NA; packaging 24.0; pandas 1.5.3; parso 0.8.4; pickleshare 0.7.5; platformdirs 4.2.0; prometheus_client NA; prompt_toolkit 3.0.42; psutil 5.9.8; pure_eval 0.2.2; pycparser 2.22; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.12; pyparsing 3.1.2; pythonjsonlogger NA; pytz 2024.1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.4.0; tornado 6.4; tqdm 4.66.2; traitlets 5.14.3; umap 0.5.5; uri_template NA; urllib3 2.2.1; wcwidth 0.2.13; webcolors 1.13; websocket 1.7.0; yaml 6.0.1; zmq 26.0.2; -----; IPython 8.22.2; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.1.6; notebook 7.1.3; -----; Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]; Linux-5.4.0-150-generic-x86_64-with-glibc2.27; -----; Session information updated at 2024-05-22 17:19. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:5232,update,updated,5232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,1,['update'],['updated']
Deployability," = 0.01; cvFilter = 2; nr_pcs = 50. ddata = adata.to_dict(); X = ddata['X']; # row normalize ; X = row_norm(X, max_fraction=0.05, mult_with_mean=True); # filter out genes with mean expression < 0.1 and coefficient of variance < ; # cvFilter ; X, gene_filter = filter_genes_cv(X, meanFilter, cvFilter); # compute zscore of filtered matrix ; Xz = zscore(X); # PCA ; Xpca = pca(Xz, nr_comps=nr_pcs); # update dictionary ; ddata['X'] = X; ddata['Xpca'] = Xpca; ddata['var_names'] = ddata['var_names'][gene_filter]; sett.m(0, 'Xpca has shape',; ddata['Xpca'].shape[0], 'x', ddata['Xpca'].shape[1]); from ..ann_data import AnnData; adata = AnnData(ddata); print(adata.X); ```; While the previous snippet works just as expected, when I want to do the same without a ddata object, some uncontrolled behavior comes up. Indexing doesn't work as expected anymore. @flying-sheep: could you have a look at why `adata['Xpca'] = Xpca` in the following throws an; ```py; >>> adata['Xpca'] = Xpca; IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices; ```; in the following snippet; ```py; X = adata.X; # row normalize ; X = row_norm(X, max_fraction=0.05, mult_with_mean=True); # filter out genes with mean expression < 0.1 and coefficient of variance < ; # cvFilter ; X, gene_filter = filter_genes_cv(X, meanFilter, cvFilter); # compute zscore of filtered matrix ; Xz = zscore(X); # PCA ; Xpca = pca(Xz, nr_comps=nr_pcs); # update adata ; adata.X = X; adata = adata.var_names[gene_filter] # filter genes ; adata['Xpca'] = Xpca; sett.m(0, 'Xpca has shape',; adata['Xpca'].shape[0], 'x', adata['Xpca'].shape[1]); print(adata.X); ```; I played around quite some bit, but the only solution that I got running then had the numerically incorrect result. It's quite to hard to keep this sequence of steps nicely organized. PS: the snippet appears in `scanpy/preprocess/advanced.py` and an example would be `./scanpy.py nestorowa16 diffmap -r pp`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/4:1594,update,update,1594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4,1,['update'],['update']
Deployability," Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----; Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]; Linux-4.19.121-linuxkit-x86_64-with-debian-10.8; 2 logical CPU cores; -----; Session information updated at 2021-04-12 15:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1796:6936,update,updated,6936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796,1,['update'],['updated']
Deployability," I have confirmed this bug exists on the main branch of scanpy. ### What happened?. cc: @Intron7 . The array types returned for the various aggregations in `sc.get.aggregate` are different (see example). This can lead to somewhat confusing behavior downstream, especially while we are using the sparse matrix classes. I would suggest we default to a dense result and consider adding an argument `array_type` that determines the type of the arrays added to `layers`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(). aggregated = sc.get.aggregate(adata, ""louvain"", [""sum"", ""count_nonzero""]); type(aggregated.layers[""sum""]); # numpy.ndarray. type(aggregated.layers[""count_nonzero""]); # scipy.sparse._csr.csr_matrix; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.10.0.dev315+gf6d5ac94; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.1; dateutil 2.8.2; decorator 5.1.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.11.3; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.41.1; markupsafe 2.1.4; matplotlib 3.8.2; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.9.0; prompt_toolkit 3.0.43; psutil 5.9.8; ptyprocess 0.7.0; pure_eval 0.2.2; pygments 2.17.2; pyparsing 3.1.1; pytz 2023.4; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.0; sparse 0.15.1; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.1; toolz 0.12.1; traitlets 5.14.1; wcwidth 0.2.13; yaml 6.0.1; zarr 2.16.1; zipp NA; -----; Python 3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:43:09) [GCC 12.3.0]; Linux-5.15.0-87-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-03-04 13:41; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2892:2161,update,updated,2161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2892,1,['update'],['updated']
Deployability," It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; h5py 3.10.0; igraph 0.11.4; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; packaging 23.2; pandas 2.2.1; psutil 5.9.8; pyparsing 3.1.1; pytz 2024.1; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; texttable 1.7.0; threadpoolctl 3.3.0; typing_extensions NA; wcwidth 0.2.13; -----; Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]; Linux-5.4.0-165-generic-x86_64-with-glibc2.31; -----; Session information updated at 2024-03-05 10:07; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:2908,update,updated,2908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['update'],['updated']
Deployability," See below. ```python; import scanpy as sc; x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'); x.var_names_make_unique(); print(x); sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); ```. ```pytb; AnnData object with n_obs × n_vars = 600 × 32838; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'; var: 'features'; Traceback (most recent call last):; File ""./main.py"", line 8, in <module>; sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3; model.fit(); File ""_loess.pyx"", line 899, in _loess.loess.fit; ValueError: b'reciprocal condition number 3.9554e-16\n'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.18.1; packaging 20.8; pandas 1.0.1; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-03 11:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1825:2247,update,updated,2247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825,1,['update'],['updated']
Deployability," [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [766](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:766) filename=handle,; [767](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:767) mode=ioargs.mode,; [768](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:768) **compression_args,; [769](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:769) ); [770](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:770) else:; [771](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:771) handle = gzip.GzipFile(; [772](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:17279,Pipeline,PipelineDevelope,17279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
