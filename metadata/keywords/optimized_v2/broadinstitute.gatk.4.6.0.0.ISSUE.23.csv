quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Usability,"@lbergelson thanks - could you take another look?. I agree about the many modes -- I'm not sure there's a way to clear that up. We're game to help with documentation/blog stuff that can help clarify what sort of usecases would benefit from different modes/features if that would help. Do you have any pointers for sample data that I could use for testing the ""many contigs to several"" case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6681#issuecomment-667421004:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6681#issuecomment-667421004,2,['clear'],['clear']
Usability,"@lbergelson that seems to be a separate bug, since this just reverts some commits. There's obviously a simple workaround here too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-267026554:103,simpl,simple,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-267026554,2,['simpl'],['simple']
Usability,@lbergelson the tests are not running on [gatk-jenkins.broadinstitute.org](url) so it's not usable yet. What remains to be done?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400#issuecomment-199324556:92,usab,usable,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400#issuecomment-199324556,1,['usab'],['usable']
Usability,"@lbergelson you beat me because I was stuck trying to actually run a Picard tool in the integration test. (For future reference, that needs a workaround because the test running adds the ERROR level logging to all command lines and Barclay can't parse that for Picard tools for some reason.). The big reason I was using this instead of IntervalListTools is because the Picard version creates a terrible output file structure that I was having trouble capturing with a simple glob in WDL. I agree that the functionality here is largely redundant, but it was helping me get my workflow working faster at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196:468,simpl,simple,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196,2,['simpl'],['simple']
Usability,"@lbergelson, @akiezun AFAIK picard tools need you to specify specifically FLAG=true/ FLAG=false if it's a boolean flag. it is true that, if you want, any argument can have a default value (true or false) but to change it you will still need to assign true or false (i.e even if there is a default you cannot simply have FLAG on the commandline). Yes, the logic of the pipeline specifies all the commandline arguments, regardless of defaults so that if the defaults change (which the GATK used to do all the time!) the pipeline will not change. Thus the use case has to include being able to set all arguments to their value boolean or otherwise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94434510:308,simpl,simply,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94434510,1,['simpl'],['simply']
Usability,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:17,simpl,simple,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834,4,['simpl'],['simple']
Usability,"@lbergson's instructions above are good, but somehow they did not work for me. I was able to follow the [application default credentials](https://developers.google.com/identity/protocols/application-default-credentials) instructions, though. Here are the steps I took:. 1. create a new service account on the Google Cloud web page and download the JSON key file.; 2. gcloud auth activate-service-account --key-file ""$PATH_TO_THE_KEY_FILE""; 3. export GOOGLE_APPLICATION_CREDENTIALS=""$PATH_TO_THE_KEY_FILE"". I cleared my credentials first to make sure that the access worked because of the above steps, not because of other credentials. After those steps, gatk was able to run from my desktop and access files using the service account credentials. `gsutil ls` worked as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470:508,clear,cleared,508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470,2,['clear'],['cleared']
Usability,"@ldgauthier & @droazen I've done as you've suggested. There is now a check in `GenomicsDBImport`, by wrapping the FeatureReader. It's a little ugly but it gets the job done. I've also added a simple test for GenotypeGVCFs to genotype a GVCF that has an MNP in it. I _think_ this is probably now ready for review. Let me know if you think further tests are needed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371:192,simpl,simple,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371,2,['simpl'],['simple']
Usability,"@ldgauthier / @davidbenjamin Would either of you like to comment on this one? This is a long-standing issue with our assembly-based callers, and it's not clear to me that there's an obvious solution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399562467:154,clear,clear,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399562467,2,['clear'],['clear']
Usability,"@ldgauthier @ahaessly and I could use your thoughts/intuition as to what might be going wrong here. The `NullPointerException` the user reported is in the `StrandBiasUtils.encode()` method below, and it implies that either the `perAlleleValues` for one of the alleles is itself null, or the `perAlleleValues` for one of the alleles contains a null `Integer`. In `computeSBAnnotation()` we have `perAlleleValues.values().removeIf(Objects::isNull)`, which seems to rule out the former option (perAlleleValues for a particular allele itself being null), and implies that instead one of the individual Integers in the `List<Integer>` perAlleleValues for a particular allele is null. Any ideas on how that could happen?. ```; public static String encode(List<Integer> alleleValues) {; return String.join("","", alleleValues.stream().map(i -> i.toString()).collect(Collectors.toList()));; }. protected static String makeRawAnnotationString(final List<Allele> vcAlleles, final Map<Allele, List<Integer>> perAlleleValues) {; final List<String> alleleStrings = vcAlleles.stream(); // does not replace a null value with zero list - only if the key is not in the map; .map(a -> perAlleleValues.getOrDefault(a, ZERO_LIST)); .map(StrandBiasUtils::encode); .collect(Collectors.toList());; return String.join(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM, alleleStrings);. }. public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {; // calculate the annotation from the likelihoods; // likelihoods can come from HaplotypeCaller or Mutect2 call to VariantAnnotatorEngine; final Map<String, Object> annotations = new HashMap<>();; final ReducibleAnnotationData<List<Integer>> myData = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);; getStrandCountsFromLikelihoodMap(vc, likelihoods, myData, MIN_COUNT);; Map<Allele, List<Integer>> perAlleleValues = new LinkedHashMap<>(myData.getAttributeMap());; perAlleleValues.values().removeIf(Ob",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697902360:52,intuit,intuition,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697902360,2,['intuit'],['intuition']
Usability,"@ldgauthier Emitting the spanning-deletion-only sites completely would definitely make things simpler, since I could then use EMIT_ALL_CONFIDENT_SITES and GenotypingEngine would just naturally do the right thing. Also, the result would comport with my own naive expectations. Using the current PR, outputs could contain LowQual sites that GATK3 wouldn't have included. So if you're good with that, I'll update the PR and tests to reflect that before any more reviewing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424454872:94,simpl,simpler,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424454872,2,['simpl'],['simpler']
Usability,@ldgauthier PR for you! Hopefully simple...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-581539634:34,simpl,simple,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-581539634,2,['simpl'],['simple']
Usability,"@ldgauthier Some parts of taking splitting MNPs at the end of HaplotypeCaller are easy: breaking eg one DNP at position n into a SNP at n and a SNP at n + 1, letting the SNPs inherit the PLs, AF, and AD (okay, this isn't quite right because a read might end in the middle of the MNP, but close enough) of the parent MNP. . . but the general problem of splitting annotations seems like it might be too tricky. I'm leaning toward instead just modifying `AssemblyBasedCallerGenotypingEngine.phaseCalls()`. It seems that this phasing relies very heavily on perfect phasing or anti-phasing and that even one questionable haplotype with incorrect phasing can spoil things. I would guess that we could improve the phasing by making some simple guess as to which haplotypes are real. Basically, the problem is that while HaplotypeCaller imposes ploidy on alleles, it does not do so on haplotypes, and so phasing information is diluted. With your permission I would like to merge this PR and open a new issue for improving `phaseCalls`. After all, the issue is fixed in M2, and HC now has a perfectly good MNP mode, with the caveat that it doesn't interact nicely with GVCF mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262:730,simpl,simple,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262,2,['simpl'],['simple']
Usability,@ldgauthier Thanks for the feedback -- I'll see if I can add some additional assertions about the actual alleles retained at each site that had more than the maximum.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446:27,feedback,feedback,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446,2,['feedback'],['feedback']
Usability,"@ldgauthier The issue that I've been dealing with in trying to implement https://github.com/broadinstitute/gatk/issues/5651 is that in sites with a star allele, you have two alternate alleles, so we need to provide an alternate mapping from GT to PGT there as well. For example this would be the representation of a phased deletion and a spanned SNP:. ```; chr1 10 . ACGT A 0|1 PGT=0|1; chr1 12 . G T,* 1|2 PGT=1|0; ```. Since the real ALT we're trying to phase at position 12 is the `T` with index 1, and the '*' is taking the place of the ref allele as a representation of ""no variation at this site"", this lead me to start thinking of PGT as the label for the haplotype on which the variant alt allele represented at this site appears. I thought this was consistent with the definition of PGT in the header line as. > Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another; will always be heterozygous and is not intended to describe called alleles. In the case of homozygous sites, though, this doesn't really make a lot of sense. Perhaps a clearer definition of PGT could be: ""Descriptor of which of the two phased haplotypes represented by the current phase set the alternate allele (excluding *) occurs on. Not intended to match genotype allele indices at the site."". Or to reduce confusion with genotype allele indices, we could change it to a different representation like . ""Aa""; ""aA""; ""AA"". And provide a more detailed explanation elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705643030:1105,clear,clearer,1105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705643030,2,['clear'],['clearer']
Usability,"@ldgauthier The test is much clearer now, thanks for pointing me to the example. This will end up being tested in WARP with the next GATK release and I'm not sure how easy it is to test two commits of GATK in WARP against each other. If it's possible to do that without updating the official truth data, then I could run that before we merge this. Otherwise we'll end up catching any issues when we update WARP after the next GATK release (which I'm motivated to do when the time comes).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159220666:29,clear,clearer,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159220666,2,['clear'],['clearer']
Usability,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:42,simpl,simple,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124,2,['simpl'],['simple']
Usability,"@ldgauthier This ticket seems to be asking for genotype priors i.e. population allele frequencies to be learned within joint calling. If I interpret the request correctly, that's what new qual does. Can we close this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389:104,learn,learned,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389,2,['learn'],['learned']
Usability,@ldgauthier what do you think would be the implications of fixing this by either keeping the 2bp ALLELE_EXTENSION overlap or remove it. I guess that most of the time the variant is supported by a healthy number of reads and the AD/DP is perhaps a couple of reads lower that is supposed based on the PL if anything. It is more parsimonious to simply don't consider reads that don't overlap the variant but it seems to me that the 2bp was put there for a reason (increase sensitivity?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-439966204:342,simpl,simply,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-439966204,2,['simpl'],['simply']
Usability,"@ldgauthier, I've fleshed out an example calculation using the counts you provided. . ### I added the new section ""Example calculation"" to SOR documentation and go through the calcuations step-by-step:; ![Screenshot 2019-03-14 17 05 41](https://user-images.githubusercontent.com/11543866/54391591-aa15fc00-467b-11e9-8ef0-25ad5c6ade0e.png). ---; ### Simply updated AS_SOR to point to example calculation in SOR:. ![Screenshot 2019-03-14 17 05 26](https://user-images.githubusercontent.com/11543866/54391599-b0a47380-467b-11e9-91c6-23af55ad6211.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315:349,Simpl,Simply,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315,1,['Simpl'],['Simply']
Usability,"@lh3 We agree about the low-cov joint calling and have already tested it on 191 low-coverage (roughly 3-4x) samples from 1kg. The calls were identical except for one site with qual just above 30 that used to be just below, but this difference is basically arbitrary. If we simply add 15 to the qual threshold (as we should, because the new qual is systematically more permissive due to learning a minor allele fraction that may be greater than the average genome-wide heterozygosity), results are completely identical.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258436797:273,simpl,simply,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258436797,4,"['learn', 'simpl']","['learning', 'simply']"
Usability,"@lucidtronix @cmnbroad we set the *_NUM_THREADS flags in the WDL, but the changes to the Dockerfile will affect users who don't use the WDL (or don't follow it as a guideline for building their own scripts).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454:165,guid,guideline,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454,2,['guid'],['guideline']
Usability,"@lucidtronix @cmnbroad, I see for v4.0.12.0, CNNScoreVariants falls under the `EXPERIMENTAL Tool` label. When you say the tool will come out of beta, do you mean there will be a change in this label or something else? I'm writing a document that links to the CNN workflow and need to be clear on the status of the workflow. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246:287,clear,clear,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246,2,['clear'],['clear']
Usability,"@lucidtronix @mbabadi @samuelklee I think the best solution would be to establish a single, common Python environment, with a single set of dependencies, that all GATK Python tools depend on. We would establish a single docker image that has all of these dependencies pip installed, and could also include a conda env for the GATK environment for users who don't want to use the docker image. If we could do that, it would eliminate the need load per-tool conda environments. From what I've seen so far based on existing branches, the two environments we need (gCNV and CNN-VQSR) don't look that far apart in terms of dependencies. gCNV is using Theano, and CNN Tensorflow, but the rest looks [pretty close](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/1RV7--uBQ0ctlXzMH09cmr0VimpZYIU68DdxJzE60y-c/edit?usp=sharing). So a strawman proposal for the main components for a common environment would be:. Python 3.6; Numpy >= 1.13.1; Scipy 1.0.0; Theano .0.9.0; Tensorflow 1.4.0; Pymc3 3.1; Keras 2.1.1. Can you all chime on on whether you think we can converge in a single environment ? If so, it would greatly simplify things, and we can start with getting a docker image built for running travis tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451:1122,simpl,simplify,1122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451,2,['simpl'],['simplify']
Usability,@magicDGS Can you please compile (with a simple `g++ avx-all.cpp`) and run the short program below on the affected Mac and report back the output? This is basically the code being executed by GKL to determine if AVX is supported. Code to compile and run (zipped): [code.zip](https://github.com/broadinstitute/gatk/files/1310975/code.zip),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343:41,simpl,simple,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343,2,['simpl'],['simple']
Usability,"@magicDGS I could certainly do that (split out an OptionalReadFilterArgumentCollection), though we'd then need to add a ""requiresReadFilters"" method to determine which to use. I guess it depends on how common that case would be. An simple alternative would be to just override makeReadFilter and reject any command line filter requests or do any custom filter handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121:232,simpl,simple,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121,1,['simpl'],['simple']
Usability,@magicDGS I'd much prefer to keep this as simple as possible. It should be fairly easy to introduce a shim layer between the GATK walker classes and your tool classes that overrides whatever methods you'd like to customize. We could certainly consider changing the way the CommandLineProgram methods are factored if that helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549:42,simpl,simple,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549,2,['simpl'],['simple']
Usability,"@magicDGS If you think an AbstractPluginDescriptor would be useful, I'd suggest initially creating a separate PR in GATK, since that would make it easy to see to how it simplifies the existing descriptors. Then once that converges, we can move the abstract part to Barclay.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101219:169,simpl,simplifies,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101219,2,['simpl'],['simplifies']
Usability,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:1047,learn,learning-combined-copy-number,1047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259,3,"['Simpl', 'learn']","['SimpleAnnotatedGenomicRegionUnitTest', 'learning-combined-copy-number']"
Usability,"@magicDGS Review complete for now. Looks good but I have some nitpicks. I think they're almost all due to it being ancient gatk3 code that no one has updated in a long time. I'd recommend dropping the deprecated formats and only supporting mpilup single sample format which should allow for massive simplification of both the Codec and the Feature. . We need some unit tests for the codec itself since it has a bunch of different potential error cases, and we should have some integration tests for the tool that show it correctly failing on cases with errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179:299,simpl,simplification,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179,1,['simpl'],['simplification']
Usability,"@magicDGS Sorry for the delayed reply, I had to see what direction the `HaplotypeCaller` branch would take before I could answer your post above. In order to get the `HaplotypeCaller` performance up to acceptable levels we've had to make some changes to the traversal that have caused it to diverge quite a bit from the idea of a `SlidingWindowWalker` in this branch. Also, the way `SlidingWindowWalker` handles the `intervalsForTraversal` (using them to select fixed-size windows) is not compatible with what the `HaplotypeCaller` currently requires. As a result, I recommend that we merge your `SlidingWindowWalker` in as a separate traversal rather than trying to reconcile it with the `HaplotypeCaller` branch and mutate it into something that might not be as useful to you. Fortunately, walkers in GATK4 are simple enough that it's perfectly fine to have several similar-but-subtly-different walker types, provided they all serve actual use cases. I'll",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-204134447:813,simpl,simple,813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-204134447,1,['simpl'],['simple']
Usability,"@magicDGS The GATK versioning scheme is not related to the API -- it is targeted at end users rather than projects using GATK as a library. Here's a slide that explains it:. <img width=""824"" alt=""gatk_versioning"" src=""https://user-images.githubusercontent.com/798637/38042254-e5bb85a4-3281-11e8-8d83-017bb6b73fda.png"">. As the slide mentions, we have given some thought to supplementing the main version number with an ""API version number"", but we'd have to more clearly define what constitutes the official public API for the GATK before doing so. On a side note, now that we're in general release it may be easier for you to get PRs for things like new walker types merged into the GATK proper, particularly if they are fairly self-contained and don't involve refactoring lots of engine classes. I was planning to ask whether you wanted to resurrect your `SlidingWindowWalker` PR at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968:463,clear,clearly,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968,2,['clear'],['clearly']
Usability,"@magicDGS The HaplotypeCaller traversal has undergone some changes in the past few weeks to improve performance and bring the output of the tool closer to GATK3. There is now an `AssemblyRegionWalker` that divides the intervals into active and inactive regions, in a greatly simplified version of the GATK3 traversal. Initially, I did plan on having `AssemblyRegionWalker` extend the former `ReadWindowWalker`, or an adapted version of your `SlidingWindowWalker`, and I did implement it like this at first, but ultimately I collapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:275,simpl,simplified,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,3,"['clear', 'simpl', 'usab']","['clear', 'simplified', 'usability']"
Usability,"@magicDGS This PR is necessary for my work on Mutect2, but I'm out on Monday and Tuesday anyway. If #2154 is merged before Wednesday then all is fine; otherwise I can simply re-instate `PerReadAlleleLikelihoodMap` in this PR and delete it in a later PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-255604622:167,simpl,simply,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-255604622,2,['simpl'],['simply']
Usability,"@magicDGS Yes, I think it would be much simpler if we had one PR with all of the fixes for the validation rules (and related help issues). The extensibility changes we've been discussing should be a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318:40,simpl,simpler,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318,2,['simpl'],['simpler']
Usability,"@magicDGS Yes, it was the additional commits beyond 6d1cbf5 that I was referring to (and it wasn't clear to me whether **all** of the code review requests were in that commit, or if some were distributed amongst the other commits with the additional changes). In general I think once we start a review, the only changes should be based the code review requests. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-271587711:99,clear,clear,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-271587711,2,['clear'],['clear']
Usability,@magicDGS You need to resolve the conflicts yet again and respond to the comments I made about the `SimpleIntervalTestFactory` then this could probably be merged,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340836437:100,Simpl,SimpleIntervalTestFactory,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340836437,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,@magicDGS very simple comments 👍 when addressed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271648869:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271648869,2,['simpl'],['simple']
Usability,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:520,usab,usable,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600,2,['usab'],['usable']
Usability,"@magicDGS:. 1. Yes, you're right that you're already correctly testing that you get the right number of shards back. No need for an extra assertion. 2. I think that realistically-sized reads (of differing lengths!) does add to the unit test, since it's important to test with reads that overlap extensively with other reads. You'll also want to vary the read lengths to test with reads of different lengths at the same start position, shorter reads that start after longer reads, and any other arrangements that are significant to your `ShardingIterator`. . It shouldn't be too difficult to write a simple method that uses `ArtificialReadUtils` to create small pileups of reads within a given interval (might be worth extracting into `ArtificialReadUtils` itself so that future tests can use it).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389998139:599,simpl,simple,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389998139,2,['simpl'],['simple']
Usability,"@magicdgs You could include this filter in ReadTools and the plugin would discover it - after all, thats part of the purpose of plugins ;-). Anyway, at a minimum we should make sure the doc clearly explains when/how to use this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393:190,clear,clearly,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393,2,['clear'],['clearly']
Usability,"@marchoeppner `MarkDuplicatesGATK` was removed because it had fallen out-of-date with respect to the version in Picard, and as an unmaintained tool was in our view not safe for use, and was causing confusion for our users. The loss of CRAM support is an unfortunate side effect of its removal. We've been doing a lot of work on our parallel version of `MarkDuplicates`, however, which is called `MarkDuplicatesSpark`. This version is fully up-to-date with respect to the Picard version, can run much faster than the Picard version when multiple cores or multiple machines are available, and will fully support CRAM in the future. CRAM support in that tool will come as a side effect of our migration to the new Disq library (https://github.com/disq-bio/disq), which is scheduled to happen within the next few months. In the meantime, I'd suggest continuing to request the Picard community to add CRAM support to their version. It's likely not a lot of work, and may simply require passing the reference through to the reader class, which could be a ~1 line change!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5218#issuecomment-424882567:966,simpl,simply,966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5218#issuecomment-424882567,2,['simpl'],['simply']
Usability,"@matthdsm this was intentionally left out of the recent 4.6 release, but should go into the next minor release. Would of course appreciate any testing/feedback from the community before then!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2200883096:151,feedback,feedback,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2200883096,2,['feedback'],['feedback']
Usability,"@mbabadi Ah, well file-based I/O would be the simplest option of all, of course, and should definitely be considered as a candidate solution to this ticket, particularly if you've already tried it and found the performance penalty to be minimal for your use case (@cmnbroad take note). The division of labor you describe between Java and Python sounds great, by the way -- exactly the sort of approach I was hoping you'd implement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-337319853:46,simpl,simplest,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-337319853,2,['simpl'],['simplest']
Usability,"@mbabadi I've updated my PR to use miniconda3. @mbabadi @lucidtronix @samuelklee I think we should aim for tools that at least run out-of-box, without depending on any out-of-band configuration other than the conda env. On top of that we can provide guidance/configs for users on how to enable further optimizations, like g++. Does that sound like an achievable goal ?. As for the docker, we're going to have strike the right balance between image bloat and performance(including test performance). I think we're around 4+ gig now, and counting. Before the Python integration we were at 1.9G, and trying to find ways to reduce it. So lets see where we wind up but keep that in mind. Finally, we need to find a way to install the (GATK) python package(s) without depending on access to the GATK repo. Right now I think the gCNV branch has a ""pip install from source"" added to the conda env .yml. That will work on the docker at the moment (and thus on travis), but that won't work for non-docker users how don't have source/repo access. Also, one of the proposals to reduce the size of the docker is to remove the repo clone that is currently there. My proposal is that we change the gradle build to create an archive/zip of the python source (this would include the VQSR-CNN package code as well as gCNV kernel). We can then copy that on to the docker image, and pip-install it from the copy. That would retain the ability to always run travis tests based on the code in the repo, and also keep the nightly docker image in sync. We'll also have deliver the archive as an artifact somehow (perhaps including PyPi) for non-docker users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277:250,guid,guidance,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277,2,['guid'],['guidance']
Usability,"@mbabadi commented on [Fri May 19 2017](https://github.com/broadinstitute/gatk-protected/issues/1069). This is a long shot, but the idea is to be able to learn biases from mixed N/T cohorts. In a way, this is similar to semisupervised learning where the _stiff_ integer-state HMM on normal samples lead the way of learning biases (as a matter of imposing a strong copy-neutrality prior), and tumor samples along with a _loose_ infinite HMM provide additional (though generalically less) statistical power. Weak tumor-in-normal contamination can be handled using an adaptive integer-state HMM where the quantizied copy ratio states are chosen uniformly, though, adaptively. In the future, we must move toward a generic CLI tool called something like FancySchmancyCNVCaller that can perform the following tasks in its idealized form:. - create PoN and make calls from normals; - create PoN and make calls from tumors (possible with iHMM); - create PoN and make calls from mixed normals and tumors (possible with iHMM); - make calls from a given model on normals; - make calls from a given model on tumors; - make calls from a given model on mixed normals and tumors. The tool would then additionally take a sample annotation table (normal, tumor) and perform its job. For the first release, all samples have be annotated as normal; otherwise, an UnsupportedFeatureException is thrown.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3004:154,learn,learn,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3004,3,['learn'],"['learn', 'learning']"
Usability,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1055). At the moment, we:; - Remove targets with possibly bad (NaN, infinity, negative) values; - Remove targets that have uniformly low coverage across all samples. Perhaps we should consider adding more filters:; - Remove targets with very high and very low GC content (can be done in the CalculateTargetCoverage step); - Remove targets with lots of repeats and anomalously low mappability (can be done in the CalculateTargetCoverage step); - In the learning mode, remove a target if _too many_ are masked across the samples (in that case, max likelihood parameter estimation is unreliable). This must be done after careful evaluations, i.e. only if certain features makes a target prone to bad calls no matter what.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2991:548,learn,learning,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2991,2,['learn'],['learning']
Usability,"@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1056). Here's a relevant conversation we had:. **David**: At some point we should consider ditching Viterbi altogether, since you can segment using the forward-backward result eg setting the call at each target to be the max posterior value. If it works equally well or better it would simplify stuff. **Mehrtash**: Sam and I had a lengthy discussion about this. The Viterbi result on one hand, and what you get from stacking MAP on each target one the other hand, can be (very) different. One can think of the former as the ground state of the entire system and the latter as the most favorable local state after tracing out the rest of the system. What we thought would be interesting to do is to:; (1) segment based on Viterbi,; (2) segment based on stacking local CR MAP, and; (3) generate a swarm of hidden state samples from the HMM, segment each sample, and create a 1D density plot for state transition ""hotspots"". The hope is that (1) gives us the best overall hidden chain (which may sacrifice local calls), (2) gives us target-resolved genotypes, and (3) gives us some insight about ""excitations"" about the Viterbi state, i.e. (3) is something between (1) and (2). **Samuel**: I think breakpoint probabilities based on sequences drawn from the joint posterior (3) would be most useful, but let's see how these look in real data.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2993:382,simpl,simplify,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2993,1,['simpl'],['simplify']
Usability,@mbabadi commented on [Thu May 18 2017](https://github.com/broadinstitute/gatk-protected/issues/1059). We have to learn the upcoming Nd4j _workspaces_ and use it to reduce the memory footprint of gCNV. It is already merged but the latest Nd4j release (0.8.0) doesn't have it yet. API:; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-buffer/src/main/java/org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.java; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-buffer/src/main/java/org/nd4j/linalg/api/memory/MemoryWorkspaceManager.java; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/memory/abstracts/Nd4jWorkspace.java; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-buffer/src/main/java/org/nd4j/linalg/api/memory/MemoryWorkspace.java. Tests:; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/workspace/BasicWorkspaceTests.java; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/workspace/EndlessWorkspaceTests.java; https://github.com/deeplearning4j/nd4j/blob/master/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/workspace/SpecialWorkspaceTests.java,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2996:114,learn,learn,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2996,1,['learn'],['learn']
Usability,"@mbabadi commented on [Wed Oct 19 2016](https://github.com/broadinstitute/gatk-protected/issues/748). At the moment, CalculateTargetCoverage simply counts the number of overlapping reads with each target. Optionally, low quality calls are hard filtered. Here, we propose a probabilistic approach that avoids the usage of hard filters and fits well with the new probabilistic target coverage modeler. By definition, mapping quality MAPQ = -10 \log_10{mapping position is wrong} (see http://samtools.github.io/hts-specs/SAMv1.pdf, pg 5, item 5). It is defined in the range [0, 2^8-1]. The specific value 255 is reserved for when MAPQ is not available. Most MAPQs are well below 255. We consider the following process for assigning reads to each target. Pick a read ""k"" aligned to target ""t"" with a given MAPQ_k. By definition, it maps to the genomic position ""x"" with p_x = 1 - 10^{-MAPQ_k/10}, and to some other position with probability 1 - p_x. We refer to the alignment genomic position of read k as x_k, and the exome target(s) it overlaps with T_k. Let's assume we have T exome targets, and let z_{kt} be a 1-of-#T indicator variable for a read where t is a target and #T is the number of all exome targets. \pi_{kq} = P(z_{kq} = 1) =. p_k x O_{kq} if q \in T_k; (1 - p_k) / (#T - #T_k) if q \notin T_k. Here, O_{kq} is the fractional overlap of the read to an exome target q. Note that since we don't have the information about the next best alignment position, we take a flat prior. Finally, the number of reads belonging to target t, n_t, reads as:. n_t = \sum_k z_{kt}. Since there are many reads, n_t will be approximately Gaussian. It is an elementary calculation to calculate coverage mean E[n_t] and coverage variance var[n_t] in terms of \pi_{kq}. In the probabilistic target coverage model, var[n_t] will be added to the statistical noise. So, the read count collection will have two entries for each target: coverage mean, and coverage variance. ---. @mbabadi commented on [Wed Oct 19 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2908:141,simpl,simply,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2908,1,['simpl'],['simply']
Usability,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:53,learn,learned,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074,2,['learn'],['learned']
Usability,@meganshand 1 very minor comment about the tests. 👍 After that. This is awesome to find such a simple solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2629#issuecomment-297761108:95,simpl,simple,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2629#issuecomment-297761108,2,['simpl'],['simple']
Usability,"@meganshand There is a warning in the docs for `ReadCoordinateComparator` that it should not be used for bam file output that needs to match the ordering of `SAMRecordCoordinateComparator` exactly, since it sorts all unmapped reads after all mapped reads. `ReadCoordinateComparator` is a comparator for `GATKRead`, and that interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return null/0. This was done mainly for consistency reasons and to simplify client code. Whenever we need bam file order for reads in GATK4, we operate on SAMRecords directly and use either the `SAMRecordCoordinateComparator` from htsjdk or the `HeaderlessSAMRecordCoordinateComparator` (for headerless Spark reads) that produces the same ordering. I recommend addressing this for this tool via `presorted = false` for now, since the GATK3 version has it set to false as well with the comment: ""**we don't want to assume that reads will be written in order by the manager because in deep, deep pileups it won't work**"". This suggests that even if you were to change the comparator used by this tool to behave like `SAMRecordCoordinateComparator`, you'd still have ordering issues in deep coverage areas. It's worthwhile, though, to open a separate ticket to explore whether `ReadCoordinateComparator` could be changed to exactly match bam file order. Eg., perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to `GATKRead` to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518:623,simpl,simplify,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518,1,['simpl'],['simplify']
Usability,"@meganshand commented on [Thu Feb 16 2017](https://github.com/broadinstitute/gatk-protected/issues/907). Using a tiny bam file that I typically use for testing while running the CNV wdl on the cloud, I got the following errors (the tiny file is here: `gs://broad-dsde-methods/takuto/test_files/small_NA12878_hg19.bam`):. 1. The output tsv from TumorNormalizeSomaticReadCounts contained NaNs; 2. TumorPerformSeg threw the following error:. ```; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp; [February 16, 2017 3:23:02 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation --tangentNormalized /cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output small_NA12878.seg --log2Input true --alpha 0.01 --nperm 10000 --pmethod hybrid --minWidth 2 --kmax 25 --nmin 200 --eta 0.05 --trim 0.025 --undoSplits none --undoPrune 0.05 --undoSD 3 --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [February 16, 2017 3:23:02 PM UTC] Executing as root@3addd2d7b373 on Linux 3.16.0-0.bpo.4-amd64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: Version:c17c8ed-SNAPSHOT; [February 16, 2017 3:23:04 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=185597952; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:932,undo,undoSplits,932,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,2,['undo'],"['undoPrune', 'undoSplits']"
Usability,@mehrzads Thank you for posting about this issue. Have you been able to demonstrate different ref-confidence calls in active regions as a result of changing USE_CACHED_READ_INDEL_INFORMATIVENESS_VALUES? It would be simple enough to add a defensive check to ensure the reads have their transient fields purged between calls to the ReferenceConfidenceModel to be absolutely sure there is no issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874:215,simpl,simple,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874,2,['simpl'],['simple']
Usability,"@mlathara Apologies, my comment was confusing. See replies below:. - I should have clarified when I said that my workspace where I simply removed the extra contigs ""executes just fine for SelectVariants"". The job start progressing (slowly) without extreme/overt errors. . - Regarding ReBlockGVCFs: the problem here is that I'm basically starting at step zero. It's not trivial to process >2000 gVCFs into genomicDb workspaces. Re-making all those gVCFs and then restarting the entire import is a huge hit. We already decided to only make workspaces with 250-500 samples (since it just wasnt working to go higher), and even that's a lot of computation time. I gotta be honest, I'm pretty close to abandoning GenomicsDB and looking at other solutions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211423602:131,simpl,simply,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211423602,2,['simpl'],['simply']
Usability,"@mlathara I think we're talking a bit in circles. The main use case I foresee for a generic split/merge tool would be to allow parallelized processing. I cant say there wouldnt be other uses I'm not seeing now (in the VCF world, SelectVariants is an extremely useful tool), but i dont have a specific use-case for GenomicsDB subsetting today beyond this. . I would point out this rapidly gets into specifics and quirks of any one user's infrastructure. I dont actually mind copying the GenomicsDB workspace prior to appending to it, because processing occurs on shared lustre space, while our permanent data lives on other disk space. Therefore we would probably do a copy no matter what. I agree you dont want to develop our one person's infrastructure. . The only aspect that gives me pause on your plan regarding split jobs is that GATK doesnt provide the scheduler. Sure there used to be queue and I gather GATK pushes WIDL/Cromwell (unless this changed), but we never used these. If GATK is not trying to provide the scheduler (which is better), does this really just look like: . 1) kick off X independent jobs for GenomicsDB/append; 2) each job specifies the interval(s) on which to operate; 3) Each job has no knowledge of the other jobs; 4) each job writes it's output to the same workspace; 5) Presumably there is something in place so jobs can run concurrently. This must be the new feature?. I imagine this could work. It does obligate one to have/use some kind of shared disk space, which we can handle, but could be a negative for some.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641469405:787,pause,pause,787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641469405,2,['pause'],['pause']
Usability,"@mlathara I updated my question with more details. Hope that is clear now. @ldgauthier Is this problem different from the one you talked about in #5449? Maybe I misunderstood that issue. I will try the normalization. By the way, what does this PID tag tells us 1660261_TC_T as it appears everywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5944#issuecomment-493098861:64,clear,clear,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5944#issuecomment-493098861,2,['clear'],['clear']
Usability,"@mlathara Our primary use case involves calling variants on a constantly growing large dataset of WGS and WXS data. As you probably realize, the CombineGVCFs/GenomicsDBImport step is incredibly time consuming, and scatter/gather is pretty much essential to make these operations work in any halfway reasonable period of time. I have off-hand heard people from the broad mention large WXS datasets, and keep in mind we're working mostly w/ WGS. Regarding processing: our main downstream use right now is GenotypeGVCFs, and yes we expect to run that scatter/gather as well. I agree that in principle we could maintain these data as a folder of workspaces. In fact that was my original plan before I realized the GenomicsDB workspace already is essentially a folder of per-contig folders. The reason I like the solution of copying around the folders is b/c our end product is in an official file format that tools understand how to use. . A related point, before we decided to try GenomicsDB, my plan was to create a scheme (""file format"") that would allow our code to better operate on a folder of per-contig CombinedGVCF file. I would probably have written out a top-level JSON file that served the same purpose as the JSON files in a GenomicsDB workspace. As noted above, GenomicsDB is essentially already doing this for me. To the question about usage and support: perhaps that ways to think about this would be interval-based split and merge tools for GenomicsDB workspaces? This would obscure the internal structure of the workspace from the user (even if they basically just to folder copying). The split tool should be really simple and not have many caveats. The merge tool could have a lot of limits on what kind of workspaces can or cannot be merged. Perhaps it could do sanity checking on the JSON files to make sure they're compatible, and then copy the folders into this new merged workspace?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635338868:1631,simpl,simple,1631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635338868,2,['simpl'],['simple']
Usability,"@mlathara The nodes have considerably more (256 or so). is there any rule or thumb or guidance on expected memory needs based on number of gVCFs and/or type of input (WES vs WGS)?. I do think you might be onto something though. Out default cluster submission code takes our slurm job memory request, subtracts only a few GB and passes the remainder to -Xmx/Xms. I will update to leave more buffer as you suggest. Our cluster happens to be undergoing maintenance this week, so this particular job was killed. I'll update the GATK version, add --genomicsdb-shared-posixfs-optimizations, and adjust the memory. One other thing: i noticed GenomicsDBImport is not nearly as verbose in logging as typical GATK tools. Is that expected, or a symptom of whatever problem we're having?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656259475:86,guid,guidance,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656259475,2,['guid'],['guidance']
Usability,"@mlathara To those points:. - Yes, the test case I tried to make using GATK's test data doesnt show this. When I was working quickly I thought I repro'd it, but as you point out the REF bases for chr20:10-20 are actually Ns, so in this instance GenotypeGVCFs is doing the right thing. - Since my original posts, we figured out new information (posted above). When we simply do a SelectVariants on the genomicsDB workspace over these intervals, it produces a gVCF with Ns listed as the reference. In the actual reference, those sites are not Ns. That's making us look in a different direction than I originally thought. Our current plan is to remake one of our workspaces (exome data from ~800 samples) and see if this repros.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7018#issuecomment-755549351:367,simpl,simply,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7018#issuecomment-755549351,2,['simpl'],['simply']
Usability,"@mlathara and @nalinigans A couple quick updates:. - ReblockGVCFs reduced gVCF size by 5-8x as advertised. I re-ran this on our ~2000 gVCFs, which is possibly one of the main reasons for improvement below.; - This meant we needed to scrap all existing workspaces. As a side comment, the poor tools around manipulation of GenomicsDB workspaces is a pretty major disadvantage. Your guidance seems to suggest they are designed as a quasi-permanent store of gVCF data. Maybe I'm missing something, but this doesnt seem very workable anymore. Any need to modify any sample that went into the workspace means the whole thing needs to be re-created. For example, we also plan to re-generate some older gVCFs with the newer HaplotypeCaller at some point in the future, and doing this would also mean we need to scrap any existing workspaces. ; - For this round, I started with the 2000 gVCFs, and ran scatter jobs where each has ~1/750th of the genome, split more or less evenly (i.e. no attempt yet to intelligently design borders). Unlike before, each job creates the workspace on-the-fly, and then immediately uses it for GenotypeGVCFs. The workspace is basically a throw-away intermediate file. As far as computational time, this is not that bad (at least for very small intervals/job). I also did not bother running consolidate on these, and imported with a batchSize of 50.; - With the limited interval GenomicsDB workspaces, GenotypeGVCFs runs reasonably well. . So some open questions:. - It's unclear why running GenotypeGVCFs with a GenomicsDB workspace that has intact chromosomes, even when using -L over a small interval, fails to run or runs painfully slowly with extremely high memory. I will try to find time for actual profiling, but this is a little cumbersome since I'm not sure I can run this on my windows dev machine. As noted above, given how awkward maintaining genomicsdb workspaces is, I'm currently thinking that we should view these as transient stores and not bother saving them a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297:380,guid,guidance,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297,2,['guid'],['guidance']
Usability,"@mohitmathew Yes, we are still working on this! The PR is not yet in a usable state, but we intend to finish it for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1680822021:71,usab,usable,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1680822021,2,['usab'],['usable']
Usability,"@mwalker174 ; Hi Mark, I've finished writing the tests and would you please check again?; Here's the log running the whole pipeline (the number of simple variants extracted is approximately 1.5X the number of complex variants):. ```; .... below is output for complex variants only; 23:09:25.288 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 23:09:25.288 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 1334; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - INS: 0; ..... below is output from this tool; 23:09:48.167 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 688 variants.; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - INV: 1; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 125; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - INS: 562; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 0; 23:09:48.215 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1555 variants.; 23:09:48.216 INFO StructuralVariationDiscoveryPipelineSpark - INV: 21; 23:09:48.216 INFO StructuralVariati",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-389343644:147,simpl,simple,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-389343644,2,['simpl'],['simple']
Usability,"@mwalker174 ; Thanks!. To answer you question about the END==POS insertion variants, . First quote the spec; > For precise variants, END is POS + length of REF allele - 1,. Now for simple insertions, the REF allele is a single base allele, which by the above definition forces be equal to POS. Second, if you look at the 4th variant (insertion) on page 11 of the spec version 4.2, END == POS. So I'm following the VCF spec. It's a little ambiguous as the spec doesn't give any example for replacements, i.e. some ref bases are replaced by other bases, so; * when the ref sequence being replaced is <50bp, I emit ""fat insertion"", as documented here. ; * when the replaced region is >49 bp, a DEL call is emitted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-391559827:181,simpl,simple,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-391559827,2,['simpl'],['simple']
Usability,"@mwalker174 If the reads in your bam are failing `WellFormedReadFilter`, then the GATK (generally speaking) can't handle them. Reads must pass at least that filter in order to be usable by GATK. Are you able to modify the bam to add read groups, etc., to allow the bam to pass the filter? If not, it is theoretically possible to disable `WellFormedReadFilter` using the `--disableReadFilter` argument, but I don't recommend it...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-254623625:179,usab,usable,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-254623625,2,['usab'],['usable']
Usability,"@nalinigans For AD, I don't think we care about the distinction between '.' and 0. If AD is the only problematic field, and we're not seeing any issues with PL or any other attribute, then I'd advocate for a simple '.' -> 0 translation (for AD only!) within GenomicsDB, if such a thing is possible. @ldgauthier do you agree?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676514387:208,simpl,simple,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676514387,2,['simpl'],['simple']
Usability,"@nalinigans I was looking over the contents of this workspace and thought I'd pass along a couple observations. This is focusing on chromosome 20. This workspace has 573 WGS samples. When I inspect the contents of 20$1$77137495, there is one sub-folder with a GUID-based name. This make sense b/c we previously ran the standalone consolidate tool on it. Within this folder, a lot of these .tdb files are 10GB or larger. The biggest is PL_var.tdb (34G). END is 15GB, GQ is 15, etc. I dont really now how GenomicsDB/GATK handles reads, but do those sizes stand out to you?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211345652:260,GUID,GUID-based,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211345652,1,['GUID'],['GUID-based']
Usability,"@nalinigans I will see how feasible that is on our cluster. Another question: I'm still baffled at the sort of issues we keep having if GenomicsDB is really used that widely. One question: I have been viewing the aggregated workspace as a semi-permanent store (more like a database). Rather than that, do most users just make the workspace on-the-fly, use it immediately, and then discard? I was thinking overnight about this, and I'm wondering if we should simply drop the idea of even trying to make workspaces with whole chromosomes. I *think* we could scatter 1000 jobs for the genome, give each a coordinate set, then import the 2000 gVCGs into a workspace of only 2m sites or so, do GenotypeGVCFs, and discard that workspace, and then merge all those VCFs. I thought in the past I read guidance that the GenomicsDB workspace needed to import intact contigs. However, if the only downstream application is to run GenotypeGVCFs on a the same targeted region, is there any reason that woudlnt work? I would hope that running GenomicsDbImport with -L would import any gVCF variant overlapping that interval, and therefore I dont think subsetting to a partial chromosome would matter. Any comments on this would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212078765:458,simpl,simply,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212078765,4,"['guid', 'simpl']","['guidance', 'simply']"
Usability,"@nalinigans OK, thanks. I'll try to get docker going w/ intellij. to the original question/bug: is there anything inherent about GenotypeGVCFs with GenomicsDB as the source vs. a gVCF as the source that one would expect to change how GATK determines the reference allele? I have not actually run this yet, but if I'm correct on the problem this probably should repo it (an addition to GenotypeGVCFsIntegrationTest):. ```. @Test(timeOut = 1000000); public void testGenotypeGVCFsWithGenomicsDbAndForceOutput() throws IOException {; final File input = CEUTRIO_20_21_GATK3_4_G_VCF;; SimpleInterval interval = new SimpleInterval(""20"", 1, 11_000_000);; final File tempGenomicsDB = GenomicsDBTestUtils.createTempGenomicsDB(input, interval);; final String genomicsDBUri = GenomicsDBTestUtils.makeGenomicsDBUri(tempGenomicsDB);. File expected = getTestFile(""CEUTrio.20.gatk3.7_30_ga4f720357.expected.vcf"");; String reference = b37_reference_20_21;. runGenotypeGVCFSAndAssertSomething(genomicsDBUri, expected, Arrays.asList(""--"" + GenotypeGVCFs.FORCE_OUTPUT_INTERVALS_NAME, ""20:10-20""), GenotypeGVCFsIntegrationTest::assertVariantsContextsHaveNonAmgibuousRefs, reference);; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754120858:579,Simpl,SimpleInterval,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754120858,2,['Simpl'],['SimpleInterval']
Usability,"@nalinigans This iteration is on a smaller input (~600 WGS samples). Based on the info below, do you suggest changing --buffer-size or --batch-size?. To your questions:. In chromosome 1's folder (1$1$223616942), there are 26 fragments (the GUID-named folders). The sizes of book_keeping files are:. 168M; 131M; 155M; 149M; 136M; 142M; 216M; 147M; 150M; 134M; 127M; 75M; 172M; 122M; 207M; 122M; 581M; 149M; 150M; 141M; 149M; 143M; 143M; 165M; 160M; 163M. The last job failed an OOM error (the job requested 256GB and the slurm controller killed it). This is the command and output (with timestamps):. ```; 10 Apr 2022 01:56:21,275 INFO : 	/home/exacloud/gscratch/prime-seq/bin/consolidate_genomicsdb_array -w /home/exacloud/gscratch/prime-seq/workDir/344c6137-8a85-103a-821a-f8f3fc86deba/Job1.work/WGS_v2_713_2ndMerge.gdb --shared-posixfs-optimizations -a 1$1$223616942. 10 Apr 2022 01:56:21,556 DEBUG: 	01:56:21.556 info consolidate_genomicsdb_array - pid=146087 tid=146087 Starting consolidation of 1$1$223616942 in /home/exacloud/gscratch/prime-seq/workDir/344c6137-8a85-103a-821a-f8f3fc86deba/Job1.work/WGS_v2_713_2ndMerge.gdb; 10 Apr 2022 01:56:22,385 DEBUG: 	Using buffer_size=10485760 for consolidation; 10 Apr 2022 01:56:22,391 DEBUG: 	Number of fragments to consolidate=26; 10 Apr 2022 01:56:22,396 DEBUG: 	Sun Apr 10 01:56:22 2022 Memory stats beginning consolidation size=483MB resident=379MB share=6MB text=13MB lib=0 data=371MB dt=0; 10 Apr 2022 01:56:22,400 DEBUG: 	Sun Apr 10 01:56:22 2022 Memory stats Start: batch 1/1 size=503MB resident=379MB share=6MB text=13MB lib=0 data=391MB dt=0; 10 Apr 2022 01:59:22,970 DEBUG: 	Sun Apr 10 01:59:22 2022 Memory stats after alloc for attribute=END size=25GB resident=25GB share=7MB text=13MB lib=0 data=25GB dt=0; 11 Apr 2022 03:36:27,065 WARN : 	process exited with non-zero value: 137; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1095228878:240,GUID,GUID-named,240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1095228878,1,['GUID'],['GUID-named']
Usability,"@nalinigans Yes, it's been surprising me quite a bit too. When you say 'can you run SelectVariants', do you mean simply trying to select from the source GenomicsDB workspace as a test to see if java has enough resources? I can try this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1201585570:113,simpl,simply,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1201585570,2,['simpl'],['simply']
Usability,"@nalinigans on a related perf question: there are posts about workspaces with lots of small contigs being a problem. There are some recommendations out there about creating multiple workspaces where each has one contig or a subset of contigs. Can you say any more about where that overhead comes from?. Given we have an existing multi-contig workspace, and aggregating this many samples into a workspace is pretty big task, are there any ways to separate the existing workspace into a bunch of single-contig workspaces? The only metadata that I see referring to contigs is vidmap.json. For example, subsetting a workspace could be something simple like this:; ```; # DB refers to the original, and LOCAL_DB is a copy with just one of the contigs:; mkdir $LOCAL_DB; cp ${DB}/__tiledb_workspace.tdb ${LOCAL_DB}/; cp ${DB}/callset.json ${LOCAL_DB}/; cp ${DB}/vcfheader.vcf ${LOCAL_DB}/; cp ${DB}/vidmap.json ${LOCAL_DB}/; ln -s ${DB}/20\$1\$77137495 ${LOCAL_DB}/; ```; Using this subset workspace seems to execute just fine as an input for SelectVariants.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211342015:641,simpl,simple,641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211342015,2,['simpl'],['simple']
Usability,@nalinigans thank you very much! do you have any guidance on what a reasonable batch size might be?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081056829:49,guid,guidance,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081056829,2,['guid'],['guidance']
Usability,@nh13 I wrote a test for your branch (its very simple it just reruns the gvcf mode tests with --disable-optimizations enabled) that should work for your branch. Its in the branch je_addTestForDisableOptimizations. Since you submitted this PR from your own clone of the GATK I cannot push this onto the branch as it stands. Would you be able to copy it into this branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7125#issuecomment-793077846:47,simpl,simple,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7125#issuecomment-793077846,2,['simpl'],['simple']
Usability,"@nh13 in particular should give feedback on whether these guidelines are useful, or if additional clarity is needed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93779237:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93779237,2,"['feedback', 'guid']","['feedback', 'guidelines']"
Usability,"@obigriffith Right, but the expression you cited did reference attribute(s) that don't exist in the variants you cited as not being filtered (I'm not saying its intuitive, just that this explains whats happening). . i.e. I think you cited this variant:. `chr6 54228213 . A G 412.77 PASS AC=2;AF=1.00;AN=2;DP=12;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=52.55;QD=28.71;SOR=3.442 GT:AD:DP:GQ:PL 1/1:0,11:11:33:441,33,0`. as not being filtered when used with this expression:. `""QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 3.0""`. Even though this has an SOR value that meets the filter criteria, the expression is short-circuited when applied to that variant because it has no `MQRankSum` attribute. This results in a PASS. If you have a counter example, or I'm missing something, please do let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436040103:161,intuit,intuitive,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436040103,2,['intuit'],['intuitive']
Usability,@pawel125 This looks like a filesystem error - `I/O error in the advisory file locking logic (disk I/O error)`. Are you using an NFS file system to store the datasources or some other kind of network-mounted drive?. To be clear - the first issue you had was **not** a typo. The v1.7 data sources are not backwards compatible and the code changes haven't been merged yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661885327:222,clear,clear,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661885327,2,['clear'],['clear']
Usability,"@pgrosu, would you like to try your hand at writing a minimal repro for the bug? This would be useful, and this doesn't require signing anything. You could then submit it as a bug report (or to SO for feedback first).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694945:201,feedback,feedback,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694945,1,['feedback'],['feedback']
Usability,"@pieterlukasse Yeah - I'm planning on updating some of the Funcotator core to be more permissive for input data types and to fix a few long-standing bugs, but have been unable to do so because of other high-priority tasks (as @lbergelson said). The output formats are pretty well-established, so I don't think there's any risk in writing an additional parser. However if you simply want to view the outputs, you can render the annotations in `MAF` format and that will produce a `MAF` (TSV) file that is much more easily viewed / parsed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1379018376:375,simpl,simply,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1379018376,2,['simpl'],['simply']
Usability,@pogodina-nadezda This is expected behavior but it's unintuitive and not necessarily ideal. ; The AD is calculated based on the best match of each read to each possible haplotype during assembly. It's not based on the pileup at the site. So a read that has no quality at a site might still be counted towards that site if it matches the relavent assembled haplotype better than any alternative one during the read scoring phase. . @jamesemery This is the second time in 2 days that we've had questions about this though so it's clearly confusing and maybe not the best solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9014#issuecomment-2432448921:528,clear,clearly,528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9014#issuecomment-2432448921,2,['clear'],['clearly']
Usability,"@ronlevine I know this a port from gatk3, but I think theres a bit of refactoring that can be done. It seems like it's more complicated than it needs to be. Could you take a look and see? In particular I'm not sure why things get converted to a bitset, it looks like you should just be able to derive the indecies directly and avoid creating a bitset. If I'm missing some detail and it can't be simplified let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049:395,simpl,simplified,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049,1,['simpl'],['simplified']
Usability,"@sahilseth This is actually a different issue. The solution is to not run `CollectSequencingArtifactMetrics` and any other tools involved in orientation bias filtering. Single-end reads do not have orientation bias artifacts and the whole model assumes paired reads. For the record, we recently deprecated `CollectSequencingArtifactMetrics` and `FilterByOrientationBias` in favor of our new orientation bias workflow that uses `LearnReadOrientationModel`. But for single-end sequencing you shouldn't use the old workflow or the new workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485923047:428,Learn,LearnReadOrientationModel,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485923047,1,['Learn'],['LearnReadOrientationModel']
Usability,"@samuelklee . The CNLoH are probably artifacts (faux-CNLoH) -- I think I misdiagnosed. However, there are other changes in this PR and we can always disable the faux-CNLoH pruning by default (there is a flag). Additionally, artifact or not, it is useful to remove the faux-CNLoH. Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. Two comments: ; > If these events were indeed not CNLOH, as we discussed, then I don't think we should merge this. Perhaps we should take a step back and answer definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. I am pretty sure that most common germline regions are being blacklisted already. The hotspots addressed in this PR (faux-CNLoH) could be added, but I think we will find new areas and a few of these areas were rather big. I have users that are actively using this from the branch, for reasons other than the faux-CNLoH pruning. Results are improving without an appreciable hit to sensitivity, which we got when using parameters like num_changepoints_penalty_factor. A",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874:339,feedback,feedback,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874,6,"['clear', 'feedback', 'simpl']","['clearly', 'feedback', 'simply']"
Usability,"@samuelklee ; My understanding: the code that **can** (and I think should) be borrowed from VCF is `CHROM`, `POS`, `ID`, `INFO`, with `END` from `INFO` extracted to be its own column. ; Then; * `FILTER` can be optional.; * `QUAL` can be optional but it is a nice-to-have feature as a quick-glance confidence measure, if that applies.; * `FORMAT` is going to be hard, because I understand the complaint that they can be wasting space, but I have seen VCF files that have rows with different numbers of fields in `FORMAT`, and that is spec-compliant. If this flexibility is allowed, i.e. allowing sample specific information to be missing on several rows, then the `FORMAT` column can be shared. Recap: only `REF`, `ALT` are missing, which is not much code I believe. I think VCF just happens to have a name that starts with V. Stripping out the `REF`, `ALT`, it is quite flexible for describing any annotated interval (OK, 0-length is up for debate) on a piecewise linear coordinate. And I just made myself sound like a VCF-lover. I simply think much of it can be reused.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416:1032,simpl,simply,1032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416,2,['simpl'],['simply']
Usability,"@samuelklee DRAGEN STRE model doesn't actually make any alterations to the smith waterman parameters or how they work, it just works by adjusting the indel gap penalties that are used for the PairHMM. At one point we were concerned about SW parameters being different with dragen but as it turns out the biggest visible effect of the SW parameters on the output (the alignment we perform after haplotypes discovery) is irrelevant since they don't realign their reads internally. We kept the default gatk alignment behavior and thus the SW parameters that are used (for dangling head recovery which I believe are the old arguments) still match. As far as unifying the parameters I suspect it could be done though one wonders if there aren't risks where the different contexts in which we use the parameters will not perform as well with a unified set. Speculation on my part though. I agree with David that we should be cautious about making changes that will affect the HaplotypeCaller before November. . I support including an argument in any case (possibly multiple) to include the SW parameters. I would actually advocate we read these files in as tables of parameters where you simply point to on the command line to configure new parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993:1182,simpl,simply,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993,2,['simpl'],['simply']
Usability,@samuelklee Expanded on your feedback. Let me know if the changes are okay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151:29,feedback,feedback,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151,2,['feedback'],['feedback']
Usability,"@samuelklee I agree with your comments, but if **arbitrary** type of annotations are allowed, especially when multiple values (lists) are allowed, then it is going to look very like VCF. I was simply pre-warning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481322968:193,simpl,simply,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481322968,2,['simpl'],['simply']
Usability,"@samuelklee I support exposing these parameters via the command line, but I'd be opposed to any consolidation of parameters that changes the HaplotypeCaller output prior to the initial DRAGEN-GATK release in November, as the evaluations in that project are difficult enough as it is. If you want to do an evaluation to find the best set of SW parameters now, that's fine of course -- but we wouldn't be able to actually merge any breaking HaplotypeCaller changes until after the November DRAGEN-GATK release, and we'd also have to check whether the proposed changes affect the functional equivalence of GATK and DRAGEN (we're developing tests now that can check this). If you want to expose the SW parameters on the CLI now, I think 12 arguments is fine. Just give each argument a clear prefix indicating what it applies to (eg., `--read-to-haplotype-mismatch-penalty`). If a user has gotten to the point where they feel the need to mess with the SW parameters, their command line is probably already long and complex as it is, so adding a few additional arguments won't ruin their day.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291:781,clear,clear,781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291,2,['clear'],['clear']
Usability,"@samuelklee I think it's right for what we're doing. We mount the test data as `/testdata` and then create a symlink from src/test/resources to /testdata to provide it to the test files. It seems to work.; ; I'm not clear what they get more of the other way around. More tests? Are they using our create docker script? Or our travis file? Or something else? I think we might just be able to just directly mount test data to src/test/resources and avoid the symlink, but I probably had a reason when I set it up that way... I think this is a non-issue unless they can provide more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3730#issuecomment-339439156:216,clear,clear,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730#issuecomment-339439156,2,['clear'],['clear']
Usability,"@samuelklee I'd say lets leave 2.1 base image up there for now, and yes on the cache clearing. Once tests pass with the cache cleared it should be good to merge. Feel free to squash and rebase if you like.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408453109:85,clear,clearing,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408453109,4,['clear'],"['cleared', 'clearing']"
Usability,"@samuelklee I've incorporated your feedback and will make a new commit that reflects these shortly. Also, as mentioned in one of the comments above, the two notebooks are on the forum now at:; - [Notebook#11685](https://gatkforums.broadinstitute.org/gatk/discussion/11685/) ; - [Notebook#11686](https://gatkforums.broadinstitute.org/gatk/discussion/11686/) . Please let me know if these are okay with you. Again, most of the content should be familiar to you as I've just condensed and reorganized the explorations I had previously shared with you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475,2,['feedback'],['feedback']
Usability,"@samuelklee It wasn't just a rebase, it was a complete rewrite because the old code had since become completely entangled with DRAGEN code. But I did it! Everything is passing, the code is dramatically simpler, and it's even a bit faster. I have done my best to make a coherent commit history. I would recommend reviewing one commit at a time in side-by-side diff mode. Note that some commits rip out old code and replace it with pseudocode, deferring the new code to a later commit. Other commits tell a story of what all the different caches meant in order to motivate the simpification of later commits. The baroqueness of the old code was motivated by three considerations:; * cache-friendliness -- traversing all arrays by incrementing the innermost index, reads. This is absolutely essential.; * flattening 3D arrays into 1D arrays. This was a premature optimization.; * Precomputing addition operations -- this was misguided. The DRAGEN code relied on these caches in a rather complex way, which fortunately turned out not to be necessary and which could be dramatically simplified. My notes on tracking all the variables from the parent genotype calculator down to the DRAGEN calculator are in this google doc: https://docs.google.com/document/d/1v6s57mUAwfj38nL3VdktjA059kYBkJfokq18IDy79E8/edit?usp=sharing. Good luck and don't hesitate to ask me to explain anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476:202,simpl,simpler,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476,4,['simpl'],"['simpler', 'simplified']"
Usability,"@samuelklee Now it's back to you. I agreed with and implemented all of your suggestions. `GenotypeIndexCalculator`, `GenotypeAlleleCounts`, `GenotypeLikelihoodsCalculator` and `GenotypeLikelihoodsCalculator` (renamed to `GenotypesCache`) now have clearly-defined roles. A lot of premature optimization is gone.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1068695779:247,clear,clearly-defined,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1068695779,2,['clear'],['clearly-defined']
Usability,@samuelklee See upcoming WDL convention guide for GATK repo.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160:40,guid,guide,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160,2,['guid'],['guide']
Usability,"@samuelklee Since currently there is no tools available, I am trying to combine the CNV at interval level first. But I don't understand very clearly what the GT (genotype) 0,1,2 and CN (0,1,2,4) indicated in gVCF result. Should I filter out all entries with GT not equals to 0 as CNV events?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434476283:141,clear,clearly,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434476283,2,['clear'],['clearly']
Usability,@samuelklee Sounds like a perfect application and a lot simpler than my fix. Hopefully your rapid prototype will be faster too.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-319178018:56,simpl,simpler,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-319178018,2,['simpl'],['simpler']
Usability,@samuelklee Thanks for yor help. I created the ython package and could set up the conda environment. I activated it and run the command for DetermineGermlineContigPloidy again. Now it`s running :-). Thanks again for you very quick respons and high quality help! I am realy looking forward to the BestPractice guide for GermlineCNV calling. Thanks to all. ; I will close this issue now.; Stefan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489:309,guid,guide,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489,2,['guid'],['guide']
Usability,"@samuelklee The module can now save and load everything, including the state of the optimizer. This allows to making interesting inference pipelines. Here's a decent strategy for obtaining the global optimum (it works flawlessly on simulated data every time):. - In the first pass, one disables annealing and obtains the variational parameters in a thermal state. The temperature needs to be _high enough_ to allow most/all local minima to merge, though, not too high to allow copy numbers to travel too far away from baseline copy numbers. If this occurs, one must anneal very slowly in the next stage (see below). The results are checkpointed once converged. - In the second pass, one makes another call to the CLI tool, this time w/ annealing enabled (starting from the same temperature) and starting from the checkpointed thermal results (model params, posteriors, adam(ax) state). The annealing rate must be slow enough to prevent thermal fluctuations from getting quenched (i.e. the evolution must be quasi-isothermal). One must look for a steady and linear rise of ELBO, such that when the annealing protocol ends, SNR quickly drops to values below 1. In both runs, the learning rate must be very small (in the rate 0.01-0.05) such that we wouldn't have to worry about controlling stochastic noise. Adam(ax) quickly adjusts its moment estimates and compensates for the small learning rate, so this doesn't increase the training time significantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020:1177,learn,learning,1177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020,4,['learn'],['learning']
Usability,"@samuelklee commented on [Mon Feb 01 2016](https://github.com/broadinstitute/gatk-protected/issues/344). Segment class that was reintroduced in the germline code requires reference to collection of Targets in constructor and also stores a call, segment mean, and number of targets. ModeledSegment (used in CNV) now extends this and adds methods to transform CR/log2CR, and in turn ACNVModeledSegment (used in ACNV) extends ModeledSegment in https://github.com/broadinstitute/gatk-protected/pull/329. However, this is awkward because ACNVModeledSegment does not store a call, segment mean, or number of targets. I think we decided in https://github.com/broadinstitute/gatk-protected/issues/57, https://github.com/broadinstitute/gatk-protected/issues/61, https://github.com/broadinstitute/gatk-protected/issues/70, https://github.com/broadinstitute/gatk-protected/issues/71, etc. that Segments should simply query the relevant collection of Targets, especially for things like number of targets (which, correct me if I'm wrong, is only needed upon output to file), and that we should use SimpleInterval to represent a segment whenever possible. This obviates the need to update internally held fields when merging segments, etc. @LeeTL1220 @vruano @davidbenjamin we should probably get together and decide how these classes should be structured before moving them over into public. I expect that some of this will also resolve once CNV's output is more along the lines of ACNV's (i.e., when it outputs posterior summaries).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2836:899,simpl,simply,899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2836,2,"['Simpl', 'simpl']","['SimpleInterval', 'simply']"
Usability,"@samuelklee commented on [Wed Apr 05 2017](https://github.com/broadinstitute/gatk-protected/issues/975). Should be an equivalent of PadTargets for WGS that outputs a file specifying the bins. Alternatively, the WES coverage collection CLI should calculate padded targets on the fly. This will simplify the WDL and reduce the number of tasks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2964:293,simpl,simplify,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2964,1,['simpl'],['simplify']
Usability,"@schaluva Could I get access to a bam for that chromosome or some smaller interval that exhibits the bug and the original, non-simplified germline resource VCF? I think the error in filtering has been fixed, so I'm focusing on the first error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255:127,simpl,simplified,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255,2,['simpl'],['simplified']
Usability,"@schelhorn @ddrichel Thanks for evaluating the new PON, and sorry that it didn't resolve the precision issue! I agree that in an ideal world where grant-imposed deadlines didn't exist, and we had unlimited developer resources, fixing the issue in M2 would be the best path forward. Since we unfortunately don't live in that world, and are unlikely to have developer bandwidth to work on this issue in the near future, let me suggest an alternate path:. Since you are satisfied with the output of 4.1.8.1, and are only prevented from running that version by the log4j issue, I think your best option for now is to run a build of 4.1.8.1 with the log4j vulnerability patched out. This is very simple to create, and just involves changing the log4j version in our build file and rebuilding GATK. If you'd like to pursue this option, we'd be happy to create such a build for you, or provide instructions for creating it yourself if you prefer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535175016:691,simpl,simple,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535175016,2,['simpl'],['simple']
Usability,"@shuaiwang2 Hi, we don't currently support indexes that long. We use a bai index for bams and tabix for vcf which only support up to 512 M. You need to use a CSI index for references that large but we don't support writing those. (Reading them is weird, I think we can read BAM csi indexes but not VCF ones). . It might be possible to work around this issue by setting `--create-output-variant-index false`, although downstream gatk tools would need an index if you're sharding them. Otherwise I recommend splitting your chromosomes into two separate parts and calling on the split chromosomes. Splitting along a long region of N's should be a safe way to avoid missing any useful calls. (The telemere might be a good spot unless you have a T2T reference.). . We should probably improve that error message to make it clear what the problem is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609:817,clear,clear,817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609,2,['clear'],['clear']
Usability,"@sooheelee Anyone on engine team is a good bet to ask for a review for simple documentation changes like this. For more tool specific complex documentation changes, the tool author/maintainer is probably best.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578:71,simpl,simple,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578,2,['simpl'],['simple']
Usability,"@sooheelee Had the very reasonable question of ""what version of bwa is being used in gatk"". There currently doesn't seem to be a way to query this from the command line. Since you need the matching bwa to build the index files this is important information for the users. Ideally it could be handled by running --version on a tool that uses BWA, but that probably needs changes in the command line parser. . Simply printing the version when a tool that uses bwa starts up would probably be fine. . We added a hook in gatk-bwamem-jni to ask it what version it's using, so it should be simple just wire that up. We may want to do the same for fermilite or other packaged native code at the same time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2711:408,Simpl,Simply,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2711,2,"['Simpl', 'simpl']","['Simply', 'simple']"
Usability,"@sooheelee I think we should be able to hit Jan 9 for what I've been calling the ""ModelSegments"" pipeline, in terms of getting the new code merged into master. It will be ready to go for WGS. However, it's hard to say whether or not we'll have completed internal evaluations of this pipeline by then. These will be necessary to identify good default values for parameters that will affect sensitivity. @LeeTL1220 and @katevoss are helping out here. @MartonKN is also beginning work on an improved caller, which could potentially replace the current one before release. As for gCNV, @asmirnov239 and I will be helping @mbabadi get the python version wrapped in Java. We should be able to get at least cohort-calling mode in by release. Case calling can come shortly after if we don't manage to get it in as well. Here, we are relying a bit more on external groups to run evaluations and provide feedback, but we will do what internal evaluations we can before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339:894,feedback,feedback,894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339,2,['feedback'],['feedback']
Usability,@stefandiederich Thanks for reporting this. We'll have to take a look if it's something simple that can be changed in our code or something fundamental in the way spark process filenames.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927:88,simpl,simple,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927,2,['simpl'],['simple']
Usability,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:361,clear,clear,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113,2,['clear'],['clear']
Usability,"@t-ogasawara @frank-y-liu @gspowley @paolonarvaez @droazen @lbergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:653,simpl,simplify,653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['simpl'],['simplify']
Usability,"@takutosato @LeeTL1220 As mentioned, this change scraps all the p values and replaces it with a simple and cheap probabilistic model. All our validations either improve or stay the same and speed is much better. * Spurious active regions are reduced by almost 50%.; * DREAM 4 goes from 40 hours total CPU time to 20 hours. All DREAM genomes now take less than a day.; * Hapmap sensitivity is the same.; * DREAM sensitivities for SNVs and indels all go up a bit.; * Upon manual review we no longer make any obviously bad inactive calls, except for very long deletions, which remain an issue. @takutosato This is a higher priority review than either of the documentation PRs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3304:96,simpl,simple,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304,1,['simpl'],['simple']
Usability,"@takutosato @LeeTL1220 I set out in all good faith to port deTiN, but I believe this will be simpler, faster, and more accurate, while taking much less of our time. The proposal is so simple that it won't take long to build it and see if I'm right.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3264:93,simpl,simpler,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3264,2,['simpl'],"['simple', 'simpler']"
Usability,"@takutosato @davidbenjamin ; This is a fairly simple addition, either of you interested, or have any thoughts about how this should be done?. We have a task like this in the liquid biopsy pipeline already, it might be nice to refine it too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6692#issuecomment-653148645:46,simpl,simple,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6692#issuecomment-653148645,2,['simpl'],['simple']
Usability,"@takutosato Here's another little one. This didn't affect sensitivity in Hapmap or DREAM and in DREAM it reduced indel false positives by about half. Not a bad short-term improvement for MC3, although deep learning will handle it better.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4845:206,learn,learning,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4845,1,['learn'],['learning']
Usability,"@takutosato If you look at the previous code for realignment to a read's best haplotype it assumes that the read start within the reference haplotype byte array is the same as its start within the best haplotype byte array (see the coordinate passed to leftAlignIndels). This means that left alignment would effectively be deactivated (since the bases didn't line up correctly) whenever the best haplotype contained indels before the read start. This also creates a rare but possible edge case bug where if a read cigar ends in an indel and we miscalculated the read's start in the reference we might get an array out of bounds exception within leftAlignIndels. The recent PR #6427, which fixed some bugs involving left alignment, actually exposed this bug, because the previous code simply skipped left alignment when it encountered an out of bounds index. The fix is in the line `final int readStartOnReferenceHaplotype = readStartOnReferenceHaplotype(rightPaddedHaplotypeVsRefCigar, readToHaplotypeSWAlignment.getAlignmentOffset());` The idea is that we know where the read starts on its best haplotype from the SW alignment. In order to find the corresponding reference base, we follow the haplotype-to-reference cigar up to the read start and count the number of reference bases consumed. For example, suppose the haplotype-to-reference cigar is 30M5D100M and the read starts at (0-indexed) position 50 on the haplotype. We want to know how many reference bases are consumed in order to consume 50 alt haplotype bases in this cigar. That is, we count the reference bases in the 30M5D20M leading sub-cigar, which is 55. Thus the reference start is 55. Conversely, if the haplotype-to-reference cigar were 30M5I100M the read would start after 30M5I15M, with 45 reference bases consumed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6461:784,simpl,simply,784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6461,1,['simpl'],['simply']
Usability,"@takutosato Most of the files changed are just due to a change in method signature. Any significant block of ""new"" code is just your code moved to a different class. This PR does a few things:. * Move logic from the orientation bias annotation into the filter.; * Package F1R2 counts and learned orientation bias models in .tar.gz files to simplify command lines and accomodate multiple samples.; * Make all orientation bias tools fully multi-sample.; *Extract a backend for CollectF1R2Counts and use this backend inside Mutect2. I have tested the new pipeline on Firecloud. Do you have time to review this before the release tomorrow? If not, I can ask Lee.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5840:288,learn,learned,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5840,2,"['learn', 'simpl']","['learned', 'simplify']"
Usability,"@takutosato Since this is an unsupported script that I have already tested to make sure results are the same, don't spend much time on it. Here's the summary:. * Put sub-sampling of hapmap (the most expensive part and a one-time cost because the samples are the same every time) into its own wdl.; * Put the rest of generating the truth into the same wdl as the sensitivity validation. This will make things simpler for the TAG team.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3379:408,simpl,simpler,408,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3379,1,['simpl'],['simpler']
Usability,"@takutosato The extra strength of normal reads informing the ref allele's annotations improves results (very) slightly in all of our validations. The deeper reason for this change is in anticipation of multi-sample mode, where filtering based on a single INFO field will be simpler and probably statistically more powerful than filtering on a bunch of separate genotype fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5518:274,simpl,simpler,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5518,1,['simpl'],['simpler']
Usability,"@takutosato This indicates that something went wrong with `CalculateContamination`, but I would rather have `FilterMutectCalls` finish and say every variant is contamination than simply fail. It is a separate issue to deal with overestimates of contamination, which can occur with gene panels (too little territory to get hom alts).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5853:179,simpl,simply,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5853,1,['simpl'],['simply']
Usability,"@takutosato To be clear, this issue is from a year ago, and I'm just confirming that we can close it. This is not new bug behavior. No action required on your part besides what you just said.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443743151:18,clear,clear,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443743151,2,['clear'],['clear']
Usability,"@takutosato had a good suggestion: to stratify to low-complexity regions in the high-confidence regions. Not sure how many variants are there, but will take a look. EDIT: looks like it's ~5k / ~54k on chr22 in CHM. More generally, I think that defining the appropriate loss function for optimization to set ""default"" parameter values obviously has no unique answer. The problem is also made a little more complicated by our current strategy of sensitive calling + non-trivial filtering. But it would be great to come up with some hard constraints (e.g., we never want runtime/cost to exceed X, we always want to maintain Y metrics in these regions on these samples) and general procedures, then apply them as equitably as possible across all method/parameter changes. Also generally, I'm a bit wary of focusing too hard on the high-confidence regions, as this might lead to overfitting or could understate the potential of method/parameter changes in more difficult regions. But probably we'll have to downweight the loss or do more manual checks in low-confidence regions until we improve truth resources there. One naive question, just want to double check: is it correct that the overall scaling of each set of SW parameters is inconsequential? E.g., if I multiply each by a constant, should I expect the same results? I would expect this to be the case (unless my hazy recollection of the details of SW scoring is off) and simple experiments bear this out, but I'm not sure if there are some edge cases or idiosyncrasies in our implementation or use of the scores that I might be missing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055:1427,simpl,simple,1427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055,2,['simpl'],['simple']
Usability,"@tedsharpe , please feel free to review as well. This to me is more about learning than reviewing, though I'll try hard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1939#issuecomment-228442132:74,learn,learning,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1939#issuecomment-228442132,1,['learn'],['learning']
Usability,@tedsharpe @SHuang-Broad I've tried to address your comments -- want to have a another look? . Due to issues in the class I backed out my usage and refactoring of SATagAlignmentBuilder and SATagAlignment and just went with my own simple little parser.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060:230,simpl,simple,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060,2,['simpl'],['simple']
Usability,"@tedsharpe I've addressed some of your comments here -- all the simpler stuff plus:. - I now only make distal targets for split reads with one supplementary alignment. We can make a ticket to handle more complex cases at some point.; - I renamed the concept of strand in the `EvidenceTargetLink` and related classes -- I'm now calling it `evidenceUpstreamOfBreakpoint`.; - I canonicalize `EvidenceTargetLinks` and only create them when the source is upstream of the target. This allowed me to get rid of the de-duplication code, so thanks for the suggestion. It seemed tricky to me to try to cluster these links during the initial pass over the reads while at the same time keeping track of coherent evidence. In my testing it doesn't seem like it is slow to run over the `EvidenceRDD` again to do this, but we could think about trying to change this sometime if we're looking for optimizations. . Want to take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806:64,simpl,simpler,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806,2,['simpl'],['simpler']
Usability,"@tfenne I'm not sure we quite expect every site in the provided intervals to be covered by a variant or homeVar call. If the HaplotypeCaller deems a site to be active then it is assembled and genotyped, the `EMIT_ALL_SITES` switch is applied to the genotyper and prevents the genotyper from returning a null variant context at sites that are clearly not real variants. That does not however mean that sites that never make it to the genotyper will get returned. That means activityRegions that are not considered sufficiently active to be assembled will still not be covered in the output in `EMIT_ALL_SITES` mode. Perhaps the docs could be updated to better reflect this? If you want an estimate of the reference confidence for non-variant sites perhaps you should use a GVCF instead?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530533223:342,clear,clearly,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530533223,2,['clear'],['clearly']
Usability,"@tomwhite @davidadamsphd could you take a look and see if it's in the right direction?. Some notes:; - This is only impl'd for pure Spark at the moment. Gonna work on adding support for dataflow as well.; - It was easier to remove the `final` modifier on the `GATKRead` impl rather than reimplement all the methods and simply pass them through. Let me know if that's ok.; - Should we target Parquet IO only in the context of writing to Hadoop? Or should I make sure it works anytime a local/single bam file is being written?; - Definitely need to add more tests. One thing that's annoying is that the cleanup for `readsSinkParquetTest` doesn't seem to happen.; - Registered `AlignmentRecord` with the `GATKRegistrator`, but there aren't any tests that exercise it. There's a touch of scala-to-java ugliness there, so let me know if we should just reimplement the `AvroSerializer` class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/888#issuecomment-139423282:319,simpl,simply,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/888#issuecomment-139423282,1,['simpl'],['simply']
Usability,"@tomwhite I just took a look and I did overstate the case when I said CramContainerIterator materializes SAMRecords. It stops short of doing that, but it does crack each container open and iterate through and decompress each data block in each slice in each container as it goes along. Its not clear to me how much this affects the difference in split calc time vs. bam.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770:294,clear,clear,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770,2,['clear'],['clear']
Usability,"@tomwhite I'm confused by the following code in `samRecordOverlaps`:. ```java; for (SimpleInterval interval : intervals) {; if (record.getReadUnmappedFlag() && record.getAlignmentStart() != SAMRecord.NO_ALIGNMENT_START) {; int start = record.getAlignmentStart();; return interval.getStart() <= start && interval.getEnd() >= start;; } else if (interval.overlaps(record)) {; return true;; }; }; ```; If a record is unmapped (which necessarily implies that `getContig()` returns `null`), it checks whether its assigned start lies between the start and end of any interval in `traversalParameters` *regardless of that interval's contig*.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358089808:84,Simpl,SimpleInterval,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358089808,1,['Simpl'],['SimpleInterval']
Usability,"@tomwhite I'm looking into the performance issues now with the new code path -- it brings the output much closer to GATK3, but clearly needs some profiling work. Can you tell me what kind of difference you saw in the runtime on Spark? Eg., was it on the order of 20-30%, or was it worse than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564:127,clear,clearly,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564,2,['clear'],['clearly']
Usability,"@tomwhite That sounds like a pretty good improvement! For reasons that are not clear to me, htsjdk doesn't generate .crai index files, only .bai, so we'd definitely want something like the CramContainerHeaderIterator method for those. One other thought that occurs to me is that we should think about how to ensure that mates are kept together for CRAM. The spec doesn't require that mates be contained in the same slice, and since the default slices-per-container for both htslib and htsjdk is 1, they don't even have to be in the same container.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481:79,clear,clear,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481,2,['clear'],['clear']
Usability,"@tomwhite To clarify, I think that the caller of `ensureCapacity()`, namely `GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables()`, also needs to be synchronized in order to avoid some unlikely but still-possible races. Given this, I think that we should consider whether `ThreadLocal` might be a better option here. It's not 100% clear to me whether a `ThreadLocal` `get()` call is cheaper than a synchronized method call, but some casual googling suggests that it might be. If we're going to end up entering a synchronized method on every single call to `GenotypeLikelihoodCalculators.getInstance()`, we might want to do some research into whether `ThreadLocal` + no synchronization would be faster, since I believe that this is a performance-sensitive section of code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244:344,clear,clear,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244,2,['clear'],['clear']
Usability,"@tomwhite We host our internal WDLs for the best practices pipeline in the dsde-pipelines repository, and we're starting to put public versions in the public repo https://github.com/broadinstitute/wdl. @vdauwera recommends that we put any WDLs we write for GATK4 in https://github.com/broadinstitute/wdl as well, but within a directory that clearly marks them as experimental/unsupported.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1974#issuecomment-231770124:341,clear,clearly,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1974#issuecomment-231770124,1,['clear'],['clearly']
Usability,@tomwhite and/or @laserson should have a look at this and give JP high-level feedback on his approach to optimization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987#issuecomment-146905889:77,feedback,feedback,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987#issuecomment-146905889,1,['feedback'],['feedback']
Usability,@tomwhite this looks fine to me as a start for us to experiment with but I wish the install was simpler and so we should either include building of jbwa as part of our build or (preferable) use a pre-built version from maven central. wdyt?. back to @tomwhite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215795846:96,simpl,simpler,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215795846,1,['simpl'],['simpler']
Usability,"@tovanadler Review complete. Looks good, just a few comments. I have a few comments about the organization of duplicate marking. I think you've inherited some very old style code that could maybe use some refactoring. I think we do need to also include the histogram and the metrics headers. Those could be done in a separate ticket though. I'm a bit worried that the test is indeterministic. Unless I overlooked something which is likely, it seems like it might depend on the ordering of a PCollection which is undefined. This isn't problematic for the actual metric file, but might be for the tests. What do you think about reorganizing to output an annotation on only 1 of the ""best"" reads with the count of all optical duplicates in it's group. That would simplify the code, and since we only care about the global count it wouldn't change the information content.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958:760,simpl,simplify,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958,1,['simpl'],['simplify']
Usability,@tovanadler Thanks for the update. It's clearer this way. Do you know how the Combine.perKey is implemented? Will it scale? I'm afraid it's going to try and pulldown all metrics in a library to a single node and then iterate through them all.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/782#issuecomment-128095847:40,clear,clearer,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/782#issuecomment-128095847,1,['clear'],['clearer']
Usability,@ttbek I see your point and thank you for bringing this up. Based on your feedback we are going to create an article to better explain common GATK file types and input file formats. Sorry about the inconvenience and please continue to share your valuable feedback with us.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-640927891:74,feedback,feedback,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-640927891,4,['feedback'],['feedback']
Usability,"@vdauwera - I think that makes sense. We've been brainstorming ideas for how a user would actually input the filter strings and there seem to be a few options. - JEXL; - it's already in use elsewhere and we can use JEXL functions at the command-line to specify ""hasAtLeast(5,""D"")"" for simple filters, but it seems like it would get clunky with increasing filter complexity; - Regular Expressions; - they're fairly universal, but it would be hard to match numerical values and can be confusing/exhausting to write correctly; - Modified regular expressions, for example:; - ^D matches any number of deletions at the start; - DMD matches any number of deletions followed by any number of (mis-)matches, followed by any number of deletions; - ^<5SM>=4D$ matches less than 5 soft clipped bases at the start of the cigar, followed by any number of (mis-)matches, followed by at least 4 deletions at the end of the cigar; - Command-line options passed into the filter, for example:; - --hasAtLeast 5 D --startsWith S --endsWith M. We can also implement some combination of these. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-308850737:285,simpl,simple,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-308850737,1,['simpl'],['simple']
Usability,"@vdauwera -- just to be clear, this is only in GATK 4 M2, which is pre-release (but we're working as fast as we can).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2291#issuecomment-272664743:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2291#issuecomment-272664743,2,['clear'],['clear']
Usability,"@vdauwera Thanks for the guidance. We'll get to work. @takutosato, you were also wondering about this. Here's our answer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-328628951:25,guid,guidance,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-328628951,2,['guid'],['guidance']
Usability,@vdauwera The latest game plan for this ticket (which is being addressed in #2021) is to have SplitNCigarReads create a supplementary alignment from each split and soft clip the bases that align elsewhere. This allows the bam to be more usable by other tools (like BQSR) since the logic to handle supplementary reads already exists. This means that we need an additional argument to HaplotypeCaller so that allows using supplementary alignments (See #2043). . My question is how can we document that SplitNCigarReads is not recommended for use with the changes to make the reads supplementary until #2043 is resolved? Is it possible to make the tool hidden in GATK4 or give it some tag that makes it clear it isn't ready for use yet?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-235062440:237,usab,usable,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-235062440,2,"['clear', 'usab']","['clear', 'usable']"
Usability,@vdauwera any feedback from GATK 3.7 users? @droazen how's the Palantir tie-out doing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-272495952:14,feedback,feedback,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-272495952,2,['feedback'],['feedback']
Usability,"@vdauwera commented on [Fri Nov 06 2015](https://github.com/broadinstitute/gsa-unstable/issues/1208). Following on https://github.com/broadinstitute/dsde-docs/issues/308. This walker enables combining callsets originating from the same sample, to avoid having to re-run the variant calling. . ---. @vdauwera commented on [Fri Nov 06 2015](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-154586008). When this gets done we should notify the user in the original issue ticket. ---. @vdauwera commented on [Fri Nov 20 2015](https://github.com/broadinstitute/gsa-unstable/issues/1208#issuecomment-158551620). Hey @ldgauthier, I'm looking at the docs for this tool and I'm not clear on the acceptable scope of application based on the usage instructions:. ```; <h3>Input</h3>; * <p>; * A VCF containing pairs of samples, as uniquified by GenotypeGVCFs. The set of sample calls in a pair should be derived from WGS and WEx data for the same sample.; * </p>; ```. Does it _have_ to be WGS + WEx? Could it be WGS + WGS or WEx + Wex for example?. ```; * <h3>Output</h3>; * <p>; * A combined VCF with combined calls for each pair of samples specified and de-uniquified sample names.; * </p>; *; * <h3>Examples</h3>; * <pre>; * java -jar GenomeAnalysisTK.jar \; * -R ref.fasta \; * -T CombineSampleData \; * --variant vcf1.vcf \; * -o output.vcf; * </pre>; * <pre>; * java -jar GenomeAnalysisTK.jar \; * -R ref.fasta \; * -T CombineSampleData \; * --variant vcf1.vcf \; * --uniquified_sample_name NA12878.variant \; * --uniquified_sample_name NA12878.variant2; * -o output.vcf; * </pre>; ```. I don't get what's the difference between the first and second example. . In any case I'm not going to push this through now in light of all the TODOs:. ```; /*TODO: when this tool is moved into protected the following will have to be addressed:; * Do more robust error checking on sample name de-uniquification -- right now checks for pairs of <sampleName>.variantX and <sampleName>.variantY bu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2485:696,clear,clear,696,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2485,1,['clear'],['clear']
Usability,"@vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gatk-protected/issues/766). @vdauwera commented on [Fri Mar 06 2015](https://github.com/broadinstitute/gsa-unstable/issues/829). As @pdexheimer pointed out: . > I think the bug here is in HaplotypeCaller. It technically generated a malformed (g)VCF by using an ambiguous allele for the reference. I don't know what the fix is, though. You can't have an ActiveRegionWalker skip over the ambiguous bases since it operates on a whole region. And a post hoc check in HC would be simple enough for SNVs, but what happens when the ambiguous site is part of a larger deletion?. Needs advice on what the behavior / solution should be by @akiezun @vruano . This Issue was generated from your [forums](http://gatkforums.broadinstitute.org/discussion/4858/reference-bases-with-ambiguity-codes-in-dbsnp/p1) . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85093784). In general, don't know how HC behaves with ambiguous reference bases at all.... I would not be surprised if it just crashes or outputs garbage. Perhaps this should be part of a larger effort to make sure HC, Combine- and GenotypeGVCFs are robust on ambiguous calls. To start, currently GATK/Picard handles bases as uppercase single `byte' representation of the corresponding character. Since we are investing (a mostly wasting) 8 bits already, we could change into a bit mask representation that would allow for quick comparison of ambiguous and non-ambigous base call using bit-wise operations. NO_CALL = 0, A = 1, C = 2, G = 4, T/U = 8, N = 15, etc... . Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. . We can provide separate tools to re-ambiguate the output or reselect the r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:550,simpl,simple,550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['simpl'],['simple']
Usability,@vdauwera wouldn't it be simpler to have those docs on the github page?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151706338:25,simpl,simpler,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151706338,1,['simpl'],['simpler']
Usability,"@vidprijatelj Thanks for the report! Can you check the UMASK value in your shell? You can do this by simply typing the command `umask`. If it's set to something like 0077, that could explain what you're seeing. . GATK does not, in general, require permissions for users other than the owner of the file/directory, so it's a bit surprising that this is causing issues for you. Could you paste the full stacktrace for the exception you're getting? You may need to set `GATK_STACKTRACE_ON_USER_EXCEPTION=true` in your environment in order to get GATK to print the stack trace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1466807447:101,simpl,simply,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1466807447,2,['simpl'],['simply']
Usability,"@vilay-nference Thank you for doing this work. It's nitpicky annoying stuff to figure out.; ; I have one additional request. Instead of addding additional direct implementation dependencies, could we specify the transtive version requirements in a [gradle constraints block](https://docs.gradle.org/current/userguide/dependency_constraints.html)? . That will: ; 1. make it clear that we don't rely on these directly; 2. prevent us from keeping them around if we do something like remove hadoop in the future; 3. lets us rewrite those force blocks to instead define minimum versions so if the libraries move forward in the future we're not accidentally holding on a to an old version",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810:373,clear,clear,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810,2,['clear'],['clear']
Usability,"@vruano ; Since there's some a major change of implementation following your suggestions (single class instead of abstract-base-and-sole-inheritor, remove over-classing), I'm issuing this PR to replace #5117, so the comments you made there are easier to be kept track of. Basically, ; * the first commit is trivial; * the second commit is to address some comments you have about various utils classes; * the third commit is what's contained in #5117 ; * the fourth commit is the re-implementation, which replaces the two old classes with a new class so it's easier to read; * the fifth commit is a simple integration test for this new tool. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5164:598,simpl,simple,598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5164,1,['simpl'],['simple']
Usability,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:600,Simpl,SimpleCountCodec,600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082,1,['Simpl'],['SimpleCountCodec']
Usability,"@vruano This is so much clearer now. Much better to write your own search function that does what you want than to use the existing one with an invalid comparator and rely on the implementation to stay the same. . The only issues left I think are to create a comparator in SimpleInterval and just use that, instead of having a lot of them scattered all over the place. I think they're all compatible with doing the same thing sorting first by contig, then start, then end. That and using the new SimpleInterval(Locatable) constructor when appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/432#issuecomment-97531671:24,clear,clearer,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/432#issuecomment-97531671,1,['clear'],['clearer']
Usability,"@vruano What happens if you make your tool extend `GATKSparkTool` directly, rather than `VariantWalkerSpark`, then do the following in your `runTool()` method?. ```; final VariantsSparkSource variantsSource = new VariantsSparkSource(ctx);; final List<SimpleInterval> intervals = hasIntervals() ? getIntervals() : IntervalUtils.getAllIntervalsForReference(getBestAvailableSequenceDictionary());; final JavaRDD<VariantContext> variants = variantsSource.getParallelVariantContexts(vcf, intervals);; ```. And then do a `variants.mapPartitions()` call on the resulting `variants` RDD to process each variant?. Also, at-mentioning @tomwhite here to comment on the `VariantWalkerSpark` issue, since he wrote that class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290236139:251,Simpl,SimpleInterval,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2545#issuecomment-290236139,1,['Simpl'],['SimpleInterval']
Usability,@vruano You can do a hacky thing where you set the label to whatever you want and then when you update the progress meter create a SimpleInterval with a fake contig that includes the information you want.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577263346:131,Simpl,SimpleInterval,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577263346,1,['Simpl'],['SimpleInterval']
Usability,"@vruano commented on [Wed Oct 14 2015](https://github.com/broadinstitute/gatk-protected/issues/149). Plots required to choose some of the parameters use along the pipeline:; To have an idea how they look like and how they would be used you can refer to XHMM tutorial:; https://atgu.mgh.harvard.edu/xhmm/tutorial.shtml. These can be totally in R and you may choose to reuse XHMM original code make reference to the appropriate license; they are quite simple so probably it is not necessary:; - min and max average sample coverage (to filter extreme samples).; - Plot a histogram of the average sample target coverage to choose this cut-offs. ; - min and max std dev. coverage across targets per sample (to filter extreme targets).; - Plot another histogram but in this case of the std .dev target coverage.; - min and max average and std. dev target coverage (to filter extreme targets); - Basically the ""transpose of the two plots above so that we can filter extreme targets:; - Histogram of the mean coverage per target across samples; - Histogram of the std. dev coverage per target across samples.; - Principal components variance explained plot.; - Y is the variance explained by the component (~ eigen value).; - X is the component index where 0 is the first component and i is the ith component.; Consequently this graph is monotonic decreasing.; - Would be nice to get the component vs covariate plot to find out whether we are getting rid ; of known biases like GC content but this one may take a bit more time an might not be necessary for now in practice. . The first few plots could be done by a script that takes in a read counts file.; The principal components one may access the .pon file directly perhaps using a cran package to read hdf5 files. Otherwise you might need to write a simple tool to extract those variances from the .pon. ---. @samuelklee commented on [Wed Aug 17 2016](https://github.com/broadinstitute/gatk-protected/issues/149#issuecomment-240525897). The new germline ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2826:450,simpl,simple,450,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2826,1,['simpl'],['simple']
Usability,"@vruano has pointed out that our method of finding the best haplotype paths in an assembly graph is equivalent to Dijkstra's algorithm for finding the shortest path in a directed graph, and that the latter is a much simpler implementation. [ Do I understand this correctly?]. We could simplify a bunch of code without changing the output of any tools by switching the implementation to Dijkstra's algorithm, which is implemented in jgrapht (our graphs extend this package's graph class) and apache commons. @vruano has also pointed out that our definition of the best paths may not be optimal, which is a separate issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561:216,simpl,simpler,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561,2,['simpl'],"['simpler', 'simplify']"
Usability,@wujh2017 Great! Let us know if you have any more feedback. Please be aware that both DetermineGermlineContigPloidy and GermlineCNVCaller are still in beta. There are some parameters that may need to be tuned appropriately for your data. We are currently running evaluations and will release some recommendations that we find suitable for data generated at the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401:50,feedback,feedback,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401,2,['feedback'],['feedback']
Usability,"@yfarjoun @vdauwera I've refined the tool categorization based on feedback on the tentative categorization. Thank you @yfarjoun for the review and feedback. The refinement is reflected in the new tabbed sheet in the shared Google Spreadsheet:`1217Changes_categorization-and-assignments`. I've separated out GATK vs Picard tools for each of the categories. . Here is a summary of the changes. 1. New 11 to `Diagnostics and QC`:; AnalyzeCovariates (from Alignment, Duplicate flagging and BQSR); GatherBQSRReports (from Alignment, Duplicate flagging and BQSR); FlagStat (from Read Data Manipulation); FlagStatSpark (from Read Data Manipulation); GetSampleName (from Read Data Manipulation); Picard BamIndexStats (from Read Data Manipulation); Picard CalculateReadGroupChecksum (from Read Data Manipulation); Picard CheckTerminatorBlock (from Read Data Manipulation); Picard CompareSAMs (from Read Data Manipulation); Picard ValidateSamFile (from Read Data Manipulation); Picard ViewSam (from Read Data Manipulation). 2. Merge 14 tools remaining in `Alignment, Duplicate flagging and BQSR` with 37 tools in `Read Data Manipulation`. Keep latter name. 	51 tools. 3. Move these out of `Read Data Manipulation`:; CompareDuplicatesSpark (to DxQC); ConvertHeaderlessHadoopBamShardToBam (to Other); CreateHadoopBamSplittingIndex (to Other). 4. Move ValidateVariants into `Variant Evaluation`. Also:; `Variant Evaluation and Refinement` --> `Variant Evaluation`; `VCF Manipulation` --> `Variant Manipulation` . Let us know your thoughts. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248:66,feedback,feedback,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248,4,['feedback'],['feedback']
Usability,@yfarjoun Geraldine has promised to followup on the categorization discussion.; @samuelklee Remember that the Best Practice Workflows and related documentation will guide folks to which tools to use for each workflow. The tool docs section is meant to categorize based on function and is purposefully workflow-agnostic.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347671295:165,guid,guide,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347671295,2,['guid'],['guide']
Usability,"@yfarjoun Just to be clear, are you saying that `getMateAlignmentEnd() + 1` is ideal for forward strand reads but `read.getStart() + abs(read.getFragmentLength())` will have to do if the `MC` tag is missing, and that we can leave it as `getMateStart() + 1` for reverse strand reads?. @droazen A priori I would expect the additional cost of parsing each read's mate CIGAR to be negligible compared to other stuff we do but I also understand the virtue of being careful. Given, however, that this is invoked for every assembled read in HaplotypeCaller it should suffice just to measure the wall clock time of HaplotypeCaller. Would seeing no change there be enough?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726:21,clear,clear,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726,2,['clear'],['clear']
Usability,"@yfarjoun We should sit down at some point to discuss the best way to activate the prefetching in Picard. It may be a little less trivial than I had thought based on the above, but should still be fairly simple.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256:204,simpl,simple,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256,2,['simpl'],['simple']
Usability,"@yurivict The large files under `src/main/resources/large/` are required to build GATK, since they are packaged inside the GATK jar and used by tools at runtime. These are things like ML models and native C/C++ libraries used for acceleration of certain tools. The large files under `src/test/resources/large/`, on the other hand, are only required by the test suite when running tests. Hope this clears things up!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2223906223:397,clear,clears,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2223906223,2,['clear'],['clears']
Usability,"@yurivict There is a note in the README about this in the ""Building GATK4"" section:. ```; Note that you must have a full git clone in order to build GATK, including the git-lfs files in src/main/resources. The zipped source code alone is not buildable.; ```. However, I will edit it to make it clearer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2225898092:294,clear,clearer,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2225898092,2,['clear'],['clearer']
Usability,A PR updating beta documentation to reflect the changes in user experience with bulk ingestion. Do not merge until workspace is ready to be updated to reflect this documentation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8397:59,user experience,user experience,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8397,1,['user experience'],['user experience']
Usability,"A collection of changes in non-GVS packages required to build a working version of GVS against master:. 1. Support for an optional monitoring script for VQSR Lite `JointVcfFiltering.wdl`.; 2. `VQS_SENS_FAILURE_PREFIX ` VCF header value updated for correctness.; 3. Moved all BigQuery classes under a `gvs` package to make clear these are currently considered to be GVS specific.; 4. Added method to BigQueryUtils.; 5. ~ExcessHet calculation fixes for the case of no PLs.~ Removed, no longer required with Annotation changes in `ExtractTool`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8362:322,clear,clear,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8362,1,['clear'],['clear']
Usability,A couple unrelated tests failing; hopefully a rebase will clear those up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-240491388:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-240491388,2,['clear'],['clear']
Usability,"A few interrelated issues:. -The install_R_packages.R script is copied and installed in the base Docker image. However, it is currently also copied (but not installed) in the non-base Docker image for some reason. @jamesemery may be able to comment (#4251).; -Different R packages are installed in that script in different ways. Some are pegged to older versions sourced from http://cran.r-project.org/src/contrib/Archive URLs; this is to prevent the http://cran.r-project.org/src/contrib URLs for the most recent versions from breaking out under us, which has happened frequently in the past. Other packages are simply installed using `dependencies = ...`; -We should perhaps consider moving the R dependencies into the conda environment, see discussion in #4209.; -R dependencies are cached in a `site-library` folder in the Travis build to avoid intermittent connection issues with the aforementioned URLs. This can cause tests to break after the fact if the cache is not cleared every time a dependency is removed. If we decide to cache pip installs similarly, we will also run into this issue.; -Requiring the base Docker image to be updated every time an R dependency is changed is also fragile. If it is accidentally not updated when dependencies are removed, tests can continue to pass.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4250:613,simpl,simply,613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250,2,"['clear', 'simpl']","['cleared', 'simply']"
Usability,"A few points:; 1. When we wrote the Java interface, the 'agreement' was that the sample names would be unique and consistent within the VCF headers. Hence, the assert statement in the Java code.; 1. Having said that, the sample name in the VCF header is ignored completely if checks are disabled (which are disabled by default). This includes the assert statement and a couple of other checks in the importer code. The sample name is taken from the name to reader map provided in the constructor call. This map is created from the tab delimited file.; 1. Would it be possible to provide a simple test case to replicate the bug? I couldn't replicate it. Here is what I did.; 1. Three VCF files - t0.vcf.gz, t1.vcf.gz, t0_dup.vcf.gz. t0 and t0_dup are identical except for the GT field in one location. So, these 2 files have the same header (same sample name in the header).; 1. Tab file (unique sample names). HG00141 test_inputs/vcf_test_inputs/t0.vcf.gz; HG0155 test_inputs/vcf_test_inputs/t0_dup.vcf.gz; HG00192 test_inputs/vcf_test_inputs/t1.vcf.gz. 1. Import. ./gatk-launch GenomicsDBImport --genomicsDBWorkspace /tmp/ws -L 1:1-1000000 --sampleNameMap test_inputs/gatk4_dup_test_list --batchSize 2; 1. Query prints the output correctly. ./bin/gt_mpi_gather -j test_inputs/query/gatk4-generated.json --produce-Broad-GVCF. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG00192 HG0155; 1 12144 . G <NON_REF> . . . GT 0/0 . 0/0; 1 12191 . T <NON_REF> . . . GT 0/0 0/0 0/0; 1 17385 . G A,T,<NON_REF> . . . GT 0/1 2/2 1/1. ./gatk-launch SelectVariants -V gendb:///tmp/ws --output t.vcf.gz -R Homo_sapiens_assembly19.fasta; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG0155 HG0192; 1 12141 . C <NON_REF> . . END=12144 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 12145 . C <NON_REF> . . END=12277 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 ./.:3:0:0:0,0,0; 1 12278 . C <NON_REF> . . END=12295 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 17385 rs987;d345",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853:589,simpl,simple,589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853,2,['simpl'],['simple']
Usability,A handful of simple optimizations for VariantRecalibrator:; - Preallocate arrays when the size is known; - Eliminate unnecessary boxing of doubles; - Lift some loop invariants with unnecessary allocations (this eliminates millions of array allocations on the full SNP test used by GATK3). The current GATK4 (multi-variant walker) implementation is about 3% faster than GATK3 without these; these bring it to about 6% faster.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2186:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2186,1,['simpl'],['simple']
Usability,A lot of tutorials and information are available on our support [website](https://gatk.broadinstitute.org/hc/en-us). It includes best practice guides and a forum to ask questions.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6592#issuecomment-626235550:143,guid,guides,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6592#issuecomment-626235550,2,['guid'],['guides']
Usability,"A new annotation with features like `failureMessage` and `force=true` is a lot more complex and more work than just prioritizing type `X` for a `FeatureInput<X>`, if that will work just as well. See the chat room slogan ""hellbender instinct shall be to simplify and rip stuff out"" :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163305134:253,simpl,simplify,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163305134,1,['simpl'],['simplify']
Usability,"A not-so-elegant way to tackle #4323, and part of #4111 . __UPDATE__: fixes #4323 . ---; Brief explanation:. The `<CPX>` variants we currently output has an annotation `SEGMENTS`, which could contain. * 0-entries (which will be simply omitted): this is when the head and tail alignments seamlessly stitch together on the reference, and middle alignments are all taken as inserted sequence; * 1-entry: this is when head/tail alignment overlap on reference over the region specified in the entry, hence we have a deletion or duplication of that region (depending on if the segment is present in another annotation `ALT_ARRANGEMENT`, or if present, whether it is inverted), and insertion of more sequences; * multiple entries: there are the truly complex ones. while the first two cases are easy to deal with, the last one is very difficult to parse into simple variants, and has the inherent evil of ambiguity in representations (to demonstrate, a not very complicated one could be like this); ```; chr6	166997615	CPX_chr6:166997615-166997944	ACCCACAGACAGAAACACAGAGACATGTTTGGAAGCCAGTGTGGATGCCCTGTGATCTGTGTGTACACATGACAAGTGCATACACACGCACATAAAGGAACCCAGAGACGTGTTTGGAAGCCAGTGTGGACACCCTGTGATCTGTGCGTACACATTTGACACCTGCGTACACACTCACAGACAGAAACACAGAGATGTGTTTGGAAGCCAGTGTGGACATCCTGTGGTCTGCGCGTACACATGTGACAGGTACGTGCACGCCCACATACAGGAACACACAGAGGCCTTTGGAAGCCAGCATGGGCAGACAGGCCCTATCCCAAAGCGGCC	<CPX>	.	.	ALIGN_LENGTHS=309;ALT_ARRANGEMENT=1,2,3,4,5,UINS-733,2,UINS-94,-6,-5,UINS-41,4,5,UINS-40,1,2,3,4,5,6;CTG_GOOD_NONCANONICAL_MAPPING=chrUn_JTFH01000473v1_decoy,1,-,51H1640M204H,60,0,1640;CTG_NAMES=asm011602:tig00001;END=166997944;HQ_MAPPINGS=1;MAPPING_QUALITIES=60;MAX_ALIGN_LENGTH=309;SEGMENTS=chr6:166997615-166997617,chr6:166997617-166997679,chr6:166997679-166997727,chr6:166997727-166997787,chr6:166997787-166997831,chr6:166997832-166997944;SEQ_ALT_HAPLOTYPE=ACCCACAGACAGAAACACAGAGACATGTTTGGAAGCCAGTGTGGATGCCCTGTGATCTGTGTGTACACATGACAAGTGCATACACACGCACATAAAGGAACCCAGAGACGTGTTTGGAAGCCAGTGTGGACACCCTGTGATCTGTGCGTACACATTTG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602:228,simpl,simply,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602,1,['simpl'],['simply']
Usability,"A quick patch to help out the Variants team, which is struggling with a problematic callset. Note that a similar regularization to the effective number per component probably should have been applied to solve the issue in https://github.com/broadinstitute/gatk/pull/6425. I'm not sure if the lack of this regularization will still lead to convergence issues, but I would hope that the fix that was implemented instead (treating vanishing components as a special case and skipping computation) suffices. As discussed there, we may also want to eventually remove the idiosyncratic finalize step; it’s likely this is the source of issues here, since the correct Bayesian M step is already regularized by the prior. The covariance regularization term added here is standard (c.f. e.g. https://github.com/scikit-learn/scikit-learn/blob/7e1e6d09bcc2eaeba98f7e737aac2ac782f0e5f1/sklearn/mixture/_gaussian_mixture.py#L154), but it may result in non-negligible changes to VQSLODs. As just discussed with the Variants team, we can probably use the WARP validation to convince ourselves that results are functionally equivalent. I updated the exact-match tests without much close examination (by simply forcing IntegrationTestSpec.assertEqualTextFiles to overwrite the old expected files), so someone may want to sanity check them. There were also a few more interactions between the integration tests for different tools than I anticipated. Some tests use output generated by an upstream tool as input and break encapsulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709:807,learn,learn,807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709,3,"['learn', 'simpl']","['learn', 'simply']"
Usability,"A reference is required, but the task WDL does not ingest the reference given to the workflow. Proposed solution is to simply add:. ```; File ref_fasta; File ref_fasta_fai; File ref_fasta_dict; ```; to the input block of `task CollectFragmentCounts`. and add ; ```; ref_fasta_dict = ref_fasta_dict,; ref_fasta_fai = ref_fasta_fai,; ref_fasta = ref_fasta; ```. to the `call CollectFragmentCounts`. and lastly, add `-R ${ref_fasta}` to the end of the `gatk` command in `task CollectFragmentCounts`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4253:119,simpl,simply,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253,1,['simpl'],['simply']
Usability,"A seemingly large change PR, but most changes are trivial.; The non-trivial part:. * a new tool `StructuralVariantionDiscoveryPipelineSpark` to run the whole process of SV discovery, by delegating works to `FindBreakpointEvidenceSpark` and `DiscoverVariantsFromContigAlignmentsSAMSpark`, both of which are refactored to accommodate the new tool;; * class `AlignmentRegion` is effectively moved into a new class `AlignedAssembly` (named quite close to the existing class `AlignedAssemblyOrExcuse` but will be moved into a different sub-package in a sequential PR).; * integration tests (local mode and on MiniClusters/hdfs) for all 5 major tools `FindBreakpointEvidenceSpark`, `DiscoverVariantsFromContigAlignmentsSAMSpark`, `StructuralVariantionDiscoveryPipelineSpark`, `AlignAssembledContigsSpark` and `DiscoverVariantsFromContigAlignmentsSGASpark`; a draw back is these integration tests do not test correctness of results but simple tests if these tools run.; * various unit tests. The two paths involving use of Fermi-lite are tested to be running and generating compatible results. The path involves using SGA as the assembler is also running but generates significantly less variants. (see attached run logs).; [differentVersions.txt](https://github.com/broadinstitute/gatk/files/956271/differentVersions.txt). The access levels of the various classes and methods are not optimal now because a serial PR that simply repackaging these classes (hence access levels must be changed) is expected to be generated immediately after this PR is approved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621:929,simpl,simple,929,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621,2,['simpl'],"['simple', 'simply']"
Usability,A simple change with a big impact.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/904:2,simpl,simple,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/904,1,['simpl'],['simple']
Usability,"A user originally reported a `RuntimeIOException: Attempt to add record to closed writer in SplitNCigarReads`. It seems setting TMP_DIR helps even though user had Djava.io.tmpdir set. Is this expected? The user post below should help as well. ----; User Report; ----. Hi @Sheila and @gerzs,; I figured out the issue (at least for me). It stems from where SplitNCigarReads is writing the temporary files. For me, it's writing them to the cluster which has very limited disk space. When I redirected this using `--TMP_DIR /my/scratch/space` everything went smoothly. The part that still confuses me is that I had already set `export _JAVA_OPTIONS=-Djava.io.tmpdir=/my/scratch/space`. This is not getting picked up by SplitNCigarReads in GATK4 as I would have expected. After much experimenting I started with a clean environment and simply set `--TMP_DIR /my/scratch/space` only which worked. . This seems a bit ""buggy"" to me and it would be great if the GATK development team could look into it and pass `Djava.io.tmpdir` to `--TMP_DIR` if possible. Thanks,. Stephen . This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/46418#Comment_46418",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4487:831,simpl,simply,831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487,1,['simpl'],['simply']
Usability,"A utility class to go from Read to SAMRecord, with an initial simple test.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/493:62,simpl,simple,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/493,1,['simpl'],['simple']
Usability,"A very simple and easy to review PR that backs off on retries a bit more, and retries for a bit longer. This may help when we're opening many cloud files in parallel.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2750:7,simpl,simple,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2750,1,['simpl'],['simple']
Usability,"A12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1368,Simpl,SimpleInterval,1368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['Simpl'],['SimpleInterval']
Usability,"AAGAACACATAGATGCATTTGGAAGCCAGTGTGGACGCCATGTGATCTGTGCCCACATATCACATGGCCGCTTTGGGATAGGGCCTGTCTGCCCATACTGGCTTCCAAACGCCTCTGTGTGTTCCTGTATGTGGGTGTGCACGTACCTGTCACATGTGTATGCACAGACCACAGGATGTCCACACTGGCTTCCAAATGCGTCTCTGTGTTCCTGTCTGTGAGTTCCAAATGTGTGCACACCTACAGACAGGAACATGGAAACACATTTGGAAGCCAGTGTGGACACCCTGTGATCTGTGCGTACACATGTGACACGTGCATGCACACCCACAGACAGGAACACAGAGACACATTTGGAAGCCAGTGTGGACGCCCTGTGATCTGTGCCCACACACATCACACGTGCATACACACCCACAGACAGGAACACAGAGACACATTTGGAAGCCAGTGTGGATGCCCTGTGATCTGTGTGTACACGTGACACGTGCGTACACACCCACATACAGGAACACAGCCACATTTGGAAGCCAGTGCAGACGCCCTGTGATCTGTGTGTACACATGTGACACGTGCGTGCACACTCACAGACAGGAACACAGAGACGCATTTGGAAGCCAGTGTGGACATCCTGTGGTCTGCGCGTACACATGTGACAGGTACGTGCACGCCCACATACAGGAACACACAGAGGCCTTTGGAAGCCAGCATGGGCAGACAGGCCCTATCCCAAAGCGGCC;SVLEN=1454;SVTYPE=CPX;TOTAL_MAPPINGS=1; ```. So the strategy taken in this branch is; * for the first two cases, re-interpretation is easy and done in this ""post-processing"" tool, and bare-bone annotated simple variants are given , annotated with `EVENT` that links the simple variants back to the complex variant; * for the last case, ; * re-collect the contigs that induced the CPX call, preprocess its alignment, then send the contig to the current pair-iteration algorithm for re-interpretation, the returned simple variants will be checked for consistency with the CPX variant that was induced by the same contig, and dropped if it is inconsistent (the two types of variants `<DEL>` and `<INV>`, are main concerns as they could easily stem from mis-interpretations of small dispersed duplications); then, ; * the CPX variants who have rejected re-interpreted simple variants will be analyzed one last time, to extract `<DEL>` and `<INV>`; ; * these variants will also be annotated with `EVENT` to link back to the CPX variants. Based on manual review, this salvages ~600 variants that would be dropped by evaluation scripts that would simply ignore the CPX variants. ---; Tests will be added if this strategy is given the green light (so no merging yet).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602:3832,simpl,simple,3832,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602,5,['simpl'],"['simple', 'simply']"
Usability,"ABLE=69,70|3,3;DP=148;ECNT=2;MBQ=20,20;MFRL=117,100;MMQ=60,60;MPOS=27;POPAF=7.3;TLOD=7.65 GT:AD:AF:DP:F1R2:F2R1:FAD:PGT:PID:PS:SB 0|1:139,6:0.044:145:40,0:42,3:85,3:0|1:25245348_C_A:25245348:69,70,3,3; chr12 25245348 . C G . . AS_SB_TABLE=94,101|2,2;DP=199;ECNT=3;MBQ=20,20;MFRL=108,118;MMQ=60,60;MPOS=39;POPAF=7.3;TLOD=3.94 GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:195,4:0.025:199:64,1:37,1:115,2:94,101,2,2; chr12 25245348 . C A . . AS_SB_TABLE=95,101|3,3;DP=207;ECNT=2;MBQ=20,20;MFRL=116,91;MMQ=60,60;MPOS=26;POPAF=7.3;TLOD=7.08 GT:AD:AF:DP:F1R2:F2R1:FAD:PGT:PID:PS:SB 0|1:196,6:0.032:202:69,0:41,3:119,3:0|1:25245348_C_A:25245348:95,101,3,3; chr12 25245348 . C A . . AS_SB_TABLE=64,69|2,3;DP=139;ECNT=1;MBQ=20,20;MFRL=86,94;MMQ=60,60;MPOS=21;POPAF=7.3;TLOD=6.28 GT:AD:AF:DP:F1R2:F2R1:FAD:SB 0/1:133,5:0.053:138:40,0:29,2:70,3:64,69,2,3. ```; The guidelines in the documentation could include filtering the calls, which I could have done independently, but this wouldn't matter here because 4 samples displaying a mutation should never have been added to a panel that was created when requesting a minimum of 30, 45, or even 50 samples displaying a variant at the same site. #### Steps to reproduce; ```; gatk --java-options ""-Xmx30g"" Mutect2 \; -R /ref/Homo_sapiens_assembly38.fasta \; -I /bams/input/WES_Normal/${infile} \; -max-mnp-distance 0 \; -O /bams/output/${outfile}. gatk --java-options ""-Xmx100g"" GenomicsDBImport \; -R /ref/Homo_sapiens_assembly38.fasta -L /mydir/S33266340_hg38_Regions.bed \; --tmp-dir /scratch/ --genomicsdb-workspace-path ${RAMDISK}/PON_db_50_samples \; --merge-input-intervals true \; -V /bams/output/sample1.vcf.gz -V /bams/output/sample2.vcf.gz [....]. gatk --java-options ""-Xmx10g"" CreateSomaticPanelOfNormals \; -R /ref/Homo_sapiens_assembly38.fasta \; -V gendb://${RAMDISK}/PON_db_50_samples \; --germline-resource /gnomad/gnomAD.r2.1.1.GRCh38.PASS.AC.AF.only.vcf.gz \; --min-sample-count 50 \; -O /mydir/output/variants_100percent_samples_PON_50_samples.vcf.gz; ```. ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8916:2510,guid,guidelines,2510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8916,1,['guid'],['guidelines']
Usability,"ACTGCATATTCTCACTCATAGGTGGGAACTGAACAATGAGATCACATGGACACAGGAAGGGGAATATCACACTCTGGGGACTGTTGTGGGGTGGTGGGAGGGGGGAGGGATAGCATCGGGAGATATACCTAATGCTAGATGACGAGTTAGTAGGTGCAGCGCACCAGCATGGCACATGTATACATATATAACTAACCTGCACAATGTGCACATGTACGCTAAAACTTAAAAGTATAATAAAAAAAAAAAAAAAGAAAAAAAAAAGAATGCAACAACAAAAAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTCAACTCCGTGAGTTGATTGAACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCGTTTCAACCATAGGTCTCAAAGTGCTCCAAATATCCACTTGCAGATTCTACAAAACGAGTCTTTCAAAACTGCTCTATCAATACGAAGGTTCAACTCTGTGAGTTGAATGCACACATCACAAAGAAGTTTCTGAGAATGCTTCTGTCTAGTTTTTATGTGAAGATATTCCCGTTTCCAATGAAAGCCTCAAAGCCATCCAAATGTCCACTTGCAGATTCTACAAAAAGAGTGTTTGAAAACTGCTCTATCAAAAGAAGATTCAACTCTGTGAGTTGAAAGCACACATCAGAAAGAATTTCCTGATAATGCTTCTGTCTAGCTTTTATGTGGAGATATTCCCGTTTTCAACGAAGGCCTCAAAGCAGTCCAAATATCCATTTGCAGGTTCTACAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTAAACTCCGTGAGTTGACTGCACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCATTTCAACTGT"".getBytes();. final AlignmentInterval region0 = new AlignmentInterval(new SimpleInterval(""21"", 96869186, 96869532), 1, 347, TextCigarCodec.decode(""347M678S""), false, 4, 9, 305, AlnModType.NONE);; final AlignmentInterval region1 = new AlignmentInterval(new SimpleInterval(""21"", 48872354, 48872986), 383, 1014, TextCigarCodec.decode(""382H375M1D257M11H""), false, 4, 73, 255, AlnModType.NONE);; final AlignmentInterval region2 = new AlignmentInterval(new SimpleInterval(""20"", 283, 651), 383, 751, TextCigarCodec.decode(""382H369M274H""), true, 60, 23, 254, AlnModType.NONE);; final AlignmentInterval region3 = new AlignmentInterval(new SimpleInterval(""20"", 1, 413), 613, 1025, TextCigarCodec.decode(""612H413M""), true, 60, 0, 413, AlnModType.NONE);. final AlignedContig alignedContig = new AlignedContig(""asm00001:tig0001"", contigSequence, Arrays.asList(region0, region1, region2, region3), false);. final List<ChimericAlignment> assembledBreakpointsFromAlignmentIntervals = ChimericAlignment.parseOneContig(alignedContig, SVDiscoveryTestDataProvider.seqDict, true, StructuralVariati",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:1355,Simpl,SimpleInterval,1355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,1,['Simpl'],['SimpleInterval']
Usability,"ADAM has no header. I realize I'm only coming into the game rather late, but would it be possible to ditch `SAMRecord`? Since you're already using Google `Read`-backed data as well, instead of writing against an interface (`GATKRead`), you could simply come up with your own, more-awesome concrete data structure. (Perhaps even an Avro `SpecificRecord` a la `AlignmentRecord`). In cases where ADAM wants a header back, at the moment it actually runs an aggregation across all the reads to rebuild it. (I'm trying to add a patch that allows you to specify a header, though, because it's breaking a hellbender test for reading/writing parquet.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644:246,simpl,simply,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644,1,['simpl'],['simply']
Usability,AFAIK the GATK3 one used multithreading etc. Can we do a simple one just for readwalkers that does not use multithreading?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/974#issuecomment-149692146:57,simpl,simple,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974#issuecomment-149692146,1,['simpl'],['simple']
Usability,"AGTTTTTATGTGAAGATATTCCCGTTTCCAATGAAAGCCTCAAAGCCATCCAAATGTCCACTTGCAGATTCTACAAAAAGAGTGTTTGAAAACTGCTCTATCAAAAGAAGATTCAACTCTGTGAGTTGAAAGCACACATCAGAAAGAATTTCCTGATAATGCTTCTGTCTAGCTTTTATGTGGAGATATTCCCGTTTTCAACGAAGGCCTCAAAGCAGTCCAAATATCCATTTGCAGGTTCTACAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTAAACTCCGTGAGTTGACTGCACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCATTTCAACTGT"".getBytes();. final AlignmentInterval region0 = new AlignmentInterval(new SimpleInterval(""21"", 96869186, 96869532), 1, 347, TextCigarCodec.decode(""347M678S""), false, 4, 9, 305, AlnModType.NONE);; final AlignmentInterval region1 = new AlignmentInterval(new SimpleInterval(""21"", 48872354, 48872986), 383, 1014, TextCigarCodec.decode(""382H375M1D257M11H""), false, 4, 73, 255, AlnModType.NONE);; final AlignmentInterval region2 = new AlignmentInterval(new SimpleInterval(""20"", 283, 651), 383, 751, TextCigarCodec.decode(""382H369M274H""), true, 60, 23, 254, AlnModType.NONE);; final AlignmentInterval region3 = new AlignmentInterval(new SimpleInterval(""20"", 1, 413), 613, 1025, TextCigarCodec.decode(""612H413M""), true, 60, 0, 413, AlnModType.NONE);. final AlignedContig alignedContig = new AlignedContig(""asm00001:tig0001"", contigSequence, Arrays.asList(region0, region1, region2, region3), false);. final List<ChimericAlignment> assembledBreakpointsFromAlignmentIntervals = ChimericAlignment.parseOneContig(alignedContig, SVDiscoveryTestDataProvider.seqDict, true, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.DEFAULT_MIN_ALIGNMENT_LENGTH, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.CHIMERIC_ALIGNMENTS_HIGHMQ_THRESHOLD, true);. Assert.assertEquals(assembledBreakpointsFromAlignmentIntervals.size(), 1);; final ChimericAlignment chimericAlignment = assembledBreakpointsFromAlignmentIntervals.get(0);; Assert.assertEquals(chimericAlignment.sourceContigName, ""asm00001:tig0001"");; final NovelAdjacencyRef",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:1911,Simpl,SimpleInterval,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,1,['Simpl'],['SimpleInterval']
Usability,"According to #2858, the new [GATK CNV pipeline](https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/somatic) is intended to replace AllelicCNV (because it now segments jointly on total copy ratio and allelic fraction). We've found the segmentation to be great for WGS data, but the new workflow does not create the same outputs as AllelicCNV - in particular, AllelicCNV generated a *-sim-final.acs.seg that could be used for [ABSOLUTE](https://software.broadinstitute.org/cancer/cga/absolute) and [DeTiN](https://github.com/getzlab/deTiN). We'd like to run these tools - Is there any way to get the equivalent of this file from the workflow's outputs? None of the outputs look like *-sim-final.acs.seg. . If not, I had planned to simply run AllelicCNV (or AllelicCapseg) using files from the new workflow. The only issue is that the input files are unclear to me - I've provided a table below with what I believe the matchups relative to the old GATK CNV workflow to be, but it would be great to get clarification!. Name of file | Old GATK CNV (task) | New GATK CNV (task); -- | -- | --; tumorHets | *.tumor.hets.tsv (GetHetCoverage) | *.hets.tsv (ModelSegments); segments | *.seg (PerformSegmentation) | *.modelFinal.seg (ModelSegments); tangentNormalized | *.tn.tsv (NormalizeSomaticReadCounts) | ????? (maybe .denoisedCR.tsv from DenoiseReadCounts?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6685:745,simpl,simply,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685,1,['simpl'],['simply']
Usability,"Actually what you said is correct: it is very painful to extend the `Main` class and use the current implementation. The simplest `Main` class that I'm using it's not extending the GATK one just because of the static methods (see the code [here](https://github.com/magicDGS/thaplv/blob/master/src/main/java/org/magicdgs/thaplv/Main.java)), that's why I would like to include this change. In few minutes I will commit the changes that you propose, including the method and the change from static. Thanks for the feedback, @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430:121,simpl,simplest,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430,4,"['feedback', 'simpl']","['feedback', 'simplest']"
Usability,"Actually, a second thing just popped into my head. The name `LocusDepth` makes perfect sense but the abbreviation `LD` is overloaded with Linkage Disequilibrium. Not a huge problem in context, but it's likely the abbreviation will make its way into VCF annotations in the future, which could create confusion. Is there another name we could use? I think `SiteDepth` or `BaseDepth` are also clear and unambiguous. @cwhelan any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1146164659:390,clear,clear,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1146164659,2,['clear'],['clear']
Usability,Add LearnReadOrientationModel documentation to ToolDocs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6862:4,Learn,LearnReadOrientationModel,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862,1,['Learn'],['LearnReadOrientationModel']
Usability,Add a tool to count reads that overlap exons (aka targets or simply arbitrary intervals),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/344:61,simpl,simply,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/344,1,['simpl'],['simply']
Usability,Add machine learning and xgboost utils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5146:12,learn,learning,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5146,2,['learn'],['learning']
Usability,"Add overlaps(), contains(), and other useful methods to SimpleInterval in htsjdk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305:56,Simpl,SimpleInterval,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305,1,['Simpl'],['SimpleInterval']
Usability,Add the most commonly-used interval operations to `SimpleInterval` in htsjdk (without going too crazy -- it is called SIMPLEInterval after all...),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305:51,Simpl,SimpleInterval,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305,2,"['SIMPL', 'Simpl']","['SIMPLEInterval', 'SimpleInterval']"
Usability,"Addded abstract class MachineLearningUtils to provide an interface and; handle common tasks. These include loading data, splitting data into; training and test sets, cross-validation, and optimizing classifier; hyperparameters. Also added XGBoostUtils which provides a concrete implemention of; MachineLearningUtils (by wrapping xgboost4j) and serves as an example; of how to provide access to a 3rd-party machine learning library. Finally, added an example tool: ExampleTrainXGBoostClassifier. This; demonstrates a typical training use case of loading data, training a; classifier, assessing accuracy, and saving the classifier. It also; demonstrates a typical filtering use case of loading a saved classifer,; and using it to calculate probabilities or class labels. This is working towards issue 4922 by providing the tools necessary to; train classifiers in general, but does not provide tools to train a; BreakpointEvidence filter, so does not resolve it. Additionally, this; framework should eventually be extended to provide a bayesian; hyperparameter optimizer. One outstanding problem with these changes is that xgboost4j threading; does not appear to work on OSX, resulting in slower training. However,; it does work on linux.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5146:414,learn,learning,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5146,1,['learn'],['learning']
Usability,Added a simple TSV/CSV/XSV writer with cloud write support,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5930:8,simpl,simple,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5930,2,['simpl'],['simple']
Usability,Added a simple tool for extracting a bed file of regions with sufficient coverage.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7570:8,simpl,simple,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7570,2,['simpl'],['simple']
Usability,"Added a test to verify that https://github.com/broadinstitute/gatk/issues/3154 is fixed now that we've upgraded htsjdk (though we should keep that ticket open until @sooheelee can verify her particular incarnation of this issue). Also note that while the CRAM MD5 slice calculation is fixed, GATK users can still have problem reading CRAMs made from references containing ambiguity codes if the .dict accompanying the reference was generated with samtools. This is tracked by https://github.com/broadinstitute/gatk/issues/3306, but is really a samtools issue. The simple workaround is to recreate the .dict using CreateSequenceDictionary, which is what I've done to create the test in this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3430:564,simpl,simple,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430,1,['simpl'],['simple']
Usability,Added a very simple test for sorting iterator. Back to you @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2249#issuecomment-267139593:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2249#issuecomment-267139593,2,['simpl'],['simple']
Usability,Added an experimental mode to HaplotypeCaller and Mutect2 to disable sequence graph simplifications.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5958:84,simpl,simplifications,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5958,2,['simpl'],['simplifications']
Usability,Added command line to do a segment union. Inputs:; - exactly two segment files (arbitrary column headers).; - columns of interest. What it does:; - Attempts to find reasonable headers in the TSVs; - Creates instances of a simplistic object that is composed of a mapping for columns and an interval. Note that the columns making up the interval are not in the map.; - Unions the segments and the columns of interest into a new TSV.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3713:222,simpl,simplistic,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3713,1,['simpl'],['simplistic']
Usability,"Added contig name overrides for hg19 VS B37; Added in code to convert VCF INDEL positions to MAF INDEL positions.; Added start/stop positions for IGRs.; Added argument to ignore filtered variants at the front of processing to save time.; Added a script to fully retrieve the COSMIC data sources. Fixed how the MafOutputRenderer handles mapping fields to values.; Fixed a bug in LocatableXsv and COSMIC parsers (was missing name and; version).; In Gencode: Now TumorSeqAllele1 is the refAllele, not the AltAllele.; Fixed some problems with VCF output.; Updated VCF outputs to have better header info.; Refactored header output for OutputRenderers.; Changed the logic for creating alt protein sequences.; Fixed a bug in the LocatableXsvFuncotationFactory that caused annotations to be incorrectly associated with a factory.; Fixed several bugs in the GencodeFuncotationFactory.; Fixed bugx in the handling of UTR variants.; Fixed the Transcript Selection Mode ordering.; Fixed an issue with splice sites. Minor speed fix to GencodeFuncotationFactory. Now CosmicFuncotationFactory opens the database in read-only mode. Bugfix - now LocatableXsvFuncotationFactories use overrides. Now the reference should properly align with ALL indels regardless of; length. ReferenceContext now always rendered on + strand. Now will create funcotations for transcripts without fasta sequences. Minor changes to FuncotatorIntegrationTest. - Added in more integration test files. These are as yet unused - must; refactor the files themselves to actually reflect what should be correct; as far as produced funcotations. - Updated LocatableXsvFuncotationFactoryUnitTest.java and SimpleKeyXsvFuncotationFactoryUnitTest.java; to reflect the change to funcotation factories to always produce the; expected funcotations (rather than only producing funcotations when; there are data that match the target variant). Fixed an issue with the new VariantClassification code. Fixed issue #4410. Fixed #4022. Fixed #4420. Fixed #3922",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4472:1762,Simpl,SimpleKeyXsvFuncotationFactoryUnitTest,1762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4472,1,['Simpl'],['SimpleKeyXsvFuncotationFactoryUnitTest']
Usability,Added guidelines for resource usage that we use for running gCNV to GermlineCNVCaller doc. This addressed #6166.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8064:6,guid,guidelines,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8064,1,['guid'],['guidelines']
Usability,"Added in test condition for AD field with only 1 value in MAF mode. This isn't really a bug, but an error mode that needed more explicit; feedback.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5860:138,feedback,feedback,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5860,1,['feedback'],['feedback']
Usability,Added logic for generating a simplified read filter output in the case of multiple filters joined by AND. Fixes #3520,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6315:29,simpl,simplified,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6315,1,['simpl'],['simplified']
Usability,Added some changes per Laura's review. Mainly:; - added a `--genomicsdb-update-workspace-path` that specifies the path to an existing workspace for incremental import and interval_list generation cases; - removed `--incremental` since the above made it superfluous; - added an `--output-interval-list-to-file` argument that will just generate a picard style interval_list at the location specified by the argument for an existing workspace. No import done when this is used; - changed the existing tests to use multiple intervals instead of a single interval. @ldgauthier I'm not entirely sure about the picard interval_list generation. Any chance you could help with providing some expected input/output for that so that I can add a test for it? I ran through a simple test with it but not really sure what the output should look like.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518447724:763,simpl,simple,763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518447724,2,['simpl'],['simple']
Usability,Added the following Adam optimization / learning parameters to the command-line:. - learning rate; - beta1; - beta2; - epsilon; - clipnorm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8483:40,learn,learning,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8483,2,['learn'],['learning']
Usability,Adding SimpleInterval(Locatable) constructor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/441:7,Simpl,SimpleInterval,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441,1,['Simpl'],['SimpleInterval']
Usability,"Adding in a parser that handles text files that are delimited with some known separator (i.e. commas, tabs, words). The new class is called `SimpleKeyXsvFuncotationFactory` and it is usable with the rest of `Funcotator` using new command-line arguments. Added new integration tests that include this new data source factory. Fixes #3757",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3897:141,Simpl,SimpleKeyXsvFuncotationFactory,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3897,2,"['Simpl', 'usab']","['SimpleKeyXsvFuncotationFactory', 'usable']"
Usability,"Adding validation to the SimpleInterval(String) constructor; Making GenomeLoc implement Locatable; Replacing all instances of SimpleInterval( locatable.getContig(), locatable.getStart(), locatable.getEnd()) with the new constructor. fixes #438 and #436",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/441:25,Simpl,SimpleInterval,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/441,2,['Simpl'],['SimpleInterval']
Usability,"Additional feedback from the user for the mutect2 workflow. > ""Of note, it is really difficult and not really 'user-friendly' to have to predict disc space and runtime for Funcotator, which seem to depend (based on calculations you copied above from other Functotator workflows) on outputs of Mutect2 (eg vcf sizes), when here Mutect and Funcotator and bundled together. So I cannot see output of Mutect to predict values for Funcotator - especially not when I get to run this over hundreds of samples. It is also pricey to have jobs failing because of this. It would be much better to have these variables encoded, so that the algorithm uses Mutect outputs to predict memory etc. that it will need to run Funcotator downstream. If this is really how things work (and this is my current understanding), I really do not know how to estimate this for many samples without 'trial and error' that is both costly and it will take extremely long time....""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230:11,feedback,feedback,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230,4,"['feedback', 'user-friendly']","['feedback', 'user-friendly']"
Usability,Address PR comments to some extent. @SHuang-Broad take a look and let me know if things are more clear/better structured to you now. I think that renaming the `AssembledBreakpoint` class makes things at least a little bit less confusing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240524115:97,clear,clear,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240524115,2,['clear'],['clear']
Usability,"Addressed feedback, updated so it can write reports and added test that checks the exact same reports as the BaseRecalibrator integration test (they pass).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201:10,feedback,feedback,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201,1,['feedback'],['feedback']
Usability,"Adds a WDL that replaces the ""serial"" SnpThenIndel joint filtering workflow added in #7932. This simplified replacement only runs one iteration of the extract-train-score toolchain, rather than running one iteration for SNPs followed by another for INDELs. The original SnpThenIndel workflow (used for Ultima) will be updated and moved to the WARP repo. (EDIT: I was originally confused here, the WDL that was replaced in this PR simply ran SNPs and indels separately, rather than serially. Curious that things still tied out, but I’m not sure it’s worth looking into at this point.). Test files have also been subset to chr21-22 and slimmed down. A test for the positive-negative was also added, as well as tests of an empty shard. The first commit contains the original workflow (JointVcfFilteringOriginal.wdl), as well as a reimplementation (JointVcfFilteringSnpThenIndel.wdl) that calls the simplified workflow (JointVcfFiltering.wdl). I've verified that both the original and reimplemented SnpThenIndel workflows tie out on the original test data. The second commit then removes the original and the reimplementation, leaving only the simplified workflow. It may thus be easier to review the first commit, second commit, or the overall changes, depending on what you are looking at. @meganshand can you take a look and let me know if there's any missing functionality, or if this otherwise won't work for Ultima and/or importing in WARP? Apologies for the delay!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074:97,simpl,simplified,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074,4,['simpl'],"['simplified', 'simply']"
Usability,Adds a simple test to test a cram in UnmarkDuplicatesIntergrationTest,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2174:7,simpl,simple,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2174,1,['simpl'],['simple']
Usability,Adds additional filtering steps to the PathSeq filter to 1) trim adapter sequences and 2) mimic a simple filter used in RepeatMasker that masks windows with excessive A/T or G/C content.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354:98,simpl,simple,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354,1,['simpl'],['simple']
Usability,"Adds the `FuncotateSegments` tool. . *`FuncotateSegments` does not support VCF input!*. This tool will create two output files from a GATK seg file:; - A simple TSV which has each segment of the input file funcotated with all the genes it overlaps and which gene/exon covers each breakpoint. The output format is meant to (closely) match Oncotator. ; - A gene list which has every gene, covered by a segment, listed with the segment that covers it. A gene can appear more than once if a segment breakpoint overlaps the gene (i.e. more than one segment overlaps the gene). The output format is meant to (closely) match Oncotator.; - Output formats may change.; - Input format is only seg files such as those generated from `ModelSegments`. . Dev and reviewer notes:; - Includes refactoring to drive much of the GencodeFuncotation data solely from the transcript. As opposed to a mix of the transcript and gene. This does cause some changes to sorting of the GencodeFuncotations (easily seen in the other transcripts field). It turns out that the transcript type field has different values for each transcript. This causes many transcripts to no longer be categorized as protein coding. Therefore, the ground truth (mostly/totally in `FuncotatorIntegrationTest`) had to be modified. *Please carefully review the ground truth changes*.; - Introduces the `CompsiteOutputRenderer`, which is composed of multiple output renderers. This is used when output type is `SEG`, so that it can write both output files simultaneously.; - Introduces the `GeneListOutputRenderer`. This does not write anything to disk until the entire input file is processed. The actual writing happens during the `close()` command. This is necessary since it cannot actually render its output until all segments have been seen. This output renderer also relies heavily on specific funcotation fields being in the input `FuncotationMap`. Internally, the gene list output renderer uses the `SimpleTsvOutputRenderer` (see below) to do t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941:154,simpl,simple,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941,1,['simpl'],['simple']
Usability,"After discussing with @ldgauthier, I'm going to approve this PR as-is, and Laura will address the remaining TODOs in a separate PR. For the record, the three remaining issues that need addressing are:. * Get rid of the `instanceof VariantWalker` check in `FeatureManager` by making `GATKTool.getGenomicsDBOptions()` return null (or `new GenomicsDBOptions(referenceArguments.getReferencePath())`) instead of throwing an exception, and then having `GATKTool.initializeFeatures()` (and its overrides) pass the GenomicsDB options in to the `FeatureManager` constructor, which can then propagate them down here. * Add a simple direct integration test for the new `--floor-blocks` HaplotypeCaller arg. * Address my maintenance concerns about `AnnotationUtils.isAlleleSpecific()` by adding an empty marker interface for AS annotations (open to other ideas here if you don't like that one)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314:615,simpl,simple,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314,2,['simpl'],['simple']
Usability,"After getting feedback from @vruano on pull request [45](https://github.com/broadinstitute/hellbender-protected/pull/45) in hellbender-protected and speaking with @droazen and @lbergelson, it seems that LocusWalker should be implemented instead. For the time being we will move forward with SamLocusIterator, but I'll file a separate issue in hellbender-protected to remind us to switch over to LocusWalker once it is implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-116846893:14,feedback,feedback,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-116846893,1,['feedback'],['feedback']
Usability,"After more digging around it seems that in the case of partial alignment (i.e. hard clipped bases) the BD and BI tags that sentieon just copies from the consensus fastq aren't trimmed to the actual length of the aligned sequence, and thus are to long and it's this that causes problems. . As these are non-standard tags the SAM/BAM format specification doesn't say anything on whether their length must equal the aligned segment of bases, but it clearly doesn't make any sense to have quality data on bases that are not part of the alignment (= hard clipped), so IMHO the solution here would be for Sentieon to fix their tool. I've written a small utility that trims the BD and BI tags (based on the CIGAR-string) to have the same length as the actual aligned segment of the read, https://github.com/avalind/doppelganger.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-669525805:446,clear,clearly,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-669525805,2,['clear'],['clearly']
Usability,"After running `./gradlew clean jacocoTestReport` (or just `./gradlew clearn test`), there are some test files appearing as ""untracked"" in the git repository:. * `likelihoods.txt`; * `src/test/resources/snpSampledModel.report`; * `src/test/resources/vqsr_model.report`. I think that this should be test files in a temp directory and should be clean after the test suite finishes (or after the single test runs).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4206:69,clear,clearn,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4206,1,['clear'],['clearn']
Usability,"After spending some time to resolve this users issue, https://gatkforums.broadinstitute.org/gatk/discussion/24134/gatk4-rmsmappingquality-results-differ-between-v4-0-0-0-and-v4-1-1-0/p1, it became clear that the issue was that the user simply mismatched her versions of gatk, which seems to have caused their MQ annotations to tank. The user didn't notice the warnings of this fact until we had already nearly found the issue by debugging. I propose that we upgrade the warning to an exception with explicit override to make it harder for this issue to slip past people in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6060:197,clear,clear,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6060,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Ah! I see. This is indeed an unintuitive behavior. Especially in the case where a user is providing a compound expression with a series of filters separated by the OR operator. The user is expecting that any variant that meets any of the filter criteria will be marked for filtering. If I understand correctly, a variant could fail 4/5 filters, be NULL for 1/5 filter expressions and end up with a PASS status! This is rarely the desired behavior. In this use case, I might want an --ignore-missing-values option. I don't necessarily want to fail all variants just because they have a missing value for a feature. But, I also don't want them to be evaluated as PASS if they fail filters for which they do have values. I guess maybe a partial solution is to strongly encourage separate filter expressions, for this the most common use case of wanting to apply several filters in the OR situation. I guess if you have AND operators in the mix, it gets more complicated. If I want to filter a variant only if it fails filter_A AND filter_B it is less clear what the right behavior is when feature A or B is NULL. I guess it should pass?. I don't have enough understanding of why these values are missing. I'm using a pretty standard workflow (GATK HaplotypeCaller) to get these variants and I guess I naively assumed they would be complete for these features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436049581:1048,clear,clear,1048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436049581,2,['clear'],['clear']
Usability,"Ah, I see. the temporary nature of your suggestion was not clear (to me). I accept your suggestion. On Thu, Nov 9, 2017 at 9:23 PM, droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> I'm suggesting that while we're; > in the process of tieing out the GATK4 HaplotypeCaller against GATK3, we; > should not be making changes like this. After the tie-out is complete, then; > we can of course revisit this branch.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343295944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mhcLngpG-X_ZcKseu-Ctszn3_Wxks5s021WgaJpZM4Pzjie>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343497974:59,clear,clear,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343497974,2,['clear'],['clear']
Usability,"Ah, I was not aware until now that we had a tool called SplitByRG -- which is probably because I'm mostly familiar with public tools, and SplitByRG appears to be in private. . After further thought, my guess is that the difference is: SplitByRG writes out a separate bam for each readgroup, and they are all output (core function modality is scattering), whereas the PrintReads + filters solution only writes out a specified subset, to a single output bam (core function modality is subsetting). If so then perhaps it does make sense to keep them separate, except that instead of making it a PrintReadsBy[blah](a name that does not clearly distinguish the core functionality), I would recommend making it a generic tool called SplitReads (analogous to PrintReads, but with a distinct scattering modality), and offer several options for how to split (e.g. you could choose a specific RG tag or other non-RG property of the read data -- including randomness, which would cover the functionality of SplitSamFile).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/74#issuecomment-67869375:632,clear,clearly,632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/74#issuecomment-67869375,1,['clear'],['clearly']
Usability,"Ah, got it. By the way, @kvinter1 thanks for being the first person to take on a ""learn GATK"" issue!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412926174:82,learn,learn,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412926174,2,['learn'],['learn']
Usability,"Ah, ok. I've filed a new issue for the documentation of -DSTACK_TRACE_ON_USEREXCEPTION (#2445). . StorageException is different from UserException in that it doesn't have the user-relevant context. Like IOExceptions, we normally catch StorageException and transform them into user-friendly UserExceptions (as this PR does). Because of this lack of context, I don't think there's much ""special"" we can do about them (printing them out fully, as we do now, is the best I can think of). If you have an idea though I'm open to suggestions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285175500:276,user-friendly,user-friendly,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285175500,2,['user-friendly'],['user-friendly']
Usability,Ah. I see. It's not clear to me what that problem is though. You can have many version of gradle coexisting. Gatk doesn't have to build with system gradle because it comes with the `./gradlew` wrapper which chooses the correct version to build it with.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479:20,clear,clear,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479,2,['clear'],['clear']
Usability,"Aha, after clearing the travis cache for the PR build it passed! Merging",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422499733:11,clear,clearing,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422499733,2,['clear'],['clearing']
Usability,Ahh... I see https://github.com/disq-bio/disq/pull/124 was such a simple fix.... How did we find this bug in the first place? Was the split guessing failing in some case? I think on this end its probably acceptable to just accept this branch and point to the PR in disq. Can we not write a unit test for the SBI index there where we provide an invalid SBI index in a place where the split guessing would have worked and assert that it is indeed trying to use the index?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567092790:66,simpl,simple,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567092790,2,['simpl'],['simple']
Usability,Ak simplify covariates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/413:3,simpl,simplify,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/413,2,['simpl'],['simplify']
Usability,"Also extracted some argument collections and genotyping code (see https://github.com/broadinstitute/gatk/issues/3915), fixed up some documentation, and did some refactoring to the Segmenter classes. This is just a first implementation for evaluation and feedback. There is some redundant (but cheap) computation performed in the genotyping step and both the genotyping and segmentation steps are not optimized for memory use. However, since requirements are not onerous (probably around ~10GB memory and <10 minutes for ~10 typical WGS samples), it might not be worth fixing up at the expense of extra code. Likewise, this implementation requires all inputs be available. We could relax this to allow optional dimensions of input (i.e., copy ratios or allele counts) and/or case-only mode (as in ModelSegments), at the expense of extra control-flow code. One could also perform segmentation with an external tool and pass it to ModelSegments, as long as it is properly formatted. Closes #2924.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499:254,feedback,feedback,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499,1,['feedback'],['feedback']
Usability,"Also fixed some minor style issues in argument variable names and the WDL. This should help recover some deletions and might possibly clear up some issues with MAF estimation when the number of hets is small. @LeeTL1220 can you run on some test cases to check the effect? (Note that the changes to fix estimation of the posterior widths, which will in turn affect similar-segment smoothing, are in another branch; we should test those changes as well.). Note that the default threshold of zero for the tumor in matched-normal mode should ensure that the sites genotyped as het should always match in the tumor and the normal. (This will ultimately make multisample segmentation, as enabled by #5524, more straightforward.) There was previously a check for this condition in the integration test; however, it wasn't actually activated by the test data. I could modify the test data to add a proper regression test, but since these test files are generated by running another tool on a test BAM in the repo, this could be misleading. I'm OK with punting in this case. @jonn-smith do you mind reviewing, since this resulted from your turn as liaison? Should be super quick. Thanks again for raising the issue!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5556:134,clear,clear,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5556,1,['clear'],['clear']
Usability,"Also renamed this ticket to be less scary and more precise, since we know it's a 2-minute pause in the NIO library. It clearly doesn't always happen, though, as I don't think I've ever seen it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743:90,pause,pause,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743,4,"['clear', 'pause']","['clearly', 'pause']"
Usability,"Also, I suspect that for Terra another workaround might be to request a different machine type that does not support AVX:. https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Skylake""; }; ```. https://cloud.google.com/compute/docs/regions-zones/#available. Would appreciate any guidance on this in the meantime. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444:332,guid,guidance,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444,2,['guid'],['guidance']
Usability,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:164,learn,learn,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179,2,['learn'],['learn']
Usability,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:466,simpl,simple,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971,2,['simpl'],['simple']
Usability,"Although identification of the copy-neutral state is still relatively manual, this will at least make the tool usable for samples with high ploidy until @MartonKN finishes up the new caller.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4263:111,usab,usable,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4263,1,['usab'],['usable']
Usability,"Am 90% certain at this point that the jar they were using for testing was built incorrectly. The `CloudStorageReadChannel.class` file in the latest `google-cloud-nio-0.19.0-alpha-shaded.jar` should be 6169 bytes, but their jar has 5401 bytes for that class. And that's the primary class JP patched in the latest release. So I am pretty hopeful that this was just a simple build error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306947226:365,simpl,simple,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306947226,2,['simpl'],['simple']
Usability,"Am un-assigning this, as it's not clear that we want to merge this at this time. Feel free to re-assign if you'd like to see this merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/345#issuecomment-101324830:34,clear,clear,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/345#issuecomment-101324830,2,['clear'],['clear']
Usability,"And another one, `https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_RMSMappingQuality.php`, in `MappingQualityRankSumTest`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652024594:54,guid,guide,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652024594,2,['guid'],['guide']
Usability,"Anecdotally, some people have seen logging issues around the Conda; progress bars filling logs. I know Conda had a change request to add a; silent or quiet mode. Suggestions on the back of a postcard... On Mon 15 Oct 2018, 21:27 Chris Norman, <notifications@github.com> wrote:. > Changing the exception throwing code won't help with either of those -; > that code would only execute when the tool is actually run. Currently, the; > PR is failing to even build on Travis during the part of the build where it; > creates the Docker image on which the tests will run. Travis is killing it; > because its producing so much progress output during the conda environment; > creation - right when its resolving tensorflow packages.; >; > My suggestion above was to see if we can (at least temporarily) get past; > that so we can see how big the Docker is, and whether the CNNScoreVariants; > tests pass with the new environment. Then we can figure out if we have any; > additional issues to resolve.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430000969>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG6lrwV2gaTYs6ur_AXznl6iV0AMxQ8Cks5ulO_DgaJpZM4XNHdi>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430007451:68,progress bar,progress bars,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430007451,2,['progress bar'],['progress bars']
Usability,Another argument against this: the map function of a tool should clearly articulate its inputs in its signature. A map() that takes no parameters and relies on reflection/injection into members for its inputs would be supremely bad design.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266:65,clear,clearly,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266,1,['clear'],['clearly']
Usability,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:302,simpl,simple,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288,2,['simpl'],['simple']
Usability,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863:1489,simpl,simple,1489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863,1,['simpl'],['simple']
Usability,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:202,undo,undocumented,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758,4,['undo'],['undocumented']
Usability,"Apologies @bbimber -- your efforts to port this tool to GATK4 are much appreciated. Our team has been extremely busy with the lead up to the 4.0 release, which is why we haven't been as responsive lately. I'll have someone take a look at the test data in question to see if it can be publicly shared.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358029799:186,responsiv,responsive,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358029799,1,['responsiv'],['responsive']
Usability,"Apologies on the poor report. There are no other users in these compute nodes (I am the tester) and for all intents and purposes the ulimit is pretty high (hard limit of 8192 max files). I am using GATK version 4.1.4.1, although it might be the one that has been optimised for IBM power9 systems by @ruzhuchen. Currently I am waiting for the sys admin to increase the max files further, but I believe that this is far from ideal. Here is the (simplified) command:; ```bash; gatk --java-options ""-Xmx40g -Djava.library.path=/bio/apps/gatk_4.1.4/gatk-4.1.4.1/libs -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" Mutect2 -R Homo_sapiens_assembly38.fa -I illuminaN_hg38.br.recal.bam --max-mnp-distance 0 -O illuminaN.vcf.gz; ```; May be I am running it wrong?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598233814:443,simpl,simplified,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598233814,2,['simpl'],['simplified']
Usability,"Applied feedback, let me know if it's OK now!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135849587:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135849587,1,['feedback'],['feedback']
Usability,"Applied feedback, rebased, squashed. Merge pending passing tests. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694686:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694686,1,['feedback'],['feedback']
Usability,"Applied feedback, reproduced bug and updated our description (#650), submitted bug report (https://github.com/google/google-http-java-client/issues/297), squashed. Merging once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/835#issuecomment-132698966:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/835#issuecomment-132698966,1,['feedback'],['feedback']
Usability,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:1149,clear,clearly,1149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062,2,['clear'],['clearly']
Usability,Are we interested in writing some definitive guide on how to tune the `af-of-alleles-not-in-resource` parameter for different contexts?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4745#issuecomment-387218068:45,guid,guide,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4745#issuecomment-387218068,2,['guid'],['guide']
Usability,Argument types should be more clearly separated from argument names in the help output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6775:30,clear,clearly,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6775,2,['clear'],['clearly']
Usability,"As I understand, there are two ways:; 1) Update all guides that include tools not ported to GATK4 so users could use GATK4 to get the results as they did earlier.; 2) Add all tools from GATK3.6 to GATK4. Otherwise non official forks will appear.. For now could you please add all tools to GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267:52,guid,guides,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267,2,['guid'],['guides']
Usability,"As a stopgap solution to allow `gs://` access on Spark with the local runner, let's add the `gcs-connector` as a project dependency, and craft a test case the runs a simple Spark tool like `PrintReadsSpark` using the local runner with GCS inputs and outputs. I've already started this in the branch https://github.com/broadinstitute/gatk/compare/dr_fix_gcs_spark_writing, but it's not working yet since the gcs-connector requires some extra authentication-related setup.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3125:166,simpl,simple,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3125,1,['simpl'],['simple']
Usability,"As determined by @davidadamsphd , the `Copyable` interface idea won't work:. The recommendation from the Dataflow team was to make a narrow API and do the copying part of the API. I started down this route, and I think it might be doable for things like the walker interface. The idea is to make a Copyable interface and have our interfaces extend that. . However, we have unsafe code already in the engine. I tried to make this SafeDoFn approach, however it became clear quickly that we'd have a combinatorial explosion of classes because we don't just have `DoFn<GATKRead,POut>`, but also `<Iterable<GATKRead>,POut>`, and many others. So, this approach will not work for the engine. I then tried to make a general purpose solution (using coders to write to bytes and then recreate a new class). This doesn't work for a few reasons, most critical is that the coder registry isn't Serializable, so that can't be passed down deep enough to get this to work. While working on this, I chatted with someone on the Dataflow team who is working on the verification on the direct runner. He has a PR out and likely going to get it approved soon. So, for the engine, we could always test using the direct runner and know for sure there are not issues (once we can use his code). However, there are two downsides:. 1) We will need to wait for a cut of the SDK (which looking at their previous clip is likely ~ two weeks away). . 2) I don't know if we want the direct runner test as our general purpose solution. Can we expect Comp Bios to always test with the direct runner first? Will they write anything more complex than functions that use the Walker interface?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661:466,clear,clear,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661,1,['clear'],['clear']
Usability,"As discussed in person, extract a simple `Shard<T>` interface here to be more compatible with the work done in the `SlidingWindowWalker` branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888:34,simpl,simple,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888,1,['simpl'],['simple']
Usability,"As expected, the hdf5 file has a different contigs order.; `; HDF5 ""sample.counts.hdf5"" {; GROUP ""/locatable_metadata/"" {; DATASET ""sequence_dictionary"" {; DATATYPE H5T_STRING {; STRSIZE H5T_VARIABLE;; STRPAD H5T_STR_NULLTERM;; CSET H5T_CSET_ASCII;; CTYPE H5T_C_S1;; }; DATASPACE SIMPLE { ( 1 ) / ( 1 ) }; DATA {; (0): ""@HD	VN:1.6; @SQ	SN:chr1	LN:249250621; @SQ	SN:chr2	LN:243199373; @SQ	SN:chr3	LN:198022430; @SQ	SN:chr4	LN:191154276; @SQ	SN:chr5	LN:180915260; @SQ	SN:chr6	LN:171115067; @SQ	SN:chr7	LN:159138663; @SQ	SN:chr8	LN:146364022; @SQ	SN:chr9	LN:141213431; @SQ	SN:chr10	LN:135534747; @SQ	SN:chr11	LN:135006516; @SQ	SN:chr12	LN:133851895; @SQ	SN:chr13	LN:115169878; @SQ	SN:chr14	LN:107349540; @SQ	SN:chr15	LN:102531392; @SQ	SN:chr16	LN:90354753; @SQ	SN:chr17	LN:81195210; @SQ	SN:chr18	LN:78077248; @SQ	SN:chr19	LN:59128983; @SQ	SN:chr20	LN:63025520; @SQ	SN:chr21	LN:48129895; @SQ	SN:chr22	LN:51304566; @SQ	SN:chrX	LN:155270560; @SQ	SN:chrY	LN:59373566; @SQ	SN:chrM	LN:16571; ""; }; }; }; }; `",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719374564:280,SIMPL,SIMPLE,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719374564,1,['SIMPL'],['SIMPLE']
Usability,"As mentioned in the discussion for https://github.com/broadinstitute/gatk/pull/987, we want to compare the manual sharding approach taken to optimizing BQSR in that branch against an alternative approach of broadcasting the reference and variants. The latter approach would be simpler and more flexible/idiomatic (allow spark to handle sharding and data localization rather than doing it manually), but might be slower. Let's find out what the performance is like for both approaches before making a decision.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/995:277,simpl,simpler,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/995,1,['simpl'],['simpler']
Usability,"As noted by @tedsharpe in the corresponding pull request #4827 there is stuff that can be done to improve the current code:. This is difficult to review because there isn't any client code: I don't know how this is going to be used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5153:761,clear,clearer,761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5153,2,"['clear', 'simpl']","['clearer', 'simple']"
Usability,"As noted in #1752, only the first sample with coverage is returned in the `AlignmentContext`. This is a simple patch to make the `LoscusIteratorByState` returns an `AlignmentContext` with all the information in the provided iterator.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1757:104,simpl,simple,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1757,1,['simpl'],['simple']
Usability,"As part of #8083 we are drastically rewriting the entire Pileup-Caller infrastructure for DRAGEN-GATK. In doing so we have largely neglected its original functionality in Mutect2 and some of the changes (namely the re-factoring of that code to now happen after trimming like in with the GGA code) are going to impact the overall results for pileupcalling. It seems that we never added a real test of this functionality and its unclear to me currently what the meterics are that we want to assure ourselves that its working as intended. In #8083 I have checked that the code is hooked up manually, but its not clear to me what a proper test looks like for mutect without re-hashing the test samples that were being used in the bacterial project. I'm a little skeptical about adding a test that just asserts ""these results were different somehow"" and yet thats essentially the sort of test i would like and that would have saved me here. I would really like to have something better in place, especially if we are going to keep sharing the pileup-calling code between HC and M2 going forward.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8242:609,clear,clear,609,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8242,1,['clear'],['clear']
Usability,"As part of my work in the Pipeline Dev team, I created 2 GATK images to address issue discussed [here](https://github.com/broadinstitute/gatk/issues/8684) (ie. having too many docker layers, we hit ACR limits very quickly). The images are in terrapublic, a premium-tier ACR and is publicly accessible. I made two images, one is squashed to just 1 layer, the other is reduced to just 12 layers (from the original 45). With these changes and the fact that terrapublic is on [premium](https://learn.microsoft.com/en-us/azure/container-registry/container-registry-skus#registry-throughput-and-throttling) tier, the maximum docker pulls per minute becomes 833 (ie. 10k readOps / 12 layers) for the reduced-layers image and 10,000 for the squashed one. We have yet to test these in our pipelines but I anticipate the squashed version to be slower since it won’t be able to take advantage of any parallel pulls or caching, hence the two versions to allow pipeline devs to decide which one is better for their use-case.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8808:490,learn,learn,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8808,1,['learn'],['learn']
Usability,"As part of my work to do a walker for sliding-window processing, I implemented a very simple argument collection for sharding intervals. As an example, I included in the `AssemblyRegionWalker`to allow users to also set the shard step in case they want to apply it. It also allows to specify a window-step to `AssemblyRegionWalker`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2371:86,simpl,simple,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2371,1,['simpl'],['simple']
Usability,"As pointed out by Julian, I incorrectly propagated errors in one part of the model translation. Not sure if this has any effect on ABSOLUTE results, but we can fix it up. Probably should re-examine some of the other expressions as well---would be great to finally get feedback on whether these are at all sensible.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5804:268,feedback,feedback,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804,1,['feedback'],['feedback']
Usability,"As the scripts evolve to be more and more complicated, ; it is time to plan a transition from scripts to a Java tool in GATK. Following the structure that is set up by the scripts in PR #4406 ,; the 1st stage development could be:. 1. parse and check the call sets emitted by callers; basically this is to make sure the tool won't be ""surprised"" by the call sets' ""features"" (bash scripts do this); 2. some basic accounting and metrics, e.g. SINE, LINE peaks (bash scripts do accounting and plots); 3. simple overlap-based TP/FP/FN analysis (bash scripts rely on bedtools for such purpose); 4. Basic reporting on FN/FP rates (bash scripts print a slew of information to screen). Variant files from different callers have their own quirks, (the BND records don't help) having a general purpose tool that covers all major callers is going to take a hefty investment, so we could start from PacBio and GATK-SV call sets.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4684:502,simpl,simple,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4684,1,['simpl'],['simple']
Usability,"As we discussed on Slack, this will fix the NaNs, but I'm not convinced that we should allow the single-contig use case without at least a warning. The ploidy step will essentially perform no inference, since I think the per-contig bias and ploidy factors will cancel out with the way the likelihood is written---it will simply return the prior, and all samples will be guaranteed to have ploidy = 2. @asmirnov239 is going to do some more testing to make sure we understand this right and perhaps add a warning/documentation. The current likelihood is a bit confusing (I tried to address some of these issues in the unmerged ploidy-model update), but in any case, the problem is degenerate and it's hard to define appropriate behavior without additional priors and model structure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6613#issuecomment-631693589:321,simpl,simply,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6613#issuecomment-631693589,2,['simpl'],['simply']
Usability,"As we discussed, it's possible that these are simply common germline CNVs that are being median-normalized out in CR by the PoN. Let's investigate the sample-median-normalized counts in some of the questionable regions, along with the per-bin medians in the PoN. I do not think a gCNV run is necessary (it will probably be a bit expensive, anyway). More generally, I think a better approach to germline tagging would be to avoid the caller entirely. Let's take the ModelSegments output for a normal, and then tag ModelSegments segments in the tumor that sufficiently overlap any normal segment in CR-AF-genomic space (where we have some freedom to define the overlap criteria). Essentially, let's just try to highlight differences between the tumor and normal in CR-AF space. This would rescue events in the normal that may be further amplified or deleted in the tumor. Subsequently, simple filtering of these events would be less misleading than imputation. I do not think such tagging should be implemented in Java, if we can avoid it. Rather, a relatively simple python script that runs through each tumor segment and checks for overlaps would suffice. This script could output a tagged/filtered ModelSegments result, as well as do the conversion step for downstream tools. This also obviates the need for the Java code for combining segment breakpoints and additional CNV collection classes in the current post-processing tools. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-442911810:46,simpl,simply,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-442911810,6,['simpl'],"['simple', 'simply']"
Usability,"At deep learning club, @lh3 suggested a kmer-based approach as the non-deep baseline for the new Mutect PoN. We like this idea and are adopting it. The basic idea is that some regression or binning model of kmers will do what a convolutional network might later do for predicting whether a site is prone to artifacts. The goal here is to get intuition as to how much information is contained in the local sequence context.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3091:8,learn,learning,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3091,2,"['intuit', 'learn']","['intuition', 'learning']"
Usability,"At one point the README says:; > [...] large files used to build GATK, and test files required to run the test suite [...]. Does this mean that all production builds should contain large files?; Are they used by some gatk commands?. The README is just not clear about this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8912:256,clear,clear,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8912,1,['clear'],['clear']
Usability,"At some point in the next several quarters @davidbenjamin I'd recommend a collaboration between your team and the engine team on a `Mutect2Spark` tool. Most of the prerequisite infrastructure has already been implemented for `HaplotypeCallerSpark`, so it may be a much simpler task than you'd imagine!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4726:269,simpl,simpler,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4726,1,['simpl'],['simpler']
Usability,Avx check simple,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5331:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5331,2,['simpl'],['simple']
Usability,BQSR: simplify covariates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/258:6,simpl,simplify,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/258,2,['simpl'],['simplify']
Usability,"BXX:2:1107:10125:22061 147 5 180041116 *0 *; 63M = 180040938 -241; TCTGCGTGGTGTACACCTTGTCGAAGATGCTTTCAGGGGCCATCCACTTCAGGGGCAGCCGGG; :???<>??>?>>>?>????>><>=>>=>>>>>=>>>>>>>>==>>=>>=>>>>>>>>?>9<>=; HC:i:-369427419 MC:Z:101M; BD:Z:IONKLIMLIILMIILKJJILMLJJHMMNOJBIMNKHHMLLMMJLINJIMNLIINOPPONKIKK; MD:Z:101 PG:Z:MarkDuplicates.3.7 RG:Z:1; BI:Z:LQPNNLMNLKMNLLNLLLKMNLKLLMNNNKDJNMLGGLMMNOJMLNLKONMHINOORPNKIMM; NM:i:0 *MQ:i:60 * *AS:i:101 * XS:i:0; -bash-3.2$; ````. In terms of MAPQ being zero, this happens for reads with multiple valid; mappings. That doesn't mean it's a bad mapping, and in fact it can be a; great mapping as you can see for the example read above in the AS tag. ###REVISED; So MAPQ indicates global mapping and AS measures local mapping score.; If one mapping site contains a variant and the other does not, then calling variants for each mapped site is not a good idea. I don't know how supplementary reads are differentiated (MAPQ?--I can look into this), since the way I learned how to run bwa mem asks that all supplementary alignments be treated as secondary alignments (with the `-M` option). It seems important to confirm whether these supplementary alignments that get flagged secondary (with the `-M) also get MAPQ of 0 or have other nonzero MAPQs. We want our tools, including HaplotypeCaller, to differentiate supplementary alignments and secondary alignments and use supplementary alignments in variant discovery. . Secondary alignments are meant for multimappers (multiple valid mapping locations) and supplementary alignments are meant for chimeric reads (say two records for the same read where one half aligns to the left and the other half aligns to the right of a very large deletion against the reference). This means that we should run bwa mem without the `-M` option. . Ok, so I'm going to resume thinking HaplotypeCaller filters on MAPQ of 20. ---. @sooheelee commented on [Wed May 11 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2916:7395,learn,learned,7395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2916,1,['learn'],['learned']
Usability,Back to @jamesemery for a simple change,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237349722:26,simpl,simple,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237349722,2,['simpl'],['simple']
Usability,"Back to @meganshand. I put in a simple mitochondrial integration test. Given that our MC3 validation already covers this particular bug I actually don't think it needs a new test for mitochondria. Also, for later, are any of your spike-in bams public (or rather, public + public)? I noticed that the NA12878 truth doesn't have very low AFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991,2,['simpl'],['simple']
Usability,"Barclay can't currently handle immutable collections in `@Argument` values due to; https://github.com/broadinstitute/gatk/issues/4702. Tests for these arguments are coming in a separate, larger branch, but I; wanted to get the fixes in first since it's such a simple fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4703:260,simpl,simple,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4703,1,['simpl'],['simple']
Usability,BaseRecalibrator with 3GB heap (file size 100GB). This is a snapshot after ~1 hour of runtime. Check out the differences in the y axis here. GATK3 is clearly struggling while Hellbender is doing fine:. GATK3 heap profile after GC (each red triangle is a full GC); ![image](https://cloud.githubusercontent.com/assets/1993519/13857812/dce2bcb8-ec51-11e5-9fb2-9745e86c8e24.png). GATK4 heap profile after GC:; ![image](https://cloud.githubusercontent.com/assets/1993519/13857765/b4525934-ec51-11e5-95aa-4135c05ef850.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198037375:150,clear,clearly,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198037375,1,['clear'],['clearly']
Usability,Beautiful results @samuelklee -- and some of that data was really squirrely too!. I think continuing with the current round of evaluations makes sense. Those unusual sex genotype samples are pretty rare so spot checking should be fine. I'm excited about having a robust set of learning parameters so we can get this tool to users. We can work on catching the tricky and interesting but rare cases as a second phase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485:277,learn,learning,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485,2,['learn'],['learning']
Usability,"Because it is related with the `LocusWalker` pull request, could you review, @droazen? It is a very simple PR, but I will need it in my software. Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220021626:100,simpl,simple,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220021626,1,['simpl'],['simple']
Usability,Because there is currently no way in travis to prevent the build stages from being triggered in every pull request it was decided to simply upload the nightly build without tests instead. An example of how to use build stages can be seen in this branch for future reference: https://github.com/broadinstitute/gatk/tree/je_travisBuildStages,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849:133,simpl,simply,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849,2,['simpl'],['simply']
Usability,BhcmsuamF2YQ==) | `76.72% <0%> (-23.28%)` | `38% <0%> (+25%)` | |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `94.444% <0%> (-5.556%)` | `17% <0%> (+5%)` | |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `87.324% <0%> (-0.431%)` | `17% <0%> (+6%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `88.889% <0%> (-0.383%)` | `72% <0%> (-1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../discovery/alignment/ContigAlignmentsModifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0NvbnRpZ0FsaWdubWVudHNNb2RpZmllci5qYXZh) | `79.235% <0%> (-0.283%)` | `40% <0%> (+4%)` | |; | [...ls/walkers/mutect/M2FiltersArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3982/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkZpbHRlcnNBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...s/GermlineContigPloidyModelArgumentCollection.java](https://codecov,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-352318594:2536,Simpl,SimpleSVType,2536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-352318594,1,['Simpl'],['SimpleSVType']
Usability,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:522,simpl,simplified,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020,2,['simpl'],['simplified']
Usability,"Built a PoN with those normals. Some tuning of parameters was required to get reasonable results. After discussion with @mbabadi, we decided that the current model has a little too much freedom and can probably be made simpler (negative binomial -> Poisson). This should result in more robust results and decrease the amount of tuning needed. Also note that normal sample 8007540251 has something going on in chr12.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616:219,simpl,simpler,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616,2,['simpl'],['simpler']
Usability,"But if your implementation is a `VariantWalker` and #2223 is implemented, this will clash. By the way, I don't know if there is any plan to include all the tools from Picard, but it seems that the behaviour will be replicated if so, no?. Thanks anyway for the feedback, close the PR in case you think that it is not necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-256020212:260,feedback,feedback,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-256020212,2,['feedback'],['feedback']
Usability,"By doing the following, I was able to get a JointGenotyping result for my 343 samples:; - increased the amount of memory allocated to the Java heap in ImportGvcfs to 50000m; - modified the runtime attributes for all the joint genotyping tasks to match the format that Cromwell accepts for HPC environments (https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks); - increasing the runtime memory attribute for ImportGvcfs and GenotypeGvcfs from 26000 MiB to 60 G; - executing the workflow with the following sbatch parameters:; nodes=4; ntasks=32; mem=248g; tmp=429G; - manually tar'ing up all the genomicsdb directories from the execution directories of all 10 shards of ImportGvcfs after they successfully completed GenomicsDBImport and failed with the error message: ; pure virtual method called ; terminate called without active exception; - running an abbreviated version of JointGenotyping which started at GenotypeGvcfs and executed the remainder of the JointGenotyping workflow unchanged.; ; I think this pretty clearly demonstrates that, whatever is going on, it occurs between GenomicsDBImport's successful creation of genomicsdb and the tar -cf of same. The failure is 100% reproducible with a number of different runtime configurations. The error messages are from C++ and seem to be occurring at the point where native C++ code is handing execution back to Java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533:1080,clear,clearly,1080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533,2,['clear'],['clearly']
Usability,"By modifying the test I was able to isolate the error in the `org.broadinstitute.hellbender.tools.walkers.variantutils` package, which is strange because the PR did not modify the javadoc for any class in that package. The integration test runs `com.sun.tools.javadoc.Main.execute` and asserts that the output code is zero, which does not yield a useful error message. In order to produce something more meaningful I hacked the test to output the entire `stdout` and `stderr` as follows:. ```; final StringWriter out = new StringWriter();; final PrintWriter err = new PrintWriter(out);. final int result = com.sun.tools.javadoc.Main.execute(""program"", err, err, err, ""doclet"",docArgList.toArray(new String[] {}));; err.flush(); // probably not needed; String message = out.toString(); // message contains the entire stdout and stderr of the call to execute; Assert.assertEquals(result, 0, message);; ```. The output is about 2000 lines, but a lot of it is clearly innocuous. Removing lines such as; * `2022-08-16T00:09:07.2336106Z [parsing completed 1ms]`; * `2022-08-16T00:09:07.4456202Z [loading ZipFileIndexFileObject[/jars/gatk-package-4.2.6.1-56-gad9a538-SNAPSHOT-test.jar(org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.class)]]`; * `2022-08-16T00:09:07.4459732Z [loading RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalIntervalArgumentCollection.java]]`; * `2022-08-16T00:09:07.4462012Z [parsing started RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalReferenceInputArgumentCollection.java]]`; * 2022-08-16T00:09:07.2322755Z [loading ZipFileObject[/gatk/gatk-package-unspecified-SNAPSHOT-local.jar(htsjdk/samtools/SAMSequenceDictionary.class)]]. brings it down to 353 lines, the majority of which look like . ```2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488:956,clear,clearly,956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488,2,['clear'],['clearly']
Usability,"By the way, I thought @vdauwera was opposed to using optional inputs in this way at some point (see #3657). Was that question ever decided? (I'm still of the opinion that they *should* be used in this way, but this is one of the reasons I didn't for this iteration of the WDL.). To be clear, the pair WDL right now does not allow all of the workflow paths (tumor-only, no PoN, etc.) that the new tools make possible. It only allows the one that we will most likely run in production (matched-normal + PoN). We should probably make the WDL a little more flexible to cover the most common use cases, but I'm fine if it doesn't completely expose all of the possible workflow paths---this would probably just make the WDL harder to maintain. Users can write their own WDLs in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132:285,clear,clear,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132,2,['clear'],['clear']
Usability,"CalculateGenotypePosteriors is only intended for trios. This is noted (admittedly not too clearly) in the output section of the docs (`Per-site, per-trio joint likelihoods (JL) and joint posteriors (JL)` -- which needs a fix to be JP for posteriors) In GATK3, CalculateGenotypePosteriors shares some code with PhaseByTransmission (namely the FamilyLikelihoods.java), which does support parent-child pairs, which is why you encountered comments relevant to pairs. We can certainly update the docs for clarity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438740998:90,clear,clearly,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438740998,2,['clear'],['clearly']
Usability,Can we simplify updates to the GENCODE version?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4786:7,simpl,simplify,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4786,2,['simpl'],['simplify']
Usability,"Can you describe more precisely what you mean by ""processing"" here?. On Wednesday, April 6, 2016, Geraldine Van der Auwera <; notifications@github.com> wrote:. > GATK3 is very slow when processing references with large numbers of; > contigs, such as draft genomes. In the past this mostly affected microbial; > genomes so we didn't do anything about it, but now the Hg38 has a lot more; > contigs so we have to make sure that's not going to be a problem with; > GATK4.; > ; > To be clear, efficient processing of reference genomes with thousands of; > contigs is a must-have.; > ; > Efficient processing of e.g. microbial draft genomes with tens of; > thousands of contigs is a nice-to-have. More than that is just crazy talk.; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/issues/1688. ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1688#issuecomment-206324138:482,clear,clear,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1688#issuecomment-206324138,1,['clear'],['clear']
Usability,"Can you give a bit more information here? If I'm understanding correctly, it's not clear that the same issue is at play here. The original issue was that duplicate/incomplete fragments were causing queries to the workspace to fail. . In this latest instance, it seems you are appending additional samples to the existing workspace. Is that right? If so,; - are you seeing the same/similar error? That is, it's a core dump? Can you share the error messages, any logs, core dump files etc?; - did you clean up the workspace before importing? That is, remove the incomplete fragment @nalinigans identified and the duplicated ones?. My first instinct is that even if the incomplete/duplicated fragments weren't cleaned up, the incremental import shouldn't have an issue -- at least not till it gets to the consolidate phase, which only happens after all batches are imported. Sounds like you were seeing an issue at batch 3 of 4, so might have something to do with the samples in that batch...or some other import issue. You mentioned that previous imports to this particular contig failed -- were those just transient failures that worked when rerun, or was there some configuration that you changed to get that to work?. For completeness, the way I identified duplicate fragments was to do an md5sum check on some of the internal files. If any pair of fragments have the same md5sum they are likely duplicates. So, from the workspace directory, something like:. ```; find . -name ""ALT.tdb"" -exec md5sum {} \;|sort; ```; That will highlight the fragments that are potentially duplicate. To confirm that the fragments are indeed duplicates, you'll then want to take that list of potentially duplicate fragments and check that all corresponding files within each pair of potentially duplicate fragments actually have the same md5sum. I have a crude bash script that I can share if you want.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707:83,clear,clear,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707,2,['clear'],['clear']
Usability,"Can you have a look to this one, @cmnbroad? It is just a simple change for let me upgrade my dependencies and do not include the NPE in not bounded arguments...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467:57,simpl,simple,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467,2,['simpl'],['simple']
Usability,"Can you have a look to this, @cmnbroad? This is a very simple PR and it is already reviewed in Picard...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-268280066:55,simpl,simple,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-268280066,2,['simpl'],['simple']
Usability,"Can you please test this change with the `HaplotypeCaller` in protected and make sure nothing changes? In particular, can you run `HaplotypeCallerIntegrationTest` and `HaplotypeCallerEngineUnitTest` and make sure they pass with this change? This PR makes me a little nervous given the centrality of the classes touched, even though the optimization itself is simple enough...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216595202:359,simpl,simple,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216595202,1,['simpl'],['simple']
Usability,"Certainly the author can't just ""certify"" that the tool works without writing tests to prove it on an ongoing basis as the tool is modified -- I don't think that was what @nh13 meant (but please correct me if I misunderstood). I read that as ""if tests pass, the author certifies that the tool is in a usable state for its intended use(s)""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93806764:301,usab,usable,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93806764,1,['usab'],['usable']
Usability,Change inputs from optional to required according to feedback [VS-1300],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8822:53,feedback,feedback,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8822,2,['feedback'],['feedback']
Usability,"Changes to the testing framework to remove references to the test resources, keeping them into the src/test package. This changes include:. * Factor out a `GATKBaseTest` for separate test resources from test utilities in `BaseTest`; * Remove duplicated `CleanSamIntegrationTest`; * Repackage `CommandLineProgramTest` to be in the test sources, and use it's interface in testers; * Move some testers to the src/test package because they are tool-specific (added TODO to other ones that aren't that clear); * Refactor `TargetsToolsTestUtils` to use a provided reference. Closes #3029; Closes #2125",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475:497,clear,clear,497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475,1,['clear'],['clear']
Usability,Checking in from the future: we have clearly been failing this as I'm finding `time gatkPrintReads --help` takes ~2.5-3 seconds.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2127#issuecomment-494961720:37,clear,clearly,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2127#issuecomment-494961720,2,['clear'],['clearly']
Usability,"Chunk full list of .tsv files ready to load to bq into sets that are less than the 15tb limit set on each bq load. From the original; datatype_tsvs directory, each set is moved to its own directory, and when the load is complete, the data is moved into a done directory within each set. . Assuming pet tsvs and 1 set, at the start:; gs://bucket/pet_tsvs/pet_001_*. At end:; gs://bucket/pet_tsvs/set_1/done/pet_001_*. --; The output file, `bq_final_job_statuses.txt`, contains the following columns (and example data):; 1. bq load job ID : bqjob_r2715fbcab1fd0e44_00000178708f0abe_1; 2. set number:; 3. path to set data: gs://fc-13e1680e-eb3d-4102-975a-be0142ee9618/full_15tb_test_2/pet_tsvs/set_1/; 4. status of the bq load: SUCCESS/FAIL. What should be the best user experience in case of FAIL?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7167:763,user experience,user experience,763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7167,1,['user experience'],['user experience']
Usability,Clean up and improve re-usability of help classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4247:24,usab,usability,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247,2,['usab'],['usability']
Usability,"Cleaning the bam (and the sam) test files is almost done - it's taken some time because some have been like mini debugging exercises in themselves, followed by the capturing and substitution of the new expected output files for the tests. There are a few issues that still remain, however, and unfortunately I am out of time - I'm headed to an overseas meeting on Monday and will be out for two weeks. I had hoped to finish before the trip, but my BMC Bioinformatics paper came through so I had to spend time on proofs etc.. I will resume ASAP after I get back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-122571160:532,resume,resume,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-122571160,1,['resume'],['resume']
Usability,"Clear guidelines needed for GermlineCNVCaller expected runtime, cpu usage and memory usage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:0,Clear,Clear,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,3,"['Clear', 'guid']","['Clear', 'guidelines']"
Usability,Clear up keep duplicates confusion in CNV tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3367:0,Clear,Clear,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3367,1,['Clear'],['Clear']
Usability,Clearer exception messages for ploidy priors in DetermineGermlineContigPloidy,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4486:0,Clear,Clearer,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4486,1,['Clear'],['Clearer']
Usability,Clearly label the number of reads in the CountReads output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6449:0,Clear,Clearly,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6449,1,['Clear'],['Clearly']
Usability,"Closes #1493. @droazen @cmnbroad Is this what was intended by #1493 -- just replace `LinkedList` with `ArrayList` and `clear` the reservoir, keeping its capacity allocated, when possible?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074:119,clear,clear,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074,1,['clear'],['clear']
Usability,"Closes #4188. @sooheelee This wraps up the wish list in #4188. @takutosato Although funcotator is off in the Travis test, I *did* test it locally. Also, I have tested with and without compressed vcf output. The funcotator command is simply copied from @jonn-smith's funcotator.wdl. Subworkflows are a pain in Firecloud, which is why I don't `import` it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4271:233,simpl,simply,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4271,1,['simpl'],['simply']
Usability,"Closes #4893. Closes #5086. Closes #5684. Closes #4500. Makes #4933, #4958, and #5085 possible. @takutosato Failing tests are superficial. You can begin reviewing. . This is a big PR:. * Refactor of all M2 filtering. Each filter has its own class, and the filtering engine ties it all together.; * Learn allele fraction clustering and somatic SNV and indel priors.; * More probabilistic filters.; * All filters have a common probabilistic threshold.; * M2 determines threshold automatically.; * Rewrite of all M2 documentation.; * Several filters, including strand bias and normal artifact, learn their own parameters. @LeeTL1220 M2 validations look really, really good. @meganshand Once this goes in mitochondria best practices will need to be tweaked again. We can merge the dangling tails homoplasmic fix before merging this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5688:298,Learn,Learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5688,2,"['Learn', 'learn']","['Learn', 'learn']"
Usability,"Closes #5821. @bhanugandham With this PR we will no longer have to recommend against using `CalculateContamination` for gene panels. @takutosato This puts in a last-ditch calculation that uses hom ref sites *and* uses sites that didn't get a clear minor allele fraction segmentation. To avoid distorting the signal with LoH hets, it removes the hom ref sites with the highest allele fraction, which will work unless there's a huge amount of CNV. This will result in a slight underestimate, but for a small gene panel there's not much you can do.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5873:242,clear,clear,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5873,1,['clear'],['clear']
Usability,Closes #6342.; Closes #6314.; Closes #6294.; Closes #5492. @takutosato Fixing bugs and simplifying code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6485:87,simpl,simplifying,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6485,1,['simpl'],['simplifying']
Usability,"Closes #6586. @droazen . `AlleleLikelihoods` caches the evidence-to-index `Map`. The previous implementation tried to update this map on the fly whenever evidence was removed. The new approach is to simply invalidate the cache and allow the existing code to generate it to run later. I don't expect this to cause performance problems for a few reasons:. 1. It only applies when we're doing contamination downsampling.; 2. It may save time whenever evidence is removed and we don't need the evidence-to-index map later.; 3. Regenerating the cache is O(N), but so is updating on-the-fly even when only one read is removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6593:199,simpl,simply,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6593,1,['simpl'],['simply']
Usability,Closing PR. It is quite old and it isn't clear that this is necssary for the current codebase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-481769701:41,clear,clear,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-481769701,2,['clear'],['clear']
Usability,"Closing as a part of my issue clearing rampage, but let it be known Pyro is on the roadmap for future CNV models, and we are currently looking into updating PyMC3 to resolve some dependency issues with gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041:30,clear,clearing,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041,2,['clear'],['clearing']
Usability,Closing because I haven't heard back from the user. If the forum discussion resumes and it turns out that there is a bug I will re-open a more specific ticket.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941:76,resume,resumes,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941,2,['resume'],['resumes']
Usability,"CollatingInterval does the equivalent of intern() without the overhead: It always returns the dictionary's copy of the contig name. (And it does this perforce. I think we're actually pretty inconsistent about interning.). I've tested sorting (which I would expect to be dominated by the cost of interval comparison) with 1) CollatingIntervals, and then, using the DictionaryOrderComparator, 2) SimpleIntervals with effectively interned contig Strings, and 3) SimpleIntervals with novel Strings. CollatingInterval is (disappointingly to me) only twice as fast with interned Strings, and three times as fast with novel Strings on my pathetically ancient Ubuntu machine. So is 2x and 3x ""a lot of time and effort""?. Seems to me like the potential issues with slightly different references are already a can of worms, and I don't see that this creates new worms. You know what? It really isn't worth the struggle. It seemed kind of cool and innovative to me, but nobody but me seems to find it compelling. I'll get rid of it all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843398745:394,Simpl,SimpleIntervals,394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-843398745,2,['Simpl'],['SimpleIntervals']
Usability,CompareBaseQualities requires a shuffle because it does not assume identical read sorting. It will be unusably slow for large files - and unnecessarily so because we aim to have the read order exactly the same. It may be simplest to implement as a walker like CompareSamFiles,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1398:221,simpl,simplest,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1398,1,['simpl'],['simplest']
Usability,"Completing https://github.com/broadinstitute/hellbender/issues/673 will take care of the case of ""missing reference for CRAM"", but we also need to make sure we're handling the case of ""wrong reference"" elegantly (where elegantly means ""throw a `UserException` with a descriptive error message). We want a test case with a reference that is the wrong reference for a CRAM, but has a compatible sequence dictionary (so that it won't be caught by the sequence dictionary validation). Both the wrong and missing reference cases should have a simple integration test that runs, eg., `PrintReads` with `expectedExceptions = UserException.class`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374:538,simpl,simple,538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374,1,['simpl'],['simple']
Usability,Complexity Δ | |; |---|---|---|---|; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `76.471% <0%> (-1.654%)` | `9% <0%> (+1%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `69.767% <0%> (-0.348%)` | `18% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <0%> (ø)` | `36% <0%> (ø)` | :arrow_down: |; | [.../tsv/SimpleCSVWriterWrapperWithHeaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlQ1NWV3JpdGVyV3JhcHBlcldpdGhIZWFkZXJVbml0VGVzdC5qYXZh) | `48.077% <0%> (ø)` | `7% <0%> (?)` | |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0%> (ø)` | `11% <0%> (?)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.971% <0%> (+0.245%)` | `159% <0%> (ø)` | :arrow_down: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430:1885,Simpl,SimpleCSVWriterWrapperWithHeaderUnitTest,1885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430,1,['Simpl'],['SimpleCSVWriterWrapperWithHeaderUnitTest']
Usability,"Comprises the commits after 7992f64. The only commit with real substance is `Updated metadata and abstract collection classes.`. The rest of the commits simply update calling code, related tests, and test files. These updates were slightly less trivial for the plotting classes, so these are also split off into separate commits. Again, probably could be engineered better (there are two parallel class hierarchies for metadata and collection classes, which is kind of gross), but we can refactor later if needed. @asmirnov239 please review. Again, lower priority than gCNV VCF, but the sooner this is in master the easier it will be to get things into FireCloud. Let's try for early next week. I'll start doc updates concurrently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3914:153,simpl,simply,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3914,1,['simpl'],['simply']
Usability,"Congratulations on your graduation! And good luck with your application, I know from personal experience it is a hassle, but it’s worth it!. Yes, that is what we are proposing. @davidbenjamin can give you some more guidance to get you started. . Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404109319:215,guid,guidance,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404109319,2,['guid'],['guidance']
Usability,Consider replacing ReferenceShard and VariantShard with SimpleInterval,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/703:56,Simpl,SimpleInterval,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/703,1,['Simpl'],['SimpleInterval']
Usability,"Contains mostly very simple utility methods, but could stand some testing.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5749:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5749,1,['simpl'],['simple']
Usability,"Copying over some discussion from Slack, with some slight modifications:. > I took a quick stab at updating the environment for gCNV. Even taking out TensorFlow (assuming that the CNN will not be supported by this environment), it's a difficult task:; > 1. The goal is to update Python from 3.6 to 3.10+, since Terra now requires the latter for officially supported images.; > 2. However, gCNV relies on the PyMC3 package. PyMC3 3.1 is currently used in GATK master. 3.1 was released in 2017, not long before our release of gCNV in 2018, but it's very old now.; > 3. The latest version of Python that is supported by PyMC3 3.1 in conda is Python 3.6.; > 4. @asmirnov239 has a draft PR (#8094) that updates PyMC3 to 3.5 and Python to 3.7, which clearly still falls short of Python 3.10+. This PR also updated some gCNV code to make it compatible with PyMC3 3.5. (It also removed TensorFlow and added PyTorch.); > 5. @asmirnov239 also merged a PR that added tests for numerical reproducibility of GermlineCNVCaller in cohort mode in #7889.; > 6. The earliest version of PyMC that supports Python 3.10+ is PyMC 4, released in 2022.; > 7. However, PyMC 4 introduces API changes, which will also require additional gCNV code changes and numerical testing.; > 8. These API changes are because the underlying computational backend for PyMC was updated from Theano (think of this as an old alternative to TensorFlow) to Aesara.; > 9. Since then, PyMC 5.9 has been released and the underlying backend has been updated again, from Aesara to PyTensor.; > 10. So if we are going to update the environment to support Python 3.10+, it probably makes sense to go all the way to PyMC 5.9. I've made some strides in this PR; as of [6b08f3a](https://github.com/broadinstitute/gatk/pull/8561/commits/6b08f3af205cb9af1f5c63a0786f9a5a52cd78c1), I've made enough updates to accommodate API changes so that cohort-mode inference for both GermlineCNVCaller and DetermineGermlineContigPloidy runs successfully under Python 3.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561:744,clear,clearly,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561,1,['clear'],['clearly']
Usability,Could I have some feedback about the efficiency of the Fisher's Exact Test implemented here? I'm planning to use it in other context where the performance could be reduced and I think that this is a good opportunity to have some information about it. Thanks in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267036486:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267036486,2,['feedback'],['feedback']
Usability,CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `1.835% <0%> (-0.804%)` | `2% <0%> (ø)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `28% <0%> (-0.125%)` | `8% <0%> (+3%)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `76.471% <0%> (ø)` | `31% <0%> (+8%)` | :arrow_up: |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `100% <0%> (ø)` | `8% <0%> (+1%)` | :arrow_up: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <0%> (ø)` | `42% <0%> (+12%)` | :arrow_up: |; | [.../tools/copynumber/denoising/SVDDenoisingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Rlbm9pc2luZy9TVkREZW5vaXNpbmdVdGlscy5qYXZh) | `79.92% <0%> (+0.521%)` | `51% <0%> (+4%)` | :arrow_up: |; | [...lbender/utils/variant/GATKVariantContextUtils.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370585617:2246,Simpl,SimpleNovelAdjacencyInterpreter,2246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370585617,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"Creates a new ""build-base"" Docker image for the expensive and less frequently changed layers of the build image allowing for much improved variantstore image build times. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%20v3/job_history/ff13e48c-a9dc-48d7-8056-63d4f2028dc0). Other improvements:. * Bumps version of Google Cloud SDK base Docker image to latest `408.0.1-alpine`; * Bumps Arrow library version from 8.0.0 to 10.0.0; * Simplifies Arrow build to use `ninja`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8085:483,Simpl,Simplifies,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8085,1,['Simpl'],['Simplifies']
Usability,Creating tools and simple command-line for validation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1240:19,simpl,simple,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1240,2,['simpl'],['simple']
Usability,"Credentials.java:100); 	at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:4519,Learn,LearnReadOrientationModel,4519,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,Currently GenomicsDB's `GenomicsDBImporter.generateVidMapFromMergedHeader` only includes specific subclasses of `VCFHeaderLine`. It's missing support for `VCFHeaderLine` and `SimpleVCFHeaderLine`. These header lines should be handled and propagated to the output.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3677:175,Simpl,SimpleVCFHeaderLine,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3677,1,['Simpl'],['SimpleVCFHeaderLine']
Usability,"Currently `AddContextDataToReadSparkOptimized` avoids shuffles by doing its own sharding. This introduces a lot of additional complexity, and doesn't leverage the built-in support for sharding in spark. During a discussion today it came up that this code could potentially be made more idiomatic/spark-friendly by using a custom partitioner. Let's investigate whether this is possible and how easy a change it would be to make (and if it's workable and a simple change, put together a quick implementation). Making `AddContextDataToReadSparkOptimized` more spark-idiomatic would allow it to compare more favorably from a stylistic standpoint against the broadcast-based approach when we do https://github.com/broadinstitute/gatk/issues/995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1007:455,simpl,simple,455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1007,1,['simpl'],['simple']
Usability,"Currently command line boolean flags can optionally accept an argument. This plays poorly with PositionalArguments in the current version of our parser. . `--flag 1 2` is currently parsed as `(--flag 1) 2` which is then fails; it can be worked around by specifying `--flag true 1 2`, but this is suboptimal. A solution to this has been introduced in the 4.9 snapshot build of jopt-simple see here https://github.com/pholser/jopt-simple/issues/76.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/170:381,simpl,simple,381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/170,2,['simpl'],['simple']
Usability,"Currently in Hellbender we have:. GenomeLoc; |-->UnvalidatingGenomeLoc . htsjdk has:; Feature (not conceptually an interval, but it's the same interface as an interval and bed features are nothing but intervals). htsjdk.samtools.QueryInterval -- interval for querying a bam file. htsjdk.samtools.util.Interval -- a named genomic interval, similar to genome loc; |--> Gene; |--> Bait. htsjdk.tribble.index.interval.Interval -- a simple range. We also have the HasGenomeLocation interface which many classes in GATK implement. There's a whole bunch of interval related classes:. We have two different interval trees:; htsjdk.tribble.index.interval.IntervalTree; htsjdk.samtools.util.IntervalTree. a couple of interval utils:; htsjdk.samtools.util.IntervalUtil; org.broadinstitute.hellbender.utils.IntervalUtils",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/159:428,simpl,simple,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/159,1,['simpl'],['simple']
Usability,"Currently read transformers are `read -> read`, but they often work by mutating their input parameter and returning it. We should either change it to a more functional style, with a new read returned and the passed in read left unchanged, or we should make them `void` functions to make it clear that they are intended to mutate their input read.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/312:290,clear,clear,290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312,1,['clear'],['clear']
Usability,Currently the GATK4 version of SplitNCigarReads softclips the overlapping segments of the reads across the split segments. This is a departure from the original GAKT3 behavior which hardclipped the edges. A few discussions have happened where this has confused users since running HaplotypeCaller/Mutect on the results can often result in confusing indels when they try to align the soft-clipped segments. Currently we can simply tell people to ignore soft-clipped bases in those tools but another solution for users who want to call based on split reads would be to add an option to the tool SplitNCigarReads to call to the hard-clipping machinery instead. We would have to be careful that the mate tags are correctly computed based on the hard-clipping.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7356:423,simpl,simply,423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7356,1,['simpl'],['simply']
Usability,Currently the `HaplotypeCallerIntegrationTests` cover most of the common use cases for our best practices HaplotypeCaller pipeline but are deficient in covering a few important less-used arguments. A non-exhaustive list of un-tested modes for the HaplotypeCaller that are significant enough to warrant better long term integration tests to ensure they aren't broken in the future are as follows:; - Multisample Calling Mode; - `--emit-all-sites`; - Genotype Given Alleles Mode. To complete this task would mean simply adding some new tests and possibly uploading to our LFS storage some data that appropriately covers the use case to make sure we don't accidentally break these functionalities in embarrassing ways going forwards. Some discretion might be necessary to decide what HC arguments are important enough to warrant new tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7632:511,simpl,simply,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7632,1,['simpl'],['simply']
Usability,Currently the `SimpleKeyXsvFuncotationFactory` needs to be improved to throw better error messages when the encoding of a file is inconsistent. This is really an issue involving how `Files.lines()` deals with the encodings. When using the `PathLineIterator` the encoding issue is not found until calling `it.next()` and getting a line with inconsistent encodings. This issue is then manifested as a `java.nio.charset.MalformedInputException`. This page has some information on a fix:. https://stackoverflow.com/questions/26064689/files-lines-to-skip-broken-lines-in-java8,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4006:15,Simpl,SimpleKeyXsvFuncotationFactory,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4006,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"Currently the prefetcher threads all show up as something like ""thread-pool-1-thread-1"". It would be nice if we could give them a name so it's immediately clear in the profiler what they are. It looks like this can be done with a custom thread factory. Guava has one that should make this easy, ; `new ThreadFactoryBuilder().setNameFormat(""nio-prefetcher-thread-%d"").build()`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2652:155,clear,clear,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2652,1,['clear'],['clear']
Usability,"Currently there are number of boolean arguments in GATKTool that are set by default to `true`. Unfortunately, the current syntax for changing that value on the command line is to write ""--argument-name false"" (eg. `--create-output-bam-index false`) which is confusing an counterintuitive. This format made more sense for arguments when the syntax in picard/gatk3 used to be ""ARGUMENT=FALSE"". I propose that these arguments have their statements inverted wherever possible so that the user should always be negating some option that was perviously true (eg. `--disable-output-bam-index-creation` or some other alternative). Given the new argument input format this makes more intuitive sense and helps differentiate between toggle arguments and arguments with inputs on the command line without having to remember what the default value is. . A change like this would affect a number of old/bedrock arguments in the engine like, `--create-output-variant-index`, `--add-output-sam-program-record`, and `--add-output-vcf-command-line` to name a few. Since there are many arguments following this pattern perhaps the overhead from making a change like this isn't worth it. . (Also applies to changes in GATKSparkTool #5574)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5600:675,intuit,intuitive,675,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5600,1,['intuit'],['intuitive']
Usability,"Currently there are two types of vc merging implemented in GATKVariantContextUtils. One (simpleMerge) is use for combine vcfs whereas the other (referenceConfidenceMerge) is used for combining gvcfs (also regenotyping). Despite differences between these two types of merge it seems that both should share quite a bit of code. Moreover it might be useful to sand away some of the differences as long as they don't change the current default behavior of CombineVariants or GenotypeGVCFs. . For example, why not allow annotation merging using means/medians in CombineVariants as an (advanced) option. Or could GenotypeGVCF bee seen as. first a CombineVariant's simple Merge, followed by a regenotyping and <NON_REF> clearing step?. Also these two functionalities seem to be rather complex as merging VCF's VC is a meaningful manner is not as trivial as it seems as you can see in the code. As a result they are cluttering GATKVCUtils code brining it over 2000 lines. Please consider to move them out to their own helping class or hierarchy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/132:89,simpl,simpleMerge,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/132,3,"['clear', 'simpl']","['clearing', 'simple', 'simpleMerge']"
Usability,Currently there is a FeatureWalker in hellbender-protected that could be moved to GATK4. In fact it would be a great parent (generalization) of the current VariantWalker as VariantContext are simply a feature.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1121:192,simpl,simply,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1121,1,['simpl'],['simply']
Usability,"Currently we emit `cpx.vcf` for complex SV's, and one record for each variant.; But this may hurt us in terms of performance evaluation when smaller, simple variants are incorporated into a complex one.; We should have a tool to extract these smaller variants and link them with `EVENTID`.; This shouldn't be difficult.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4323:150,simpl,simple,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4323,1,['simpl'],['simple']
Usability,"Currently, `IntervalArgumentCollection` still uses `GenomeLocs` internally during parsing, despite the rest of the engine using `SimpleIntervals`. This forces us to provide a sequence dictionary when interval arguments are present even if the only input is an interval list (eg., an `IntervalWalker` that purely processes/transforms intervals). We should provide a mode in `IntervalArgumentCollection` in which intervals can be parsed into `SimpleIntervals` without a sequence dictionary. This will require us to fill in a special value such as `Integer.MAX_VALUE` for the stop position of intervals that don't contain a stop position (eg., ""chr1"" or ""chr1:1+""), since we won't know the true contig lengths, but our future query interfaces should all be robust to requests for locations outside of contig boundaries (and not blow up given such requests). This will also require adding some way of determining whether or not an interval has been validated against a sequence dictionary -- perhaps `ValidatedInterval` could be a subclass of `SimpleInterval`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/298:129,Simpl,SimpleIntervals,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/298,3,['Simpl'],"['SimpleInterval', 'SimpleIntervals']"
Usability,"D; [INFO] GATK Aggregator Protected .......................... SKIPPED; [INFO] GATK Tools Private ................................. SKIPPED; [INFO] GATK Package Internal .............................. SKIPPED; [INFO] NA12878 KB Utilities ............................... SKIPPED; [INFO] GATK Queue Private ................................. SKIPPED; [INFO] GATK Queue Extensions Internal ..................... SKIPPED; [INFO] GATK Queue Package Internal ........................ SKIPPED; [INFO] GATK Aggregator Private ............................ SKIPPED; [INFO] ------------------------------------------------------------------------; [INFO] BUILD FAILURE; [INFO] ------------------------------------------------------------------------; [INFO] Total time: 01:23 min; [INFO] Finished at: 2018-04-20T20:52:19+02:00; [INFO] Final Memory: 67M/922M; [INFO] ------------------------------------------------------------------------; [ERROR] Failed to execute goal on project external-example: Could not resolve dependencies for project org.mycompany.app:external-example:jar:1.0-SNAPSHOT: The following artifacts could not be resolved: org.broadinstitute.gatk:gatk-tools-public:jar:3.8-SNAPSHOT, org.broadinstitute.gatk:gatk-utils:jar:tests:3.8-SNAPSHOT, org.broadinstitute.gatk:gatk-engine:jar:tests:3.8-SNAPSHOT: Could not find artifact org.broadinstitute.gatk:gatk-tools-public:jar:3.8-SNAPSHOT in gatk.public.repo.local (file:../../public/repo) -> [Help 1]; [ERROR] ; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR] ; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException; [ERROR] ; [ERROR] After correcting the problems, you can resume the build with the command; [ERROR] mvn <goals> -rf :external-example; ```. it could be the cause.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686:3514,resume,resume,3514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686,1,['resume'],['resume']
Usability,DDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); at org.apache.spark.rdd.RDD.collect(RDD.scala:911); at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:360); at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.writeVariants(HaplotypeCallerSpark.java:205); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.runTool(HaplotypeCallerSpark.java:115); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:121); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:142); at org.broadinstitute.hellbender.Main.main(Main.java:220); Caused by: java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:10389,clear,clear,10389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['clear'],['clear']
Usability,Data is sensitive and bug is recapitulated in https://github.com/broadinstitute/dsde-docs/issues/3026. CombineGVCFs gives the following error message:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:HLA-DRB1*15:03:01:02 start:11569 end:11005; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.onTraversalSuccess(CombineGVCFs.java:415); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:895); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```; Here are the dictionary lines for two consecutive HLA-DRB1 contigs:; ```; @SQ SN:HLA-DRB1*15:03:01:02 LN:11569 M5:4e0d459b9bd15bff8645de84334e3d25 AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; @SQ SN:HLA-DRB1*16:02:01 LN:11005 M5:4a972df76bd3ee2857b87bd5be5ea00a AS:38 UR:/seq/references/Homo_sapiens_assembly38/v0/Homo_sapiens_assembly38.fasta SP:Homo sapiens; ```; Notice the `LN` lengths match up. It appears that our tool is mistaking contig information.; Note that `HLA-DRB1*16:02:01` is the very last contig in GRCh38.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4572:377,Simpl,SimpleInterval,377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4572,4,['Simpl'],['SimpleInterval']
Usability,"Dear *,; I just tested the Docker Container 4.4.0.0 (upgrade from 4.3.0.0) and my pipeline tried to execute BaseRecalibrator and ApplyBQSR. It crashed with a message:; `/usr/bin/env: 'python': No such file or directory`. A simple test with a python script, using ""/usr/bin/python"" in shebang revealed that is truly not available in this path.; A test with the 4.3.0.0 Container worked. I solved the issue by typing ; `ln -s /usr/bin/python3 /usr/bin/python`. Kind regards,; Daniel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8402:223,simpl,simple,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8402,1,['simpl'],['simple']
Usability,"Dear Gökalp: . Thank you very much!. You suggested to run **conda env create -f gatkcondaenv.yml**. Where is the **gatkcondaenv.yml** file?. If I simply used **git clone https://github.com/broadinstitute/gatk.git**. The cloned package has a **gatk executable**. I found that I could run it directly. If I simply go to **https://gatk.broadinstitute.org**/hc/en-us homepage, and download the latest version file https://github.com/broadinstitute/gatk/releases/download/4.6.0.0/gatk-4.6.0.0.zip. After unzipping it, there is also a **gatk executable**, and I could also run it directly (./gatk) on the shell. So, now I am a bit puzzled: which is the recommended way to install and run GATK?. Finally, it seems that you guys now recommend **WARP** https://broadinstitute.github.io/warp/, which seems to be a completely new set of tools and pipeline scripts. Is WDL now the recommended approach to run GATK?. Thank you very much & best regards,; Jie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2215391015:146,simpl,simply,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2215391015,4,['simpl'],['simply']
Usability,"Dear all,. I am a bit confused why GATK uses `[0,1,2]` for the `GT` files, even though VCF specifications clearly state that the `GT` field is `encoded as allele values separated by either of / or |`. They even say that for `diploid calls examples could be 0/1, 1 | 0, or 1/2, etc`. As it is right now, if I read a VCF from GATK CNV germline pipeline through `bcftools`, the `GT` field is changed to `-65`:; ```; 1 17345376 CNV_1_17345376_161326630 N <DUP> 101.19 . END=161326630 GT:CN:NP:QA:QS:QSE:QSS -65:3:13:11:101:3:18. 1 161332119 CNV_1_161332119_161332223 N <DEL> 3.19 . END=161332223 GT:CN:NP:QA:QS:QSE:QSS -65:1:1:3:3:3:3. 1 193091331 CNV_1_193091331_241683022 N <DUP> 268.21 . END=241683022 GT:CN:NP:QA:QS:QSE:QSS -65:3:27:34:268:36:3. 2 96919546 CNV_2_96919546_96931119 N . 62.93 . END=96931119 GT:CN:NP:QA:QS:QSE:QSS -65:2:3:38:63:38:63. 3 10183532 CNV_3_10183532_69928534 N . 469.93 . END=69928534 GT:CN:NP:QA:QS:QSE:QSS -65:2:22:31:470:19:75. 3 69986973 CNV_3_69986973_70014399 N <DUP> 10.12 . END=70014399 GT:CN:NP:QA:QS:QSE:QSS -65:3:8:4:10:4:10; ```. Any reason to not use the standaed `GT` format?. I have also noticed that GATK outputs some non-variable SVs to the VCF without any ALT allele. Why not remove them if they are actually not SVs, if `GT=0` and `CN=2`?. thanks,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904:106,clear,clearly,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904,2,['clear'],['clearly']
Usability,"Dear developers,; At present, I am using GATK's CombineGVCFs module in AWS platform to merge gvcf of 30 samples respectively according to different chromosomes. This species has 10 chromosomes, so a total of 10 CombineGVCFs tasks are carried out in parallel (10 EC2 virtual machines are opened respectively). The input gvcf file is stored in S3 and mounted to the EC2 VM. In this process, java.io.IOException occurs after some samples are analyzed: The Transport endpoint is not connected, but the merged gvcf file and its index are still produced. I did not find any feedback about GATK relation on the Internet, so I would like to know the reason for the error and why some staining machines reported errors. Some will not report errors, in addition, will the gvcf file generated after the ""Transport endpoint is not connected"" prompt be used? At present, I have tried gatk4.5, 4.4, 4.2 and other versions, and this has happened. Paste the run log as follows:. 06:26:14.775 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 06:26:14.867 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.869 INFO  CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.5.0.0; 06:26:14.869 INFO  CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 06:26:14.869 INFO  CombineGVCFs - Executing as root@ip-10-1-156-254.cn-northwest-1.compute.internal on Linux v4.14.334-252.552.amzn2.x86_64 amd64; 06:26:14.869 INFO  CombineGVCFs - Java runtime: OpenJDK 64-Bit Server VM v17.0.9+9-Ubuntu-122.04; 06:26:14.869 INFO  CombineGVCFs - Start Date/Time: March 13, 2024 at 6:26:14 AM GMT; 06:26:14.869 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.869 INFO  CombineGVCFs - ------------------------------------------------------------; 06:26:14.870 INFO  CombineGVCFs - HTSJDK Version: 4.1.0; 06:2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8735:568,feedback,feedback,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8735,1,['feedback'],['feedback']
Usability,"Decode().` In fact the only code path I can see that calls fullyDecode() is by setting the `fully-decode` SelectVariants argument, which seems to just call fullyDecode at the beginning just for the sake of calling it (or so it appears to me. The utility of this command line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype fields like 'GQ > 0', where the behavior in the multi-sample case is 'GQ > 0' in at least one sample. I have not added the ability to do 'GQ > 0 for all samples' but it should be a simple (but not easy…) exercise in boolean operations.; * `applyJexlFiltersBeforeFilteringGenotypes`: if set to true, we do the JEXL checking before we subset by samples. In my tests, performance improvement from this option was very modest. Subsetting a ~3k 1kg SV vcf to a single sample was about 30 seconds faster (out of ~20 min total run time) than the default. I kept it in the PR because I thought some user might find it useful, but I wouldn't be opposed to removing it. Tests needed:; - [x] Filter by genotypes with a new flag --genotype-select, with the default behavior being 'passes if at least one sample passes' ; - [x] Multiple --select expressions should be combined with logical-or; - [x] Test string annotations (e.g. ALGORITHM == 'depth'); - [x] Jexl involving with logical-and (e.g. AC > 0 && AF > 0.01); - [x] Access genotypes directly e.g. vc.getsample('NA12878'); - [x] DP > 0 as --genotype-select and as --select; - [x] Combine --select and --select-genotypes; - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:2181,simpl,simple,2181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['simpl'],['simple']
Usability,Deep learning model for Mutect,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3239:5,learn,learning,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3239,2,['learn'],['learning']
Usability,"Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3597,Learn,LearnReadOrientationModel,3597,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6604,Learn,LearnReadOrientationModel,6604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"Despite possible not-best practices, it is alarming that this base-quality clipping action is occurring for reads that HaplotypeCaller sees (reads pass engine filtering), that it is undocumented, and that it seems to inconsistently alternate between assigning ! and 5 scores. Should note that the users who reported this inconsistency also have proposed code changes to fix the inconsistency such that clipping does not occur at all. . It's not clear to me: ; [1] Do we intend for this clipping action to occur or not, and; [2] If yes, then is it clipping in a manner that we intend?. Please let me know if this is something to clarify on the documentation end. Also, if you need, I can bundle up the data I generated in broadinstitute/dsde-docs#2661 towards examining this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3834#issuecomment-344370788:182,undo,undocumented,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3834#issuecomment-344370788,4,"['clear', 'undo']","['clear', 'undocumented']"
Usability,"Did a quick test with sklearn's BayesianGaussianMixture, fitting 8 components to 2.5M 10D points generated from 4 isotropic blobs. On a Google Colab instance (which I believe are n1-highmem-2s), 150 iterations (which I think is the current maximum) completed in 14 minutes, with `%memit` reporting a memory peak of ~1.5GB. Note that convergence within the default tolerance isn't actually reached in 150 iterations for this toy data (as usual, it takes a while for the weights of unused components to shrink to zero). In any case, we'd have to compare against the number of iterations currently required to converge with the real data (and perhaps also check that the convergence criteria match up) to get a better idea of real runtime. Various tweaks to priors or other runtime options (such as k-means vs. random initialization) could also affect convergence speed. Minibatching isn't built in, but I think it should be pretty trivial to hack together something with the `warm_start` option; we could probably just do a warm start with a subset of the data. See also https://github.com/scikit-learn/scikit-learn/pull/9334.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6425#issuecomment-594205039:1095,learn,learn,1095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6425#issuecomment-594205039,4,['learn'],['learn']
Usability,"Did some more thinking about this issue. Ideally, we'd drop all -L bins that overlap at all with any -XL regions, then check that the remaining bins are a subset of the annotated intervals and/or count files, if available. This seems most natural, in that -L/-XL would specify the desired set of intervals for filtering, and we'd fail if all of these are not available in the other inputs. However, due to the way intervals are resolved by the engine, I don't think it's easy to identify which bins overlap with -XL regions---the engine will instead split bins and retain the parts that don't overlap. So alternatively, if we assume that in typical use the annotated intervals and count files will contain the desired intervals as a subset, we can simply take the intersection of all intervals to drop these partial bins. However, if a user screws up and provides annotated intervals or count files with bins that don't match those specified via -L, then we don't really have a good strategy for failing---probably the only fair check we can do is fail if no bins remain after intersection. If we assume that users will typically be using or following the WDL, I think I'm OK with the second strategy. Any objections or thoughts, @sooheelee?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-437393687:748,simpl,simply,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-437393687,2,['simpl'],['simply']
Usability,"Did you ever hook up the new qual to the genotyping? I read this ticket as; asking for genotype posteriors to be output by HC/GGVCFs. On Wed, Apr 10, 2019, 2:22 PM David Benjamin <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> This ticket seems to be; > asking for genotype priors i.e. population allele frequencies to be learned; > within joint calling. If I interpret the request correctly, that's what new; > qual does. Can we close this?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdFqZ7Nrl4o9sSY5GwbEAvb0e6XuUks5vfiv7gaJpZM4XCuSv>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-483664820:356,learn,learned,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-483664820,2,['learn'],['learned']
Usability,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:415,simpl,simpler,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271,6,['simpl'],"['simple', 'simpler']"
Usability,"Disagree. For sophisticated Java developers like us, it's clear enough. But will the average GATK user know that `source release 1.8` refers to **Java 8**, and that they may need to set their Java default version **manually** even after installing Java 8? Would like to hear from @vdauwera on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119227449:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119227449,1,['clear'],['clear']
Usability,Does functotator support structural variants now? It is not clear from the documentation or this Github issue. Cheers!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917,2,['clear'],['clear']
Usability,Doing some empirical data testing I found some instance of reads that have no single based aligned with the reference. E.g. CIGAR: 50I2S so insertion followed by soft-clip. That causes ReadWalker to crash when trying to create SimpleInterval on the read with a IAE. I guess the solution is to add additional Wellformed filter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/373:227,Simpl,SimpleInterval,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/373,1,['Simpl'],['SimpleInterval']
Usability,"Done with my review. Thanks for doing this much-needed refactor! The BaseRecal stuff looks sound, but I have some other feedback that we should discuss/address.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080:120,feedback,feedback,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080,1,['feedback'],['feedback']
Usability,E=) | `77.778% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ncotator/mafOutput/MafOutputRendererConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.029% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/funcotator/Funcotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0aW9uLmphdmE=) | `50% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...llbender/tools/funcotator/FuncotatorConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JDb25zdGFudHMuamF2YQ==) | `75% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...nterval/SimpleAnnotatedIntervalWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `98.148% <ø> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.462% <ø> (+0.153%)` | `245 <0> (+1)` | :arrow_up: |; | [...s/funcotator/BaseFuncotatorArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5941/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Jhc2VGdW5jb3RhdG9yQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <100%> (ø)` | `1 <1> (?)` | |; | [...es/xsv/LocatableXsvFuncotationFactoryUnit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941#issuecomment-492723640:2545,Simpl,SimpleAnnotatedIntervalWriterUnitTest,2545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941#issuecomment-492723640,1,['Simpl'],['SimpleAnnotatedIntervalWriterUnitTest']
Usability,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885:1203,simpl,simple,1203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885,1,['simpl'],['simple']
Usability,"EFkamFjZW5jeVJlZmVyZW5jZUxvY2F0aW9ucy5qYXZh) | `90.377% <85.714%> (ø)` | `55 <0> (ø)` | :x: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <89.474%> (-1.33%)` | `21 <0> (-14)` | |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `64.706% <90.741%> (+12.941%)` | `32 <31> (+19)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <0%> (-2.083%)` | `36% <0%> (ø)` | |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=footer). Last update [92cb860...3ac3c99](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-276436132:4574,learn,learn,4574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-276436132,2,['learn'],['learn']
Usability,Edits to README: general guidelines,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/415:25,guid,guidelines,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/415,2,['guid'],['guidelines']
Usability,Enable DocumentedFeature for LearnReadOrientationModel.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6726:29,Learn,LearnReadOrientationModel,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6726,1,['Learn'],['LearnReadOrientationModel']
Usability,"Evaluation is so complicated (as necessary, and correctly so) now as we learned along the way, this ticket is no longer relevant.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4684#issuecomment-566723997:72,learn,learned,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4684#issuecomment-566723997,2,['learn'],['learned']
Usability,"Even if we had default methods, `Locatable` should be simple (like `Comparable`) and shouldn't be polluted with every possible operation you might want to perform on an interval.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79198026:54,simpl,simple,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79198026,1,['simpl'],['simple']
Usability,"FBhcnNlci5qYXZh) | `67.476% <0%> (+0.558%)` | `66% <0%> (+28%)` | :arrow_up: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.911% <0%> (+1.427%)` | `74% <0%> (+25%)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `48% <0%> (+19%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `59% <0%> (+6%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=footer). Last update [e1e71d7...8e22a8a](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2488#issuecomment-287907716:4600,learn,learn,4600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2488#issuecomment-287907716,2,['learn'],['learn']
Usability,"FWIW I poked around a bit with the deflater and the main issue is that if we pass the deflater as a parameter then the default is specified simply by a constructor call and not by a run-time constant (also, the deflater can only be created once the compression level is known which is very late) and so there's no longer a central place where everyone gets their customizable deflaters from. I have a solution that I can submit for review in the next few days (make `DeflaterFactory` a proper factory with an overridable `makeDeflater` method, make it settable on writerFactory and also and provide a default one that can be set/queried in `BlockCompressedOutputStream.getDeflaterFactory` - that way one can set the default once and for all for everyone and also selectively use different deflaters for different writers is one so desires).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223078285:140,simpl,simply,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223078285,1,['simpl'],['simply']
Usability,"FYI I'm planning a ""GATK 4 Alpha"" category for the forum + documentation guide to host the user-facing documentation, so feel free to keep the developer docs in the readme -- or we'll add a note in the readme pointing to the forum/guide pages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151661949:73,guid,guide,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151661949,2,['guid'],['guide']
Usability,Factory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2Nvc21pYy9Db3NtaWNGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `62.238% <100%> (-1.143%)` | `28 <1> (+1)` | |; | [...er/tools/funcotator/FuncotatorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.693% <100%> (+0.44%)` | `114 <1> (+1)` | :arrow_up: |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeVVuaXRUZXN0LmphdmE=) | `94.047% <100%> (+0.009%)` | `68 <1> (+1)` | :arrow_up: |; | [...es/xsv/SimpleKeyXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.438% <100%> (+0.05%)` | `24 <1> (+1)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.149% <100%> (-0.851%)` | `29 <1> (ø)` | |; | [...es/xsv/LocatableXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `96.732% <100%> (+0.043%)` | `15 <1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542:2981,Simpl,SimpleKeyXsvFuncotationFactoryUnitTest,2981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542,1,['Simpl'],['SimpleKeyXsvFuncotationFactoryUnitTest']
Usability,"Fair enough. So could you then give guidance on how much it would require as a function of number of read groups? Since we're scrapping indels, the context covariate is just previous base.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178321797:36,guid,guidance,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178321797,1,['guid'],['guidance']
Usability,Feature Request: Progress Bar Estimated Time Remaining,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8997:17,Progress Bar,Progress Bar,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8997,1,['Progress Bar'],['Progress Bar']
Usability,File(ReferenceSequenceFileFactory.java:59); at org.broadinstitute.hellbender.engine.datasources.ReferenceFileSource.getReferenceSequenceDictionary(ReferenceFileSource.java:52); at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.getReferenceSequenceDictionary(ReferenceMultiSource.java:110); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:354); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:320); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:311); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:102); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:151); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:170); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:66); at org.broadinstitute.hellbender.Main.main(Main.java:81); Caused by: java.nio.file.NoSuchFileException: ../human_g1k_v37.fasta; at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214); at java.nio.file.Files.newByteChannel(Files.java:361); at java.nio.file.Files.newByteChannel(Files.java:407); at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384); at java.nio.file.Files.newInputStream(Files.java:152); at htsjdk.samtools.util.IOUtil.openFileForReading(IOUtil.java:519); ... 16 more; ```. we should present those as a simple message that the reference file is missing: `UserException.MissingReference`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1593:2763,simpl,simple,2763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1593,1,['simpl'],['simple']
Usability,"Fine but this is clearly premature optimization. How about a class called Intervals or intervalutils for this sort of random; utility ?. On Thursday, February 18, 2016, droazen notifications@github.com wrote:. > @akiezun https://github.com/akiezun What will actually happen is that; > someone will need that functionality months from now, forget that it; > already exists (embedded in some random tool), and re-implement it. It; > should be moved back now before this is allowed to happen.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185886728. ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185888065:17,clear,clearly,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185888065,1,['clear'],['clearly']
Usability,"Fine either way, as long as it's clear what remains to be done",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-224300621:33,clear,clear,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-224300621,1,['clear'],['clear']
Usability,"First commit:; -Added CreateReadCountPanelOfNormals tool. This is an update of CreatePanelOfNormals. Related code is written from scratch.; -Added DenoiseReadCounts tool. This is an update of NormalizeSomaticReadCounts. Related code is written from scratch.; -Added AnnotateIntervals tool. This is an update of AnnotateTargets. Related code (e.g., GCBiasCorrector) is mostly ported and does not have to be closely re-reviewed. I naively introduced RecordCollection and LocatableCollection classes that are analogous to SampleRecordCollection and SampleLocatableCollection, respectively, for collections that are not tied to a sample (e.g., GC-content annotations); we can go back and refactor these classes later.; -SVDDenoisingUtils contains many package-private helper methods for filtering and denoising without unit tests. This is intentional. I have verified that this code exactly reproduces the old PoN results down to the 1E-16 level (with the discrepancy coming from the removal of redundant pseudoinverse operations). Rather than writing or porting unit tests for this code, I think it is best if we simply do not reuse this code or make non-trivial changes to it going forward. We can add unit tests later if we have extra time on our hands...; -SparkGenomeReadCounts now outputs TSV and HDF5.; -Added some tests for SimpleCountCollection, HDF5SimpleCountCollection, and some disabled tests for HDF5Utils.; -Miscellaneous cleanup and boy scout activities. Second commit:; -Updated coverage collection in germline and legacy somatic CNV WDLs to use only integer read counts and account for changes to SparkGenomeReadCounts.; -Added tasks for PreprocessIntevals, AnnotateIntervals, and CollectFragmentCounts.; -Renamed and moved some files. Closes #3570.; Closes #3356.; Closes #3349.; Closes #3246.; Closes #3153.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3820:1110,simpl,simply,1110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3820,2,"['Simpl', 'simpl']","['SimpleCountCollection', 'simply']"
Usability,"First simply gather reads and their mates for evaluation, then we can evaluate whether to put them into a more compact data structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1104:6,simpl,simply,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1104,1,['simpl'],['simply']
Usability,"First, question: what must we do to convince ourselves to pull the plug on the old QUAL? In every test so far, the new model performs equally well on biallelics and better on multiallelics. We will eliminate about 6000 lines of code, many future bugs, and GATK workshop slides that nobody wants to present. Assuming that we are soon convinced, the ticket is pretty simple: delete every implementation of `AFCalculator` and replace anything that calls for an abstract `AFCalculator` with the concrete class `AlleleFrequencyCalculator`. Then clean up hacky parts of `AlleleFrequencyCalculator` that were put in to implement `AFCalculator`. Finally, delete all the ancillary classes like `StateTracker` that comprised the `AFCalculator`'s military-industrial complex.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255:365,simpl,simple,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255,1,['simpl'],['simple']
Usability,"First-pass review complete -- back to @tomwhite. Many of my suggestions center around pushing arguments and functionality up into `GATKSparkTool` as much as possible, even if they're not applicable to every tool, as we ideally want to spare tool authors from having to manually manage these low-level Spark parameters when they don't want/need to, and we also want to enforce consistency across tools and avoid duplicated boilerplate code. At the same time, there should be clear mechanisms for tools to override the defaults when they have to (eg., overridable methods in `GATKSparkTool`), as I'm not sure whether tools like BQSR are going to be happy with the new 128 MB default input split size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-172100907:474,clear,clear,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-172100907,1,['clear'],['clear']
Usability,"First-pass review complete, back to @akiezun. This is a bit messy/spotty, with large blocks of missing GATK3 functionality, some annotations not in a usable state (eg., `AS_QualByDepth`), lots of TODOs in the code, and the branch is not currently compiling. We can probably get it merged in as a work-in-progress, but we should make sure we have tickets to capture the remaining work to be done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1840#issuecomment-223696878:150,usab,usable,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1840#issuecomment-223696878,1,['usab'],['usable']
Usability,Fixed bugs and simplified AlleleLikelihoods evidence-to-index cache,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6593:15,simpl,simplified,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6593,2,['simpl'],['simplified']
Usability,Fixed dead links - Google Java Style guide,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5405:37,guid,guide,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5405,2,['guid'],['guide']
Usability,"Fixes #1027 . This follows google java style guide. Not sure why `pf_read_only` and `aligned_reads_only` are not; camel-cased, but I'm all for that style of casing. ---. The following test passes:. > gradle test --tests org.broadinstitute.hellbender.tools.spark.pipelines.metrics.MeanQualityByCycleSparkIntegrationTest. It seems that there is no need for a unit test here, but please let me; know if you would prefer one. I have a skeleton test class to verify; that GatkReadFilter blocks secondary alignment reads,; blocks supplementary alignment reads, can restrict to passing filter; reads only, and can restrict to aligned reads only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1053:45,guid,guide,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1053,1,['guid'],['guide']
Usability,Fixes #4586. Released new version of datasources to go with this release (1.4.20180615).; This was necessary because the data sources needed to be made; consistent with hg19 (before they were a mix of hg19 and b37; contig names). Now Funcotator assumes all data sources for the hg19 reference are; compliant with hg19 contig names. Updated the minimum data source version to the new release (1.4.20180615). Simplified `Funcotator::enqueueAndHandleVariant`. Not clear that the `--allow-hg19-gencode-b37-contig-matching-override`; flag does anything anymore. Updated the `getDbSNP.sh` and `createSqliteCosmicDb.sh` data source; scripts to preprocess those data sources to be have hg19-compliant; contigs names. New speeds are ~20k variants/minute for hg19 and ~200k variants/minute for hg38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4927:407,Simpl,Simplified,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4927,2,"['Simpl', 'clear']","['Simplified', 'clear']"
Usability,"Fixes #4739; Refactored UTR VariantClassification handling.; Added warning statement when a transcript in the UTR has no sequence info (now is the same behavior as in protein coding regions).; Added tests to prevent regression on data source date comparison bug.; Now can run on large data.; Fixed DNA Repair Genes getter script.; Fixed an issue in COSMIC to make it robust to bad COSMIC data.; Gencode no longer crashes when given an indel that starts just before an exon.; Fixed the SimpleKeyXsvFuncotationFactory to allow any characters to work as delimiters (including characters used in regular expressions, such as pipes).; Modified several methods to allow for negative start positions in; preparation for allowing indels that start outside exons.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4817:485,Simpl,SimpleKeyXsvFuncotationFactory,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4817,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"Fixes https://github.com/broadinstitute/gatk/issues/6173. I added a single line test that shows the problem, and regenerated the other test files. I didn't write a specific unit test that proves it's solved. Feel free to do so if you think it's necessary.; I validated the output by adding the field name to the output value and checking it by eye against the header lines. This could fairly simply made into a unit test if desired. I'm not sure if there are other large files that need to be regenerated. I had initially said this bug only affects vcf but I think it happens to Maf output as well. I removed a weakly typed method that allowed this bug to occur.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178:392,simpl,simply,392,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178,1,['simpl'],['simply']
Usability,Fixes the Python part of https://github.com/broadinstitute/gatk/issues/4209. Also updated the README with more specific instructions based on previous feedback from another user. This was tested manually.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4233:151,feedback,feedback,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4233,1,['feedback'],['feedback']
Usability,"Fixing the tests failures. Some simple ones (test groups now ""_todo"", rename test inputs on git too). One of them is weird, and only reproduces with the command line... after many minutes of running...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/812#issuecomment-132282122:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812#issuecomment-132282122,1,['simpl'],['simple']
Usability,For @cmnbroad. It shouldn't be too hard to implement some simple mechanism here. . Needed for @lucidtronix 's work on the next-generation VQSR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-336995777:58,simpl,simple,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-336995777,2,['simpl'],['simple']
Usability,For @jamesemery -- this would be a good one for learning about Spark serialization,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1926#issuecomment-227537537:48,learn,learning,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1926#issuecomment-227537537,1,['learn'],['learning']
Usability,"For a quick analysis, I made a serialized versions of DBSNP (13572728 variants from `dbsnp_135.b37.excluding_sites_after_129.vcf`), size of VCF on disk 2175071049 bytes (2.0G). (all false postive probs are predicted, it'd be easy to measure it too). Map keys are contig names. ```; Map of String->BloomFilter with 0.001 false positive prob = 27320529 bytes (26M); Map of String->BloomFilter with 0.0004 false positive prob = 30943001 bytes (30M); Map of String->BloomFilter with 0.0001 false positive prob = 36423625 bytes (35M); Map of String->BloomFilter with 0.00004 false positive prob = 40046089 bytes (38M); Map of String->BloomFilter with 0.00001 false positive prob = 45526681 bytes (43M); Map of String->BloomFilter with 0.000001 false positive prob = 54629745 bytes (52M); Map of String->int[] of positions = 60790452 bytes (58M); List<GATKVariant> made just like the one in spark BQSR = 366463957 bytes (349M); ```. Variants from dbSNP cover 0.004 of the genome (15195436 bases of 3101804739) so if we want reasonable precision (number of false positives over all reported hits), say 0.9 precision (of 10 hits only 1 can be false) we need (1-0.9) x 0.004 false positive prob = 0.0004. For 0.99 precision (of 100 hits only 1 can be false) we need (1-0.99) x 0.004 false postive prob = 0.00004. These are approximations of course. Given these numbers, I conclude that, for now, exploring BloomFilters does not seem to make sense (too little saving and too many complications with using a probabilistic data structure - eg we'd need to use it too for the walker BQSR). It does make sense however to explore alternatives to the list of GATKVariants because it's very big when serialized (maybe Kryo does a better job but it's still a big object). A simple alternative like sorted int[] may be sufficient and has attractive properties (trivial to implement and understand, O(log) lookups, 0% false positives, small size when serialized).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1407#issuecomment-203727133:1756,simpl,simple,1756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1407#issuecomment-203727133,1,['simpl'],['simple']
Usability,"For a read with the following id line in the fastq:; `@HJYFJCCXX160204:4:1124:22424:1133/1 mapping=20:61724009;151M`; This method would return pretty much the whole descriptor except for the starting '@':; ` HJYFJCCXX160204:4:1124:22424:1133/1 mapping=20:61724009;151M`; Intuitively it should be only the first part, what an equivalent SAMRecord object getName() would return:; `HJYFJCCXX160204:4:1124:22424:1133`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2754:271,Intuit,Intuitively,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2754,1,['Intuit'],['Intuitively']
Usability,"For a single sample with uncovered intervals and the interval-median filter disabled, it looks like the PoN builds successfully, but we get a `java.lang.IllegalArgumentException: Non-finite log2 copy ratio is not allowed` later on in DenoiseReadCounts. Probably should fail earlier in CreateReadCountPanelOfNormals, but it looks like bad behavior is ultimately prevented. For multiple samples with completely uncovered intervals and the relevant filters disabled, an exception is thrown when the SVD fails (unless the SVD is skipped by requesting `--number-of-eigensamples 0`, in which case behavior reverts to the above). Probably could fail a bit earlier here as well. Note that running with the interval-median filter disabled is atypical, but it is done in CreateReadCountPanelOfNormalsIntegrationTest simply to make checking filtering of simulated data a little more sane.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6878#issuecomment-705946973:806,simpl,simply,806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6878#issuecomment-705946973,2,['simpl'],['simply']
Usability,"For now we'll use tribble to index the locatable *SV sources. For gene name / transcript ID indexed files, we will use simple maps (key -> annotation list) for now. Down the road we may explore methods to speed this up, maybe with a database.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3758#issuecomment-347610537:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3758#issuecomment-347610537,2,['simpl'],['simple']
Usability,"For record keeping, as the comments and replies may be buried in the many commits. ------------; ### On the problem of too many splits of RDD and performance concerns. Initial comment by @cwhelan :; > I'm starting to really not like this approach of splitting up the RDD into lots of smaller RDDs for later processing. It seems inefficient to me: it launches tons of different Spark stages each of which has a bunch of overhead. Perhaps not in this PR, but I think it would be better to classify the contigs on the fly and dispatch them to the right processing methods in a single pass over the RDD. Reply by @SHuang-Broad. > I tried to fix it in this PR, but that seems to be a big task,; and probably is impossible to achieve in a single pass,; because currently each class of contig ends up producing a different type of object; (3 general classes: simple -> SimpleNovelAdjacency, complex -> ComplexVariantCanonicalRepresentation, and unknown -> SAM records of the contigs); and a groupBy() operation is necessary in the middle using these objects as keys; due to the fact that different contigs may produce the same variant; So what I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:852,simpl,simple,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,3,"['Simpl', 'simpl']","['SimpleNovelAdjacency', 'simple']"
Usability,"For reference, doc from the GATK3 best practices (https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_bqsr_AnalyzeCovariates.php). ```; # Generate the first pass recalibration table file.; java -jar GenomeAnalysisTK.jar \; -T BaseRecalibrator \; -R myreference.fasta \; -I myinput.bam \; -knownSites bundle/my-trusted-snps.vcf \ # optional but recommendable; -knownSites bundle/my-trusted-indels.vcf \ # optional but recommendable; ... other options; -o firstpass.table. # Generate the second pass recalibration table file.; java -jar GenomeAnalysisTK.jar \; -T BaseRecalibrator \; -BQSR firstpass.table \; -R myreference.fasta \; -I myinput.bam \; -knownSites bundle/my-trusted-snps.vcf \; -knownSites bundle/my-trusted-indels.vcf \; ... other options \; -o secondpass.table. # Finally generate the plots and also keep a copy of the csv (optional).; java -jar GenomeAnalysisTK.jar \; -T AnalyzeCovariates \; -R myrefernce.fasta \; -before firstpass.table \; -after secondpass.table \; -csv BQSR.csv \ # optional; -plots BQSR.pdf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94592372:86,guid,guide,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94592372,1,['guid'],['guide']
Usability,"For repeated operators (whether xIyI or xMyM), I think GATK3 has/had a function to simplify cigars to ""sanitize"" that situation. In terms of desired behavior, we don't want to filter out the reads, we want to transform them to be processable without difficulty. I think xIyD should be considered valid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320:83,simpl,simplify,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320,1,['simpl'],['simplify']
Usability,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:691,simpl,simpler,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699,2,['simpl'],['simpler']
Usability,"For the most part I expect people use the precompiled jar for production; work, so I'm not too worried about that. Just make sure to have a TL;DR; line at the top of the readme that makes it clear what this is. On Mon, Oct 5, 2015 at 1:16 PM, Adam Kiezun notifications@github.com; wrote:. > sad but necessary; > @vdauwera https://github.com/vdauwera will buy us a plush hellbender; > ; > BTW, @vdauwera https://github.com/vdauwera will people be confused when; > they find the broadinstitute/gatk repository and think this is the 3.x; > branch that they can use for production? I bet they will - what should we; > do about this then?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/945#issuecomment-145602883; > . ## . Geraldine A. Van der Auwera, Ph.D.; Group leader, Comms & Support; Data Science & Data Engineering; Broad Institute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/945#issuecomment-145615665:191,clear,clear,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/945#issuecomment-145615665,1,['clear'],['clear']
Usability,"For what its worth, I know I always find it difficult to find things on the GATK forums. A wiki is a much clearer way for me to navigate static information. It's also easy for everyone to edit and has a clear history.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151874932:106,clear,clearer,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151874932,2,['clear'],"['clear', 'clearer']"
Usability,"Found this improvement request in the Classic GATK Pivotal. Would be good to check whether this is satisfied by the ported version. ---. Quality-based clipping should be more straightforward than it is. As explained by Mauricio in relation to this forum question:. http://gatk.vanillaforums.com/discussion/comment/13108#Comment_13108. ""As implemented it doesn't really clip all bases below a certain threshold. It does something gnarly. It keeps a running sum and sets the clipping point to where the running sum exceeds the threshold after subtracting the qual for each base. It only traverses from the end of the read (depending on read orientation). . Essentially , this is a tool to hard clip bad read ends from the sequencer (meaning, the last few cycles) in case the sum of their qualities is not large enough. Not at all what our user wanted. Instead, he was looking for a very simple if statement here. Which I also think would be much more useful."". Here are Mark's comments:. ```; * Clip bases from the read in clipper from; * <p/>; * argmax_x{ \sum{i = x + 1}^l (qTrimmingThreshold - qual); * <p/>; * to the end of the read. This is blatantly stolen from BWA.; * <p/>; * Walk through the read from the end (in machine cycle order) to the beginning, calculating the; * running sum of qTrimmingThreshold - qual. While we do this, we track the maximum value of this; * sum where the delta > 0. After the loop, clipPoint is either -1 (don't do anything) or the; * clipping index in the read (from the end).; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/263:885,simpl,simple,885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263,1,['simpl'],['simple']
Usability,"From Lee:. he COSMIC datasource in oncotator simply finds all overlapping records and counts the protein change (""Mutation AA"") values. Like a histogram of all overlapping records. (edited). `mutation_AAs = collections.Counter([entry['Mutation AA'] for entry in overlapping_cosmic_entries])`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969:45,simpl,simply,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969,2,['simpl'],['simply']
Usability,"From a researcher in the field. Their data processing would be much simpler if GenomicsDB accepted non-diploid and mixed-ploidy cases. Currently, researcher is encountering challenges to a workaround that uses CombineGVCFs (a GATK3 tool). ---. As an update, looks like `GenomicsDBImport` only supports diploid data, so we cannot use it. Would really appreciate your help on this. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/53201#Comment_53201",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5383:68,simpl,simpler,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5383,1,['simpl'],['simpler']
Usability,Funcotator - SimpleXsv parser needs improved error handling for different encodings,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4006:13,Simpl,SimpleXsv,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4006,1,['Simpl'],['SimpleXsv']
Usability,Funcotator currently ignores transcript version numbers when doing internal comparisons. . There should be a flag to enable transcript ID version checking (but it should remain off by default). This will involve updates to:; - Funcotator.java; - GencodeFuncotationFactory.java; - SimpleXsvFuncotationFactory.java. And possibly other classes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5558:280,Simpl,SimpleXsvFuncotationFactory,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5558,1,['Simpl'],['SimpleXsvFuncotationFactory']
Usability,Funcotator needs a tool to create new simple delimited data sources.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3785:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785,2,['simpl'],['simple']
Usability,"GATK seems to not handle gzipped reference genomes and throws quite cryptic errors instead. This is problem given that the readily available reference genome is gzipped (see [here](ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/) and its not obvious that gzipped files cannot be handled by GATK (samtools and picard seem to handle them just fine). This just happened to me with the `gatk SplitNCigarsReads`. This can be easily made more user-friendly by checking if the file has "".gz"" or "".gzip"" filetype and checking the first two bytes are ""1f 8b"" (see [here](https://stackoverflow.com/a/3703300) )",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6590:507,user-friendly,user-friendly,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6590,1,['user-friendly'],['user-friendly']
Usability,"GATK version: 4.0.9.0. The issue: I wanted to use the built-in Tool SplitIntervals to partition the WGS calling intervals (GATK bundle). These are in interval_list format. A simple line count (excluding the headers) shows vast differences (much fewer intervals across all the splits than were in the original interval list), which seems to suggest a problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5236:174,simpl,simple,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5236,1,['simpl'],['simple']
Usability,"GATK version: 4.4.0.0. Crashing in FilterAlignmentArtifacts. Not clear why. Command; ```; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30g -jar /gpfs/data/lab/bin/gatk/gatk-package-4.4.0.0-local.jar FilterAlignmentArtifacts -R /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta -V 60603-bulk.filtered.vcf.gz -I /gpfs/data/lab/projects/Mini/analysis/STR/60603-bulk_results/60603-bulk.cram --bwa-mem-index-image /gpfs/data/lab/reference-files/hg38-gatk/Homo_sapiens_assembly38.fasta.img -O 60603-bulk.filtered.FAA.vcf.gz; ```. Error:; ```; 11:02:16.087 INFO ProgressMeter - chrX:144247387 619.0 145000 234.3; 11:05:08.297 WARN IntelInflater - Zero Bytes Written : 0; 12:29:39.297 INFO FilterAlignmentArtifacts - Shutting down engine; [August 15, 2023 at 12:29:39 PM EDT] org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts done. Elapsed time: 710.24 minutes.; Runtime.totalMemory()=4345298944; java.lang.IllegalStateException: Padded span must contain active span.; at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:109); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:85); at org.broadinstitute.hellbender.engine.AssemblyRegion.<init>(AssemblyRegion.java:120); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.makeAssemblyRegionFromVariantReads(FilterAlignmentArtifacts.java:280); at org.broadinstitute.hellbender.tools.walkers.realignmentfilter.FilterAlignmentArtifacts.apply(FilterAlignmentArtifacts.java:212); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:133); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.afterTraverse(MultiVariantWalkerGroupedO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8476:65,clear,clear,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8476,1,['clear'],['clear']
Usability,"GATK3 is very slow when processing references with large numbers of contigs, such as draft genomes. In the past this mostly affected microbial genomes so we didn't do anything about it, but now the Hg38 has a lot more contigs so we have to make sure that's not going to be a problem with GATK4. . To be clear, efficient processing of reference genomes with thousands of contigs is a must-have. . Efficient processing of e.g. microbial draft genomes with tens of thousands of contigs is a nice-to-have. More than that is just crazy talk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1688:303,clear,clear,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1688,1,['clear'],['clear']
Usability,"GATK4 has a number of options that presumably alter performance in different ways under different conditions, including and probably not limited to: Intel Deflater/Inflater, snappy, and HTSJDK's various USE_ASYNC_XXXXX_READ params. I can appreciate there is probably not a one-size fits all answer, but would it be possible to provide some type of general guidance on what's available, and when one or the other might be worth evaluating? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3648:356,guid,guidance,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648,1,['guid'],['guidance']
Usability,"GATK4 uses contig names, rather than contig indices, and so does not; need to be as strict as GATK3 and require contigs to occur in the same; relative order in two sequence dictionaries, or check for lexicographic; ordering in human dictionaries. This solves several major usability issues:. -2bit references (used by the spark BQSR) typically contain dictionaries; with very non-standard contig ordering. Since we query contigs by name,; we are actually compatible with these references and shouldn't blow up. -Many VCF dictionaries use lexicographic ordering, and GATK4 would blow; up on these. With this change, we also no longer require variant dictionaries to share; a common subset of contigs with each other (just with the reference and/or; reads). Resolves #1176; Resolves #1024",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1178:273,usab,usability,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1178,1,['usab'],['usability']
Usability,GATKariantContextUtils.createVCFWriter should call clearOptions,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1143:51,clear,clearOptions,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1143,2,['clear'],['clearOptions']
Usability,GUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `3.077% <0%> (-1.09%)` | `2% <0%> (+1%)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `85.714% <0%> (-0.952%)` | `6% <0%> (+3%)` | |; | [...er/tools/ConvertHeaderlessHadoopBamShardToBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db252ZXJ0SGVhZGVybGVzc0hhZG9vcEJhbVNoYXJkVG9CYW0uamF2YQ==) | `76% <0%> (-0.923%)` | `3% <0%> (+1%)` | |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `66.667% <0%> (-0.725%)` | `13% <0%> (+6%)` | |; | [...dinstitute/hellbender/tools/walkers/qc/Pileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3FjL1BpbGV1cC5qYXZh) | `97.727% <0%> (-0.455%)` | `24% <0%> (+8%)` | |; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `82.979% <0%> (-0.355%)` | `8% <0%> (+4%)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `92.857% <0%> (-0.325%)` | `82% <0%> (+34%)` | |; | ... and [66 more](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357290124:3723,Simpl,SimpleInterval,3723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357290124,1,['Simpl'],['SimpleInterval']
Usability,"Gatk-protected needs to be able to write bed files. They've implemented a simple writer, but it only writes the required fields and doesn't include optional ones. . This will be considered completed when a complex bed file can be read in as a FeatureInput and then written back to disk identically.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1201:74,simpl,simple,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1201,1,['simpl'],['simple']
Usability,"Gave a bit of initial feedback -- will do a full review next week, and answer all of the questions you posted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128807445:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128807445,1,['feedback'],['feedback']
Usability,"GenomicsDB workspaces can be moved freely - i.e., there is nothing about the workspace name or path that cannot be changed after initial creation. This wasn't true in the past (way way back in the past) but is certainly true now. Just want to clarify that in case that wasn't clear. I guess I see this as six of one, half a dozen of the other. Currently, the user can copy the initial workspace to a new location and incrementally import samples to the new location. The option proposed by @bbimber (specify existing workspace, new gVCFs and new output location) would require the tool to copy the existing workspace to the new location and then import new samples to it. Only real difference is who is doing the copying.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617366264:276,clear,clear,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617366264,2,['clear'],['clear']
Usability,GermlineCNVCaller setting Nd4j could be more user-friendly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3098:45,user-friendly,user-friendly,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3098,2,['user-friendly'],['user-friendly']
Usability,Get simple Spark tools like PrintReadsSpark out of beta,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5638:4,simpl,simple,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5638,2,['simpl'],['simple']
Usability,"Goal was to get WGS coverage collection at 100bp at ~15 cents per sample. Since this is I/O bound (takes ~2 hours to stream or localize a BAM, or about the same to decompress a CRAM), cost reduction can be most easily achieved by reducing the memory requirements and moving down to a cheaper VM. . Memory requirements at 100bp are dominated by manipulations of the list of ~30M intervals. There were a few easy fixes to reduce requirements that did not require changing the collection method (which can be easily modified for future investigations, see #4551):. -removed WellformedReadFilter. See #5233. EDIT: We decided after PR review to retain this filter by default and disable it at the WDL level when Best Practices is released. Leaving the issue open.; -initialized HashMultiSet capacity; -removed unnecessary call to OverlapDetector.getAll; -avoided a redundant defensive copy in SimpleCountCollection; -used per-contig OverlapDetectors, rather than a global one. This brought the cost down to ~9 cents per sample using n1-standard-2's with 7.5GB of memory when collecting on BAMs with NIO. Note that I didn't optimize disk size, which accounts for ~50% of the total cost and is unused when running with NIO, so we are closer to ~5 cents per sample. It is possible that using CRAMs with or without NIO and with or without SSDs might be cheaper. Note that OverlapDetectors may be overkill for our case, since bins are guaranteed to be sorted and non-overlapping and queries are also sorted. We could probably roll something that is O(1) in memory. However, since we are I/O bound, as long as we are satisfied with the current cost, I am willing to sacrifice memory for implementation and maintenance costs, as well as the option to change strategies easily. In any case, @lbergelson found some easy wins in OverlapDetector that may further bring the memory usage down, and will issue a fix in htsjdk soon.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5715:888,Simpl,SimpleCountCollection,888,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715,1,['Simpl'],['SimpleCountCollection']
Usability,"Good catches, thank you! I've switched to using paging as you recommend since the code's a big shorter and simpler that way. I'll squash&merge once tests pass, unless you object.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135875333:107,simpl,simpler,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135875333,1,['simpl'],['simpler']
Usability,"Good point. In the cases when you're running a tool on a data set with a knowable number of records, it would be useful to have this feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5179#issuecomment-420762396:133,feedback,feedback,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5179#issuecomment-420762396,2,['feedback'],['feedback']
Usability,"Gradle 2.12 just released which includes some improvements we've been waiting for. It includes a ""compileOnly"" scope which should make some of our spark configuration unnecessary. We should investigate if we can simplify the sparkJar setup using the new scope, and possible improve things for gatk-protected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1578:212,simpl,simplify,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1578,1,['simpl'],['simplify']
Usability,"Great! I can't remember if I wrote up the design requirements somewhere, but they're simple. The only non-obvious thing is to take a ""high-confidence"" interval list where we assume anything not in the truth is a false positive (as in NIST GiaB). Might also be useful for DREAM, but I don't remember the details of how that truth data is represented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-266453955:85,simpl,simple,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-266453955,2,['simpl'],['simple']
Usability,Great! Thanks for the feedback @magicDGS.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-286425107:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-286425107,2,['feedback'],['feedback']
Usability,"GvsCreateFilterSet.wdl failed recently for Morgan because of this bug. When run in a brand new project, filter model creation fails because we expect the project to have a hard coded dataset named ""temp_tables"" which is likely does not have. The workaround is simply to manually create one. This ticket removes the need for this dataset altogether. This is removed, and instead, the default dataset is used (that the many other tables created in this pipeline use as the default). able to reproduce with a dummy dataset name:; <img width=""1278"" alt=""Screen Shot 2022-03-03 at 10 44 39 PM"" src=""https://user-images.githubusercontent.com/6863459/156822409-a99d7068-169c-48a2-83ff-5bcc81cdbd2e.png"">. tested here:; https://app.terra.bio/#workspaces/broad-dsp-spec-ops-fc/gvs_testing_ingest/job_history/1dd27d90-82c4-44e6-8172-15c10c8a9c7f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7704:260,simpl,simply,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7704,1,['simpl'],['simply']
Usability,"HG00731 fails with a similar error:. ```; 18/04/11 16:08:40 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 98.0 in stage 42.0 (TID 49620, cwhelan-hg00731-cram-samtools-bam-feature-w-4.c.broad-dsde-methods.internal, executor 43): java.lang.IllegalArgumentException: Invalid interval. Contig:chr6 start:34662153 end:34662143; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.computeNewRefSpanAndCigar(ContigAlignmentsModifier.java:163); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.clipAlignmentInterval(ContigAlignmentsModifier.java:42); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.removeOverlap(CpxVariantInterpreter.java:179); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.deOverlapAlignments(CpxVariantInterpreter.java:122); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.furtherPreprocess(CpxVariantInterpreter.java:79); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$bdd686a3$1(CpxVariantInterpreter.java:51); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648#issuecomment-380510575:448,Simpl,SimpleInterval,448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648#issuecomment-380510575,4,['Simpl'],['SimpleInterval']
Usability,"HaplotypeCaller and Mutect2:. ![screen shot 2018-05-30 at 2 36 58 pm](https://user-images.githubusercontent.com/8438890/40759148-b860a5da-645e-11e8-8f94-21534ed9ab48.png). Notice how all of the reads that appear to support a single-base deletion actually do not because they do not span the poly-T homopolymer. This makes the bamout harder to interpret. In this particular case (of a false positive M2 insertion) it is a red herring because it suggests that the multiallelicness of the site is relevant to the false positive deletion. One could ask what in the GATK engine is responsible. * The assembly engine, perhaps? No, it is the assembly engine's job to propose possible haplotypes, not to call them. In any case, there *is* one spanning read with the deletion above the reads shown, so it is a valid path in the graph.; * Pair-HMM? This one confused me for a while, but no. The engine is *not* saying that these reads' best alignment to the reference has a deletion, which would be false because there is a gap opening penalty. Rather, it says that they align equally well (with no deletions) to the ref haplotype and to the deletion haplotype. The deletion shown in IGV is the deletion of the alt haplotype relative to the reference, not of the reads relative to their best haplotype.; * The bamout writer? Nope, that code is really straightforward and does the right thing. So what's the issue? Well, the bamout writer gets its read alignments from the `readLikelihoods` after the reads have been realigned to their best haplotype. In these cases, it turns out that the alignment of the reads to their best haplotype, the deletion has a log likelihood better than the alignment to the ref haplotype by about 0.00001. The simplest solution would be to give an extremely modest prior in favor of the reference and break these near-ties in favor of the reference. @droazen @ldgauthier @yfarjoun if you think this is a good idea I can fix it for both HC and M2. Otherwise I'll do an M2-only fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829:1780,simpl,simplest,1780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829,1,['simpl'],['simplest']
Usability,HaplotypeCaller does not resume from where it stopped. If you need to perform the same task again restart the whole task using the very same commandline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7454#issuecomment-918232900:25,resume,resume,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7454#issuecomment-918232900,2,['resume'],['resume']
Usability,"HaplotypeCaller expends massive effort to generate a set of local candidate haplotypes along with their read likelihoods. After that, however, it throws away the haplotypes, using them _only_ for their CIGAR strings from which individual and independent variants are extracted. While this approach probably has some merits, it would be nice if HaplotypeCaller had a ""haplotype"" mode in which it genotypes and calls whole local haplotypes, basically by _not_ splitting up the haplotypes and defining each haplotype as a `VariantContext` (although perhaps splitting these by CIGAR string for the final vcf). In addition to giving some amount of phasing (about as much as `ReadBackedPhasing` currently does) for free, this would let nearby variants share statistical strength. All the calls that we reject upon manual review by simple phasing considerations would be correct.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1700:825,simpl,simple,825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1700,1,['simpl'],['simple']
Usability,Have since learned external tools can separate out mixed-type records into biallelic records.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-447900242:11,learn,learned,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-447900242,1,['learn'],['learned']
Usability,"Have to disagree with you on that point, @magicDGS. Comma-separated values for lists seems like the most straightforward/simple/human-editable approach, whereas the other options seem more complex (and therefore more messy/error-prone). (Unless it turns out that we need nested lists, which I'm hoping is not the case!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543:121,simpl,simple,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543,2,['simpl'],['simple']
Usability,Have you considered merging `SVInterval` with `SimpleInterval`? What's the rationale for keeping them separate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418496216:47,Simpl,SimpleInterval,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418496216,1,['Simpl'],['SimpleInterval']
Usability,"Having the same issue here, and I follow essentially the same steps with .csi and .idx indexing for bam and .g.vcf files, respectively. ; @tfenne or anyone else, have you figured a workaround to worked with compressed VCF files properly indexed for large chromosomes (> 512 * 2^20)? . I would have to carry ~1000 uncompressed *.g.vcf to GenomicsDBImport and I simply don't have the disk-space for that manoeuvre.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6110#issuecomment-624152200:360,simpl,simply,360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6110#issuecomment-624152200,2,['simpl'],['simply']
Usability,"Hello - I'm not sure if you want me using issues for feedback, but i thought I'd pass this along. In another thread we discussed how to possibly do scatter/gather processing of GenomicsDB workspaces. The general idea is that we want to have long-lived workspaces to which we will repeatedly add more samples. Executing this append would be a lot more convenient to do scattered over intervals. Since GenomicsDB already has the data organized into folders by interval, I figured we might be back to manually split one workspace apart by copying each contig's folder out to make a new workspace, execute the merge over that interval, and then copy them back together. So far as I can tell this works. It seems like it will significantly speed the process of creating new workspaces and also adding samples. As I said on the other thread, since your docs recommend making a backup of a workspace before trying to append samples anyway, copying it out into new working folders to execute that append step isnt all that different. I realize we're doing a non-supported thing here. I post simply to mention that this scheme seems like it will be quite useful and I hope you might keep it in mind as GenomicsDB evolves.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620:53,feedback,feedback,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620,2,"['feedback', 'simpl']","['feedback', 'simply']"
Usability,"Hello - in GATK3 we wrote a variety of custom VariantAnnotation classes, and created a GATK3 fork / custom JAR with those classes. We run VariantAnnotator using that. I am hoping you might comment on whether this plan seems reasonable:. I am going to try to implement this in our DISCVRseq package, which is a standalone package that depends on GATK4. I am currently expecting that I would need to be a separate tool, like ""VariantAnnotationExtended"" in our code. My tool can make an instance of VariantAnnotatorEngine, passing whatever annotationList I see fit. It seems like I will either be able to use GATKTool.makeVariantAnnotations() as-is, or override it to search custom classpaths (not currently clear if that's needed). In the end, my new tool should be able to function like core GATK4 VariantAnnotator, picking up your core annotations and whatever new ones I make. The latter is useful so I dont need to execute two annotation commands if I want to use a combination of annotations. . Is there a better way to implement custom VariantAnnotations in GATK4?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929:705,clear,clear,705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929,1,['clear'],['clear']
Usability,"Hello - we're trying to run Funcotator with a custom data source, where that source is a locatableXsv (i.e. simple tab-delimited file with columns for contig, start, and end). I believe I understand how to make this TSV and the config file. The issue is that I dont see a way to create the index (i.e. tsv.idx), and GATK fails when I try to run against a data source without the index. Not that surprisingly, IndexFeatureFile errors when trying to index a TSV saying ""no suitable codecs found"". Is there another tool that's able to make indexes on simple TSVs?. FWIW, the only example LocatableXsv source I could find in the default data sources is Oreganno. The majority of TSV-based sources are simpleXSV and just map using Gene symbol (so apparently no index is required). When I try to index the existing oreganno.tsv file, I get the same problem. I dont know how that original index was created. Thanks for any help or ideas.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7986:108,simpl,simple,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7986,3,['simpl'],"['simple', 'simpleXSV']"
Usability,Hello @bbimber thank you for the response. I would recommend using the read filters (in your case `-rf MappingQualityReadFilter --minimum-mapping-quality ##` to achieve the same functionality as the `-mmq` argument from GATK3. When porting over the tool we tried to push as much functionality from obscure arguments into the existing filtering framework as possible and `-mmq` was one of the ones that was redundant as it was a simple filter placed on the reads before counting them which the existing filtering code was able to handle. I will add some lines to the documentation clarifying this for users in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634752928:428,simpl,simple,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634752928,2,['simpl'],['simple']
Usability,"Hello @cmnbroad. My current solution satisfy all the constraints and it's not too complicated, although is not as simple as a common generic class that just need to be extended. Have a look and if you like it I can implement some tests for `CountingVariantFilter`; if not, I could come back to a separate `CountingVariantFilter` with its own and/or/negate inner classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490:114,simpl,simple,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490,2,['simpl'],['simple']
Usability,"Hello Geraldine:. > On 1/Mar/2017, at 7:56 PM, Geraldine Van der Auwera <notifications@github.com> wrote:; > ; > @chlangley One thing we could potentially do to attract attention to this issue and solicit feedback from the community would be to feature it on the GATK blog. If you were to write a concise case study detailing the impact of the problem on your results, others may be motivated to look at their own results, and if it causes problems there, add their voices to yours. We're willing to bring this to public attention, we just don't have the bandwidth to do the legwork. I started to work on this a bit and found myself blocked. . At this point I have a simple question: The GATK blog is separate from the forum (?). When I am on the blog page I can’t seem to find a button to submit a new post. I must be missing something or the route to blog posting is only via the forum?. Sorry to bother you with such mundane question. Cheers,; Chuck",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436:205,feedback,feedback,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Hello Laura, one question. You stated that the above alt allele should be treated as a deletion. Just wanted to check with you a boolean condition to determine if an alt allele is a deletion (not including symbolic allele handling for simplicity):; ```cpp; is_deletion = ( ref_allele.length() > alt_allele.length() ); || ( ref_allele.length() == alt_allele.length() ; && ref_allele[0] == alt_allele[0] ); ```; The second predicate in the OR expression is for the case described above. Do you think this condition is correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6500#issuecomment-601676489:235,simpl,simplicity,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6500#issuecomment-601676489,2,['simpl'],['simplicity']
Usability,"Hello everyone: I am realizing that the GATK framework is going to have a lot of dependencies from java and python even if the simpler framework is the one need it. Maybe it is a good idea to start thinking about sub-modules within the same repository for the engine (maybe even separate the Spark framework), CNV...and create an independent artifact for every of them, and one combined one. Does it sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614:127,simpl,simpler,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614,2,['simpl'],['simpler']
Usability,"Hello, ; I forgot to report back here. I figured out what my problem was:; I ran ApplyVQSR twice on my dataset. The first time with a sensitivity threshold of 99% and the second time with 97% (on the data which resulted from the 99% threshold run). When I use 97% right away everything worked. . However, I am still a little confused, why ""updating"" the sensitivity threshold results in my observed output, where these sites PASS the filtering and if I use 97% right away they do not pass. However, the ""fix"" (i.e. using the intended filtering threshold on the original data) is very simple and doesn't take long, so I will close this issue. Feel free to reopen if you need any more information. ; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7259#issuecomment-847682476:584,simpl,simple,584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7259#issuecomment-847682476,2,['simpl'],['simple']
Usability,"Hello,. @jonn-smith and @lbergelson: I'd like to make a custom data source using tabular data as the input. These data should be matched on position, not considering allele, using LocatableXSV as the type. There is an example of a TSV using Oreganno in the docs (https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial).; however, I ran into two issues:. - A TSV needs to be indexed to be read. It's not clear how to generate an idx file from a non-bgzipped tsv. GATK's IndexFieldFile does not recognize basic TSVs as input files. Perhaps I'm missing something. - It would be possible to gzip the TSV and make a tabix index. The problem is that while most GATK code seamlessly handles unzipped or gzipped inputs, LocatableXsvFuncotationFactory expected unzipped. This is a minor change to the file reading code that allows gzipped TSV inputs. Below is an example input. You can bgzip this and index using:; ```; tabix textSource.txt.gz -s 1 -b 2 -e 3 -S 1 -f; ```; With this PR, I think funcotator will now support gzipped LocatableXSV sources. Would it be possible to add this?. [textSource.txt](https://github.com/broadinstitute/gatk/files/11747583/textSource.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591439727:447,clear,clear,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591439727,2,['clear'],['clear']
Usability,"Hello,. Mutect2 [version 4.0.11.0] doesn't seem to be filtering out strand artifacts when they clearly are. This is in some data from the NovaSeq and I am looking specifically at the dinucleotide changes `TT>GG or AA>CC`. . Most of them are PASS even when they are clearly in the same strand when looking at IGV (and also the `F1R2 and F2R1` tags in the VCF). Only 1 out of hundreds FAILS with the `strand_artifact` filter. PASS example; ```; 1 213663521 . TT GG . PASS DP=112;ECNT=1;NLOD=14.45;N_ART_LOD=-1.698e+00;POP_AF=3.125e-05;P_CONTAM=0.00;P_GERMLINE=-1.875e+01;TLOD=23.33 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:OBAM:OBAMRC:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB 0/1:49,10:0.177:59:35,0:14,10:30,30:331,317:60:35:false:false:0:0.172,0.00,0.169:1.573e-03,0.670,0.329 0/0:48,0:0.020:48:27,0:21,0:30,0:337,0:0:0:false:false:0; 2 186475118 . TT GG . PASS DP=101;ECNT=1;NLOD=11.44;N_ART_LOD=-1.596e+00;POP_AF=3.125e-05;P_CONTAM=0.00;P_GERMLINE=-1.949e+01;TLOD=8.12 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:OBAM:OBAMRC:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB 0/1:55,6:0.103:61:35,0:20,6:30,30:353,293:60:52:false:false:0:0.101,0.00,0.098:2.429e-03,0.382,0.615 0/0:38,0:0.013:38:22,0:16,0:30,0:341,0:0:0:false:false:0; ```. FAIL example; ```; 8 134390574 . TT GG . strand_artifact DP=172;ECNT=1;NLOD=11.14;N_ART_LOD=-1.299e+00;POP_AF=3.125e-05;P_CONTAM=0.00;P_GERMLINE=-2.386e+01;TLOD=18.05 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:OBAM:OBAMRC:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_POST_PROB 0/1:109,20:0.130:129:63,0:46,20:30,25:346,379:60:50:false:false:0:0.152,0.00,0.155:5.139e-06,0.998,2.050e-03 0/0:37,0:0.026:37:23,0:14,0:30,0:339,0:0:0:false:false:0; ```. I would appreciate any input!. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5965:95,clear,clearly,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5965,2,['clear'],['clearly']
Usability,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7038:798,intuit,intuitive,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038,1,['intuit'],['intuitive']
Usability,"Hello,. We're looking to switch our large-scale WGS/variant calling project to use GenomicsDB instead of CombineGVCFs to stage data prior to GenotypeGVCFs, primarily b/c it allows incremental addition of samples. I'm wondering if you'd be willing to comment on this from the perspective of scatter/gather. We process most GATK jobs using scatter/gather across a cluster by providing each job with a list of intervals. While GenomicsDB workspaces appear to currently support multiple intervals, I am thinking that it actually makes more sense to simply maintain our data as a folder of workspaces, where each has a defined interval set. The reasoning is that there seems to be no reason to maintain it as one large whole-genome workspace. So far as I can tell, if I maintain this as a whole-genome workspace, I cannot easily scatter/gather the jobs to add new batches of samples? in contrast, if maintained as a folder of workspaces, I could execute the merge job as one job per workspace/interval-set. This obligates us to always execute GenotypeGVCFs as scatter/gather on those specific intervals; however, that doesnt seem like that big a limitation. . If doing this, I'm considering maintaining a Multi-interval GenomicsDB 'file format', which would basically be a JSON or simple text file that maps Interval->Workspace, allowing code to figure out which workspace to select as input based on the intervals provided. Does this seem sane? Am I missing features in GenomicsDB that would argue toward maintaining a large gVCF dataset as a single workspace rather than many?. Thanks,; Ben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6557:545,simpl,simply,545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6557,2,['simpl'],"['simple', 'simply']"
Usability,"Hello,. When using JEXL expressions, is there a good built-in solution for handling both single and multi-allelic sites? A good example is trying to filter on AF, which could be either a single number or a list. Perhaps I'm missing something now, but it seems like there are two possibilities:. 1) Split multi-allelic sites into multiple variants (like VariantsToTable can do), and output/filter them independently.; 2) Support functions, like perhaps min() and max(). One would need to think about the desired result, but filtering on ""min(AF) < 0.05"" might be reasonable. In the simplest implementation, the entire site would be in or out (as opposed to trying to be smart about filtering specific alt alleles). . Just curious if there is something built-in i'm missing, or if ways to support this have already been discussed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8443:581,simpl,simplest,581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8443,1,['simpl'],['simplest']
Usability,"Hello,; I wish to try the deep learning search but what are we supposed to feed the program with the option ""a"" ?; `--architecture,-a:String Neural Net architecture and weights hd5 file Required`. By hd5 file, do you mean hdf5 file? . Thanks a lot. . Alessandro",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4559:31,learn,learning,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559,1,['learn'],['learning']
Usability,"Hello,; yes simply because i was working under the base environment of conda, so; conda deactivate command solved the problem. Le dim. 9 avr. 2023 à 15:09, wangwenzheng-agis ***@***.***> a; écrit :. > Hi,i have the same problem, have you solve it ?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501137724>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AWCQKJGPGKTPFL54TTIL5LLXAK7INANCNFSM6AAAAAAWV6IL2A>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041:12,simpl,simply,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041,2,['simpl'],['simply']
Usability,"Hello.; I am not sure if this is a bug or simply a tool version problem but when running the tests with `./gradlew test` I get 18 failures with the `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest` class. I wanted to make sure GATK was working right when compiled it from source to have a working base a I intend to try out some experimental modifications to the code. ## Bug Report. ### Affected tool(s) or class(es); `org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest`. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of [11.12.18]. ### Description; The following commands were used to build and test GATK; ```; git pull; ./gradlew clean; ./gradlew bundle; ./gradlew test; ```; The tests resulted in 18 failed as can be seen in the attached file. ; [Test results - Class org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip](https://github.com/broadinstitute/gatk/files/2667609/Test.results.-.Class.org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest.html.zip). If this is normal (expected) when building from the last commit on master you can close this issue. For experimental development should I use the most recent release or can I work from the most recent commit on master ?. #### Steps to reproduce; see commands above description. The problem could be from a library or java version maybe. I run a Ubuntu 16.04 LTS desktop.; ```; uname -a; Linux A13PC04 4.4.0-140-generic #166-Ubuntu SMP Wed Nov 14 20:09:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. javac -version; javac 1.8.0_102. java -version; java version ""1.8.0_102""; Java(TM) SE Runtime Environment (build 1.8.0_102-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode); ```. #### Expected behavior; I was expecting the tests to pass. #### Actual behavior; 18 tests failed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511:42,simpl,simply,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511,1,['simpl'],['simply']
Usability,"Heng's paper _""A statistical framework for SNP calling. . .""_ presents two methods for calculating a variant QUAL score. The first and simpler approach finds a maximum likelihood allele fraction. The second, which is implemented in the GATK, enumerates the likelihoods of all possible partitions of allele counts among the total ploidy of all samples. The latter approach becomes nightmarish (in terms of speed and code complexity) for non-diploid organisms _or_ multiple alt alleles and scales poorly (quadratically, I believe) with the number of samples. Known bugs in the calculation -- and the difficulty of repairing them -- can be attributed to its complexity. And its treatment of multiple alt alleles involves a major hack. The task is to generalize the allele fraction (as opposed to allele count) equations to non-diploid samples with multiple alt alleles, figure out appropriate priors, and implement it as a new QUAL score calculator.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697:135,simpl,simpler,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697,1,['simpl'],['simpler']
Usability,Here is a blog regarding the Deep CNN model used for variant filtering.... https://gatkforums.broadinstitute.org/gatk/discussion/10996/deep-learning-in-gatk4,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136:140,learn,learning-in-,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136,2,['learn'],['learning-in-']
Usability,Here's a profile. It's clear that all time goes into reading and writing and almost no overhead comes from the engine. Closing this - we win and no obvious problems in the profile.; ![image](https://cloud.githubusercontent.com/assets/1993519/10668338/da596c10-78a9-11e5-8aa0-b6c0ceddad08.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1035#issuecomment-150248706:23,clear,clear,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1035#issuecomment-150248706,1,['clear'],['clear']
Usability,"Here's a prototype showing one way of doing this: https://github.com/broadinstitute/gatk/commit/3cf7f9078b6aedcb87a4ca77c2aa8e84e7e5fe99. The idea is that `GATKTool` has a `-spark` flag, so you can run a tool in Spark mode. The parallel `GATKSparkTool` hierarchy would disappear, and tool writers would optionally be able to support Spark as an alternative to the regular walker, by providing the relevant code in the same tool class. As an example, the `FlagStat` implementation looks like this:. ``` java; @Override; public void traverse() {; if (sparkArgs.useSpark) {; sum = getReadsRdd().aggregate(new FlagStatus(), FlagStatus::add, FlagStatus::merge);; } else {; sum = getReadsStream().collect(FlagStatus::new, FlagStatus::add, FlagStatus::merge);; }; }; ```. Note that the walker version uses the Java 8 Streams API, while the Spark version uses the RDD API. While these are different APIs, many of the concepts are similar, so it should be possible to share the underlying logic by encapsulating it in classes, in much the same way as is done by the `FlagStatus` class for `FlagStat`. It would also be possible to keep the existing `apply` method for walker versions of tools that simply iterate over each record. Removing the parallel `GATKSparkTool` hierarchy has a number of benefits, such as reducing duplication, making it easier for tool writers to add Spark support, and making it easier to share tests. Thoughts? /cc @DR, @lbergelson, @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254180398:1188,simpl,simply,1188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254180398,2,['simpl'],['simply']
Usability,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1053,simpl,simplely,1053,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030,2,['simpl'],['simplely']
Usability,"Here's some old code that uses SamLocusIterator (from tfennel) that AllelicCapseg can adapt for now. From Tim:; ""They key to making this nice and simple is the SamLocusIterator class, which given a BAM file and a list of intervals, will give you pileups at each position in the intervals, filtered how you want them, and even provide convenience methods to access the exact base per read that is piled up at the site etc. The really nice things about doing it this way is that the constructor to SamLocusIterator takes a simple parameter to tell it whether to use an index/query mechanism (similar to what you're doing now) or to just read the BAM serially up until the last interval is reached and output the loci of interest. Running the below with ~100k sites on a standard exome (15GB or so) without using the index took only about 15 minutes."". ```; public void pileup(final File bam, final IntervalList intervals, final int minQ, final File outputFile) {; final int MAX_INTERVALS_FOR_INDEX = 25000; // just a guess, not sure what the right number is. final SamLocusIterator iterator = new SamLocusIterator(new SAMFileReader(bam), intervals, intervals.size() < MAX_INTERVALS_FOR_INDEX);; iterator.setEmitUncoveredLoci(false);; iterator.setQualityScoreCutoff(minQ);. final BufferedWriter out = IoUtil.openFileForBufferedWriting(outputFile); // will automatically gzip if filename ends with .gz; try {; while (iterator.hasNext()) {; final SamLocusIterator.LocusInfo locus = iterator.next();; int a=0, c=0, g=0, t=0;. for (final SamLocusIterator.RecordAndOffset rec : locus.getRecordAndPositions()) {; switch (rec.getReadBase()) {; case 'A' : ++a; break;; case 'C' : ++c; break;; case 'G' : ++g; break;; case 'T' : ++t; break;; }; }. out.append(locus.getSequenceName() + ""\t"" + locus.getPosition() + ""\t"" + a + ""\t"" + c + ""\t"" + g + ""\t"" + t + ""\t"");; }. out.close(); ; }; catch (IOException ioe) { throw new RuntimeIOException(ioe); }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420:146,simpl,simple,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420,2,['simpl'],['simple']
Usability,"Hey @bbimber I will have to think on this. The most simple solution might be to add a feature context side input for the annotation in question but looking at how that code is threaded in the variant callers it would take a little bit of work to add it to those tools and probably introduce some complicated questions, (like for example: what is the correct featurecontext to send to annotate a variant that only covers one base of the site in question where the feature context object exists?). Its possible to do something like that for variant annotator a little bit more easily but i guess the question comes down to this: How generalized do you think this annotation will be? Does it need to be annotatable with variant annotator or could you write a separate tool that does the variant -> variant association and calculates the annotation without using the plugin framework? If it needs to be generalizable I would agree with @droazen that the easiest approach would be to add the side input as an argument and make the annotation object responsible for querying the feature context. This is inelegant but might be preferable to putting the entire walker context into the `annotate()` function.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851:52,simpl,simple,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851,2,['simpl'],['simple']
Usability,"Hey @brianjohnhaas. I'm not quite sure i fully understand what we can change to help you here. However there is a feature you might not be aware of in the bamout that can help you figure out which reads go with what haplotype. In our bamout we assign a tag (that for whatever reason it looks like IGV hides by default) called the XA tag. If you look at an IGV bamout and color by that tag you can see what reads were grouped by what haplotypes. If a read has no XA tag that means it was non-informative about any one haplotype over a second possible contender and thus it was not strong evidence one way or another. Given that in reality when genotyping we are taking the net likelihoods of all reads vs all haplotypes its somewhat of a simplification to say ""this read comes from that haplotype"" as often reads can be evidence for a number of haplotypes that might get called in aggregate but this simplification works in simple cases. Below is a screenshot of what it looks like to do this in a very simple case. Hopefully this answers your question? I would be happy to go deeper into this if you would like. . ![Screenshot 2024-03-08 at 2 35 42 PM](https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994:737,simpl,simplification,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994,8,['simpl'],"['simple', 'simplification']"
Usability,Hey @gokalpcelik thanks for writing in. So there are a few important differences that could be confounding the results you see for SplitNCigarReads between GATK3 and GATK4. The big one is that in GATK 4 the reads get soft clipped instead of hard clipped and the subsequent splits for the reads are marked as Supplementary reads (which does not seem to have been the case in GATK3). Can you check that you aren't filtering non-primary alignments from your output/IGV sessions? Many downstream tools that might operate on split reads must be careful to handle these differences correctly which can easily cause confusion when comparing gatk3.8 results to gatk4+ results. A simple way to confirm is to slect one of those softclipped reads in IGV and to search the output BAM for GATK4 for reads sharing the same name. You should see the matched mates. If it really does appear that the right overhangs are getting dropped as appears from your screenshots then it would be helpful if you could clarify what arguments you ran for both versions of the tool as well as sharing with us an example file where this is happening.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865275697:671,simpl,simple,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865275697,2,['simpl'],['simple']
Usability,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:363,guid,guide,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734,2,['guid'],['guide']
Usability,"Hey @lbergelson, @droazen or @jamesemery: sorry to keep bugging you all here, but I'm not sure what else to do here. I'm hoping we can finalize and close out this feature, or identify what is needed to do so. I recapped the state of this PR in my post above. . I could make a clean feature branch with everything in one place if you want; however, if someone with write permissions could simply approve (https://github.com/broadinstitute/gatk/pull/8871) , merge into this branch, and kick off tests that is all I need right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2243039952:388,simpl,simply,388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2243039952,2,['simpl'],['simply']
Usability,"Hey @lucidtronix, sorry for the delay. . I like the CNNVariant* basename in principle, as it makes it easy to understand which tools are related. CNNVariantWriteTensors and CNNVariantTrain are both quite straightforward so no objections there. However I have some reservations about CNNVariantScore because it's ambiguous as to whether it refers to a score called that, or whether it's the verb to score. As I see it we could resolve that by simplifying the basename to just CNN, and making the three tools CNNWriteTensors, CNNTrainModel and CNNScoreVariants. What do you think? Do we have any reason to believe we would need to be able to call something else CNN* where *!=Variant? If not, the overall process can still be called CNNVariant without needing to include Variant explicitly in the tool names. . For VariantTranchesFromInfoKey, I'd like to find a simpler way to express what it does -- would FilterVariantTranches sound appropriate to you? I'm still a bit fuzzy on exactly what are the inputs/outputs of this tool. Is it a direct analog to the VQSR ApplyRecalibration tool, ie does it take a sensitivity threshold? And can one use any arbitrary Info key? That's what the current name implies to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321:442,simpl,simplifying,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321,4,['simpl'],"['simpler', 'simplifying']"
Usability,"Hey @mwalker174,. Setting `--host-min-identity 20` lowered the `READS_AFTER_PREALIGNED_HOST_FILTER` to 131467, which is closer to what I expected (albeit still 12% of the reads) so thanks for the suggestion. I'm still unsure why the preferred approach is to use this fairly arbitrary metric that doesn't incorporate both mates instead of leveraging the known alignments from STAR, which does. Given what I've learned today, I think the better approach (for my use case) would be to filter the unique mappers, the multi-mappers and the chimeric reads (which in my data set represent 97.5% of the reads) and then apply the QUALITY_AND_COMPLEXITY_FILTER and the DUPLICATE_READS_FILTER. Would you agree?. To put myself in your shoes, I would guess that PathSeq is designed for general purpose use cases (which is probably `--is-host-aligned false`) and that performing such a filtering would require specific handling for each supported aligner, which would be a lot of work. Moreover, my use case with short paired-end reads is also probably not common. So I understand why you use the existing approach but are there any reasons that I'm missing as to why you'd suggest to stick with the basic approach for my use case instead of the one that I proposed above?. Best, Welles",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652524772:409,learn,learned,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652524772,2,['learn'],['learned']
Usability,"Hey @samuelklee. That is true, the default location for a gradle test output is tests/#taskname#. I'm not sure what the problem is however. If you look at the gradle test logs there is a line pointing to where the reports live: "" Test report will be written to https://storage.googleapis.com/hellbender-test-logs/build_reports/master_20802.3/tests/test/index.html."" Those links seem to work on the latest master. We fix this by simply renaming the files before we upload them however. Is this explanation adequate or would you like the build system changed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5029#issuecomment-406332294:428,simpl,simply,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5029#issuecomment-406332294,2,['simpl'],['simply']
Usability,"Hey all, I'm still interested in supporting this. We don't really have a ""plugin API"", I am in fact the API, but if you give me something usable I'll plug it in. As this is marked ""QuixoticDream"" I don't think that's likely. I'm closing the corresponding IGV issue, too many open issues, but it doesn't mean I've lost interest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230:138,usab,usable,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230,2,['usab'],['usable']
Usability,Hi ; We have a forum post asking help for getting GATK 4.1.0.0 conda environment installed using the yml file. ; [https://gatk.broadinstitute.org/hc/en-us/community/posts/18332470602523-Install-GATK-version-4-1-0-0-using-Conda-](url). Looks like restructuring of the default repository under conda took out some of these packages and they are no longer directly accessible. They can be accessed from the forge repo with certain flags. This issue seems to deprecate some of the older but still usable versions of GATK (due to various reasons). Directing people to use the docker version or upgrading to the latest GATK version seems to be the only solution left for now. Any other ideas of how we should pursue this issue? @lbergelson @droazen ?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8504:493,usab,usable,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8504,1,['usab'],['usable']
Usability,"Hi @LiviaMoura . We don't have any haploid calling in the Broad production pipeline, so we never included that feature in Gnarly. (For chrY people typically filter out hets and then treat 0/0 as 0 and 1/1 as 1. chrX on males admittedly requires a little more finesse.) I can probably take a look next week. I'm not sure how much effort a fix would entail, but hopefully the haploid case is just a simpler version of the diploid case right? :-)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545:397,simpl,simpler,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545,2,['simpl'],['simpler']
Usability,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:1064,feedback,feedback,1064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177,2,['feedback'],['feedback']
Usability,Hi @RWilton i'm sorry to hear that. I suspect its unrelated given how simple this PR is but its quite possible that filter has been broken since evidently nobody was able to use and adjust it for a long time. This is the logic here that the filter uses:; `return read.isPaired() && !read.isUnmapped() && !read.mateIsUnmapped() &&; (Math.abs(read.getStart() - read.getMateStart()) >= mateTooDistantLength || !read.getContig().equals(read.getMateContig()));`. That logic is correct for what the filter is doing. It should be noted that the filter does the opposite of what you expect it to (since its intended for our SV pipeline) in that it filters out all reads that are NOT having distant mates. This means if you try to run HaplotypeCaller with this setting you will be throwing away every read pair EXCEPT the distant ones which results in mostly no reads. We should perhaps rename this filter to be a little less confusing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098:70,simpl,simple,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098,2,['simpl'],['simple']
Usability,"Hi @ScienceConnor - thanks for the feedback, this is Ilya from Ultima Genomics. ; From what I see, this seems to me to be more of the output format issue rather than the issue with HaplotypeCaller per se.; Would you mind pinging me over ilya dot soifer at ultimagen dot com and I am happy to help you out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8112#issuecomment-1332400762:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8112#issuecomment-1332400762,2,['feedback'],['feedback']
Usability,"Hi @Tintest,. If you need some guidance in interpreting the WDL pipeline script that @samuelklee linked, please let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160:31,guid,guidance,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160,2,['guid'],['guidance']
Usability,"Hi @bklein345, thanks for this contribution! I'd be happy to review, but the current CNV tech lead @mwalker174 should probably make the final decisions about how this tool should ultimately go in. A few quick thoughts:. 1) If you'd like to make the PR from your Broad account, feel free to reopen---either way is fine with us. However, if you do, perhaps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we als",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:548,guid,guide,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,2,['guid'],['guide']
Usability,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:224,simpl,simple,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525,2,['simpl'],['simple']
Usability,"Hi @david-wb . I reformatted your comment slightly to make the stack trace more legible, I hope you don't mind. I suspect your intuition about the System.exit(0) is entirely correct. I suspect we haven't noticed it because we typically run in yarn client mode and you're running in cluster mode. . Two questions:; 1. How often does it happen? Can you regularly reproduce it?; 2. Have you examined the output files to make sure they are correct and not truncated? . It looks like we'll probably have to add a check and wait for the spark context to properly shut down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299493397:127,intuit,intuition,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299493397,2,['intuit'],['intuition']
Usability,"Hi @jean-philippe-martin ,. A `Feature` in our codebase has a specific meaning that is different from ""interval"": it is a record that 1. has a location on the genome plus (typically) some metadata information about that location and 2. is in one of the formats supported by our file-parsing framework tribble and is the product of a tribble codec. A VCF record is an example of a `Feature`. . The common interface between `Feature` and `SimpleInterval` is called `Locatable`. I recommend (for now) that you simply alter your uprooted version of BQSR to take a `List<? extends Locatable>` instead of a `List<? extends Feature>` in `apply()`. This should require no code changes beyond changing method parameter types, and it will allow you to feed BQSR `SimpleIntervals` for the known sites for now, and `Features` like VCF records later on when we're ready for that. Please do return `ArtificialTestFeature` to the `FeatureDataSourceUnitTest` from which it came -- this is a very incomplete class meant only for testing purposes and not for external use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247:507,simpl,simply,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247,1,['simpl'],['simply']
Usability,"Hi @lbergelson and thanks for considering my issue,. I'm sorry but I'm not familiar to artifactory dependency, if necessary I'll deepen about it; so I just inserted this dependency in the project's pom.xml; ```; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; ```; as reported in the [artifact repository](https://broadinstitute.jfrog.io/broadinstitute/webapp/#/artifacts/browse/tree/General/libs-snapshot-local/org/broadinstitute/gatk/4.beta.6-18-g2ee7724-SNAPSHOT/gatk-4.beta.6-18-g2ee7724-20171025.162137-1.jar), but when I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 -> [Help 1]; ```. Am I making any mistake?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024:650,clear,clear,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024,2,['clear'],['clear']
Usability,"Hi @magicDGS. After looking a bit more at this PR , and talking with others, I think we should put this branch on hold for a bit. We plan to introduce a new class soon that will serve as a common currency for input specifiers, and we'll probably want to revisit these constructors then. Hopefully that will be a simplifying change. In the meantime, I'd prefer not to introduce more overloads. We'd like to put this on hold until we make progress on that, and then perhaps resurrect parts of this branch as needed. My apologies for the churn.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-274960068:312,simpl,simplifying,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-274960068,2,['simpl'],['simplifying']
Usability,"Hi @magicDGS. I went down this same path (composition of CountingFilter) when I originally implemented CountingReadFilter, but I abandoned it for the model we currently have. I think the current model is much simpler in a number of ways. This is an interesting problem, but I would say lets just implement a straight CountingVariantFilter/tests and not try to do the common implementation. . BTW, when looking at this PR I noticed two bugs in the existing code that we should make sure not to propagate to the Variant one (feel free to fix/test these as part of this PR):. - CountingReadFilter.resetFilterCount only resets the root filter count; it needs an override in BinOp to propagate the reset call to the lhs/rhs operands.; - there is a bug in the getSummary tests/code; you can see the fix [here](https://github.com/broadinstitute/gatk/commit/9ef1458271834aed9b64a5d66f94df33f025eafb). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272954313:209,simpl,simpler,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272954313,2,['simpl'],['simpler']
Usability,Hi @potter-s ; Our docker image is already built with root account only however PATH is set to be usable by all users so if you wish to keep user priviledges after execution you may add ` -u $UID:$GID` parameter to docker command line therefore the container will run using your user permissions. . This has a catch of course. Temporary folders must be set where your user has RWX permissions therefore we want users to pay attention to that. There is a writing that we posted a while ago which you may refer to for setting up your temporary files for GATK workflows. . [How to setup temporary folder for GATK local executtion](https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution). For some of the tools such as gCNV or CNN you may need to setup additional environment variables to locate python compilation directory to a place where you have read and write permissions. . I hope this helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965:98,usab,usable,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965,2,['usab'],['usable']
Usability,"Hi @qindan2008 - is this the full log file that is produced, or is there more to it? If there is more to the log file can you post it? Would you mind posting one or two of your variants as well? They can be simplified - I only the need position and alleles. Also, did you happen to make any modifications to the data sources? If you enabled gnomAD, Funcotator will try to read the gnomAD data sources via the Google Cloud API, which may be slow or fail depending on your internet connection and settings. You could experience similar issues if you added another web-facing data source.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869:207,simpl,simplified,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869,2,['simpl'],['simplified']
Usability,"Hi @samuelklee ; yes you are right, I did not recreate the conda environment when updating to 4.0.3.0. I'll try that and give you a feedback. Do you know the state of developement of the germline CNV best practise or a short manual?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382717819:132,feedback,feedback,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382717819,2,['feedback'],['feedback']
Usability,Hi @samuelklee @mwalker174 . New defaults are clearly not suitable for anyone to use them directly. I forgot to pay attention to this detail and realized that all my female samples turned turner (X:1 Y:0) due to these new parameters (I reverted these parameters and looks like the problem is solved). Could that be possible that UKBB is using a very heterogenous exome dataset generated from different centers with different kits etc..?. My sample set is usually smaller like 50 to 100 samples at a time but sequenced using a single instrument and single kit so I expect them to be more homogenous compared to UKBB. I also tend to remove samples with extreme AT/GC Dropout values (samples with values greater or equal to ~%9 are removed from my set. Of course I usually check for mean and median values as well for that I may keep some but still remove anything more than %10) which kills the whole purpose of CNV calling due to extreme fluctuation.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858805583:46,clear,clearly,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858805583,2,['clear'],['clearly']
Usability,"Hi @tedsharpe ! . I also commented about it on the helpdesk but should probably reply directly here. The .bam file was aligned to a reference , the same reference I used to run the tool. I was wondering If the bam still contained unmapped reads and so used ; `samtools view -b -F 4` on the file to retain only mapped reads and re-run the GATK tool. However this did not improve the situation. Best,; Domniki. error log:. 22/03/11 06:13:57 INFO SparkUI: Stopped Spark web UI at http://10.222.0.104:4040; 22/03/11 06:13:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 22/03/11 06:13:58 INFO MemoryStore: MemoryStore cleared; 22/03/11 06:13:58 INFO BlockManager: BlockManager stopped; 22/03/11 06:13:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 22/03/11 06:13:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 22/03/11 06:13:58 INFO SparkContext: Successfully stopped SparkContext; 06:13:58.369 INFO FindBreakpointEvidenceSpark - Shutting down engine; [March 11, 2022 6:13:58 AM GMT] org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark done. Elapsed time: 3.28 minutes.; Runtime.totalMemory()=29312942080; java.lang.ArithmeticException: / by zero; at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.removeUbiquitousKmers(FindBreakpointEvidenceSpark.java:640); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.addAssemblyQNames(FindBreakpointEvidenceSpark.java:507); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.; at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.runTool(FindBreakpointEvidenceSpark.java:136); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1064823936:647,clear,cleared,647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1064823936,2,['clear'],['cleared']
Usability,"Hi @wujh2017,. You should filter your variants using the various quality scores described in the VCF header. We find that simply filtering on QS is typically a good strategy. Also, you might find it more helpful to post this sort of question in the GATK forums---other users might benefit from seeing the answer there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4790#issuecomment-394487888:122,simpl,simply,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4790#issuecomment-394487888,2,['simpl'],['simply']
Usability,"Hi Adam,. Maybe I'm thinking naively here - and I don't have access to a complete and proper Spark cluster for rigorous testing - but just as a simple test of loading a VCF via Spark, I took [PrintReadsSpark.java](https://github.com/broadinstitute/gatk/blob/030858bc08328200b9df287db2571b907189ec66/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark.java) and performed following updates:; - Copied `./src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:144,simpl,simple,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['simpl'],['simple']
Usability,"Hi Adam,. This is based on your feedback from Friday afternoon. ; Lots of issues are still to be addressed (multilevel collection, more test coverage, performance, etc).; If you are too busy to review, let me know and I'll bug @cwhelan or @tedsharpe or someone else. Branch travis log available [here](https://travis-ci.org/broadinstitute/gatk/builds/110702136). Thank you.; Steve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1514:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1514,1,['feedback'],['feedback']
Usability,"Hi Chuck, the GATK blog is set up to only accept posts from admins or moderators on the forum (or my team). If you're willing to write something up, we would do it as a guest post, where I would post the text on your behalf (with clear attribution to you). If you'd like to share a draft with us the easiest way to do it is through a google doc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287546670:230,clear,clear,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287546670,1,['clear'],['clear']
Usability,"Hi DarioS. FastaAlternateReferenceMaker is a really simple tool. It actually just looks at the alternate alleles at each site and uses the first non-symbolic one to make the fasta. It doesn't even look at the genotypes. So it should work fine with a multisample vcf but it will give you a mush of samples together as a single fasta. I could be extended to be smarter but it's not a high priority for us right now. . We should improve the documentation, I had to go look in the code to see what it was doing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729:52,simpl,simple,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729,2,['simpl'],['simple']
Usability,"Hi David,. Thanks for your response and effort developing the best practices pipeline and GATK. I'm not certain, but I would suspect that a significant percentage of your users may also not use the best practices pipeline for one reason or another. In my particular case, I intersect calls from multiple variant callers and prefer to run this pipeline without the added abstraction of Terra (or WDL) for the sake of simplicity. This was easy to fix on my end, thanks again. Andrew. @davidbenjamin. > On Sep 3, 2019, at 4:16 PM, David Benjamin <notifications@github.com> wrote:; > ; > @lbergelson The stats file is not optional, but the argument is optional because by default FilterMutectCalls looks for the stats file produced automatically by Mutect2 in the same directory as the output vcf.; > ; > @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?; > ; > As for backwards compatibility, while we can guarantee that Mutect2 and FilterMutectCalls from the same GATK release will always work together we do not make any promises about the interoperability of different releases.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415:416,simpl,simplicity,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415,2,['simpl'],['simplicity']
Usability,"Hi Jose,; Your system ulimit setting is too low. Please do this with root at; /etc/security/limits.conf; * soft memlock unlimited; * hard memlock unlimited; * hard nofile 20480; * soft nofile 20480; * hard nproc 40960; * soft nproc 40960; * soft stack unlimited; * hard stack unlimited. Ruzhu; -------------------------------------------; Ruzhu Chen, PhD (845) 433-8426(T/L 293-8426); Email: ruzhuchen@us.ibm.com, Mobile: (845) 337-7238; Sr. Technical Solution Architect, HPC / Genomics & Life Sciences; IBM Systems, 2455 South Road, Poughkeepsie, NY 12601. From:	Jose Sergio Hleap <notifications@github.com>; To:	broadinstitute/gatk <gatk@noreply.github.com>; Cc:	ruzhuchen <ruzhuchen@us.ibm.com>, Mention; <mention@noreply.github.com>; Date:	03/12/2020 11:37 AM; Subject:	[EXTERNAL] Re: [broadinstitute/gatk] Got ""Too many open files""; when use BaseRecalibratorSpark (#5316). Apologies on the poor report. There are no other users in these compute; nodes (I am the tester) and for all intents and purposes the ulimit is; pretty high (hard limit of 8192 max files). I am using GATK version; 4.1.4.1, although it might be the one that has been optimised for IBM; power9 systems by @ruzhuchen. Currently I am waiting for the sys admin to; increase the max files further, but I believe that this is far from ideal.; Here is the (simplified) command:. gatk --java-options ""-Xmx40g; -Djava.library.path=/bio/apps/gatk_4.1.4/gatk-4.1.4.1/libs; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" Mutect2 -R; Homo_sapiens_assembly38.fa -I illuminaN_hg38.br.recal.bam; --max-mnp-distance 0 -O illuminaN.vcf.gz. May be I am running it wrong?. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062:1327,simpl,simplified,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062,2,['simpl'],['simplified']
Usability,"Hi Karthik @kvn95ss ,. This isn't going to do what you want it to do if we implement it as you suggest. The latest GVCF formats try to preserve more annotation data so we can get better statistical power by using all mapping quality values (for example) rather than taking the median across all samples. As such, genomicsDB is going to return a value that isn't usable by VariantRecalibrator without going through GenotypeGVCFs to take the final mean and square root of the stored sum of the squared MQ values. GenomicsDB also won't calculate the FS or SOR values; it will only return the strand bias table. Finally, GenotypeGVCFs will apply a QUAL threshold to remove the lowest evidence variants so your final callset isn't riddled with false positives. GATK4 joint calling pipelines should always include GenotypeGVCFs, whether using CombineGVCFs or GenomicsDBImport to combine single-sample GVCF data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495:362,usab,usable,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495,2,['usab'],['usable']
Usability,"Hi Laura, hope you are enjoying your maternity leave!; Unfortunately i will not have time to look into this, since I’m writing up a paper.; cheers,. > On Feb 12, 2017, at 4:17 PM, Laura Gauthier <gauthier@broadinstitute.org> wrote:; > ; > This is probably affecting some of the GWAS studies but in subtle ways that haven't popped up yet. I'm cc'ing Andrea in the hopes that he has some time to think about the issue. I'd need some uninterrupted time to work out the details and that's hard to come by at the moment.; > ; > On Feb 11, 2017 12:21 AM, ""chlangley"" <notifications@github.com <mailto:notifications@github.com>> wrote:; > Thanks for getting this cleared up.; > OK, what next? I'll check with colleagues who may be aware this 'feature'. Perhaps the case can be made more clearly by a group of users, including visible labs working on human evolutionary genomics.; > ; > I don't know the CA genomics community well, but my shallow poling suggests most are happily unaware that SNPs near indels will often be assigned lower quality than they might.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AGRhdNaqeg_h2KxcxGULyoiSO3D8EY9eks5rbUVogaJpZM4DrC8o>.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279274088:656,clear,cleared,656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279274088,2,['clear'],"['cleared', 'clearly']"
Usability,"Hi Marissa - I think we're all in agreement that we'd like to find a way to make Intel-TF the default, but whether or not we can have CNNScoreVariants require AVX to run is less clear. Naturally, we'd prefer to not have to provide a custom TF distribution for a fallback, but there are 3 cases where we may not have a choice: user with old hardware, Travis/CI testing, and GCE. We may need to provide a fallback environment for those (I'll try to get resolution on that). If it turns out we do, I'm actually not suggesting the fallback be automatic (3 in your list), just that we have a graceful failure mode and an instructive error message. . In the meantime, there is still the issue that this PR fails to even build on Travis. It looks like it produces so much output building the Docker image that it exceeds the allowable Travis build log size. That will need to be resolved, and we'll also need to understand the impact of this change on the size of our Docker image, which is already large, and continues to be a challenge for us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059:178,clear,clear,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059,2,['clear'],['clear']
Usability,"Hi Nick, looks good. A few comments: many if not all of the warnings could be fixed rather than simply suppressed. Fixing warnings is always preferred to suppressing them. Can you try fixing them?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/435#issuecomment-95712825:96,simpl,simply,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/435#issuecomment-95712825,1,['simpl'],['simply']
Usability,"Hi all, thanks again for working to integrate this code!. Saw some confusion in the comments above and just wanted to clarify: if you take a look at the VQSR-lite PR https://github.com/broadinstitute/gatk/pull/7954/commits that the current branch is rebased upon, you'll see that it contains a version of the Joint Genotyping WDL (which was put together by Megan for Ultima) along with Java code for the tools (which was written by me). Both the WDL and the code have been updated in subsequent PRs. The WDL was rewritten by me in #8074; the main difference is that we no longer run SNPs and indels filtering in ""series"", but instead run them in a single step. However, this requires that you use the same annotations for both SNPs and indels; GVS might not be ready for that just yet, since the default WARP implementation uses different annotations. (But see also the comment here: https://github.com/broadinstitute/gatk/pull/8074#issue-1423991277. The gist is we can easily reimplement Megan's/WARP's ""serial"" SNP-then-indel workflow using the simpler single-step workflow.) (EDIT: I was originally confused here, Megan’s WDL simply runs SNPs and indels separately—thanks to George for correcting me here!). Note also that test infrastructure was moved from Travis to Github Actions between these PRs, so the Travis references above have already been cleaned up. There have also been a few additional minor PRs merged in the interim, with a couple more incoming. These PRs do not fundamentally change the interfaces of the tools/WDL, however, so I think you can update to them when you're ready. Punchline: this branch should suffice for a first cut of a VQSR/VQSR-lite bakeoff, and although it is already slightly out of date, it shouldn't be too much work to get things updated after the first cut is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649:1047,simpl,simpler,1047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649,4,['simpl'],"['simpler', 'simply']"
Usability,Hi all.; We do have a PR in the master branch to fix this issue. However keep in mind that the variant you are trying to call is probably way above the size that one can call a simple INDEL. ; [https://github.com/broadinstitute/gatk/pull/6388](https://github.com/broadinstitute/gatk/pull/6388),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2374721379:177,simpl,simple,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2374721379,2,['simpl'],['simple']
Usability,"Hi all;; I'm running to a segfault issue with GATK4 beta6 when running GenomicsDBImport on some batches. This is a small self contained test case that demonstrates the problem:. https://s3.amazonaws.com/chapmanb/testcases/gatk/gatk4_genomicsdb_segfault.tar.gz. When running:; ```; gatk-launch --javaOptions '-Xms1g -Xmx2g' GenomicsDBImport --genomicsDBWorkspace fails_genomicsdb -L chr6:130365070-146544250 --variant NA12878.vcf.gz --variant NA24631.vcf.gz --variant NA24385.vcf.gz; ```; It appears to segfault in jniImportBatch:; ```; Java frames: (J=compiled Java code, j=interpreted, Vv=VM code); j com.intel.genomicsdb.GenomicsDBImporter.jniImportBatch(J[J)Z+0; j com.intel.genomicsdb.GenomicsDBImporter.importBatch()Z+160; j org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse()V+301; j org.broadinstitute.hellbender.engine.GATKTool.doWork()Ljava/lang/Object;+12; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool()Ljava/lang/Object;+27; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs()Ljava/lang/Object;+431; j org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain([Ljava/lang/String;)Ljava/lang/Object;+14; j org.broadinstitute.hellbender.Main.runCommandLineProgram(Lorg/broadinstitute/hellbender/cmdline/CommandLineProgram;[Ljava/lang/String;)Ljava/lang/Object;+20; j org.broadinstitute.hellbender.Main.mainEntry([Ljava/lang/String;)V+19; j org.broadinstitute.hellbender.Main.main([Ljava/lang/String;)V+8; v ~StubRoutines::call_stub; ```; The same command works without the NA24385.vcf.gz sample but it wasn't clear what caused the issue from this input. I'm also seeing similar behavior over a few other regions and guess they're all caused by the same underlying issue. Thanks much for any pointers or ideas and please let me know if any other information would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3736:1610,clear,clear,1610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3736,1,['clear'],['clear']
Usability,"Hi gatk team,. I just run a cfDNA sample and there is no variant being called, thus there is no "".stats"" file being generated so that when it comes to `filterMutectCalls`, it gives error. I wonder if it is wiser that we output an empty stats file, e.g.; ```; statistic	value; callable	0; ```. or simply reports . ```; ERROR: No callable variants detected!; ```. instead of reporting missing stats file? This would be more informative. Thanks!!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6170:296,simpl,simply,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6170,1,['simpl'],['simply']
Usability,"Hi team,. GATK have a GRCh38 version that available in Resource bundle. It is not clear if this version have a masked duplicates.; Could you provide a GRCH38 version, ready to use, with masked duplicates? that can deal with this issue that affect on variants recall in these regions, such as CBS gene. B.W",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8043:82,clear,clear,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8043,1,['clear'],['clear']
Usability,"Hi there,. I am using ASEReadCounter and it works fine, but I did not find any other output than count tables. I'd like to count by haplotypes, or simply to be able to merge several snp counts together (because I know they are in LD, or they come from the same haplotype); If the tool could export read names per allele, instead of counts, I would be able to merge them together. But here I cannot merge the counts, since they can originate from the same read. Could you add an option to allow users to count per haplotypes/LD snps/group of snps, or simply output read names instead of count tables?. Thanks",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4813:147,simpl,simply,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4813,2,['simpl'],['simply']
Usability,"Hi! This issue is a duplicate of #7054 - under the hood a few changes need to be made to support arbitrary `FeatureTag`s. ; As gencode is updated they seem to be adding more `FeatureTag`s, which Funcotator doesn't expect. The fix is relatively straight-forward, but requires several other changes as well. Unfortunately there isn't a good workaround right now. As a side-note, the `getGencode.sh` script you referenced (and all scripts in that same folder: `scripts/funcotator/data_sources`) are not supported and are designed to be for internal use (I have a file in that folder to indicate this, but I'll admit it's not 100% clear). That said, `getGencode.sh` should work properly - the issue is in the GATK itself (specifically in `org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature` and associated classes). This is on the short list of things to update next, so I'll try to get to it soon (though I'm not exactly sure when that will be). Given two people have experienced this issue, I'll prioritize it somewhat higher.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339:627,clear,clear,627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339,2,['clear'],['clear']
Usability,"Hi, I am encountering a similar error attempting to run `GenotypeGVCFs` in `gatk v4.1.2.0`. It runs very briefly and writes a handful of variants from a single scaffold to the output file but then exits with `java.lang.ArrayIndexOutOfBoundsException` (see below). I have also tried adding the `-L` flag and an interval list, which performs similarly but outputs variants from a different scaffold. Any idea why this is happening or what I can do to overcome this problem? I have run `GenomicsDBImport` and `GenotypeGVCFs` successfully in the past (same version, same computer) on a different dataset, so I'm not sure what about this data is causing the problem. Any guidance is much appreciated!. Thanks,; Jessie. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jsalt/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar GenotypeGVCFs -R /nfs/data1/jsalt/3RAD/colinus_virginianus_13May2017_V3Fw6_newchrom.fasta -V gendb://odont_cyr_8_snp_db -O odont_cyr_8_snp_db.vcf; 14:59:47.866 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jsalt/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 2:59:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:59:59.674 INFO GenotypeGVCFs - ------------------------------------------------------------; 14:59:59.675 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.2.0; 14:59:59.675 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:00:09.686 INFO GenotypeGVCFs - Executing as jsalt@mustard on Linux v3.10.0-957.1.3.el7.x86_64 amd64; 15:00:09.686 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 15:00:09.687 INFO GenotypeGVCFs - Start Date/Time: F",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640:666,guid,guidance,666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640,2,['guid'],['guidance']
Usability,"Hi, everyone! I'm trying to call mutation with Mutect2 with RNA-seq, and my scripts are given below. I simply use one sample as a test, with a prior knowledge that the mutation in ASXL1(c.1934dupG) can be detected with a pretty high VAF, and I can also see this mutation by using bam file in IGV, but I really wonder why my scripts can not call this mutation before filtering? Thank you so much!!!; ![image](https://github.com/user-attachments/assets/58bfd1be-748e-453c-be0b-d49569e14dd5); gatk Mutect2 \; -R ${ref}.fa \; -I ${sam}/${sam}.BQSR.bam \; -O ${sam}/gatk/${sam}_withpon.vcf \; --create-output-bam-index FALSE \; --af-of-alleles-not-in-resource 0.0000025 \; --create-output-variant-index false \; --germline-resource /home/cuiyiran/data/mtDNA_mutation/reference/somatic-hg38_af-only-gnomad.hg38.vcf \; --panel-of-normals /home/cuiyiran/data/mtDNA_mutation/reference/somatic-hg38_1000g_pon.hg38.vcf. gatk FilterMutectCalls \; -R ${ref}.fa \; -V ${sam}/gatk/${sam}_withpon.vcf \; --create-output-variant-index false \; -O ${sam}/gatk/${sam}_withpon_fv.vcf. bcftools norm -m -both ${sam}/gatk/${sam}_withpon_fv.vcf | bcftools norm -m +both -f ${ref}.fa ${sam}/gatk/${sam}_withpon_fv.vcf -Ov -o ${sam}/gatk/${sam}_withpon_norm.vcf; ####annotation; perl ~/miniconda3/envs/vep/bin/vcf2maf.pl \; --input-vcf ${sam}/gatk/${sam}_withpon_norm.vcf \; --output-maf ${sam}/gatk/${sam}_withpon_vep.maf \; --vep-path ~/miniconda3/envs/vep/bin/ \; --vep-data $vepcache \; --ncbi-build GRCh38 \; --cache-version=112 \; --ref-fasta ${ref}.fa \; --tumor-id ${sam}",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9021:103,simpl,simply,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9021,1,['simpl'],['simply']
Usability,"Hi, i can't install gatk via conda/mamba. couldyou pls help; pls see steps that i took. ```; $conda config --add channels conda-forge; $conda config --add channels bioconda; $conda config --add channels defaults; $conda config --set channel_priority strict; ```. install command; ```; bash:iscxf001:/data1/greenbab/users/ahunos/apps/gatk-4.5.0.0 1023 $ conda env create -n gatk -f gatkcondaenv.yml; ```. ```; Channels:; - conda-forge; - defaults; - bioconda; Platform: linux-64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::typing_extensions==4.1.1; - conda-forge::theano==1.0.4; - pkgs/main::tensorflow==1.15.0; - conda-forge::scipy==1.0.0; - conda-forge::scikit-learn==0.23.1; - conda-forge::python==3.6.10; - bioconda::pysam==0.15.3; - conda-forge::pymc3==3.1; - conda-forge::pip==21.3.1; - conda-forge::pandas==1.0.3; - conda-forge::numpy==1.17.5; - conda-forge::mkl-service==2.3.0; - conda-forge::mkl==2019.5; - conda-forge::matplotlib==3.2.1; - conda-forge::keras==2.2.4; - conda-forge::joblib==1.1.1; - pkgs/main::intel-openmp==2019.4; - conda-forge::h5py==2.10.0; - conda-forge::dill==0.3.4. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/r/linux-64; - https://conda.anaconda.org/bioconda/linux-64; - https://conda.anaconda.org/bioconda; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https://conda.anaconda.org/conda-forge; - https:/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8838:802,learn,learn,802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8838,1,['learn'],['learn']
Usability,"Hi, there:. I realize that GATK team released plenty of wonderful tutorials, best practice guidances, WDL scripts, etc. However, for users like me, I still prefer some simple and straight-forward BASH scripts that I could easily embed into existing pipelines and fire up. . Below is what I got from Chat-GPT. I tested it and it actually worked magically, processing my fasta.gz files into VCF. Can someone please kindly take a look at this, and let me know if there is some issue with this script?. Thank you very much & best regards,; Jie. ![image](https://github.com/broadinstitute/gatk/assets/26947455/12e2c577-2633-4189-a02c-ec45c677aa50)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8905:91,guid,guidances,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8905,2,"['guid', 'simpl']","['guidances', 'simple']"
Usability,"Hi,. Thanks for the response. Running with -u isn’t ideal as we can’t control; how the user runs this (unless they do this on their own hardware or say a; cloud instance). However, I managed to convert the docker image into a singularity one and; that runs ‘out of the box’ in user space. Simon. On 3 Jun 2024, at 18:43, Gökalp Çelik ***@***.***> wrote:. Hi @potter-s <https://github.com/potter-s>; Our docker image is already built with root account only however PATH is; set to be usable by all users so if you wish to keep user priviledges after; execution you may add -u $UID:$GID parameter to docker command line; therefore the container will run using your user permissions. This has a catch of course. Temporary folders must be set where your user; has RWX permissions therefore we want users to pay attention to that. There; is a writing that we posted a while ago which you may refer to for setting; up your temporary files for GATK workflows. How to setup temporary folder for GATK local executtion; <https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution>. For some of the tools such as gCNV or CNN you may need to setup additional; environment variables to locate python compilation directory to a place; where you have read and write permissions. I hope this helps. —; Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965>,; or unsubscribe; <https://github.com/notifications/unsubscribe-auth/ABU3SAWISO2HSCUNHK3SGIDZFSTK5AVCNFSM6AAAAABIWRNXGKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBVG44DAOJWGU>; .; You are receiving this because you were mentioned.Message ID:; ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154:483,usab,usable,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154,2,['usab'],['usable']
Usability,"Hi,; Currently, using spark tools, we can set the runner and master using --sparkRunner and sparkMaster.; However, there is not similar parameter to set the deploy-mode so we have to manually set it using --conf.; For example , the following parameters are currently used in the command-line to run on a yarn+cluster spark environment : ; `--sparkRunner SPARK --sparkMaster yarn --conf 'spark.submit.deployMode=cluster'`; It's not very user-friendly, a sparkDeployMode parameter could be usefull :; `--sparkRunner SPARK --sparkMaster yarn --sparkDeployMode cluster`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933:436,user-friendly,user-friendly,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933,1,['user-friendly'],['user-friendly']
Usability,"Hi,; The HaplotypeCaller_GATK4_VCF task in the gatk4-exome-analysis-pipeline doesn't seem to add any interval padding. Shouldn't there be interval padding?. Unless the configured Broad intervals already have padding added, but it is not clear why that would be, since that same file is used for calculating HsMetrics, which should not have padding. The question is, for my own implementation of this pipeline, should I add on interval padding to the interval list file? And if so, what size padding? Or should I add the interval padding option to the HaplotypeCaller itself in the wdl script. Thanks for any advice on this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071:237,clear,clear,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071,1,['clear'],['clear']
Usability,"Hi,; With gatk 4.6.0 and Funcotator data sources v1.8, and output in VCF format, I'm seeing some annotations with strange character combinations inside of them:; ""_%7C_""; ""_%20_"". For example for one varaint chr11:54942730 C>T (hg38), for gnomAD_genome_AF, I'm seeing:; 8.55286e-05_%7C_3.46021e-04. But this should simply be one number. Seems like a bug in the parsing of the retrieval of gnomAD info from the google cloud bucket by Funcotator.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8965:315,simpl,simply,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8965,1,['simpl'],['simply']
Usability,"Hitting a snag: the md5 output option doesn't seem to work with streams, and so the simple approach of ""just use Path everywhere"" fails because makeSAMWriter in htsjdk doesn't behave identically between a file or an outputStream. Now the question is: is there a fundamental reason for that, or can just add in the md5 feature? At first blush, it seems possible. @droazen, what's your expert opinion?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-290866339:84,simpl,simple,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-290866339,2,['simpl'],['simple']
Usability,HlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdBc3NlbWJsZXIuamF2YQ==) | `52.479% <100%> (-13.636%)` | `29 <0> (-20)` | |; | [...hellbender/engine/spark/IntervalWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSW50ZXJ2YWxXYWxrZXJDb250ZXh0LmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ls/walkers/mutect/filtering/BaseQualityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvQmFzZVF1YWxpdHlGaWx0ZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...nder/tools/readersplitters/SampleNameSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9yZWFkZXJzcGxpdHRlcnMvU2FtcGxlTmFtZVNwbGl0dGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...nder/tools/spark/pipelines/CountVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...lbender/tools/walkers/mutect/clustering/Datum.java](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL0RhdHVtLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-7%)` | |; | ... and [1845 more](https://codecov.io/gh/broadinstitute/gatk/pull/6047/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6047#issuecomment-513288952:3460,Simpl,SimpleSVD,3460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6047#issuecomment-513288952,1,['Simpl'],['SimpleSVD']
Usability,"Hmm, I started taking a stab at the LL score implementation, but I think it's going to complicate the code quite a bit and add some branching options to the tool interfaces. Compounding this with a change in the use of ""truth"" and ""validation"" terminology, I fear that the resulting differences from the legacy strategy might be a bit much for users to digest!. So I'd want to better understand the cost/benefit before we proceed. How critical is automatic tuning of the hard threshold? And what's the relative importance to method changes that increase AUC (i.e., as opposed to figuring out where on the curve to hard threshold)? Is there a clear path forward for evaluating such a tuning process? @meganshand would be glad to chat more!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909:642,clear,clear,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909,2,['clear'],['clear']
Usability,"Hmmm....as an alternate proposal, what if we implemented a custom serializer for `SimpleInterval` that does the contig name -> index and index -> contig name conversion transparently at serialization/deserialization time? Would that address the performance issue with shuffles and allow us all to share the same interval class?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418509374:82,Simpl,SimpleInterval,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418509374,1,['Simpl'],['SimpleInterval']
Usability,"How much does count collection cost at the desired bin size? How does this compare to bincov? Perhaps we could eliminate one of these steps if redundant. Note that the read counts are read once and stored in memory, so unless this takes a significant amount of time, then indexing is probably not the highest priority here (although I agree it would be nice to have in general). One related issue, as you mention, is file localization---since each shard only operates on a portion of the counts in each sample, it is a bit wasteful to localize the whole file. But how much does file localization cost? I can't imagine that it is the lowest hanging fruit. One of the more important issues, which you also mention, is optimizing parameters for inference. This includes not only the minimum number of epochs for training, but also things like the learning rate, annealing schedule, iterations per epoch, conditions for epoch convergence, etc. I'll be talking about how to tune these inference parameters---as well as other things in the pipeline---at the next BSV meeting. Let's brainstorm more things to try and prioritize them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932:844,learn,learning,844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932,2,['learn'],['learning']
Usability,"However, the current algorithm and the k-dijkstra still would show the same problems in terms of doing a suboptimal selection of haplotypes in terms of their coverage of plausible variation. . I had implemented an alternative that fixed that issue... but I couldn't find the code ... perhaps just in my local machine (backups) need to find it. ; . In any case the idea is quite simple.... we simply simulate haplotypes based on those same furcation likelihoods and we stop when we have not discovered anything new for a while... the problem of such an approach is to make it deterministic. I guess we could fix a seed based on information on the current active region.... anyway,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212:378,simpl,simple,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212,4,['simpl'],"['simple', 'simply']"
Usability,"I _believe_ your issue is that you are assigning 600GB to execution of cromwell, but the error is with the call to **VariantRecalibrator** in one of the tasks not having enough memory. A few tasks call **VariantRecalibrator**, do you know which task failed? Can you post the java call from the STDERR file? For me, it was task **SNPsVariantRecalibrator** which was assigned only 3.5GB of memory by default. In [joint-discovery-gatk4.wdl](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.wdl), the memory assigned for each task can be set via ""machine_mem_gb"", but it looks like the current [input.json](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.hg38.wgs.inputs.json) does not have that variable, but instead ""mem_size"" for each task. . A simple solution would be to replace ${java_mem} with a static value in calls to **VariantRecalibrator** (lines 564 & 684). For example, replace:. `${gatk_path} --java-options ""-Xmx${java_mem}g -Xms${java_mem}g""`. with. `${gatk_path} --java-options ""-Xmx100g -Xms100g""`. I'm not certain this will help, but I think it's a step in the right direction.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381:837,simpl,simple,837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381,2,['simpl'],['simple']
Usability,"I added a simple patch to fix this undocumented behaviour (#1757). Nevertheless, I'm working in an abstraction to include multi-sample support instead of include all the reads without differentiation in the pileup.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514,2,"['simpl', 'undo']","['simple', 'undocumented']"
Usability,"I added integration tests for simple output and including features or verbose. While doing it, I realized that GATK 3.5 included some filters that wasn't included here, and that indels weren't tracked, so I changed also the code to fit the previous implementation. Back to you @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158:30,simpl,simple,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158,1,['simpl'],['simple']
Usability,"I added one unrelated bugfix. FuncotatorUtils.createReferenceSnippet tries to expand the reference window. When doing this, it should never allow a start less than 1. The last commit addresses that. . Note: I did not see an easy way for createReferenceSnippet() to identify the length of the contig (such as access to the SequenceDictionary), but it would in theory be useful to also check contig size and not exceed it. @droazen or @jonn-smith: it would be helpful if you could approve the test run. ```; 22 Jun 2023 14:54:27,152 DEBUG: 	java.lang.IllegalArgumentException: Invalid interval. Contig:MT start:0 end:20; 22 Jun 2023 14:54:27,154 DEBUG: 		at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); 22 Jun 2023 14:54:27,155 DEBUG: 		at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); 22 Jun 2023 14:54:27,156 DEBUG: 		at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); 22 Jun 2023 14:54:27,158 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1461); 22 Jun 2023 14:54:27,159 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createIgrFuncotation(GencodeFuncotationFactory.java:2481); 22 Jun 2023 14:54:27,160 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createIgrFuncotations(GencodeFuncotationFactory.java:2407); 22 Jun 2023 14:54:27,162 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.create",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:800,Simpl,SimpleInterval,800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,4,['Simpl'],['SimpleInterval']
Usability,"I added the split size option back, and wrote a test for `dirSize`. All feedback should have been addressed now. Back to @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-173633156:72,feedback,feedback,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-173633156,1,['feedback'],['feedback']
Usability,"I addressed partially your comments (and fixed a compilation error due to the tests using the previous arguments). One of the major points of discussion are the following:. * `Collection` instead of `List`: I think that the first is more flexible, because a client maybe wants to have a `LinkedHashSet` as the argument to avoid repetition of the same filter. I agree that the abstract class should discourage not honoring the user order.; * Access to methods/fields: I think that the plugin could be used outside GATK in a different way by extending it. I explained some of my usage cases in one of the comments in the code, but just by overriding a simple method the whole plugin could be used very nicely in some of them. I would prefer to do that than copy your code and re-implement the bits that I would like to change. Back to you for your ideas on this, @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208:650,simpl,simple,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208,2,['simpl'],['simple']
Usability,"I agree that it is better to keep it simpler. I was proposing this before looking the latest commits in the HC branch. I will work on this walker without thinking about other cases, but I would like to keep the idea of padding and slide over intervals instead of the genome from the begining. It will be useful for the things that I have in mind. Should I close this PR until I implement everything, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210833987:37,simpl,simpler,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210833987,1,['simpl'],['simpler']
Usability,"I agree with Joshua: there are several places where the billing project currently needs to be specified in the command line and such manual modifications are not very user-friendly. Another way to perhaps address this is to make sure that an input argument, which specifies the billing project, also addresses the issue throughout the script, so that the user does not need to make any additional changes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647584422:167,user-friendly,user-friendly,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647584422,2,['user-friendly'],['user-friendly']
Usability,"I already addressed the reviewer's feedback, so this should be assigned to @droazen or @lbergelson.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285121959:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285121959,2,['feedback'],['feedback']
Usability,"I also prefer the use of flags over special values, because of the case where the special value is accidentally triggered: maybe that value is obviously out of a reasonable range to us but not an unsophisticated user. I worry about complaints like ""I clearly set the value, but it didn't take effect."" At the least, there needs to be something like: `WARN: disabling trim feature due to parameter value -1`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71232186:251,clear,clearly,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71232186,1,['clear'],['clearly']
Usability,"I am looking into porting VariantEval to GATK4. In GATK3, this used RodWalker, which basically iterated all covered sites, driven by a ROD file. A VCF is typically a pretty sparse file, so you end up with large stretches of non-covered positions of the genome. In GATK3, RodWalker / AlignmentContext explicitly tracked getSkippedBases(), which seems designed to allow tools to track stretches of REF sites. VariantEval in GATK3 relied on AlignmentContext.getSkippedBases() to count the number of loci it processed, for example. In GATK4, VariantWalker simply iterates over the sites in the VCF. Am I missing an analog, and/or is there a design reason why GATK4 does not track something akin to GATK3's getSkippedBases()?. I dont fully know the implications for parallelization, but if VariantWalker tracked something like lastProcessedSite, then this would effectively provide the same information as GATK3's AlignmentContext.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4447:552,simpl,simply,552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4447,1,['simpl'],['simply']
Usability,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6990:261,clear,clear,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990,1,['clear'],['clear']
Usability,"I am starting a Maven Project in which I would like to import your library; so I added this [dependency](http://search.maven.org/#artifactdetails%7Corg.broadinstitute%7Cgatk%7C4.beta.2%7C) to my pom.xml; ```; <dependency>;     <groupId>org.broadinstitute</groupId>;     <artifactId>gatk</artifactId>;     <version>4.beta.2</version>; </dependency>; ```; When I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact com.github.fommil.netlib:all:jar:1.1.2 in ; all (https://mvnrepository.com/artifact/com.github.fommil.netlib/all) -> [Help 1]; ```; and it seems that the problem is the dependency by com.github.fommil.netlib/all, indeed according to the output of `mvn clear install`, it attempt to download all-1.1.2.jar:; `Downloading: https://repo.maven.apache.org/maven2/com/github/fommil/netlib/all/1.1.2/all-1.1.2.jar`; but this jar is not available in the repository. I noticed that even in other [projects](https://github.com/amplab/ml-matrix/issues/11) have the same issue. How is possible to resolve this issue? . Thanks for your time,; Nicholas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724:374,clear,clear,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724,2,['clear'],['clear']
Usability,"I am trying to use GATK source code to get read depth at a base, what should I do? . As far as I know, there is a simpleInterval class I can use to pass the genome region I want to inspect. But I don't know where should I pass the simpleInterval and get the read depth. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3881:114,simpl,simpleInterval,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3881,2,['simpl'],['simpleInterval']
Usability,"I am using GATK 4.4.0.0 via the official docker release to reheader output from SVABA with an appropriate sequence dictionary. I am using `UpdateVCFSequenceDictionary` for this purpose with the following command: . ```; singularity exec -B ""$PWD"" broadinstitute-gatk-4.4.0.0.img gatk UpdateVCFSequenceDictionary --source-dictionary Mus_musculus.GRCm39.dna.primary_assembly.dict -V svaba.somatic.indel.vcf --replace true -O svaba.somatic.indel.vcf.reheaded.vcf; ```. I have encountered a curious behavior, where by the tool is not simply adjusting the sequence dictionary, but is also modifying a FORMAT field. . Original VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=String,Description=""Genotype quality (currently not supported. Always 0)"">; ```. Updated VCF header: . ```; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ```. From what I can see, the updated text is used frequently in your GATK VCF files, but I can't dig out the specific code where it is being set via `UpdateVCFSequenceDictionary`. I am wondering if there is a collision where `UpdateVCFSequenceDictionary` detects GQ and prints a stock header field to match expectation, rather than leaving it alone. I would expect the tool to simply replace the dictionary portion of the VCF without modifying the FORMAT/INFO fields. This is causing issues with downstream analysis because SVABA QC values are float/string not integer.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8629:530,simpl,simply,530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8629,2,['simpl'],['simply']
Usability,"I am using GATK DepthOfCoverage tool for some of my samples.; I need to use genome reference GRCh37.; Everything is working fine but an error will occur whenever I run it (attached photos).; I have used all different type of references, including Ensembl, UCSC, NCBI, and GATK source itself but the same error is still there.; Also I know that I need to use a unique database and use that to create all fai, dict, bed file so that for sure the namings are the same in my all types of files. But I don't know how to create .bed file out of a reference genome (i.e. Homo_sapiens.GRCh37.dna.primary_assembly.fa); Would you please guide me what can I do about that?. . ![Screenshot from 2021-09-02 00-11-51](https://user-images.githubusercontent.com/87016284/131868327-660a9a9c-cc93-4c6e-a08c-0a67eddf2f47.png); ![Screenshot from 2021-09-02 00-12-00](https://user-images.githubusercontent.com/87016284/131868369-0a80d306-8a05-4a87-a566-02c3713561c4.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7453:627,guid,guide,627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7453,1,['guid'],['guide']
Usability,"I am very interested in this feature. In my current workflow I am using `freebayes` (and in an older version simply `pileup`) to query mutation sites (after doing the actual mutation calling using gATK4 M2) on a cohort level and would be very interested in a GATK naive approach. P.s. personally more interested in a multi-step mutation calling method than multi-sample calling, where one first calls mutation in multiple samples that are then joined together in a consensus callset, after which the consensus callset is queried individually across the entire cohort of patient resulting in genotype and allele frequencies for each variant across the entire cohort",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-430817379:109,simpl,simply,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-430817379,2,['simpl'],['simply']
Usability,"I am working on a test for #1572. I am not sure what a test for #3069 would look like, or if it is really necessary. We simply changed the way GKL outputs warnings and information. Any ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566:120,simpl,simply,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566,2,['simpl'],['simply']
Usability,"I asked about a status update on the travis image space issue in the travis ticket, and based on feedback I tried moving to the new image. It seems to work now. Fixes https://github.com/broadinstitute/gatk/issues/3559.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3622:97,feedback,feedback,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3622,1,['feedback'],['feedback']
Usability,"I calculated ASECount of genome resequence data by GATK-3.8 , but I want do the same test by GATK-4.0 , It's so strange when I use GATK-4.0 argument ""--variants"" to substitute ""sites"" of GATK-3.8 , the ERROR remaind me that the ""SNP site is not hetero"" , so l want to ask ; What is the mean of ASECountReader ""sites"" argument of GATK-3.8 ? and what is the corresponding argument in GATK-4.0 ? the answer is undocumented in instruction of ""GATK-3.8 --help"", so l want get exact answer, thank you !",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7712:407,undo,undocumented,407,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7712,1,['undo'],['undocumented']
Usability,I can confirm that the fix works for me: I now see a user-friendly error message. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762:53,user-friendly,user-friendly,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762,1,['user-friendly'],['user-friendly']
Usability,"I can do this but first, since it seems like a nice way to learn about the GATK engine, I'll open it up to @TedBrookings @MartonKN @takutosato @meganshand @sjfleming @madduran @dalessioluca.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5079#issuecomment-409967138:59,learn,learn,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5079#issuecomment-409967138,2,['learn'],['learn']
Usability,I can see the reassurance of knowing that the input Locatable is constant and with a non-null contig... yet as a result we are often creating redundant simpleIntervals instances when our objects of interest are some other type of Locatable.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3541:152,simpl,simpleIntervals,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541,1,['simpl'],['simpleIntervals']
Usability,"I can see why you'd change this; however, it breaks this particular legacy tool. VariantEval uses those labels to populate columns in the reports is creates. In GATK3, if there is no user-supplied label on in the argument, it will simply use the argument name, which ends up being either eval, comp or dbsnp. Those strings end up in most reports that are created. Switching these to the filepath doesnt strictly break function, but it's a lot less friendly to look at and doesnt add much value in most cases. Generally speaking, I agree there isnt much of a reason for a tool to reply on those user-supplied names as much of anything beyond a label. However, if this is essentially just a label, is there a situation where non-unique names is actually a problem? A tool probably shouldnt rely on this user-supplied value as a way to uniquely find an input. If this value if generally being used for things like populating user-facing values in a reports, having this extremely long filepath as the name isnt exactly user friendly. If a given tool accepts a list of FeatureInputs, it would seem like it's the responsibility of that developer to make sure that tools deals with the potential of overlapping labels appropriately. Perhaps a solution is to delegate some of this behavior back to the argument definition? A few thoughts/comments:. 1) Is there any reason name can't just be NULL (instead of file URI) if nothing was supplied, instead of filepath? . 2) Similar to 1, if FeatureInputs somehow tracked whether there was actually a user-supplied name or if name was NULL (defaulting to filename), then upstream code could potentially use this information to change behavior. 3) While this if more involved, perhaps ParsedArgument.of() could take another nullable ""defaultName"" argument, and if there is no user-supplied name in the argument value and if defaultName is non-null then it is used as the FeatureInput name instead of filepath? Then perhaps through either a flag in the tool, or bett",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387:231,simpl,simply,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387,2,['simpl'],['simply']
Usability,"I can't reproduce this yet. I tried downloading the jar, unzipping it, and running the example command you gave, but I can't reproduce what you're seeing. I modified it for my local files:; ```; java -jar gatk-package-4.2.5.0-local.jar \; GenotypeGVCFs \; -R /Users/louisb/Workspace/gatk/src/test/resources/large/Homo_sapiens_assembly19.fasta.gz \; --variant gendb:///Users/louisb/Workspace/gatk/output \; -O out.vcf \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 \; --max-alternate-alleles 6 \; --force-output-intervals 20 \; -L 20 \; --only-output-calls-starting-in-intervals \; --genomicsdb-shared-posixfs-optimizations; ```; It runs to completion on my machine. ; My md5sum matches yours so that's not the problem. It's not clear to me what's going on here. Are the previous releases working on your cluster still?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522:746,clear,clear,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522,2,['clear'],['clear']
Usability,"I could be onboard with `site`. It's not entirely intuitive, but it will get a header line, right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590338945:50,intuit,intuitive,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590338945,2,['intuit'],['intuitive']
Usability,"I created a panel of normals from 90 WGS TCGA samples with 250bp (~11.5M) bins, which took **~57 minutes** total and produced an **11GB PoN** (this file includes all of the input read counts---which take up 20GB as a combined TSV file and a whopping 63GB as individual TSV files---as well as the eigenvectors, filtering results, etc.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:580,simpl,simply,580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,2,['simpl'],['simply']
Usability,"I did a quick scalability ministudy - this seems to scale well up to 12 cores and then diminishes due to Amdahl's law I think that's fine. There is no diminished runtime due to OMP overhead when on 1 core. Note that our cluster on which I wan these was not empty (a few of the 48 cores were in use) and do this is just a ballpark estimate of scalability, in particular 24 was worse than 12 probably due to interference. Based on this I think OMP is a good idea and it's going to work on 1 CPU too. limited to 1 OMP thread, using 10GB of RAM. ```; real 2m15.621s; user 3m17.269s; Total compute time in PairHMM computeLogLikelihoods() : 50.964700625000006; ```. ---. limited to 1 OMP thread, using 32GB of RAM . ```; real 1m46.597s; user 3m17.363s; Total compute time in PairHMM computeLogLikelihoods() : 45.797104454; ```. limited to 2 OMP threads, using 32GB of RAM. ```; real 1m26.310s; user 3m24.636s; Total compute time in PairHMM computeLogLikelihoods() : 23.790980359000002; ```. limited to 4 OMP threads, using 32GB of RAM. ```; real 1m15.298s; user 3m29.834s; Total compute time in PairHMM computeLogLikelihoods() : 11.332445694; ```. limited to 6 OMP threads, using 32GB of RAM. ```; real 1m14.015s; user 3m20.876s; Total compute time in PairHMM computeLogLikelihoods() : 7.862075811; ```. limited to 12 OMP threads, using 32GB of RAM. ```; real 1m6.370s ; user 3m42.340s; Total compute time in PairHMM computeLogLikelihoods() : 4.585800097; ```. limited to 24 OMP threads, using 32GB of RAM (clearly, OMP hits the limit here). ```; real 1m8.779s; user 4m15.489s; Total compute time in PairHMM computeLogLikelihoods() : 3.047581173; ```. limited to 48 OMP threads, using 32GB of RAM (worse than 12 threads). ```; real 1m11.535s; user 6m26.100s; Total compute time in PairHMM computeLogLikelihoods() : 4.112299148; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1800#issuecomment-218810496:1501,clear,clearly,1501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1800#issuecomment-218810496,1,['clear'],['clearly']
Usability,"I did a simple experiment and changed the version of Java used in the non-Docker (""17"", although again I'm not sure what this actually resolves to) to that used in the Docker (17.0.1+12). This causes both non-Docker and Docker tests to now fail, rather than just the Docker tests; see https://github.com/broadinstitute/gatk/pull/8174#issuecomment-1402974502. Moreover, the test failures produce exactly the same discrepant numerical results. I think we can probably conclude that the expected test results were generated with ""17"" and that changing to 17.0.1+12 generates different results. This is not too unreasonable; see the Slack thread linked in https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680, for example, which shows that we might be getting into pretty hairy territory and that even changes to things like how HotSpot Intrinsics are implemented in each JVM can cause the numerical differences we see here. So perhaps we can either 1) change the Docker version to the version corresponding to ""17"" or 2) change the non-Docker version to 17.0.1+12 and update the expected results?. Not sure about the failing WDL test yet, but hopefully this is enough to get us started!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955:8,simpl,simple,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955,2,['simpl'],['simple']
Usability,"I did some more work on the broadcast approach to see how feasible it would be, and found that Spark Dataflow made two unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:641,simpl,simply,641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['simpl'],['simply']
Usability,"I did this and learned some things. However, it will be easier to evaluate the impact of GC correction with a standard evaluation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140:15,learn,learned,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140,2,['learn'],['learned']
Usability,"I didn't expect Hellbender to crash for this command:. `$ ./hb PrintReads -I CEUTrio.HiSeq.WGS.b37.NA12878.bam -O 4m.bam -L 20:1000000-4000000`; (...); [August 17, 2015 2:04:43 PM PDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=412090368; java.lang.IllegalArgumentException: end must be >= start. start:2801961 end:2801960; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$19(ReadWalker.java:64); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$50/1094674892.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:63); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:370); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/828:424,Simpl,SimpleInterval,424,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/828,6,['Simpl'],['SimpleInterval']
Usability,"I didn't read the description of this tool well enough, apparently you can simply add a `--PROGRAM null` to remove the default list. Closing the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690:75,simpl,simply,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690,2,['simpl'],['simply']
Usability,I don't believe @mwalker174 has incorporated feedback as of yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4026#issuecomment-355865508:45,feedback,feedback,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4026#issuecomment-355865508,2,['feedback'],['feedback']
Usability,I don't doubt that there could be issues caused by reads with previously filled caches. Ultimately this shouldn't have too significant an impact except in very pathological circumstances with highly repetitive regions or reads that hang beyond a certain length into the next region and happen to have had good looking indel sites without the cirgar actually containing any indels for that read. This should eliminate any of these circumstances entirely so we can be sure the cache is clear before every call. . Fixes #5908,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5911:484,clear,clear,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911,1,['clear'],['clear']
Usability,"I don't know how to accomplish that with gradle. Is just keeping the test jvm going all we need? Or does the ui shutdown after each test? We could add an infinitely running ""test"" in a special test group to If we want to be keep the test jvm open. Alternatively if we really need to be able to run tests and then view the UI afterwards we could put together something using https://github.com/hammerlab/spree. It's a minor pain to set up, I had weird ruby packaging problems getting meteor installed, but it solves the problem of ""how do we collect spark logs in a usable way"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676:565,usab,usable,565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676,1,['usab'],['usable']
Usability,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:56,simpl,simple,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631,2,['simpl'],['simple']
Usability,"I don't think that will work as the key needs to be `GATKRead` to take advantage of the `SAMRecordToGATKReadAdapterSerializer`. How about writing a new `Comparator<GATKRead>` that wraps a `SAMRecordCoordinateComparator`? That should be pretty simple and won't require a new serializer. BTW minor correction: `ReadSparkSink` operates on `JavaPairRDD<GATKRead, Void>` (not `JavaPairRDD<GATKRead, SAMRecordWritable>`) at the moment - the values are null so as to not duplicate the amount of data going through the shuffle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954:243,simpl,simple,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954,1,['simpl'],['simple']
Usability,"I don't think this branch satisfies https://github.com/broadinstitute/hellbender/issues/372 at all. There are still methods with 4+ undocumented parameters, and you eliminated what seemed a useful abstraction (`TruthSensitivityMetric`) in favor of passing around a raw array of doubles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/416#issuecomment-99142930:132,undo,undocumented,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/416#issuecomment-99142930,1,['undo'],['undocumented']
Usability,"I don't want to make any changes to phasing until the new assembly modifications are done, because I expect that will clear up a lot of lost sensitivity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987:118,clear,clear,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987,2,['clear'],['clear']
Usability,"I downloaded the GTF file for comprehensive gene annotation in CHR regions from Gencode. However, based on the errors I encountered earlier, I made some simple modifications to the GTF file in an attempt to identify the cause of the errors.; Here're the errors I encountered earlier and my codes to modify the GTF file.; ```; #error:; java.lang.IllegalArgumentException: Unexpected value: overlaps_pseudogene; #code:; grep -v '""overlaps_pseudogene""' gencode.v43.annotation.gtf >gencode.v43.annotation_nooverlaps_pseudogene.gtf; ```; ```; #error:; java.lang.IllegalArgumentException: Unexpected value: Ensembl_canonical; #code:; grep -v 'Ensembl_canonical' $newgtf_path>gencode.v43.annotation_nooverlaps_pseudogene_Ensembl_canonical.gtf; ```; ```; #error:; java.lang.NullPointerException: Cannot invoke ""org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature.getContig()"" because ""transcript"" is null; #code:; grep 'transcript' $newgtf_path>gencode.v43.annotation_transcript.gtf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613939137:153,simpl,simple,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613939137,2,['simpl'],['simple']
Usability,I figure: ; - Create a `SimpleAnnotatedGenomicRegionCollection`; - It will allow the sequence dictionary to be null. I need to be able to support random tsv files (that have locatable data).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352786819:24,Simpl,SimpleAnnotatedGenomicRegionCollection,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995#issuecomment-352786819,1,['Simpl'],['SimpleAnnotatedGenomicRegionCollection']
Usability,"I find the `--sparkRunner` arg to be a bit confusing:; - `DIRECT` uses the local walker impl, and doesn't run Spark at all, so it probably shouldn't be a ""sparkRunner"". I also initially thought this would use the Spark local runner.; - `SUBMIT` only makes sense to me because I use Spark, but also not as clear as could be. Also it seems a bit non-obvious that this is the option to pick if you want to run Spark with the local runner. I would propose; - `--runner LOCAL` or `--runner WALKER` (or `--runner DIRECT`, though I personally find this less clear) for the actual local impl that doesn't use Spark at all.; - `--runner SPARK` for anything that uses the `spark-submit` script, including running it in `local[*]` mode. This is the only option that should accept `--sparkMaster`, or maybe just `--master` to be more in line with `spark-submit`; - `--runner GCS` for Google; - `--runner AWS` for Amazon in the future. Thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1329:305,clear,clear,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1329,2,['clear'],['clear']
Usability,"I finished the implementation for the draft `SlidingWindowWalker` (I should implement an example and an integration test, but I would like to wait till some issues are solved). made a ""TODO"" about the way in which the intervals are constructed, because I will need a that `ReadShard` have a way to construct a shard without `ReadSource` (either null or empty source), just in case that the implemented `SlidingWindowWalker` does not require reads. @droazen, could you review and give me some feedback about this, because this class is important for other parts of GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163:492,feedback,feedback,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163,1,['feedback'],['feedback']
Usability,I fixed the artifact uploading as well now. Everything should be good provided tests are passing. It turned out to be something really simple and dumb.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-506503209:135,simpl,simple,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-506503209,2,['simpl'],['simple']
Usability,"I fully understand, and realize this isnt a priority for the group. Nonetheless, just getting the test data seems like it should be a simple thing if at all possible. i dont know the full reasoning behind why the GATK3 test data are not public, but I have no need to share it beyond myself if that makes this easier.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358031120:134,simpl,simple,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358031120,1,['simpl'],['simple']
Usability,"I get a consistent failure with BaseRecalibrator on a handful of samples. It occurs in both GATK 4 and GATK 3 (I checked the most current git repository of both). I also submitted this bug to the gatk forum before seeing that it affects GATK 4 and submitted this bug report.; [Forum link](https://gatkforums.broadinstitute.org/gatk/discussion/comment/44650). I've trimmed the command line down to the minimum necessary to generate the error, and I've trimmed the input files to the minimum section needed to generate the failure (a specific single read). You can find the failure below, but I also dug out the location of the failure with a proposed fix. ./gatk/src/main/java/org/broadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:851,simpl,simpleBaseToBaseIndex,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['simpl'],['simpleBaseToBaseIndex']
Usability,"I had a look at the source code of [HypergeometricDistribution](HypergeometricDistribution). If I am right, we are doing the following. We are invoking `logProbability()` for all possible `x[0][0]`. For a table with large numbers, we have to compute logBinomial for many iterations (see line 202–222 in the HypergeometricDistribution source code). Typically logBinomial calls three logGamma and each logGamma calls `log()` twice. This involves lots of computation and is not the fastest way to implement Fisher's exact test. A faster way to implement the test takes the advantage of two observations. 1) When carrying the test, we are calling hypergeo(i,m+n,m,k), hypergeo(i+1,m+n,m,k), ... in order, and we can derive hypergeo(i+1,m+n,m,k) from hypergeo(i,m+n,m,k) by simply multiplying a number. This will be much faster than doing the full hypergeo->logBionomial->logGamma->log computation for each `i`. 2) For a large table, often when `i` is sufficiently smaller or larger than `x[0][0]`, the hypergeo probability is small enough to be ignored from the sum. It is not necessary to calculate hypergeo for the full range of `lo<=i<hi`. This trick can also dramatically reduce the number of iterations for large tables. htslib has a [exact test implementation](https://github.com/samtools/htslib/blob/bf753361dab9b1640cf64f7886dbfe35357a43c5/kfunc.c#L201) that considers the two observations. I understand that the time spent on the `FisherExactTest` class probably won't show up at all in a profiler. I am not requesting to improve the implementation now. Just let you know the tricks. In addition, when we use this class for other purposes, a fast exact test may become a good thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212:769,simpl,simply,769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212,2,['simpl'],['simply']
Usability,"I had a look to the other branch, @droazen, and I think that it is more functional than this one:; - Check if the input already have a sequence dictionary, and only updates if `--replace` is provided. The version in this PR just overrides the dictionary.; - Check if all the variants agree with the new sequence dictionary, throwing an error if the contig is not present or the variant falls outside the chromosome range. This version does not account at all for that.; - It is a `VariantWalker`, and thus the code is simplest. But the pitfall of this is that if #2223 is implemented, that class will require a dictionary for the input as a `GATKTool`. I'm not sure how that is going to be done, but I guess that it will introduce problems in the class implemented by @cmnbroad. I think that the other version is more complete and I like it more because it is more concern about putative problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389:518,simpl,simplest,518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389,2,['simpl'],['simplest']
Usability,"I have a few lines of code that dynamically sets the log4j level for command line tools to match the existing VERBOSITY arg, It seems to work in simple testing so I don't think we need to downgrade to do it. Let me know if you want the code, or if you haven't started you can reassign this to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/243#issuecomment-115810391:145,simpl,simple,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243#issuecomment-115810391,1,['simpl'],['simple']
Usability,"I have a good feeling about numerical instability from this point forward because:. * My terminology was lazy. It's not really ""numerical instability,"" which is a deep and frightening topic, but rather just plain old finite precision, which is not nearly so hydra-headed a problem.; * I learned the general rule for avoiding finite precision problems with a qual score, which is: always calculate probabilities of alleles being absent. Previously I was calculating the probability that samples had an allele and subtracting (in log space) that from 1. The problem with that is that for very good GQs this probability is so closed to 1 that quals can become infinite. In this PR we add up the probabilities of genotypes that don't have the allele, which is small but non-zero and everything works fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-434769078:287,learn,learned,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-434769078,2,['learn'],['learned']
Usability,"I have been running into an issue with Funcotator where some mutations are causing Funcotator to crash because it attempts to query a segment that extends beyond the boundary of the transcript ( see https://github.com/broadinstitute/gatk/issues/6345 ). This pull request addresses the issue by adding a check for transcript length before executing the query. I looked at the code, and Funcotator currently handles problematic sequence queries in `getFivePrimeUtrSequenceFromTranscriptFasta()` by returning an empty string. I modified `getFivePrimeUtrSequenceFromTranscriptFasta()` to also return an empty string when the segment it is trying to retrieve extends beyond the boundary of the transcript. . I have a small VCF that can be used to reproduce the problem using the current code on `master` and the hg38 data source, and I have verified that this pull request allows Funcotator to process the problematic variant without crashing. I did not add the VCF to the tree, but can provide it if that is preferred. Is there any guidance for how to implement integration tests with funcotator? The Funcotator data source I am using is ~12gb, but I would think the problem could be reproduced with 1 transcript and 1 variant. This is my first pull request to GATK, so please let me know if there is anything you would like me to adjust, I'm happy to address any comments.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6546:1028,guid,guidance,1028,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6546,1,['guid'],['guidance']
Usability,"I have no objection to this PR. However, it might be simpler to modify the SV pipeline to optionally produce this data on the fly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327:53,simpl,simpler,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327,2,['simpl'],['simpler']
Usability,I have noticed after looking at the HaplotypeCaller command line in some recent forum posts (https://gatk.broadinstitute.org/hc/en-us/community/posts/7293912288795-Haploytpe-caller-shows-me-that-0-read-s-were-filtered-by-MappingQualityAvailableReadFilter-etc) that the output of the filtering summary can be confusing if a lot of reads were processed. It can be very useful to know that a lot of reads are lost to a particular filter as an important sanity check for processing but unfortunately that information can be very confusing and not helpful without some indication of the total number of reads that were processed to begin with. I propose that we add to the `CountingReadFilter` code additional logic to keep track of the unfiltered reads as well so we can report both numbers to the user and clear up potential confusion.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7944:803,clear,clear,803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7944,1,['clear'],['clear']
Usability,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6898:326,simpl,simple,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898,5,['simpl'],"['simple', 'simpleInterval']"
Usability,"I have noticed that running print reads with a stringent filter which I expect to only return a handful of reads results in the progress meter never printing any progress. This makes it look like the gatk has hung despite the fact it is chugging away and filtering every read it passes over. This should be updated to include an indication of how many reads have been filtered. Additionally, it should be improved to use a second thread to make periodic updates based on execution time in case the tool really has hung in order to make it clearer to the user what is going on.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4641:539,clear,clearer,539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4641,1,['clear'],['clearer']
Usability,I have tested that this explicitly works on the users data. I decided it was simplest to just check for mis-trimming at the very last stage. I'm a little weary about the change of the locus for the ref context from being the culledVC to being the mergedVC. . Fixes #5994,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6044:77,simpl,simplest,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6044,1,['simpl'],['simplest']
Usability,"I have the following instruction in a handson tutorial:. > If you haven't already done so, create a symlink to the gatk-launch script. Navigate back to /gatk and test the symlink by listing the tools available.; ```; cd /usr/local/bin; ln -s /gatk/gatk-launch gatk-launch; cd /gatk; gatk-launch –-list; ```. @vdauwera says:; > wouldn't it be simpler to export to path?. My reply:; > Environmental variables persist ephemerally. I haven't tested persistence when containers are stopped and restarted. @vdauwera requests:; > hmm, could also add to path in the bash profile... we should ask the devs if it's possible to set that up in the docker itself, for next time. Could we have both an environmental variable and a symlink that invokes the launch script in the Docker from any location? Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3899:342,simpl,simpler,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899,1,['simpl'],['simpler']
Usability,"I have to deal with this component recently and I found the design rather awkward.... In general between GATK and htsjdk we don't seem to have a proper support for managing and querying Supplementary alignment information from read alignment records:. 1. Querying: implemented in htsjdk consists in forging artificial SAMRecords that contain only the alignment info in the SA tag element... It seems to me that it makes more sense to create class to hold this information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder already has defined a private inner class with that in mind ""SARead"" so why not flesh it out and make it public. 2. Writing: currently SATagBuilder gets attached to a read, parsing its current SA attribute content into SARead instances. It provides the possibility adding additional SAM record one by one or clearing the list. ... then it actually updates the SA attribute on the original read when a method (setTag) is explicitly called.; I don't see the need to attach the SATag Builder to a read... it could perfectly be free standing; the same builder could be re-apply to several reads for that matter and I don't see any gain in hiding the read SA tag setting process,... even if typically this builder output would go to the ""SA"" tag, perhaps at some point we would like to also write SA coordinate list somewhere else, some other tag name or perhaps an error message... why impose this single purpose limitation?; I suggest to drop the notion of a builder for a more general custom ReadAlignmentInfo (or whatever name) list. Such list could be making reference to a dictionary to validate its elements, prevent duplicates, keep the primary SA in the first position... etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3324:842,clear,clearing,842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324,1,['clear'],['clearing']
Usability,"I have to say, too bad we don't have a mechanism in place that allows for the full reference, e.g. NIO only the contigs or portions thereof that are needed for a particular analysis @droazen @cmnbroad. That would make making test data so much easier. I would imagine this is simple to implement, given the reference is indexed. Such a feature would be useful for cloud analyses. I have to jump through ridiculous hoops to make small test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560:275,simpl,simple,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560,2,['simpl'],['simple']
Usability,"I haven't understood how multi-allele model exactly works in the old GATK, so can't comment on why it does not perform well. In general, I am supportive of making the new model the default going forward. However:. > when we remove the other models. I would suggest retaining the old model if possible. As I said on the method meeting, the old model takes the full power of population information (by full, I mean under the Wright-Fisher and HWE assumptions, you can't derive a more powerful model in theory). My understanding is that David's current model isn't. This is fine as long as the information from sequence data overwhelms the population information, which is usually true for highCov data. However, when data is thin, the population information will play a more important role. Without thorough evaluations in multiple scenarios, it is not clear when the loss of population information in the new model starts to matter. It would be good to keep the old model as a reference point, at least for biallelic SNPs, until we have more comparison.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127:851,clear,clear,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127,2,['clear'],['clear']
Usability,"I havent published to github yet, pending getting these core changes in; however, the purpose is pretty simple: allow VariantEval to inherit from MultiVariantWalker, but not require it to include the required argument -V. this seemed comparable to VariantWalkerBase (no arguments), and VariantWalker (specifies -V). GATK3's VariantEval uses the --eval argument and I generally tried to keep everything in this port in sync with GATK3, within reason. If there is another way to subclasses to negate some @argument defined by a superclass this would work too. If you want to see more I'll push to github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776:104,simpl,simple,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776,2,['simpl'],['simple']
Usability,"I implemented a very simple test for tracking Ns. Is it enough, @akiezun?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220032813:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220032813,1,['simpl'],['simple']
Usability,"I just learned that KEBAB case is different from SNAKE case @cmnbroad. Sorry if KEBAB is offensive @cmnbroad but it is meant to clarify syntax (e.g. https://lodash.com/docs#kebabCase). To be clear, Geraldine wants KEBAB case that uses hyphens, and not SNAKE case, which uses underscores. . - So `--emitRefConfidence` would become `--emit-ref-confidence`. ; - So `--contamination_fraction_to_filter` would become `--contamination-fraction-to-filter`. @vruano will describe how he uses constants to manage parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346172549:7,learn,learned,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346172549,4,"['clear', 'learn']","['clear', 'learned']"
Usability,I learned that gatk HaplotypeCaller does not phase multiallic sites anyways and thus will not continue with the development of this PR but it looks like it works so I will leave it here in case anyone needs it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1787023462:2,learn,learned,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1787023462,2,['learn'],['learned']
Usability,"I like the first idea the most, not adding it for a concrete sample. The point of the methods that I described is added the likelihood for a single sample, and default likelihood to the others. Probably will be better defined as following: `add(String sample, GATKRead read, Allele allele, double likelihood, double defaultLikelihood)`. Do you think that you can implement the `Visitor` before removing the `PerReadAlleleLikelihoodMap`? Thanks a lot for all the feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-250233112:462,feedback,feedback,462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-250233112,2,['feedback'],['feedback']
Usability,"I like the idea of the modified regexes, that seems like the best balance of usability and flexibility/power. I'd rather avoid having a slew of new special-cased arguments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640:77,usab,usability,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640,1,['usab'],['usability']
Usability,I made you a page to start collecting such reminders at https://github.com/broadinstitute/gatk/wiki/Checks-and-tests-guidelines.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468819341:117,guid,guidelines,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468819341,2,['guid'],['guidelines']
Usability,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6860:505,feedback,feedback,505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860,1,['feedback'],['feedback']
Usability,"I need this for my own work, and it is a very simple change that does not affect the default behaviour. @droazen can you review?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-222350655:46,simpl,simple,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-222350655,1,['simpl'],['simple']
Usability,I patched this in joptSimple in https://github.com/pholser/jopt-simple/pull/89. This can be enabled by upgrading to the 5.0.1-beta build or waiting for a stable release. Unclear on the time lines for stable release. I suspect if we really need it we can ask for a 4.10 release and the maintainer would likely be willing to create one.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249:64,simpl,simple,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249,1,['simpl'],['simple']
Usability,"I prefer the classic GATK paradigm, in which by default every boolean is false, until you pass the flag to set it to true. This allows you to be able to just add the flag to the CL without specifying a value. From user POV this provides valuable consistency. It seems a lot more intuitive as well. It's like you're asking ""do you see a flag?"" and in the answer, no means no, and yes means yes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-70925401:279,intuit,intuitive,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-70925401,1,['intuit'],['intuitive']
Usability,"I prefer to host the docs in the forum for the following reasons:; - We want people to use the GATK website and forum as a one-stop shop for all GATK needs, not have to go to Github for some things, both for convenience and as a matter of branding;; - Many end-users don't know/understand Github;; - In the forum we can easily host multiple documents in a way that's intuitive to navigate;; - We can easily render the docs as webpages within the GATK website, which many end-users prefer;; - Forum docs are easy for my team to update or tweak at a moment's notice;; - Users can comment directly on the documents, or create new discussion threads, and it's easier for us to answer them if all is in the same place. ; - If we need to open a github issue ticket (for bug report, feature request etc) we can do it directly from the forum discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594:367,intuit,intuitive,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594,1,['intuit'],['intuitive']
Usability,"I prefer to keep this one open, it will be simpler to rebase and include the changes. Should the `common = true` changes being included in the other or here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278340959:43,simpl,simpler,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278340959,2,['simpl'],['simpler']
Usability,"I propose to still hide from the command line and docs the example walkers. They are meant only for developers, to show how to use some kind of walkers and have a running tool for integration tests. Having then in the command line will generate software users to run them instead of use them for developmental purposes... In addition, I think that this is a good moment to also generate a sub-module structure (as I suggested in #3838) to separate artifact for different pipelines/framework bits (e.g., engine, Spark-engine, experimental, example-code, CNV pipeline, general-tools, etc.). For the aim of this issue, this will be useful for setting documentation guidelines in each of the sub-modules: e.g., example-code should be documented for developers, but not for the final user; experimental module should have the `@Experimental` barclay annotation in every `@DocumentedFeature`; etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829:662,guid,guidelines,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829,2,['guid'],['guidelines']
Usability,"I rebased on master and addressed the feedback. I've added comments (prefixed with ""Hellbender"") in the htsjdk code to make it very clear where the changes are. I'll look at the changes needed in htsjdk next to address #831.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/827#issuecomment-132560424:38,feedback,feedback,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827#issuecomment-132560424,2,"['clear', 'feedback']","['clear', 'feedback']"
Usability,I released a snapshot. A signed artifact will follow (1.0.0). Feel free to send me feedbacks BEFORE.; https://oss.sonatype.org/content/repositories/snapshots/com/github/jsr203hadoop/jsr203hadoop/0.0.1-SNAPSHOT/. Final artifact will follow these names:. ``` xml; <groupId>com.github.jsr203hadoop</groupId>; <artifactId>jsr203hadoop</artifactId>; <version>0.0.1-SNAPSHOT</version>; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912:83,feedback,feedbacks,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912,1,['feedback'],['feedbacks']
Usability,"I see `Timeout (30 minutes) reached. Terminating ""./gradlew jacocoTestReport""`. It's not clear to me how my changes could have introduced a deadlock or similar problem. . I ran the full test suite (`./gradlew test`) locally to take a look and it passes. Took 20min. Running `SeekableByteChannelPrefetcherTest` by itself also passes, unsurprisingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-277399501:89,clear,clear,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-277399501,2,['clear'],['clear']
Usability,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:275,Simpl,SimpleInterval,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095,6,['Simpl'],['SimpleInterval']
Usability,"I see. . Yes. That's what I'm planning on (except that `AssemblyContigAlignmentsConfigPicker` is upstream of this unit), and here's the thought for why:; * I'd try to place the alignment picking step in a single place as much as possible, this makes improvements to the alignment picking/filtering step easier; * the size-based filter can be tuned, even by an CLI argument, this would affect the number of segments in the CPX logic, and the alt_arrangment annotations, and the simple variants re-interpreted by `CpxVariantReInterpreterSpark`, but it won't affect the alt haplotype sequence, which IMO is what really is important. ; * I'm developing a downstream variant filter, which hopefully can cut down the false-positives. And for the question of ""why 2 instead of 1"", I think what you are suggesting is to change; ```java; public static final int MIN_READ_SPAN_AFTER_DEOVERLAP = 2;; if (one.getSizeOnRead() >= MIN_READ_SPAN_AFTER_DEOVERLAP) result.add(one);; ```; to; ```java; public static final int MIN_READ_SPAN_AFTER_DEOVERLAP = 1;; if (one.getSizeOnRead() > MIN_READ_SPAN_AFTER_DEOVERLAP) result.add(one);; ```; Am i right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405619353:477,simpl,simple,477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405619353,2,['simpl'],['simple']
Usability,"I simply mean migrate to hellbender. On Thu, Dec 11, 2014 at 9:40 AM, rpoplin notifications@github.com wrote:. > What does as a command line program mean?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/18#issuecomment-66627537; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/18#issuecomment-66629944:2,simpl,simply,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/18#issuecomment-66629944,1,['simpl'],['simply']
Usability,"I started investigating how to do this, here are a few notes:; * The change in Picard's MD added a histogram for counts of (all) duplicates, optical duplicates, and non-optical duplicates.; * The histogram is serialized to text in the metrics file. (I believe there was no histogram before this change.); * The duplicates are found by sorting the file and breaking reads into chunks, where each chunk contains reads that are duplicates. (See `MarkDuplicates#generateDuplicateIndexes`). It's not clear to me where the equivalent code would live in the GATK Spark implementation. It looks like `MarkDuplicatesSparkUtils#markDuplicateRecords` is where the duplicate counts can be obtained, but I'm not sure if the code that uses this method (`MarkDuplicatesSpark#mark`) can piece together the counts for the histogram. Even if it could, the return type of `MarkDuplicatesSpark#mark` is `JavaRDD<GATKRead>`, which would need altering to incorporate the extra three int fields for the counts. Thoughts @jamesemery?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-539036697:495,clear,clear,495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-539036697,2,['clear'],['clear']
Usability,"I suggest we start with just the toggle, since we have an immediate need for that. Finer-grained control can be addressed as part of the more general customization/delegation mechanism we've started in other PRs, and so clearly need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214:220,clear,clearly,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214,2,['clear'],['clearly']
Usability,"I talked to comms and we agreed that a ""mitochondria-mode"" argument to Mutect2 was the right balance of clarity (you're really running Mutect2 not a wrapper) and simplicity (you don't need a laundry list of arguments to change which mode you're in if you just want to run with optimized defaults). . @ldgauthier @davidbenjamin @takutosato @rcmajovski Could you please take another look? Removing the wrapper tools has cleaned up the code so there are fewer changes now. I also changed TLOD to LOD in this version, but I'm happy to take that out and have that be future work if anyone is worried about it being a breaking change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077:162,simpl,simplicity,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077,2,['simpl'],['simplicity']
Usability,"I think I see what's going on. Since the force calling allele is so huge (a deletion from 36957826 to 36958130) the GATK engine does not create an AssemblyRegion that spans it. Rather, it creates a big region from 36957826 to 36958125 and a tiny one from 36958125 to 36958130. This is silly and worth fixing but the bug hasn't occurred yet. The GATK goes through both assembly regions, the big one and the small one, and _the force calling allele is genotyped in both_. This happens because in `HaplotyeCallerEngine`, line 607, the call to `features.getValues(hcArgs.alleles)` grabs all overlapping variants in the force calling VCF, thus leading to its appearance in both assembly regions. I think the fix might be as simple as counting only force calling alleles that _begin_ in an assembly region. A different solution might be to guarantee upstream that force calling alleles fit completely in a single assembly region, perhaps skipping them with a warning if they are too big for the GATK to handle. @droazen I can get my hands dirty and probably fix this reasonably quickly at this point, but could you weigh in on the two possible solutions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106#issuecomment-1405466500:719,simpl,simple,719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106#issuecomment-1405466500,2,['simpl'],['simple']
Usability,I think I'm inclined towards just the simple toggle.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383,2,['simpl'],['simple']
Usability,"I think even more important is that they share the reference genome that they are using. Get Outlook for Android<https://aka.ms/AAb9ysg>; ________________________________; From: Gökalp Çelik ***@***.***>; Sent: Wednesday, April 24, 2024 12:28:39 AM; To: broadinstitute/gatk ***@***.***>; Cc: Ilya Soifer ***@***.***>; Assign ***@***.***>; Subject: Re: [broadinstitute/gatk] Prevent users enabling annotations with mismatching data type (flow etc) (Issue #8788). Assigned #8788<https://github.com/broadinstitute/gatk/issues/8788> to @ilyasoifer<https://github.com/ilyasoifer>. —; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/8788#event-12581899218>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGDPRCP66IKPOBF2GPENP6LY63HAPAVCNFSM6AAAAABGTGMBPWVHI2DSMVQWIX3LMV45UABCJFZXG5LFIV3GK3TUJZXXI2LGNFRWC5DJN5XDWMJSGU4DCOBZHEZDCOA>.; You are receiving this because you were assigned.Message ID: ***@***.***>. ________________________________. CONFIDENTIALITY NOTICE: This message (including any attachments) should be presumed to contain confidential, proprietary, privileged and/or private information. Information contained in this message is intended only for the recipient(s) named above. Any disclosure, reproduction, distribution or other use of this message or any attachments by any unauthorized individual or entity is strictly prohibited. If you have received this message in error, please notify the sender immediately, and delete the message and any attachments. Learn more about Ultima Genomics’ Privacy Policy<https://www.ultimagenomics.com/privacy-policy>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625:1535,Learn,Learn,1535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625,1,['Learn'],['Learn']
Usability,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:106,simpl,simply,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141,2,['simpl'],['simply']
Usability,I think it's simply that HDF5Library uses `org.apache.log4j.LogManager` rather than `org.apache.logging.log4j.LogManager`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340867902:13,simpl,simply,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340867902,2,['simpl'],['simply']
Usability,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:903,usab,usable,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605,2,['usab'],['usable']
Usability,"I think that it is necessary to have a way for downstream projects to override some of the top-level arguments in the base CLP class. For example, the config file is for documentation purposes, but I don't want to expose users to that argument because I will set the defaults programmatically. Another example is the GCS retries, which might not be useful for a software that is not planning to support GCS even if it is already implemented (or does not want to expose). As a downstream developer, for me it is important to being able to configure arguments and expose/hide them to my final users; with the current implementation, my main issue is to have an argument that are irrelevant for the toolkit user and that I get questions about why and how to use them (the most clear example, the config file). If the main problem is to change an interface, a default value for new methods can be added to keep the same behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183:774,clear,clear,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183,2,['clear'],['clear']
Usability,"I think that the full version of the binned read-count collection that @asmirnov239 is working on could be easily modified to give you what you want. Let's keep this tool as simple as possible for now. However, something that would be much easier to change in this code (and might have a bigger effect) would be adding counts to all bins that overlap each fragment. It would be interesting to see how this changes the statistics of the counts. If we have some bandwidth, we can try experimenting with this before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868:174,simpl,simple,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868,2,['simpl'],['simple']
Usability,I think that the name `Transformer` makes it pretty clear that it mutates its input. Returning a brand new read upon each transformation would introduce non-trivial overhead for no good reason (unless we're going to make reads immutable across the board).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82511749:52,clear,clear,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82511749,1,['clear'],['clear']
Usability,"I think that this does not require a line reader. It could be done by simply use `Files.lines(path).iterator()` for the `Path`. Maybe it could be included directly in the utils class (e.g., `Utils.lineIterator(Path)`).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3756#issuecomment-340714843:70,simpl,simply,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3756#issuecomment-340714843,2,['simpl'],['simply']
Usability,"I think the general format `gatk-launch Tool toolArgs -- sparkArgs` is pretty clear. Would this be solved by just making the terminology consistent (eg., change `Tool` to `GATKTool` etc.)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1286#issuecomment-163307090:78,clear,clear,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1286#issuecomment-163307090,1,['clear'],['clear']
Usability,"I think the upgrade to samtools was a consequence of changing the base image from Ubuntu 16.04 -> 18.04 in #5026, since samtools is simply installed using apt-get. If we want to be more specific about which versions of samtools, bedtools, tabix, etc. are included in the Docker images, we may want to build these accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760:132,simpl,simply,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760,2,['simpl'],['simply']
Usability,"I think this makes gatk less user-friendly and is in contrast with; Cromwell's behavior, which does use the current billing project by default. On Mon, Jun 22, 2020 at 10:58 AM droazen <notifications@github.com> wrote:. > Closed #6669 <https://github.com/broadinstitute/gatk/issues/6669>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6669#event-3468784130>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABH6TH6RUMGKVXEMGQUBVGLRX5WPVANCNFSM4OETXLIQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647573660:29,user-friendly,user-friendly,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647573660,2,['user-friendly'],['user-friendly']
Usability,I think this should be contained in the WDL style guide.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2923#issuecomment-459396390:50,guid,guide,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2923#issuecomment-459396390,2,['guid'],['guide']
Usability,I think this will be difficult and we don't have a python unit testing framework. Let's try for some simple tests in #4375.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819:101,simpl,simple,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819,2,['simpl'],['simple']
Usability,"I think we can generally enable this by pushing the option up to VariantWalker / GATKTool and integrating it with the createVCFWriter method. . It can optionally return a writer wrapped in a decorator that only outputs sites within the given intervals. We might want to rename the option in that case to something like ""only-output-variants-starting-in-intervals"" so it's clear that it only effects variant outputs. Or make it work with generated bamWriters too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260:372,clear,clear,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260,2,['clear'],['clear']
Usability,"I think we have a good idea of what side inputs are for and when we would need them now. . My understanding is that side inputs are appropriate to use when you have a fixed object or set of objects which must be provided as a whole to a task or tasks in a pipeline. If these things can be known at pipeline creation and are inexpensive to generate, it's possible to simply pass the objects as parameters in the pipeline creation. However, if the object is generated as part of the pipeline, then it must be passed as a side input instead. . @wbrockman Is my understanding correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043:366,simpl,simply,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043,1,['simpl'],['simply']
Usability,I think we've satisfied this one for alpha purposes with our recent README changes. We can write a more in-depth guide for beta.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/964#issuecomment-164045940:113,guid,guide,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/964#issuecomment-164045940,1,['guid'],['guide']
Usability,"I think without a matched normal, there is not much you can do for high purity samples in LOH regions. Flipping the binomial test to filter against the null hypothesis of hom (rather than a null of f = 0.5, as in GetHetCoverage) seems to work well otherwise. Expanding the allele-fraction model to include hom sites is an option, but then you would be guided by the prior. Closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2856#issuecomment-335586260:352,guid,guided,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2856#issuecomment-335586260,2,['guid'],['guided']
Usability,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:185,clear,clear,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516,2,['clear'],['clear']
Usability,"I tried clearing my caches and rebuilding, but I resolve everything. I noticed that our artifactory website looks much different today than it did yesterday. I wonder if it was down temporarily for an update. Maybe try again now? Unless they put it behind the firewall which would be a disaster... can you access https://artifactory.broadinstitute.org/?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641:8,clear,clearing,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641,2,['clear'],['clearing']
Usability,"I tried to do it, and I'm afraid that it won't be trivial as I expected: because it is a facade, there is not accesibility to `Logger.setLogLevel()` and this is required to set the verbosity level in the command line. After explore a bit the code, it seems that [`LoggingUtils`](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java) is the only place where a concrete implementation should be used. My suggestion is to move this class to a package that could be excluded by the backend user (because it contains methods to change the logging of log4j, I suggest `org.apache.logging.log4j`), which implements a simple interface/abstract class `org.broadinstitute.hellbender.utils.LoggingUtils` to set the log level (LoggingUtils.setLoggingLevel(final Log.LogLevel verbosity)`. The default implementation (that could be used by final users callid`super.setLoggingLevel(final Log.LogLevel verbosity)`) could setup the htsjdk and the java.util.logger.Logger. This implementation requires to change the `CommandLineProgram` to have a setter for the `LoggingUtils` to use, that could be set in `Main` (as in my PR for improve the extensibility of this class). The only pronblem is that it requires to be initialize with a simple implementation class of `LoggingUtils`, which should use the default. I think that this design does not break the behaviour of GATK, but introduce more complexity in the code. If you think that this is worthy, I could implement it today. @lbergelson, I'm not able to run Spark tools in a cluster yet, neither in gcloud dataproc, sorry. I'll wait for your answers on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062:676,simpl,simple,676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062,4,['simpl'],['simple']
Usability,"I tried to run it locally with inputs in GCS and the program crashed with a; null pointer exception. The same command worked fine when running on the; cluster. I'm happy to learn that copying the inputs locally is a workaround. I'll start on the rebasing journey. I'll post a note once I'm done so; someone can do the code review. On Tue, Oct 13, 2015 at 6:19 AM, Tom White notifications@github.com wrote:. > @jean-philippe-martin https://github.com/jean-philippe-martin, that's; > accurate.; > ; > BTW ReadsSparkSink should work fine locally (it can write local files, see; > ReadsSparkSinkUnitTest). What was the problem that you hit?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/pull/987#issuecomment-147711651.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987#issuecomment-147777938:173,learn,learn,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987#issuecomment-147777938,1,['learn'],['learn']
Usability,"I updated from 4.0.4.0 to 4.0.6.0 and noticed either a memory bug or spike in GenotypeGVCF. . Based on https://github.com/EvanTheB/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.simple.wdl:. ```; ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenomicsDBImport \; --genomicsdb-workspace-path ""$genomicsdb"" \; --batch-size ""50"" \; -L ""chr18:1-80373285"" \; --sample-name-map ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/-321562876/sample_map"" \; --reader-threads 5 \; -ip 500. tmp_vcf=""$TMPDIR""/tmp.vcf.gz. ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; GenotypeGVCFs \; -R ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.fasta"" \; -O ""$tmp_vcf"" \; -D ""/share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e64f393e-2ac6-43e6-9b20-cbfa905e7c33/call-GenotypeGVCFs/shard-17/inputs/1017648146/Homo_sapiens_assembly38.dbsnp138.vcf"" \; -G StandardAnnotation \; --only-output-calls-starting-in-intervals \; --use-new-qual-calculator \; -V gendb://""$genomicsdb"" \; -L ""chr18:1-80373285"". ""/share/ClusterShare/software/contrib/evaben/gatk/prebuilt/4.0.4.0/bin/gatk"" --java-options ""-Xmx8g -Xms8g"" \; VariantFiltration \; --filter-expression ""ExcessHet > 54.69"" \; --filter-name ExcessHet \; -O ""output.vcf.gz"" \; -V ""$tmp_vcf""; ```. And a SGE hard memory limit of 40G (GenotypeGVCFs has -Xmx8g).; On gatk 4.0.4.0 I see peak memory usage of 15.7G, while with gatk 4.0.6.0 I get:. ```; ...; 19:06:23.757 INFO GenotypeGVCFs - Initializing engine; 19:06:24.785 INFO FeatureManager - Using codec VCFCodec to read file file:///share/ScratchGeneral/evaben/cromwell/cromwell-executions/JointGenotyping/e9bf8c5e-3e70-476a-9",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024:192,simpl,simple,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024,1,['simpl'],['simple']
Usability,"I utilized Mutect2 during clinical tumor testing, and the example I provided earlier clearly represents a false positive site. Regrettably, Mutect2 failed to accurately identify it, thereby leading to the inclusion of such false positive sites in clinical medical reports. This outcome is entirely unacceptable. If it is inappropriate to categorize these false positives as STRs, are there alternative methods available for determining these erroneous sites?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613985690:85,clear,clearly,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613985690,2,['clear'],['clearly']
Usability,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7042:556,guid,guide,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042,1,['guid'],['guide']
Usability,"I was developing a `LocusWalker` (#1707) when I found that if several BAM files are provided, the `LocusIteratorByState` (LIBS) returns only a `AlignmentContext` with associated `ReadPileup` with only one sample. I realized that in the LIBS there is a commented exception thrown about that multi-sample is not supported. Because it is commented, the LIBS is providing an `AlignmentContext` for the next sample if the first of them does not have coverage. This is misleading for an API user (it took me some time to understand where the error comes from). I was thinking to do a pull request (or include this in #1707) to solve the issue. There are two ways of doing this:; - As in GATK3, implement an internal `PerSampleReadPileup` that extends the `ReadPileup` and provides an efficient way of separate sample-specific pileups.; - If there is no plan to support multi-sample pileups (I'm worried about this, because I will need it), construct the `AlignmentContext` in the LIBS from all samples. Then, the method `makeFilteredPileup` could be used to extract (in a complicated way) a per-sample pileup by the user side. Because the current implementation was done by @akiezun, could you please give me some feedback? I will need it for my stuff, and I will be very grateful if I can solve this as soon as possible...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752:1208,feedback,feedback,1208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752,1,['feedback'],['feedback']
Usability,"I was hoping that by hardcoding the standard set of covariates, we'd end up with something a bit cleaner -- but it looks like there is still a fair bit of ugliness here (eg., the persistence of things like `getOptionalCovariatesStartIndex()`). Do you feel that we've gained enough in code reduction / simplicity to justify the loss of flexibility?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78085268:301,simpl,simplicity,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78085268,1,['simpl'],['simplicity']
Usability,"I was investigating an issue where the depth is reported lower than expected at a given site. The default value of `--minimum-mapping-quality` is `20`, so I tried `1`, `20,` and `60`. Both values `1` and `60` give _higher_ depth (`INFO.DP`) than `20`, which is very counter-intuitive. The read pairs are overlapping, so I tried the `--do-not-correct-overlapping-quality` option, which caused this bias to go away. I'd still don't understand why increasing and decreasing the minimum mapping quality makes a difference, but it is likely to do with overlapping read pairs. ```bash; $ gatk HaplotypeCaller \; -I in.bam \; -L chr7:145945238-145945238 \; -stand-call-conf 0 \; --disable-optimizations \; --force-active -O out.vcf \; --reference /path/to/ucsc.hg19.fasta \; --minimum-mapping-quality <value>;; $ gatk --version; ...; The Genome Analysis Toolkit (GATK) v4.2.0.0; HTSJDK Version: 2.24.0; Picard Version: 2.25.0; ```. (I tried this `4.1.4.0`). `--minimum-mapping-quality 1`:; ```bash; chr7	145945238	.	A	G	7534.06	.	AC=2;AF=1.00;AN=2;DP=247;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=58.06;QD=31.52;SOR=1.050	GT:AD:DP:GQ:PL	1/1:0,239:239:99:7548,716,0; ```. `--minimum-mapping-quality 20`:; ```bash; chr7	145945238	.	A	G	267.64	.	AC=1;AF=0.500;AN=2;BaseQRankSum=2.838;DP=14;ExcessHet=3.0103;FS=6.264;MLEAC=1;MLEAF=0.500;MQ=59.06;MQRankSum=0.000;QD=22.30;ReadPosRankSum=2.208;SOR=2.022	GT:AD:DP:GQ:PL	0/1:3,9:12:28:275,0,28; ```. `--minimum-mapping-quality 60`:; ```bash; chr7	145945238	.	A	G	7150.06	.	AC=2;AF=1.00;AN=2;DP=224;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=32.06;SOR=1.008	GT:AD:DP:GQ:PL	1/1:0,223:223:99:7164,668,0. ```. <details>; <summary>test.bam</summary>. ```; @HD	VN:1.6	SO:coordinate; @SQ	SN:chr1	LN:249250621; @SQ	SN:chr2	LN:243199373; @SQ	SN:chr3	LN:198022430; @SQ	SN:chr4	LN:191154276; @SQ	SN:chr5	LN:180915260; @SQ	SN:chr6	LN:171115067; @SQ	SN:chr7	LN:159138663; @SQ	SN:chr8	LN:146364022; @SQ	SN:chr9	LN:141213431; @SQ	SN:chr10	LN:135534747; @SQ	SN:c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7124:274,intuit,intuitive,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7124,1,['intuit'],['intuitive']
Usability,"I was mistaken about this not being faster - I was using a counting function that Spark can optimise by pulling onto the map side so that the records don't go through the shuffle. I changed this to simply dump the processed reads so they have to go through the shuffle, and I got the following timings when processing a 121GB BAM file.; - With shuffle: 27 min; - No shuffle (two scans over input): 24.7 min (8% saving); - No shuffle (one scan over input): 17 min (37% saving). The version that does two scans is faster, but not hugely so. Removing a scan is possible, but requires the use of a sequence dictionary to find the end points of contigs. I've done this in the latest version of my branch (https://github.com/broadinstitute/gatk/compare/tw_overlap_partitioner), but there are more edge cases to test. Before I do this, however, it would be worth trying this approach with the Haplotype Caller to see if it works, and if it is appreciably faster. If the number of reads is filtered significantly so only a fraction go through the shuffle, then the performance gains will be smaller, and may not in fact be worth the increase in code complexity. @droazen, what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1988#issuecomment-249590040:198,simpl,simply,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1988#issuecomment-249590040,1,['simpl'],['simply']
Usability,"I was thinking that if we relied on PyPI for distribution, it would only be for released builds, not a release for every repo merge commit. But, I'm increasingly inclined to think that in the short term we should just include the python archive/zip file right in the gatk distribution zip, and modify the env .yml to install from that. Then every configuration (docker image, git clone user, and end user) could use exactly the same method to establish the environment. That seems like the simplest solution for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343:490,simpl,simplest,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343,2,['simpl'],['simplest']
Usability,I wasn't able to reproduce this exact issue. However at least I can make the error message a bit more user-friendly (submitting #2417 for review). Crucially this will now give the name of the file we're having issues with (thus removing the uncertainty about whether it's the data or the index file we cannot access).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286:102,user-friendly,user-friendly,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286,2,['user-friendly'],['user-friendly']
Usability,I will incorporate my feedback to the branch @mwalker174.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918#issuecomment-356035082:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918#issuecomment-356035082,2,['feedback'],['feedback']
Usability,"I wonder if we could factor out a common base interface to cut down on code duplication, and ensure a more consistent API across `SimpleInterval` and `SVInterval`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418501188:130,Simpl,SimpleInterval,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418501188,1,['Simpl'],['SimpleInterval']
Usability,"I would be useful to be able to explicitly indicate the Codec class for a FeatureInputs perhaps using an annotation. . Currently the feature manager tries every possible codec hoping to find one and only one that answers yes to the canDecode(FileName) method call. If none does execution fails saying that there is no code available to deal with the input file; if more than one codec returns true then is supposed to throw another error indicating the ambiguity. The former is likely an user cased error whereas the later is rather a bug as Codec developers seems to be responsible to make sure that such a collision never happens... This has a few draw backs:; - Seems to quasi-force to establish a 1-to-1 assignation of Codecs and file extension names; canDecode documentation encourages use the file name as the way to determine whether the codec can decode or not the file. What if the file is a simple tab separated value file (with some column count and format constrains) and general extensions such as .tab or .tsv seem acceptable names in practice?; - The error message when there is no supporting code does not tell what the problem is; whether the extension of the file (due to the the 1-to-1 name to type quasi-restriction above) or a more complex formatting issue in the file (e.g. required header missing, version not supported ... blah blah). ; - All codecs are tried out even when most won't ever apply. Even if the performance impact should in practice be minimal still may cause several file IO open operations as several Codec do actually peek into the file (e.g. BCF and VCF codecs). ; - Codec developers have to make sure their new codec does not collides with others; it would be better if codec development can be totally independent.; - General file extensions such as .tab , .tsv cannot be used by codecs due to possible collisions constraining users to name their files the way GATK needs them to; ""I don't like people telling what file names a have to use... I'm already pl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184:901,simpl,simple,901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184,1,['simpl'],['simple']
Usability,"I would like to keep in some of my tools the read group arguments in sync with the `AddOrReplaceReadGroup` in picard, but currently there is no way of access them. This is a very simple and trivial patch to extract the short/long names to a static String variable to be able to use them. In addition, I refactored the variable names to the camel-case java convention.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260:179,simpl,simple,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260,1,['simpl'],['simple']
Usability,"I would like to know how to add more allele-specific annotations. Example; code would be great. On Thu, Aug 23, 2018 at 8:12 PM, Karthik Gururaj <notifications@github.com>; wrote:. >; > - If you are planning to add more allele specific annotations (other; > than the ones listed [here](For the allele specific annotation fields; > that we know; > <https://github.com/Intel-HLS/GenomicsDB/blob/master/src/main/java/com/intel/genomicsdb/importer/Constants.java>)),; > then I can provide more example code in GATK showing how to set the type; > and length descriptors.; > - If you simply wish to change the combine operation for existing; > annotations, the example code in this PR should suffice; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415611462>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOgKRPyTCP0gxEq0Ye1b4Q5CZ8HFks5uT0TWgaJpZM4VJ9WN>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415804596:578,simpl,simply,578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415804596,2,['simpl'],['simply']
Usability,"I would like to specify what passing a `ReadFilter` to some of my tools means, so maybe passing an `ArgumentCollection` will be simpler than this one, I agree. Although #2085 may solve the issue regarding the `ReadTransformer`/`ReadFilter` ordering, I would like to have in the plugin a way to specify different parameters (maybe some of then hidden before expose to users or advanced in the case of disabling). I will open a new PR for that change, but I will really appreciate if I can get something like that in this and other plugins (if implemented).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983:128,simpl,simpler,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983,2,['simpl'],['simpler']
Usability,"I would prefer to not require an extra `--sparkMaster` argument to run a Spark tool locally -- ie, `/gatk-launch CountReadsSpark -I flag_stat.bam` should run locally by default. I think we should keep the name `sparkRunner` for symmetry with `sparkMaster`, and to make it clear it's a Spark argument and not a tool argument, but we should rename `SUBMIT` to `SPARK`, and `DIRECT` to `LOCAL`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-163672338:272,clear,clear,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-163672338,1,['clear'],['clear']
Usability,I wrote a very minimal guide that says the same thing here: https://github.com/broadinstitute/gatk/wiki/How-to-update-the-gatk-base-docker,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446:23,guid,guide,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446,2,['guid'],['guide']
Usability,"I'd also be hesitant to break the previous expectation that IntervalArgumentCollection contains a non-empty list of intervals. If I understand correctly (and apologies if not, I'm glancing at the repo between paternity-leave duties and am quite sleep deprived!), all calling code would have to add an explicit check that the new option isn't enabled or risk failing ungracefully downstream. For CNV code, this might be as simple as changing the validation method `CopyNumberArgumentValidationUtils.validateIntervalArgumentCollection`, but I wouldn't generally expect it to be so straightforward to add such checks throughout the codebase. I also agree with @lbergelson that the expected behavior might not be immediately clear and that perhaps this could be addressed in the scattering step---seems like shards could just be limited to regions that cover the resource at the outset. Consider also an older comment at https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435588845 about whether or not we should just use the equivalent Picard tool (horrible glob aside).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687:422,simpl,simple,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687,4,"['clear', 'simpl']","['clear', 'simple']"
Usability,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:68,simpl,simply,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746,2,['simpl'],['simply']
Usability,"I'll wait for @laserson and @tomwhite to get a chance to chime in, but it looks like we have plan. Supposing that it takes @cmnbroad two weeks (which seems like a reasonable estimate to me). We should we do in the mean time? Is there something simple we can do (that's hacky but correct) to hold us over until the real fix is in?; @tomwhite's suggestion of stripping the header before shuffles, then adding it back after sounds OK to me (and should be easy to clean up).; Other thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141293657:244,simpl,simple,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141293657,1,['simpl'],['simple']
Usability,"I'm OK with the HG38 only, considering that we are evaluating against HG38, unless other SV team members have different opinions.; Also, it's OK to remove those HLA stuff, since we don't evaluate SV calls on them, AND they can reck __havoc__ for constructor `SimpleInterval(String)`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-423582005:259,Simpl,SimpleInterval,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5111#issuecomment-423582005,1,['Simpl'],['SimpleInterval']
Usability,"I'm adding some issues and PRs for make the plugin usable in other cases too, @cmnbroad. Maybe you prefer that solution instead of make it extensible. Just let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544:51,usab,usable,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544,2,['usab'],['usable']
Usability,"I'm going to assign it to @kshakir for now - to implement the simplest -L (one set of intervals, provided by a file). He may choose to split this issue into smaller ones for more granular features. The approach we're going to take is to implement only the features of -L that we need. The first milestone reflects the first feature to implement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4#issuecomment-67049771:62,simpl,simplest,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4#issuecomment-67049771,1,['simpl'],['simplest']
Usability,"I'm going to close this issue because it's not a bug. Several things in the code of Mutect2 and FilterMutectCalls adapt as they traverse the genome and it's possible that some learned parameter shifts minutely. For example, the assembly graph pruning algorithm uses knowledge of previously assembled regions to better distinguish between errors and somatic variation. It's also possible that somewhere we forgot to give something a fixed random seed. In full honesty, I _wish_ that I knew exactly what causes the 3142 to become 3143, and I regret that I don't have time for it. Nonetheless, in principle it is not cause for alarm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338:176,learn,learned,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338,2,['learn'],['learned']
Usability,I'm going to keep the initialization as is because it mirrors HaplotypeCaller and because I feel like defining blocks by their size is more intuitive than defining the number of blocks between two bounds.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294:140,intuit,intuitive,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294,2,['intuit'],['intuitive']
Usability,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930:213,simpl,simplify,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930,1,['simpl'],['simplify']
Usability,"I'm not clear why the inputs table in gvs-overview.md is rendering as not having rows between some of the items, the only changes to that table were intelliJ auto-white space added to make the columns line up, and one more row on the bottom about the new boolean for using classic vqsr.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8466#issuecomment-1674974109:8,clear,clear,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8466#issuecomment-1674974109,2,['clear'],['clear']
Usability,"I'm not completely opposed to that way of dealing with this, but I'm not yet convinced either. . I'm not sure I see how having an extra argument is somehow shorter than having one special value that is included in the description of the original argument. As in:. --trimWhatever | -trimWvr -- bla bla bla; default w; min x max y; to disable trimming, use z. . As for the documentation auto-generator showing the two args together, that is dependent on setting up the arguments so that the code specifies they are related, and adding some logic to the auto-generation to pull related arguments together. (As a contributing developer to a documentation auto-generator --the GATKDocs-- I can tell you that is not necessarily trivial and adds even more moving parts.) This also generates additional complexity for third-party developers of wrappers (such as Galaxy). Finally, it can be a source of confusion for users who are trying to look up an argument called ""-dont-Trim-whatever"" since presumably it's only going to be listed under T (-Trim-whatever) and not under D in the alphabetical list. Or should it be listed twice? . A reference manual can be very ""nice"" and helpful, and it must be organized in the most intuitive way possible, especially since there is no way we can provide examples that cover every single use case under the sun (trust me, there's not).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930:1214,intuit,intuitive,1214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930,1,['intuit'],['intuitive']
Usability,I'm not totally clear from your response but I think you've resolved the problem? . If you're encountering a bug merging bai files could you open an issue describing that with your stack trace and any relevant information about the configuration you're running?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623:16,clear,clear,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623,2,['clear'],['clear']
Usability,"I'm sorry, I don't know another tool that does the same thing. If you could provide some samples that cause the problem that would actually be really helpful. It *should* be a simple fix so I could try to get a path out soon, but it's always faster with a test case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8427#issuecomment-1646250031:176,simpl,simple,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8427#issuecomment-1646250031,2,['simpl'],['simple']
Usability,"I'm trying to figure out the best way to replicate GATK3 behavior in GATK4. The GATK4 VariantWalker iterates all variants from VCF(s), calling apply() once per variant. If the input VCFs has duplicates at a given location, apply() is called multiple times for the same locus. In GATK3, VariantEval iterates each locus, and generates a list of variants at that site. I'm trying to figure out the most efficient way to do this in GATK4. One solution is to override traverse(), and add some kind of groupingBy step, for example:. StreamSupport.stream(getSpliteratorForDrivingVariants(), false); .filter(variantfilter); .collect(Collectors.groupingBy(x -> new SimpleInterval(x))); .values(); .forEach(variantList -> {; final SimpleInterval variantInterval = new SimpleInterval(variantList.get(0));; apply(variantList,; new ReadsContext(reads, variantInterval, readFilter),; new ReferenceContext(reference, variantInterval),; new FeatureContext(features, variantInterval));. progressMeter.update(variantInterval);; });. This will get me the right end result (like of variants per site); however, it's not clear to me if this is the most efficient route, and I'm not sure if it's aware of the sorted input. Because the input data are sorted, I could iterate, track the previous location and maintain a list of track variants per site. Each time we hit a new location I call apply() with that list. Are the places in GATK4 that already do this type of per-locus grouping?. Thanks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4456:656,Simpl,SimpleInterval,656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4456,4,"['Simpl', 'clear']","['SimpleInterval', 'clear']"
Usability,"I'm with @davidbenjamin that a camel-case looks clearer, because there are very long names in the GATK-framework that may involve a lot of dashes. Even if the bash-completion will help on this, for downstream projects it can be a nightmare to change this. For instance, I'm not planning to add the bash-completion generation to my toolkit, and I personally find difficult to read long arguments with tons of dashes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323703013:48,clear,clearer,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323703013,2,['clear'],['clearer']
Usability,"I've added a new end-to-end test for SelectVariants that writes to GCS. Sadly, the IntegrationTestSpec class uses Files throughout, so it wasn't possible to do this simply without first completely refactoring IntegrationTestSpec (which should probably be its own pull request). . Doing this refactoring would have the advantage that changing existing end-to-end tests from local to GCS would be trivial. For now instead I went with an ad-hoc approach. It works, and the test passes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612:165,simpl,simply,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612,2,['simpl'],['simply']
Usability,"I've added some non-trivial (code-wise, logical wise very simple) code to single out slow assemblies more obviously. That is, generating another txt file collecting the runtime for those slow ones.; Example here ; /user/shuang/experiments/NA12878_PCR-_30X; /user/shuang/experiments/NA12878_PCR-_30X/assembly_betterLogging_longOnes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1997#issuecomment-245295941:58,simpl,simple,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1997#issuecomment-245295941,1,['simpl'],['simple']
Usability,"I've added the additional test you requested, and confirmed that it passes. The `SkipExceptions` are there to skip JBWA tests on platforms for which we don't have a build of the library -- I've extracted a `skipJBWATestOnUnsupportedPlatforms()` method to make this clearer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1847#issuecomment-220757508:265,clear,clearer,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1847#issuecomment-220757508,1,['clear'],['clearer']
Usability,"I've addressed @davidadamsphd's feedback. The tests were passing on Friday, but now the build is failing due to https://github.com/broadinstitute/gatk/pull/1185, so that should be merged before this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1174#issuecomment-158912039:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174#issuecomment-158912039,1,['feedback'],['feedback']
Usability,I've addressed all the feedback and all tests are passing so I'm going to squash and merge this now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019,2,['feedback'],['feedback']
Usability,"I've addressed the feedback so far - except for @davidadamsphd's last comment about checking in a sharded BAM. @lbergelson let me know if you'd like me to do that; also, what do you think about the overwriting behaviour?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/980#issuecomment-147751416:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/980#issuecomment-147751416,1,['feedback'],['feedback']
Usability,I've also incorporated @davidbenjamin 's in line feedback. Please let me know if there are additional fixes for the documentation section.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306281558:49,feedback,feedback,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306281558,2,['feedback'],['feedback']
Usability,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:905,learn,learned,905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238,2,['learn'],['learned']
Usability,I've incorporated your feedback @davidbenjamin. Many thanks for the review. Waiting for checks to pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042,2,['feedback'],['feedback']
Usability,I've incorporated your feedback @ldgauthier.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009,2,['feedback'],['feedback']
Usability,I've incorporated your feedback @samuelklee. Thanks for the review.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868,2,['feedback'],['feedback']
Usability,"I've incorporated your feedback to #5601 @ldgauthier and the commit is undergoing tests. Please feel free to merge the PR if you accept the changes and have no further comments. . As for [Article#11074](https://software.broadinstitute.org/gatk/documentation/article?id=11074), given we have addressed the original issues (e.g. Latex), I am going to consider the additional recommendations as something for the not-so-near future. Would that be okay with you @ldgauthier?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-458728389:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-458728389,2,['feedback'],['feedback']
Usability,"I've just run into this issue, is it okay to ignore these warnings? I'm new to GATK so it's not clear to me what a combination operation is, and if it has effect on the output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-369990259:96,clear,clear,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-369990259,2,['clear'],['clear']
Usability,"I've made some improvements to this PR, including:; - Made it easier to use the `joinOverlapping` method by making the function you supply only have to worry about one interval (shard) at a time. This simplifies the callers code, so PileupSpark (for example) is now shorter.; - Added some documentation. I've also used the same technique to improve `AddContextDataToReadSpark` so that references are filled in on a per shard basis, rather than per read. In tests on a 6.6GB file I managed to get BaseRecalibratorSpark's runtime down from 10.61 minutes to 3.73 minutes, which is over 60% faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250750843:201,simpl,simplifies,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250750843,2,['simpl'],['simplifies']
Usability,"I've now improved the naming of the parameter tot specify the Spark submit command (now it's `--sparkSubmitCommand`), to address @lbergelson's feedback. I updated to the latest shaded google-cloud-nio artifact, and it works with Spark 2 on a cluster. However, the `GcsNioIntegrationTest` fails due to the `javax` package (and subpackages) being shaded (these packages should not be shaded since Java provides these classes). So I'm afraid we'll need another release to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314:143,feedback,feedback,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314,2,['feedback'],['feedback']
Usability,I've ran this one in my test and it's clear the current code doesn't have the problem of prefetching a prefetcher.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298468693:38,clear,clear,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298468693,2,['clear'],['clear']
Usability,"I've tried to organize these changes into three separate commits with one issue per commit.; 1) Running the new ExtractSVEvidenceSpark tool via manage_sv_pipeline.sh; 2) Dumping more useful info for machine learning; 3) Reinstating option to not copy fastq files. Hopefully this is sensible, it's my first time trying to organize a PR this way. This should resolve issue #4332",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4385:207,learn,learning,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4385,1,['learn'],['learning']
Usability,"ID 1976). 667 bytes result sent to driver; 23/05/23 13:20:19 INFO TaskSetManager: Finished task 66.0 in stage 31.0 (TID 2040) in 160 ms on localhost (executor driver) (1/128); 23/05/23 13:20:19 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 1976) in 330 ms on localhost (executor driver) (2/128); 23/05/23 13:20:19 INFO Executor: Finished task 3.0 in stage 31.0 (TID 1977). 667 bytes result sent to driver; ...; 23/05/23 13:20:19 INFO TaskSetManager: Finished task 97.0 in stage 31.0 (TID 2071) in 123 ms on localhost (executor driver) (127/128); 23/05/23 13:20:19 INFO TaskSetManager: Finished task 112.0 in stage 31.0 (TID 2086) in 88 ms on localhost (executor driver) (128/128); 23/05/23 13:20:19 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool ; 23/05/23 13:20:19 INFO DAGScheduler: ResultStage 31 (foreach at BwaMemIndexCache.java:84) finished in 0.389 s; 23/05/23 13:20:19 INFO DAGScheduler: Job 7 finished: foreach at BwaMemIndexCache.java:84, took 0.392269 s; 23/05/23 13:20:19 INFO SparkUI: Stopped Spark web UI at http://d01.capitalbiotech.local:4040; 23/05/23 13:20:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 23/05/23 13:20:26 INFO MemoryStore: MemoryStore cleared; 23/05/23 13:20:26 INFO BlockManager: BlockManager stopped; 23/05/23 13:20:26 INFO BlockManagerMaster: BlockManagerMaster stopped; 23/05/23 13:20:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 23/05/23 13:20:26 INFO SparkContext: Successfully stopped SparkContext; 13:20:26.099 INFO PathSeqPipelineSpark - Shutting down engine; [May 23, 2023 1:20:26 PM CST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.04 minutes.; Runtime.totalMemory()=156475326464; 23/05/23 13:20:26 INFO ShutdownHookManager: Shutdown hook called; 23/05/23 13:20:26 INFO ShutdownHookManager: Deleting directory pathseq/tmp/spark-2042a18b-a4af-4a86-a236-c4914f0407a1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8339:57643,clear,cleared,57643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8339,1,['clear'],['cleared']
Usability,"INV55 interval's left/right boundary: `ABC -> AC'B'A'C`; * INV33 interval contains INV55 interval: `ABC -> ABA' or AB'A'`; * INV55 interval contains INV33 interval: `ABC -> C'BC or C'B'C`. Note that for the last two cases, where the inverted dispersed duplication is guaranteed, the two possible alternate alleles are reverse complement&mdash;inversion&mdash;of each other, hence signatures of contig alignments along is not enough, and alignments of short reads within the affected region cannot break the degeneracy either.; So we need to attach left and right flanking regions to the affected region, and align short reads back to these two haplotypes and study the pair orientations of the alignments to break the degeneracy. #### output:. * VCF containing the inversion and flanking deletion and dispersed duplication calls (together with CPX-derived inversion calls, total number of `INV` calls are ~ 30). * BED file on filtered BND's citing reason for filtering. Relevant files, including an IGV session can be found in this [bucket](https://console.cloud.google.com/storage/browser/broad-dsde-methods/shuang/archive/inversion-algo-demo/?project=broad-dsde-methods&organizationId=548622027621). ## Todo:. * Large inversions. The primitive size-based filtering step and the filtering step requiring matched mate pairs undoubtedly will cause us false negatives, as sometimes we don't expect assembly of all breakpoints for inversions complicated by copy number events. The inversions currently captured tend to be small inversions; ; ```; Min. 1st Qu. Median Mean 3rd Qu. Max.; 77.0 188.0 359.0 1144.5 823.2 12697.0; ```; ; * run check against reference annotation: known Seg. Dup., RC-STR, centromere, as well as consistent pair support from short reads; ; * __Question: is this pre-filtering a bad idea; if not, how to report?__. * __Question: is the number $10^5$ reasonable?__; ; * __Question: any other suggestion on filtering criteria?__; ; * Corner cases here & there in the proposed tool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789:5422,undo,undoubtedly,5422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789,1,['undo'],['undoubtedly']
Usability,"If Louis says this is allowed in our style guide then you can leave them; in. I didn't realize that. Feel free to drop the hammer on us for any style; violations. On Mon, May 1, 2017 at 1:04 PM, tedsharpe <notifications@github.com> wrote:. > *@tedsharpe* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/spark/sv/; > BreakpointClusterer.java; > <https://github.com/broadinstitute/gatk/pull/2627#discussion_r114155944>:; >; > > }; >; > - @Override; > - public Iterator<BreakpointEvidence> apply( final BreakpointEvidence evidence ) {; > - if ( evidence.getContigIndex() != currentContig ) {; > - currentContig = evidence.getContigIndex();; > - locMap.clear();; > + public Iterator<BreakpointEvidence> apply( final Iterator<BreakpointEvidence> evidenceItr ) {; > + while ( evidenceItr.hasNext() ) {; > + final BreakpointEvidence evidence = evidenceItr.next();; > + final SVInterval location = evidence.getLocation();; > + final SVIntervalTree.Entry<List<BreakpointEvidence>> entry = evidenceTree.find(location);; > + if ( entry != null ) entry.getValue().add(evidence);; >; > Pretty sure that Louis said that this was one of our departures from; > Google style: single statements following an ""if"", ""else"", or ""else if""; > that fit comfortably on the same line are allowed (but not required) to be; > unbraced.; > Since you prefer braces, I'll change these.; > However, since you've thrown down the gauntlet, I'm going to start nailing; > you guys on very long lines (max line length is supposed to be 100; > characters). So there.; >; > —; > You are receiving this because your review was requested.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2627#discussion_r114155944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZZPkQPglpEhCzZqbA17GshZt6t-Dks5r1hCsgaJpZM4NKPYH>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2627#issuecomment-298379400:43,guid,guide,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2627#issuecomment-298379400,4,"['clear', 'guid']","['clear', 'guide']"
Usability,"If anyone wants to learn more about the horrors of HLA (and MHC more generally) naming, ping me elsewhere, probably best at https://github.com/nmdp-bioinformatics/genotype-list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655:19,learn,learn,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655,2,['learn'],['learn']
Usability,"If it's a difficult/non-trivial change, though, then it may not be worth fixing. I thought it would be a simple change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066:105,simpl,simple,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066,2,['simpl'],['simple']
Usability,"If the assembler has not discovered an allele it could be simply that the samples does not have that allele but it could also be the case that it failed to assemble due to some edge case. . If the former it makes sense to assign depth 0 but for the latter that would be misleading and a ""I don't know"" output (""."") would be more appropriate. For example, what about those HOM-REF sites that end up with PL=0,0,0 because the reference-confidence-model found reads that don't support the reference sequence yet the assembly did not produce a concrete alternative. Fast forward and the same sample is joint-genotyped with in a cohort with other samples for which HC assembled the alternative haplotype/allele (correctly). Then we will assign AD=0 to those alternative alleles in the original (no-quite)-hom-ref sample. . I think the better answer would be AD=""."" in light of the lack of confidence on the hom-ref call. . Would this even extend to cases where we are confident on hom-ref? Unless any single read is exactly the reference at that site there is a potential for that allele to have gone unnoticed. . Would make sense that if someone wants to know the AD for every alt. allele at a sample where some weren't discovered in, he must re-run HC in GGA mode with the full list of alt alleles?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7290:58,simpl,simply,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7290,1,['simpl'],['simply']
Usability,"If there is sufficient demand, we could implement a `LocusWalker` class for GATK4, particularly as the key classes from GATK3 were recently ported as part of https://github.com/broadinstitute/gatk/pull/1442. Adding new walker types in GATK4 is much simpler than it was in GATK3, so this would actually be a fairly easy thing to add.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1463#issuecomment-178662601:249,simpl,simpler,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1463#issuecomment-178662601,1,['simpl'],['simpler']
Usability,"If these events were indeed not CNLOH, as we discussed, then I don't think we should merge this. Perhaps we should take a step back and answer definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. If tagging/filtering rare germline is still a concern, then I'd say the next step is to see whether simply changing segmentation parameters to artificially decrease resolution and/or simple length-based filtering suffices. Finally, simple filtering based on CR-AF as described above could be implemented. If the normal is available, we can make IS_NORMAL calls simply based on the overlap of the ModelSegments posteriors (with corresponding qualities). If not, then some heuristic determination of the normal state from the tumor alone as in Marton's caller could be performed. This would combine the IS_NORMAL calling and filtering steps into one simple tool. The output could be a tagged/filtered ModelSegments .seg file and the corresponding VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-458551250:164,simpl,simply,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-458551250,12,['simpl'],"['simple', 'simply']"
Usability,"If we do keep both methods, we should make it VERY clear in the docs that `onTraversalDone()` should be for closing resources, and `onTraversalSucess()` should be for producing final outputs, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212597490:51,clear,clear,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212597490,1,['clear'],['clear']
Usability,"If you don't mind the list being public, the github wiki, e.g. like this existing article https://github.com/broadinstitute/gatk/wiki/GATK4-Documentation-Guidelines, seems like a good place to start a list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468818077:154,Guid,Guidelines,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468818077,1,['Guid'],['Guidelines']
Usability,"If you get any more of these errors, it's either an argument that never had any effect or something that you 4.1.1 got rid of. In the latter case, you don't need to replace it with anything. In 4.1.1 `FilterMutectCalls` automatically learns a lot of parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007:234,learn,learns,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007,2,['learn'],['learns']
Usability,"If you're interested in BWASpark tool I might wait a bit. There are a lot of issues with it as it currently stands, it's one of the least tested tools we have. We have someone working on a different more efficient implementation of the bwa bindings that may eventually be integrated into mainline gatk, so we've sort of stopped most development on BWASparkEngine until we're clear on the direction that the new work is going to take.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998:375,clear,clear,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998,2,['clear'],['clear']
Usability,"Implement a `PythonScriptExecutor` that is similar to the existing `RScriptExecutor` (invokes Python with a given set of arguments). Then ask the CNV team to prototype an example tool or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all depend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:253,learn,learning,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,1,['learn'],['learning']
Usability,"Implement a `SeqGraph` version of the junction trees described in Kiran's paper. For now we can do something naive about reads with errors corresponding to pruned edges, such as skipping the remainder of the read. In addition to involving a minimal change to the current code, using `SeqGraph`s will make handling read errors a bit simpler and is a much more natural way to handle dangling ends.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5923:332,simpl,simpler,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5923,1,['simpl'],['simpler']
Usability,Implement a simple Map/Reduce system to simplify walker transfer,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/20:12,simpl,simple,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20,4,['simpl'],"['simple', 'simplify']"
Usability,Implement a version of CollectInsertSizeMetrics that runs on dataflow and produces the same output as the current picard version. . It seems like a pretty simple and fairly representative metric. . Should deal with #468 as part of this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/491:155,simpl,simple,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/491,1,['simpl'],['simple']
Usability,Implement the simplest CountReads as a Picard CommandLineProgram,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3:14,simpl,simplest,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3,2,['simpl'],['simplest']
Usability,"Implements tool for clustering SVs, built on top of the clustering engine code refined recently in #7243. In addition to a few bug fixes, updates also include:. - `PloidyTable` class, which ingests and serves as a simple data class for a tsv of per-sample contig ploidies. This was necessary for inferring genotypes when input vcfs contain non-matching sample and variant records.; - Modified `SVClusterEngine` to render sorted output.; - Improved code for SV record collapsing (see the `CanonicalSVCollapser`), particularly for CNVs. Genotype collapsing now infers allele phasing in certain unambiguous cases, in particular for DUPs and multi-allelic CNVs. Testing for this has been cleaned up and augmented with further cases to validate this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7541:214,simpl,simple,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7541,1,['simpl'],['simple']
Usability,"Implements two new tools and updates some methods for a revamp of the `CombineBatches` cross-batch integration module in [gatk-sv](https://github.com/broadinstitute/gatk-sv). - `SVStratify` - tool for splitting out a VCF by variant class. Users pass in a configuration table (see tool documentation for an example) specifying one or more stratification groups classified by SVTYPE, SVLEN range, and reference context(s). The latter are specified as a set of interval lists using `--context-name` and `--context-intervals` arguments. All variants are matched with their respective group which is annotated in the `STRAT` INFO field. Optionally, the output can be split into multiple VCFs by group, which is a very useful functionality that currently can't be done efficiently with common commands/toolkits.; - `GroupedSVCluster` - a hybrid tool combining functionality from `SVStratify` with `SVCluster` to perform intra-stratum clustering. This tool is critical for fine-tuned clustering of specific variants types within certain reference contexts. For example, small variants in simple repeats tend to have lower breakpoint accuracy and are typically ""reclustered"" during call set refinement with looser clustering criteria.; - `SVStratificationEngine` - new class for performing stratification.; - Updates to breakpoint refinement in `CanonicalSVCollapser` that should improve breakpoint accuracy, particularly in larger call sets. Raw evidence support and variant quality are now considered when choosing a representative breakpoint for a group of clustered SVs.; - Added `FlagFieldLogic` type for customizing how `BOTHSIDE_PASS` and `HIGH_SR_BACKGROUND` INFO flags are collapsed during clustering.; - `RD_CN` is now used as a backup if `CN` is not available when determining carrier status for sample overlap.; - Removed no-sort option in favor of spooled sorting.; - Bug fix: support for empty EVIDENCE info fields; - Bug fix: in one of the JointGermlineCnvDefragmenter tests",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8990:1081,simpl,simple,1081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8990,1,['simpl'],['simple']
Usability,Improve Beta UX with a default `extract_output_gcs_dir` [VS-1040],MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8510:13,UX,UX,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8510,2,['UX'],['UX']
Usability,In #1774 I added to LIBS the possibility to keep reads with Ns. This is a simple commit to allow `LocusWalker` implementations to use this behaviour (switch off by default).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833:74,simpl,simple,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833,1,['simpl'],['simple']
Usability,"In GATK4, the way to make a tool multithreaded is to implement it as a Spark tool. All Spark tools can be trivially parallelized across multiple threads using the local runner, and across a cluster using spark-submit or gcloud. . We wanted to avoid the complexities of implementing our own map/reduce framework, as was done in previous versions of the GATK, and instead rely on a standard, third-party framework to keep the GATK4 engine as simple as possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164:440,simpl,simple,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164,2,['simpl'],['simple']
Usability,"In addition just to clarify that the ""contig"" word reference to the sequences in the given reference not the number of contigs that you might align to it, so single-contig-reference-aligner means an aligner that will align several sequences (read, contigs, random-stuff) vs a single sequence/contig reference. . I guess I shall change contig for chromosome or sequence to make it more clear.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389990976:385,clear,clear,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389990976,2,['clear'],['clear']
Usability,"In good news, the spark mailing list announced that spark master builds and runs all tests on 11 now. So it looks like support for java 11 coming in spark 3.0. When that is is going to be release isn't clear though. We should start moving to support java 11 in advance of that so we're ready when it releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068:202,clear,clear,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068,2,['clear'],['clear']
Usability,"In helping @bhanugandham figure out why a particular site was failing it became apparent that merging dangling head code was failing to recover deletions in the dangling head. Furthermore there is some code in the dangling end recovery code that asserts a certain high standard of matching (usually 1 but sometimes dangling branch length/kmersize) `getMaxMismatches(final int lengthOfDanglingBranch)`. Both of these facts seem likely to cause dangling heads to be dropped despite their being still potentially informative, particularly the indel code. . I have added the ability for the index recovery code to account for the cigar string when merging dangling ends. Addtionally rather than counting mismatches to reject the branch it simply requires a minimum matching end (which can be changed, I suspect this is where the lionshare of the differences come from). Unfortunately changing the tests is non-trivial (as this happened to change the integration test results for HaplotypeCaller at a few sites) so I wanted to get this branch up to solicit advice a to whether it is worth pursuing this fix. @davidbenjamin @ldgauthier @droazen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113:735,simpl,simply,735,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113,1,['simpl'],['simply']
Usability,In light of #6463 I'm clearly wrong about some part of this. I'll take another look after digging into that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-590344630:22,clear,clearly,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-590344630,2,['clear'],['clearly']
Usability,In light of the recent #7357 and #7358 it has become clear that we are blind changes that cause the logging outputs for GATK to become unusable because we are spitting endless warnings to stdout. I think we should change our integration tests to capture the log output for each of our tests and assert that none of them balloon beyond some reasonable threshold that would capture these problems (perhaps a megabyte but it would take a little bit of sleuthing to be sure). . I would think the best place would be to add a capture into `CommandLineProgramTest.runCommandLine()` that instead of using the current behavior `injectDefaultVerbosity()` we instead leave the logging output as the default and capture it somewhere explicit where we can make assertions about the size of the outputs. Possibly we could create a dummy logging level that just saves and counts the outputs so we can make assertions about the logs. Ideally this should apply to every tool simultaneously since it would be too patchwork to simply add logging output tests for enough of the tools to protect us manually.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7368:53,clear,clear,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7368,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"In looking at his further, the container header contains a stream offset, and each slice header also contains a global record counter. Both of these need to be updated. Its not clear if its possible to repair these without re-encoding the entire container stream, but if so that should probably be done in a method exposed by htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574:177,clear,clear,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574,2,['clear'],['clear']
Usability,"In my case, as an API user, my main usage of GATK is for traverse `GATKRead` and `VariantContext`, so I would like to have in `GATKTool` a simpler way of access to the `FeatureInput<VariantContext>` instead of getting them from `FeatureManager features`. It will be useful in the `VariantWalker` as a step to issue #692, to get all the variants provided by the user in the same walker. My idea is modify the `GATKTool` to include:; - A `public abstract boolean requiresVariant()`, which will be used to determine if we should detach or not all the variants inputs from the `FeatureManager features`.; - A `private void initializeVariants()`, which will implement a way to extract the `FeatureInput<VariantContext>` from `features` and initialize a `FeatureManager variants` or a extended class which includes only `VariantContext` inputs.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1710:139,simpl,simpler,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1710,1,['simpl'],['simpler']
Usability,"In order to get it running though you will need to install the following things on each machine using apt-get: gawk, sysstat, and perf-tools-unstable. Additionally as root, you will have to set the /proc/sys/kernel/perf_event_paranoid variable from 1 to 0. For these tasks it might be possible to automate these steps by updating the system image that is used to setup dataproc clusters. In order to actually run and install PAT, you will need to download it from [here](https://github.com/intel-hadoop/PAT/tree/master/PAT) and add all the machines and ssh ports (including the master) in your cluster to the ""ALL_NODES"" setting in the config.template -> config file. You will also have to setup an SSH key to root on the cluster, which can be done with the command `gcloud compute ssh` and set the ""SSH_KEY"" variable in the config file to point to the google_compute_engine file in roots .ssh directory (public keys should have automatically been distributed to the other nodes). . At this point you need simply input the command line command you wish to run into the ""CMD_PATH"" variable and run ./pat run. I recommend running a spark-submit job using yarn-client as master. NOTE: the output will be a directory containing an excel spreadsheet and a bunch of data for each cluster. You will need to open the spreadsheet on a windows copy of excel and use ""control+q"" to run the macros that load the data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495:1006,simpl,simply,1006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495,1,['simpl'],['simply']
Usability,"In the VAT validation, give clearer error msg about which clinvar classification values are missing",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939:28,clear,clearer,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939,1,['clear'],['clearer']
Usability,"In the course of investigating https://github.com/broadinstitute/gsa-unstable/issues/1409 a few things came up that I want to document for when it's time to test the new model:; - Throw away the spanning deletions alleles! They shouldn't affect the QUAL anymore since we won't be using the independent alleles approximation, but I don't want them mucking with the site type and choice of prior (SNP vs INDEL); - For the purposes of QD for VQSR, we should be using AS_QD very shortly, in which case the choice of prior for mixed sites will be clear because we're evaluating per-allele; - For the purposes of QUAL for emission, at mixed sites I'm in favor of continuing to apply the SNP prior in accordance with the doctrine of maximal sensitivity until VQSR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-230464015:542,clear,clear,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-230464015,1,['clear'],['clear']
Usability,"In the documentation for the `SelectVariants` tool, it isn't clear what does `-R` do. The documentation for the `-R` is empty, it is set as an optional parameter, but both examples on the page do set it. https://gatk.broadinstitute.org/hc/en-us/articles/360036362532-SelectVariants. On the other hand, examples mentioned elsewhere ignore reference sequence when calling `SelectVariants`. https://gatk.broadinstitute.org/hc/en-us/articles/360035531112--How-to-Filter-variants-either-with-VQSR-or-by-hard-filtering",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8721:61,clear,clear,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8721,1,['clear'],['clear']
Usability,"In the genotyping code, we represent and iterate over all possible genotypes with a given number of alleles and ploidy in two different ways. The first is simply an `alleleCounts` array of type `int[numAlleles]`, where `alleleCounts[n]` is the number of times allele `n` appears in the (unphased) genotype. This is implemented in the nested `SumIterator` class in `GeneralPloidyExactAFCalculator`. The second is as a `GenotypeAlleleCounts` object, which encapsulates a rather different `int[]` called `sortedAlleleCounts`. A value of `{1 2 4 5}` means a ploidy-7 genotype in which allele 1 appears 2 times and allele 4 appears 5 times. It doesn't seem right to have both of these. Does anyone have an opinion which should stay and which should go? I'm especially hoping that @vruano can advise.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1907:155,simpl,simply,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1907,1,['simpl'],['simply']
Usability,"In the interest of getting this merged, I've addressed the remaining blocking issue via documentation and naming: tool is now named `ConvertHeaderlessHadoopBamShardToBam`, and the docs make it clear what kinds of Hadoop bam shards it should be used with, and which it shouldn't. Will merge once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1278#issuecomment-221101168:193,clear,clear,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1278#issuecomment-221101168,1,['clear'],['clear']
Usability,In the process of getting MarkDuplicatesSpark working for the 1000x bam it has become clear that multi-input bams are necessary. Unfortunately we have set a hard restriction that all multi-input bams must be query-group sorted to be valid. This creates issues if there are reasons for the input files to not be sorted consistently we want to be able to handle the problem more gracefully. I propose we add an opt-in argument that disables the check and allows mixed file bams.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5973:86,clear,clear,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5973,1,['clear'],['clear']
Usability,"In the process of unifying CalculateTargetCoverage / SparkGenomeReadCounts for the rewrite of the CNV pipeline, we decided to experiment with switching over to fragment-based counts due to a request from CGA. For each fragment, CollectFragmentCounts adds a count to *the bin that overlaps with the fragment center*. We filter to properly-paired, first-of-pair reads in order to have well formed fragments and avoid double counting. We also filter out duplicates. In contrast, CalculateTargetCoverage added a count to *all bins that overlapped with a read* and SparkGenomeReadCounts added a count to *the bin that contained the read start*. These tools kept duplicates. However, none of these collection strategies have been rigorously evaluated. Using a small set of WGS SV tandem-duplication calls from @mwalker174 as a truth set, I did some experimenting with changing the count-collection strategy. (We initially thought we were missing some of these simply due to over-denoising/filtering by the PoN, but as we'll see below, the count-collection strategy plays a non-trivial role.). Subsetting to chr3, I built a small PoN of 12 normals (including the case normal) at 100bp and denoised using bin medians only (i.e., `--number-of-eigensamples 0`) to avoid denoising away common events. In chr3, the case sample had three events:. ````; chr3	8559423		8560126; chr3	64547471	64549936; chr3	90414457	90415989; ````. I tried the following, running `ModelSegments` using fairly sensitive parameters (`--number-of-changepoints-penalty-factor 0.1 --maximum-number-of-segments-per-chromosome 10000 --window-size 16 --window-size 32 --maximum-number-of-smoothing-iterations 0` in copy-ratio-only mode:. 1) CollectFragmentCounts. This only recovered event 2.; 2) CollectReadCounts - same as CollectFragmentCounts, but removing the properly-paired and first-of-pair filters and adding a count for each read to the bin containing its start. This recovered all 3 events.; 3) CollectFragmentOverlaps - same filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519:954,simpl,simply,954,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519,1,['simpl'],['simply']
Usability,In the work on #7295 it became clear that there are a lot of overlapping overloads of the `createGenomeLoc()` method that has already caused some confusion since some overloads will skip the reference validation step. Somebody should audit all of the uses of `GenomeLocParser` and evaluate where validation is and isn't appropriate (possibly if you want an unvalidated genomeLoc use a SimpleInterval?) and wire them accordingly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7300:31,clear,clear,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7300,2,"['Simpl', 'clear']","['SimpleInterval', 'clear']"
Usability,"InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <100%> (ø)` | `11 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <100%> (ø)` | `4 <1> (ø)` | :arrow_down: |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.592% <100%> (ø)` | `22 <2> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/GenotypeUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZVV0aWxzLmphdmE=) | `94.872% <100%> (+2.767%)` | `12 <0> (+3)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=footer). Last update [c8ede6e...c63c08b](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295:2535,learn,learn,2535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295,2,['learn'],['learn']
Usability,Inconsistency between Locatable.overlaps() and SimpleInterval.Overlaps() methods,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6898:47,Simpl,SimpleInterval,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898,1,['Simpl'],['SimpleInterval']
Usability,"Initial commit by Mark DP in 2009: . > simpleComplement function() in BaseUtils. Generic framework for clipp…; > …ing reads along with tests. Support for Q score based clipping, sequence-specific clipping (not1), and clipping of ranges of bases (cycles 1-5, 10-15 for example). Can write out clipped bases as Ns, quality scores as 0s, or in the future will support softclipping the bases themselves. https://github.com/broadinstitute/gsa-unstable/commit/d6385e0d884cbd80c34e16e848297c3694f85a5a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/263#issuecomment-95101660:39,simpl,simpleComplement,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263#issuecomment-95101660,1,['simpl'],['simpleComplement']
Usability,"Initial implementation of DRAGEN joint detection. Functional equivalence with respect to DRAGEN joint detection is actually worse than before due to many outstanding questions. . We currently have no idea how joint detection is supposed to interaction with BQD and FRD. I have tried a few guesses and none have worked (see below for functional equivalence results of the particular guess used in this PR). The interplay of joint detection with BQD and FRD is complicated for several reasons. Naively one would simply define the BDQ and FRD likelihoods on entire haplotypes rather than alleles at one locus. Unresolved difficulties with this include:. - BQD and FRD are defined with respect to one particular variant position. How would we define them for a haplotype that has no particular locus?; - BQD involves the base qualities at one particular variant locus, how would this be defined for an entire haplotype?; - The above is especially thorny for haplotypes that exhibit multiple variants.; - The FRD prior is only defined for individual events, not haplotypes.; - The BQD and FRD models use reads that overlap a variant site, but it is not clear how to use reads that only partially intersect a haplotype.; - BQD and FRD likelihoods are only defined for homozygous haplotypes, but heterozygous combinations of _haplotypes_ contribute to homozygous genotypes all loci where the distinct haplotypes agree. Clearly, generalizing BQD and FRD to entire haplotypes is not straightforward. Nor does it suffice to produce ""raw"" genotype likelihoods using the joint detection approach and then apply BQD and FRD on variant loci afterwards. Some difficulties with this include:. - BQD and FRD require the read-allele likelihoods matrix. Where are these likelihoods supposed to come from? The pre-joint-detection unrigorous ""marginalization"" where to each allele we assign the maximum likelihood over all haplotypes supporting that allele? Some read-allele likelihoods matrix derived from the read-haplot",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616:510,simpl,simply,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616,1,['simpl'],['simply']
Usability,Integration run [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/76c46310-3c0d-43a8-9fce-072ef7750651). As written the task requires `apt-get`. Converting this to Alpine would be non-trivial and not really worthwhile as it might even take longer to build all the extra things into the `alpine` image that we simply download with the `slim` image.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8065:320,simpl,simply,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8065,1,['simpl'],['simply']
Usability,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:1714,clear,clearly,1714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976,2,['clear'],['clearly']
Usability,"Interesting, thanks for doing this experiment. It's already clear to me that Funcotator will need a different caching strategy for https://github.com/broadinstitute/gatk/issues/4771 -- I was going to implement one after merging your reads caching PR. Re-assigning this ticket to myself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143#issuecomment-416985644:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143#issuecomment-416985644,2,['clear'],['clear']
Usability,"Interesting. Sorry this is causing so much trouble. From one of your above comments I wasn't clear if the solution using `--conf 'spark.submit.deployMode=cluster'` work correctly or not. . Is it possible that it's correct behavior for it to fail with the linkage error? According to the [mapr doc](https://maprdocs.mapr.com/52/DevelopmentGuide/c-loading-mapr-native-library.html) that command causes it to expect the application to load the library itself, but GATK by default doesn't have a copy of MAPR and won't load it on it's own. Have you included the mapr library somehow into the gatk jar? Or is it provided to spark some other way? I don't really know how maprfs works and how it interacts with hadoop paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653:93,clear,clear,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653,2,['clear'],['clear']
Usability,"IntervalWalker, VariantWalker enhancements, and GenomeLoc -> SimpleInterval migration in the engine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/297:61,Simpl,SimpleInterval,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/297,1,['Simpl'],['SimpleInterval']
Usability,"Intriguing. Thanks for the good example. To get around this it looks like we need to update NIO to allow it to be in a special ""broken"" state where the CloudStorageFileSystemProvider allows itself to be constructed even without credentials, failing later when we ask it to do anything. I think this is possible, but the change would have to be in gcloud-java-nio itself. The additional state is a bit counter-intuitive (usually allocation-is-initialization) but it seems worthwhile in this case. I'll get the ball rolling over at gcloud-java-nio.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191:409,intuit,intuitive,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191,2,['intuit'],['intuitive']
Usability,Intro to Cosmos spike comprised of a couple of scripts and quite a few learnings.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8254:71,learn,learnings,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8254,1,['learn'],['learnings']
Usability,"Introducing the IntervalLocusIterator which will traverse every locus in intervals, regardless of coverage. Minor changes. Removed imports. AlignmentContextLocusIterator first cut. Still needs unit tests. Putting in the walker. Still needs unit tests. Adding tests (and fixes) so that we can get AlignmentContexts. Adding tests (and fixes) so that we can get AlignmentContexts. Working tests. Beginning migration to a LocusWalker change rather than a separate walker. Merging the emit empty loci into locus walker. Still need warnings and validation of parameters. Next step is the LocusWalker testing. Simple test of the new LocusWalker when it emit empty loci. Addressing PR requests and added ShardedIntervalIterator to save RAM on big intervals. Addressing the rest of the PR comments. Rolling back to int from long. Addressing second round of PR comments. Wrapped LIBS in a factory so that we can encapsulate the retrieval of the best alignment context iterator. Spark empty loci traversal being supported. Rebasing based off of the other emit loci branch.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2731:603,Simpl,Simple,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2731,1,['Simpl'],['Simple']
Usability,Investigate if using Spark Datasets (and Spark SQL) in MarkDuplicatesSpark improves performance and/or simplifies the code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6103:103,simpl,simplifies,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6103,1,['simpl'],['simplifies']
Usability,Is the NeuralNetInference usable?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4559:26,usab,usable,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559,2,['usab'],['usable']
Usability,Is there a way we can use constants for common arg names? Would be the simplest way to keep them all in sync IMO.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94413465:71,simpl,simplest,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94413465,1,['simpl'],['simplest']
Usability,It appears the merge process has undone a bunch of the work. Working on fixing that now :-(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/894#issuecomment-142445038:33,undo,undone,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/894#issuecomment-142445038,1,['undo'],['undone']
Usability,It does in this very simple test I ran on dataproc.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266636027:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266636027,2,['simpl'],['simple']
Usability,"It gives us the ability to easily aggregate records across multiple FeatureInputs, and (potentially, if we wanted) to retrieve records by type rather than by source. . FeatureInput should be simple, since (due to the way the argument-parsing system works) it must be initialized by a constructor that takes a single String (the argument value).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76735788:191,simpl,simple,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76735788,1,['simpl'],['simple']
Usability,It is not clear for me what 2 separate repos can improve. Could you elaborate on that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217072086:10,clear,clear,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217072086,1,['clear'],['clear']
Usability,"It is not clear to me from the docs whether parent/child pairs are intended to be supported by `CalculateGenotypePosteriors`, but a quick glance at the [mention](https://github.com/broadinstitute/gatk/blob/67f0f0f2e59185b721398b17c24eba487a2ac76c/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/FamilyLikelihoods.java#L210)[s](https://github.com/broadinstitute/gatk/blob/67f0f0f2e59185b721398b17c24eba487a2ac76c/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/FamilyLikelihoods.java#L231) in comments in `FamilyLikelihoods.java` makes me suspect that they are intended to be supported. (In any case, from my perspective, it would be a very nice feature as I have yet to find a tool that will robustly handle this use case.). Here are the main issues that I'm encountering when trying to use `CalculateGenotypePosteriors` for a parent-child pair:; 1) If I supply a ped file with two individuals like the following, [this check](https://github.com/broadinstitute/gatk/blob/1e98c6d02cefefbaa1a15db0aea64ea7518025fa/src/main/java/org/broadinstitute/hellbender/tools/walkers/variantutils/CalculateGenotypePosteriors.java#L260) gets triggered, resulting in printing of the warning and skipping family priors.; ```; FAM	MOM	0	0	2	0; FAM	CHILD	0	MOM	2	0; ```; 2) If I add a father to the ped file to form a trio, like below, `CalculateGenotypePosteriors` proceeds without the warning that occurs in first approach, but the output doesn't appear to make any adjustments to genotypes, posteriors, etc. Note that there is no entry for ""DAD"" in the input VCF.; ```; FAM	MOM	0	0	2	0; FAM	DAD	0	0	1	0; FAM	CHILD	DAD	MOM	2	0; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409:10,clear,clear,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409,1,['clear'],['clear']
Usability,"It looks like all of our builds are failing since we cleared the cache because of R dependency issues. ```; ... Setting up r-base-core (3.1.3-1trusty) ...; Installing new version of config file /etc/bash_completion.d/R ...; Installing new version of config file /etc/R/Renviron.site ...; Installing new version of config file /etc/R/Makeconf ...; Installing new version of config file /etc/R/repositories ...; Installing new version of config file /etc/R/Rprofile.site ...; Installing new version of config file /etc/R/ldpaths ...; Replacing config file /etc/R/Renviron with new version; W: --force-yes is deprecated, use one of the options starting with --allow instead.; Installing packages into ‘/home/travis/site-library’; (as ‘lib’ is unspecified); Error: (converted from warning) dependencies ‘rlang’, ‘vctrs’ are not available; Execution halted; ```. Both libraries now require R >= 3.2.; We could either try again to nail down the R versions exactly, which is almost certainly possible but not something we've ever figured out a good way to do, or we could just upgrade R and hope for the best, kicking the can down the road again.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6072:53,clear,cleared,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6072,1,['clear'],['cleared']
Usability,It looks like it made the tests substantially slower.... I'm not totally clear on why. Maybe because it has to re-optimize code every time it restarts the jvm.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6093#issuecomment-521372663:73,clear,clear,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6093#issuecomment-521372663,2,['clear'],['clear']
Usability,It looks like it shouldn't be to difficult but it would necessitate either moving the bucket they are located in or asking people to clear out the hellbender bucket of other things because it appears the lifecycle features can only be applied on a per-bucket basis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545:133,clear,clear,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545,2,['clear'],['clear']
Usability,"It looks like when reading from cloud we sometimes hit a bug that crashes GATK with the following message:. ```; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-385875968]; at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:78); at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:140); at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:121); ```. This doesn't happen every time, but clearly it should never happen at all.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2516:695,clear,clearly,695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2516,1,['clear'],['clearly']
Usability,"It looks like when this was added, a mistake was made between a filter returning test() == true (passing the filter) and test() == false (failing the filter, read removed). Furthermore the invert filter argument in here is now redundant as of #8724 and I will go ahead and remove it from this filter. I have also tweaked the filter arguments slightly to clarify what they do now mean more intuitively. . Fixes #8887",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8888:389,intuit,intuitively,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8888,1,['intuit'],['intuitively']
Usability,It seems that SimpleInterval(String) constructor does not check that the start and end positions make sense (greater than 0 and end >= start).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/438:14,Simpl,SimpleInterval,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/438,1,['Simpl'],['SimpleInterval']
Usability,"It seems to me that producing some parallel coordinate plots is the way to go to gain some intuition about how the SW and filters parameters affect the Area under the curve of the precision/recall curve. I assume that, overall we have about 10 parameters and 2-3 metrics (AUC for SNP, AUC for short Indel, AUC for long Indel). This is small enough that we should be able to gain intuition by looking at parallel coordinate plots. . This is a nice visualization package to produce parallel coordinate plots: https://facebookresearch.github.io/hiplot/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451:91,intuit,intuition,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451,4,['intuit'],['intuition']
Usability,"It seems to me the `Header definition line` encompasses the information given by the `VCF Field` so this latter is redundant. . It would definitely be useful to categorize INFO (cohort) versus FORMAT (SAMPLE) level annotations. I'm not clear on the significance of the `Type` nor `Category` fields. `Type` might be the groupings, e.g. HaplotypeCaller standard annotations versus Mutect2 standard annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344423143:236,clear,clear,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344423143,2,['clear'],['clear']
Usability,It should detect that java is missing and exit with a clear error message instead.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5993:54,clear,clear,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5993,1,['clear'],['clear']
Usability,"It would be nice to keep the separate tool around so that it can be used; for stuff like calling variants from de novo assemblies, like I showed at; Tuesday's meeting. But if both of you think it's not necessary to simplify the conversions; I'll defer to you. On Fri, Apr 14, 2017 at 11:59 AM, tedsharpe <notifications@github.com>; wrote:. > The decision about whether to hard clip or soft clip supplementary; > alignments is a flag to bwa mem. All it does is to replace initial and; > final 'S' in the cigar with 'H' instead. The code in applyAlignment; > respects that decision. So if we don't want any hard clipping, that's easy; > enough to do -- we just turn off that flag.; > That's probably the right thing to do since the code on line 89 of the; > AlignmentAssemblyParser always grabs the entire sequence, whether or not; > there's been hard clipping. I'd guess it's likely that there a bugs lurking; > here.; > I don't see any particular need to convert to SAM and then back into an; > AlignmentRegion. We can eliminate the SAM writing entirely once we have a; > single tool, and then there will only be a single path.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294179814>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZffa-htFUWK3AckY3g2y2kR14wW-ks5rv5fKgaJpZM4M8xRs>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294180667:215,simpl,simplify,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294180667,2,['simpl'],['simplify']
Usability,"It would be wonderful to be able to use SelectVariants with a query like -select ""AF > 0.1"" on a VCF containing multiallelics and have it filter multiallelics by the allele with the highest AF. (Possibly conversely for ""AF < X""queries. Right now it crashes unless you use a crazy JEXL or pull out the multiallelics. Maybe we could make a maxAF/minAF in htsjdk/JEXLmap.java which equals AF for biallelics?. Internally, it might be nice to have a Map<Allele, Double> with the AF (or AC) for each allele for the SelectVariants issue and to simplify some of the crazy logic already in VariantAnnotator to deal with different allele ordering. As part of this task, we should also make 100% sure that allele ordering is preserved so that AF/AC array ordering is preserved during VC reading/writing/manipulation.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/241:537,simpl,simplify,537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/241,1,['simpl'],['simplify']
Usability,"It's a problem because we have to work with formats that support zero-length intervals (eg., BED). We need to talk this issue through and come to a clear decision.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/317#issuecomment-185798929:148,clear,clear,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317#issuecomment-185798929,1,['clear'],['clear']
Usability,"It's a simple change that I've implemented locally, I need to fix the picard programs that rely on the old behavior though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/175#issuecomment-94355649:7,simpl,simple,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/175#issuecomment-94355649,1,['simpl'],['simple']
Usability,"It's a type of quality metrics they designed - quotes below -(https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/dragen-bio-it/Illumina-DRAGEN-Bio-IT-Platform-User-Guide-1000000141465-00.pdf). . About the chrM, thank you. . Anyway, I don't think the ""VCFAdapterException"" error is related with the chrM, because the JoinGenotype pipeline worked fine with Reblock(snap) + GATK 4.2.5, and they were there (of course we know it was generating wrong data, but we had results to open and check in HAIL). ```; You can use somatic quality (SQ) as the primary metric to describe the confidence with which the caller; made a somatic call. SQ is reported as a format field for the tumor sample. Variants with SQ score; below the SQ filter threshold are filtered out using the weak_evidence tag. To trade off sensitivity; against specificity, adjust the SQ filter threshold. Lower thresholds produce a more sensitive caller and; higher thresholds produce a more conservative caller.; ```. ```; QUAL is not output in the somatic variant records. Instead, the confidence score is FORMAT/SQ.; ##FORMAT=<ID=SQ,Number=1,Type=Float,Description=""Somatic quality"">; The field is specific to the sample. For the tumor samples, it quantifies the evidence that a somatic; variant is present at a given locus.; If a normal sample is also available, the corresponding FORMAT/SQ value quantifies the evidence that; the normal sample is a homozygous reference at a given locus.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1113714714:218,Guid,Guide-,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7797#issuecomment-1113714714,1,['Guid'],['Guide-']
Usability,"It's also worth noting here that GATK has a `--tmp-dir` argument, while Picard has `--TMP_DIR`, and it's not clear how they interact when running Picard tools from within GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691243311:109,clear,clear,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691243311,2,['clear'],['clear']
Usability,"It's common for Hadoop JARs to be provided at runtime (e.g. when running the `hadoop` or `spark-submit` commands). This is because the client-server RPC is fragile, so it's important to use the same version of each. To solve this we should make the Hadoop JARs a ['provided' dependency](https://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html) (in the Maven sense). Gradle doesn't support 'provided' out of the box, so a workaround may be needed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/836:312,guid,guides,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/836,1,['guid'],['guides']
Usability,"It's currently not clear what the best setting for DEFAULT_READSHARD_SIZE is, or how important it is to performance / results. We should find out.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4298:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4298,1,['clear'],['clear']
Usability,"It's not a technical problem but it's more than a question of style. It's a user experience problem. Happy to go into detail at some point (just not now). I hear you on the internal wiring rationale; but I think we should explore whether it's possible to fix that, potentially through changes to WDL itself. Clearly the language isn't allowing you to do what you need as an author and what I need as a user -- which I would characterize as ""conditional optionality"", ie things are made optional or not depending on a condition. Would be good to get redteam involved to see what they can suggest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665:76,user experience,user experience,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665,3,"['Clear', 'user experience']","['Clearly', 'user experience']"
Usability,It's not clear to me how this is happening. It seems like a bug in the scattering code. Why do we want to support this? . Do we expect tools to produce empty bams/ vcfs if they're given empty intervals? What about tools that require intervals? It's not clear to me what the behavior of a tool with empty intervals specified should be.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540723529:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540723529,4,['clear'],['clear']
Usability,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988,2,['clear'],['clear']
Usability,"It's not clear to me what code path you're going through when using a `gs://` URI for the input bam in your second test. `CountReadsSpark` calls `GATKSparkTool.getReads()` which calls `JavaSparkContext.newAPIHadoopFile()`, but the question is how Hadoop-BAM handles your `gs://` URI. In other parts of the GATK (eg., `ReferenceTwoBitSource`) we call into `BucketUtils.openFile()`, which handles GCS URIs directly by calling into `GcsUtil.open()`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213153356:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213153356,1,['clear'],['clear']
Usability,"It's not clear what to do in this case - the MAF format spec has limited values in the `VariantClassification` field, so `GencodeGtfFeature.GeneTranscriptType` doesn't map 1:1 to `VariantClassification`. Will need to put off until later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259,2,['clear'],['clear']
Usability,It's not exactly clear what you're trying to do here. Are you trying to write a new tool that just gets the per base read depth? If that's what you want to do you would start by implementing a new `LocusWalker`. In the `apply` method you implement you can check `alignmentContext.size()` to get the pileup depth at each locus.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3881#issuecomment-347585515:17,clear,clear,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3881#issuecomment-347585515,2,['clear'],['clear']
Usability,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:195,clear,cleared,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058,2,['clear'],['cleared']
Usability,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:12,clear,clear,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307,2,['clear'],['clear']
Usability,"Its not clear what the distinction is between ""Tool"" and ""GATKTool"", or ""toolsArgs"" vs ""GATK arg 1"".",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1286:8,clear,clear,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1286,1,['clear'],['clear']
Usability,Its not entirely clear to my why Codecov hasn't commented here. But here is the commit on their page: https://codecov.io/gh/broadinstitute/gatk/commit/af23590723748fa27a2d065e48c26a20d0e91488,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5018#issuecomment-405633317:17,clear,clear,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5018#issuecomment-405633317,2,['clear'],['clear']
Usability,"Its possible to specify CNN inference size argument values that cause the Python process run out of memory, and the failure mode appears to be the java process hangs. Its not clear whether its always possible to recover from this using the global exception handler we currently install on the Python side - we need to explore a bit to see if the handler is being invoked on OOM; whether catching the OOM exception explicitly would help, or if we need an alternative reporting strategy for low-memory conditions. Attached is a log provided by @bhanugandham from a run in a Terra notebook that failed and that exhibited a hang that we assume was due to OOM, and that was resolved by reducing the inference batch size. [gatkStreamingProcessJournal-772629669.txt](https://github.com/broadinstitute/gatk/files/2988819/gatkStreamingProcessJournal-772629669.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5820:175,clear,clear,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5820,1,['clear'],['clear']
Usability,Jar on Maven central updated - please clear any cached jars,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988:38,clear,clear,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988,2,['clear'],['clear']
Usability,"Java implementation of segmentation is now in the sl_wgs_segmentation dev branch, with a few simple unit tests. I'll expand on these and add tests for denoising in the future, but for now we have a working revised pipeline up through segmentation. The CLI is simply named ModelSegments (since my thinking is that it could eventually replace ACNV). I ran it on some old denoised exomes. Runtime is <10s, comparable to CBS. Here's a particularly noisy exome:. CBS found 1398 segments:; ![cbs](https://user-images.githubusercontent.com/11076296/30165095-cdf6251a-93ac-11e7-91fb-dcc8f48fe07f.png). Kernel segmentation with a penalty given by a = 1, b = 0 found 1018 segments:; ![kern](https://user-images.githubusercontent.com/11076296/30165106-dbbe0b40-93ac-11e7-99ec-5d58d8417d8b.png). Kernel segmentation with a penalty given by a = b = 1 (which is probably a reasonable default penalty, at least based on asymptotic theoretical arguments) reduced this to 270 segments :; ![kern-smooth](https://user-images.githubusercontent.com/11076296/30165113-e2b545a8-93ac-11e7-97a9-a692e43ebbdf.png). The number of segments can similarly be controlled in WGS. WGS runtime is ~7min for 250bp bins, ~30s of which is TSV reading, and there is one more spot in my implementation that could stand a bit of optimization, which might bring the runtime down. In contrast, I kicked off CBS 45 minutes ago, and it's still running... @LeeTL1220 this is probably ready to hand off to you for some WDL writing and preliminary evaluation. ; Although I can't guarantee that there aren't bugs, I ran about ~80 exomes with no problem. We can talk later today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936:93,simpl,simple,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936,4,['simpl'],"['simple', 'simply']"
Usability,Just adding a note here that `FeatureCache` should eventually be refactored to use the simplified Interval class (when it exists) to track cache boundaries and compute overlap.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630:87,simpl,simplified,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630,1,['simpl'],['simplified']
Usability,Just as feedback we use gcs nio too in Cromwell and have had to add retries around this error as it has popped up every now and then.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300269489:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300269489,2,['feedback'],['feedback']
Usability,"Just follow the recommendations from our readme file ; ```. First, make sure [Miniconda or Conda](https://conda.io/docs/index.html) is installed (Miniconda is sufficient). To ""create"" the conda environment:; If running from a zip or tar distribution, run the command conda env create -f gatkcondaenv.yml to create the gatk environment. Execute the shell command source activate gatk to activate the gatk environment.; See the [Conda](https://conda.io/docs/user-guide/tasks/manage-environments.html) documentation for additional information about using and managing Conda environments.; ```; And yes you don't have to call SNPs and INDELs separately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998:461,guid,guide,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998,2,['guid'],['guide']
Usability,"Just learned `awk '$5=""*""'` replaces `T,*` with `*` and the correct usage is `awk '5~""*""'`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417441866:5,learn,learned,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417441866,2,['learn'],['learned']
Usability,"Just pushed two commits to address your feedback, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226:40,feedback,feedback,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226,2,['feedback'],['feedback']
Usability,"Just realized CNV WDLs are not using NIO in FireCloud. This is as simple as changing `File` to `String` for supported files. Not sure if these need to live in our repo (I see we have a M2 NIO WDL), I'd be fine with them just living in FireCloud. @bshifaw would you be OK making the changes in FireCloud for the next release? If not, I can add an NIO version to the repo. @LeeTL1220 perhaps something to add to the style guide (if it's not already there)?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806:66,simpl,simple,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806,2,"['guid', 'simpl']","['guide', 'simple']"
Usability,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:162,simpl,simple,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890,2,['simpl'],['simple']
Usability,"Just tested this locally outside of the Docker. I do not see the WARN:; ```; WMCF9-CB5:shlee$ gatk40110 LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv ; Using GATK jar /Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv; 12:16:19.960 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java run",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:104,Learn,LearnReadOrientationModel,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,2,['Learn'],['LearnReadOrientationModel']
Usability,"Just to be clear folks, we are using `gatk` directly, not `./gatk` in the example commands. And if you can, for those of you yet to make your updates, please use compressed file examples. Those of you who've already put in changes, thank you and Comms can tidy those bits later.; ```; <h3>Usage examples</h3>; <pre>; gatk --javaOptions ""-Xmx4g"" GenotypeGVCFs \; 	-R Homo_sapiens_assembly38.fasta; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>. <pre>; gatk GenotypeGVCFs \; 	-R reference.fa; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894:11,clear,clear,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894,2,['clear'],['clear']
Usability,"Just to be clear, the gCNV code expects that the intervals obtained after resolving the inputs of `-L` and `-XL` via the engine should specify the *bins* that the user wishes to retain from the coverage files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-435497601:11,clear,clear,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-435497601,2,['clear'],['clear']
Usability,"Just to make sure I understand the issue---will this cause technical problems in the Firecloud environment, or is it more of a style issue?. If the latter, one reason I prefer the use of optional file inputs to trigger tool-level ""modes"" when possible is that it propagates more naturally from the tool level. For example, let's consider a tool that can operate in either tumor-only or matched-pair mode. It is natural at the tool level to make the tumor a required input and the normal optional. The other options are quite awkward: 1) make both inputs required and switch between using the normal or not with a flag (in which case it is very easy for the user to shoot themselves in the foot if they forget to set the flag right, and we'd have to pass a dummy normal every time we want to run tumor only if we don't actually have a pair), 2) leave the normal as optional but add a flag anyway, which would be redundant and require an additional validation (i.e., if the flag is set to matched mode but we don't have a normal, we should fail early), or 3) write separate tools for each mode with the corresponding required inputs. If we accept that optional file input is the way to handle such a scenario at the tool level but not at the workflow level, then we will simply run into the same problems at the workflow level. I'm sure there are more complex scenarios when triggering on file presence/absence doesn't uniquely specify a workflow, in which case flags are a must. But for simple scenarios, I'm not sure why we shouldn't take advantage of the ability to specify optional file inputs in WDL (actually, I'm not sure how else we are supposed to use them?). However, if this is a problem for Firecloud, then I'd like to understand why---and what possible solutions there might be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444:1269,simpl,simply,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444,4,['simpl'],"['simple', 'simply']"
Usability,KVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZDb25zdGFudHMuamF2YQ==) | `75% <ø> (-5%)` | `4 <0> (ø)` | |; | [...ntamination/GetPileupSummariesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2V0UGlsZXVwU3VtbWFyaWVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `95.745% <100%> (+0.29%)` | `4 <0> (ø)` | :arrow_down: |; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `95.906% <100%> (+0.073%)` | `10 <0> (ø)` | :arrow_down: |; | [...walkers/readorientation/ArtifactPriorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9BcnRpZmFjdFByaW9yVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.671% <100%> (ø)` | `43 <0> (ø)` | :arrow_down: |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `89.744% <100%> (+1.508%)` | `6 <2> (+1)` | :arrow_up: |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5560#issuecomment-452017370:3461,Learn,LearnReadOrientationModelEngineUnitTest,3461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5560#issuecomment-452017370,1,['Learn'],['LearnReadOrientationModelEngineUnitTest']
Usability,"LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; > + }; > +; > + // get the sequence dictionary; > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); >; > I think the right word is uniquify; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646179>:; >; > > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' int",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:5635,Simpl,SimpleInterval,5635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['Simpl'],['SimpleInterval']
Usability,Learn Smith-Waterman parameters,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1902:0,Learn,Learn,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1902,1,['Learn'],['Learn']
Usability,Learn polymerase slippage / STR indel model parameters,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5531:0,Learn,Learn,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5531,1,['Learn'],['Learn']
Usability,LearnReadOrientationModel gatkdoc does not exist,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6720:0,Learn,LearnReadOrientationModel,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720,1,['Learn'],['LearnReadOrientationModel']
Usability,LearnReadOrientationModel is a Memory Hog,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7948:0,Learn,LearnReadOrientationModel,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7948,1,['Learn'],['LearnReadOrientationModel']
Usability,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6720:0,Learn,LearnReadOrientationModel,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720,1,['Learn'],['LearnReadOrientationModel']
Usability,"LearnReadOrientationModel loads tables for one ref context at a time, reducing memory demands 32x",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8639:0,Learn,LearnReadOrientationModel,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8639,1,['Learn'],['LearnReadOrientationModel']
Usability,"Legacy pipeline (note, the following should only be done after final ModelSegments PR is in):; - [x] Delete prototype tools. (#3887) (SL, PR issued by 12/1); - ~~Add deprecated/legacy tag to legacy pipeline tools. (SL, PR issued by 12/1 EDIT: need further input from @vdauwera )~~; - ~~Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PR issued by 12/15)~~; - ~~(Reach) Collect all legacy code in a new package.~~; - [x] Delete old pipelines. (SL, #3935 awaiting review). ModelSegments pipeline:; - [x] Review and merge denoising PR (#3820).; - [x] Add WDL changes from @LeeTL1220, @meganshand, and @jsotobroad to dev branch. (Note that we exposed PreprocessIntervals.bin_length in these WDLs; I'm assuming that https://github.com/broadinstitute/cromwell/issues/2912 will allow this to be specified via the json, so I reverted this change.); - [x] Make simple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:901,simpl,simple,901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['simpl'],['simple']
Usability,Lessons learned in VDS creation during Echo Scale Testing. Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e6aa362-e25b-49d0-83cd-d64e926c6386).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8602:8,learn,learned,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8602,1,['learn'],['learned']
Usability,"Let's discuss. In the new pipeline, I currently have median absolute deviation after standardization and denoising output as text files during the plotting step, as before. But I think it actually makes more sense to output them after DenoiseReadCounts. We also can't output the number of segments until after the ModelSegments step. However, I would rather not bake this sort of thing into the jar if a simple `wc -l` would suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331:404,simpl,simple,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331,2,['simpl'],['simple']
Usability,"Let's hear what others say, but I think I would strongly prefer to simply take over VariantEval in another repo if this was something you'd consider. I'd likely do much of what you propose anyway (certainly WRT testing); however, perhaps not the microscope we went through with the core GATK changes earlier. On plugins: I like what seems to be shaping up w/ Barclay. I carried over the Stratifier and Evaluator as plugins because it seems like it would make sense to allow tools to provide extensions (VariantEval, our tool, does). If I took this PR a step further, I would have migrated many arguments currently top-level on VariantEval into the plugins themselves (a good feature in Barclay). As an aside: I dont think VariantAnnotator is migrated yet, but we have many GATK3 plugins related to annotation, and hope that tool retains Annotator plugins when it get migrated. My impressions of barclay are probably a little out of date. I agree the main argument parsing framework is pretty robust. Specifically on plugins, it seems a little less so, or at least there are not many tools I visibly see exercising that part of the code. For example, there really should be a default implmentation or base class between Barclay's plugins and ReadFilter plugins. I'm guessing if more tools in GATK4 were using plugins this would have happened. I created something like this for VariantEval, and without a ton of work that could probably get generalized; however, doing so would throw a lot higher bar on me and as noted above I'm trying to take on less, not more at the moment. If we do take over VariantEval, I'm certainly happy to try to contribute code and experiences to improve the core, through more targeted PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501:67,simpl,simply,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501,2,['simpl'],['simply']
Usability,Look into broadcasting the reference to all of the workers. This would make AddContextDataToReadSpark and the BQSR code simpler and may have better performance than our current code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/855:120,simpl,simpler,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/855,1,['simpl'],['simpler']
Usability,Looking at the code changes the way this argument work has changed from simply clearing previous filters while apply new ones to being used standalone just to revert filtering (i.e. adding the . again) with the expectation that it would not be used in conjuction with new filters. I think we should create to different arguments for each of those operations. say --overwrite-existing-filters that that the former and --revert-filters that that the latter and will fail if you try to filter again in the same run. ... or perhaps the latter should have its own tool RevertFilration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608#issuecomment-995592204:72,simpl,simply,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608#issuecomment-995592204,4,"['clear', 'simpl']","['clearing', 'simply']"
Usability,"Looking at the existing code in Hadoop_BAM it makes the assumption that coordinates are always of the form ```chr:start-stop``` never things like ```chr```, ```chr:pos```, ```char:star+```... I've just generalized a bit more so that it can handle ':' and '-' inside the ```chr``` in a PR. I guess is not ideal but In any case this addresses the current fire and dependants have a clear work around which is to provide their intervals in the expected ```chr:start-stop``` format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249:380,clear,clear,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249,2,['clear'],['clear']
Usability,Looking into finding a way to enable experimental docker features for `gcr.io/cloud-builders/docker` so that we can run with the `--squash` argument -- it's not yet clear that this is possible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1480107181:165,clear,clear,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1480107181,2,['clear'],['clear']
Usability,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:84,simpl,simply,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536,2,['simpl'],['simply']
Usability,"Looks like all packages *except* ggplot2 were successfully installed. The following lines in the R script are responsible for installing 3 of the packages:. ```; dependencies = c(""ggplot2"",""gplots"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"",; ""https://cran.mtu.edu"",; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try], clean = TRUE); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```. I guess this is supposed to ensure that the installs don't fail due to intermittent connection errors, etc., but each repo is only hit once and it's possible for the loop to exit with dependencies still missing. Could this have happened when the current base image was built and pushed? @jamesemery did you push this image?. Also, I learned that *reshape2* (as opposed to reshape) is actually a dependency of ggplot2 that is automatically installed along with ggplot2. So the original removal of reshape from the `install.packages` list was fine. However, the import statement that is removed in this PR fails whether or not ggplot2 successfully installs, and is extraneous in any case. This is all consistent with the fact that the users from the forum post only get an error message about reshape and not ggplot2. Note that they are using broadinstitute/gatk:4.0.4.0, in which ggplot2 is successfully installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261:950,learn,learned,950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261,2,['learn'],['learned']
Usability,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:226,simpl,simple,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086,2,['simpl'],['simple']
Usability,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:315,simpl,simply,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908,2,['simpl'],['simply']
Usability,"Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing eng",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:5288,Learn,LearnReadOrientationModel,5288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"Make GATK docker buildable via a simple ""docker build"", with no required extra arguments",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6747:33,simpl,simple,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6747,2,['simpl'],['simple']
Usability,Make M2 wdls consistent with methods wdl template / guidelines,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4138:52,guid,guidelines,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4138,2,['guid'],['guidelines']
Usability,Make SimpleAnnotatedGenomicRegion able to produce and consume the SequenceDictionary,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3995:5,Simpl,SimpleAnnotatedGenomicRegion,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3995,1,['Simpl'],['SimpleAnnotatedGenomicRegion']
Usability,Make and evaluate simple changes to ReCapSegCaller.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3825:18,simpl,simple,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825,2,['simpl'],['simple']
Usability,"Make the logging frequency used by the ProgressLogger available as an input. If not used, sets the default value. Variants team is using a branch of gatk and have made this change there, so pulling this change into master to simplify future merges / branch updates.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8662:225,simpl,simplify,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8662,1,['simpl'],['simplify']
Usability,Maybe @lbergelson would be willing to review or provide guidance for a new engine team member?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613:56,guid,guidance,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613,2,['guid'],['guidance']
Usability,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:746,simpl,simplify,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550,2,['simpl'],['simplify']
Usability,"Maybe I'm simplifying things too much, but can't the equation in the paper be just rewritten as follows and thus the 2 will get eliminated:. ![paternal-maternal-phasing](https://cloud.githubusercontent.com/assets/6555937/17099330/b068c106-5235-11e6-83a1-718903d0012a.png). The above shows both orders that the phasing can happen assuming each phase representation is independent of the other, where each can appear with equal probability averaging to the unphased likelihood.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234686510:10,simpl,simplifying,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234686510,1,['simpl'],['simplifying']
Usability,"Maybe it would be clearer to rename `onTraversalDone()` -> `cleanup()` It seems useful to offer both options, but it is a bit confusing still.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212609203:18,clear,clearer,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212609203,1,['clear'],['clearer']
Usability,Merge in lessons learned from debugging SGA on Spark performance issues,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1912:17,learn,learned,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1912,2,['learn'],['learned']
Usability,"Merging this now to have usable VCF NIO support in master -- continuous tests to prove that the wrapper is applied will be added in a separate PR, but my ad-hoc tests on the latest version of this branch suggest it's working fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090:25,usab,usable,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090,2,['usab'],['usable']
Usability,Might actually be a simple fix in HTSJDK...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669#issuecomment-390027480:20,simpl,simple,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669#issuecomment-390027480,2,['simpl'],['simple']
Usability,"Migrated from https://github.com/broadinstitute/gatk-protected/pull/962. Changes by @davidbenjamin; -changes to docs; -got rid of weights and concentration; -got rid of constant states to simplify before CRP pre-training; -smarter transition matrix; -switched to binomial AF likelihoods for segmentation; -got rid of attempt big change in memory length; -fixed outlier likelihood; Changes by @samuelklee; -ACNV with joint segmentation; -tweaked convergence criteria and removed extraneous MCMC fit; -sorted acc in AF segmentation; -NaN fixes in binomial likelihood; -fixed some tests and added EXPERIMENTAL tags; -disabled JointAFCRSegmenterUnitTest. This introduces a new command line (AllelicCNVHMM---@sooheelee, this command line is experimental and should not be used) that performs joint segmentation and then fits model parameters using MCMC. It performs relatively well on some samples (and was used to generate results for the AACR poster), but others result in oversegmentation and convergence issues. It's possible that this could be due to the naive copy-ratio model used. @davidbenjamin may want to do some additional tweaking, but I think we will also explore other iHMM variants concurrently.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3036:188,simpl,simplify,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3036,1,['simpl'],['simplify']
Usability,"Modeling PCR stutter is better done with Valentin's approach, or in BQSR, or with deep learning. Making pairHMM fancier is not the answer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1869#issuecomment-381080555:87,learn,learning,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1869#issuecomment-381080555,1,['learn'],['learning']
Usability,"Most of these changes are to support automated evaluation of GATK CNV. - Updates SimpleAnnotatedGenomicRegion to use the collection framework used in other GATK CNV CLIs. CLIs (both experimental quality): ; - `TagGermlineEvents` is a simple tool that attempts to identify events in a tumor seg file that correspond to a germline events. ; - This is done purely with concordance on the breakpoints of the events (within some padding). ; - Input germline segments must have calls. ; - If a germline call is broken into multiple segments, this tool will handle that appropriately (ditto if there are multiple tumor segments overlapping the germline call); . - `MergeAnnotatedRegions` will merge all overlapping regions and resolve annotation value conflicts.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205:81,Simpl,SimpleAnnotatedGenomicRegion,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205,2,"['Simpl', 'simpl']","['SimpleAnnotatedGenomicRegion', 'simple']"
Usability,"Most of these changes are to support automated evaluation of GATK CNV. - Updates `AnnotatedIntervals` (formerly `SimpleAnnotatedGenomicRegion`) to use the tribble framework for reading. Writing is done in a way that should be concordant with a future tribble writing framework, as per discussion with @droazen.; - Changes to `XsvLocatableTableCodec` to support usage of arbitrary config files. This cannot be done when using tribble features in the CLI. Already reviewed with @jonn-smith . Support for SAM File headers and comments is included.; - *Note:* The reading of `AnnotatedIntervals` cannot be done automatically on the command line, unless the config file is a sibling. The tools below do not even attempt this, since the use cases involved will never have a sibling config file.; - Created a default config file in the jar file resources to read tsvs with locatable fields from the CNV collection files. This is much less strict than the framework used by the CNV tools. The reader will accept any columns (or subset of the columns). CLIs (both experimental quality): ; - `TagGermlineEvents` is a simple tool that attempts to identify events in a tumor seg file that correspond to a germline events. ; - This is done purely with concordance on the breakpoints of the events (within some padding). ; - Input germline segments must have calls. ; - If a germline call is broken into multiple segments, this tool will handle that appropriately (ditto if there are multiple tumor segments overlapping the germline call). - `MergeAnnotatedRegions` will merge all overlapping regions and resolve annotation value conflicts. Closes #3995",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276:113,Simpl,SimpleAnnotatedGenomicRegion,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276,2,"['Simpl', 'simpl']","['SimpleAnnotatedGenomicRegion', 'simple']"
Usability,Move BigQuery classes that are only used by GVS into a `gvs` package. This should facilitate the alignment of GVS with GATK master by making it clear that these classes were created specifically for GVS and are not necessarily more generally usable in their current forms.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375:144,clear,clear,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375,2,"['clear', 'usab']","['clear', 'usable']"
Usability,"Move MarkDuplicates/EstimateLibraryComplexity, tests, and resources:; - from `tools.picard.sam` to `tools.walkers.markduplicates` package; - rename both tools to have a “2” suffix; - for now, these are still `PicardCommandLinePrograms`; - remaining related [classes](https://github.com/broadinstitute/gatk/tree/master/src/main/java/org/broadinstitute/hellbender/utils/read/markduplicates) are not moved or renamed, though most have Picard analogs with the same simple name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3482:461,simpl,simple,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3482,1,['simpl'],['simple']
Usability,Move SimpleInterval functions to htsdjk locatable,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1191:5,Simpl,SimpleInterval,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1191,1,['Simpl'],['SimpleInterval']
Usability,"Move SimpleInterval to hellbender, and add overlaps()/contains()/size() methods",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/316:5,Simpl,SimpleInterval,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/316,1,['Simpl'],['SimpleInterval']
Usability,Move SimpleIntervalTestFactory methods to IntervalUtils,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3778:5,Simpl,SimpleIntervalTestFactory,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3778,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,Moved allele reduction out of AFCalculator and simplified code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1918:47,simpl,simplified,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1918,2,['simpl'],['simplified']
Usability,"Multiple badges should be fine, provided we include a clear label for each one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-213567101:54,clear,clear,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-213567101,1,['clear'],['clear']
Usability,"Mutect2 Adaptive Pruning issue as discussed in GATK OH meeting. ; Here is the original post:. This request was created from a contribution made by Nabeel Ahmed on April 07, 2021 09:13 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360077647812-Why-do-a-clear-expected-variant-not-show-up-in-the-Mutect2-vcf-file](https://gatk.broadinstitute.org/hc/en-us/community/posts/360077647812-Why-do-a-clear-expected-variant-not-show-up-in-the-Mutect2-vcf-file). \--. I am running Mutect2 on a sample in tumor-only mode. This sample has mutations introduced and known to be true positive calls. However, I am unable to detect some of these calls in the vcf file after Mutect2 is run that have very clear read support as seen in IGV. I have used the –bam-output option to show the output bam and in IGV, it shows that there is no assembly in this region and no mutation event was detected. I am showing the IGV screenshot for one of such calls (chr12:25398285). ![](https://gatk.broadinstitute.org/hc/user_images/46GjRo3tH-Y456j6ApIsqw.png). I am using the latest version GATK 4.2.0.0 and the following is the full Mutect2 command from the log file. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.2.0.0-local.jar Mutect2 -R ../resources/hg19.fa -L ../resources/coding\_regions.bed -I bam\_files/sample1.bam --pon ../resources/pon.vcf.gz --germline-resource ../resources/af-only-gnomad.raw.sites.hg19.vcf.gz --bam-output sample1.mutect2\_out.bam --recover-all-dangling-branches true -min-pruning 1 --min-dangling-branch-length 2 --debug --max-reads-per-alignment-start 0 --genotype-pon-sites True --f1r2-tar-gz vcf\_files/f1r2.sample1.tar.gz -O vcf\_files/unfiltered.sample1.vcf  . In the debug mode, the following log messages are generated for this region. 08:01:26.086 INFO  Mutect2Engine - Assembling chr12:**2539**8242-**2539**8320 wi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7232:275,clear,clear-expected-variant-not-show-up-in-the-,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7232,3,['clear'],"['clear', 'clear-expected-variant-not-show-up-in-the-']"
Usability,"Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:151); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.insta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1527,learn,learnAndClearAccumulatedData,1527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['learn'],['learnAndClearAccumulatedData']
Usability,Mutect2 should learn its lod threshold,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5086:15,learn,learn,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5086,2,['learn'],['learn']
Usability,Mutect3 Deep Learning Filter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4815:13,Learn,Learning,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4815,1,['Learn'],['Learning']
Usability,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:798,feedback,feedback,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344,2,['feedback'],['feedback']
Usability,"My lab has a variety of custom walkers. Many subclass MultiVariantWalkerGroupedOnStart, which is a useful iteration pattern. We tend to scatter/gather on our cluster, where each job is given an interval set. When doing this, handling variant spanning those borders is critical. We just had an issue around this, which stems from MultiVariantWalkerGroupedOnStart and the fact that ignoreIntervalsOutsideStart defaults to false. For our usage, we almost never want this to be true, and it's a really subtle problem if the user doesnt remember to set this. So my question is: is there a best-practice way for subclasses to override / remove or set default on inherited arguments? Granted, individual walkers could simply change the value of ignoreIntervalsOutsideStart during the init phase, but I dont like that solution since it basically leaves an useless/ignored argument. . thanks in advance for any ideas.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7287:711,simpl,simply,711,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7287,1,['simpl'],['simply']
Usability,"N Please initialize the log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 23:01:58.560 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///omics/chatchawit/bundle/test/gencode/hg38/gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; 23:02:05.335 INFO ProgressMeter - Starting traversal; 23:02:05.337 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:02:06.530 INFO Funcotator - Shutting down engine; [April 27, 2018 11:02:06 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=3420979200; java.lang.IllegalArgumentException: Invalid interval. Contig:ENST00000342066.7|ENSG00000187634.11|OTTHUMG00000040719.10|OTTHUMT00000276866.2|SAMD11-202|SAMD11|2551|protein_coding| start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getCodingSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:418); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1177); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotation(GencodeFuncotationFactory.java:619); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnTranscript(GencodeFuncotationFactory.java:575); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:487); at org.broadinstitute.hellbender.tools.funcotator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:7287,Simpl,SimpleInterval,7287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['Simpl'],['SimpleInterval']
Usability,N0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19RdWFsQnlEZXB0aC5qYXZh) | `54.545% <0.000%> (-27.273%)` | :arrow_down: |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/8231?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `86.667% <0.000%> (-10.000%)` | :arrow_down: |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/8231?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `80.952% <0.000%> (-9.524%)` | :arrow_down: |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/8231?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0.000%> (-4.545%)` | :arrow_down: |; | [...lkers/ReferenceConfidenceVariantContextMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/8231?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1JlZmVyZW5jZUNvbmZpZGVuY2VWYXJpYW50Q29udGV4dE1lcmdlci5qYXZh) | `94.079% <0.000%> (-1.316%)` | :arrow_down: |; | [.../hellbender/utils/genotyper/AlleleLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/8231?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8231#issuecomment-1451152696:2766,Simpl,SimpleXSVWriter,2766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8231#issuecomment-1451152696,1,['Simpl'],['SimpleXSVWriter']
Usability,"NFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3473,Learn,LearnReadOrientationModel,3473,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"NFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6480,Learn,LearnReadOrientationModel,6480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"N_REF> . . DP=2528691;MQRankSum=0.387;MQ_DP=158;QUALapprox=1557;; chr20 1270175 . A *,<NON_REF> . . DP=1680371 | chr20 1270175 . A *,<NON_REF> . . DP=2528811; chr20 1270176 . A <NON_REF> . . . chr20 1270176 . A <NON_REF> . . .; chr20 1270177 . A <NON_REF> . . . chr20 1270177 . A <NON_REF> . . .; chr20 1270178 . C <NON_REF> . . . chr20 1270178 . C <NON_REF> . . .; chr20 1270179 . A G,<NON_REF> . . DP=1681456;MQ=60.00;MQRankSum=-1.330e-01;MQ_DP=3998;Q | chr20 1270179 . A G,<NON_REF> . . DP=2529148;MQ=60.00;MQRankSum=-1.330e-01;MQ_DP=3998;Q; chr20 1270180 . T <NON_REF> . . . chr20 1270180 . T <NON_REF> . . .; chr20 1270181 . T G,<NON_REF> . . DP=1680135;MQRankSum=-5.980e-01;MQ_DP=122;QUALapprox= | chr20 1270181 . T G,<NON_REF> . . DP=2528796;MQRankSum=-5.980e-01;MQ_DP=122;QUALapprox=; chr20 1270182 . G <NON_REF> . . . chr20 1270182 . G <NON_REF> . . .; chr20 1270183 . A <NON_REF> . . . chr20 1270183 . A <NON_REF> . . .; chr20 1270184 . C <NON_REF> . . . chr20 1270184 . C <NON_REF> . . .; chr20 1270185 . C A,<NON_REF> . . DP=1679938;MQRankSum=0.401;MQ_DP=276;QUALapprox=3525; | chr20 1270185 . C A,<NON_REF> . . DP=2528310;MQRankSum=0.401;MQ_DP=276;QUALapprox=3525;; chr20 1270186 . A <NON_REF> . . . chr20 1270186 . A <NON_REF> . . .; chr20 1270187 . G T,<NON_REF> . . DP=1680013;MQRankSum=1.52;MQ_DP=16;QUALapprox=210;RAW | chr20 1270187 . G T,<NON_REF> . . DP=2528560;MQRankSum=1.52;MQ_DP=16;QUALapprox=210;RAW; chr20 1270188 . C G,<NON_REF> . . DP=1680051;MQRankSum=-1.480e+00;MQ_DP=13;QUALapprox=1 | chr20 1270188 . C G,<NON_REF> . . DP=2528536;MQRankSum=-1.480e+00;MQ_DP=13;QUALapprox=1; ```; GenotypeGVCFs from the original jar agrees with the version on the left from the same jar, which isn't a big surprise. My intuition leads me to believe that this could be something like excluding no-call sites from the DP sum, but in the new version those sites don't become no-call without genotyping. Can you see if you can reproduce the problem with a more manageable number of samples?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376896240:2039,intuit,intuition,2039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376896240,2,['intuit'],['intuition']
Usability,Need simple parser for non-locatable files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3757:5,simpl,simple,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3757,2,['simpl'],['simple']
Usability,"Need some guidance here. The CompareSAMs tool was not propagating the validation stringency. I have a fix for that, but that alone doesn't fix the compareBAMFiles test in BaseRecalibrationIntegrationTest.java, since that uses SamAssertionUtils.assertSamsEqual, which also doesn't propagate (or accept) a validation stringency. Changing SamAssertionUtils to use either SILENT or LENIENT does fix the integration test, and all the other tests pass, but it seems like a relaxing of the stringency, and I'm not sure it should be necessary to the BQSR test. If relaxing the stringency for BQSR test _IS_ the right path, one possibility is to add a new method to SamAssertionUtils that accepts a validation stringency argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266:10,guid,guidance,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266,1,['guid'],['guidance']
Usability,Need to create a tool that allows a user to import / create a simple delimited data source (i.e. from a given CSV / TSV file). See how Oncotator structured its config files for insights on how to do this. It may be possible to simply reuse that config file format.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3785:62,simpl,simple,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3785,2,['simpl'],"['simple', 'simply']"
Usability,"Needs to:. -support overriding config settings via a simple mechanism (like providing an override config file); -use a simple, easy-to-edit file format like Java Properties (name = value); -be widely used in the Java community & well-maintained.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078:53,simpl,simple,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078,2,['simpl'],['simple']
Usability,"New implementation of `SlidingWindowWalker` with some ideas from the discussion in #1528. The thinks that are requested in #1198 still holds, but now it is more general: padding option is added and construction of windows are done by interval. The code contain a lot of TODO because it relies on changes implemented in #1567, and because it is suppose to be a walker over `ReadWindow` instead of `SimpleInterval`+`ReadsContext` if reads are available. I think that with these changes it could be general to be extended by `ReadWindowWalker` and by users that needs a different way of ""slide"" over intervals.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708:397,Simpl,SimpleInterval,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708,1,['Simpl'],['SimpleInterval']
Usability,"New tool aiming to call all types of precise variants detectable by long read alignments (not fully functioning yet in the sense that not all types of variants are detected yet&mdash;to be handled by later PRs in this series).; This new tool splits the input long reads by scanning their alignment characteristics (number of alignments, if strand switch is involved, if mapped to the same chromosome, if have equally good alignment configurations based on the scoring tool, etc), and send them down different code path/logic units for variant type inference and VCF output.; This PR would only deal with simple INSDEL, for long reads having exactly 2 alignments (no other equally good alignment configuration) mapped to the same chromosome without strand switch or order switch (translocation or large tandem duplications), because we already have this type of variant covered in master. __UPDATE__; See updated roadmap in #2703. NEEDS TO WAIT UNTIL PART 1 IS IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3456:604,simpl,simple,604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3456,1,['simpl'],['simple']
Usability,"Next I set out to determine whether hellbender is slowing down on the larger interval simply because there is more data / a longer traversal, or because it's slower at processing the `1:1-10000000` interval than the `1:10000000-20000000` interval. And surprisingly, it appears that the latter is the case:. Time to process the `1:1-10000000` interval across two runs:. ```; GATK3: 5m25.983s 5m31.913s; HB: 6m2.156s 5m59.804s; ```. (Recall that HB was ~5% faster than GATK3 at processing the `1:10000000-20000000` interval). Moreover, our newly-installed progress meter shows that the rate at which we process records is unusually low at the start of the `1:1-10000000` interval, but is consistent throughout the processing of the `1:10000000-20000000` interval:. HB processing rate over 1:1-10000000:. ```; 14:22:19.520 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 14:22:29.522 INFO ProgressMeter - 1:769026 0.2 133000 797920.2; 14:22:39.531 INFO ProgressMeter - 1:1066133 0.3 298000 893553.2; 14:22:49.544 INFO ProgressMeter - 1:1389358 0.5 471000 941247.0; 14:22:59.572 INFO ProgressMeter - 1:1695902 0.7 636000 952785.2; 14:23:09.601 INFO ProgressMeter - 1:1961884 0.8 808000 968031.8; 14:23:19.636 INFO ProgressMeter - 1:2264803 1.0 985000 983099.3; 14:23:29.637 INFO ProgressMeter - 1:2583326 1.2 1162000 994352.2; 14:23:39.694 INFO ProgressMeter - 1:2817177 1.3 1297000 970638.9; 14:23:49.705 INFO ProgressMeter - 1:3095124 1.5 1467000 975993.8; 14:23:59.726 INFO ProgressMeter - 1:3372416 1.7 1637000 980190.6; 14:24:09.734 INFO ProgressMeter - 1:3678706 1.8 1810000 985355.8; 14:24:19.777 INFO ProgressMeter - 1:4087198 2.0 1984000 989880.0; 14:24:29.813 INFO ProgressMeter - 1:4341518 2.2 2165000 996983.7; 14:24:39.822 INFO ProgressMeter - 1:4598153 2.3 2350000 1004975.0; 14:24:49.834 INFO ProgressMeter - 1:4859664 2.5 2530000 1009892.7; 14:24:59.838 INFO ProgressMeter - 1:5103960 2.7 2712000 1014982.7; 14:25:09.887 INFO ProgressMeter - 1:5341742 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236:86,simpl,simply,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236,1,['simpl'],['simply']
Usability,"Next commit includes:. * Change the name to PrimaryLineReadFilter; * Remove impl notes completely, because if they aren't tags, they will be populated to the user documentation. With the name change, I believe that it isn't necessary anymore: with the current text is clear that the concept of primary alignment is more stringent for this filter, the name change clarify that it is a different filter than the previous GATK versions, and the name of HTSJDK flag is also different. Back to you @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250:268,clear,clear,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250,2,['clear'],['clear']
Usability,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:429,simpl,simple,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,4,['simpl'],['simple']
Usability,"Nifty, I learned about docker system prune...; Total reclaimed space: 9.254GB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679242347:9,learn,learned,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679242347,2,['learn'],['learned']
Usability,"No AVX = it'll crash... sounds bad, I admit. But remember we are talking about running a deep neural network over a large dataset: is someone really going to want to do that on hardware that is 8 years old (pre-AVX)? This version of TensorFlow is now the _default_ for all Anaconda users, which in practice probably means a sizeable fraction of the machine learning community, and so having minimum hardware requirements in line with theirs is perhaps not so unreasonable?. Another option would be to change the default: have the gatk enviroment use the accelerated TensorFlow (since almost everyone has AVX, and they can get a 10X or so speedup), but make a second environment available for people that want to try to run a deep neural network on very old hardware - gatk-old?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417041021:357,learn,learning,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417041021,2,['learn'],['learning']
Usability,"No problem – I can see how this would be challenging to review – maybe it’s not even practical – if you decide it’s best just not to use it that’s OK - working on these issues has been a valuable learning experience for me. . I sent an archive with the new validations and the diffs between the old and new bams to akiezun. Although in many cases the files shared types of errors, I had to look at each file individually to take into account the particular errors in each file and how to fix them without (to the best of my knowledge) interfering with the purpose of the test. I did write a python script to use where necessary for converting multiple unpaired reads in a file to single reads, and I used bash scripts to call the picard tools to convert multiple files at a time from bam to sam for editing and then back again after they were modified. In some cases I had to modify the values in test output files to match the values produced by the test using the modified bams/sams, or just capture the new output files and use them to replace the old with the new. In two cases where file format errors appeared to be necessary but the filename did not indicate this, I renamed the files to make this clear. From: Louis Bergelson ; Sent: Thursday, August 20, 2015 2:13 PM; To: broadinstitute/hellbender ; Cc: nenewell ; Subject: Re: [hellbender] Issue 569 - bam and sam file cleanup. (#809). @nenewell Sorry this has been sitting. We've been trying to figure out how to review this one. Could you describe how you made the changes? Did you script it or go through by hand and modify them all?. —; Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051:196,learn,learning,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051,2,"['clear', 'learn']","['clear', 'learning']"
Usability,"No problem. I'd rather take styling issues ironed out from the beginning, and in fact I learn quite a lot about GATK/Picard and Java in the process.; Thank you very much for your patience!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1529#issuecomment-191304706:88,learn,learn,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1529#issuecomment-191304706,1,['learn'],['learn']
Usability,No worries Laura. Thanks again for the feedback.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569:39,feedback,feedback,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569,2,['feedback'],['feedback']
Usability,"No worries on the timeline. I definitely appreciate your willingness to look into it and considering a fix. I know how unexpectedly time consuming it can become even if it seems simple, especially with other tasks and responsibilities. I hope you enjoy your holidays!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134#issuecomment-1360383177:178,simpl,simple,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134#issuecomment-1360383177,2,['simpl'],['simple']
Usability,"NoSuchFieldException e) {; throw new RuntimeException(""Couldn't reset FilesystemProviders"");; }; try {; final Path index = Paths.get(new URI(""gs://hellbender/test/build_reports/1626.1/tests/index.html""));; System.out.println(""Count:"" + Files.lines(index).count());; } catch (URISyntaxException | IOException e) {; throw new RuntimeException(""Couldn't read file"");; }; }; }. private void modifyProviders() throws IllegalAccessException, NoSuchFieldException {; final Field installedProviders = FileSystemProvider.class.getDeclaredField(""installedProviders"");; installedProviders.setAccessible(true);; installedProviders.set(null, loadInstalledProviders());; installedProviders.setAccessible(false);; }. //copied from FileSystemProvider, modified to use TestGCS.classLoader() instead of systemClassloader; private static List<FileSystemProvider> loadInstalledProviders() {; List<FileSystemProvider> list = new ArrayList<FileSystemProvider>();. ServiceLoader<FileSystemProvider> sl = ServiceLoader; .load(FileSystemProvider.class, TestGCS.class.getClassLoader());. // ServiceConfigurationError may be throw here; for (FileSystemProvider provider: sl) {; String scheme = provider.getScheme();. // add to list if the provider is not ""file"" and isn't a duplicate; if (!scheme.equalsIgnoreCase(""file"")) {; boolean found = false;; for (FileSystemProvider p: list) {; if (p.getScheme().equalsIgnoreCase(scheme)) {; found = true;; break;; }; }; if (!found) {; list.add(provider);; }; }; }; return list;; }; }; ```. We'd have to add an initial action to GATKSparkTool that would run `modifyProviders` once on each executor which may be a bit of a trick on it's own. . If we decided to do this it would make sense to make `modifyProviders` use the same synchronization conditions as the actual `FileSystemProvider` loading, in order to not have any race conditions, I wanted to get feedback on this approach before putting effort into doing it correctly though. @tomwhite @jean-philippe-martin What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312:3211,feedback,feedback,3211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312,1,['feedback'],['feedback']
Usability,Non intuitive behaveour of VariantFiltration ```--invalidate-previous-filters```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608:4,intuit,intuitive,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608,2,['intuit'],['intuitive']
Usability,"Non-Spark walker implementations don't need an explicit --runner argument at all (and shouldn't, as we want them to be as easy to run as their GATK3 counterparts). I vote no on the `--sparkRunner` -> `--runner` rename, as I think our users are mostly unfamiliar with Spark, and it's good to be clear about what is a Spark argument and what is a tool argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1357#issuecomment-164069571:294,clear,clear,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1357#issuecomment-164069571,1,['clear'],['clear']
Usability,"Nope, simply an ignorance of that part of the VCF spec, and the fact that `INSERTED_SEQUENCE_MAPPINGS` is using `,` for separating fields of a single mapping.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288285382:6,simpl,simply,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288285382,2,['simpl'],['simply']
Usability,"Normally for most tools in order to traverse the entire reference you simply would not specify anything for --intervals (or -L which is equivalent) but currently DepthOfCoverage requires intervals be specified. The reason for this is that for several of the outputs of DepthOfCoverage we output rows where each row is one of the user supplied intervals which don't exist in the case where no intervals are supplied. This behavior could probably be changed to simply treat each chromosome separately as an ""interval"" though given the complexities of regions that are dropped/in gaps it might warrant a warning. . @humblescientist If you would like to traverse over your entire reference in DepthOfCoverage the best way would be to provide an interval list file with -L/--intervals that covers the entire genome. If you would like more information on interval list files that GATK accepts you can find more information here https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists. I would recommend directing further questions about this to the forums since this tracker is intended for bug reports and feature requests in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7155#issuecomment-804299340:70,simpl,simply,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7155#issuecomment-804299340,4,['simpl'],['simply']
Usability,"Not really an issue, just wanted to document some surprising behavior. @tmelman has been reviving/reimplementing some ancient CNV/ModelSegments evaluations (dating as far back as 4.0.2.1!) and trying to understand whether observed differences---intentional or otherwise---are due to method changes I might have made, or if she might've introduced changes in her reimplementation of the evaluation code. I ran some checks on the stability of ModelSegments using an old set of inputs (normal/tumor allelic counts and denoised copy ratios for SM-74P4M WES). Behavior has remained largely stable since at least 4.1.0.0. Namely:. 1) We evaluated and signed off on a change that went into 4.1.0.0. See comments in https://github.com/broadinstitute/gatk/pull/5575.; 2) A slight numerical difference in the MCMC-sampled allele fractions was introduced by changes made to some MathUtils code for calculating logs/factorials/etc. between 4.1.0.0 and 4.1.1.0 in https://github.com/broadinstitute/gatk/pull/5814. Note that no CNV code was directly changed, it's just that we call out to that changed MathUtils code---namely, to calculate log10factorial. The overall result in my test was a very slight change to the number of segments found, from 516 to 522.; 3) No further numerical changes have been introduced through the current 4.2.4.1, so any additional code changes I made were indeed true refactors, at least from the perspective of this simple test. Phew!. I was indeed surprised to find that very slight differences in the log10factorial behavior (which result from changing the recursive calculation of cached values to a direct one, and appear in something like the 13th decimal place) led to non-negligible changes in the MCMC estimates of the allele fractions---and thus, changes in the number of segments. Although these are also relatively slight differences in terms of practical impact, they are perhaps much larger than one might guess, given their humble origins.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7649:1434,simpl,simple,1434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7649,1,['simpl'],['simple']
Usability,"Not sure how to get Travis to take up your branch again, so I made a pull request (#1691); https://github.com/broadinstitute/gatk/pull/1691. even though I don't actually intend to merge this yet (it should stay in a separate branch because it changes the repository). To be clear I don't intend to merge it into _main_ yet, but it makes perfect sense to merge it into the _gcs-nio_ branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207071663:274,clear,clear,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207071663,1,['clear'],['clear']
Usability,"Not sure if this is outside the scope of a simple port, but I think it would be great if the fitting of a `GaussianMixtureModel` was made a little bit more generic and extracted. Right now the method `maximizeGaussian` takes in `List<VariantDatum>`, but it should be trivial to refactor it to take in a `double[]` or `List<Double>`. Fitting a GMM could be more generally useful for other methods, after all. It might even be useful to extract the k-means clustering code used to initialize the model, if this is retained in the port. Perhaps also outside the scope, but it'd also be nice if variable names were changed to match the notation in Bishop Ch. 10 (on which the variational-Bayes algorithm is based). I think this would make the code much easier to parse from a mathematical standpoint.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146:43,simpl,simple,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146,2,['simpl'],['simple']
Usability,"Not sure this is ready for a complete review yet, but wanted to get feedback early (not a lot of testing here).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-556364217:68,feedback,feedback,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-556364217,2,['feedback'],['feedback']
Usability,"Not sure what your `GenotypeGVCFs` command was, but did you use the `--genomicsdb-shared-posixfs-optimizations` option? This option is available for the import too and may improve your performance.; ```; --genomicsdb-shared-posixfs-optimizations <Boolean>; Allow for optimizations to improve the usability and performance for shared Posix; Filesystems(e.g. NFS, Lustre). If set, file level locking is disabled and file system; writes are minimized. Default value: false. Possible values: {true, false} ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879779166:296,usab,usability,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879779166,2,['usab'],['usability']
Usability,"Note: this has the ""learn GATK"" label because it is self-contained, but it is not easy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4919#issuecomment-400757635:20,learn,learn,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4919#issuecomment-400757635,2,['learn'],['learn']
Usability,"Now that I've spent a day surveying the landscape of p-values, I'm thinking what must've happened is that an undocumented mid-p-value correction was added to the one-tailed p-value we claim to calculate. This is probably a fine thing to calculate, but such a correction is not discussed in the annotation docs nor in the Wigginton paper cited there. Nor is this what is calculated by any of the other implementations out there, as far as I can tell. So we could keep the original calculation, while further clarifying what exactly we are calculating in the docs (and add references, if appropriate). In this case, we can just keep the cleanup and improved tests as a bonus. (As a further bonus, we won't lose our old friend 3.0103!). Or we could move to this calculation. In this case, I believe we would match the bcftools ExcHet p-value (although I still need to check this claim for correctness). I'm not sure if the original intent was to be more/less conservative in retaining sites during hard filtering prior to VQSR. But since the filtering threshold used in Best Practices seems very conservative, I would guess that we wanted to err on the side of not throwing out possible variants, even if they are pretty out of HWE. Which makes the choice of a mid p-value puzzling, since it's strictly smaller and will thus lead to more rejections (I think, if I've got everything the right way around!). Happy to go either direction. In the end, I have just reaffirmed my dislike for p-values, which I had hitherto thought to be saturated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-893597356:109,undo,undocumented,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-893597356,2,['undo'],['undocumented']
Usability,"Now, it seems like calling `contaminationDownsampling` right after `retainEvidence` could cause problems if both methods remove reads. However, one might correctly point out that although the cache invalidation I mentioned is not handled systematically, the method `removeEvidenceByIndex` _does_ have some code to update the evidence by sample and the evidence index map. It's possible that this code is totally fine and that this lead is a dead end. However, the code looks like it could be simpler and it's tough to parse. For example, try to track the `to` variable, which determines the determination of the outer `for` loop:. ```; for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {; if (etrIndex < evidencesToRemove.length) {; nextIndexToRemove = evidencesToRemove[etrIndex];; evidenceIndex.remove(evidences.get(nextIndexToRemove));; } else {; nextIndexToRemove = oldEvidenceCount;; }; for (; from < nextIndexToRemove; from++) {; final EVIDENCE evidence = evidences.get(from);; evidences.set(to, evidence);; evidenceIndex.put(evidence, to++);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697:492,simpl,simpler,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697,2,['simpl'],['simpler']
Usability,"O LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrien",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2717,Learn,LearnReadOrientationModel,2717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"OK - PedigreeValidationType is now set in the constructor and is final. This does not separate the two intertwined codepaths around PedigreeFile vs. FounderIds, but that was a pre-existing problem. It doesnt doesnt change the pre-existing weirdness around the timing of setting pedigreeFile and/or founderIds within GATKAnnotationPluginDescriptor, where PedigreeAnnotation gets special treatment. I dont think this makes that situation any worse. if you still have concerns on this proposal, I actually think I could make our code work if you simply exposed a protected getPedigreeFile() method on PedigreeAnnotation. I can make the SampleDB instance in my code without needed to share code here. It seemed useful to expose some of that code to avoid duplication, but if it's going to over-complicate we can remove it. Also: that one test failure seems potentially unrelated (https://travis-ci.com/github/broadinstitute/gatk/jobs/510624560)? A compile issue with javadoc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169:543,simpl,simply,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169,2,['simpl'],['simply']
Usability,"OK, great---I'll issue some PRs to delete some of the prototype tools soon and update the spreadsheet accordingly. A non-CNV-specific ""Deprecated"" program group seems reasonable to me if there is enough demand. If this is the only way to delineate the legacy CNV + ACNV pipeline from the new pipeline, I'm OK with it---but we should probably make the situation clear at any workshops, presentations, etc. between now and release that might focus on the legacy pipeline. On a different note, are there any conventions for short names that we should follow?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550:361,clear,clear,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550,2,['clear'],['clear']
Usability,"OK, interesting. This was not entirely clear from the docs. Our cluster in theory is functioning again on monday and we will start these.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656385491:39,clear,clear,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656385491,2,['clear'],['clear']
Usability,"OK, so to be clear - should I press the ""merge"" button?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-248730919:13,clear,clear,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-248730919,2,['clear'],['clear']
Usability,"OK, thanks @droazen. I'll go ahead and expose all of them in a branch for now. For my own education, perhaps @jamesemery or @vruano can comment---does turning on DRAGEN sidestep all or some subset of the code paths where the above 3 sets of parameters come into play?. For what it's worth, now that I'm looking at short variants in malaria as a ""novice"" HC/M2 user, the command line options are quite daunting! Many of them are not well documented and it's not always clear which options might interact with each other. Perhaps once the evaluations are in place, it might be worth doing some model ablation to see if we can come up with a more minimal set of options (including the consolidation of the parameters under discussion, if possible).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593:468,clear,clear,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593,2,['clear'],['clear']
Usability,"OK, thanks for rerunning! I wonder if there are generalizations akin to F-score that would weight sensitivity higher, but the LL score is probably already unfamiliar enough. I think considering that this quantity is the square of the recall of labeled instances over the fraction M_1 / M of overall positive calls may make it more intuitive; we divide by M at some point, but this is balanced by the presence of the proportional M_1. In some sense, we are thus concerned with the relative distribution of labeled instances in the overall score-ordered callset, and less so the overall class balance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170094169:331,intuit,intuitive,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170094169,2,['intuit'],['intuitive']
Usability,"OK, that's reasonable. I'll dig into the other test changes. I can answer a few:. - Regarding passing the VariantWalker: I agree that's not an improvement by itself, but I would argue it's not that much different than it was. My plan is to pass a VariantEvalContext object, which would obscure any need to have knowledge of the walker. In an attempt to keep this PR simpler, I didnt complete that work. I do expect to make a second PR in relatively short order, once we get this resolved. - With respect to testEvalTrackWithoutGenotypesWithSampleFields and the different reference: I think the issue is that the old version (master GATK branch) didnt validate as strictly. When switching to MultiVariantWalkerGroupedOnStart, the reference is required, and the tool will error if the contigs dont match. VariantEval on the master branch didnt really need the reference for anything, and was apparently more permissive if it didnt line up. It probably preferentially grabbed the dictionary from the VCF header. I will look into those other questions",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072:366,simpl,simpler,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072,2,['simpl'],['simpler']
Usability,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:737,clear,clear,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449,2,['clear'],['clear']
Usability,"OK. However, don't forget that the denoising model is fit independently in each block. So introducing too many blocks could cause overfitting, in a sense. Also, you want to make sure that you have enough bins in each block to learn the model. 10k seems safe, but I'd spot check results first if you want to go down to 1k.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615:226,learn,learn,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615,2,['learn'],['learn']
Usability,"ON\_FISHER=0;CSQ=T|stop\_gained|HIGH|PPM1D|ENSG00000170836|Transcript|ENST00000305921.8|protein\_coding|6/6||ENST00000305921.8:c.1384C>T|ENSP ; ; 00000306682.2:p.Gln462Ter|1606|1384|462|Q/\*|Caa/Taa|CM131995&COSV59955543||1||SNV|HGNC|HGNC:9277|YES|NM\_003620.4||1|P1|CCDS11625.1|ENSP00000306682|O15297.184|A ; ; 0A0S2Z4M2.32|UPI0000130FE8|O15297-1||Ensembl||C|C||1||||||||||||||||||||||||||0&1|1&1||||||||MAGLYSLGVSVFSDQGGRKYMEDVTQIVVEPEPTAEEKPSPRRSLSQPLPPRPSPAALPGGEVSGK ; ; GPAVAAREARDPLPDAGASPAPSRCCRRRSSVAFFAVCDGHGGREAAQFAREHLWGFIKKQKGFTSSEPAKVCAAIRKGFLACHLAMWKKLAEWPKTMTGLPSTSGTTASVVIIRGMKMYVAHVGDSGVVLGIQDDPKDDFVRAVEVTQDHKPELPKER ; ; ERIEGLGGSVMNKSGVNRVVWKRPRLTHNGPVRRSTVIDQIPFLAVARALGDLWSYDFFSGEFVVSPEPDTSVHTLDPQKHKYIILGSDGLWNMIPPQDAISMCQDQEEKKYLMGEHGQSCAKMLVNRALGRWRQRMLRADNTSAIVICISPEVDNQGN ; ; FTNEDELYLNLTDSPSYNSQETCVMTPSPCSTPPVKSLEEDPWPRVNSKDHIPALVRSNAFSENFLEVSAEIARENVQGVVIPSKDPEPLEENCAKALTLRIHDSLNNSLPIGLVPTNSTNTVMDQKNLKMSTPGQMKAQEIERTPPTNFKRTLEESNS ; ; GPLMKKHRRNGLSRSSGAQPASLPTTSQRKNSVKLTMRRRLRGQKKIGNPLLHQHRKTVCVC||||||||||||||||||||||||||||||    GT:AD:AF:DP:F1R2:F2R1:SB        0/1:158,5:0.031:163:70,2:79,2:8 ; ; 7,71,3,2. Call (your guys also sequenced this sample for the TCGA since the center is **\-08** TCGA-19-2620-10A-01D-1495-08):. NORMAL=$(samtools view -H $normal\_bam | /usr/bin/perl -nE 'say $1 if /^\\@RG.+\\tSM:(\[ -~\]+)/' | head -n 1) ; ; TUMOR=$(samtools view -H $tumor\_bam | /usr/bin/perl -nE 'say $1 if /^\\@RG.+\\tSM:(\[ -~\]+)/' | head -n 1). /gatk/gatk Mutect2 --java-options ""-Xmx8g"" -O $1 -R $2 -I $3 -tumor ""$TUMOR"" -I $4 -normal ""$NORMAL"" -L $5 --f1r2-tar-gz f1r2.tar.gz #Running Mutect2. /gatk/gatk LearnReadOrientationModel -I f1r2.tar.gz -O artifact.priors.tar.gz. /gatk/gatk FilterMutectCalls --java-options ""-Xmx8g"" -R $2 -V $1 -O $6 -ob-priors artifact.priors.tar.gz #Running FilterMutectCalls on the output vcf.<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/278802'>Zendesk ticket #278802</a>)<br> gz#278802</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7904:4169,Learn,LearnReadOrientationModel,4169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7904,1,['Learn'],['LearnReadOrientationModel']
Usability,Oh!!; I thought GATK on conda was maintained by GATK. My bad. Just learned from this [blog](https://gatkforums.broadinstitute.org/gatk/discussion/11361/installing-gatk4-via-conda). I will install it separately.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955:67,learn,learned,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955,2,['learn'],['learned']
Usability,"Ok -- caveat for all -- objects in bucket that are accessed via simple API Key need to have: User:allUsers:reader ACL permissions. if you need more complex access control, we'll have to support the ""secretFile"" attribute in `gcloud dataproc` -- not just the apiKey.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738:64,simpl,simple,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738,1,['simpl'],['simple']
Usability,"Ok, thanks for the feedback @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411500763:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411500763,2,['feedback'],['feedback']
Usability,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:97,simpl,simple,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008,2,['simpl'],['simple']
Usability,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:256,simpl,simple,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640,2,['simpl'],['simple']
Usability,"On branch `ll_CollectAllelicCountsSpark`, I have created a CLI called: `CollectAllelicCountsSpark` ... This tool will have the exact same functionality as `CollectAllelicCounts`, to the point where I can re-use the integration tests. However, the integration tests fail. When I dig deeper in `CollectAllelicCountsSpark`, I see that only 8 RDDs (correct amount: 11) are being passed to processAlignments... Consider the following code:. ```; @Override; protected void processAlignments(JavaRDD<LocusWalkerContext> rdd, JavaSparkContext ctx) {; final String sampleName = SampleNameUtils.readSampleName(getHeaderForReads());; final SampleMetadata sampleMetadata = new SimpleSampleMetadata(sampleName);; final Broadcast<SampleMetadata> sampleMetadataBroadcast = ctx.broadcast(sampleMetadata);. final AllelicCountCollector finalAllelicCountCollector =; rdd.mapPartitions(distributedCount(sampleMetadataBroadcast.getValue(), minimumBaseQuality)); .reduce((a1, a2) -> combineAllelicCountCollectors(a1, a2, sampleMetadataBroadcast.getValue()));; final List<LocusWalkerContext> tmp = rdd.collect();; ....snip....; ```. In this case `tmp` will have a size of 8. However, the integration test would indicate a size of 11 is correct, since 11 intervals are being passed in. Note that `emitEmptyLoci()` returns `true`, so 11 is the correct number as seen in `CollectAllelicCountsSparkIntegrationTest` . . Additionally, in (at least) one result, the counts are wrong. `CollectAllelicCounts` (non-spark) passes the integration test. I have tried a couple of tests to gather more information:. - Is `emitEmptyLoci()` causing an issue? ; Does not appear to be causing the issue. I say this because when set to `false`, I get (essentially) the same error.; - The code uses `mapPartition` and not `map`, does this cause the issue? Why are you doing this?; This does not cause the issue. I refactored the code to use `map` and got the exact same issue. I use `mapPartition` in order to instantiate only one instance of `A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3823:665,Simpl,SimpleSampleMetadata,665,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3823,1,['Simpl'],['SimpleSampleMetadata']
Usability,"On second thought -- to simplify the merge to master we may take a different approach (copying files, squashing, etc) so I'm updating the approach above for this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7260#issuecomment-844179537:24,simpl,simplify,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7260#issuecomment-844179537,2,['simpl'],['simplify']
Usability,On second thought there is an incredibly simple solution that R uses by including everything past 10e-7 as equal or more extreme.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2586#issuecomment-297757830:41,simpl,simple,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2586#issuecomment-297757830,2,['simpl'],['simple']
Usability,"On the first question, we definitely appreciate how much work this will take. Often, porting the code is the easy part; developing new tests and test data can be a huge effort. I can try to find out if it would be possible for you to take the tool over - I know this kind of thing has come up before for other tools, but I'd have to ask around to find that out. @vdauwera do you have input on this ?. As for the plugins, currently in your branch `VariantStratification` and `VariantEvaluator` are modeled as Barclay command line plugin descriptors, and I was questioning whether thats necessary. Being a plugin is not necessarily required - `ReadFilter` and `Annotation` are both plugins, but they didn't have to be, and it takes quite a bit of work (again, mostly test development) to get a plugin right. Also, I'd consider the Barclay plugin framework to be pretty developed at this point, so I'd be curious to learn more about what issues you see. And yes, definitely don't check any of the large GATK3 test files into the repo, even temporarily. Take a look at [General guidelines for GATK4 developers](https://github.com/broadinstitute/gatk#dev_guidelines) if you haven't already. As you pointed out, new GATK4 tests that use smaller files would have to be developed. We'd want those to be included, and passing tests on the CI server, before we started reviewing the branch, so we know we're reviewing code that works and is covered by tests as much as possible. The second commit in my list above would have only your GATK3 java test files, etc (but not the big files, which you appear to have locally). The third commit would have your ported tool code, as well as the new test code, with the new tests enabled, as well as the smaller input files and expected results files. At the end we'd remove commit #2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633:913,learn,learn,913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633,4,"['guid', 'learn']","['guidelines', 'learn']"
Usability,"On the general comment of this class being too big: I totally agree.; I haven't figured out how to make Java in this semi-functional style pretty. I could certainly pull a mess of nested classes out into top-level classes just to make the file smaller. But most of them are so specific to their use in this program that they wouldn't really be useful outside this context. I'll probably do just that, but it's not clear to me that it makes the program more comprehensible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285411154:414,clear,clear,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285411154,2,['clear'],['clear']
Usability,"Once https://github.com/broadinstitute/gatk/pull/2389 is merged, we need to make a simple PR against the tool to allow it to work with NIO, and add a GCS-based test case. This should be an easy change and < 1 day of work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2608:83,simpl,simple,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2608,1,['simpl'],['simple']
Usability,"Once we have implement junction trees on `SeqGraph`s we will need a reasonable heuristic for handling bases in reads that have been pruned from the graph. For example, upon finding a mismatch between a read and a `SeqVertex` we might scan for the next kmer in the read that matches some `SeqVertex` and simply proceed from there. Or we might only do so if the matching vertex is either the current `SeqVertex` or one of its edge targets etc.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5924:303,simpl,simply,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5924,1,['simpl'],['simply']
Usability,"Once we have support for the necessary formats (https://github.com/broadinstitute/gatk/issues/3277, https://github.com/broadinstitute/gatk/issues/3278, https://github.com/broadinstitute/gatk/issues/3279), implement a simple, non-Spark prototype functional annotator just to check that everything is working. Ie., implement something approximating the ""main loop"" of the Oncotator tool:. ```; for each mutation; 	for each datasource compatible with your reference; 		annotate; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3283:217,simpl,simple,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3283,1,['simpl'],['simple']
Usability,"One more DepthOfCoverage observation. The GATK4 version let's one control the delimiter in the output, which seems like a useful idea. However:. 1) this isnt that big a deal, but why change the GATK3 default of tab to comma in GATK4?. 2) The enum is named CSV and TABLE. Why not rename 'TABLE' to 'TSV' to make it more clear? A comma-delimited table is still a table. This is a beta tool now, and I assume with the next release changing an argument becomes harder.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6623:319,clear,clear,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6623,1,['clear'],['clear']
Usability,"One note that might be useful (or known already to the team): simply calling `cache()` doesn't cause any action. It seems that one might need to force the computation to be done on the RDD (e.g. `count()`), for caching to work, if the predicate depends on the results of computation. (ref last comment in #1877)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823:62,simpl,simply,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823,1,['simpl'],['simply']
Usability,"One of our goals for alpha (https://github.com/broadinstitute/gatk/issues/961) is actually to wrap `spark-submit` and its many options to make it easier to run hellbender tools on spark. We want users to be able to type a simple command like `./hellbender ToolName [toolArgs] --sparkMaster X`, and have hellbender figure out whether to invoke `spark-submit` or `gcloud dataproc` on their behalf, and provide sensible defaults for all relevant spark options. . Perhaps there is a way in `SparkCommandLineProgram` to detect whether an option has already been set externally, and allow the default to be overridden if it has been?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633:222,simpl,simple,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633,1,['simpl'],['simple']
Usability,One of the issues:. [Utils] [ERROR] [Error] java.lang.IllegalArgumentException: Invalid interval. Contig:1 start:350001 end:300000; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.&lt;init&gt;(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.copynumber.utils.annotatedinterval.AnnotatedIntervalUtilsUnitTest.provideMergeByAnnotation(AnnotatedIntervalUtilsUnitTest.java:215); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:55); 	at org.testng.internal.MethodInvocationHelper.invokeMethodNoCheckedException(MethodInvocationHelper.java:45); 	at org.testng.internal.MethodInvocationHelper.invokeDataProvider(MethodInvocationHelper.java:115); 	at org.testng.internal.Parameters.handleParameters(Parameters.java:509); 	at org.testng.internal.Invoker.handleParameters(Invoker.java:1308); 	at org.testng.internal.Invoker.createParameters(Invoker.java:1036); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1126); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:126); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-431874410:247,Simpl,SimpleInterval,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-431874410,4,['Simpl'],['SimpleInterval']
Usability,One of the most important filters in Mutect2 is the STR / polymerase slippage filter. It has some hard-coded parameters of PCR slippage rates as a function of STR repeat unit and length. We could probably increase indel sensitivity a lot (decrease filtered false negatives) by learning a model for each bam.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5531:277,learn,learning,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5531,1,['learn'],['learning']
Usability,"One very simple way to do this would be for `GenotypeGVCFs` to simply invoke `CombineGVCFs` directly upon initialization when multiple inputs are specified. We should consider doing this as a quick way of restoring this functionality, as several users have requested this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2584#issuecomment-381198194:9,simpl,simple,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2584#issuecomment-381198194,4,['simpl'],"['simple', 'simply']"
Usability,"Oops, did not realize that CRAM support required special treatment of the reference. This only needs to be added as an input to the CollectFragmentCounts task, then, correct? Why are the changes to the CreateReadCountPanelOfNormals task needed?. More generally, if we are aiming to support CRAMs passed via -I in all relevant GATKTools/walkers, then this is probably something that should be added to the WDL style guide. I guess it’d be overkill to make the reference required for these on the Java side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965:415,guid,guide,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965,2,['guid'],['guide']
Usability,"Oops, looks like they just updated the URL last week. Perhaps another reason why we should host these dependencies or have some simple contingencies for testing them other than manually building the base image.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3712:128,simpl,simple,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712,1,['simpl'],['simple']
Usability,Opened https://github.com/broadinstitute/GATKZendesk/pull/2 to resurrect this old article (source: https://web.archive.org/web/20160415213604/https://www.broadinstitute.org/gatk/guide/article?id=1328). I updated the article text and command lines for the modern era.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330:178,guid,guide,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330,2,['guid'],['guide']
Usability,"Or maybe I'm confused and the user can get either/or, based on the wdl? It wasn't very clear either way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592:87,clear,clear,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592,2,['clear'],['clear']
Usability,Originally by @vruano . Currently the dangling head and tail recovery algorithm only handle simple paths without furcations from the dangling source/sink vertex and the reference path. . However some variation that fail in complex dangling subgraphs can be lost. For example. https://www.pivotaltracker.com/story/show/80381400 ; So this story is about implementing an improved algorithm to handle these cases.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/266:92,simpl,simple,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/266,1,['simpl'],['simple']
Usability,"Originally reported as https://github.com/broadinstitute/gatk-tool-wdls/issues/1. Tracking this here until we figure out the governance and permissions for the [gatk-tool-wdls](https://github.com/broadinstitute/gatk-tool-wdls/) repo:. For example in CombineGVCFs.wdl one can see indexOutput as optional input argument:. ```; # Required Arguments; String output_arg; String? outputIndex; ```; (first of all, outputIndex is not required, since it's a String?....but this is semantics). but more importantly, this argument (a String) is not used in the command section, which simply reads. ```; ~{gatk} CombineGVCFs \; --output ~{sep=' --output ' output_arg} \; --reference ~{sep=' --reference ' reference} \; --variant ~{sep=' --variant ' variant} \; ```; and the where is does appear is in the output section where the String? is converted to a File?. ```; File? CombineGVCFs_outputIndex = outputIndex; ```; which effectively means that the user needs to know in advance what will be the name of the index that is generated, if they want to delocalize it. This seems to be cumbersome. I would think that a tool that generates an index should be able to figure out the name of this index and provide it to the user rather then expect the user to know the name. I understand that there are idx/tbi issues, but these are issues we should tackle, rather than leave them to the user to tackle. Can write a small GATK/htsjdk commandline tool that for every filename provides the name of its natural index, and call to that in order to find the name of the index...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6984:573,simpl,simply,573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6984,1,['simpl'],['simply']
Usability,"Otherwise, when json is refreshed, contents of the file are different, hash of the file is different, and call-caching will not register a match, despite the same ""account"" being used. - changed input type from `File` to `String`; - changed the name to make it more obvious/clear. Closes https://github.com/broadinstitute/dsp-spec-ops/issues/327",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7347:274,clear,clear,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7347,1,['clear'],['clear']
Usability,"Our goal is to have the combination step for allele-specific annotations handled by TileDB, but we should still port this code to GATK4 for the following reasons:. -We can likely simplify the code greatly, reducing it down to the three cases of List concatenation, sum, and contingency table combination, making it easier for Intel to replicate in TileDB. -It will be good to have a non-TileDB way to combine gvcfs as a model implementation and fallback option.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1893:179,simpl,simplify,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1893,1,['simpl'],['simplify']
Usability,"Overall this looks good to me. I've added a few comments inline. Note that I haven't reviewed for style particularly, or consistency with the existing codebase. > 5) There are unit tests for all code except for the skeleton itself. This could be as simple as a Spark variant of `ReadsPreprocessingPipelineIntegrationTest`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/850#issuecomment-134164842:249,simpl,simple,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850#issuecomment-134164842,1,['simpl'],['simple']
Usability,"Overall, this looks fine, just a few minor comments. Two broader questions/issues:; - Does the test data exercise all of the code paths and edge cases?; - In general, putting the majority of testing in integration tests instead of unit tests is bad pattern. It have several bad consequences (1) it becomes less clear which cases are being tested (2) it's slower than just running unit tests and (3) it makes it unhelpful to (perhaps someday) move to a testing framework that only runs tests relevant to the code directly affected (because all integration tests must be run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490:311,clear,clear,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490,1,['clear'],['clear']
Usability,"PR Punts:. - [ ] Profile and check whether interning of resource labels in the LabeledVariantAnnotationsWalker affects memory or runtime. Unfortunately, I can't remember why I added this, but maybe I had a good reason. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933375971.; - [ ] Consider writing allele-specific scores and/or different strategies for consolidating to a site-level score. The current strategy of simply taking allele with the max score (across SNPs/INDELs for mixed sites, to boot) is borrowed from ApplyVQSR. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933570228.; - [ ] Add behavior for dealing with mixed SNP/INDEL sites in separate passes (and note that the current WDL currently does this, to allow for the use of different annotations across SNPs and INDELs). This might include rescuing previously filtered sites, etc. (e.g., by using the option to ignore the first-pass filter in the second pass). Alternatively, one could use a different FILTER name in each pass, which downstream hard-filtering steps could utilize intelligently. Or one might just split multiallelics upstream. In any case, I would hope that we could move towards running both SNPs and INDELs in a single pass with the same annotations as the default mode of operation.; - [ ] Clean up borrowed code in the `VariantType` class for classifying sites as SNP or INDEL. We mostly retained the VQSR code and logic to make head-to-head comparisons easier. Note also that we converted some switch statements to conditionals, etc. (which I think was done properly, but maybe I missed an edge case). See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934776584.; - [ ] Think more about how to treat empty HDF5 arrays. It's possible we should handle this at the WDL level with optional inputs/outputs. Likely only relevant for atypical edge cases. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934845337. Next steps:. - [ ] I'll update the B",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008:435,simpl,simply,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008,2,['simpl'],['simply']
Usability,PRs like https://github.com/broadinstitute/gatk/pull/2156 make it clear that we need some master configuration mechanism in the GATK that can be overridden by clients/downstream projects. . One promising option is `commons-configuration` (https://commons.apache.org/proper/commons-configuration/userguide/user_guide.html) using properties files -- we should look into this to see whether it does what we want.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2297:66,clear,clear,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2297,1,['clear'],['clear']
Usability,"Part of road map laid out in #4111 . ## Consolidate logic, update variant representation (PR#4663) . ### consolidate logic in the following classes. - [x] `AssemblyContigAlignmentSignatureClassifier` now gone, its inner enum class `RawTypes` is moved to `AssemblyContigWithFineTunedAlignments.AlignmentSignatureBasicTypes` and reduced into fewer cases (`Suspicious`, `Simple` and `Complex`). - [x] static method `BreakpointsInference.inferFromSimpleChimera()` now moved to state query method `ChimericAlignment.inferType()`. - [x] `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` merged with `ChimericAlignment.hasIncompletePicture()`. ### update how variants are represented. - [x] change `SVLEN` for `CPX` variants to the difference between _[alt haplotype sequence length]_ and _[affected reference region length]_, which is following the technical definition of `SVLEN` in VCF spec. - [x] change `RPL` output to one of these (note that test coverage is expected); - [x] ins/del, when del/ins bases are < 50 and annotate; when type is determined as ins, the POS will be 1 base before the micro-deleted range and END will be end of the micro-deleted range, where the REF allele will be the corresponding reference bases.; - [x] ins and del when both are >= 50, and link by `EVENT`. - [x] change `SVTYPE=DUP` to`SVYTPE=INS` when the duplicated region is shorter than 50 bp (tests). Note that this will lead to `INS` records with `DUP_REPEAT_UNIT_REF_SPAN` and `DUP_SEQ_CIGARS` (when available). In addition, we are currently treating duplication expansion as insertion. ; The VCF spec doesn't force `DUP` records as such.; If we decide to allow `POS` and `END` to designate the beginning and end of the duplicated reference region, we need to make at least the following change:. - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663:368,Simpl,Simple,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663,1,['Simpl'],['Simple']
Usability,PathSeq Illumina adapter trimming and simple repeat masking,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354,2,['simpl'],['simple']
Usability,"PathSeqFilterSpark and PathSeqPipelineSpark clear all the sequences from the input header file, as the Bwa step only accepts unaligned reads. However, the header sequences were being cleared before the reads were loaded, causing WellformedReadFilter to remove any mapped reads (by failing to find the corresponding sequence name in the header). This PR fixes this bug by creating a deep copy of the header. It also refactors this code, which is used in both the Filter and Pipeline tools, into a utility function `checkAndClearHeaderSequences()` in PSUtils. Tests have also been added/updated accordingly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3453:44,clear,clear,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3453,2,['clear'],"['clear', 'cleared']"
Usability,"Perhaps related to #7185. It is not clear to me why min or median would be options, rather than GenotypeGVCFs simply getting the actual correct DP from each sample's GVCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9007#issuecomment-2420589421:36,clear,clear,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9007#issuecomment-2420589421,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,Picard CollectMultipleMetrics's goal is to avoid reading the file multiple times. In dataflow this should be simple - compute metrics independently from the same pcollection of reads. We need a generic way of doing it and a specific example that implements CollectMultipleMetrics's functionality,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/398:109,simpl,simple,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/398,1,['simpl'],['simple']
Usability,Pinging @tedsharpe who gave feedback on the above thread,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1775300469:28,feedback,feedback,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1775300469,2,['feedback'],['feedback']
Usability,Please make this option hidden if it's only being kept for testing purposes (and document clearly that that is the case). Users should not have access to options that are not expected to have value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338:90,clear,clearly,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338,2,['clear'],['clearly']
Usability,"Please review for the overall structure/design for adding support for allele specific filters in the info field. I'm learning more and more about what I can do with streams. If you have suggestions, especially better alternatives please let me know.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6290:117,learn,learning,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6290,1,['learn'],['learning']
Usability,"Posting at the suggetion of shlee. There's discussion about what parts of VariantEval will be ported to GATK4 or whether Picard's partially overlapping tool CollectVariantCallingMetrics will take this over. I want to at least make you aware that we've developed a tool we're calling VariantQC, which is built in GATK3 and runs VariantEval internally to generate data stratified in various ways to make HTML QC reports, sorta like FASTQC or MultiQC (https://github.com/bbimber/gatk-protected/releases). An example report is here: https://prime-seq.ohsu.edu/_webdav/Internal/Bimber/Public/%40files/VariantQC_Example.html. Our goal was always to port this to GATK4, polish it up, and then make it more generally available. Much of what this tool does is take the pre-built tables/reports from VariantEval and put them into HTML, but we also wrote some custom stratifications to bin data by filter, etc. Like this thread notes, VariantEval has a lot of features not in picard, and honestly we dont use many of them. However, the extensibility of Stratifier/VariantEvaluator are pretty important for us. . We realize this is prioritized against all the GATK4 features; however, 1) how set are plans about migration of VariantEval/merge w/ picard and 2) if most of VariantEval isnt going to be ported, can we pick it up in our repo? We could also potentially offer some assistance in porting the tool because we have a vested interest; however, unless the task is defined as porting VariantEval as close as possible to as-is (not that this is critical, but it's the simplest thing for the outsider to do), it would need some discussion around exactly what's planned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252:1560,simpl,simplest,1560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252,1,['simpl'],['simplest']
Usability,"Posting issue on @cmnbroad's request. . I see this stacktrace of a WARN for some GATK tools. The tools proceed to run successfully. For example, LearnReadOrientationModel gives this. I've been preparing for the GATK workshop and have been running a variety of tools. . For this particular message, I am running GATK v4.0.11.0 locally on my Mac laptop, in the 4.0.11.0 Docker. How can I deal with this WARN?. ```; (gatk) root@3231a24c7afb:/gatk/my_data/3-somatic# gatk LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O tumor-artifact-prior-table.tsv ; Using GATK jar /gatk/gatk-package-4.0.11.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.0.11.0-local.jar LearnReadOrientationModel -alt-table 13_tumor-alt.tsv -ref-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O tumor-artifact-prior-table.tsv; 16:20:57.885 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 26, 2018 4:20:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(H",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:145,Learn,LearnReadOrientationModel,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,3,['Learn'],['LearnReadOrientationModel']
Usability,"Prior to assembly (in `AssemblyBasedCallerUtils.assembleReads`, we transform reads in several ways that are meant to be permanent (that is, we want to use them in both assembly and genotyping) within `finalizeRegion`. (Additionally, we error reads within `ReadThreadingAssembler.runLocalAssembly`, but this is done on temporary copies of reads that are used for kmers and discarded). These transformations include hard clipping low-quality ends, adaptor sequences, and, optionally, soft-clipped bases, as well as correcting the base qualities of overlapping mates. According to the git history, these transformations have been accidentally temporary for quite a while. Let's look at the relevant code. First, in `Mutect2Engine.callRegion` we have (comments added and code simplified for clarity). ```; final AssemblyRegion assemblyActiveRegion = AssemblyBasedCallerUtils.assemblyRegionWithWellMappedReads(originalAssemblyRegion . . .);. // assembleReads finalizes region, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6686:772,simpl,simplified,772,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686,1,['simpl'],['simplified']
Usability,"Profile and optimize simple read walkers: PrintReads, CountReads",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1034:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1034,2,['simpl'],['simple']
Usability,"Prototype a PythonScriptExecutor, and assess maintainability of an example tool that calls into a Python machine-learning library",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:113,learn,learning,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,2,['learn'],['learning']
Usability,R1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0.000% <0.000%> (-94.737%)` | :arrow_down: |; | [...ellbender/utils/bigquery/StorageAPIAvroReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9iaWdxdWVyeS9TdG9yYWdlQVBJQXZyb1JlYWRlci5qYXZh) | `0.000% <0.000%> (-78.571%)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `2.970% <0.000%> (-71.287%)` | :arrow_down: |; | [...nder/utils/codecs/copynumber/SimpleCountCodec.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MvY29weW51bWJlci9TaW1wbGVDb3VudENvZGVjLmphdmE=) | `21.875% <0.000%> (-53.125%)` | :arrow_down: |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17.085% <0.000%> (-52.764%)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/7810/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7810#issuecomment-1109049263:3014,Simpl,SimpleCountCodec,3014,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7810#issuecomment-1109049263,1,['Simpl'],['SimpleCountCodec']
Usability,"Ran into this when trying to create a PoN with 100 samples x 100 bp bins = 1.27 * max int elements. This currently causes issues when truncating outliers, at which point all elements are loaded into an array so that Percentiles can be naively computed, resulting in a `java.lang.NegativeArraySizeException`. Solutions include: 1) simply throwing a message and failing early if the counts matrix is too large (perhaps recommend scattering by contig, see #4728), 2) changing the outlier truncation procedure to be more robust. I'm not sure how important outlier truncation is to the SVD, as it remains to be evaluated, but for now we should be able to get around this with no code changes by simply disabling it (i.e., setting the relevant truncation percentile to 0). Note that file I/O takes about an hour for this case. Also note that this is probably on the extreme end of what we should expect to support on a single machine with all counts in memory, as the SVD is probably sufficiently good with 100 samples and 100 bp is on the order of the read length. #4728 will get around this and also make downstream tasks complete faster in parallel, at the very small expense of reducing a few global parameters to per-contig parameters in the modeling step.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4734:330,simpl,simply,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4734,2,['simpl'],['simply']
Usability,"Rationale for engine changes:; This tool opens a large number of feature files (TSVs, not VariantContexts) and iterates over them simultaneously. No querying, just a single pass through each.; Issue 1: When a feature file lives in the cloud, it takes unacceptably long (several seconds, typically) to initialize it. A few seconds doesn't seem like a long time, but when there are large numbers of feature files to open, it adds up. This is caused by a large number of codecs (mostly the vcf-processing codecs) opening and reading the first few bytes of the file in the canDecode method. To avoid this I've reversed the order in which we test each codec, checking first if it produces the correct subtype of Feature, and only then calling canDecode. If you don't know what specific subtype you need, you can just ask for any Feature by passing Feature.class. It's much faster that way.; Issue 2: Each open feature source soaks up a huge amount of memory. That's because text-based feature reading is optimized for VCFs, which can have enormously long lines. So huge buffers are allocated. The problem is compounded for cloud-based feature files for which we allocate a large cloud prefetch buffer. (Though that feature can be turned off, which helps a little.) But the biggest memory hog is the TabixReader, which always reads in the index, regardless of whether it's used or not. Tabix indices are very large. To avoid this, I've created a smaller, simpler FeatureReader subclass called a TextFeatureReader that loads the index only when necessary. The revisions allow the new tool to run using an order of magnitude less memory. Faster, too.; Issue 3: The code in FeatureDataSource that creates a FeatureReader is brittle, and tests for various subclasses. To allow use of the new TextFeatureReader, I added a FeatureReaderFactory interface that allows one to ask the codec for an appropriate FeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770:1449,simpl,simpler,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770,2,['simpl'],['simpler']
Usability,"Re-assigning to @tomwhite as a possible future project, since he has a clear idea of how this could be implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1644#issuecomment-288515251:71,clear,clear,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1644#issuecomment-288515251,1,['clear'],['clear']
Usability,Re-runs with PR feedback incorporated:. - [Integration](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/e8b6077d-a90a-4cc2-be0d-0a08cb98280a); - [Beta](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/52a3c02e-485b-4320-bb21-07931ecbe7dd),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023,2,['feedback'],['feedback']
Usability,Re-worded the title and description to make it clear that the call in question is happening in the constructor for `GenomicsDBImporter` (`GenomicsDBImporter` line 464),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2714#issuecomment-301542931:47,clear,clear,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2714#issuecomment-301542931,2,['clear'],['clear']
Usability,"Readme packaged with the jars should be more user-friendly, omit dev instructions such as how to compile (since the package by definition does not include source code) and start right away with quickstart instructions:. - how to run ; - where to find docs; - where to get help. Could be largely lifted from http://gatkforums.broadinstitute.org/gatk/discussion/9881/howto-get-started-with-gatk4-beta",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3199:45,user-friendly,user-friendly,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199,1,['user-friendly'],['user-friendly']
Usability,"Ready for second pass review, @lbergelson. Now the implementation is much more simple than the previous one, and I added unit tests for the codec.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224670233:79,simpl,simple,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224670233,1,['simpl'],['simple']
Usability,"Recently I was setting up GATK to run in a VM and I had forgotten to install Java8 onto the machine. When I tried to run GATK from the launch script I ran into the following error: ; ```; Using GATK jar /home/emeryj/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/emeryj/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar -help; Traceback (most recent call last):; File ""./gatk"", line 479, in <module>; main(sys.argv[1:]); File ""./gatk"", line 152, in main; runGATK(sparkRunner, sparkSubmitCommand, dryRun, gatkArgs, sparkArgs, javaOptions); File ""./gatk"", line 328, in runGATK; runCommand(cmd, dryrun); File ""./gatk"", line 384, in runCommand; check_call(cmd, env=gatk_env); File ""/usr/lib/python2.7/subprocess.py"", line 181, in check_call; retcode = call(*popenargs, **kwargs); File ""/usr/lib/python2.7/subprocess.py"", line 168, in call; return Popen(*popenargs, **kwargs).wait(); File ""/usr/lib/python2.7/subprocess.py"", line 390, in __init__; errread, errwrite); File ""/usr/lib/python2.7/subprocess.py"", line 1024, in _execute_child; raise child_exception; OSError: [Errno 2] No such file or directory; ```; This should perhaps be made a little bit clearer for users as this isn't particularly helpful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5992:1322,clear,clearer,1322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5992,1,['clear'],['clearer']
Usability,"Recently added SV tools including SVConcordance and SVCluster make use of VariantContext's `getStructuralVariantType()` method, which returns a `StructuralVariantType` enum. This causes the tools to crash with some VCFs, such as those produced by gatk-sv where some SVTYPE values are `CPX` or `CTX`, which are non-standard. In practice, it will be useful allow these types to be ingested, which could be done by simply using the standard attribute getter rather than than `getStructuralVariantType()`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8033:412,simpl,simply,412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8033,1,['simpl'],['simply']
Usability,Recently for Mutect a new class of `JumboInfoFieldAnnotations` and `JumboGenotypeAnntations` were introduced into GATK and their names are somewhat misleading and confusing on first pass. I would suggest renaming them to `FragmentAnnotations` or something that more accurately describes what they are using. . Furthermore given the state of the annotation engine and the type system nightmare that lurks beneath the surface it is quite difficult to use these annotations in any context except when the likelihoods have been computed in terms of fragments which can be a non-trivial conversion that shouldn't happen in every case. We should revisit the types for this whole class and find some way to make these annotations more usable outside of mutect.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7543:728,usab,usable,728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7543,1,['usab'],['usable']
Usability,"Refactoring of the structs and utilities involved calling simple inversions.; This helps preparing for calling simple insertions and deletions in SV.; Most changes are simple changes, no changes are made to the algorithm itself.; A simple fix of orginal code in `AlignmentRegion` was put in.; Major re-engineering of `getVariantContextForBreakpointAlleleAlignmentList()` in caller was done and explained in the temporary comment that will be removed after review is done. @cwhelan would you please review? Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258:58,simpl,simple,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258,4,['simpl'],['simple']
Usability,Reference requirements for intervals could be more clear,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4507:51,clear,clear,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4507,2,['clear'],['clear']
Usability,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:157,clear,cleared,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441,2,['clear'],['cleared']
Usability,Remove SimpleIntervalTestFactory (unused),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4664:7,Simpl,SimpleIntervalTestFactory,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4664,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,Remove TargetsToolsTestUtils/SimpleIntervalTestFactory,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3771:29,Simpl,SimpleIntervalTestFactory,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3771,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,"Removed the `splitContextByReadGroup()`, simplified methods and testing exception thrown by `splitBySample()`. Back to you for review again, @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-219648141:41,simpl,simplified,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-219648141,1,['simpl'],['simplified']
Usability,Removed undocumented mid-p correction to p-values in exact test of Hardy-Weinberg equilibrium and updated corresponding tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394:8,undo,undocumented,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394,2,['undo'],['undocumented']
Usability,Rename WordCount to make it clear that it is an example program.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/537:28,clear,clear,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/537,2,['clear'],['clear']
Usability,"Renamed ExonCollection, use Locatable instead of SimpleInterval, and add two methods",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/767:49,Simpl,SimpleInterval,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/767,1,['Simpl'],['SimpleInterval']
Usability,"Reopening. It was hard to see due to the in-house cluster being used by multiple people. On a private cluster on GSC, the difference is clear - MarkDuplicatesSpark goes from 7.4 minutes to 6.6-6.7 minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-212155764:136,clear,clear,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-212155764,1,['clear'],['clear']
Usability,Request: provide some guidance on various perf-modulating options,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3648:22,guid,guidance,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3648,2,['guid'],['guidance']
Usability,"Requested by support team. Follow-up to https://github.com/broadinstitute/dsde-docs/issues/526. `--forceValidOutput` is an argument to SelectVariants (in GATK3) that forces its walker to completely unpack the information in the VariantContext (which holds all the annotations) then re-pack it using the underlying HTSJDK functions, which are usually fully spec-compliant. This is useful when dealing with older VCFs that have some annotations formatted in a way that violates later versions of the spec, since running the VCF through the tool with this flag effectively converts the VCF to spec compliance. This unpacking and repacking can't be done by default because it impacts performance, which is why we need an option to make it happen. . This issue comprises two points to address:; 1. Make the argument usable by all walkers that read and write VCFs (SelectVariants, CombineVariants, VariantFiltration, any others I may have omitted), if possible by promoting it to an engine-level argument.; 2. Ensure that it can be applied by SelectVariants even when there is no subsetting happening. When I checked the (GATK3) code, this comment (which comes before where that work gets done) suggested it might only do the job when you are subsetting samples out of a VCF:; ; `//If no subsetting happened, exit now`; ; This is not actually the desired behavior since you should be able to use this to convert an old VCF to be spec-compliant without having to subset anything. But I could have misread the code. Once this is done, please let me know and make a note in gsa-unstable to have this backported to GATK3.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1483:811,usab,usable,811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1483,1,['usab'],['usable']
Usability,Requested guidance (in a different ticket) on how this works when running locally.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077:10,guid,guidance,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077,2,['guid'],['guidance']
Usability,"Researcher reports a discrepancy in code comments (two occasions) vs. what is actually implemented in the code. The concern is that pairHMM actually performs global alignment (Durbin Figure 4.2) but the code comments indicate local alignment and Durbin Figure 4.3. . ---; Hello, thank you for your reply.; The algorithm is clear to me, from what I read of the code it is effectively the right of figure 4.1 (or 4.2 without the start and end states for simplicity) that is used and not 4.3. Therefore my concern, the comments in the source code clearly state that 4.3 is used and that it is local alignment, while the code in fact does global alignment. It makes more sense to do global alignment (sequence to sequence, like Needleman-Wunsch) and this is what the codes seems to do (does). Thank you for your answer. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/54930#Comment_54930",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5529:323,clear,clear,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5529,3,"['clear', 'simpl']","['clear', 'clearly', 'simplicity']"
Usability,"Resolves https://github.com/broadinstitute/dsp-spec-ops/issues/239. See README.md in this PR for full details. ----; To make this easier to review, the changes break down into a few sections. 1. Docs -- the README.md. Does it make sense? Could you follow it?. 2. Comparison Script (compare_data.py)-- is it clear? Obvs any bugs would be great. The Github Issue for this PR describes _what_ is compared. 3. WDL changes -- should be straightforward to review, just minor changes; ; 4. Code changes (java) -- we can walk through this together if that's more effective",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7106:307,clear,clear,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7106,1,['clear'],['clear']
Usability,"Results are in:. Using the branch for PR #4971 with the value `ALIGNMENT_LOW_READ_UNIQUENESS_THRESHOLD` set to 10 and 19, while keeping the gap split children together (that is, method ; `private static GoodAndBadMappings splitGaps(final GoodAndBadMappings configuration, final boolean keepSplitChildrenTogether)` is called with `false` for its second parameter). Here are the comparisons:; ```; simple variants unique TP unique FP; size-10 filter: 10756 24 101; size-19 filter: 10755 1 0; ```. So I think your suggestion is a better trade off!. What I'll do is make that parameter an (advanced) CLI argument in PR #4971 , and experiment more to settle on a good default value.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890:396,simpl,simple,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890,2,['simpl'],['simple']
Usability,"Returning false instead of throwing when data is missing in the `GoogleGenomicsReadToGATKReadAdapter` is misleading -- we don't know the answer to the question the client is asking in such cases, so returning false is not correct behavior. If these fields are actually missing in the underlying reads we really do want to blow up with an exception on access, as it means the read object is not usable by us (and the query that produced these incomplete objects likely needs to be modified). Could you restore the previous versions of these methods (`isSecondaryAlignment()`, `isDuplicate()`, etc.) before I review?. As for the Google read converters, could you open a separate ticket with your description of the inconsistencies so we can decide whether to submit a patch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148:394,usab,usable,394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148,1,['usab'],['usable']
Usability,Revert htsjdk clearOptions workaround in createVCFWriter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1274:14,clear,clearOptions,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1274,2,['clear'],['clearOptions']
Usability,"Reverts the reversion in #5225, this time addressing the lexicographical ordering issue in #5217 at the WDL level by simply renaming gCNV output at the command line. If desired, we can eventually change gCNV itself to output filenames that are robust against lexicographic ordering, but this is low priority in my opinion. @vruano this is what we discussed last week. Tests pass on Travis, and I'm pretty sure this fix should work OK, but I have not done an actual run with enough samples to see the fix in action. Can I assign you to review once I get a chance to do this?. EDIT: Also went ahead and rolled an older PR #5304 into this one so I can test both at the same time. Closes #4724.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5490:117,simpl,simply,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5490,1,['simpl'],['simply']
Usability,"Right @sooheelee, the template is certainly useful for that, but can just as easily be generated using `wdltool inputs`. Whatever you and @davidbenjamin decide, let me know if I should add the CNV templates back to be consistent. (But again, my vote is for removing the M2 template!). @LeeTL1220 can add whatever we decide about optional string type args to the style guide, but I'd prefer for this sort of thing to be automatically generated (#2480).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099:368,guid,guide,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099,2,['guid'],['guide']
Usability,"Right now we don't generate any annotations if `do_explicit_gc_correction = False`, which affects mappability filtering. Note that gCNV will automatically model GC bias if annotated intervals are passed to it. We should probably always perform annotation and filtering (the latter can be made essentially optional by simply changing the filtering parameters), and then instead optionally pass the annotated intervals to gCNV. This should mean that all tasks will always be run, as opposed to the current behavior.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6228:317,simpl,simply,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6228,1,['simpl'],['simply']
Usability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=footer). Last update [92cb860...6737d16](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034:4906,learn,learn,4906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034,2,['learn'],['learn']
Usability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=footer). Last update [dfa9cf1...f539662](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315:4871,learn,learn,4871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315,2,['learn'],['learn']
Usability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...gine/spark/AddContextDataToReadSparkOptimized.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQWRkQ29udGV4dERhdGFUb1JlYWRTcGFya09wdGltaXplZC5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | ... and [92 more](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=footer). Last update [e7c90f1...08af964](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333:4140,learn,learn,4140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333,2,['learn'],['learn']
Usability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `82.857% <59.091%> (-6.234%)` | `6 <3> (+1)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <60%> (ø)` | `5 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.048% <66.667%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98.413% <0%> (-1.587%)` | `34% <0%> (+20%)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `9% <0%> (+6%)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=footer). Last update [88c181d...6a33314](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612:4128,learn,learn,4128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612,2,['learn'],['learn']
Usability,"Running a particular bam sort takes ~20minutes with hdd and 16 minutes with ssd. So it's definitely being used somehow. It looks like spark.local.dir is over ridden by the environment variable LOCAL_DIRS, and I don't see that set, but it's possible it's being set but not recorded correctly in the UI or something like that. Someone will need to poke at a bit more to be more clear about what's happening.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370:376,clear,clear,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370,2,['clear'],['clear']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <0%> (ø)` | `7% <0%> (+3%)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=footer). Last update [724fbd0...a163be6](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771:4125,learn,learn,4125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771,2,['learn'],['learn']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...llbender/tools/walkers/annotator/TandemRepeat.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9UYW5kZW1SZXBlYXQuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...tute/hellbender/metrics/SAMRecordAndReference.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1NBTVJlY29yZEFuZFJlZmVyZW5jZS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | ... and [430 more](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=footer). Last update [724fbd0...6b3c7a9](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519:4925,learn,learn,4925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519,2,['learn'],['learn']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `58.53% <0%> (-23.18%)` | `33% <0%> (-9%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `77.08% <0%> (-3.13%)` | `31% <0%> (ø)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.39% <0%> (-3.04%)` | `61% <0%> (-2%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=footer). Last update [626c887...a1e13fc](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464:4416,learn,learn,4416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464,2,['learn'],['learn']
Usability,"SVIntervals are comparable, and provide the same total order as coordinate-sorted BAMs. They can encode any contiguous stretch of bases on the reference, or strand-sensitively on its reverse complement. They can encode 0-length intervals (i.e., locations) to indicate things like the precise, unambiguous location of an insert between two reference bases. They're super light-weight, and cache friendly (no references), and they can be compared and tested for equality quickly and locally. They know how to serialize themselves with Kryo. They have a much more complete set of operations to calculate overlaps and underlaps, total order, etc. How will we implement isUpstreamOf using SimpleIntervals, when SimpleIntervals has no concept of contig order?; I think we'd have a heck of a job retrofitting our code to use SimpleIntervals, and a lot of testing to do to prove that the performance loss isn't significant. I'm sorry we struck out in an incompatible direction, but SimpleInterval just didn't seem up to the job at the time we started the SV project.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418520720:684,Simpl,SimpleIntervals,684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418520720,4,['Simpl'],"['SimpleInterval', 'SimpleIntervals']"
Usability,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:774,clear,clearing,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,6,"['clear', 'learn']","['clearing', 'learn']"
Usability,See my minor correction/suggestion. Should follow up with a task to explain the two-repo structure clearly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1207#issuecomment-160844574:99,clear,clearly,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1207#issuecomment-160844574,1,['clear'],['clearly']
Usability,"See some issues---mostly stemming from the HDF5 library and the BLAS library optionally used by MLlib SVD at e.g. https://gatkforums.broadinstitute.org/gatk/discussion/23591/createreadcountpanelofnormals-in-gatk4-1-doesnt-output-valid-hdf5-files#latest; https://gatkforums.broadinstitute.org/gatk/discussion/12537/get-error-when-using-createreadcountpanelofnormals-in-calling-somatic-copy-number-variation; https://gatkforums.broadinstitute.org/gatk/discussion/11461/gatk-4-0-1-2-no-non-zero-singular-values-were-found-in-creating-a-panel-of-normals-for-somatic-cnv/p1. Would also be nice to to turn down the verbosity of Spark logging, which emits a ridiculous amount of messages for a simple SVD. I think this is a relatively ancient issue (https://github.com/broadinstitute/gatk/issues/1370), not sure if it's been resolved for other Spark tools since.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5771:687,simpl,simple,687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5771,1,['simpl'],['simple']
Usability,"See some of my findings about numerical differences across 8/11/17 and possible causes in this old Slack thread: https://broadinstitute.slack.com/archives/C1HH1V5EC/p1657634295565369 We’re starting to get into some relatively hairy issues there, IMO!. But just in case it wasn’t clear: 1) None of these numerical differences should be scientifically concerning in the end, and 2) I think we still have numerical reproducibility within each fixed Java version (although if we happen to see any evidence to the contrary, please point to them here). So I don’t think we have too much to worry about once the test infrastructure settles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680:279,clear,clear,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680,2,['clear'],['clear']
Usability,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:137,simpl,simple,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481,2,['simpl'],['simple']
Usability,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13258,clear,cleared,13258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['clear'],['cleared']
Usability,Set the system property 'dataflowRunner' to the simple classname of the; runner you wish to use. E.g. gradle test -Dtest.single=CountBasesDataflowUnitTest -DdataflowRunner=SparkPipelineRunner,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/546:48,simpl,simple,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/546,1,['simpl'],['simple']
Usability,"Several experimental changes that improve precision results, and expand possible evaluations, of GATK CNV:. - `combine_tracks.wdl` for post-processing somatic CNV calls. This wdl will perform two operations:; - Increase precision by removing:; - germline segments. As a result, the WDL requires the matched normal segments.; - Areas of common germline activity or error from other cancer studies.; - Convert the tumor model seg file to the same format as AllelicCapSeg, which can be read by ABSOLUTE. This is currently done inline in the WDL. ; - This is not a trivial conversion, since each segment must be called whether it is balanced or not (MAF =? 0.5). The current algorithm relies on hard filtering and may need updating pending evaluation.; - For more information about AllelicCapSeg and ABSOLUTE, see: ; - Carter et al. *Absolute quantification of somatic DNA alterations in human cancer*, Nat Biotechnol. 2012 May; 30(5): 413–421 ; - https://software.broadinstitute.org/cancer/cga/absolute ; - Brastianos, P.K., Carter S.L., et al. *Genomic Characterization of Brain Metastases Reveals Branched Evolution and Potential Therapeutic Targets* (2015) Cancer Discovery PMID:26410082. - Changes to GATK tools to support the above:; - `SimpleGermlineTagger` now uses reciprocal overlap to in addition to breakpoint matching when determining a possible germline event. This greatly improved results in areas near centromeres.; - Added tool `MergeAnnotatedRegionsByAnnotation`. This simple tool will merge genomic regions (specified in a tsv) when given annotations (columns) contain exact values in neighboring segments and the segments are within a specified maximum genomic distance. . - `multi_combine_tracks.wdl` and `aggregate_combine_tracks.wdl` which run `combine_tracks.wdl` on multiple pairs and combine the results into one seg file for easy consumption by IGV.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5252:1239,Simpl,SimpleGermlineTagger,1239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5252,2,"['Simpl', 'simpl']","['SimpleGermlineTagger', 'simple']"
Usability,"Several of our HGSV snapshot samples are failing with current master due to an exception in `CpxVariantInterpreter`. For example, sample HG00732 fails with this stacktrace:. ```; 18/04/11 14:30:28 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 2.0 in stage 42.0 (TID 60116, cwhelan-hg00732-cram-samtools-bam-feature-w-5.c.broad-dsde-methods.internal, executor 27): java.lang.IllegalArgumentException: Invalid interval. Contig:chr19 start:33757506 end:33757488; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.computeNewRefSpanAndCigar(ContigAlignmentsModifier.java:159); at org.broadinstitute.hellbender.tools.spark.sv.discovery.alignment.ContigAlignmentsModifier.clipAlignmentInterval(ContigAlignmentsModifier.java:42); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.removeOverlap(CpxVariantInterpreter.java:179); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.deOverlapAlignments(CpxVariantInterpreter.java:122); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.furtherPreprocess(CpxVariantInterpreter.java:79); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.CpxVariantInterpreter.lambda$inferCpxVariant$bdd686a3$1(CpxVariantInterpreter.java:51); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4648:585,Simpl,SimpleInterval,585,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4648,4,['Simpl'],['SimpleInterval']
Usability,"Sharded output is extremely useful for pipelining. This adds the option `--max-variants-per-shard` to `GATKTool` to let users easily split out VCFs. The functionality is implemented in the `ShardingVCFWriter` class, which is a simple wrapper around `VariantContextWriter` that basically creates a new writer whenever the max shard size is reached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6959:227,simpl,simple,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6959,1,['simpl'],['simple']
Usability,"Should I follow the existing convention of using UserException for user errors and GATKException for everything else that doesn't clearly fall under a standard exception type?. The alternative would be to port PicardException, which we decided not to do IIRC.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/73#issuecomment-69978719:130,clear,clearly,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/73#issuecomment-69978719,1,['clear'],['clearly']
Usability,Should have clear instructions in README on how to use the docs system from another project (likely via one's build file).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2209#issuecomment-253618941:12,clear,clear,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2209#issuecomment-253618941,2,['clear'],['clear']
Usability,"Similar to #4253 . The M2 task calls out to `GetSampleName`, twice, but does not supply the input reference. Therefore, it will not work with cram. Proposed solution: Simply add `-R ${ref_fasta}` to each invocation of `GetSampleName` in the M2 wdl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4285:167,Simpl,Simply,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4285,1,['Simpl'],['Simply']
Usability,Simple GATKConf (NO MERGE),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322,1,['Simpl'],['Simple']
Usability,Simple PythonScriptExecutor.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3536:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536,1,['Simpl'],['Simple']
Usability,Simple WDL with the sole purpose of getting the cost for a callset based on the callset identifier,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7940:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7940,1,['Simpl'],['Simple']
Usability,Simple cmd line tool for creating index image file,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452,1,['Simpl'],['Simple']
Usability,"Simple code changes that improve performance of BaseRecalibrator by ~20%. . NOTE: this is not related to removing indels. That will come later and is expected to improve performance further. According to my tests, we now beat GATK3 on the infamous first 10Mb of chr1 in CEUTrio.HiSeq.WGS.b37.NA12878.bam. @droazen can you review? some of those changes are similar to those in #1099",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1114:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1114,1,['Simpl'],['Simple']
Usability,Simple copy/paste bug. Closing the header line creator fixes the hanging issues as seen in [this run](https://job-manager.dsde-prod.broadinstitute.org/jobs/21c1ec08-444e-4acd-8490-cc9640d9ea03) (requires PMI ops). Integration run [in progress](https://job-manager.dsde-prod.broadinstitute.org/jobs/3b5129bb-b7fe-47db-abc4-dda5d7f5006a) (regular auth).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533,1,['Simpl'],['Simple']
Usability,Simple fix to copy_sv_results.sh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4873:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4873,1,['Simpl'],['Simple']
Usability,"Simple fix to remove trailing slash in GCS_SAVE_PATH to avoid double slashes in GCS_RESULTS_DIR. Without this, if the `manage_sv_pipeline.sh` is launched with `-s gs://custom/path/to/save/` having the trailing slash, log file and cmd line info will be saved to a strange place.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4873:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4873,1,['Simpl'],['Simple']
Usability,Simple fixes to capitalize VCF and changed command to reflect ./gatk-launch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3108:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3108,1,['Simpl'],['Simple']
Usability,Simple one liner to replace an errant println.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4697:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4697,1,['Simpl'],['Simple']
Usability,Simple patch to allow passing specific tool classes to `Main.instanceMain` instead of whole packages to solve #2140. This will allow clients that want their own command line with their tools to include only `IndexFeatureFile` for their own codecs and/or bundle tools like `CreateSequenceDictionary` to pre-process input files.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204,1,['Simpl'],['Simple']
Usability,Simple patch to improve the `Main` usage in the same direction as previous PRs to finer control by API user:. * Added `handleNonUserException(final Exception exception)` to handle custom exceptions.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2261:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2261,1,['Simpl'],['Simple']
Usability,Simple to do! There is a move function that let me move the issue right over and close this :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2203#issuecomment-258872689:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2203#issuecomment-258872689,1,['Simpl'],['Simple']
Usability,"Simple toggle wins the day, by a vote of 2-1 :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790,1,['Simpl'],['Simple']
Usability,Simple update to use the correct version of Spark in the scripts.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125,1,['Simpl'],['Simple']
Usability,Simple way to have VariantsToTable output all fields. Just want the entire VCF as a table.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7677:0,Simpl,Simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7677,1,['Simpl'],['Simple']
Usability,SimpleAnnotatedGenomicRegion refactoring to use Tribble,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3738:0,Simpl,SimpleAnnotatedGenomicRegion,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3738,1,['Simpl'],['SimpleAnnotatedGenomicRegion']
Usability,"SimpleInterval has a constructor that parses an interval String, but without access to a SequenceDictionary its not possible to correctly interpret intervals with contig names such as those used in hg38. It looks like the only non-test consumer of this method is TableCodec. For example:. - `HLA-A*01:01:01:01` is interpreted as `HLA-A*01:01:01:1-1`, but `HLA-A*01:01:01` doesn't exist; - `HLA-A*01:01:01:02N` its interpreted as position `02N` on contig `HLA-A*01:01:01`, which fails to parse, and the contig doesn't exist. GATK command line intervals resolve these by consulting the sequence dictionary. For hg38 at least, there can be no ambiguity and there is always only one correct interpretation. Its possible to construct a legal sequence dictionary that has ambiguities though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4597:0,Simpl,SimpleInterval,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4597,1,['Simpl'],['SimpleInterval']
Usability,SimpleInterval#getSpanningOverlap NPE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1405:0,Simpl,SimpleInterval,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1405,1,['Simpl'],['SimpleInterval']
Usability,SimpleIntervals String creator can be pass an invalid range and no exception will be thrown.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/438:0,Simpl,SimpleIntervals,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/438,1,['Simpl'],['SimpleIntervals']
Usability,SimpleIntervals lacks a needed SimpleInterval(Locatable) constructor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/436:0,Simpl,SimpleIntervals,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/436,2,['Simpl'],"['SimpleInterval', 'SimpleIntervals']"
Usability,Simpler and faster allele fraction likelihoods for HMM segmentation,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2937:0,Simpl,Simpler,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2937,1,['Simpl'],['Simpler']
Usability,Simplified KBestHaplotypeFinder by replacing recursion with Dijkstra's algorithm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5462:0,Simpl,Simplified,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5462,1,['Simpl'],['Simplified']
Usability,Simplified cigar and clipping code; added tests and fixed a few bugs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6403:0,Simpl,Simplified,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6403,1,['Simpl'],['Simplified']
Usability,Simplified genotype likelihood calculation (no change in output),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351:0,Simpl,Simplified,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351,1,['Simpl'],['Simplified']
Usability,Simplifies BQSR covariates - use only 4 standard ones. Remove magic indexing. Add tests. Addresses #258 . @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/413:0,Simpl,Simplifies,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/413,1,['Simpl'],['Simplifies']
Usability,Simplifies code and speeds up ApplyBQSR by ~50%. See https://github.com/broadinstitute/gatk/issues/1056 for some numbers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1099:0,Simpl,Simplifies,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1099,1,['Simpl'],['Simplifies']
Usability,Simplify HaplotypeBAMWriter code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/944:0,Simpl,Simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/944,1,['Simpl'],['Simplify']
Usability,Simplify HaplotypeBAMWriter code. #944,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5122:0,Simpl,Simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5122,1,['Simpl'],['Simplify']
Usability,Simplify Mutect annotations,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3351:0,Simpl,Simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3351,1,['Simpl'],['Simplify']
Usability,Simplify spark_eval scripts and improve documentation.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3580:0,Simpl,Simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3580,1,['Simpl'],['Simplify']
Usability,"Simplify to use Spark's sortByKey, which does a totally-ordered sort.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1363:0,Simpl,Simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1363,1,['Simpl'],['Simplify']
Usability,Simplifying argument in mitochondria pipeline,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6904:0,Simpl,Simplifying,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6904,1,['Simpl'],['Simplifying']
Usability,"Simply replaced a custom version of the task with a standard one we are using elsewhere. Original run:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20hatcher/job_history/193c7c2b-2d29-4bab-8abc-6ab85a2f5270. Run from the modified branch:; https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20hatcher/job_history/575121f1-07e9-4821-bb20-35b6ed430560. Both ran within my quickstart workspace, but were pointed at George's dataset. Both failed the same two predicted tasks.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8024:0,Simpl,Simply,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8024,1,['Simpl'],['Simply']
Usability,"Simply take the methods in org.broadinstitute.hellbender.utils.param.ParamUtils and add to org.broadinstitute.hellbender.utils.Utils, since these are all static. Then delete ParamUtils and have all usages use Utils.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/861:0,Simpl,Simply,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/861,1,['Simpl'],['Simply']
Usability,"Since NIO reportedly now works from Spark clients, this bit of; authentication is unnecessary. Removing it greatly simplifies; BucketUtils, and also stops users having to worry about where; to get the AuthHolder from. This work is part of #2402",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565:115,simpl,simplifies,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565,1,['simpl'],['simplifies']
Usability,Since the intent and implementation of this filter are not essential to my work -- I can simply filter pairs on TLEN prior to variant calling -- perhaps it's best to just let this one be. Thanks for the discussion and for helping me think things through.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1105639777:89,simpl,simply,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1105639777,2,['simpl'],['simply']
Usability,"Since the simple fix is merged for now, can we close this ticket and open a new one if the speed ends up being a problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1865#issuecomment-226005625:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1865#issuecomment-226005625,1,['simpl'],['simple']
Usability,"Since we never actually look to see if something IS an optical duplicate and only care about the total number, we could just output a single annotation on one read in the best read pair with the number of optical duplicates found for that set of reads. It would make the code simpler but maybe not make as much sense logically?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126755071:276,simpl,simpler,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126755071,1,['simpl'],['simpler']
Usability,"Since you asked, I have a couple of thoughts:. First, I don't know if allowing the SAMRecord header to be set to null ; something that was intended to be widely used, or whether it was an ; oversight in the API or done to solve some particular corner case. If ; many SAMRecord methods appear to be broken if the header is null, then ; perhaps this isn't something that was intended for wide use. Second, it sounds like the suggestion is that headerless SAMRecords ; would now be widely used, and thus a common thing that people writing ; code against htsjdk need to anticipate.; So if you go this way you should update the SAMRecord documentation to ; clearly indicate that SAMRecords can be in either a headerless or ; non-headerless (headerful?) state; and indicate how each API function is affected by this. If certain ; methods behave differently, then people writing code against SAMRecord ; need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and com",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:652,clear,clearly,652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['clear'],['clearly']
Usability,"Slightly speculative PR to try and address (or rather, create a workaround for) #5727. Simply removes the restriction that physical phasing cannot be used in non-ERC mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5772:87,Simpl,Simply,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772,1,['Simpl'],['Simply']
Usability,"So behavior when disabled (parameter set to 0) and when set to 2 or above gives the same results for my data where smoothing iterations you say plateau at two iterations. When set to 1, the smoothing iterations increase to seven and this is the only other alternative result one can expect for this data. It is somewhat counter-intuitive. But given @samuelklee says this is the expected behavior for this parameter, then I can close this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382863906:328,intuit,intuitive,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382863906,2,['intuit'],['intuitive']
Usability,"So the long term timeline is fairly up in the air. You can check out the alpha and beta milestones for some idea of what's been prioritized. Alpha milestone is due for completion ~this week. Beta is much more up in the air and will depend at least in part on feedback from user. . Incidentally, if you're interested in CNV calling take a look at https://github.com/broadinstitute/gatk-protected/ which has some tools for CNV calling built on this engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606:259,feedback,feedback,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606,1,['feedback'],['feedback']
Usability,"So, I tried this out and it's harder than it seems. Some calls get better, some get worse. There probably exists a simple set of heuristics to make reasonable alignments, but I don't think that it can be represented as a single set of SW parameters. We might need to have some kind post-processing to judge whether a better alignment than the Smith-Waterman one exists.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799:115,simpl,simple,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799,2,['simpl'],['simple']
Usability,"Somatic CNV tagging germline events, bringing SimpleAnnotatedGenomicRegion in line with the collection conventions, and region merging,",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205:46,Simpl,SimpleAnnotatedGenomicRegion,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205,1,['Simpl'],['SimpleAnnotatedGenomicRegion']
Usability,"Some clarification questions about the field AS_RAW_MQ. In the examples provided, the header line corresponding to this field is. ##INFO=<ID=AS_RAW_MQ,Number=A,Type=Float,Description=""Allele-specfic raw data for RMS Mapping Quality"">. The data lines contain entries similar to `AS_RAW_MQ=123769.00|3600.00|46800.00|0.00`. Is the AS_RAW_MQ field simply a vector of float?; - If yes; - Why is the '|' used as the delimiter? Why not simply use ','?; - Based on the entries, shouldn't the Number descriptor in the header line be 'R' instead of 'A'; - If no, i.e. AS_RAW_MQ can be a vector of vector of float (entries such as `AS_RAW_MQ=1,2|3,4,5|6|0.00` where `[1, 2]` corresponds to allele 0 (reference allele) etc.); - Shouldn't the Type descriptor in the header line be 'String' instead of 'Float'? (similar to the AS_RAW_\*RankSum fields)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919:345,simpl,simply,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919,4,['simpl'],['simply']
Usability,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:395,feedback,feedback,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['feedback'],['feedback']
Usability,"Some factors to consider in making this decision:. -Operations on zero-length intervals are error-prone due to lack of understanding/consensus about expected results (eg., should a query on a zero-length interval return records that abut it on either side?). -We need to determine how a query involving a zero-length interval is supposed to behave in the GA4GH API, as this does not seem to be clearly defined in the API documentation (eg., http://ga4gh.org/documentation/api/v0.5.1/ga4gh_api.html#/schema/%2FUsers%2Fkeenan%2FDropbox%2Fgit-checkouts%2Fschemas%2Fsrc%2Fmain%2Fresources%2Favro%2Ftarget%2Fall.avpr/org.ga4gh.GASearchReadsRequest). The representation is 0-based closed-open (like BED), which means zero-length intervals are possible, but their behavior appears undefined. -None of our current query interfaces (tribble/samtools) support computing overlap with zero-length intervals (although they don't throw an error when given such an interval -- they just never return any records for such queries). -It seems unlikely that we'll be moving anytime soon to representing insertions using zero-length intervals, given that the VCF spec requires insertions to be represented in terms of the preceding reference base.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/317:394,clear,clearly,394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317,1,['clear'],['clearly']
Usability,"Some notes on individual commits:. Updated CallCopyRatioSegments and PreprocessIntervals; reorganized copynumber packages.; -For motivation of changes in CallCopyRatioSegments, see #3825.; -I added the ability to turn off binning in PreprocessIntervals by specifying bin_length = 0.; -I removed the separation between coverage and allelic packages to make the package structure a bit simpler.; -@MartonKN should review, since he wrote PreprocessIntervals and is updating the caller. Added segmentation classes and tests for ModelSegments CNV pipeline.; -I added implementations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:384,simpl,simpler,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,2,['simpl'],"['simpler', 'simply']"
Usability,"Some of the categories we are removing are still in the HelpConstants, e.g. DOC_CAT_SPARK*.; --> learned on purpose otherwise code breaks. Will be removed at later time. Here's that spreadsheet again. It's the fourth tab `categories_summaries`: https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. I see two place holders for Picard, ReadProgramGroup and VariantProgramGroup. Are these for those categories only in Picard? Because then there is only one such category and it is the `Base Calling` category.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185:97,learn,learned,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185,2,['learn'],['learned']
Usability,"Some of the data in the COSMIC database contain invalid protein position information. For example, the protein position field here indicates a stop position before the start:; ```; CEBPA, ENST00000498907, 1077, 1833, 2404659, 2404659, 2267510, haematopoietic_and_lymphoid_tissue, NS, NS, NS, haematopoietic_neoplasm, acute_myeloid_leukaemia, NS, NS, n, COSM5065102, c.926_927ins24, p.V308_P39insDKAKQRNV, Insertion - In frame, het, u, 37, 19:33792394-33792395, -, , -, , , Variant of unknown origin, 20439648, , blood-bone marrow, NS, , ; ```. Specifically: **p.V308_P39insDKAKQRNV**. This is clearly a typo. However, for the moment we are ignoring these data and throwing a warning, rather than attempting to fix them or include them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4812:593,clear,clearly,593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4812,1,['clear'],['clearly']
Usability,"Some offline discussions have led us to the conclusion that this is best handled by tools upstream. Adapters should not be simply soft-clipped, so it shouldn't be the responsibility of M2 or HC to include logic to remove adapters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816:123,simpl,simply,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816,2,['simpl'],['simply']
Usability,"Some preliminary evaluation of the new ModelSegments pipeline on CRSP samples has revealed some weaknesses of the ReCapSeg caller (which is simply ported from the old pipeline) to me. I think there are a lot of confusing things going on:. 1) For determining copy-neutral segments, all segments with log2 mean below some threshold are used (rather than absolute log2). There is a comment that this is done to ""mimic the python code"" but I have no idea why this would be sensible, since it includes all deletions.; 2) There is some confusion arising from inconsistent use of z-score and T-statistic. Standard deviation, rather than standard error, is used for calling; i.e., a ""called segment"" is one that has a mean log2 copy ratio that has a z-score above some threshold with respect to the standard deviation of the log2 copy ratios of intervals that fall within copy-neutral segments (note also that these intervals have already been filtered by z-score to remove outliers). That is, any segment with a mean that falls sufficiently within the fuzziness of the caterpillar is not called.; 3) However, even calling using standard error is probably not what we want. This would simply be asking the question: given a population of copy-neutral intervals with a mean and standard deviation, does any non-copy-neutral segment contain intervals with a mean significantly different than the population? We've already answered this question during segmentation!. I think what we want to do instead is ask questions about the population of segment-level copy-ratio estimates, weighted by length.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3825:140,simpl,simply,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825,2,['simpl'],['simply']
Usability,"Some tools work with a large list of intervals. In some case these are quite repetitive and they could specify in a single line but due to the need to enumerate each interval explicitly in the interval lists it might result in a uncessary large file, potentially GB in size. ## Repetitive intervals. For example the SV detection pipeline collects read counts at 100bp intervals. In a 3.2Gbp genome that is roughly 30M entries. Easily a text interval_list in its simplest form would need around 30ch for each interval that bump it up to 900MB . However one could express the same list just like:. `* *:100`. where the first asterisk stands for ""any contig"", the second stands for ""whole contig"" and the 100 means into 100bp adjacent intervals. from 7ch to 900M??? A few more example as to how such a language could look like:. ```; chr1 # the entire chr1; chr1 * # same; chr1,chr2 # both chr1 and chr2, in full.; * # all contigs in full.; * * # same.; chr1 100-200 # sigle interval from 100-200 on chr1.; chr1 { 100-200 } # same; chr1 { # same; 100-200; }; * 100-200 # 100-200 at every contig.; chr1,chr2 100-200 # only on chr1 and chr2; chr1 *200 # from 1-200 i.e. start to 200.; chr1 4000* # from 4000 to the end of chr1.; chr1 4000 # only position 4000; chr1 4M # only position 4 million. M=10^6, k/K=10^3 ; chr1 10000-99 # from 10000 to 10099... ; # perhaps is best not to accept this as it might silence user input errors.; # but what about instead?; chr1 100[00-99]; chr1 10000+100 # 100 bps starting at 10000 so 10000-10099; chr1 4k # only poistion 4000.; chr20 1M+32K # from position 1 million extending to the following 32Kbps.; chr20 1M1+32K # from position 1 million and 1 instead. (avoiding all those 0s). chr1 *:200 # consecutive 200bp intervals for the entire chromosome; chr1 *:200(100) # 200bp intervals with 100 gaps; chr1 *:200/20 # 200bp intervals with an overlap of 20bp.; chr1 *:20/200 # 200bp starting every 20 positions (so 180bp overlap); chr1 *:200~20 # 200bp intervals truncat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702:462,simpl,simplest,462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702,1,['simpl'],['simplest']
Usability,Something is discussed in the style guide about NIO.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724103:36,guid,guide,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724103,2,['guid'],['guide']
Usability,"Sorry @droazen, the previous commit had an error in the tests. I'm rebasing/squashing to make a clear PR and when all check pass (except CLOUD), you can review if you have time. Thank you very much.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-246346004:96,clear,clear,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-246346004,1,['clear'],['clear']
Usability,Sorry that sentence was not clear at all. I meant I am using an additional locus based caller in order not to miss those variants missed by haplotypecaller padding issue. I want to drop that duct tape solution from my workflows completely.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379801534:28,clear,clear,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379801534,2,['clear'],['clear']
Usability,"Sorry, I know this is old, but i'm currently dealing with this exact issue using `gatk-4.beta.5`. It sounds like this has been solved, but the solution isn't clear to me. . EDIT: Perhaps an upgrade to 4.1 will solve this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603:158,clear,clear,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603,2,['clear'],['clear']
Usability,"Sorry, I wasn't very clear: Spark doesn't return the user exception to the driver even as the 'cause' exception (only the exception message is preserved). So it won't be possible to do the unwrapping in the same way at the moment. I agree that #551 will help catch regressions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502:21,clear,clear,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502,1,['clear'],['clear']
Usability,"Sorry, but this bug still isn't fixed as of v4.2.6.1. Reproduce as follows:. ```; --read-filter MateDistantReadFilter; --mate-too-distant-length 1500; ```. Instead of a run-time exception (as in v4.2.5.0), HaplotypeCaller simply produces no variant calls at all. Expected behavior would be to exclude paired-end mappings whose TLEN exceeds the parameterized value. Perhaps there is an implementation bug, unrelated to the original problem, that contains faulty logic for doing this. Thanks...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692:222,simpl,simply,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692,2,['simpl'],['simply']
Usability,"Sorry, just saw this now. We still don't have a simple solution for training models without pysam. We can probably do something similar to what we do with inference, but I think the current priority is to improve inference throughput so it will probably be a little while before we get to re-writing the training code. If people feel we should re-prioritize please let me know.; I have installed the conda environment on the same OSX version, without seeing this issue.; Which gcc version are you using @mwalker174 ? ; My `gcc -v` output is:; ```; Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1; Apple LLVM version 8.0.0 (clang-800.0.42.1); Target: x86_64-apple-darwin15.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193:48,simpl,simple,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193,2,['simpl'],['simple']
Usability,"Sorry, just seeing this now. ; I'm mainly looking at the sample output and it looks great!! I can't find anything wrong with it but here are some suggestions for improvement; - If its too late now maybe for later it would be nice to add a runtime block for each task so that it would executable in a cloud environment. ; - Why have inputs declared at a workflow level input block (which requires them to be repeated in the call block, and again at the task input block) when they can be declared simply at the task level?; - If it's an easy fix it would be nice to see the full parameter name instead of abbreviation for input and output (e.g. ""I"", ""O"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611039729:496,simpl,simply,496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611039729,2,['simpl'],['simply']
Usability,"Sorry, perhaps I wasn't clear. The bamout not only output the read records realigned to the reference (thru their alignment to te best haplotype) but also the haplotype themselves as reads records. I'm not 100% sure of this is true for your run but these special records probably have a sample name ""HC"" and as read id something like ""HCXXXXXXX"" where XXXXXXX is a number. . My hope was that by grouping by sample the haplotypes would stand out and that we could then verify what haplotypes were reconstructed. . My suspicion is that haplotype with no C mutation but with downstream mutation has not be reconstructed.. You need to identify the complete list of reconstructed haplotypes to confirm that, either by grouping somehow haplotypes away from the actual reads in the bamout or perhaps looking into HaplotypeCaller's debugging output. If that is true, what is happening is that reads that contain the downstream mutation would artifactually have support for the C mutation even if the have a ref base for that position or if they don't even overlap that position. So if this is confirmed, the following step would be to figure out why this is happening (not reconstructing that obvious haplotype) and fix the issue. Hopefully someone in the GATK developer team can look into this as you may well have hit an interesting edge case that needs to be ironed out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8238#issuecomment-1483076912:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8238#issuecomment-1483076912,2,['clear'],['clear']
Usability,"Sounds good. Thanks,; Chuck. > On Mar 18, 2017, at 06:33, Geraldine Van der Auwera <notifications@github.com> wrote:; > ; > Hi Chuck, the GATK blog is set up to only accept posts from admins or moderators on the forum (or my team). If you're willing to write something up, we would do it as a guest post, where I would post the text on your behalf (with clear attribution to you). If you'd like to share a draft with us the easiest way to do it is through a google doc.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287551239:354,clear,clear,354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287551239,1,['clear'],['clear']
Usability,"Spark tools should be just as easy to run as walkers. Users shouldn't have to write a shell script to invoke spark-submit or gcloud, build a special jar and upload it somewhere, log in to a particular machine, etc. Ideally we want something as simple as: `./hellbender ToolName [toolOptions] [sparkOptions]`, and the engine should figure out whether to invoke spark-submit or gcloud and invoke it on the user's behalf. Options include:; -Invoke spark-submit/gcloud programmatically within hellbender (possibly using a simple `Runtime.getRuntime().exec()` approach). -Write a shell script that can run any hellbender command and auto-delegate to spark-submit / gcloud as necessary.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/961:244,simpl,simple,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/961,2,['simpl'],['simple']
Usability,"SparkSharder: add test with long reads (eg., 10,000 bases), and ensure it doesn't crash and a user-friendly message is thrown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2253:94,user-friendly,user-friendly,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2253,2,['user-friendly'],['user-friendly']
Usability,SplitIntervals has non-intuitive behavior for lists of adjacent intervals,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6423:23,intuit,intuitive,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6423,2,['intuit'],['intuitive']
Usability,"Status as of PR #4238:. ## Remaining wants; - Outputs should allow either .vcf or .vcf.gz compression by user-specification. Alternatively, if we want to keep it simple and hardcode, then the preference is for compressed files. Some of us prefer to save on storage.; - The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849:162,simpl,simple,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849,2,['simpl'],['simple']
Usability,"Still working on my review but just wanted to respond to a couple of @davidbenjamin 's points:. - Agree that we should get rid of the hard coded paths (and I think most of those resources should live with the reference bundle rather than in GATK resources anyway). Already discussed this with @TedBrookings in person.; - IMO iterators are fine and are still idiomatic Java. Often we do have very large collections that we want to iterate over online, or at least without having to know how they are represented in the calling code. Spark APIs often return or provide iterators and using them lets you port code easily between working on RDDs and working on in memory collections. Also iterators give you the option to implement `remove` which is often important and useful. Of course, they are a little heavier than streams for simple use cases, so it's a tradeoff on whether you think the extra functionality / flexibility is useful.; - `Tuple2` and the other tuple Scala classes are used in the Java Spark API extensively and therefore is in a lot of our code, it's fine to use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389898045:828,simpl,simple,828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389898045,2,['simpl'],['simple']
Usability,Substitute GenomeLoc by SimpleInterval in ExomeReadCounts tool.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/421:24,Simpl,SimpleInterval,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/421,1,['Simpl'],['SimpleInterval']
Usability,"Successful integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/ef747737-4d19-4770-83b7-47715eff8237). tl;dr the only commit really worth looking at is 9ac0befbcc39b9c5a7eb0938dd79a7d5cbd5f297, everything else is a simple merge from master. This is just minor tweaks around recent changes in the JointVariantCalling WDL. I'll need to merge and push this locally to preserve history from master as that option is not available within the GATK GitHub repo.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8537:257,simpl,simple,257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8537,1,['simpl'],['simple']
Usability,Sure. But we'll probably need to use some simpler stylesheets than what the website uses.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2769#issuecomment-309642761:42,simpl,simpler,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2769#issuecomment-309642761,2,['simpl'],['simpler']
Usability,"TACATATATAACTAACCTGCACAATGTGCACATGTACGCTAAAACTTAAAAGTATAATAAAAAAAAAAAAAAAGAAAAAAAAAAGAATGCAACAACAAAAAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTCAACTCCGTGAGTTGATTGAACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCGTTTCAACCATAGGTCTCAAAGTGCTCCAAATATCCACTTGCAGATTCTACAAAACGAGTCTTTCAAAACTGCTCTATCAATACGAAGGTTCAACTCTGTGAGTTGAATGCACACATCACAAAGAAGTTTCTGAGAATGCTTCTGTCTAGTTTTTATGTGAAGATATTCCCGTTTCCAATGAAAGCCTCAAAGCCATCCAAATGTCCACTTGCAGATTCTACAAAAAGAGTGTTTGAAAACTGCTCTATCAAAAGAAGATTCAACTCTGTGAGTTGAAAGCACACATCAGAAAGAATTTCCTGATAATGCTTCTGTCTAGCTTTTATGTGGAGATATTCCCGTTTTCAACGAAGGCCTCAAAGCAGTCCAAATATCCATTTGCAGGTTCTACAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTAAACTCCGTGAGTTGACTGCACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCATTTCAACTGT"".getBytes();. final AlignmentInterval region0 = new AlignmentInterval(new SimpleInterval(""21"", 96869186, 96869532), 1, 347, TextCigarCodec.decode(""347M678S""), false, 4, 9, 305, AlnModType.NONE);; final AlignmentInterval region1 = new AlignmentInterval(new SimpleInterval(""21"", 48872354, 48872986), 383, 1014, TextCigarCodec.decode(""382H375M1D257M11H""), false, 4, 73, 255, AlnModType.NONE);; final AlignmentInterval region2 = new AlignmentInterval(new SimpleInterval(""20"", 283, 651), 383, 751, TextCigarCodec.decode(""382H369M274H""), true, 60, 23, 254, AlnModType.NONE);; final AlignmentInterval region3 = new AlignmentInterval(new SimpleInterval(""20"", 1, 413), 613, 1025, TextCigarCodec.decode(""612H413M""), true, 60, 0, 413, AlnModType.NONE);. final AlignedContig alignedContig = new AlignedContig(""asm00001:tig0001"", contigSequence, Arrays.asList(region0, region1, region2, region3), false);. final List<ChimericAlignment> assembledBreakpointsFromAlignmentIntervals = ChimericAlignment.parseOneContig(alignedContig, SVDiscoveryTestDataProvider.seqDict, true, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.DEFAULT_MIN_ALIGNMENT_LENGTH, StructuralVariationDiscoveryArgumentCollection.DiscoverVari",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:1537,Simpl,SimpleInterval,1537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,1,['Simpl'],['SimpleInterval']
Usability,"TTCTGTCTATTTTTTCTGTGAAGATATTCCCGTTTCAACCATAGGTCTCAAAGTGCTCCAAATATCCACTTGCAGATTCTACAAAACGAGTCTTTCAAAACTGCTCTATCAATACGAAGGTTCAACTCTGTGAGTTGAATGCACACATCACAAAGAAGTTTCTGAGAATGCTTCTGTCTAGTTTTTATGTGAAGATATTCCCGTTTCCAATGAAAGCCTCAAAGCCATCCAAATGTCCACTTGCAGATTCTACAAAAAGAGTGTTTGAAAACTGCTCTATCAAAAGAAGATTCAACTCTGTGAGTTGAAAGCACACATCAGAAAGAATTTCCTGATAATGCTTCTGTCTAGCTTTTATGTGGAGATATTCCCGTTTTCAACGAAGGCCTCAAAGCAGTCCAAATATCCATTTGCAGGTTCTACAAAAAGAGTGTCTCAAAACTGCTCTATCAAAAGGCAGGTTAAACTCCGTGAGTTGACTGCACACATAACAAAGAAGTTTCTGAGAATGCTTCTGTCTATTTTTTCTGTGAAGATATTCCCATTTCAACTGT"".getBytes();. final AlignmentInterval region0 = new AlignmentInterval(new SimpleInterval(""21"", 96869186, 96869532), 1, 347, TextCigarCodec.decode(""347M678S""), false, 4, 9, 305, AlnModType.NONE);; final AlignmentInterval region1 = new AlignmentInterval(new SimpleInterval(""21"", 48872354, 48872986), 383, 1014, TextCigarCodec.decode(""382H375M1D257M11H""), false, 4, 73, 255, AlnModType.NONE);; final AlignmentInterval region2 = new AlignmentInterval(new SimpleInterval(""20"", 283, 651), 383, 751, TextCigarCodec.decode(""382H369M274H""), true, 60, 23, 254, AlnModType.NONE);; final AlignmentInterval region3 = new AlignmentInterval(new SimpleInterval(""20"", 1, 413), 613, 1025, TextCigarCodec.decode(""612H413M""), true, 60, 0, 413, AlnModType.NONE);. final AlignedContig alignedContig = new AlignedContig(""asm00001:tig0001"", contigSequence, Arrays.asList(region0, region1, region2, region3), false);. final List<ChimericAlignment> assembledBreakpointsFromAlignmentIntervals = ChimericAlignment.parseOneContig(alignedContig, SVDiscoveryTestDataProvider.seqDict, true, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.DEFAULT_MIN_ALIGNMENT_LENGTH, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.CHIMERIC_ALIGNMENTS_HIGHMQ_THRESHOLD, true);. Assert.assertEquals(assembledBreakpointsFromAlignmentIntervals.size(), 1);; final ChimericAlign",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:1732,Simpl,SimpleInterval,1732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,1,['Simpl'],['SimpleInterval']
Usability,"TableReader is a dumb-dumb one-record at a time reader so it shouldn't suffer from memory leaks. . In contrast the parser() method uses a incremental ""buffer"" that accumulates the counts until the end when the actual returned table is created... The reason for this is to keep the ReadCountsCollection class constant. So at some point you need at least twice the amount of memory as compare to a solution that would simply use the returned object as the accumulator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316479500:416,simpl,simply,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316479500,2,['simpl'],['simply']
Usability,Take what we learn in #2973 and apply it.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3094:13,learn,learn,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3094,1,['learn'],['learn']
Usability,Tell me about it :). Biggest support burden of upping the java version was due to Apple making it hard to seamlessly upgrade the java version. Users themselves didn't care all that much as long as the requirements were clear. . So far we've been lucky that no other major tool seems to dictate which version of java users should have on their machine. Otherwise collisions could happen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138:219,clear,clear,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138,1,['clear'],['clear']
Usability,Test for presence of ack result message and simplify ProcessControllerAckResult API,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7816:44,simpl,simplify,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7816,2,['simpl'],['simplify']
Usability,Test runs after PR feedback-based changes:. - Sample run with interval of 5k lines: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/8ac48d8a-f2ca-4cef-bc10-271d3503d607; - Sample run with interval of 10k lines (it determined that this was too many intervals and just ran for all): https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b6189b51-fa16-46c2-953c-4571045eae34,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8666#issuecomment-1917906310:19,feedback,feedback-based,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8666#issuecomment-1917906310,2,['feedback'],['feedback-based']
Usability,Tests are passing using a snapshot generated while debugging https://github.com/broadinstitute/picard/pull/1904. Folks can review and give feedback. Perhaps we shouldn't merge though unless referencing a library SNAPSHOT is ok or picard 3.0.1 is released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824:139,feedback,feedback,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824,2,['feedback'],['feedback']
Usability,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:57,clear,clear,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367,2,['clear'],['clear']
Usability,"Thank you @SHuang-Broad, this confirms the problem: the ""convention"" has been changed so NIO's special casing needs to be adjusted to the new reality of what sort of files are created to make fake directories. In the meantime, the workaround is clear: if a tool offers to create directories in Google cloud, gently decline. It's not necessary and in some cases (like here), creates problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492827551:245,clear,clear,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492827551,2,['clear'],['clear']
Usability,Thank you @chen42. Looking at the exception it looks like it is another issue with a seperate tool (GenotypeGVCFs as opposed to CombineGVCFs). This is clearly a seperate issue and I have created an issue to track it #6357. It would be helpful to get a snippet of the beginning of your input bam `/lustre/haven/proj/UTHSC0013/Tristan_GATK//gvcf//merged//joint_called_gvcfs_chr7.vcf` in order evaluate what is happening. Here are some instructions for sharing files: https://software.broadinstitute.org/gatk/guide/article?id=1894.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572128609:151,clear,clearly,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572128609,4,"['clear', 'guid']","['clearly', 'guide']"
Usability,"Thank you @cmnbroad .; > Java 17 uses strict floating point math by default. ; I didn't know this. I learned a lot. I downloaded and built gatk-4.4.0.0.; I realized that Log10Cache.java is not in gatk-4.4.0.0 but is in 4.3.0.0. In gatk-4.4.0.0, log10 value is calculated by Math.log10 directory.; Thus, I modified computeLogPenaltyScore in kBestHaplotype.java from Math.log10 to StrictMath.log10. I compared variant call results of original or modified to StrictMath class log10. ```; public static double computeLogPenaltyScore(int edgeMultiplicity, int totalOutgoingMultiplicity) {; // return Math.log10(edgeMultiplicity) - Math.log10(totalOutgoingMultiplicity);; return StrictMath.log10(edgeMultiplicity) - StrictMath.log10(totalOutgoingMultiplicity);; }; ```. Original gatk-4.4.0.0 and gatk-4.4.0.0 modified ver. from Math to StrictMath OpenJDK-17.0.6+10 output different results with this link bam ( https://pezycomputing-my.sharepoint.com/:f:/g/personal/sakai_pezy_co_jp/Eo5Gvfau1BpMszGCcfDrD14BOfMgxvk7Mt2JCFqcDfgItQ?e=wzZbpL ).; Same as gatk-4.3.0.0 openjdk-1.8.0; I previously examined Math.log10 output different result from StrictMath.log10 on x64 CPU but same result on arm CPU with following code. ```; import java.util.*;. public class log10_check {; public static void main(String[] args){; int n = 100;; for (int i = 2; i < n; ++i){; if (Math.log10(i) != StrictMath.log10(i)) {; System.out.printf(""i = %d, %20.16f, %20.16f\n"", i, Math.log10(i), StrictMath.log10(i));; } ; }; }; }; ```. Output on x64 CPU. On arm CPU, no output.; ```; i = 11, 1.0413926851582251, 1.0413926851582250; i = 40, 1.6020599913279623, 1.6020599913279625; i = 43, 1.6334684555795864, 1.6334684555795866; i = 52, 1.7160033436347992, 1.7160033436347990; i = 53, 1.7242758696007890, 1.7242758696007892; i = 85, 1.9294189257142926, 1.9294189257142929; i = 90, 1.9542425094393250, 1.9542425094393248; i = 92, 1.9637878273455553, 1.9637878273455551; i = 93, 1.9684829485539350, 1.9684829485539352; ```. Thus, gatk-4.4",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1560470696:101,learn,learned,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1560470696,2,['learn'],['learned']
Usability,Thank you @lbergelson for the fix! For once a dependency conflict that turns out to be simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259:87,simpl,simple,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259,2,['simpl'],['simple']
Usability,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:720,simpl,simplified,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,2,['simpl'],['simplified']
Usability,Thank you at @ldgauthier for volunteering to review and for all of the feedback. The Travis checks are still in progress but the only code change is with the logger type.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262:71,feedback,feedback,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262,2,['feedback'],['feedback']
Usability,"Thank you for looking into this and sharing the analysis. I always believed that there is _a lot_ to be gained from a decent coverage collection strategy. For example, I have seen Genome STRiP cleanly resolving cases that are essentially impossible to resolve from our raw data. Perhaps we should:. (1) Include genome mappability analysis tracks as a filtering strategy w/ or w/o MQ-based filtering. We can download fairly accurate mappability data based on noisy Illumina-like paired-end reads from here:; https://sourceforge.net/p/gma-bio/wiki/Home/; They have a decent publication too. (2) While a simple fragment-based coverage collection has major pitfalls, I am not quite convinced that one must throw away fragment information altogether. By theoretically considering various SV events (tandem duplication, disperse duplication, deletion, inversion, inter- and intra-contig translocation, etc.), and studying paired-end reads coming from various parts of such SVs case by case and how they would theoretically align to the reference, we can come up with a heuristic counting strategy that gives the most consistent signal for downstream tools. This analysis requires taking into account basic summary statistics such as read and fragment length distribution in order to resolve anomalous fragments to putative SV events. I have worked out a few cases and this is fairly doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064:601,simpl,simple,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064,2,['simpl'],['simple']
Usability,Thank you for the feedback! I applied it all. Back to @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107677904:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107677904,1,['feedback'],['feedback']
Usability,Thank you for the feedback! Will update style.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825,1,['feedback'],['feedback']
Usability,"Thank you for the kind explanation, *@davidbenjamin*. I understand your; rationale. BTW, in my test with a PoN of ~100 sample, this set of changes; makes significant performance improvement regardless of the value of; --genotypePonSites. Could you advise how many samples you used to create; the PoN you test? Thanks!. On Tue, Aug 8, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/; > Mutect2Engine.java; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>:; >; > > }; >; > - if (hasNormal() && normalContext != null && countNonRef(refBase, normalContext) > normalContext.getBasePileup().size() * MTAC.minNormalVariantFraction) {; > + if (!MTAC.genotypePonSites && !featureContext.getValues(MTAC.pon, new SimpleInterval(context.getContig(), (int) context.getPosition(), (int) context.getPosition())).isEmpty()) {; >; > I deliberately made --genotypePonSites false by default because running; > local assembly and realignment of PoN sites is very expensive, especially; > so because PoN sites are frequently in regions that yield very messy; > assembly graphs, hence many haplotypes. It's true that explicit results can; > be useful, and we frequently want them in the course of development, but a; > tenet of the GATK is to make the tools work as well as possible with; > default settings.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABD6FgXbu1QybkQOkGpGBtjNQINUx13rks5sWRk3gaJpZM4OcvPO>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425:908,Simpl,SimpleInterval,908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425,1,['Simpl'],['SimpleInterval']
Usability,"Thank you so much @Neato-Nick for your feedback, highly useful indeed! I was just worried that all these locations with warning signs are getting bypassed which as per your feedback should not be the case.; Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663:39,feedback,feedback,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663,4,['feedback'],['feedback']
Usability,Thanks @asmirnov239 for the feedback! I will incorporate these changes shortly to the forum version and here for posterity.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288:28,feedback,feedback,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288,2,['feedback'],['feedback']
Usability,"Thanks @davidbenjamin for the feedback and sorry for the slow response. We have been working on improving PairHMM by adding AVX-512 (#3615) and FPGA (#2725) implementations. . We are also adding AVX2 (#3701) and AVX-512 (future PR) Smith-Waterman, which will improve the performance of Mutect2. We have the data above and will provide benchmarking results of your Mutect2 command with these improvements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-338732871:30,feedback,feedback,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-338732871,2,['feedback'],['feedback']
Usability,"Thanks @davidbenjamin, I can try that out. Any other parameters or modes that you feel might be gating any of these metrics/optimizations, which should be explored jointly with the SW parameters?. I guess the same question applies for `linked-de-bruijn-graph`, which is currently marked as experimental: what would be the procedure/criteria for changing the default behavior? Hopefully, we can answer this question for the case of a binary parameter before tackling 12 parameters! In general, I'm interested in establishing clear processes so it's easier for anybody to propose improvements. If there's no clear answer just yet, I'm happy to stop at exposing these parameters, perhaps consolidating defaults to one of the current sets if that is not too disagreeable (which is just slightly more complicated than a binary decision). Don't want to rabbit hole if there's no need. Hopefully, at the least, the blog-like documentation above will provide useful pointers to anyone that might want to tackle similar efforts in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619:524,clear,clear,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619,4,['clear'],['clear']
Usability,"Thanks @droazen, I suspected that was the case from looking at the history. Though it's not clear to me from @eitanbanks' commit why he would disable it for non-ERC modes. FWIW my PR looks to have only failed where the HC tests are comparing against existing files, and the existing files don't have phasing (whereas newly generated test files do). I'm going through and double-checking that that is the case, and will hopefully amend that PR shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198:92,clear,clear,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198,2,['clear'],['clear']
Usability,Thanks @gbggrant! @droazen @ldgauthier I just pushed a branch that resolves the error by simplifying the evidence-to-index cache.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-626448066:89,simpl,simplifying,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-626448066,2,['simpl'],['simplifying']
Usability,"Thanks @ilyasoifer ! Was the test bam you added aligned with minimap2? If not, we should make sure to add at least one simple HaplotypeCaller regression test that takes an actual minimap2-aligned input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558029097:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558029097,2,['simpl'],['simple']
Usability,Thanks @jean-philippe-martin! I've addressed your other feedback points and submitted a new pull request against the main repo (so that tests are run): https://github.com/broadinstitute/hellbender/pull/827. I'm closing this one now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131862850:56,feedback,feedback,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131862850,1,['feedback'],['feedback']
Usability,"Thanks @jonn-smith. Is Funcotator ready for us to document now or in the next month? Meaning, is it usable by users now? Otherwise, we can release an `alpha` tutorial initially to get folks to use it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664:100,usab,usable,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664,2,['usab'],['usable']
Usability,"Thanks @kdatta. The branch builds now, but there are a couple of problems that cause several tests to fail, including some existing tests that used to pass. You can see the results [here](https://travis-ci.org/broadinstitute/gatk/jobs/221534229). - The main issue is that GenomicsDB fails to load. This causes the importer tests to fail, as well as the existing GenomicsDB integration tests. (Note that the importer tests fail with a null pointer exception, but that problem is secondary and only happens when the db fails to load, which is the root problem.) We can fix the NPE in code review, for now the main issue is fix the core problem of why genomics db fails to load. - The changes in OptionalVariantInputArgumentCollection and RequiredVariantInputArgumentCollection are causing argument name collisions in other tools, which is why ExampleIntervalWalkerIntegrationTest tests are failing in this branch. The simplest fix in the short term is to just revert the changes you made to those two classes, and remove the new VariantInputArgumentCollection class. These aren't being used by the importer tool anyway. It should be pretty easy to reproduce load issue, it happens on my laptop and and travis, but let me know if you need help or have questions about any of this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791:916,simpl,simplest,916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791,2,['simpl'],['simplest']
Usability,"Thanks @lbergelson and @droazen. Could it be possible to add a simple patch to add all the reads to the returned `AlignmentContext`, instead of just add the `ReadPileup` from just one covered sample?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081:63,simpl,simple,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081,1,['simpl'],['simple']
Usability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:139,learn,learned,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,2,['learn'],['learned']
Usability,Thanks @samuelklee for the feedback! I will go over these and incorporate as much as I can before Monday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547:27,feedback,feedback,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547,2,['feedback'],['feedback']
Usability,"Thanks JP. This is really Interesting. Unfortunately I think the vcf slice is the major motivating use case. How; large was that vcf? Do you think there's anything we can do to get some; speedup with NIO for small files when we only have 1 core? I'm not totally; clear on how data transfer over a network interacts with thread waiting.; If we are receiving data over the internet does that need cpu time or is; that handled asynchronously by the network card? I.e. if we're prefetching; in on thread, can that thread be asleep or is it consuming cpu time the; whole time a transfer is in progress?. I suspect that the immediate next question people are going to have is ""4; cores are inefficient, 1 core is slow, how about 2 cores..."". I'm curious about async and vcf. The updated slides show vcf with async on; being ~40% slower than with async off. That's; setting use_async_io_write_tribble on / off? It looks like we should just; disable it if we're on a single core, but by default we have it on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588:263,clear,clear,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588,2,['clear'],['clear']
Usability,"Thanks a lot @davidbenjamin! One of the questions that I have is how to add a new read to the `ReadLikelihoods` for a new allele that is found while iterating. A very simple example will be:. ``` java; public static PerReadAlleleLikelihoodMap flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele) {; final PerReadAlleleLikelihoodMap pralm = new PerReadAlleleLikelihoodMap();; final byte ref = refAllele.getBases()[0];; for (final PileupElement e : pileup) {; final Allele current;; if (e.isDeletion()) {; current = Allele.SPAN_DEL;; } else if (e.getBase() == ref) {; current = refAllele;; } else {; current = Allele.create(e.getBase());; }; pralm.add(e, current, DEFAULT_FAKE_LIKELIHOOD);; }; return pralm;; }; ```. The solution that I found after looking at the class was this one, that it's very complicated:. ``` java; public static ReadLikelihoods<Allele> flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele, final SAMFileHeader header) {; final Set<Allele> alleleSet = new TreeSet<Allele>();; final Map<String, List<GATKRead>> reads = new HashMap<>();; final byte ref = refAllele.getBases()[0];; alleleSet.add(refAllele);; for (final PileupElement e : pileup) {; if (e.isDeletion()) {; alleleSet.add(Allele.SPAN_DEL);; } else if (e.getBase() == ref) {; alleleSet.add(refAllele);; } else {; alleleSet.add(Allele.create(e.getBase()));; }; final String sample = ReadUtils.getSampleName(e.getRead(), header);; List<GATKRead> list = reads.getOrDefault(sample, null);; if(list == null) {; list = new ArrayList<>();; reads.put(sample, list);; }; list.add(e.getRead());; }; final ReadLikelihoods<Allele> likelihoods = new ReadLikelihoods<>(new IndexedSampleList(reads.keySet()), new IndexedAlleleList<Allele>(alleleSet), reads);; for(final PileupElement e: pileup) {; final String sample = ReadUtils.getSampleName(e.getRead(), header);; final LikelihoodMatrix<Allele> l = likelihoods.sampleMatrix(likelihoods.indexOfSample(sample));; f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107:167,simpl,simple,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107,2,['simpl'],['simple']
Usability,"Thanks a lot for all your feedback about this @lbergelson and @droazen. From my side this could be close now, although it may be useful to have some of this information in the Wiki to avoid confusion. Thank you very much again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273732039:26,feedback,feedback,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273732039,2,['feedback'],['feedback']
Usability,"Thanks a lot for your detailed information. ; I just had a look into the branch you told me, but it looks quite complicated to me at this time. I think I will wait until the official release in January and hope for some kind of best practise guidelines to come up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559:242,guid,guidelines,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559,2,['guid'],['guidelines']
Usability,"Thanks for all the feedback Adam. I got a bunch of the metrics code written; today and hopefully once I have that I can actually test this code and port; the other tests. I will merge that PR into this one and fix these changes; and get back to you. On Thu, Jul 16, 2015 at 9:04 PM, Adam Kiezun notifications@github.com; wrote:. > Assigned #631 https://github.com/broadinstitute/hellbender/pull/631 to; > @tovanadler https://github.com/tovanadler.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/pull/631#event-358132720.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/631#issuecomment-122149505:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631#issuecomment-122149505,1,['feedback'],['feedback']
Usability,"Thanks for getting this cleared up. ; OK, what next? I'll check with colleagues who may be aware this 'feature'. Perhaps the case can be made more clearly by a group of users, including visible labs working on human evolutionary genomics. . I don't know the CA genomics community well, but my shallow poling suggests most are happily unaware that SNPs near indels will often be assigned lower quality than they might.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551:24,clear,cleared,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551,2,['clear'],"['cleared', 'clearly']"
Usability,"Thanks for helping me to understand why you didn't mark the metadata. This may seem like quibbling, but I'd suggest that we mark the metadata with a comment character, and let the pandas/R users remove it. They'll notice if they forget to do that, because the columns won't be named as expected, and they'll have to fix it up. Whereas the risk for automated programs is that they'll simply delete the first row, which might be real data if the file has been reordered for some reason, or if the tool implementing the standard is non-compliant. The resulting bugs will be subtle, and might easily go undetected. Building in behavior to delete lines starting with ""CHROM\t"" seems odd and fraught with peril in a way that building in behavior to strip comments, doesn't. That's my take, anyway.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480956381:383,simpl,simply,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480956381,2,['simpl'],['simply']
Usability,"Thanks for incorporating feedback. Everything looks good except I think since I last looked at this PR, `--sparkRunner` has become `--spark-runner`. If this will get fixed, then there is a tiny thing to fix in addition. The ReadsPipelineSpark example command is missing a backslash.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355892072:25,feedback,feedback,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355892072,2,['feedback'],['feedback']
Usability,"Thanks for reporting this @lbergelson. I've raised it internally at Cloudera, so we'll see if it can be fixed. I also had a hunt around to see if it would be possible to suppress this on the Gradle side, but I couldn't see anything. It's possible for Maven, but I don't think this applies to Gradle:. http://maven.apache.org/guides/mini/guide-http-settings.html#Ignoring_Cookies",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/610#issuecomment-118360200:325,guid,guides,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/610#issuecomment-118360200,2,['guid'],"['guide-http-settings', 'guides']"
Usability,"Thanks for sharing your analysis. What is your criterion for choosing the main peak? I have seen quite a few WGS samples, which before mappability filtering, have their coverage peak at 0, and/or the median count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:434,simpl,simply,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669,2,['simpl'],['simply']
Usability,"Thanks for the explanation. It isn't clear to me that the SAMRecord API was ever intended to support ; headerless records (except maybe in very rare corner cases). I don't really know the scope of hellbender. If it is just for internal ; DSDE tools development, then I guess it doesn't matter.; If you ever want to leverage code/libraries from elsewhere, then those ; would have to be ""headerless-aware"", I guess. For example, a common operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:37,clear,clear,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,1,['clear'],['clear']
Usability,Thanks for the feedback @cmnbroad! I could wait til #2218 is accepted to continue working and check that nothing is broked...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261775822:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261775822,2,['feedback'],['feedback']
Usability,"Thanks for the feedback @cmnbroad. I would like to have something more consistent for my own tools, independently on if I'm using `Path` or `File, but it could wait.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-275080208:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-275080208,2,['feedback'],['feedback']
Usability,Thanks for the feedback Brad. We'll continue to look into the core dump to make sure it doesn't cause issues in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352,2,['feedback'],['feedback']
Usability,Thanks for the feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278732586:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278732586,2,['feedback'],['feedback']
Usability,"Thanks for the feedback, @cmnbroad.  @droazen, should I open a ticket for implement the plugin and close this issue? What's about the checking of the quals?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652,2,['feedback'],['feedback']
Usability,"Thanks for the feedback, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2177#issuecomment-288761221:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2177#issuecomment-288761221,2,['feedback'],['feedback']
Usability,"Thanks for the quick review, @ldgauthier!. I don't think my fix will address any non-determinism in the integration tests. I'm inclined to just do better with the new tools---there does seem to be enough duct tape in the integration tests regarding re/setting the RNG so that the exact-match tests consistently pass. As for learning how to run the WARP tests, I think that would indeed be pretty useful---for anyone that might have to update code for VQSR or the new tools in the future! Can we teach everyone to fish? Isn't this what CARROT is for?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649:324,learn,learning,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649,2,['learn'],['learning']
Usability,"Thanks for the response, @droazen! Technically, yes, that would be satisfactory & accurate... and if that's easiest, I'm fine with that. . From a user perspective though, it might be beneficial to report the first occurrence of this error, as that's most likely where I would go back to do future testing & troubleshooting. That being said, all of the overlapping intervals are already outputted to stderr, so all the information is retained regardless, and I could just look through the logs to find that first problematic interval. As an aside, I find it a bit weird that the overlapping interval message shows up as a _warning_ even when using the `-no-overlaps` option (I would assume it would be an error, not a warning). In my experience, most errors cause the program to quit immediately. So, perhaps instead, if this warning were an _error_ when using the `-no-overlaps` option, the program would stop after the first occurrence of this error... and then the error message would be accurate. Maybe that was the original intent of this code. But, again, if that requires much more testing & changes, when a quick rewording would also suffice, there's no need. If it's simply a rewording, I'm happy to make a pull request. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570:1175,simpl,simply,1175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570,2,['simpl'],['simply']
Usability,"Thanks for the review @bshifaw. > If its too late now maybe for later it would be nice to add a runtime block for each task so that it would executable in a cloud environment. There is limited support for runtime blocks now (you can see one [here](https://github.com/broadinstitute/gatk/pull/6504/files#diff-bebfeef541c0066d7a692aae54d76f6bR263)) but it requires [annotating](https://github.com/broadinstitute/gatk/pull/6504/files#diff-7b13b03f206ff3c35e846f8a15eaf290R88) the tool with the proper values. It currently only supports the `memory` attribute, but we can certainly add support for other attributes if it makes sense for them to have static values. Perhaps we should add `docker` ? Others ?. > Why have inputs declared at a workflow level input block (which requires them to be repeated in the call block, and again at the task input block) when they can be declared simply at the task level?. I chose to make each WDL have both a workflow and a task, and generated an input JSON that contains the default values for each optional arg so that only the required args have to be provided (they're initialized with the type of value required similar to the skeleton that womtool generates). But maybe theres an alternative structure thats better. Can you point me to a WDL that uses the structure you're proposing? I'm not sure I understand how it would be used. > If it's an easy fix it would be nice to see the full parameter name instead of abbreviation for input and output (e.g. ""I"", ""O""). I used the full names wherever possible, but many of the tools have args with names that are WDL reserved works like `input` and `output`, so I had to use the short name in those cases. An alternative would be to mangle/annotate them instead, i.e., turn `input` into something like `input_` or some such thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-612900828:879,simpl,simply,879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-612900828,2,['simpl'],['simply']
Usability,Thanks for the review @droazen. I've addressed all your feedback in the latest commit. I'll merge once the tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-175651593:56,feedback,feedback,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-175651593,1,['feedback'],['feedback']
Usability,"Thanks for the review @lbergelson. I've addressed most of the feedback, but still have a few more to do.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267098362:62,feedback,feedback,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267098362,2,['feedback'],['feedback']
Usability,"Thanks for the review and running those tests, @ldgauthier! Will restore the aforementioned GnarlyGenotyperIntegrationTests and update a few other exact matches in the rebase this afternoon. You also asked above if there was a theoretical reason to change the threshold. Since it seems the original was relatively arbitrary (at least from what I've been told, happy to be corrected), I think we can leave it. The new annotation is strictly larger, so we will then be slightly more conservative about keeping sites if we leave the threshold fixed. You can think of this as a slight change in the decision boundary in genotype-count space---perhaps I can add some plots to this thread this afternoon to demonstrate. In practice, what we care about is whether: 1) many sites flicker across the change in boundary after hard filtering, and/or 2) these sites result in discrepancies post-VQSR. I think the tests you ran suggest that we don't need to worry much about the second issue, and I can take a closer look later to check about the first (which will depend simply on the number of samples and the allele frequency spectrum). We can also take a basic look at how things might change with e.g. more samples using the aforementioned plots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272:1059,simpl,simply,1059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272,2,['simpl'],['simply']
Usability,"Thanks for the suggestion!. To answer the questions:; >Would it make more sense to have a much more stringent cutoff for alignment size after de-overlap? . Yes! The filtering step is actually done in the class `AssemblyContigAlignmentsConfigPicker` in the `alignment` package, where the unique read span length filter is defaulted to 10 base. I put it this way so that the contigs won't be ""re-classified"" in `CpxVariantInterpreter` as having a simple chimera and having to be sent back to `SimpleNovelAdjacencyInterpreter`. So, the idea was to separate the concerns of alignment picking from type inference. > What's the downstream effect of changing this cutoff that you're proposing here; and would it make sense to make it something much higher, like say 19 to match the minimum BWA-MEM seed length?. I'll experiment with the new suggested length.; The idea behind settling on this size-10 filter was to be more permissive when it comes to alignment filtering in `AssemblyContigAlignmentsConfigPicker`, and filter variants later in VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403600389:445,simpl,simple,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403600389,3,"['Simpl', 'simpl']","['SimpleNovelAdjacencyInterpreter', 'simple']"
Usability,"Thanks for the suggestions @mwalker174! That makes sense and it gives me something to think about. I'll close this issue since it's clearly not a bug. If I have more questions like this, is there a better place to ask them? Or should I just open another issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-653003128:132,clear,clearly,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-653003128,2,['clear'],['clearly']
Usability,"Thanks for these questions, @tfenne, and glad you are experimenting with the workflow. Several Broad-internal groups are running various WGS and WES analyses and are seeing encouraging performance, so I’m looking forward to hearing feedback from you as well. However, I am currently indisposed and may be out for the next month or so, but @mwalker174 (who has now taken over from me as CNV tech lead, with a focus on the germline workflows) and @asmirnov239 should be able to point you in the right direction and respond to you in more detail. In the meantime, you may find some pointers in various forum posts or issues here on GitHub. We’re looking into improving documentation processes for runtime/requirements GATK-wide, which should help with this sort of thing in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-532343246:232,feedback,feedback,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-532343246,2,['feedback'],['feedback']
Usability,"Thanks for your feedback, @cmnbroad. In my case, I think that `IntegrationTestSpec` is a good way of avoid complicated code to test tool results, but it is true that it have some problems (one that I had was the usage for testing programs where the outputs are determined by a prefix in the command line, but with different suffixes). I think, from the API user point of view, that a class like `IntegrationTestSpec` to facilitate program output testing (including user exceptions) will be nice for developing purposes. Nevertheless, this is just a convenience that I asked for here, but I can try to solve the issues with the `BaseTest` instead. By the way, I would love to have this interface in GATK at least for now, because several of my tools rely on the `IntegrationTestSpecs` for development...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889,2,['feedback'],['feedback']
Usability,"Thanks for your feedback, @droazen. I think that it will be nice to have a better annotator engine for handling what should be on/off in which cases instead of hardcoded them when it is necessary. But I can wait til the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995,2,['feedback'],['feedback']
Usability,"Thanks for your feedback, @jamesemery! I just made some changes before I saw your last comment. I liked the idea of using the tool verbosity as the default but allowing the Spark verbosity argument to override it. Even if that has no effect at the moment, I just pushed a solution for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141,2,['feedback'],['feedback']
Usability,"Thanks guys!. On Sat, Sep 23, 2017 at 11:38 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* requested changes on this pull request.; >; > Done with my review. Mainly the usual stuff about writing more idiomatic; > Java that all C++ coders go through!; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646010>:; >; > > +import org.broadinstitute.hellbender.utils.IntervalUtils;; > +import org.broadinstitute.hellbender.utils.SimpleInterval;; > +; > +import java.io.File;; > +import java.util.List;; > +; > +; > +; > +@CommandLineProgramProperties(; > + summary = ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + pri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:604,Simpl,SimpleInterval,604,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['Simpl'],['SimpleInterval']
Usability,Thanks you for accepting it... and all the reviewers for the feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206:61,feedback,feedback,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206,2,['feedback'],['feedback']
Usability,"Thanks! Just to be clear, the PR is incomplete. We need to determine the additional dependencies (which were previously installed along with R) required for AVX, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300,2,['clear'],['clear']
Usability,"Thanks, @cmnbroad!. - You're right about gatkbase-2.1.0, that image is coming from #5026, which needs some more work. We can delete it for the time being if you think it'll cause confusion.; - Correct, I think the import statement for `reshape` in BQSR.R was always incorrect/extraneous. `reshape2` is the correct dependency for `ggplot2` (which is itself imported), and `reshape` is not explicitly used in BQSR.R. So to recap: I removed the installation of this unnecessary package, but failed to remove an unnecessary import statement since it was in an untested code path, which was then caught when users tried to run the tool. Investigation of this issue then revealed that `ggplot2` was not installed correctly in the current base image, due to a completely unrelated dependency issue.; - Good call on clearing the Travis cache. Not actually sure how to do that, do I just delete the cache at https://travis-ci.org/broadinstitute/gatk/caches for this particular branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924:808,clear,clearing,808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924,2,['clear'],['clearing']
Usability,"Thanks, @davidbenjamin. I started learning Java over the break as planned. I'm a quarter in to my intro to Java class. So at this point, I think it best to leave the review to those who are more versed in the language.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317:34,learn,learning,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317,2,['learn'],['learning']
Usability,"Thanks, @droazen. While I understand the effects of the funding landscape on academic resources, it seems to me this is a full capitulation of the GATK developer team given a serious bug, especially in light of the fact that the team seems to have enough resources to continue working on Mutect3. Mutect2 has been one of the best performing variant callers of the last years and is a major reason for the Broad's good reputation in the oncology bioinformatics field. GATK and Mutect2 are used by hundreds of institutions in clinical practice, affecting thousands of real patients' lives. Almost all of these institutions are likely to use clinical WES assays due to cost reasons and will thus have been directly affected by this issue _for the last three years_. Also, almost all of these institutions will never learn of this bug since they likely trusted in the developers to have proper functional regression tests in place. If this is indeed the best the Broad can do as an institution, then I will take your offer of providing a build of Mutect2 4.1.8.1 with the log4j vulnerability patched out - thank you. The one thing that I am asking for in addition (for the sake of the overall oncology bioinformatics community), however, is that you conduct a best effort to notify organizations (universities, hospitals, and biotechs/pharmaceuticals that you know are using Mutect2) and best-practise workflow owners (Nextflow, Snakemake, WDL, CWL etc. that include Mutect2) of the forced downgrade. Also, I think it makes sense to include a very prominent warning into the Mutect2 READMEs and GATK best practice documentations and guides. I know that this is work, too, but with success comes responsibility, and I can just hope that providing proper warnings uses less developer bandwidth than applying binary search to find out which of these [10 commits between 4.1.8.1 and 4.1.9.0 that are touching variant filtering (see below)](https://github.com/broadinstitute/gatk/compare/4.1.8.1...4.1.9.0) bro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226:813,learn,learn,813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226,2,['learn'],['learn']
Usability,"Thanks, @lbergelson. I was also thinkinhg that this code is mostly deprecated, but I wanted to ported as is for the first pass review. I just need to support the new mpileup version (unique sample, because if not it is more difficult), because the consensus one is deprecated. I will update the codec and add some tests for it. In addition, ~~I was thinking to create a list of `PileupElement` inside the feature to make easier to compare the internal pileup, but with ""reads"" of one base-pair.~~ Update to this: `PileupElement`is difficult to generate without including `GATKRead` simple implementation, and I think that it is not worthy. On the other hand, I will improve the walker itself. I will tell you when I finished with the changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331:582,simpl,simple,582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331,1,['simpl'],['simple']
Usability,"Thanks, @yfarjoun, I think those are reasonable. Just to be clear, the code for the tool mentioned above is a little confusing, in that an early fail for writability when the directory does not exist prevents us from reaching code that appears to be intended to create the directory. Not a big deal in the end (and I checked that this was also the case before the PR). But minor things like this can easily break downstream scripts, etc., as was demonstrated above, so we should take some care. I agree that it's fine to leave some decisions up to each tool, but we should try to document them for the benefit of users and future devs that might need to maintain the behavior of the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470172806:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470172806,2,['clear'],['clear']
Usability,"Thanks, James! I'll check that out - I think we might be able to leverage; that. best,. Brian. On Fri, Mar 8, 2024 at 2:38 PM jamesemery ***@***.***> wrote:. > Hey @brianjohnhaas <https://github.com/brianjohnhaas>. I'm not quite sure; > i fully understand what we can change to help you here. However there is a; > feature you might not be aware of in the bamout that can help you figure; > out which reads go with what haplotype. In our bamout we assign a tag (that; > for whatever reason it looks like IGV hides by default) called the XA tag.; > If you look at an IGV bamout and color by that tag you can see what reads; > were grouped by what haplotypes. If a read has no XA tag that means it was; > non-informative about any one haplotype over a second possible contender; > and thus it was not strong evidence one way or another.; >; > Below is a screenshot of what it looks like to do this in a very simple; > case. Hopefully this answers your question? I would be happy to go deeper; > into this if you would like.; >; > Screenshot.2024-03-08.at.2.35.42.PM.png (view on web); > <https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX773HENZD2UVB356GDYXIHTTAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOBWGMYDEOJZGQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258:906,simpl,simple,906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258,2,['simpl'],['simple']
Usability,"Thanks, but I’m still not sure I understand. What are the intervals that HaplotypeCaller “sees” at each given step:; Initial calling; Assembly; Final output; . From what you wrote, HaplotypeCaller uses the assembly-region-adding regions for initial calling and assembly, but not final output. But this does not make sense. Any exome calling should also include padded regions adjacent to the targeted exome regions in order to capture potential splice variants. . Another way to rephrase the question is this:. How precisely is the HaplotypeCaller output different when using only interval-padding vs only assembly-region-padding vs both?. . Thanks. . From: droazen <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Thursday, August 1, 2019 at 2:10 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Missing interval padding for HaplotypeCaller (#6071). . @gevro The --interval-padding argument is a GATK-wide argument shared by all tools that simply adds the specified amount of padding to each -L interval. The --assembly-region-padding argument is a HaplotypeCaller-specific argument that adds padding to both the -L intervals and the assembly regions created within the intervals. It allows the HaplotypeCaller to keep track of which regions are part of the main intervals for calling and which are just padding regions. So with --assembly-region-padding you shouldn't get variant calls in your VCF that are entirely contained within the padding regions, whereas with --interval-padding you would, since --interval-padding transforms the intervals before the HaplotypeCaller even sees them. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517412587:1093,simpl,simply,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517412587,2,['simpl'],['simply']
Usability,"Thanx for feedback. I obviously don’t know much if anything about the underlying logic but; have had enough experience to look in unusual places. Have a good weekend. RDB. On Fri, Nov 1, 2019 at 4:24 PM JP Martin <notifications@github.com> wrote:. > @rdbremel <https://github.com/rdbremel> for ""mystery 1"" see issue #5447; > <https://github.com/broadinstitute/gatk/issues/5447>. This should be an; > innocuous warning that it can't initialize the Google Cloud Storage code; > and shouldn't cause a failure unless you try to access paths that start; > with ""gs://"". Going through the Cloud initialization steps described in the; > README should remove the warning (though again, this isn't required if you; > don't need to read files from the cloud).; >; > Mystery 2: For what it's worth, ""GC overhead limit exceeded"" indicates; > that the VM was spending too much time in GC. Running low on memory is a; > possible cause but generating too many small objects or being stuck in an; > infinite loop of allocation/deallocation are others. In the past these have; > been caused by inputs that were malformed in some way. This isn't the place; > for this discussion though, please file a separate issue since it's a; > separate bug.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VHWQ6XDSUQ6KEGISFDQRSM7TA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEC4GNZY#issuecomment-548955879>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANCR2VEC5ARUEQRTEDGJ3TDQRSM7TANCNFSM4I2MRFQA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454:10,feedback,feedback,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454,2,['feedback'],['feedback']
Usability,"That sounds prudent. The new version of the GermlineCNVCaller workflow will be available at release; I think you'll find the workflow itself to be quite streamlined and hopefully easy to use. However, because the model is relatively sophisticated, there are some parameters and model priors that may need to be set appropriately to generate optimal results. We plan on spending some time shortly after release doing internal evaluations to determine some best-practices guidelines for data generated at the Broad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485:470,guid,guidelines,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485,2,['guid'],['guidelines']
Usability,That would be a clearer error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999:16,clear,clearer,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999,1,['clear'],['clearer']
Usability,"That would not be a valid test, since it wouldn't be testing the way the code actually handles invalid intervals. All we want to know is that we throw when we encounter an invalid interval. Did I mention that this very simple change is urgently needed by many branches?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/526#issuecomment-104401315:219,simpl,simple,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/526#issuecomment-104401315,1,['simpl'],['simple']
Usability,"That would work, yet I don't see why we simply can focus only in codecs that return the right type. Seems that would be the same amount of work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163301007:40,simpl,simply,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163301007,1,['simpl'],['simply']
Usability,"That's correct, @akiezun.; However, it's not just stripping out that code. There are a ton of optimizations that can then be made to the code to simplify it afterwards. These classes were made very bulky to accommodate the indel calibration, and we should really remove that bulk. I can help with that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152047427:145,simpl,simplify,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152047427,1,['simpl'],['simplify']
Usability,"That's correct. We could easily add an optional sequence-dictionary input for plotting in the WDL, if desired, but I decided to keep it simple for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386341401:136,simpl,simple,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386341401,2,['simpl'],['simple']
Usability,That's exactly what I came here to do! I checked if Picard's FixMateInformation would fix it but it doesn't look that simple.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222236240:118,simpl,simple,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222236240,1,['simpl'],['simple']
Usability,"That's very strange @cmnbroad -- in the test I did in front of you yesterday, I added only the exclusion above and it worked fine for me. Are you building with `gradle` or `gradlew`?. Recommend we add whatever exclusions are necessary in a separate, simple PR, independent from the GenomicsDB PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292619716:250,simpl,simple,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292619716,2,['simpl'],['simple']
Usability,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:886,simpl,simply,886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090,2,['simpl'],['simply']
Usability,"The GATK4 port of GATK3 VariantEval uses a MultiVariantWalker traversal, along with individual `FeatureInput` arguments for evals, knowns, comps, etc., which are all manually merged together as the walker's driving variants. The resulting variants are then manually processed in groups, by start position. Since the tool needs to know the origin of each variant (eval, comp, dbsnp, known, etc.), and since this isn't preserved by the engine, it re-queries the `FeatureContext` for each input to get the same set of variants grouped by source. Since the inputs are typed as `FeatureInput`, this results in all inputs being both consumed and cached twice; once by `MultiVariantDataSource` and once by `FeatureManager`. Once alternative would be to use a LocusWalker, but that would still require index queries (though the features would be cached), and it would still require manual filtering/aggregation on start position. Proposed fix is to switch the base class to use `MultiVariantWalkerGroupedOnStart` (this would allow removal of `PositionAggregator` class); change the engine to preserve the input source of each variant as proposed in https://github.com/broadinstitute/gatk/pull/4571; and change the input arguments for VariantEval from individual named arguments to tagged feature inputs. This would greatly simplify the initialization code, eliminate redundant reading and caching, and allow the tool to do the input source grouping by just looking at each variant's source field.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5439:1315,simpl,simplify,1315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5439,1,['simpl'],['simplify']
Usability,"The HaplotypeBAMWriter implementation as ported from GATK is currently spread out over 5 classes, with a base class and two subclasses for the writers and a base class and one subclass to represent the writer destination. All of the functionality can be reduced to one simple HaplotypeBAMWriter class (or possibly two if we want to keep the destination separate).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/944:269,simpl,simple,269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/944,1,['simpl'],['simple']
Usability,"The Hardy-Weinberg equilibrium (HWE) theorem characterizes the distributions of genotype frequencies in populations that are not evolving. Let’s recall it in its simplest form. [Hardy-Weinberg] Let ( A ) and ( a ) be alleles at a single locus in a non-evolving population with random mating. Let ( p ) and ( q ) be their respective frequencies in that population. ( p ) and ( q ) will remain constant in average from generation to generation. The expected frequencies of the genotypes, ( AA ), ( Aa ) and ( aa ), will also remain constant and are respectively ( p^2 ), ( 2pq ), and (q^2 ). Description:. Use Wigginton’s exact test because it adequately controls type I errors in large and small samples. Calculated by:. Pedstats and vcftools use efficient implementations from Wigginton et al.; use code by Wigginton as your starting point (need to translate to java i think). Remark:. Deviations from HWE can indicate inbreeding, admixture, or population stratification. In order to avoid the latter, HWE tests should be run for each ethnicity/population separately. Typically a variant is filtered out if, for any of the ethnicities, the P-value is lower than (10^\textrm{-6}). HWE tests can also identify loci with systematic genotyping errors, which makes HWE useful for QC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/538:162,simpl,simplest,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/538,1,['simpl'],['simplest']
Usability,The MAF reader could simply produce a `VariantContext` or something else that can be iterated through via a `Walker`.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3703:21,simpl,simply,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3703,1,['simpl'],['simply']
Usability,The PR at googleapis/google-cloud-java#5789 makes it possible to add a BigQuery dependency without having to move to the unshaded version. This should make our lives simpler.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784:166,simpl,simpler,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784,2,['simpl'],['simpler']
Usability,"The Talkowski lab version of this is in R and requires some packages that don't seem to be available anymore as well as the python tool svtk, also developed in their lab. It also localizes all the files with a separate Java program they developed. Their implementation is here (most critically gCNV_Pipeline.Rmd and gCNV_helper.jar): https://github.com/theisaacwong/talkowski/tree/master/gCNV It appears to be under active development. My simplified implementation is at https://app.terra.bio/#workspaces/broad-firecloud-dsde-methods/gCNV-CMG-test/notebooks/launch/perform_clustering.ipynb but it's still under development with some help from Brian in TAG.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837:439,simpl,simplified,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837,2,['simpl'],['simplified']
Usability,"The WDL *input* parameter for any tool argument that is the name of a file that is *created* by the tool has WDL type `String` because if the input parameter were typed as `File`, cromwell would attempt to localize the (most likely non-existent) file at the start of the task. However, in the output block, the parameter has to have type `File` for the reverse reason; if it were `String`, it wouldn't be delocalized. The transformation is admittedly non-intuitive when reading the WDL code. Maybe there is some better alternative ?. The reason the parameter doesn't appear in the command block (in this case anyway) is because there is no corresponding tool parameter. Any `companion` files like this, such as input reference dictionary, input file index, etc., that don't appear as named tool parameters still have to be included in the WDL parameters, but aren't passed directly to the tool. I generally tried to keep the companion parameters adjacent to their source parameter whenever they appear in the WDL or JSON files, so they always travelled together. But since outputIndex is an *optional* companion for a *required* output, this results in it being listed under ""required"" parameters. We could separate the optional args into a separate ""Optional"" header comment as we do for (non-companinon) optional tool args, or we could just add a line comment like:; ```; # Required Arguments; String output_arg; String? outputIndex // optional companion for output_arg; ```. Agreed that it would be nice to find a robust way to prevent the name guessing required.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736621798:455,intuit,intuitive,455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736621798,2,['intuit'],['intuitive']
Usability,The [Google Java Style guide](http://google-styleguide.googlecode.com/svn/trunk/javaguide.html) links are dead and give a 404 error. References were changed to [Google Java Style guide](https://google.github.io/styleguide/javaguide.html).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5405:23,guid,guide,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5405,2,['guid'],['guide']
Usability,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:321,simpl,simply,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,2,['simpl'],['simply']
Usability,"The `SlidingWindowWalker` variant implementation (#1198) requires a similar class to `LocalReadShard` to perform sharding over variants. Here is a simple implementation based on the read one, which also includes:. * Move up to `Shard<T>` some methods in the read shard implementation.; * Extract a common `FilteringIterator` from `ReadFilteringIterator`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2372:147,simpl,simple,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2372,1,['simpl'],['simple']
Usability,"The advantage of using SLF4J is that it is a general facade, so it makes simpler to change for one logging system to other if the bound is implemented. For the most common logging systems (log4j, jul, JLC, etc.), there are this implementation and even no-op logging. One of the nice things from slf4j is that it allows to use the logging format set by the software to every library dependency, controlling the verbosity of other libraries too. . After having a look to the gradle dependencies, it seems that ADAM and Spark use slf4j. This will allow better integration with the two libraries: now the `slf4-jdk` is completely removed, and I don't know if this will blow up at some point if some of the ADAM/Spark classes try to load them. In addition, it will make GATK4 more general. Regarding features, I'm not using more that what log4j is providing, but I'm quite familiar with logback and I have a bias to use it if possible, but the GATK framework as it is implemented now ""force"" to use log4j. But anyway, I'm happy also with using log4j and I was only suggesting this for make GATK4 more general (and to come back in my work to logback, but that is just personal taste). @lbergelson, feel free to close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054:73,simpl,simpler,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054,2,['simpl'],['simpler']
Usability,"The annoyance is having to run a command on data, with proper syntax, to find out the Picard version. It should b something we can pull up via `docker inspect`, `gatk --version` or other simple command that does not involve some tool. I just assume this will not be addressed so I closed it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-386419307:187,simpl,simple,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-386419307,2,['simpl'],['simple']
Usability,"The behavior of the GATK3 CombineVariants was very inconsistent and the arguments weren't entirely clear. I also suspect that some operations weren't possible with the arguments given. Rather than port that old broken version, I would advocate for an overhaul or rewrite. @bhanugandham it's going to be a big project to collect requirements and expected behavior for this tool. For example, what should the MQ be for the combined VCF for two different input VCFs with different MQ values? Much of the confusion stemmed from the old ability to merge VCFs containing the same sample. In the case where we take one genotype for each sample name (e.g. the old ` -genotypeMergeOptions PRIORITIZE`) then I believe the old behavior was wrong in some cases, taking the filter status from an input VCF at random. We also need to clarify `FilteredRecordMergeType` options, e.g. https://github.com/broadinstitute/gsa-unstable/issues/935",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167:99,clear,clear,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167,1,['clear'],['clear']
Usability,The build should give a clear error message explaining how to skip building the native code if it fails to build.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1554:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1554,1,['clear'],['clear']
Usability,"The code changes here are actually fairly small all things considered after doing some cleaning of the working branches. There are 3 big differences between this branch and the previous version of LinkedDebrujin code: ; 1: Implemented an algorithm to the KBestHaplotypeFinder for coloring ""pivotal edges"" (i.e. edges in which we have made a choice that would be in the junction trees) and then upon fininshing with all of the junctinon tree reachable paths from reference source, we then check for edges that have not been recovered and attempt to rescue them (this fixes the loss of sensitivity from the previous version); 2: Changed the ReadThreadingAssembler to increment the kmer size it uses (when in JT mode) to increment its sizes AFTER it has attempted to recover haplotypes (this catches some new edge cases that causes complicated graphs to fail). This currently is a very rudimentary approach (we simply expand if the KBestHaplotypeFinder failed to find anything at all). ; 3: includes some code to squeeze extra sensitivity out of the junction trees by tolerating SNP errors when threading the junction trees themselves . There are a number of things I think maybe could be tweaked from here:; - I think ""k"" for max haplotypes can be lowered given the new haplotype recovery improvements; - We can and perhaps should revisit the question of how/when to expand the kmer size, as given recent fixes in this branch that could potentially save some sensitivity/specificity that we were losing before. (the code for one approach to this still lives in this branch). . Fixes #5924, #5923, #5828",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6394:908,simpl,simply,908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6394,1,['simpl'],['simply']
Usability,The current GenomeLoc needs a not-so-aptly-named GenomeLocParser to create it (making this more of a factor than a parser). Hopefully this can be simplified in the new engine.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/61:146,simpl,simplified,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/61,1,['simpl'],['simplified']
Usability,"The current Mutect panel of normals has been quite effective, but we can probably improve upon it by *learning* features that predict artifacts rather than *memorizing* problematic sites. As of June, 2017 we imagine an end goal of a deep learning model that predicts a fraction of artifact reads from reference context, annotations, and perhaps additional information such as chromatin states. This prediction could then be compared with the actual allele fraction to determine whether a true variant or artifact is a better explanation. One virtue of a regressor versus a classifier is that it doesn't require labeled data, which is hard to come by in the somatic context. It also gets around the risk of a classifier simply learning to throw out all low allele fractions.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3086:102,learn,learning,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3086,4,"['learn', 'simpl']","['learning', 'simply']"
Usability,The documentation for `LeftAlignAndTrimVariants` indicates that it only works for indels. It should be updated to work for MNPs as well. . This operation would simply remove any common leading bases from all alleles of a `VariantContext` and update the start position by however many bases were removed. It would be implemented in `LeftAlignAndTrimVariants.java:289` replacing the noop for non-indels.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7516:160,simpl,simply,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7516,1,['simpl'],['simply']
Usability,"The fact that `ReadCoordinateComparator` does not exactly match the ordering of htsjdk's `SAMRecordCoordinateComparator` has been the cause of a few bugs. It sorts all unmapped reads after mapped reads, whereas `SAMRecordCoordinateComparator` sorts unmapped reads that are assigned the positions of their mapped mates with their mapped mates. The issue is that the `GATKRead` interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return `null`/`0`. This was done mainly for consistency reasons and to simplify client code. Perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to GATKRead to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes, and use these in `ReadCoordinateComparator`. This should allow us to match `SAMRecordCoordinateComparator` exactly, and then `ReadCoordinateComparator` could be used even when sorting for the purpose of writing a bam.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1911:679,simpl,simplify,679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1911,1,['simpl'],['simplify']
Usability,The first commit is included in another PR and should be reviewed/committed independently there. Only the second commit in this PR contains the example collectors. There are two examples included here with simple tests; a single level collector and a multi level collector.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2049:206,simpl,simple,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2049,1,['simpl'],['simple']
Usability,"The gap-opening and gap-continuation parameters of Smith-Waterman realignment depend on PCA slippage and other stuff that depends on the sequencing platform and sample prep. In other words, they are not global parameters (_note: Smith-Waterman is often used to determine sequence similarity between individuals or species in which case its parameters are constants of the population. But a read differs from a candidate haplotype via sequencing error, not mutation_). @ronlevine suggested (and I am reporting because I like the idea) that we probably have sufficient data to learn these parameters for each sample.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1902:575,learn,learn,575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1902,1,['learn'],['learn']
Usability,The goal of this PR is to adjust the ingest in two ways:; 1. To update the ingest to loop through all samples (not just the first 10k); 2. To update the ingest to be far more efficient in a few ways:; - To remove the files that are downloaded to each vm so that they do not carry around the extra weight; - To check that the samples in the fofns have not been ingested already so that additional work doesn't need to be done toward processing those samples. There is still work to do around making the bulk ingest process significantly more user-friendly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8197:541,user-friendly,user-friendly,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8197,1,['user-friendly'],['user-friendly']
Usability,"The goal of this PR is to investigate if what needs doing to compile GATK and run its tests on Java 11. Some notes:. * The Scala 2.12 version of Spark 2.4 is needed to run on Java 11. I disabled `ADAMKryoRegistrator` in this branch since the version we are using is compiled against Scala 2.11. We might consider removing it entirely and no longer support ADAM formats directly in GATK - the workaround would be to use ADAM to convert to/from BAM/VCF. ADAM is also needed for reading 2bit files.; * Java 11 deprecates some APIs. Most of these are fairly easy to fix or suppress. The exception is the Javadoc API [com.sun.javadoc](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/com/sun/javadoc/package-summary.html), which has been replaced by [jdk.javadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:989,clear,clear,989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,2,['clear'],['clear']
Usability,"The indent there was sometimes 2 spaces, sometimes 4 spaces. The IDE likes to auto-format things sometimes, causing havoc when we're trying to have nice, simple, small commits. One solution is to let the IDE format things its way, so then things are consistent and if someone's IDE takes liberties and auto-formats a function then, well, it has no effect because the function's already the way the IDE likes it. Besides, consistent whitespace makes code easier to read.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/635:154,simpl,simple,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/635,1,['simpl'],['simple']
Usability,"The javadoc for `AddContextDataToReadSpark` clearly mentions that unmapped reads are filtered out, so it hopefully shouldn't be too much of a surprise. But I agree that ideally this transform should function as an ""outer join"" and not filter unmapped reads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/951#issuecomment-169148886:44,clear,clearly,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/951#issuecomment-169148886,1,['clear'],['clearly']
Usability,"The latest code in htsjdk, which includes https://github.com/samtools/htsjdk/pull/1454 (changes the Allele class into an interface, and uses SimpleAllele as the concrete implementation) causes the `VariantAnnotatorEngineUnitTest.testCombineAnnotations` test to fail because the order of the list returned by `ReducibleAnnotationData.getAlleles` is different with that change than it is without it (presumably due to the different hashCode/equals implementations). `AS_RMSMappingQuality.parseRawData` seems to assume that the order of the Alleles in the list returned by ; `ReducibleAnnotationData.getAlleles` exactly matches the order of the raw data in the String returned by `ReducibleAnnotationData.getRawData`, since it uses indexed access to the list, but I don't see anything that states or ensures/enforces this. Changing the Map maintained by `ReducibleAnnotationData` into a LinkedHashMap fixes the issue for this test, but that just changes the order to be input order - the real issue is that the contract around how the order of the list and the order of the raw data is maintained isn't clear. This will need to be addressed before we can upgrade to the next release of htsjdk.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7586:141,Simpl,SimpleAllele,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7586,2,"['Simpl', 'clear']","['SimpleAllele', 'clear']"
Usability,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7787:312,simpl,simply,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7787,1,['simpl'],['simply']
Usability,"The main issue was that the `StatusRuntimeException`s that the baseline error handling code was trying to catch in practice always seem to be wrapped in at least one layer of exception of a different type. There was no catch handing for these wrapper exception types so the `CreateVariantIngestFiles` tool would simply crash. ~The changes here also more generally try to follow the recommendations in the [BQ Write API documentation](https://cloud.google.com/bigquery/docs/write-api#error_handling), in particular `close`ing the `JsonStreamWriter` before retrying error codes not explicitly called out by the documentation.~. EDIT: actually closing the writer didn't work out too well as we use the writer in `PENDING` mode and closing it seems to lose all pending writes. 😬 So in this circumstance we just throw and let WDL-level `maxRetries` start the data loading over from the beginning. An exponential backoff was also added before retry attempts. Parallel logic was also added to load status writing which should reduce (but not eliminate) the possibility of inconsistent sample status writes that require manual intervention. There is still the possibility of an inopportunely timed preemption, which is why VS-262 exists. All of the WDL changes here are in support of a 2000-sample tieout, a large enough set that intermittent BigQuery errors are almost always observed. The tieout confirms that errors of the two major classes are seen (retryable and non-retryable) and that the number of rows per sample in the tieout dataset matches those in a reference dataset.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7841:312,simpl,simply,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7841,1,['simpl'],['simply']
Usability,"The marginalization over all paths, not the the likeliest one, would make a small difference, but I'm not sure in which direction. In fact, I would even guess it would tend to favor the reference over a deletion because there are more contributions from things like TTTTT -> TT(DELETE A T)TT(INSERT A T)T that don't actually change the bases but do contribute to the sum. That is, if the reference has a longer poly-T, there are more places to put the cancelling deletion(s) and insertion(s). However, all this stuff incurs gap opening penalties and I would be surprised if it could make a difference as big as 0.07. I think I know what can, however. If you take a look at the top of page 3 of our pair-HMM docs https://github.com/broadinstitute/gatk/blob/master/docs/pair_hmm.pdf, you will see, as @yfarjoun guessed, that there is a preference for shorter haplotypes in the form of a 1/haplotype length factor. And in fact, this amount seems to be in the right ballpark. For example, @ldgauthier's case is a 28-base deletion. If you calculate the log_10 ratio of the 1/length factors assuming a 100-base deletion haplotype, you get log_10(128/100) = 0.107. This, by the way, would explain why we don't see this sort of thing with insertions. We could simply say that any uninformative read (a log likelihood difference of 0.2) should go to the reference if that is the second best. That's basically the prior I was talking about. The M2-only solution would be to use the somatic likelihoods model on the haplotypes and remove unsupported haplotypes from the likelihoods matrix. Similarly, I could use it to align reads to the haplotype with the greatest posterior probability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393547216:1252,simpl,simply,1252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393547216,2,['simpl'],['simply']
Usability,The methods in `TargetsToolsTestUtils` (renamed in #3475 to `SimpleIntervalTestFactory`) are better suited to be static methods in `IntervalUtils` taking a dictionary as a parameter.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3771:61,Simpl,SimpleIntervalTestFactory,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3771,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,"The only place I’ve used them is in the malaria genotyping method, where we calculate very simple annotations for each set of breakpoints—mostly summary statistics of the posterior means, like the minimum in a segment or the segment-level mean. We also calculate a single changepoint statistic using the posterior means. Didn’t see any indicators that posterior sampling noise was causing any issues—the only real issue I had was fixed in #7261. I think the initial reason we started emitting these is because Talkowski folks wanted to use them for plotting/visualization, in which case I would be even less worried about sampling noise. But maybe you all are using them for something else now? Even then, not sure if anyone is using the posterior variances. If we ever move towards emitting this for somatic/mosaicism at the single-bin, percent level, then I might be a bit more worried—in which case, good for us for exposing it! But if you’d like to increase the default and it doesn’t seem to add significant runtime, go for it! Might also be good to get some understanding of the sampling noise level for typical data, if only for a few different parameter values.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601:91,simpl,simple,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601,2,['simpl'],['simple']
Usability,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:10,clear,clears,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629,2,['clear'],['clears']
Usability,"The prefetching code right now grabs one ""block"" at a time around the site of interest. It would be beneficial to make the prefetching smarter so that it performs better when there are large files involved. A couple of options:. * Slightly smarter (still simple):; * keep 1 block before, current block, and one block ahead at all times. * Much smarter:; * determine where the next position ( or next 10 positions ) will be based on driving reads/variants and asynchronously fetch in a small space around it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5515:255,simpl,simple,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5515,1,['simpl'],['simple']
Usability,"The previos message was written a bit quick from my phone. The concrete PR is https://github.com/samtools/htsjdk-next-beta/pull/12. @lbergelson - would like to have a look to it, or do you prefer that I open another one with the interface on top of the CIGAR part? I prefer to go step by step, as it is clearer than adding too many classes to review at once...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904:303,clear,clearer,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904,2,['clear'],['clearer']
Usability,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:747,clear,clearly,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,2,['clear'],['clearly']
Usability,"The pull request addresses two issues:. 1. Improved and more robust parsing of FlowBasedReads. Specifically, the code now determines the minimal reportable quality; 2. New tool AddFlowSNVQuality that allows users to convert the flow-based quality format when every base quality reports probability of an insertion or deletion to a conventional format that gives base qualities (total probability of mismatch and probability of each mismatch in separate tags). . We believe that this tool is going to be important for users of the Ultima Genomics data that care about calling SNVs, especially in somatic setting, so the goal was to make documentation more accessible. . Happy to receive feedback about it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8697:686,feedback,feedback,686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8697,1,['feedback'],['feedback']
Usability,"The situation in `ReadsSparkSource` with unmapped reads is very confused. It's not clear which (if any) methods return unmapped reads. It appears that queries by interval will return some unmapped reads (those that have the position of their mapped mates), but not others (those that are unmapped and not mated to a mapped read). We need to clarify this situation by providing a clear API for retrieving unmapped reads, documenting under precisely what circumstances unmapped reads may be returned even when they're not explicitly requested (eg., unmapped reads that are assigned the position of their mates).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1408:83,clear,clear,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1408,2,['clear'],['clear']
Usability,The somatic likelihoods model becomes very expensive when evaluated at every reference position. MT calling takes about 40 minutes in GVCF mode and 5 minutes without ref conf. Ideas for optimization include:; - Reducing the convergence threshold for `alleleFractionsPosterior` method (my initial attempts here didn't make a big improvement); - Using a simplified likelihoods model for reference sites (similar to `lnLikelihoodRatio` used for active region determination); - Keeping LOD calculation from active region determination and only calculating it once,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5561:352,simpl,simplified,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5561,1,['simpl'],['simplified']
Usability,"The spark tools all end in `*Spark` and are in clearly marked groups that begin with `Spark*`, which seems pretty clear to me :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1291#issuecomment-163309365:47,clear,clearly,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1291#issuecomment-163309365,2,['clear'],"['clear', 'clearly']"
Usability,"The task here is to simply move the code while changing as little as possible, and then validate that. Once that's done, we can do whatever refactoring/changes we want to VQSR, or replace it completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525:20,simpl,simply,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525,2,['simpl'],['simply']
Usability,"The test failures in the branch build are clearly related to the recent travis key migration. The PR build (which is the one we care about) passes, so this should be safe to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953279491:42,clear,clearly,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953279491,2,['clear'],['clearly']
Usability,"The tests would be very short-running, so each run should be cheap. Most of the runtime will be just spinning up the cluster. If someone malicious opened up a crazy number of PRs, he would at least quickly hit our travis quota limit which would slow him down considerably. We can look into whether other mechanisms exist on travis to deal with this sort of hypothetical situation. We do ideally want these tests to work with forked PRs, but if that's simply not going to be possible on travis then we'll obviously have to choose between having these tests in the same place as all of our other PR-related tests on travis and just skipping them for forked PRs, vs. having them in jenkins and requiring those making and reviewing PRs to deal with/check both CI environments. Let's meet early next week to chat about this issue and come to a decision.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287544886:451,simpl,simply,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287544886,2,['simpl'],['simply']
Usability,"The tool is currently hard-coded to work with funcotations from v3 of the AoU data source, but opening for early feedback / discussion of the best way to generalize things.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4991:113,feedback,feedback,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4991,1,['feedback'],['feedback']
Usability,"The updates based on code review are done, but I need feedback on couple of questions above before I can finalize this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000:54,feedback,feedback,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000,2,['feedback'],['feedback']
Usability,"The use of Targets to refer to genomic intervals is unnecessary and confusing. It obfuscates the fact that most of the tools and code can be applied to not only counts from WES targets, but also counts from WES baits, WGS bins, etc. Requiring that Targets be named also adds unnecessary storage and memory burden. We should just use SimpleIntervals everywhere. We should also get rid of the target file format. In terms of external visibility, we can just rename tools and edit javadoc. Internally, there will be many classes that need to be both renamed and refactored. I instead suggest that we rebuild new versions of the classes and tools as necessary in the tools/copynumber package. - [ ] Rename tools: AnnotateTargets -> AnnotateIntervals, TargetCoverageSexGenotyper -> ReadCountSexGenotyper. ; - [ ] Deprecate tools: CalculateTargetCoverage, ConvertBedToTargetFile, and PadTargets will be replaced by @asmirnov239's new CollectReadCounts tool and on-the-fly padding specified by --interval_padding parameters.; - [ ] Deprecate target file format and change all other affected file formats.; - [ ] Refactor/rename/rebuild classes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3246:333,Simpl,SimpleIntervals,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3246,1,['Simpl'],['SimpleIntervals']
Usability,"Their SNP priors are based on a point estimate of 1/1000 of being variant 0/1 or 1/1 and the 10^-3 is split between 0/1 1/1 with a 2:1 ratio. This is perhaps based on an empirical observation that the ""average"" human variant sites have a 2:1 het to hom-var ratio or simply to implement a flat prior between these two genotypes as there are two way to be a het and only one to be a hom-var. This is in high contrast with our vanilla priors which are based a AF prior and HardyWeinberg so HET would be roughtly 1/1000 and hom-var 1/1000000 !!! if the ratio of het to hom-var in the ""average"" human is close to 2:1 rather than 1000:1 then they are more right that we are. . The indel priors are based on their per-sample recalibration. . Priors are priors however simplistic or synthetic they are. And the posteriors are posterior the same. But yes, a more informative and correct prior should yield better posteriors. Answering to @ldgauthier old question (that I didn't really answer back then :P), I'm not aware if there is the possibility of provide a pop prior in DRAGEN, but is possible and a reasonable request. Now, the DRAGEN priors can be reconstructed from the reference sequence at the site, a couple of single value arguments and the DRAGstr model parameters that seats in a separate file (perhaps could be enclosed in the VCF header to make the vcf selfcontained). . The GP or (PP) is derived from PL and those priors so you don't really need those in the output. Another matter is the value that we use for the QUAL and the GT calls. Something that we have been doing wrong in vanilla GATK is to use the PL to fill GT (and perhaps GQ but I think that the VCF spec may be asking to do it that way not sure). Because it makes more (and perhaps only) sense to use posterior genotype probs to do so. By using the max PL we effectively setting a highly unrealistic flat uniform prior across genotypes. This only has a GT-noticeable effect on low coverage data though. For QUAL, vanilla GATK doe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-790002197:266,simpl,simply,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-790002197,4,['simpl'],"['simplistic', 'simply']"
Usability,Then definitely have this tool fail with a clear explanation if there's no AF.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3955#issuecomment-351525468:43,clear,clear,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3955#issuecomment-351525468,2,['clear'],['clear']
Usability,Then they should be functions from `read -> ()` to make it clear that they operate via side effects I think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82514530:59,clear,clear,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82514530,1,['clear'],['clear']
Usability,"There are a few heuristics in allele-fraction/joint segmentation, namely: 1) only the first het in each copy-ratio bin is used, and 2) copy-ratio bins with no hets are assigned AAF = 0.5. We could instead perform a simple estimation of MAF in each bin using all of the hets, or something along those lines. Alternatively, although kernel segmentation doesn't require it, we could also investigate whether simply folding the AAF suffices. Probably OK to ignore reference bias in both of these methods. Hopefully any AF concordance added in #4122 will be able to discern the level of improvement.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5626:215,simpl,simple,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5626,2,['simpl'],"['simple', 'simply']"
Usability,"There are pretty significant incompatibilities between java 8 and 11 that make it hard to run the same code on both. It affects a number of our dependencies which use features which were removed/altered from java 8 -> 11. Unfortunately despite there being significant pain in switching to 11 there aren't particularly compelling new features after 8 so there isn't much incentive for developers to move forward. That said, you CAN now run gatk on java 11 if you build it using java 11, the jars built on 8 are incompatible with 11 and vice a versa. We consider running on 11 to be a beta feature and would love to hear feedback about either success or failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535:619,feedback,feedback,619,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535,2,['feedback'],['feedback']
Usability,"There are some insignificant differences between the QUAL score in GATK3 and GATK4 that we haven't been able to explain. This also means that QD is also different at those sites. Here are some examples (note that this data is private and cannot be used in public tests):. Input Combined gvcf: `/humgen/gsa-hpprojects/dev/mshand/palantir/Analysis/535_GenotypeGVCFs/inputVCF/shard-314.vcf.gz`. Chr | Site | QUAL in GATK3 | QUAL in GATK4 | QD in GATK3 | QD in GATK4; ---|---|---|---|---|---; chr5 | 43191532 | 3233.06 | 3234.67 | 11.93 | 11.94; chr5 | 43298363 | 3233.06 | 3232.12 | 14.9 | 14.89. While these sites are clearly not significantly different, it would still be nice to know why these differences are occurring.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2756:616,clear,clearly,616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2756,1,['clear'],['clearly']
Usability,"There are two commits. The first one factores out code that can be shared between the R and Python executors, along with a few opportunistic changes in existing tests that have bad names. The second has a simple PythonScriptExecutor in the spirit of the RScriptExecutor, along with unit tests, and an example tool and integration test. First pass for https://github.com/broadinstitute/gatk/issues/3501.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3536:205,simpl,simple,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3536,1,['simpl'],['simple']
Usability,There has been a request to do some more work on the HMM again and its become clear that there is not an efficient way to rapidly generate large amounts of test data based on the old HMM results. It would be helpful to add an option to dump the hmm scores out to the command line in an easily machine parseable format. Here is an example of how it has been done in the past (and probably how we should do it this time): https://github.com/Intel-HLS/GKL/blob/master/src/test/resources/pairhmm-testdata.txt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7647:78,clear,clear,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7647,1,['clear'],['clear']
Usability,"There have been a few instances like this though. This one was obviously accidental, but things like the correct spelling of @magicDGS actual name seem like reasonable things to be able to include in the source. Also, testing non-ascii characters seems like something that is going to be increasingly common as we support new versions of the spec so it seems like we should learn to avoid this problem...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492761095:374,learn,learn,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492761095,2,['learn'],['learn']
Usability,"There have been requests for some additional clarity on ""how; much test coverage is enough"" for hellbender tools. Rather than; mandate a particular coverage target, I proposed a more flexible; set of guidelines which I've added to the README in this commit.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382:200,guid,guidelines,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382,1,['guid'],['guidelines']
Usability,"There is an existing method in GATKTool called getHeaderForSAMWriter that creates and populates the PG record, and it's called by GATKTool.createSAMWriter, so we already do this for BAMs that are created that way (which excludes the Picard tools). We should probably fix MarkDuplicates though. HaplotypeCaller and Mutect2 use HaplotypBAMWriter/SAMFileDestination/HaplotypeBAMDestination, all of which live in gatk, but create their own writers directly, so they need to be updated (and could probably be simplified a bit). We need a similar method for vcf header lines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291:504,simpl,simplified,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291,2,['simpl'],['simplified']
Usability,"There is currently an issue with spark stderr output if running through the wrapper script, this should make it a little clearer what spark is doing after it finishes with the tools work.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4501:121,clear,clearer,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4501,1,['clear'],['clearer']
Usability,"There is likely common code between the two, but we would need to pre-process the inputs to determine whether they are GVCFs: the merging algorithm is different for the two cases even if all input variants at a site are non-reference-blocks: see `ReferenceConfidenceVariantContextMerger.merge()` vs `GATKVariantContextUtils.simpleMerge()`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/16#issuecomment-66795521:324,simpl,simpleMerge,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/16#issuecomment-66795521,1,['simpl'],['simpleMerge']
Usability,"There is. Gatk-launch should be handling --files for both yarn and dataproc. I think James found some bug with gatk-launch and multiple files passed in, can't remember exactly what it was but it should be a simple fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1689#issuecomment-234084913:207,simpl,simple,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1689#issuecomment-234084913,1,['simpl'],['simple']
Usability,"There should be a package for each top level transform. Right now, transforms are organized haphazardly roughly by simple vs composite.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/651:115,simpl,simple,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/651,1,['simpl'],['simple']
Usability,"There should be an option to inform the user when reads do not pass the WellFormedReadFilter. This could be by logging the number of reads failing this filter or exploding (user-specified). Ideally, it would also report which part of the filter they failed. There are a lot of simple ""gotchas"" that can cause reads to fail, like not adding read groups with sample names. To a lay user, this could be very frustrating. In Spark tools that perform their own additional filtering, it can be impossible to tell even when a substantial subset of the input is silently lost this way (very scary stuff!). A tool to detect reads that are not Wellformed (akin to ValidateSamFile) would be helpful, although not for catching bugs like #3453. @lbergelson suggested creating a WellFormedOrExplodeReadFilter, which would allow tool developers to handle this issue at their discretion. I will work on something like this because PathSeq is especially susceptible to the problem.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454:277,simpl,simple,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454,1,['simpl'],['simple']
Usability,"There were a couple of things I needed to do to get the new Spark code running on a cluster:. i. Go back to using Spark's version of Kryo. Using a different version of Kryo is not actually needed (2.21 used by Spark passes the tests), and actually caused errors on the cluster when run with `--conf spark.driver.userClassPathFirst=true` (which is needed to avoid other library conflicts, like with jopt-simple). ii. Exclude Spark from the JAR file to avoid library conflicts. It's normal to exclude Spark and Hadoop from JAR files since they are supplied by `spark-submit`. Since Gradle doesn't have a 'provided' dependency (see https://github.com/broadinstitute/hellbender/issues/836), I had to do a bit of a workaround with the `shadowJar` target, which is now `sparkJar`. . Here's the command I ran:. ``` bash; NAMENODE=...; SPARK_MASTER=yarn-client; HELLBENDER_HOME=...; spark-submit \; --master $SPARK_MASTER \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; build/libs/hellbender-all-*-spark.jar ReadsPipelineSpark \; --input hdfs://$NAMENODE/user/$USER/bam/NA12878.chr17_69k_70k.dictFix.bam \; --output hdfs://$NAMENODE/user/$USER/out/spark-reads-pipeline \; --reference hdfs://$NAMENODE/user/$USER/fasta/human_g1k_v37.chr17_1Mb.fasta \; --baseRecalibrationKnownVariants $HELLBENDER_HOME/src/test/resources/org/broadinstitute/hellbender/tools/BQSR/dbsnp_132.b37.excluding_sites_after_129.chr17_69k_70k.vcf \; --sparkMaster $SPARK_MASTER ; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/882:403,simpl,simple,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/882,1,['simpl'],['simple']
Usability,"There were a few issues with this case. First, the data source was not constructed 100% correctly. The config file is correct. . The index file is for the tar.gz version of the source data and not for the uncompressed version that they're using. The index should correspond to the source data in the file referenced by the config file itself (not a zipped or otherwise transformed version). Secondly, the source `tsv` data file has the header line for the table commented out. The Xsv codec is aware of leading hash marks as comments and will ignore any such lines. Because of this, the leading hash in the table header is ignored and the file cannot be properly parsed. The fix is simple - just remove the leading hash from the table header (the preceding line with the two hash marks is correctly interpreted as a file header because of the leading hashes acting as comments). Lastly, even if the user fixed the file they would still need to index it with`IndexFeatureFile`. At some point the code underlying this in `HTSJDK` was broken such that no Xsv files can currently be indexed. I have submitted a pull request in `HTSJDK` (https://github.com/samtools/htsjdk/pull/1429) for this and have another ready to go in GATK (#6224) that includes a test for this case so this reversion cannot happen again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183:682,simpl,simple,682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183,2,['simpl'],['simple']
Usability,There were a number of methods that got ported in VariantAnnotator to make the RankSumTest output match the gatk3 output when computed on variants based on the pileup. Most of this code is buggy and in many cases simply wrong. We should reevaluate this code and fix it to do the correct thing and write stronger tests for the changed behavior in VariantAnnotator. . Specifically the methods `getNumClippedBasesAtEnd`/`getNumClippedBasesAtStart` make incorrect assumptions about how clipping works.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4450:213,simpl,simply,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4450,1,['simpl'],['simply']
Usability,"There's a small set of tools that only outputs their results to stdout, making it difficult to use the output in a pipeline/script. This PR adds a way to output simple results from such tools to an (optional) output file. I Added this option to the following tools:; - CountBases; - CountBasesInReference; - CountReads; - CountVariants; - FlagStat. Other tools that might benefit from this (but it will require an API change, so I didn't do it):; - CompareIntervalLists; - ValidateVariants",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7072:161,simpl,simple,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7072,1,['simpl'],['simple']
Usability,"They are all intact chromosomes. The ones still going are each one chromosome and happen to be the largest 4. Also, it isn't entirely clear if they are failing per se, just that they've been hanging for a week without anything obvious happening.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-654415271:134,clear,clear,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-654415271,2,['clear'],['clear']
Usability,"Think it might be worth saving a VariantFiltration pass for the bit of code it'd take, but up to you!. ScoreVariantAnnotations will output both the raw ""VQSLOD"" score and the converted sensitivity, so we're free to specify thresholds on either. However, given that different types of models may have scores in different ranges (e.g., BGMM vs. IsolationForest, positive/negative vs. positive-only, etc.), I think it's better to restrict all command-line options to be expressed in terms of a sensitivity. Same thing goes if you decide to filter externally with VariantFiltration for now. Even though you have both quantities available to you, just use the sensitivity. This brings us to questions related to whether we want to keep the old VQSR requirements of having both training and truth sets specified. For example, we could instead drop the distinction between training and truth for the new tools, and always calibrate sensitivity to the training set (you can essentially force this behavior with the current code by specifying training=true,truth=true for all of your resources). And yes, all of the tools should have a variety of command lines in the tests to demonstrate behavior. If you want to explore positive/negative mode, take a look at the *Unlabeled tests. Also feel free to ping me if anything isn't clear!. I'll push another round of minor updates here, too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523:1318,clear,clear,1318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523,2,['clear'],['clear']
Usability,"This PR deals with long reads with exactly two alignments (no other equally good alignment configuration), mapped to the same chromosome with strand switch, but NOT significantly overlapping each other. We used to call inversions from such alignments, but it is more appropriate to emit BND records because a lot of times such signal is actually generated from inverted segmental duplications, or simply inverted mobile element insertions. To confidently interpret and distinguish between such events, we need other types of evidence, and is better to be dealt with downstream logic units. Inverted duplications are NOT dealt with in this PR and is going to be in the next. NEEDS TO WAIT UNTIL PART 1 & 2 ARE IN.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3457:397,simpl,simply,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457,1,['simpl'],['simply']
Usability,"This PR is a simple addition to add GATKReportTable.getDescription(), to allow other classes to get the value of description.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5443:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5443,1,['simpl'],['simple']
Usability,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6903:317,Learn,LearnReadOrientationModelIntegrationTest,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903,1,['Learn'],['LearnReadOrientationModelIntegrationTest']
Usability,"This PR reimplements the overlap detector used in WeighedSplitIntervals in a much faster form for our particular use case. It also involved preprocessing the weighted bed input file in a new way, so the previous weights files will no longer work. As such, there's a new weights file uploaded and referred to as part of this pr. I pulled down the documentation and rationale for the original process from the git issue to a markdown file that can live in our repo, and made python scripts out of the necessary bits of python logic there (as well as a new one to do the further preprocessing step that I added). The motivation for this was the inability of the previous WeightedSplitIntervals task to complete when run against an exome interval list. This new one does, and it does so quickly. The link referenced below is not a ""successful"" run in the Terra sense because it was 190k exomes and that was simply too much for Terra to handle, but it DOES show a successful WeightedSplitIntervals run before the real extract started and I believe that is sufficient to merge. Delaying while ticket VS-189 gets figured out will create an unnecessary delay. Successful integration run: https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/294fd6a8-15ed-4722-a63e-bdf089c1c52a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507:903,simpl,simply,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507,1,['simpl'],['simply']
Usability,"This PR:. * fixes a problem observed for a complex event with tandem duplicated sequence and insertion and deletion, which causes the discovery phase of SV pipeline to throw exceptions;; * the fix works by changing how tandem duplications are annotated:; * duplicated sequence is no longer provided, instead the corresponding duplication unit reference span is provided in `DUP_REPET_UNIT_REF_SPAN`,; * the duplicated units on the assembled contigs' CIGAR when aligned to reference is provided in `DUP_ASM_CTG_CIGARS`;; * adds annotation `DUP_ANNOT_FROM_OPT` when tandem repeat annotations were generated by a simple approximation procedure, which should be viewed with care;; * logs the total number of variants and different types; * updated and added tests to reflect these changes. The PR was tested to be runnable based on output from scanning the CHM-mix bam with PR #2444, which discovered the exception.; The number of variants discovered are:. For CHM-mix; ```; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 204 INVs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 2775 DELs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 954 DUPs; 20:43:36.213 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 977 INSs; ```; And for NA12878_PCR-_30X; ```; 22:14:15.653 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - Discovered 4686 variants.; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 228 INV's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 2719 DEL's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 835 DUP's; 22:14:15.660 INFO DiscoverStructuralVariantsFromAlignedContigsSAMSpark - 904 INS's; ```; @cwhelan Could you please to review?; @tedsharpe feel free to poke around and test run it. __UPDATE__:; This is to be merged after PR #2444.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567:610,simpl,simple,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567,1,['simpl'],['simple']
Usability,"This adds the many gnomad subpopulations as columns into the VAT schema, and grabs most of them directly from the nirvana annotations. The max is done as a simple calculation in the python script and retains the order of subpops (for tie-breaking) that Lee specified",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7381:156,simpl,simple,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7381,1,['simpl'],['simple']
Usability,This allow us to simplify our R installation in Travis. . R tests now only test Rscript executor; Using standard ubuntu R in travis instead of the more up to date one; Removing installation of R packages as part of gradle and travis builds; Updating readme,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/518:17,simpl,simplify,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/518,1,['simpl'],['simplify']
Usability,This also means the `GeneListOutputRenderer` will need to accept a config file as a parameter. `SimpleTsvOutputRenderer` already does this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5962#issuecomment-494907060:96,Simpl,SimpleTsvOutputRenderer,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5962#issuecomment-494907060,1,['Simpl'],['SimpleTsvOutputRenderer']
Usability,"This brings to us approximately 60 variants (without any filter applied). @cwhelan Please take time to review, another PR (supposedly dealing with simple ""translocation""s) is going to line up after this. Then the major graph-based one, but expected to take sometime to codeup. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765:147,simpl,simple,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765,2,['simpl'],['simple']
Usability,"This can be described more simply as:. Ensure that intervals in GVCF traversals are END tag aware, so all reference blocks are included correctly. GATK3 considers start position only, so some reference blocks are missed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99306834:27,simpl,simply,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99306834,1,['simpl'],['simply']
Usability,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:440,user-friendly,user-friendly,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300,2,['user-friendly'],['user-friendly']
Usability,"This code wraps around BaseRecalibrator and presents a very basic interface (set up, add reads, teardown) that's going to be used at each Dataflow worker. Challenges here:; (1) I need to convert the intervals to Features because that's what the BaseRecalibrator class uses, and SimpleInterval is not a subclass of Feature. This may change in the future.; (2) BaseRecalibrator takes Features as inputs - the only simple Feature class I found I could reuse is ArtificialTestFeature. Please let me know if there is a better choice (solving (1) also solves this); (3) I didn't find code to test overlap between a SimpleInterval and a Feature. Rather than roll my own I chose to use the SimpleInterval overlap test and convert to Feature lazily instead of eagerly. This may cause an interval to be converted more than once. So please consider this the start of a discussion on ""here is something that works, but surely there's a better way?"" I'm not so much looking for every performance opportunity, but ideally I'd like to avoid using ArtificialTestFeature if a better candidate is available.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511:278,Simpl,SimpleInterval,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511,4,"['Simpl', 'simpl']","['SimpleInterval', 'simple']"
Usability,"This consists almost entirely of using `Utils.nonNull` and `Utils.validateArg` in code ported from GATK 3. There are less trivial but straightforward simplifications of code in `MathUtils` and `ReadLikelihoods`. @droazen and @lbergelson is one of you willing to review this mind-numbing PR, or suggest a victim? It should be quick.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979:150,simpl,simplifications,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979,1,['simpl'],['simplifications']
Usability,"This difference of 20 makes sense theoretically. The old qual always has a heterozygosity prior of 1 in 1000, whereas new qual starts there but is willing to learn a different allele frequency. Very hand-wavingly, a difference of 20 or so means that new qual has learned an allele frequency in the ballpark of 1 in 10 (since log_10 1/10 = log_10 1/1000 + 2 and 2 --> 20 in phred scale). So basically, they only squeak by the old threshold because new qual has learned the *artifact* allele frequency as a true allele frequency. :thumbsup: for `stand-call-conf 30`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-395427599:158,learn,learn,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-395427599,6,['learn'],"['learn', 'learned']"
Usability,"This feature request stems from discussion at the end of <https://github.com/broadinstitute/gsa-unstable/issues/1547> for CombineVariants. If the field as a whole (and its tools) does not have a deterministic logic in ordering ALT alleles in multiallelic VCF records of mixed types (@vdauwera says AFAIK there is no order), then I think it will be useful to have an option when combining sites of different types, e.g. INDEL and SNP, to be able to represent the ALT alleles according to a user-provided file. ALT alleles not present in the user-provided file would become a separate VCF record. I ask for this feature because (outside) tools like Beagle (identity-by-descent calculations) require identical representation of ALT alleles to its resource file. Records that do not match in CHROM, POS, REF and ALT are ignored by the tool. I have used an outside tool to merge records vertically so each site is represented once. It wasn't clear to me how the ALT alleles were ordered so I manually reviewed the 80-some multiallelic sites of mixed type after the merge. Not a scalable solution.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2464:937,clear,clear,937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2464,1,['clear'],['clear']
Usability,"This happens whenever the start position of an interval for which intermediate bands must be created is less than the value `of break-bands-at-multiples-of`. For example, an input reference block record with a `start` position (say 1) that is less than the value of `of break-bands-at-multiples-of` (say 10000) would result in the invalid intermediate band interval:; ```; java.lang.IllegalArgumentException: Invalid interval. Contig:chr21 start:-1 end:-1. 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.createIntermediateVariants(CombineGVCFs.java:191); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:134). ```; This doesn't happen in GATK3.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4672:572,Simpl,SimpleInterval,572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4672,4,['Simpl'],['SimpleInterval']
Usability,"This includes wrappers to present `SAMRecords` to the tools; Also adding 4 simple tools as examples; `FlagStatsDataflow`; It makes use of dataflow's built in hierarchical aggregation; `CountBasesDataflow`; Simple walker that makes use of the SAMRecord conversion; `CountReadsDataflow`; Does what it says; `PrintReadsDataflow`; This is a very limited version of our print reads walker; It prints `SAMRecords` as strings to an unordered text file; It could potentially be useful as method for examining bam output before we have a proper bam writer. These tools exist in two parts:; A transform extending from `PTransformSAM` (A subclass of `PTransform<Read,O>` which facilitates conversion to `SAMRecord`; A command line tool implementing a complete pipeline; These pipelines can apply arbitrary `ReadFilter`s/ `ReadTransformer`s which are applied before the main transform; (a list of transforms and a list of filters can be applied, it's currently not handled very efficiently though, better to pre-comine them into a single meta transform). Currently, only tests which use local files are running on travis.; There is code included to run on files in buckets, but the tests for it are currently disabled due to travis configuration issues (will be resolved in a seperate ticket). Some changes were made to existing classes to make them Serialize properly; Some test files were moved to help normalize test data locations (although not all tests are normalized, should be done in separate ticket); the new storage locations are based on the complete package name rather than just the tool name",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/443:75,simpl,simple,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/443,2,"['Simpl', 'simpl']","['Simple', 'simple']"
Usability,"This is a beta ticket -- for alpha we will just recommend conventions that promote composability when we write the guide in https://github.com/broadinstitute/gatk/issues/1016. For beta, we should probably create a Transform abstraction a la dataflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/960#issuecomment-158207631:115,guid,guide,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/960#issuecomment-158207631,1,['guid'],['guide']
Usability,"This is a relatively simple change, but has not been tested. The reviewer should make sure I haven't screwed it up!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5027:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5027,1,['simpl'],['simple']
Usability,"This is a very minimal change of the testing framework to allow users of the framework to use `IntegrationTestSpec` with their own classes. It solves the problem of a custom `Main` class to run the command line test in programs using the framework (through overriding default behavior), and the loading of `GenomeLocParser` by the `BaseTest` if the test is simply extending `CommandLineProgramTest`. More details for this issue in #2033. Now API users could implements and modify default behavior of `CommandLineProgramTestInterface` and use this test classes in `IntegrationTestSpec`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122:357,simpl,simply,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122,1,['simpl'],['simply']
Usability,This is a very simple PR. Maybe @droazen or @lbergelson could have a quick look? Thank you very much.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274518246:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274518246,2,['simpl'],['simple']
Usability,This is a very simple change to allow subclasses of `AbstractConcordanceWalker` to use NIO for their truth callset.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4905:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4905,1,['simpl'],['simple']
Usability,"This is a very simple patch, @cmnbroad. Could you have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677,2,['simpl'],['simple']
Usability,"This is a very simple path, @lbergelson. Could you have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260#issuecomment-268280390:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260#issuecomment-268280390,2,['simpl'],['simple']
Usability,"This is an experiment to see if it's possible to run BWA-MEM on Spark. (Please don't merge.) The basic idea is that it uses JNI to call BWA-MEM's align function to align a batch of read pairs in one go. I think it should complement the work that @SHuang-Broad has been doing in #1701. It would be great to get your (and @akiezun's) feedback on the direction here. A few comments; - Building the native libraries is not integrated, and it's not using the Apache 2 licensed code. I think this could use some of the changes in #1701.; - The ref is assumed to be on the local FS for the moment - it should really be loaded from HDFS. Also, the output is a single SAM file on the local FS, not a sharded BAM as for the rest of the GATK Spark tools.; - It is assumed that read pairs are interleaved and reads in a pair are placed in the same split (by setting `hadoopbam.bam.keep-paired-reads-together`). However, that property only works for queryname sorted BAMs, which isn't the case here, so we need to relax that requirement in Hadoop-BAM.; - I haven't tried this on large inputs, so I don't know how well it performs. To run, I used the following on a cluster. ```; ./gatk-launch BwaSpark \; --ref /home/tom/workspace/jbwa/test/ref.fa \; --input hdfs:///user/$USER/bwa/R.bam \; --output /tmp/bwa.sam \; -- \; --sparkRunner SPARK --sparkMaster yarn-client \; --driver-memory 3G \; --num-executors 1 \; --executor-cores 1 \; --executor-memory 3G \; --archives jbwa-native.tar#jbwa-native \; --conf 'spark.executor.extraLibraryPath=jbwa-native'; ```. The interesting bit is the use of Spark's `--archives` flag to copy a tarball of native libraries (which I built manually) to every executor, and unpacks it in the working directory. Then `spark.executor.extraLibraryPath` is set to add that path to the library path of the executor. This means that you don't have to rely on the native libraries being installed on every node in the cluster.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750:332,feedback,feedback,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750,1,['feedback'],['feedback']
Usability,This is currently in development at Intel -- should be usable within a quarter.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1812#issuecomment-287792231:55,usab,usable,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1812#issuecomment-287792231,1,['usab'],['usable']
Usability,"This is difficult to review because there isn't any client code: I don't know how this is going to be used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706:636,clear,clearer,636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706,4,"['clear', 'simpl']","['clearer', 'simple']"
Usability,This is great! We can solicit feedback on style at the Methods meeting as well. Feel free to spin off low-priority TODOs into issues that we can leave for after release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173:30,feedback,feedback,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173,2,['feedback'],['feedback']
Usability,"This is probably affecting some of the GWAS studies but in subtle ways that; haven't popped up yet. I'm cc'ing Andrea in the hopes that he has some time; to think about the issue. I'd need some uninterrupted time to work out the; details and that's hard to come by at the moment. On Feb 11, 2017 12:21 AM, ""chlangley"" <notifications@github.com> wrote:. > Thanks for getting this cleared up.; > OK, what next? I'll check with colleagues who may be aware this 'feature'.; > Perhaps the case can be made more clearly by a group of users, including; > visible labs working on human evolutionary genomics.; >; > I don't know the CA genomics community well, but my shallow poling; > suggests most are happily unaware that SNPs near indels will often be; > assigned lower quality than they might.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdNaqeg_h2KxcxGULyoiSO3D8EY9eks5rbUVogaJpZM4DrC8o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279249883:379,clear,cleared,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279249883,2,['clear'],"['cleared', 'clearly']"
Usability,This is simply intended to scope out what breaks with forked PR branches so they can be fixed.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7785:8,simpl,simply,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7785,1,['simpl'],['simply']
Usability,"This is the keypoint. ; ""Merging the gVCFs generated by HaplotypeCaller, DeepVariant, BCFtools mpileup&call and FreeBayes. "". CombineGVCFs tool's aim is not to combine GVCFs from different sources. The tool can only work with GVCFs from HaplotypeCaller. . For us to understand the issue clearly we need to get the actual command line for HaplotypeCaller for generating the GVCF file. GVCFs generated by other tools are not our concern therefore if you are doing something outside of GATK domain we cannot help. . There may be other tools doing this kind of work but we don't have extensive information on them and we cannot debug their issues either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755490839:287,clear,clearly,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755490839,2,['clear'],['clearly']
Usability,"This is to overhaul tests on SV assembly-based non-complex breakpoint and type inference code. ------. What is done:. * new AssemblyBasedSVDiscoveryTestDataProvider classes which hold manually computed expected values. Unit tests simply load the expected values and compare with actual values calculated on the fly; * fix bugs in BND formatted variants and tested (using the structure above). Classes affected in `main` ; * `AnnotatedVariantProducer`: methods are grouped together and renamed to reflect that the annotations added are assembly-specific or using short reads; * `BreakEndVariantType`: more detailed types (mostly about how alt allele, with the ref bases and square brackets); * `BreakpointComplications` and `BreakpointsInference`: mostly to add trivial methods used only in tests; `DiscoverVariantsFromContigAlignmentsSAMSpark`: now a thin CLI, where functionalities are refactored into new class `ContigChimericAlignmentIterativeInterpreter`; * `SimpleChimera`: new documented and tested method `firstContigRegionRefSpanAfterSecond ` and trivial test-related code",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4835:230,simpl,simply,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4835,2,"['Simpl', 'simpl']","['SimpleChimera', 'simply']"
Usability,"This issue has come up during my work on #6634 and has resulted in the decision to add the `--disable-spanning-event-genotyping` argument in GATK. . The results from the GATK-DRAGEN ROC curves on synthetic diploid CHM samples looks like this: ; ![otherCH1_CHM13_WGS1_PAIR_indel](https://user-images.githubusercontent.com/16102845/87469757-c3211b00-c5e9-11ea-830f-f3db5f7b8aed.png); ![otherCH1_CHM13_WGS1_PAIR_snp](https://user-images.githubusercontent.com/16102845/87469766-c5837500-c5e9-11ea-8914-7bf5660c3ead.png); Clearly these show that for SNPs at low complexity regions GATK performs better but for indels it is less specific. To explain the SNPs here is an example site: ; <img width=""1614"" alt=""Screen Shot 2020-07-14 at 3 08 10 PM"" src=""https://user-images.githubusercontent.com/16102845/87470068-39be1880-c5ea-11ea-80b5-2dba4a23c1dc.png"">; We can explain what is going on here by imagining the 3 relevant haplotypes, A) reference haplotype, B) the one with the deletion, C) the one with the snp underlying the deltion. ; - GATK and dragen genotype the deletion more or less the same and call it (assigning B to the variant and A/C to reference) ; - At the second position:; -- DRAGEN (and GATK with the `--disable-spanning-event-genotyping` argument enabled) follow the GATK3 approach of assigning haplotype C to the variant and the A and B haplotypes to the reference. The B haplotype is assigned as such because the deletion does not START at position 224905964 thus its reference according to the old way of assigning likelihoods. This means that all of the likelihoods from the true deletion at this site are weighted towards the reference which will end up drowning out the SNP call resulting in no SNP being called at this site.; -- GATK assigns C to the variant, A to to the reference, and B to a third option “spanning deletion” which prevents the deletion from outweighing the likelihoods assigned to the SNP resulting in better performance at many sites. This pattern even extends ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6707:517,Clear,Clearly,517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707,1,['Clear'],['Clearly']
Usability,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:858,clear,cleared,858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984,2,['clear'],['cleared']
Usability,"This makes probably at least 214-59=155 test fail. The first one is [assertMatchingAnnotationsFromGenomicsDB_newMQformat](https://github.com/broadinstitute/gatk/blob/423d106612074aa3480b67b321dc66426b1c600a/src/test/java/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFsIntegrationTest.java#L405):; ```; assertMatchingAnnotationsFromGenomicsDB_newMQformat[0](src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/expected.testGVCFMode.gatk4.g.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/newMQcalc.singleSample.genotyped.vcf, 20:1-11000000, src/test/resources/large/human_g1k_v37.20.21.fasta); java.lang.AssertionError: Genotype string expected [C*|T] but found [T|C*]; 	at org.testng.Assert.fail(Assert.java:97); ```. However looking at the input file and the expected output file it is clear that the expected output is wrong here (`:PL:PS `**`0|1`**`:23,38:61:99:1` in the last line) and this PR does the right thing instead:; ```; # input:; $ bcftools view org/broadinstitute/hellbender/tools/GenomicsDBImport/expected.testGVCFMode.gatk4.g.vcf | grep -e '1|0' -e ""10007150""; 20 10007150 . G C,<NON_REF> 669.77 . BaseQRankSum=-4.476;DP=63;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.5,0;MQRankSum=0;RAW_MQandDP=226800,63;ReadPosRankSum=-0.077 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:38,25,0:63:99:0|1:10007150_G_C:698,0,1479,813,1554,2366:10007150:16,22,14,11; 20 10007175 . C T,<NON_REF> 1350.77 . BaseQRankSum=2.249;DP=61;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.5,0;MQRankSum=1.319;RAW_MQandDP=216841,61;ReadPosRankSum=-1.213 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|0:23,38,0:61:99:1|0:10007150_G_C:1379,0,780,1448,894,2343:10007150:9,14,18,20; #""expected"" output (wrong):; $ bcftools view org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/newMQcalc.singleSample.genotyped.vcf | grep -e '1|0' -e ""10007150""; 20 10007150 . G C 690.64 . AC=1;AF=0.5;AN=2;BaseQRankSum=-4.476;DP=63;ExcessHet=0;FS=5.048;MLEAC=1;MLEAF=0.5;MQ=60;MQRankSum=0;QD=10.96;ReadPosRank",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1784915555:851,clear,clear,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1784915555,2,['clear'],['clear']
Usability,"This method simply writes a list of strings (one per line) to a text file. Does such a thing already exist in gatk? If not, we can move `ParamUtils.writeStringListToFile(...)` to `Utils.writeStringListToFile(...)` (or similar).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1387:12,simpl,simply,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1387,1,['simpl'],['simply']
Usability,"This request was created from a contribution made by Brian Wiley on March 18, 2022 22:33 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073119131-MuTect2-annotations#community\_comment\_4797484535835](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073119131-MuTect2-annotations#community_comment_4797484535835). \--. 394224746911, do you think it would be possible for Broad to start documenting things like this and most of the tags in your VCF files.  More like simple things not like the algorithm for clustered events.  For instance I have variant from which I can get the depth from the bam file with samtools with a variant called by Mutect at position chr17:60663118 C>T.  The depth of my bam file at this position is 170 (after removing duplicates; 222 before removing duplicates which is what shows in IGV). $ samtools depth C484.TCGA-19-2620-10A-01D-1495-08.5\_gdc\_realn.bam -r chr17:60663117-60663119 ; ; chr17    60663117    172 ; ; chr17    60663118    170 ; ; chr17    60663119    173. This coincides exactly with IGV (also shows 170 for position 60663118 when remove duplicates is turned on). $ samtools view C484.TCGA-19-2620-10A-01D-1495-08.5\_gdc\_realn.bam chr17:60663118-60663118 | wc -l ; ; 222. However Mutect has 2 depth DP tags, an INFO/DP and a FMT/DP.  The format DP shows a depth of 163 at this position which makes sense that it's at least lower.  But the INFO/DP shows a depth of DP=318 which makes almost zero sense (that's almost double!!) and in the VCF file it even indicates some reads are filtered... ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">. Additionally the AS\_SB\_TABLE shows ""164,135|3,2"" in which the total is 304 which again makes almost zero sense.  So from a researcher perspective it is absolutely necessary to know how Mutect2 is calculating these numbers else the strand bias filter cannot be trusted at all.  I am using version 4.2.1.0 of GATK an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7904:502,simpl,simple,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7904,1,['simpl'],['simple']
Usability,"This seems like a consequence of the fact that we use `java.nio.file.Path`for a lot of things in gatk. This requires a custom `java.nio.file.spi.FileSystemProvider` to be available for each type of path you want to be able to resolve. Spark native uses `org.apache.hadoop.fs.Path` for a lot of things. It's seems likely that that maprfs provides a hadoop file system plugin, which many spark applications can consume, but it's unlikely that it also provides a java.nio.file.Path implementation. ; ; I don't think we'd be able to implement a provider for maprfs ourselves. We don't have any systems with maprfs and don't have the bandwidth to take it on right now. Implementing a file system provider isn't a terribly complicated project, but it's not a trivial one either. However, there's an implementation for hadoop here https://github.com/damiencarol/jsr203-hadoop which is sufficient for what gatk does. If maprfs provides a hadoop file system, it would probably not be too difficult to take that project as a template and modify it to use the maprfs implementation. . I think the only things you'd have to implement for the spark tools to work are the basic Path operations that support the simple operations like `Paths.get()`,`Files.exists()`, and `Path.resolve()`. (although that's not a complete list. . If you are interested in writing a plugin like that, you can add it to the gatk class path at runtime. We might also be open to packaging such a plugin with the gatk if there was wide demand for it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555:1197,simpl,simple,1197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555,2,['simpl'],['simple']
Usability,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6835:19,simpl,simple,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835,1,['simpl'],['simple']
Usability,"This set of optimizations brings the GATK4 HaplotypeCaller performance into line; with GATK3.x performance. Note that HaplotypeCallerSpark is not touched by this PR (that is for a future PR). Summary of changes:. * AssemblyRegionWalker: query all intervals on each contig simultaneously, rather than individually; * GATKRead: Cache adaptor boundary, soft start/end, and cigar length; * GATKRead: add getBasesNoCopy() / getBaseQualitiesNoCopy(); * ReadPileup: speed up stratified constructor; * LIBS.lazyLoadNextAlignmentContext(): don't keep pileup elements unnecessarily separated by sample during pileup creation; * Restore faster GATK3 version of ReferenceConfidenceModel.sumMismatchingQualities(); * RefVsAnyResult: nest within ReferenceConfidenceModel, and allow direct field access; * Remove redundant getBases() call in ReadThreadingGraph; * Fix BaseGraph Utils.validateArg() call; * ReadPileup: replace Collections.unmodifiableList(pileupElements).iterator() with direct return of an iterator that forbids removal; * Kill expensive bounds checking in GATKRead getBase()/getBaseQuality()/getCigarElement(); * Kill nonNull checks in PileupElement; * Kill expensive PileupElement and ReadPileup arg validation; * GATKRead adapter: clear cached values upon mutation",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4031:1236,clear,clear,1236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4031,1,['clear'],['clear']
Usability,"This should be as simple as PrintReads + VariantFilters , see issue #7",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/12:18,simpl,simple,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/12,1,['simpl'],['simple']
Usability,This should be fixed in the next release as we are now on Picard 2.25.4 in master via #7255. If you need a docker build with an updated picard dependency I would suggest checking out our nightly builds gs://gatk-nightly-builds which should have an up-to-date version of master soon or simply waiting for the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791:285,simpl,simply,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791,2,['simpl'],['simply']
Usability,This simplifies the code and didn't affect specificity in our validations. @takutosato can you review this?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3243:5,simpl,simplifies,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3243,1,['simpl'],['simplifies']
Usability,"This sounds like a good rule, in general. In this case though, if users are going to run deep neural networks, there is going to be a substantial computational burden, such that running them is unlikely to appeal to users with older hardware (about 95% of users who _train_ these models use accelerators, for example - one reason Deep Learning didn't really take off till 2014). If you could see your way to making AVX (i.e. 8 year old hardware) the minimum requirement for your default docker image, you would be giving a 10X speedup to almost every user.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417366430:335,Learn,Learning,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417366430,1,['Learn'],['Learning']
Usability,"This task is to take the training data generated in issue #3092 and learn something from it, for example a regression model that predicts a distribution of artifactual read fractions. Using the learned model in filtering is a separate issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2973#issuecomment-307680993:68,learn,learn,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2973#issuecomment-307680993,4,['learn'],"['learn', 'learned']"
Usability,This ticket should be fairly simple once https://github.com/broadinstitute/gatk/issues/1988 is implemented.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1558#issuecomment-231765000:29,simpl,simple,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1558#issuecomment-231765000,1,['simpl'],['simple']
Usability,"This user is receiving an empty output file when running GenomicsDBImport. The user ran ValidateVariants on the input files which was successful. . This request was created from a contribution made by Enrico Cocchi on July 14, 2021 10:31 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB](https://gatk.broadinstitute.org/hc/en-us/community/posts/4403568031515-Mutect2-PoN-GenomicsDBImport-creates-empty-DB). \--. I am trying to follow GATK 4.2.0 best-practice guidelines for  \[Mutect2 PoN creation\](/hc/en-us/articles/360035531132--How-to-Call-somatic-mutations-using-GATK4-Mutect2). I called variants in my samples as recommended with:. gatk Mutect2 \\ ; ; \-R ${REF} \\ ; ; \-L ${EXOME\_INPUT\_INTERVALS} \\ ; ; \-I ${BAM} \\ ; ; \--sequence-dictionary ${DICT} \\ ; ; \--max-mnp-distance 0 \\ ; ; \-O ${SAMPLE\_NAME}.mutect2.vcf. but I see that the tool is unable to create a proper  `GenomicsDB`  through the  \[GenomicsDBImport\](/hc/en-us/articles/360057439331-GenomicsDBImport) command. Even focusing the analysis on a little interval in which I know I have variants in the Mutect2 generated VCFs, here the  `SelectVariants`  output from one of the VCF I'll use in the  `GenomicsDBImport`  command:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT XXX ; ; 1 883625 . A G . . AS\_SB\_TABLE=0,0|12,41;DP=54;ECNT=1;MBQ=0,33;MFRL=0,260;MMQ=60,60;MPOS=31;POPAF=7.30;TLOD=182.40 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:0,53:0.981:53:0,26:0,26:0,0,12,41. \`\`. and here the command to generate the DB:. gatk \ ; . \--java-options ""-Djava.io.tmpdir=/nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR"" \\ ; ; GenomicsDBImport \\ ; ; \-R $REF \\ ; ; \-L 1:883600-883650 \\ ; ; \--genomicsdb-workspace-path $OUT \\ ; ; \--tmp-dir /nfs/projects/CNV\_WGS/CHIP-PON-DB/TMP-DIR \\ ; ; \-V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0003D.Roche-M.mutect2.vcf -V /nfs/projects/CNV\_WGS/Mutetc2-PON-OUT/Roche-M/fetal0020D.Roche-M.mutect2.vcf -V ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7362:539,guid,guidelines,539,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7362,1,['guid'],['guidelines']
Usability,This will greatly simplify setup for gatk-protected.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1990:18,simpl,simplify,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1990,1,['simpl'],['simplify']
Usability,"To add some commentary to why this is happening: It looks like multiple threads are hitting this line simultaneously and based on the overload of `ArrayList.add()` this error could be triggered by multiple calls to `ensureCapacityInternal()` inside the add method:; ```; final List<ReadsPathDataSource> readSources = new ArrayList<>(threads);; final ThreadLocal<ReadsPathDataSource> threadReadSource = ThreadLocal.withInitial(; () -> {; final ReadsPathDataSource result = new ReadsPathDataSource(readArguments.getReadPaths(), factory);; readSources.add(result);; return result;; });; ```; The fix should be simple you just have to make sure ti synchronize the initialization or swap out the readSources object to one that is itself thread safe. @vruano",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721:607,simpl,simple,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721,2,['simpl'],['simple']
Usability,"To add, just in case it wasn't clear, note that this is almost certainly overkill for most somatic applications. However, if this is going to double as a more lightweight germline pipeline (as it is for the time being, as we are using some of the results to prototype SV integration), it might be worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562:31,clear,clear,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562,2,['clear'],['clear']
Usability,"To be clear, this will work perfectly fine as long as you have enough space in /dev/shm---which is typically true everywhere outside of our default Docker container. I'm loath to cripple a tool just because of limitations that are fundamentally elsewhere...let's just address those in the appropriate places. (Furthermore, I'm especially loath to write a plotting tool that takes ~5 minutes to generate a plot!) And yes, while it is not great that data.table forces us to use /dev/shm, I think `fread(""grep ..."")` is relatively standard. If `--shm-size` is indeed not exposed, why doesn't the Google backend scale /dev/shm or other tmpfs space with requested machine memory?. If there really is no other way around it, then all we're doing is filtering out the lines beginning with `@`. We could do this first by calling system commands within R to write to a temporary file, and then reading that back in with fread. This seems hacky to me, but I've confirmed that it works within the Docker. This will solve our immediate problem, but I still think it's worth taking a look at those other limitations elsewhere now as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827,2,['clear'],['clear']
Usability,"To be clear, when I learned to use VariantFiltration 1.5 years ago, I was told to use the `&&` and `||` expressions and _no other formatting_. This may have been alright in GATK3 (I did not check), but it seems in GATK4 it is not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-433233584:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-433233584,4,"['clear', 'learn']","['clear', 'learned']"
Usability,To be clear: I really appreciate the help from the GATK and GenomicsDB teams. There has just been a lot of problem and issues trying to make GenomicsDB work for this dataset,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211424808:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211424808,2,['clear'],['clear']
Usability,"To be fair, @vruano suggested the solution and I am simply writing code to try to make the allele-trimming work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1868#issuecomment-223043508:52,simpl,simply,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1868#issuecomment-223043508,1,['simpl'],['simply']
Usability,"To be honest, I don't have a clear idea of why this is happening. I tried running a query with 1000 samples using the same GenomicsDB jar that GATK uses and the memory consumption stayed below 1 GB. Some suggestions/questions:; * If you were importing/querying multiple intervals at once, I would expect #4994 to be relevant. But your script shows a single interval being imported/queried.; * Would it be possible to run the SelectVariants tool using the GenomicsDB workspace as input and see how much memory is being consumed (instead of GenotypeGVCFs)? The Select tool simply extracts the data from GenomicsDB and prints out a VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537:29,clear,clear,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"To be perfectly clear, do you mean high/low confidence or high/low complexity?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631:16,clear,clear,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631,2,['clear'],['clear']
Usability,"To clarify this ticket: in `GATKTool.initializeReads()`, just check `readArguments.getReadFiles()` for files ending with a cram extension (should see if there's a canonical method in htsjdk for checking whether a file is cram) -- if you find any and we don't have a reference according to `hasReference()`, throw a `UserException` with a clear error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449:338,clear,clear,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449,1,['clear'],['clear']
Usability,"To me, it seems VariantFiltration is incorrectly adding a filter when it clearly should not - unless I am missing something. I am adding a filter when `VAF in normal is > 2%` or `VAF in tumor is < 5%`. For this i am using the following expression:. ```; gatk VariantFiltration -R $ref_fasta -V tmp5 \; --filter-expression 'vc.getGenotype(""3105-T"").getAD().1 / vc.getGenotype(""3105-T"").getDP() < 0.05 ' --filter-name ""low_taf"" \; --filter-expression 'vc.getGenotype(""3105-N"").getAD().1 / vc.getGenotype(""3105-N"").getDP() > 0.02 ' --filter-name ""high_naf"" \; -O tmp6; ```; However, for this critical variant, the tool is incorrectly adding a filter, when TAF is 0.55. ```; tail -n2 tmp5; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT 3105-N 3105-T; 12 25398284 . C T . clustered_events CONTQ=93;DP=529;ECNT=5;GERMQ=93;MBQ=27,27;MFRL=0,0;MMQ=97,91;MPOS=80;NALOD=2.18;NLOD=31.43;POPAF=6.00;REF_BASES=GCCTACGCCACCAGCTCCAAC;SEQQ=93;STRANDQ=93;TLOD=309.98 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:105,0:7.035e-03:105:15,0:84,0:87,18,0,0 0/1:99,123:0.556:222:20,50:71,69:72,27,71,52; tail -n1 tmp6; 12 25398284 . C T . clustered_events;low_taf CONTQ=93;DP=529;ECNT=5;GERMQ=93;MBQ=27,27;MFRL=0,0;MMQ=97,91;MPOS=80;NALOD=2.18;NLOD=31.43;POPAF=6.00;REF_BASES=GCCTACGCCACCAGCTCCAAC;SEQQ=93;STRANDQ=93;TLOD=309.98 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:105,0:7.035e-03:105:15,0:84,0:87,18,0,0 0/1:99,123:0.556:222:20,50:71,69:72,27,71,52; ```. VAF calc:. ```; # GT:AD:AF:DP:F1R2:F2R1:SB; # 0/0:105,0:7.035e-03:105:15,0:84,0:87,18,0,0; # 0/1:99,123:0.556:222:20,50:71,69:72,27,71,52. TAF: 123/222=0.5540541; NAF: 0/105=0 [however 7.035e-03 is reported in AF field which is also fine...]; ```. I have another unrelated question regarding non-mutect files. If a tool has the AD values listed under a different name (in this case AO: allele observed, instead of allele depth), how can I construct a jexl expression to filter the same?. Imagine having the same data as above, with a slightly different naming convention:. ```; AD --> AO; # G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5916:73,clear,clearly,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5916,1,['clear'],['clearly']
Usability,"To reiterate, for me, GenotypeGVCFs 4.2.4.1 gives an ```IllegalStateException``` at the exact same place regardless of whether I run GenomicsDBImport 4.2.4.0 (with the 50 max allele bug) or GenomicsDBImport 4.2.4.1 (with the fix to respect 6 max alleles). As far as I can tell, the ```IllegalStateException``` has nothing to do with GenomicsDBImport, it's simply a new bug in GenotypeGVCFs 4.2.4.1 that happens to occur when the number of ALT alleles is 1 more than the limit set in GenotypeGVCFs. As @mlathara stated: ""the AF calculation [in GenotypeGVCFs] used to [in 4.2.4.0] ignore sites if they didn't have likelihoods, but has now been updated slightly [in 4.2.4.1] to also allow sites with GQ or sites where any alleles are called+nonref+not symbolic. The stack traces above show the AlleleFrequencyCalculator as the culprit:; ```; java.lang.IllegalStateException: Genotype [T199970 ATATATAT/T GQ 49 DP 4 AD 0,2,0,0,0,2,0,0 {SB=0,0,2,2}] does not contain likelihoods necessary to calculate posteriors.; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370:356,simpl,simply,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370,2,['simpl'],['simply']
Usability,"To summarize current state of discussions - we're going to have 3 repos, as originally planned (1 for the interfaces and 2 for Intel and IBM implementations, respectively). There will be a bit code duplication but many other aspects (some technical, some organizational) are massively simplified by such architecture. . @droazen @lbergelson @gspowley @paolonarvaez @frank-y-liu @t-ogasawara - please use this ticket to comment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820:285,simpl,simplified,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820,1,['simpl'],['simplified']
Usability,Tool arguments that are GCS-enabled should be clearly marked in the help output,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3773:46,clear,clearly,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3773,2,['clear'],['clearly']
Usability,Tools that require python should be clearly identified,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5420:36,clear,clearly,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5420,2,['clear'],['clearly']
Usability,Two commits here:. - The first is to fix a no longer accurate message in `UserException.BadTmpDir`; - The second is a few improvements to IOUtils. ; 1. Rename and simplify `tmpDir` -> `createTempDir` and make it automatically scheduled for deletion; 2. Add documentation to the confusing `absolute` method so that I stop wondering what it's for,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4711:163,simpl,simplify,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4711,1,['simpl'],['simplify']
Usability,"Two questions:. `getMaxClusterableStartingPositionWithParams` in `CanonicalSVLinkage` uses the `window` to determine the max clusterable position. Will setting the value to 10MB make everything look clusterable to this method, potentially bogging down the algorithm for large callsets?. Is there a reason to keep the keep the old code around if this is the intended way to disable the proximity check (setting the window very large)? Seems like an opportunity to simplify if you don't want to support that special case anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2342036804:463,simpl,simplify,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2342036804,2,['simpl'],['simplify']
Usability,"UIET false --use_jdk_deflater false; [February 16, 2017 3:23:02 PM UTC] Executing as root@3addd2d7b373 on Linux 3.16.0-0.bpo.4-amd64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: Version:c17c8ed-SNAPSHOT; [February 16, 2017 3:23:04 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=185597952; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentati",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2013,undo,undosplits,2013,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,2,['undo'],"['undoprune', 'undosplits']"
Usability,"Unfortunately I don't think it's practical to try to enforce that ""only the arg parser can throw `CommandLineException`"" -- there's too much downstream code and too many tools that do so already, so it would be a bit painful to treat it as a bug. Instead I think what we should do is:. * Make sure that barclay uses a separate exception class for internal errors that are not the user's fault. This internal exception class should not be usable outside of barclay (perhaps we can make it package-private?).; * Catch `CommandLineException` in GATK and present it as a user error (output should say ""A USER ERROR HAS OCCURRED"").; * Move the `printDecoratedUserExceptionMessage()` call for caught `CommandLineExceptions` from `CommandLineProgram.parseArgs()` to `Main.mainEntry()`, to ensure that a message always gets printed for `CommandLineException`. As @cmnbroad said, this will have to wait until after the holiday break (most of us are going to be away until early January).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854:438,usab,usable,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854,2,['usab'],['usable']
Usability,UnmarkDuplicates: a tool to undo the work of MarkDuplicates,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1089:28,undo,undo,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1089,2,['undo'],['undo']
Usability,"Update on the gene list format discussion: We recently in added GFF3 support in HTSJDK and one possible path forwards for supporting more general gene list formate for DoC would be to leverage the existing implementation that was included in #6602 to allow a second source of gene objects. This could be trivially implemented if we wanted to follow the same approach as #6602 where we simply farm the decision about what feature type is important out to the user to specify. This would mean that if the user cares about genes they could specify a count for each gene object with its reported boundaries that would be output as a line. This is similar but not analogous to the current behavior for the existing gene lists where we take pains to exclude from the overlap counts bases that are intronic bases in the gene list. . Unfortunately, since the GFF3 format is hierarchical and supports a very large number of feature types it will be very difficult to extract the intron/exon boundaries without properly parsing the GFF3 format. The GFF3 format supports .obo files that lay out the feature hierarchy and through parsing of that format it would be possible to extract intron/exon boundaries but that is not currently supported by HTSJDK and would involve us merging https://github.com/kachulis/htsjdk/tree/ck_gff3_feature_evaluator first in order to support and then on top of that coming up with some rules for deciding what units exactly make up a gene that should be merged for coverage counting. . I see a few options going forwards:; - We could support GFF3 gene lists with hard coded genes/CDS features to be included. This is brittle given that there are a number of more specific names for CDS (coding sequence) exons in genes that might end up being excluded.; - We could support GFF3 format but ignore exon sequences which would mean that the behavior for counting the same genes will vary depending on which format the gene is provided.; - We could support GFF3 gene lists but allow th",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413:385,simpl,simply,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413,2,['simpl'],['simply']
Usability,"Update: we have a PoC impl. working with sharded writing and simple indexing implementation in https://github.com/googlegenomics/dataflow-java/tree/sharded-bam-writer , need to do some more benchmarking and merge to main branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/621#issuecomment-132294611:61,simpl,simple,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/621#issuecomment-132294611,1,['simpl'],['simple']
Usability,Updated docs with usage examples and kebabed long args for:; - HaplotypeCaller; - HaplotypeCallerSpark; - CombineGVCFs; - GenomicsDBImport; - GenotypeGVCFs; - VariantFiltration; - ASEReadCounter; - SplitNCigarReads; - CalculateGenotypePosteriors; - VariantRecalibrator; - ApplyVQSR. Elaborated on/fixed docs for:; - InbreedingCoeff; - ExcessHet; - SampleList. Hid GatherTranches. Added a ReadTransformer to SplitNCigarReads to simplify the command from the old RNA best practices (https://software.broadinstitute.org/gatk/documentation/article.php?id=3891) NOTE: this slightly changes the default behavior @vdauwera . Unfortunately I squashed the SplitNCigarReads changes into the doc fixes. :( If that's a problem I can split into two commits.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3891:427,simpl,simplify,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891,1,['simpl'],['simplify']
Usability,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:720,simpl,simple,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,2,['simpl'],['simple']
Usability,Updating SimpleGermlineTagger and somatic CNV experimental post-processing workflow,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5252:9,Simpl,SimpleGermlineTagger,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5252,1,['Simpl'],['SimpleGermlineTagger']
Usability,"Upon speaking with @davidbenjamin, it has become clear that perhaps changing `--max-genotype-count` is not the best solution, as that value is intended to bound our PL arrays from being excessively expanded. It is clear that instead if the user is looking to extract Allele Counts from their Pooled sample it would be best for the user to instead run Mutect, as that should sidestep the maximum of 2 Alleles per site problem that we observed. @bhanugandham",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5994#issuecomment-511935395:49,clear,clear,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5994#issuecomment-511935395,4,['clear'],['clear']
Usability,"User Report:; ------------; Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360055990891-CollectGcBiasMetrics-Array-Index-Out-Of-Bounds-Exception](https://gatk.broadinstitute.org/hc/en-us/community/posts/360055990891-CollectGcBiasMetrics-Array-Index-Out-Of-Bounds-Exception); ------------. Hello,. When running CollectGcBiasMetrics on a moderately sized sam file (~500Mb), picard gives ArrayIndexOutOfBoundsException and ""Exception counting mismatches for read ..."". The SCAN\_WINDOW\_SIZE=1000. When it's set to default value 100, the error message is slightly different but ArrayIndexOutOfBoundsException persists. I have also experimented with different window sizes, all values >1000 give same error at the same read on chrX (details below). The reference fasta file is taken from UCSC: [https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz](https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz). Any feedback leading to resolving the issue is greatly appreciated. a) Picard version:. 2.21.6-SNAPSHOT. b) Command script:. java -jar picard.jar CollectGcBiasMetrics \\ ; ; I=sorted.sam \\ ; ; O=gc\_bias\_metrics.txt \\ ; ; CHART=gc\_bias\_metrics.pdf \\ ; ; S=summary\_metrics.txt \\ ; ; R=hg19.fa \\ ; ; SCAN\_WINDOW\_SIZE=1000. c) Error log:. MINIMUM\_GENOME\_FRACTION=1.0E-5 IS\_BISULFITE\_SEQUENCED=false METRIC\_ACCUMULATION\_LEVEL=\[ALL\_READS\] ALSO\_IGNORE\_DUPLICATES=false ASSUME\_SORTED=true STOP\_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION\_STRINGENCY=STRICT COMPRESSION\_LEVEL=5 MAX\_RECORDS\_IN\_RAM=500000 CREATE\_INDEX=false CREATE\_MD5\_FILE=false GA4GH\_CLIENT\_SECRETS=client\_secrets.json USE\_JDK\_DEFLATER=false USE\_JDK\_INFLATER=false ; ; \[Tue Jan 07 16:48:19 PST 2020\] Executing as [akoch@hpc5-0-3.local](mailto:akoch@hpc5-0-3.local) on Linux 2.6.32-431.11.2.el6.x86\_64 amd64; OpenJDK 64-Bit Server VM 1.8.0\_181-b13; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.21.6-SNAPSHOT ; ; INFO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6372:949,feedback,feedback,949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6372,1,['feedback'],['feedback']
Usability,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:42,pause,pause,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756,2,['pause'],['pause']
Usability,"User would like to know if we have guidelines to provide. It would be nice to have a timeframe to tell our users or some generic guidelines in setting parameters. . ---; I find really interesting the Flagstat [chart](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_chart.png ""chart"") and the relative [table](https://software.broadinstitute.org/gatk/resources/img_tutorials/tutorial_10060_figures/wes_increase_executors_table.png ""table""), it lets me understand that 7 is the most efficient executors-number for this tool. It's the same even for other tools? Or is there something similar (charts) for Pipelines like [BwaAndMarkDuplicatesPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.2/org_broadinstitute_hellbender_tools_spark_pipelines_BwaAndMarkDuplicatesPipelineSpark.php ""BwaAndMarkDuplicatesPipelineSpark""), [BQSRPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.3/org_broadinstitute_hellbender_tools_spark_pipelines_BQSRPipelineSpark.php ""BQSRPipelineSpark""), HaplotypeCallerSpark and [ReadsPipelineSpark](https://software.broadinstitute.org/gatk/gatkdocs/4.beta.5/org_broadinstitute_hellbender_tools_spark_pipelines_ReadsPipelineSpark.php ""ReadsPipelineSpark"") ?; And then, the ```--driver-memory``` is an important parameter? Which should be his value?. I'm waiting for a your kind answer,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/43894#Comment_43894",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3822:35,guid,guidelines,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3822,2,['guid'],['guidelines']
Usability,"Users (@yfarjoun @jnoms) have been reporting high run times in PathSeq when the samples have a large proportion (on the order of 10%+) of microbial reads. PathSeq was designed to run on samples with low numbers (<1%) microbial reads, but there are two ways users can currently improve performance when that's not the case:. 1) Run the 3 PathSeq tools individually (Filter, Align, and Score) instead of using `PathSeqPipelineSpark`, which simply runs those in series. This will eliminate over-allocation of resources during Filter and Score. This also will reduce the likelihood that Spark will recompute parts of the graph when it is low on memory/disk. ; 2) Enable `--skip-pre-bwa-repartition`, see https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_spark_pathseq_PathSeqPipelineSpark.php#--skip-pre-bwa-repartition; 3) Omit metric file outputs. This may also help Spark to avoid recomputing tasks from earlier parts of the graph. Planned features to help improve this:; 1) Automatically enable `--skip-pre-bwa-repartition` when a large amount of non-host reads is detected.; 2) Option to downsample the input BAM on the fly. This is also useful for estimating the proportion of non-host contamination.; 3) Option to limit the number of non-host reads that are processed. This is essentially equivalent to (2), but the downsampling would be performed after host filtering and could be used when the fraction of non-host reads is unknown a priori.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5780:438,simpl,simply,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5780,1,['simpl'],['simply']
Usability,"Using GENOTYPE_GIVEN_ALLELES (""GGA"") mode with HaplotypeCaller, I've encountered a couple instances of crashes that I've traced to spanning deletions (of the type considered in #4963).; One case involved the following in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:959,simpl,simpleMerge,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['simpl'],['simpleMerge']
Usability,"Using the latest version of ADAM (which has a Scala 2.12 version) fixes the 2bit failures. I also added a fix for the `java.nio.ByteBuffer.clear()` problem. All unit tests are passing, and the only integration test failures are the `Could not serialize lambda` problems. It should be possible to fix these by making the relevant classes implement `Serializable` (like in https://github.com/samtools/htsjdk/pull/1408).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090:139,clear,clear,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090,2,['clear'],['clear']
Usability,"Using this: https://guides.github.com/activities/citable-code/; To track GATK in scientific publications as we do not currently publish our work in scientific journals otherwise. Being able to track our use will come in handy some day, I promise.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3085:20,guid,guides,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3085,1,['guid'],['guides']
Usability,"VCF sequence dictionary detected as B37 in HG19 annotation mode. Performing conversion.; 17:14:13.209 WARN FuncotatorEngine - WARNING: You are using B37 as a reference. Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references.; 17:14:13.411 INFO ProgressMeter - Starting traversal; 17:14:13.412 INFO ProgressMeter - Current Locus Elapsed Minutes Features Processed Features/Minute; 17:14:15.391 INFO FuncotateSegments - Shutting down engine; [September 11, 2022 5:14:15 PM GMT] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.30 minutes.; Runtime.totalMemory()=1752170496; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:917445 end:911649; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2939); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:1238,Simpl,SimpleInterval,1238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['Simpl'],['SimpleInterval']
Usability,VQSR tranche functionality. I had to add the VRAC and VariantDatum (also present on another branch) to make things compile. These are simple classes. @droazen please review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/338:134,simpl,simple,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/338,1,['simpl'],['simple']
Usability,"Versions of Kryo less than 3.0 can't serialize Java 8 lambda functions, forcing us in some cases to replace lambdas with full function class objects even when a lambda would be simpler and easier to read. See for example https://github.com/broadinstitute/gatk/pull/1489 . This ticket is to look through the codebase after an upgrade to Kryo 3.0+ takes place and to replace unnecessary function classes with lambdas where they'd be more appropriate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1510:177,simpl,simpler,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1510,1,['simpl'],['simpler']
Usability,"Very funny! Closing, since this is clearly meant as a joke. Let's discuss after alpha ways to actually slim down our dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278:35,clear,clearly,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278,1,['clear'],['clearly']
Usability,Very simple implementation of #2297 using a custom `GATKConf` class to allow both promatically (`GATKConfBuilder`) and by commons-configuration API (constructor). Only includes:. * Packages/Classes to include in the CLP on startup.; * Packages to look for codecs on startup.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2322:5,simpl,simple,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2322,1,['simpl'],['simple']
Usability,Very simple patch to extract arguments that may be useful for other toolkits into `StandardArgumentDefinitions` and some in-class changes.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2283:5,simpl,simple,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2283,1,['simpl'],['simple']
Usability,"VsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=footer). Last update [e1e71d7...71c03a3](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894:4846,learn,learn,4846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894,2,['learn'],['learn']
Usability,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4615,learn,learn,4615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399,2,['learn'],['learn']
Usability,"WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2075,Learn,LearnReadOrientationModel,2075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3721,Learn,LearnReadOrientationModel,3721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6728,Learn,LearnReadOrientationModel,6728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4415,learn,learn,4415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327,2,['learn'],['learn']
Usability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <ø> (-62.264%)` | `8% <ø> (+8%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <ø> (-60.87%)` | `2% <ø> (+2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `44.444% <ø> (-29.861%)` | `28% <ø> (+28%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <ø> (-23.729%)` | `0% <ø> (ø)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/2385/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=footer). Last update [14f73e2...b1802b2](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892:4899,learn,learn,4899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892,2,['learn'],['learn']
Usability,"Was this issue ever resolved, or was the problem clearly identified? I am currently experiencing this error, but any help would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-752792318:49,clear,clearly,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-752792318,2,['clear'],['clearly']
Usability,"We are currently plagued with cryptic intermittent failures coming from the BWA and FML bindings in Travis CI. These usually manifest as a simple ""exited with code 137"" (ie., killed by signal 9) error, but sometimes we get an explicit segfault or out-of-memory error. Examples:. ```; �[31mFAILURE: �[39m�[31mBuild failed with an exception.�[39m; * What went wrong:; Execution failed for task ':test'.; �[33m> �[39mProcess 'Gradle Test Executor 1' finished with non-zero exit value 137; ```. ```; :test[M::bwa_idx_load_from_disk] read 0 ALT contigs; OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000715180000, 719847424, 0) failed; error='Cannot allocate memory' (errno=12). #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 719847424 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid11513.log; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f27ebfe7d9a, pid=11455, tid=0x00007f27e87e5700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libfml.6198146539708364717.jnilib+0xed9a] rld_itr_init+0x4a; ```. ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fd2680a350c, pid=11685, tid=0x00007fd2b02bf700; #; # JRE version: OpenJDK Runtime Environment (8.0_111-b14) (build 1.8.0_111-8u111-b14-3~14.04.1-b14); # Java VM: OpenJDK 64-Bit Server VM (25.111-b14 mixed mode linux-amd64 compressed oops); # Problematic frame:; # C [libbwa.5694772191018335324.jnilib+0x850c] bwa_mem2idx+0xcc; ```. The underlying issue in these cases is likely either ""out of memory"" or, perhaps in the case of the seg faults, ""file not found"" o",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3209:139,simpl,simple,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209,1,['simpl'],['simple']
Usability,"We are running GenomicsDBImport on a single chromosome with about 96 WGS gVCF samples as input. It's being run on a slurm cluster, lustre filesystem. Most of the scatter jobs finished, but the 4 largest have been sitting for nearly 5 days, and it's not clear whether they're doing anything, or what the problem is. Can you suggest any debugging steps to try to troubleshoot what's going on with the jobs? The command is essentially this:. java -Djava.io.tmpdir=<a local SSD on the node> \; -Xmx128g -Xms128g -Xss2m \; -jar GenomeAnalysisTK4.jar \; GenomicsDBImport \; -V <repeated for 96 different gVCFs> \; -L intervals.list \; --genomicsdb-workspace-path <a lustre directory>. Thanks for any debugging suggestions. -Ben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688:253,clear,clear,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688,1,['clear'],['clear']
Usability,"We can add this as an option, but I think there are a few arguments against outright replacement (which may have led to this design decision in the first place):. 1) I don't believe any CNV tools take in sample name as input at the GATK command line, by design. We instead take the BAM basename as the entity ID during the CollectCounts task; this ID is then passed along at the WDL level and is only used to construct the filenames of output files. This obviates the need for tools like GetSampleName and avoids issues with parsing funky sample names at the command line, handling/passing special characters at all levels (WDL, Java, python), etc. (The implicit assumption is that the BAM basename is more likely to be well formed.). 2) I would argue that specifying a sample index is relatively user friendly, especially if we are typically running on all samples. In that case, all you need to know is the total number of samples and that we use zero indexing, and then you simply iterate over all indices. (If you want to run on a single, particular sample, then perhaps using the sample name might be more friendly, but I'd argue that this use case is not typical.). 3) If you want to go ahead and add this option, I would probably keep the directory structure of the GermlineCNVCaller output the same (i.e., with folders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:977,simpl,simply,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,2,['simpl'],['simply']
Usability,"We can certainly modify IntervalListTools to make the behavior more intuitive (e.g. add a new mode for `INTERVAL_COUNT_WITH_OVREFLOW`), but I'm not sure I understand the issue. We're just trying to avoid calling the GATK command if the scatter is going to be a noop?. The GATK SplitIntervals has slightly different behavior that's helpful in some cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599618889:68,intuit,intuitive,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599618889,2,['intuit'],['intuitive']
Usability,"We can implement this, but first can you explain why your `canDecode()` methods can't unambiguously detect your file formats? The VCF/BCF codecs use a magic value at the start of the file to detect the format -- are your codecs guessing as to the intended format? Is there no way to be sure what the format is?. If we have multiple codecs able to decode a file, and only one produces `Features` that match the type parameter of the `FeatureInput`, would it solve your problem if we selected that codec rather than blow up? This would be a bit simpler/easier than a new annotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297503:543,simpl,simpler,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297503,1,['simpl'],['simpler']
Usability,We can simplify it by removing thread safety guarantees and then push it down into htsjdk,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/89:7,simpl,simplify,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/89,1,['simpl'],['simplify']
Usability,"We created a GenomicsDB workspace using GenomicsDBImport, followed by 2 rounds of adding new samples using GenomicsDBImport. We then ran GenotypeGVFs on it and received this NPE. Is there any information or debugging you can suggest that would help diagnose this?. The command run was approximately this (filepaths have been simplified):. java -Xmx48g -Xms48g -Xss2m GenomeAnalysisTK4.jar GenotypeGVCFs -R 128_Mmul_10.fasta --variant gendb://CombinedGenotypes_WES.gdb -O Test_WES_variantcalling.vcf.gz --annotate-with-num-discovered-alleles -stand-call-conf 30 --max-alternate-alleles 12 --allow-old-rms-mapping-quality-annotation-data. and the error:. 17 Jun 2020 15:49:59,410 DEBUG: java.lang.NullPointerException; 17 Jun 2020 15:49:59,412 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeInt(BCF2Decoder.java:226); 17 Jun 2020 15:49:59,413 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeSingleValue(BCF2Decoder.java:157); 17 Jun 2020 15:49:59,414 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:146); 17 Jun 2020 15:49:59,416 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:130); 17 Jun 2020 15:49:59,417 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:125); 17 Jun 2020 15:49:59,419 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeInfo(BCF2Codec.java:410); 17 Jun 2020 15:49:59,420 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeSitesExtendedInfo(BCF2Codec.java:298); 17 Jun 2020 15:49:59,422 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:132); 17 Jun 2020 15:49:59,423 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); 17 Jun 2020 15:49:59,425 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:183); 17 Jun 2020 15:49:59,426 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); 17 Jun 2020 15:49:59,428 DEBUG: at java.util.Iterator.forEachRemaining(Iterator.java:116); 17 Jun 2020 15:49:59,42",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6667:325,simpl,simplified,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667,1,['simpl'],['simplified']
Usability,"We decided to remove the ""conversion"" to AllelicCapseg output from ModelSegments, since this was an ill defined procedure. The models used by AllelicCapseg and AllelicCNV/ModelSegments are simply different, so it's not possible to define a unique conversion between their model parameters. Compounding this, we also had difficulty finding up-to-date documentation about the models used by various versions of both AllelicCapseg and ABSOLUTE. That said, some of this removed functionality can be found in unsupported WDLs at https://github.com/broadinstitute/gatk/tree/master/scripts/unsupported/combine_tracks_postprocessing_cnv (specifically, see the PrototypeACSConversion task in combine_tracks.wdl). These scripts also attempt to perform rudimentary filtering of germline events found in the matched normal; see first link below for some additional caveats. Note that we cannot really answer further questions or otherwise support these scripts (and it's possible that the experimental/beta GATK tools used in the WDLs may be removed in the future), and the developer responsible for them has moved on from the Broad---use them at your own risk. See also https://gatkforums.broadinstitute.org/gatk/discussion/comment/59467 https://github.com/broadinstitute/gatk/pull/5450 https://github.com/broadinstitute/gatk/issues/5804 for additional context.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6685#issuecomment-652407603:189,simpl,simply,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685#issuecomment-652407603,2,['simpl'],['simply']
Usability,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:62,simpl,simple,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583,2,['simpl'],['simple']
Usability,"We don't yet have good regression tests for Spark that run on a cluster and are separate from the jenkins performance tests. https://github.com/broadinstitute/gatk/issues/2298 will satisfy part of the requirements for this ticket once it's done (by catching the most basic regressions before merge), but there's also a need for larger-scale correctness tests whose status is clearly visible on github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-287473713:375,clear,clearly,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-287473713,2,['clear'],['clearly']
Usability,"We encountered an error with git-lfs in #1378. This was worked around by simply pulling twice in `scripts/install_git_lfs.sh`, but it shouldn't have to do that. . Remove this extra pull once a better solution is found in https://github.com/github/git-lfs/issues/904",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1404:73,simpl,simply,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1404,1,['simpl'],['simply']
Usability,"We ended up using jopt-simple alongside some of our existing code. It was chosen somewhat arbitrarily after examining a number of different options. It supports arguments on the style that we wanted, is under active development, and was easy to plug into our existing code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/72#issuecomment-71662187:23,simpl,simple,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/72#issuecomment-71662187,1,['simpl'],['simple']
Usability,We found (the hard way) that simple `gradle` sometimes fails (eg when a dotkit is broken) and `gradlew` should be the uniformly recommended way. @lbergelson please have a look,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1511:29,simpl,simple,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1511,1,['simpl'],['simple']
Usability,"We found this trying to tie out the BQ version of the VQSR annotations with the Evoquer+Gnarly outputs, specifically in the RankSumTest annotations. This never got merged into master. The short story is... the implementation of median in the Histogram class is broken. Precisely, in this line it iterates through the bins of the histogram to find the midpoint index... however the keySet() it gets is from a HashMap and therefore not ordered. That code hasn't been touched in 2 years, so it's been this way for a while. It's tough to catch because of course there is a non-guaranteed ordering to the keys, and in the case of hashmap today when there are < 16 keys will be the hashcode of the keys modulo 16 until there is collision. The hashcode of integers is just the integer... so in our tests we have today it just happens to work because we have a small number of keys and they are close to each other so hash in the order we happen to want. I learned more about [HashMap internals](http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/687fd7c7986d/src/share/classes/java/util/HashMap.java) than I wanted to know in order to make a test case for it :/ . I. A test on data like this breaks:. 1,2,16. as it returns 1 instead of 2 as the median. I have a test for this, and have a fix (basically sort the keys, running through a TreeSet). Thanks to @mmorgantaylor and @schaluva for helping with this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7131:949,learn,learned,949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7131,1,['learn'],['learned']
Usability,We had a breakage in our java 11 support which went undetected by tests because it only happened when we actually packaged the jar and that isn't done in our java 11 tests.; ; See #7339 #7338. We should add a simple test to make sure something like this doesn't happen again.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7346:209,simpl,simple,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7346,1,['simpl'],['simple']
Usability,"We have a lot of code in Hellbender that's at its core a simple function, but it needs many lines of Dataflow boilerplate to wrap it into a transform. It would be a great timesaver to create a helper function that goes from function to PTransform. We might for example use it like this:. `PTransform<A,B> myTransform = Map.<A,B>of( a -> new B(a.start+1, a.end));`. references:; lambda syntax: https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html; serializable lambdas: http://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/658:57,simpl,simple,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/658,1,['simpl'],['simple']
Usability,We have a number of R package dependencies and it's not clear if we actually need all of them or if some of them are there for historical reasons. We should review them and identify which we actually need.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3047:56,clear,clear,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3047,1,['clear'],['clear']
Usability,"We have determined that a sites-only VCF causes ASEReadCounter to only output a header. There are warnings in the stack trace but it is not clear that the tool found no genotypes in the file. We can look into adding a check in ASEReadCounter to exit out if the VCF has no genotype fields. The documentation for this tool should also be more specific. This request was created from a contribution made by Chunyang Bao on June 14, 2021 23:15 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/1260803844270-ASEReadCounter-ouputs-only-header-](https://gatk.broadinstitute.org/hc/en-us/community/posts/1260803844270-ASEReadCounter-ouputs-only-header-). \--. I am using ASEReadCounter to call allelic read counts on 1000 genome reference. But, I found ASEReadCounter generatd only header in output file. Here I enclosed my command and stderr log. Please help me to check it. Thank you!. If you are seeing an error, please provide(REQUIRED) : ; ; a) GATK version used: 4.1.8.1 ; ; b) Exact command used:. java -Xmx8000m -Djava.io.tmpdir=/broad/hptmp/cbao \\ ; ; \-jar ${path2gatk}/gatk-package-4.1.8.1-local.jar \\ ; ; ASEReadCounter \\ ; ; \-L scattered.interval\_list \\ ; ; \-R Homo\_sapiens\_assembly19.fasta \\ ; ; \-V 1000G\_phase1.snps.high\_confidence.b37.vcf.gz \\ ; ; \-I downsample\_10k.bam \\ ; ; \-O output.txt --verbosity INFO. c) Entire error log:. 19:13:25.991 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/broad/software/free/Linux/redhat\_7\_x86\_64/pkgs/gatk\_4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so. Jun 14, 2021 7:13:26 PM shaded.cloud\_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials. WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota excee",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7327:140,clear,clear,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7327,1,['clear'],['clear']
Usability,"We have discussed this and I have shown @lbergelson the error of his ways ;). Admittedly I'm still working on improving the presentation of content on the website -- but user feedback suggests they find the current site far superior to the old wiki. Also, I hate wikis. Also also, Louis was mostly complaining about the dev zone and queue docs, which do suck.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151957099:175,feedback,feedback,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151957099,1,['feedback'],['feedback']
Usability,We need a parser that can read in non-Locatable files. These files will be *sv formatted (e.g. tsv / csv / etc.). This should be based off of the simple `Path` reader in #3756,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3757:146,simpl,simple,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3757,1,['simpl'],['simple']
Usability,"We need a plan for this. It would be nice to use the SV team's in-memory BWA-mem binding, but it's not clear that tweaking settings would be enough to capture possible alignment errors in a BWA-aligned bam file. CGA has used Novo-align and BLAT in the past. We'll want to talk with Chris, Heng, and Julian about this.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3089:103,clear,clear,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3089,1,['clear'],['clear']
Usability,"We need to help users help themselves either with better checks in tools or with better documentation to avoid the discrepancies observed in this thread, whose answer is recapitulated below. ---; Hi @obigriffith,. I am using GATK v4.0.11.0 and I also see what you are seeing. I've been taking an Android App development course since January (in my free time of course), and I've learned that with multiple expressions, sometimes the Java programming language needs help in parsing expressions. That is, we need to help the tool demarcate where an expression begins and ends. **1. no filtering expected works as expected (but this is misleading)**; ```; --filter-expression ""QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRandSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 3.0""; ```; ![](https://us.v-cdn.net/5019796/uploads/editor/a8/q0yjdx55d0fz.png """"). **2. should be filtered based on SOR (at 0.608) but is not**; ```; --filter-expression ""QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRandSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 0.5"" ; ```; ![](https://us.v-cdn.net/5019796/uploads/editor/2s/tft38knytdib.png """"). **3. Using parentheses around each expression allows SOR (and presumably other expressions) to be read correctly**; ```; --filter-expression ""(QD < 2.0) || (FS > 60.0) || (MQ < 40.0) || (MQRankSum < -12.5) || (ReadPosRankSum < -8.0) || (SOR > 0.5)""; ```; This will allow the tool to read the SOR expression unambiguously. Here are results from my testing:; ![](https://us.v-cdn.net/5019796/uploads/editor/o4/5939fiysxmr4.png """"). **4. Providing each expression as a separate parameter also allows SOR (and others) to be read correctly and also provides additional insight**; Separate out each condition into individual filter expressions:; ```; --filter-expression ""QD < 2.0"" --filter-name ""QDlessthan2"" --filter-expression ""FS > 60.0"" --filter-name ""FSgreaterthan60"" --filter-expression ""MQ < 90.0"" --filter-name ""MQlessthan90"" --filter-expression ""MQRankSum < -12.5"" --filter-name ""MQRank",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362:379,learn,learned,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362,1,['learn'],['learned']
Usability,"We need to see how many variants from COSMIC a typical tumor contains, and of these what is the precision. If there are a decent number with high confidence we could use it as follows:. * Get high-confidence somatic sites for a tumor-in-normal tool. For such a tool we can't rely on the normal artifact filter and so a bit of extra help would be nice.; * Get training data for deep learning, perhaps to seed a semi-supervised approach.; * Modify the tumor lod threshold based on presence in COSMIC.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5089:382,learn,learning,382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5089,1,['learn'],['learning']
Usability,"We recently determined that the FTZ setting gets cleared during integration tests for unknown reasons. We temporarily fixed this by explicitly turning FTZ on in every call to `jniComputeLikelihoods()` (https://github.com/broadinstitute/gatk/pull/1764), but this might be inefficient, and even if it isn't it would be good to understand what's going on. Without the fix in https://github.com/broadinstitute/gatk/pull/1764, if you run `HaplotypeCallerIntegrationTest`, the ""consistent with past results"" tests will either succeed or fail depending on whether they run first or not, and the failure is definitely due to FTZ somehow getting unset between tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771:49,clear,cleared,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771,1,['clear'],['cleared']
Usability,"We recently discovered that some of the tests we didn't think required google cloud authentication require that gcloud be initialized. Travis didn't catch this because we always initialize gcloud in order to do log uploading. We should change this so it's only initialized during the tests for the cloud tests. . The actual error we discovered didn't require that credentials be correct, only that a default project had been configured so simply logging out isn't enough to trigger it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706:439,simpl,simply,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706,1,['simpl'],['simply']
Usability,We should have a progress bar for local walkers. This can be based on GATK's progress bar,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/974:17,progress bar,progress bar,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974,2,['progress bar'],['progress bar']
Usability,"We should have an installer script checked in to the repo for downloading the Funcotator datasources. Ideally the script would have a trivial Java frontend in the form of a simple GATK tool, to make it more discoverable by users.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4549:173,simpl,simple,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4549,1,['simpl'],['simple']
Usability,"We should update any public docs that contain recommendations on how to write JEXL expressions to reflect the align with the doc changes made in https://github.com/broadinstitute/gatk/pull/5422. Specifically, we should recommend that multiple simple expressions be used in place of a single compound expression. Here are @sooheelee 's notes on what docs need to change:. Here are the documents we should also update to reflect these updates:. https://gatkforums.broadinstitute.org/gatk/discussion/1255/using-jexl-to-apply-hard-filters-or-select-variants-based-on-annotation-values; https://software.broadinstitute.org/gatk/documentation/article?id=11080; Also, here is a list of documents with the jexl tag:; https://gatkforums.broadinstitute.org/gatk/discussions/tagged/jexl. I have put in a word of caution in https://gatkforums.broadinstitute.org/gatk/discussion/12350/how-to-filter-on-genotype-using-variantfiltration/p1?new=1.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5509:243,simpl,simple,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5509,1,['simpl'],['simple']
Usability,"We use Gauss-Legendre integration in the strand bias model. The number of subdivisions increases with the read count and for very deep coverage this can cause a stack overflow because, unfortunately, Apache Commons has a very questionable recursive implementation. The short-term fix is to cap the number of subdivisions. The long-term fix is to write some sort of simple adaptive 1D and 2D quadrature method. This ticket is for the short-term fix.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3317:365,simpl,simple,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3317,1,['simpl'],['simple']
Usability,"We want the public GATK framework to contain all the generic capabilities for loading and traversing data in various formats -- all new walker types, general-purpose utilities for working with different formats, etc. should ideally live in the framework rather than in protected. Moving these classes to public should also improve code quality by preventing general-purpose code from getting embedded within particular tools, and would encourage the development of clear APIs for using this code. @akiezun since you love to rip code out, you get this one :) You should consult with @LeeTL1220 and @vruano to identify which classes should be moved. If the classes to be moved have already been adequately reviewed and are covered by tests, they shouldn't require a re-review (though we can do one if @LeeTL1220 requests it).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1427:465,clear,clear,465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1427,1,['clear'],['clear']
Usability,"We want to add an overload of `SamReaderFactory.open()` in htsjdk that accepts a `java.nio.file.Path`, and uses `Files.newInputStream(path)` or similar to get an `InputStream` from it and return a SAM/BAM/CRAM reader. This should enable us to transparently load reads from any input source for which there is a Java NIO file system provider available. Such a provider is already implemented for HDFS (https://github.com/damiencarol/jsr203-hadoop). There may be one for GCS as well (and if there isn't, it might be simple to implement one). Note that this feature needs to handle the companion index as well, if present. Also note that we should not add any new dependencies to htsjdk as part of this change. This change should be modeled on the equivalent change @tomwhite recently made for the reference classes in htsjdk (https://github.com/samtools/htsjdk/pull/308). The unit tests in htsjdk for this feature can be very simple -- just take existing `File` arguments to test cases and call `toPath()` on them, and make sure the existing test cases pass. . On the GATK side, we'd want tests to make sure that we can use the new `SamReaderFactory.open()` overload to open BAM/SAM/CRAM files locally, on HDFS, and on GCS. If it turns out that there isn't already a Java NIO provider for GCS and it's non-trivial to implement, that could become a separate ticket.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1426:514,simpl,simple,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1426,2,['simpl'],['simple']
Usability,We'll need a simple build system + README + documented release procedure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598,2,['simpl'],['simple']
Usability,"We're going to release the new model in 3.7 and have users test-drive that for quite a bit before we move to release 4.0, so we should be able to get some feedback on performance in the wild before we need to make any final decisions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589:155,feedback,feedback,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589,2,['feedback'],['feedback']
Usability,"We're trying to chop out huge pile-ups, and genomically ubiquitous kmers, and high frequency kmers in the read set, and then we yet again eliminate kmers that appear in numerous intervals. Can't we do something simpler that cleans up the drek more efficiently?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1889:211,simpl,simpler,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1889,1,['simpl'],['simpler']
Usability,"We've filed a ticket with github support -- however, the branch has been cleared to merge in its current state, as it's had more than enough reviews. We can file tickets to improve/refactor once it's in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625:73,clear,cleared,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625,2,['clear'],['cleared']
Usability,"We've had to do that in other places... On Fri, Jan 12, 2018 at 3:20 PM, samuelklee <notifications@github.com>; wrote:. > To be clear, this will work perfectly fine as long as you have enough; > space in /dev/shm---which is typically true everywhere outside of our; > default Docker container.; >; > I'm loath to cripple a tool just because of limitations that are; > fundamentally elsewhere...let's just address those in the appropriate; > places. (Furthermore, I'm especially loath to write a plotting tool that; > takes ~5 minutes to generate a plot!) And yes, while it is not great that; > data.table forces us to use /dev/shm, I think fread(""grep ..."") is; > relatively standard.; >; > If --shm-size is indeed not exposed, why doesn't the Google backend scale; > /dev/shm or other tmpfs space with requested machine memory?; >; > If there really is no other way around it, then all we're doing is; > filtering out the lines beginning with @. We could do this first by; > calling system commands within R to write to a temporary file, and then; > reading that back in with fread. This seems hacky to me, but I've confirmed; > that it works within the Docker. This will solve our immediate problem, but; > I still think it's worth taking a look at those other limitations elsewhere; > now as well.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxNvcMcJfIhdlPhdU3vLHTiAVPPSks5tJ76mgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198:128,clear,clear,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198,2,['clear'],['clear']
Usability,"We've run some basic WGS tests in gatk-sv, and the results look good. Using our 161-sample 30x NYGC 1KGP test panel, here is a summary of per-sample raw calls from gCNV+cnMOPs. That is, records look like:. ```; chr1	103639835	103663835	1kgp_161_bwa_scramble_DEL_9527	HG01552	DEL	cnmops,gcnv; chr1	103643835	103645835	1kgp_161_bwa_scramble_DEL_9531	HG01494	DEL	gcnv; chr1	103643835	103652200	1kgp_161_bwa_scramble_DEL_9534	HG02236	DEL	cnmops,gcnv; chr1	103645600	103724500	1kgp_161_bwa_scramble_DEL_9538	HG03370	DEL	cnmops,gcnv; chr1	103647835	103649835	1kgp_161_bwa_scramble_DEL_9541	HG01495	DEL	gcnv; chr1	103647835	103681000	1kgp_161_bwa_scramble_DEL_9542	HG01494	DEL	cnmops,gcnv; …; ```. Master:; DEL: 641700; DUP: 699063. Branch:; DEL: 640669; Master intersection: 635178 (99.14% sensitivity); DUP: 691469; Master intersection: 677687 (98.00%). Note that this is a simple bedtools intersection requiring 90% reciprocal overlap, but not matching samples. Subsetting just to NA19420:. Master:; DEL: 4974; DUP: 4254. Branch:; DEL: 4958; Master intersection: 4797 (96.75%); DUP: 4210; Master intersection: 3802 (90.30%). Further subsetting to NA19240 variants over 5kbp, which is the default gatk-sv threshold for depth-only calls:. Master:; DEL: 1133; DUP: 916. Branch:; DEL: 1132; Master intersection: 1060 (93.64%); DUP: 893; Master intersection: 757 (84.77%). While it does appear there's an appreciable difference here, if we subset to NA19240 variants that survive gatk-sv filtering to the ""CleanVcf"" stage (in the current master), the differences are much less:. Master:; DEL: 225; DUP: 61. Branch:; DEL: 226; Master intersection: 223 (98.67%); DUP: 58; Master intersection: 58 (95.08%). I think the differences in raw calls is probably ""in the noise"" for WGS, given the high concordance in this test sample after gatk-sv filtering and genotyping are applied. Edit: Thanks to @kirtanav98 for running these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2186896268:869,simpl,simple,869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2186896268,2,['simpl'],['simple']
Usability,"Well, that explains that, sort of. The code snippet you're providing looks like it ought to do what you say it does (i.e., the mates have to be paired, not unmapped, mapped to the same contig, and have a difference in their start positions that is at least `mateTooDistantLength`). . But there are two problems with this:. 1) This filter's behavior is unexpected wrt HaplotypeCaller. It seems to me that an inclusive filter (i.e., process only paired-end mappings whose TLEN falls within a specified range) would be more usable. That would imply a filter implementation that accepts a pair of integers, but the expected behavior would be more obvious and in line with GATK's other range-limited parameterizations (e.g., `MappingQualityReadFilter` comes immediately to mind). 2) I can't tell from where I sit, but the code snippet looks correct only if `getStart()` and `getMateStart()` return a zero-based start position of each mate relative to the start of the strand to which the mate is mapped. If the code is just computing the difference between POS for the mates, the computation is incorrect for forward + reverse-complement (Illumina-style) pairs. In addition, computing TLEN requires not only that you consider the orientation of the individual mate mappings, but also that you make an arbitrary decision about how to handle soft-clipped reads. I hate to say this, but I think this parameter needs some attention. Its potential utility with HaplotypeCaller seems evident to me (i.e., it would be good to be able to exclude outliers with unreasonable TLENs) but its implementation and frugal documentation make it unusable in practice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220:521,usab,usable,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220,2,['usab'],['usable']
Usability,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:16,clear,clearItems,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723,4,['clear'],['clearItems']
Usability,"What is the best Sparkified way to recapitulate our germline Best Practices workflow? Is there one pipeline that encompasses all steps from BWA alignment to HaplotypeCaller calling?. Please see forum thread as I have answered the user question tentatively with these two options:. [1] BwaSpark --> SortReadFileSpark --> ReadsPipelineSpark; [2] BwaAndMarkDuplicatesPipelineSpark --> SortReadFileSpark --> BQSRPipelineSpark --> HaplotypeCallerSpark. Thanks. ---; Hi @shlee ,; I am really sorry for the delay but I was busy in the last weeks. Anyway I will try to be clearer with this picture:. ![](https://us.v-cdn.net/5019796/uploads/editor/3x/9bu9fsvbgjrh.png """"). as you can see I would like to combine the tools `BwaAndMarkDuplicatesPipelineSpark` and `BQSRPipelineSpark` in one single tool, in order to improve efficiency of the pipeline (avoiding for example a disk writing). ; I tried to do it with [this](https://pastebin.com/XEqvpKmG ""this"") naive approach as I reported in previous comments, but executing this code I obtain this error (as you can see at the end of this [stack-trace](https://paste.ee/p/dMod1 ""stack-trace"") ) : ; ```; 17/11/03 13:02:14 ERROR Utils: Aborting task; java.lang.IllegalArgumentException: Reference index for 'chr11' not found in sequence dictionary.; ```. Do you think is better if I speak directly with developers in the GitHub repository?. Best regards,; Nicholas. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/comment/44143#Comment_44143",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878:564,clear,clearer,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878,1,['clear'],['clearer']
Usability,"When I was trying to use user exceptions in a consistent way independently of the constructor (mostly related with files), I found very weird behaviour with the messages. Here I try to fix some of the things that I was struggling with:. * Support for path in constructors for `CouldNotReadInputFile`, `CouldNotCreateOutputFile`, `MalformedFile` and `MalformedBAM`, in addition to some missing constructors to have the same structure for all of them (with `File` and/or `String`).; * ~~Updated javadoc in `CommandLineException`, including extending classes to make clear that in the GATK framework is not printed out if it is thrown out of parameter validation.~~ __Edited__: this is not longer required, because `CommandLineException` is decoupled from `UserException` through barclay.; * Added a TODO into the `MalformedBAM` constructor that includes a `GATKRead` that is not used.; * __Edited__: added final to constructors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282:564,clear,clear,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282,1,['clear'],['clear']
Usability,"When `GenotypeGVCFs` is sharded by `-L` interval, as it typically is in production, it needs a way to avoid emitting the same call across shards in the case of indels that span interval boundaries. The simplest way to do this is to only emit records that start in the current interval. It might make sense to do this at the VCF writer level, and hook it up to an engine-wide argument to toggle this behavior. `HaplotypeCaller` and `Mutect` currently do something similar internally, and could possibly leverage this functionality.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2735:202,simpl,simplest,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2735,1,['simpl'],['simplest']
Usability,"When a variant has an ambiguity between two alleles (say in an STR, when the likelihood is hard-pressed to choose between two different alleles) the AF calculator tosses both alleles even though it is clear that the site isn't reference. for example:; REF = A; ALT1=AC; ALT2=ACC; (diploid); PL = (300,0,300,5,300,300). So the likelihoods are pointing to a heterozygous site, with reference and one of the other two alleles, probably the first, but maybe the second.; Clearly not 0/0. however, pass this variant through the genotypingEngine.calculateGenotypes and you get null. (see PR #6363 for failing test). The reason is that calculateGenotypes goes over the alleles and checks if it can throw any of them out...since there are viable options without either allele, both alleles get thrown out. This is despite the fact that there are no viable options without BOTH alleles..... I think that the way to fix this is to remove alleles in an iterative manner. of the alleles that can be removed, remove the least likely one, then repeat until the VC isn't changed. I'm happy to implement this, but I wanted someone to look and agree that the test is correct and that the current behavior is undesirable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6364:201,clear,clear,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6364,2,"['Clear', 'clear']","['Clearly', 'clear']"
Usability,"When a variant has an ambiguity between two alleles (say in an str, when the likelihood is hard-pressed to choose between two different alleles) the AF calculator tosses both alleles even though it is clear that the site isn't reference. for example: ; REF =A; ALT1=AC; ALT2=ACC; (diploid); PL = (300,0,300,5,300,300). So the likelihoods are pointing to a heterozygous site, with reference and one of the other two alleles, probably the first, but maybe the second.; Clearly not 0/0. however, pass this variant through the genotypingEngine.calculateGenotypes and you get null. The reason is that calculateGenotypes goes over the alleles and checks if it can throw any of them out...since there are viable options without either allele, both alleles get thrown out. This is despite the fact that there are no viable options without BOTH alleles..... I think that the way to fix this is to remove alleles in an iterative manner. of the alleles that can be removed, remove the least likely one, then repeat until the VC isn't changed. I'm happy to implement this, but I wanted someone to look and agree that the test is correct and that the current behaviour is undesirable. @ldgauthier @davidbenjamin @vruano ?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6363:201,clear,clear,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6363,2,"['Clear', 'clear']","['Clearly', 'clear']"
Usability,"When both panel of normals and sample are GC bias corrected, does that undo all the work you do for GC bias? As in if you apply the kernel to both normals and sample and then divide the sample by the normals, that should also divide out the kernel? It's hard to tell from going through the code.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6038:71,undo,undo,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6038,1,['undo'],['undo']
Usability,"When each haplotype has a deletion and they overlap, but the first is low quality, the resulting reference block gets the wrong END. Input:; ```; chr22	10515074	.	AGAAG	A,<NON_REF>	0	.	DP=10;ExcessHet=3.0103;MLEAC=0,0;MLEAF=0.00,0.00;RAW_MQ=19758.00	GT:AD:DP:GQ:PL:SB	0/0:6,0,0:6:18:0,18,253,18,254,254:5,1,0,0; chr22	10515076	.	AAGGAAGG	A,<NON_REF>	112.73	.	BaseQRankSum=-0.365;ClippingRankSum=0.365;DP=10;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.365;RAW_MQ=19758.00;ReadPosRankSum=2.383	GT:AD:DP:GQ:PL:SB	0/1:6,4,0:10:99:150,0,211,168,223,391:5,1,3,1; ```. Current behavior:; ```; chr22 10515074 . A <NON_REF> . . END=10515078 GT:DP:GQ:MIN_DP:PL 0/0:6:18:6:0,18,254; chr22 10515076 . AAGGAAGG A,<NON_REF> 121.77 . DP=10;MQRankSum=0.365;MQ_DP=10;QUALapprox=150;RAW_MQ=19758.00;ReadPosRankSum=2.383;VarDP=10 GT:AD:DP:GQ:PL:SB 0/1:6,4,0:10:99:150,0,211,168,223,391:5,1,3,1; ```. Expected behavior:; ```; chr22 10515074 . A <NON_REF> . . END=10515075 GT:DP:GQ:MIN_DP:PL 0/0:6:18:6:0,18,254; chr22 10515076 . AAGGAAGG A,<NON_REF> 121.77 . DP=10;MQRankSum=0.365;MQ_DP=10;QUALapprox=150;RAW_MQ=19758.00;ReadPosRankSum=2.383;VarDP=10 GT:AD:DP:GQ:PL:SB 0/1:6,4,0:10:99:150,0,211,168,223,391:5,1,3,1; ```; such that the END of the ref block from the first deletion doesn't exceed the start of the next deletion. This may be as simple as checking the start of the next variant when a deletion is converted to a hom ref block.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5722:1334,simpl,simple,1334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5722,1,['simpl'],['simple']
Usability,"When reads are mapped onto the genome short reads don't always find the best spot for indels. Sometimes reads are clipped at a position where a particular indel could have been mapped properly. Those regions you showed here are all homopolymer rich regions where assembly and variant calls are usually harder than other places. 3bp insertion within a GC rich region could easily be mapped wrong due to G and C nucleotide positioning and the way G/C nucleotide is handled by the sequencing instrument. Due to chemistry and optics reasons certain basecalls in GC rich regions may get convoluted with wrong nucleotide assertions such as 1 less G and one more C. . Reassembly, Realignment and PairHMM removes such artifacts by looking at basecalling metrics, mapping qualities, regional metrics etc. I cannot see it directly from the image however it is possible that some of those reads could have been soft/hard clipped due to such errors but yet they are still valid and usable by the assembly engine. . You may wish to read about the DepthPerAlleleBySample class and its documentation as it is the object class that calculates AD for variant contexts. ; [DepthPerAlleleBySample](https://gatk.broadinstitute.org/hc/en-us/articles/360037592411-DepthPerAlleleBySample). I hope this helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304798951:970,usab,usable,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304798951,2,['usab'],['usable']
Usability,Whew -- glad this was something simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-291179390:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-291179390,2,['simpl'],['simple']
Usability,"While we normally don't recommend ignoring that wrapper, this seems like a good reason to do so. . The wrapper is pretty simple, most of what it's doing is some munging of the input to allow it to be more standardized in several different gatk use cases. The only thing I can think of that you would want to be sure to copy is that it sets a number of properties. . We set these spark `--conf` properties with the wrapper. I don't actually know how important some of them are anymore. If it works without them then you're probably good.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. These are htsjdk properties we want to set for spark. ; ```; EXTRA_JAVA_OPTIONS_SPARK= ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. If you can get this value into your spark environment variables it prevents and anying warning output. `SUPPRESS_GCLOUD_CREDS_WARNING=true`. Let us know how it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054:121,simpl,simple,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054,2,['simpl'],['simple']
Usability,"While working on #1394 I noticed that there are some issues with clipping op that need decisions to be made about how they work. Specifically, if you perform a Softclip operation on a read where you tell it to Softclip the entire read it will silently shorten the clip to include everything but the last base of the read in the following code from ClippingOp.java:. `if ((stop + 1 - start) == readCopied.getLength()) { ; // BAM representation issue -- we can't SOFTCLIP away all bases in a read, just leave it alone; myStop--; // just decrement stop; }`. This behavior is inconsistent with the behavior of a hardclip operation, where the tool will simply produce a read with an empty cigar string. Arbitrarily deciding not to clip the read to one particular base does not seem like the right way to deal with this. I added a test ReadClipperUnitTest.java that explores this behavior in #2021 pull request.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2022:648,simpl,simply,648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2022,1,['simpl'],['simply']
Usability,"With the GATK gCNV having great performance results on the first round of evaluations it is ready to be used to call on ExAC. The following things need to be done first:. - Set up gCNV workflow to run on SGE (since exome samples are stored on prem). - Decide on target filtering strategy. . - Decide on the number of samples to use to learn the model (PoN). - Get some truth data to do QC, for example CNV calls from Genome STRiP on matched genome samples in gnomAD. - Design an interval list for samples in ExAC that do not mention one in their metadata. One possible solution could be to use cluster assignment of a sample to choose the interval list pertaining to that cluster. - (Optional) Consider importing list of common CNV regions into gCNV. To make job of gCNV inference easier we could use the list of common CNV regions that was obtained from Genome STRiP calls. To start @ldgauthier suggested using samples sequenced using latest Illumina capture protocol (Standard_Exome_Sequencing_v4) to get the ball rolling",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4738:335,learn,learn,335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4738,1,['learn'],['learn']
Usability,"Woohoo, knew it would be a simple fix! :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155500559:27,simpl,simple,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155500559,1,['simpl'],['simple']
Usability,Work is split into two commits:. - Removed undocumented mid-p correction to p-values in exact test of Hardy-Weinberg equilibrium and updated corresponding unit tests.; - Updated expected ExcessHet values in integration test resources and added an update toggle to GnarlyGenotyperIntegrationTest. Various scout cleanups as well. We now report the same value as ExcHet in bcftools. Note that previous values of 3.0103 (corresponding to mid-p values of 0.5) will now be 0.0000. See discussion below and in linked issue for additional details. Closes #7392.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394:43,undo,undocumented,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394,1,['undo'],['undocumented']
Usability,Would be better that IntervalsSkipList.getOverlapping would accept a Locatable rather than a SimpleInterval.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3541:93,Simpl,SimpleInterval,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541,1,['Simpl'],['SimpleInterval']
Usability,Would it be better/simpler to just have both `./gradlew gatkDoc` and `./gradlew phpDoc`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823:19,simpl,simpler,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823,2,['simpl'],['simpler']
Usability,Write a programming guide for hellbender once the tool API stabilizes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1016:20,guid,guide,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1016,2,['guid'],['guide']
Usability,"Write a simple annotator that annotates a vcf with a GC context in the reference near a variant as an INFO field. Ideally it would take a k-mer size as an argument, but I'm not sure if VariantAnnotator supports that.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3205:8,simpl,simple,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3205,1,['simpl'],['simple']
Usability,"Wrote a SimpleCopyRatioCaller that is still relatively naive, but I think a bit more sensible than ReCapSegCaller. It does the following:. 1) use the non-log2 mean copy ratio to determine copy-neutral segments (those within 1 +/- x, where x is an exposed parameter),; 2) weight segments by length for determining the mean and standard deviation of the non-log2 copy ratio in copy-neutral segments,; 3) filter outlier copy-neutral segments by non-log2 copy ratio z-score,; 4) use the filtered copy-neutral segments to determine a length-weighted mean and standard deviation,; 5) call remaining segments using z-score based on this mean and standard deviation. @MartonKN take note of these changes! I am sure that your caller will still do much better, especially given the allele-fraction data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3825#issuecomment-344590576:8,Simpl,SimpleCopyRatioCaller,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3825#issuecomment-344590576,1,['Simpl'],['SimpleCopyRatioCaller']
Usability,"X). ![unnamed](https://cloud.githubusercontent.com/assets/15305869/26426249/ce3ffb68-40a5-11e7-8002-6ea4f8513eea.png). A naive calculation of the relative X ploidy, i.e. calculating X_pcov = (X_total_read_counts / autosome_total_read_count) for all samples, performing a 2-mean clustering, and dividing the X_pcov by the lower ploidy cluster mean reveals that indeed, the X conting has twice more coverage on _average_ in XX samples:; ![image](https://cloud.githubusercontent.com/assets/15305869/26426348/2b2d6982-40a6-11e7-8eca-e93916bfc80c.png). Further investigation shows that the wrong behavior of TargetCoverageSexGenotyper stems from the lack of robustness of Poisson regression to outliers: there are a number of targets in the X contig with anomalously high coverage (200x median!). In the absence of Y coverage data (and bias adjustment), higher ploidy genotypes are always favored (in this case, XX). Solution: either filter read counts for outliers before calculating Poisson log likelihoods, or simply use the naive median-based ploidy estimates and perform genotyping on the estimated ploidies (rather than target-resolved read counts). The latter is proven to be robust to outliers. Update: it turns out that the issue can be fixed by simply taking into account bait count as a multiplicative bias. Otherwise, the distribution of raw read counts is multimodal and far from Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516437/54da4930-4254-11e7-9093-5e5fe1e0e28e.png). Correcting for bait count yields a neat over-dispersed Poisson:; ![image](https://cloud.githubusercontent.com/assets/15305869/26516442/68d9ba4c-4254-11e7-82f0-c182f2485d67.png). Todo:; - [x] bait count target annotations; - [x] take bait count into account in TargetCoverageSexGenotyper model; - [x] PAR region blacklisting via command line in TargetCoverageSexGenotyper; - [ ] unit test for bait count functionality of TargetAnnotator; - [x] unit tests for genotyping with only X coverage",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3015:1546,simpl,simply,1546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3015,2,['simpl'],['simply']
Usability,XNvdXJjZS5qYXZh) | `62.963% <100.000%> (ø)` | |; | [...tils/CombineSegmentBreakpointsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6780/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL0NvbWJpbmVTZWdtZW50QnJlYWtwb2ludHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `93.671% <100.000%> (ø)` | |; | [...geAnnotatedRegionsByAnnotationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6780/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9uc0J5QW5ub3RhdGlvbkludGVncmF0aW9uVGVzdC5qYXZh) | `100.000% <100.000%> (ø)` | |; | [...number/utils/TagGermlineEventsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6780/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100.000% <100.000%> (ø)` | |; | [...nterval/SimpleAnnotatedIntervalWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/6780/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `100.000% <100.000%> (ø)` | |; | ... and [29 more](https://codecov.io/gh/broadinstitute/gatk/pull/6780/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6780#issuecomment-1364369697:5163,Simpl,SimpleAnnotatedIntervalWriterUnitTest,5163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6780#issuecomment-1364369697,1,['Simpl'],['SimpleAnnotatedIntervalWriterUnitTest']
Usability,YQ==) | `95.041% <0%> (-4.959%)` | `29% <0%> (+16%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.745% <0%> (-1.553%)` | `18% <0%> (+1%)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `76.471% <0%> (-1.307%)` | `30% <0%> (+8%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `85.393% <0%> (-1.174%)` | `2% <0%> (ø)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `74.194% <0%> (-1.02%)` | `15% <0%> (+5%)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `70.37% <0%> (-0.823%)` | `50% <0%> (-1%)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://code,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4473#issuecomment-369354277:2855,Simpl,SimpleSVType,2855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4473#issuecomment-369354277,1,['Simpl'],['SimpleSVType']
Usability,YXZh) | `75.949% <ø> (ø)` | `29 <0> (-1)` | :arrow_down: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...s/walkers/contamination/GatherPileupSummaries.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2F0aGVyUGlsZXVwU3VtbWFyaWVzLmphdmE=) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `12 <10> (?)` | |; | [...orientation/LearnReadOrientationModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...s/walkers/contamination/PileupSummaryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `6 <5> (+4)` | :arrow_up: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.745% <100%> (+0.074%)` | `45 <2> (+2)` | :arrow_up: |; | [...ers/readorientati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576:2799,Learn,LearnReadOrientationModelUnitTest,2799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576,1,['Learn'],['LearnReadOrientationModelUnitTest']
Usability,"Yeah - this makes 2 assumptions: the data are evenly distributed and that progress is constant. This isn't the most accurate way to do this, but something is better than nothing. . There is another implementation that I considered - base the remaining time on the time it has taken for the last `N` updates. This would account for bursty processing times, but would also result in wildly fluctuating estimates (because it would still assume a uniform distribution of data). We cam also do something like this with a sliding window average to smooth it out. If you prefer another implementation I can change it, but again - something is better than nothing. . I don't want to have to scan the input data to make the progress bar work - that seems way too heavy-handed and would slow everything down. The tradeoff doesn't seem worth it. . For small files it doesn't matter anyway, so I'm not too concerned. . This arose for me because I've been needing to wait many hours for jobs to finish and I would like an estimate of when I cam expect it to finish.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371:715,progress bar,progress bar,715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371,2,['progress bar'],['progress bar']
Usability,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:362,simpl,simplify,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,1,['simpl'],['simplify']
Usability,"Yeah, it would be useful (see https://github.com/broadinstitute/gatk/issues/2582). Not sure if/when we'll ever get around to the Barclay changes though. Another simple option that wouldn't require Barclay changes would be to implement it as just another (plugin descriptor) command line argument that could be sued alongside `--read-filter`'. So if you wanted a `ReadNameFilter` and an inverted `ReadLengthFilter`, the syntax would be:. `--read-filter ReadNameFilter --invert-read-filter ReadLengthReadFilter`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306:161,simpl,simple,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306,2,['simpl'],['simple']
Usability,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:25,simpl,simply,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,2,['simpl'],['simply']
Usability,"Yep, sorry. Just learned that as you were closing it. On Tue, Aug 14, 2018 at 11:51 AM, Louis Bergelson <notifications@github.com>; wrote:. > It's useful to put something like fixes #5104 in the commit message. That; > way it automatically closes the issue and shows a link from the PR to the; > Issue.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AoMkWAqeYbmnX12i6s9k_5bEWy149CPFks5uQvITgaJpZM4UyozK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593:17,learn,learned,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593,2,['learn'],['learned']
Usability,"Yes, agreed @akiezun -- and as mentioned at group meeting this week, we can meet with you guys to provide guidance in setting this up in a way that GATK can easily use after we meet our June deadlines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227452491:106,guid,guidance,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227452491,1,['guid'],['guidance']
Usability,"Yes, but... It looks to me as if the index files, which appear to be in the master node's Linux file system in this failing example, are probably not available to the worker nodes. You'd have to copy each of the 5 index files to each of the workers, putting them in the same location on each. The same problem would occur with the new version: The single-image index file will still need to be available to all workers. You could distribute this file with:; ```--conf spark.yarn.dist.files=<location of the image file>```; which will copy it from your local machine to all workers each time you run the program. This isn't optimal, because it's pretty large. So, instead, you could copy it to a fixed path, identical on each worker, once up front, and then run your alignment jobs to your heart's content. The new version is a little simpler, because there's just one index file, but otherwise suffers from the same issue: bwa mem only knows how to deal with ordinary file system files -- not HDFS, not GCS -- and so the file must be copied to each worker machine in the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-288545672:834,simpl,simpler,834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-288545672,2,['simpl'],['simpler']
Usability,"Yes, that is easy to do. The guidance on how much memory to leave wasnt clear on the docs. Is there a rule of thumb on how much we should leave? We can do whatever makes sense. the command is something like:. ```. /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; -Djava.io.tmpdir=/mnt/scratch/prime-seq/tmp.5E76utMagnGenomicsDB_Append_Merge_2020-11-04_09-17-56-Job1 \; -Xmx104g \; -Xms104g \; -Xss2m \; -jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar GenomicsDBImport \; -V <Repeated 183 times for gVCFs> \ ; --genomicsdb-update-workspace-path /home/exacloud/gscratch/prime-seq/workDir/9a2611e8-0112-1039-8c80-f8f3fc869aa5/Job1.work/WGS_Nov_1300.gdb \; --batch-size 50 \; --consolidate \; --genomicsdb-shared-posixfs-optimizations. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565:29,guid,guidance,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565,4,"['clear', 'guid']","['clear', 'guidance']"
Usability,"Yes. We should expect that PCR error shouldn't affect the base-quality, so two high quality, disagreeing bases are an indication of a PCR error, while one low-quality base, and one high quality base that have differing qualities looks more like a sequencing error. We might be able to obtain a data-driven model for that using the overlapping bases themselves (over monomorphic sites). The only problem is that this is only true when the reads haven't been processed by Consensus calling....but if we have a good model for consensus calling within haplotype caller we could avoid doing that upfront and simply deal with everything within haplotype caller. **That** would be ideal!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400815571:603,simpl,simply,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400815571,2,['simpl'],['simply']
Usability,YnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `80.263% <100%> (+0.811%)` | `22 <1> (+1)` | :arrow_up: |; | [...cotator/dataSources/vcf/VcfFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.582% <100%> (+0.248%)` | `48 <1> (+1)` | :arrow_up: |; | [...r/dataSources/cosmic/CosmicFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2Nvc21pYy9Db3NtaWNGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `66.917% <100%> (+0.763%)` | `26 <1> (+1)` | :arrow_up: |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeVVuaXRUZXN0LmphdmE=) | `94.033% <100%> (+0.009%)` | `67 <1> (ø)` | :arrow_down: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.5% <100%> (+0.403%)` | `28 <3> (+1)` | :arrow_up: |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.926% <22.222%> (-11.031%)` | `17 <1> (ø)` | |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/5491/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5491#issuecomment-445079102:3632,Simpl,SimpleKeyXsvFuncotationFactory,3632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5491#issuecomment-445079102,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"You are going to want to change all the ; `memory: machine_mem + "" GB""` ; lines to ; `memory: machine_mem + "" MB""`.; Otherwise you are going to be asking for massive amounts of memory 😄. Sorry if I wasn't clear the first time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065:205,clear,clear,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065,2,['clear'],['clear']
Usability,You can consider this fixed if it passes a simple unit test where you run `ReadPosRankSumTest.getReadPosition` on a few artificial read of the form <ref match><short deletion><short ref match of 1-5 or so bases><short deletion>.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5492#issuecomment-445115098:43,simpl,simple,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5492#issuecomment-445115098,2,['simpl'],['simple']
Usability,"You're partially correct. A push build builds exactly the branch as pushed, while the PR build essentially merges the branch into master and builds that, so it's what you would get on merging. Since the only result we really care about is what happens when we merge to master, we try to skip the push builds by instantly passing them and only building the PRs. . I think there's an issue though when there is a merge conflict, because then it can't build the PR build since you have to resolve the conflict manually, but it still skips the push build, so we don't get any useful feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584454027:579,feedback,feedback,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584454027,2,['feedback'],['feedback']
Usability,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:219,learn,learning,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340,2,['learn'],['learning']
Usability,"Your interpretation sounds right, although I wish the language in the SAM spec were clearer - something like ""if 0x1 is unset, fields 0x2, 0x8, 0x20, 0x40, and 0x80 have no meaning and are ignored by the tools"". SAMRecord.IsValid() returns errors not only for 0x8(mate unmapped)/unpaired read, but also for the other four fields, so all of these errors would need to be removed. IsValid() also triggers an error when an unpaired read has RNEXT set, but the spec. ; doesn't appear to exclude this error. No error is triggered for the unpaired/PNEXT case. . So I agree that it looks like IsValid() should be changed to align with the spec. But I can also imagine potential pitfalls of leaving the GenomicsConverter code the way it is. The code adds spurious information to the bam that might cause problems with legacy versions of the tools. I don't know what the plans are for the state of the existing tool distribution once gatk4 is released. Is it possible that bam files produced in the cloud could make their way into gatk3 workflows, maybe via the sharing of bams between groups? If this happens, then unpaired reads processed in the cloud, with their mate unpaired flags set by the converter, could trigger validation errors when they are fed to the legacy tools. Is there a downside to altering the converter code as well as modifying the ; validator (I don't know what altering google packages entails...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392:84,clear,clearer,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392,1,['clear'],['clearer']
Usability,ZlcmVuY2VUYXhvblByb3BlcnRpZXMuamF2YQ==) | `90% <0%> (-10%)` | `13% <0%> (+12%)` | |; | [...stitute/hellbender/tools/walkers/vqsr/Tranche.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> (ø)` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (ø)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (ø)` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> (ø)` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:2754,Simpl,SimpleRepeatMaskTransformer,2754,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054,1,['Simpl'],['SimpleRepeatMaskTransformer']
Usability,[![Coverage Status](https://coveralls.io/builds/2381417/badge)](https://coveralls.io/builds/2381417). Coverage increased (+0.01%) to 70.37% when pulling **ddae3d1f9ca34832ab52d445f25c2e2cde2fafc3 on akiezun-README-guidelines** into **eff7d0f596502c4425366fad1985e6a1d5ad0542 on master**.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/415#issuecomment-94565460:214,guid,guidelines,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/415#issuecomment-94565460,1,['guid'],['guidelines']
Usability,[...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `84.375% <66.667%> (+0.164%)` | `50 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/walkers/mutect/M2TestingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMlRlc3RpbmdVdGlscy5qYXZh) | `91.304% <91.304%> (ø)` | `6 <6> (?)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `72.193% <0%> (-18.334%)` | `9% <0%> (-15%)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `80.882% <0%> (-8.824%)` | `11% <0%> (-1%)` | |; | [...institute/hellbender/utils/NucleotideUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OdWNsZW90aWRlVW5pdFRlc3QuamF2YQ==) | `90.698% <0%> (-4.795%)` | `34% <0%> (-91%)` | |; | [...ls/ExtractOriginalAlignmentRecordsByNameSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5123/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9FeHRyYWN0T3JpZ2luYWxBbGlnbm1lbnRSZWNvcmRzQnlOYW1lU3BhcmsuamF2YQ==) | `86.364% <0%> (-4.545%)` | `9% <0%> (-1%)` | |; | [...nalAlignmentRecordsByNameSparkIntegrationTest.java],MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5123#issuecomment-414350367:2586,Simpl,SimpleNovelAdjacencyInterpreter,2586,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5123#issuecomment-414350367,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,` | :arrow_down: |; | [...ender/tools/spark/sv/utils/GATKSVVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZDb25zdGFudHMuamF2YQ==) | `75% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `97.297% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.667% <100%> (+0.226%)` | `3 <1> (+1)` | :arrow_up: |; | [...der/tools/spark/sv/utils/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `82.813% <100%> (+0.273%)` | `7 <0> (ø)` | :arrow_down: |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `87.5% <100%> (+63.176%)` | `10 <2> (+5)` | :arrow_up: |; | [...ry/inference/CpxVar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-383235501:2207,Simpl,SimpleSVType,2207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-383235501,1,['Simpl'],['SimpleSVType']
Usability,"`--argument_file` is a parameter shared by many tools. It allows providing arguments in a file instead on a command line, which is very convenient when e.g., merging multiple files using `CombineGVCFs`. And yet, the format of the `argument_file` is not mentioned anywhere. Compare with the `--sample-name-map` from `GenomicDBImport` which mentions tab-delimited format for this file.; Some guidance like this for the `argument_file` would be useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8722:390,guid,guidance,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8722,1,['guid'],['guidance']
Usability,"`-nt` is data threads, that is, threads on a single core. This is not true CPU-level parallelism but can save significant time because different threads need not be delayed by each other's memory fetches and I/O. That is, it is data parallelism but not processor parallelism. `-nct` is CPU parallelism and means multiple cores. I'm closing this issue, but feel free to re-open if I have not answered clearly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5035#issuecomment-443588742:400,clear,clearly,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5035#issuecomment-443588742,2,['clear'],['clearly']
Usability,"`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2416 +/- ##; ===============================================; - Coverage 76.224% 76.218% -0.006% ; + Complexity 10820 10819 -1 ; ===============================================; Files 750 750 ; Lines 39422 39420 -2 ; Branches 6883 6883 ; ===============================================; - Hits 30049 30045 -4 ; - Misses 6755 6757 +2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...alkers/genotyper/afcalc/CustomAFPriorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ3VzdG9tQUZQcmlvclByb3ZpZGVyLmphdmE=) | `94.444% <ø> (-0.556%)` | `6 <ø> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <ø> (-3.333%)` | `10% <ø> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=footer). Last update [75f6331...3f2a04a](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092:1825,learn,learn,1825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092,2,['learn'],['learn']
Usability,`35.714% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../copynumber/formats/records/AnnotatedInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Bbm5vdGF0ZWRJbnRlcnZhbC5qYXZh) | `52.632% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ols/copynumber/formats/records/ModeledSegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Nb2RlbGVkU2VnbWVudC5qYXZh) | `93.75% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `73.913% <ø> (+4.348%)` | `9 <0> (+1)` | :arrow_up: |; | [.../tools/copynumber/formats/records/SimpleCount.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9TaW1wbGVDb3VudC5qYXZh) | `52.632% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/utils/mcmc/ParameterReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlclJlYWRlci5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | ... and [164 more](https://codecov.io/gh/broadinstitute/gatk/pull/3935/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3935#issuecomment-350041068:3480,Simpl,SimpleCount,3480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3935#issuecomment-350041068,1,['Simpl'],['SimpleCount']
Usability,`80.902% <ø> (ø)` | `127 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vUGF0aExpbmVJdGVyYXRvci5qYXZh) | `75% <75%> (ø)` | `4 <4> (?)` | |; | [...kers/annotator/allelespecific/AS\_FisherStrand.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19GaXNoZXJTdHJhbmQuamF2YQ==) | `73.913% <0%> (-6.087%)` | `7% <0%> (+2%)` | |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `73.913% <0%> (-6.087%)` | `6% <0%> (+2%)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `91.667% <0%> (-1.437%)` | `59% <0%> (+11%)` | |; | [...er/tools/walkers/annotator/MappingQualityZero.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9NYXBwaW5nUXVhbGl0eVplcm8uamF2YQ==) | `90.476% <0%> (-1.19%)` | `16% <0%> (+7%)` | |; | [...institute/hellbender/utils/help/HelpConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `2.564% <0%> (-1.14%)` | `1% <0%> (ø)` | |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3801?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3801#issuecomment-342331911:2152,Simpl,SimpleInterval,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3801#issuecomment-342331911,1,['Simpl'],['SimpleInterval']
Usability,"`CreateSequenceDictionary` have several things that could be improved:; - The ouptut is necessary, but a default value could be created within the tool. Because the framework reads the sequence dictionary from the same path and a default extension (**.dict**), it would be nice to allow the creation without specifying the output file and create it according to the convention.; - An option to create the **.fai** index could be included. The `samtools faidx` indexing is well [documented](http://www.htslib.org/doc/faidx.html) and it looks simple to implement. I don't know if this should be implemented here or in htsjdk. I can contribute with both if the GATK developers think that this will improve the tool. I think that the first point is good because is fairly simple and consistent with the framework. The second could be an improvement to be able to create the two required indexes using the same bundled tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2177:541,simpl,simple,541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2177,2,['simpl'],['simple']
Usability,"`FragmentCollection.create(ReadPileup)` assumes a `ReadPileup` sorted by start position and thus it throws an exception (#2245) while trying to fix a multi-sample `ReadPileup` constructed with an stratified one (like in LIBS). For solving the issue, I just implemented a simple fix from the constructor (sorting the stratified pielup) and a simple test for check if #2245 is solved.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2249:271,simpl,simple,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2249,2,['simpl'],['simple']
Usability,"`GATKTool` uses stricter sequence dictionary validation settings for CRAM vs. reference than for non-CRAM vs. reference:. ```; if ( hasCramInput() ) {; // Use stricter validation for CRAM vs. the reference; SequenceDictionaryUtils.validateCRAMDictionaryAgainstReference(refDict, readDict);; }; else {; // Use standard validation settings for non-CRAM reads input vs. the reference; SequenceDictionaryUtils.validateDictionaries(""reference"", refDict, ""reads"", readDict);; }; ```. `GATKSparkTool.validateToolInputs()` should be patched to do the same, AFTER https://github.com/broadinstitute/gatk/issues/966 is done and cram support is in a usable state.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1179:638,usab,usable,638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1179,1,['usab'],['usable']
Usability,"`HaplotypeCaller` and `Mutect2` share an argument `min-base-quality-score` that restricts low-quality bases from assembly. This argument gets passed to `ReadThreadingAssembler`, but take a look at the following code in that class:. ```java; private static final byte MIN_BASE_QUALITY_TO_USE_IN_ASSEMBLY = DEFAULT_MIN_BASE_QUALITY_TO_USE;; protected byte minBaseQualityToUseInAssembly = DEFAULT_MIN_BASE_QUALITY_TO_USE;; ```; The latter variable is set from the command line argument, but only the `static` constant is ever used, in particular in line 447:. ```java; final ReadThreadingGraph rtgraph = new ReadThreadingGraph(kmerSize, debugGraphTransformations, MIN_BASE_QUALITY_TO_USE_IN_ASSEMBLY, numPruningSamples);; ```. The fix is extremely simple: just replace `MIN_BASE_QUALITY_TO_USE_IN_ASSEMBLY` with `minBaseQualityToUseInAssembly`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4126:745,simpl,simple,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4126,1,['simpl'],['simple']
Usability,"`InfiniteRandomMatingPopulationModel` is simpler than its name suggests. The _only_ assumption it makes is that samples have independent genotypes -- after all, the only thing it really does is delegate the calculation, independently for each sample, to `GenotypeLikelihoodCalculator`. Any further assumptions are built into `GenotypeLikelihoodCalculator`. In particular, it is the latter class that assumes Hardy-Weinberg equilibrium (independent alleles). Does anyone else like @vruano or @ldgauthier think that `InfiniteRandomMatingPopulationModel` should be renamed something like `IndependentSamplesModel` and the comment: `And genotypes should exhibit the ratios expected under HWE` moved to `GenotypeLikelihoodCalculator`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1686:41,simpl,simpler,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1686,1,['simpl'],['simpler']
Usability,"`MarkDuplicatesSparkIntegrationTest.testMDOrder()` _always_ passes when run locally, but fails about 50% of the time when run in travis. As a result, it's currently disabled. Some things I've tried to fix the test on travis, without success:; -Run MD with `--parallelism 1` instead of `--parallelism 0` (which doesn't guarantee ordering at all!) -- the original version of the test was running with `--parallelism 0`; -Converted test inputs from sam to bam; -Cleared all of travis's caches. This may be purely a travis issue or a flaw in the test itself, or it may indicate that there remain issues with `MarkDuplicatesSpark` output and ordering despite the recent fixes. Note, however, that the original test from @davidadamsphd that first detected the ordering issue with MD on spark now passes, as do the new `ReadsSparkSink` ordering tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1258:459,Clear,Cleared,459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1258,1,['Clear'],['Cleared']
Usability,"`ReadsSparkSinkUnitTest.readsSinkADAMTest()` fails on the bams `CEUTrio.HiSeq.WGS.b37.ch20.1m-1m1k.NA12878.bam` and `NA12878.chr17_69k_70k.dictFix.bam` (currently commented-out in its `DataProvider`), and it's not clear what the issue is.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1254:214,clear,clear,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1254,1,['clear'],['clear']
Usability,"`ReadsSparkSource.putPairsInSamePartition()` is currently rather naive -- it assumes that in queryname-sorted data, read pairs are always sorted with the first of pair first and the second of pair second, that there are no secondary or supplementary alignments, and that there are always two reads per fragment. We should make this method more robust:. 1. It should not assume that each pair is sorted with the first of pair first and the second of pair second. This is not an invariant of queryname sort order, which requires only that reads with the same name be together. 2. It should work in the presence of secondary and supplementary alignments. 3. It should work even if there are more than two reads per fragment (which is the case with some sequencing technologies). All of these points could be resolved by simply iterating until the read name changes when peeking into each partition. Once we make that change, we should add good unit tests to cover the above 3 cases.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2442:817,simpl,simply,817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2442,1,['simpl'],['simply']
Usability,"`ValidateVariants` performs several checks that go above and beyond what the VCF spec requires for VCF files (e.g. throwing an exception if a variant has an alt allele but has a genotype of hom ref [as found by this user](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061452132-GATK4-RNAseq-short-variant-discovery-SNPs-Indels-)). This is good - it helps catch logic errors in our and others' pipelines. . However, we should add a flag to `ValidateVariants` that will cause it to validate solely based on the VCF spec and not the more strict guidelines.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6553:556,guid,guidelines,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6553,1,['guid'],['guidelines']
Usability,"```; spark-submit --class org.broadinstitute.hellbender.Main \; --deploy-mode client \; --master yarn-client \; --driver-memory 8G \; --conf spark.driver.maxResultSize=0 \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.coll",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:956,Simpl,SimpleInterval,956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['Simpl'],['SimpleInterval']
Usability,"a) GATK version used: 4.2.0.0; b) Exact command used:; ```; ""gatk --java-options '{java_opts}' HaplotypeCaller""; ""-L {interval_list} ""; ""-R {ref} ""; ""-I {bam} ""; ""-bamout {output_bam} ""; ""-O {vcf} {dbsnp} {log}""; ```; . Hi GATK community,. I am experiencing an issue while working with GATK, and I'd appreciate your assistance in resolving it. In my BED file, I have the following line:. `chrX 31182732 31182909 DMD . .`. There is a significant variant at the position chrX-31182732 T>G. However, when I run the command with the provided BED file, I cannot see the variant at the ""chrX 31182732"" position in the output VCF file. Interestingly, when I perform a test by expanding the BED file by one base on each side (changing it to ""`chrX 31182731 31182910 DMD . .`""), I can observe the variant at the ""chrX 31182732"" position in the VCF file. Is it expected behavior for GATK not to consider variants at the boundaries of interval files? Your insights and guidance on resolving this issue would be greatly appreciated. ![Screenshot from 2023-12-18 13-50-05](https://github.com/broadinstitute/gatk/assets/57506727/62386a08-2d9d-4a03-bcad-3c6b34f35357). Thank you in advance for your help. Best regards,; Meryem",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8631:958,guid,guidance,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8631,1,['guid'],['guidance']
Usability,"a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.694% <0%> (+2.083%)` | `36% <0%> (ø)` | :x: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `90.083% <0%> (+4.132%)` | `57% <0%> (+2%)` | :white_check_mark: |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `90.476% <0%> (+4.762%)` | `8% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=footer). Last update [5211285...cab0d17](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687:2964,learn,learn,2964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687,2,['learn'],['learn']
Usability,"abled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref an",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2389,Learn,LearnReadOrientationModel,2389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"adOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4092,Learn,LearnReadOrientationModel,4092,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"adOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7099,Learn,LearnReadOrientationModel,7099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,add a clear error message if native code fails to build,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1554:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1554,2,['clear'],['clear']
Usability,add a progress bar for local walkers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/974:6,progress bar,progress bar,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974,2,['progress bar'],['progress bar']
Usability,adding a very simple tool to compare two interval list files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702:14,simpl,simple,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702,1,['simpl'],['simple']
Usability,adds arg validation to make sure margin is non-negative in SimpleInte…,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3794:59,Simpl,SimpleInte,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3794,1,['Simpl'],['SimpleInte']
Usability,adinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `76.351% <100%> (ø)` | `30 <2> (ø)` | :arrow_down: |; | [.../tools/funcotator/dataSources/DataSourceUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL0RhdGFTb3VyY2VVdGlscy5qYXZh) | `56.432% <29.73%> (-11.616%)` | `33 <7> (+7)` | |; | [...cotator/dataSources/vcf/VcfFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.333% <58.333%> (-4.219%)` | `23 <2> (+1)` | |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `81.997% <75%> (+1.209%)` | `146 <1> (+4)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.097% <77.778%> (-0.403%)` | `27 <2> (+1)` | |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `84.694% <88.889%> (+0.823%)` | `28 <3> (+2)` | :arrow_up: |; | ... and [20 more](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881:3491,Simpl,SimpleKeyXsvFuncotationFactory,3491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"ake our WDL scripts more extensible. So here goes. <img width=""824"" alt=""screenshot 2018-01-17 13 22 27"" src=""https://user-images.githubusercontent.com/11543866/35060379-501cb8c8-fb8c-11e7-845e-a146fc2ced94.png"">. ## Major wants; - The is_bamout Boolian appears to be hardcoded to `false` in the script. Users need to be able to understand that this option can be changed without ambiguity. So this should become a proper optional variable. @LeeTL1220 tells me this can be overwritten. However, why leave this as misinterpretable to newbie WDL-scriptors? Especially since `wdltools inputs` doesn't include it as a variable at all in the generated inputs list. Please can we make this a proper optional argument that `wdltools inputs` will generate a variable for.; - [ ""${variants_for_contamination}"" == *.vcf ] does not allow *.vcf.gz files. It should accept either.; - Outputs should allow either .vcf or .vcf.gz compression by user-specification. Alternatively, if we want to keep it simple and hardcode, then the preference is for compressed files. Some of us prefer to save on storage.; - Need to be able to specify optional string args for SplitIntervals. I would like to be able to use the BALANCING_WITHOUT_INTERVAL_SUBDIVISION mode. Furthermore, I'd like for the tool to automatically interpret this mode, when not given an -L intervals list, to not split reference contigs. I.e. a contig is an interval. (Perhaps already the tool behavior?); - The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator? . ## Minor wants; - The JSON template in the repo should show the optional variables.; - Script calls for a Picard jar. I don't mind specifying this because I like controlling for the Picard version I use. However, users may want to call the Picard version within the GATK jar. I cannot fathom a simple way to allow switching this out in the script, but perhaps something like the gatk_override option could work. The goal wo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188:1083,simpl,simple,1083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188,1,['simpl'],['simple']
Usability,alVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `88.482% <0%> (-0.324%)` | `15% <0%> (+5%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <0%> (ø)` | `18% <0%> (+9%)` | :arrow_up: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <0%> (ø)` | `5% <0%> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <0%> (ø)` | `19% <0%> (?)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.74% <0%> (+0.101%)` | `3% <0%> (+1%)` | :arrow_up: |; | ... and [13 more](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547:3168,Simpl,SimpleNovelAdjacency,3168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547,1,['Simpl'],['SimpleNovelAdjacency']
Usability,"ally(Utils.scala:1360)** ; **at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)** ; **at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)** ; **at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)** ; **at java.lang.Thread.run(Thread.java:745)**. **Driver stacktrace:** ; **20/03/05 09:28:58 INFO DAGScheduler: Job 0 failed: count at PathSeqPipelineSpark.java:245, took 63.806676 s** ; **20/03/05 09:28:58 INFO SparkUI: Stopped Spark web UI at http://cm132:4040** ; **20/03/05 09:28:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!** ; **20/03/05 09:28:58 INFO NewHadoopRDD: Input split: file:/clinix1/Analysis/mongol/phenomata/04.GC\_CC/01.Alignment/Aligned/17039\_N.bam:1342177280+33554432** ; **20/03/05 09:28:58 INFO MemoryStore: MemoryStore cleared** ; **20/03/05 09:28:58 INFO BlockManager: BlockManager stopped** ; **20/03/05 09:28:58 INFO BlockManagerMaster: BlockManagerMaster stopped** ; **20/03/05 09:28:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!** ; **20/03/05 09:28:58 INFO SparkContext: Successfully stopped SparkContext** ; **09:28:58.889 INFO PathSeqPipelineSpark - Shutting down engine** ; **[2020년 3월 5일 (목) 오전 9시 28분 58초] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.25 minutes.** ; **Runtime.totalMemory()=19560660992** ; **org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 0.0 failed 1 times, most recent failure: Lost task 34.0 in stage 0.0 (TID 34, localhost, executor driver): com.esotericsoftware.kryo.KryoException: Buffer underflow.** ; **at com.esotericsoftware.kryo.io.Input.require(Input.java:199)** ; **at com.esotericsoftware.kryo.io.Input.readLong(Input.java:686)** ; **at org.broadinstitute.hellbender.tools.spark.utils.LongHopscotchSet.<init>(LongHopscotchSet.java:83)** ; **at org.broadinstitute.hellbender.tools.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6493:41802,clear,cleared,41802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6493,1,['clear'],['cleared']
Usability,amF2YQ==) | `95% <ø> (ø)` | `18 <0> (ø)` | :arrow_down: |; | [.../hellbender/tools/spark/sv/utils/SVFastqUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZhc3RxVXRpbHMuamF2YQ==) | `65.152% <ø> (+1.849%)` | `5 <0> (ø)` | :arrow_down: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `94.872% <ø> (-0.065%)` | `6 <0> (ø)` | |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `86.047% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `27.848% <0%> (-4.744%)` | `13 <0> (ø)` | |; | [.../sv/discovery/prototype/InsDelVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0luc0RlbFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...tools/spark/sv/sga/AlignAssembledContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9zZ2EvQWxpZ25Bc3NlbWJsZWRDb250aWdzU3BhcmsuamF2YQ==) | `100% <100%> (+2.222%)` | `12 <0> (ø)` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-323622997:2461,Simpl,SimpleStrandSwitchVariantDetector,2461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-323622997,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"an edge case where ""=="" is to be distinguished from ""<="" or "">="". The reason is that when two quantities are equal, the value to be deduced from their difference is simply zero and an expensive computation could be avoided (the method performing the expensive computation has a check for such optimization opportunity and caught this).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3751:165,simpl,simply,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3751,1,['simpl'],['simply']
Usability,"and to my thinking copying each contig's folder into a new workspace, vs. copying each contig into the same workspace is basically the same overhead. We also tend to keep the long-lived copy on our warm storage, with processing happening on our cluster's lustre filesystem. . 2) Again, i dont think it's necessarily right to assume every job will operate on the same set of intervals. We generally would use the same pattern, but there are legitimate cases in which different intervals/job would better match the cluster's availability. If we're appending a limited number of samples and our cluster is busy, we might want to scatter using more intervals/job since each job would finish fairly quickly and the practical reality is fewer total jobs would complete quicker. if we are performing an operation that requires a lot of time/job (like creating a new workspace or appending a lot of samples), we might do one job/contig. It's also worth pointing out that macaque has 1000s of small unplaced contigs, and therefore we almost never do a simple 1:1 job:contig scheme.; ; 3) When I was originally thinking about how to scatter/gather the creation of a combined gVCF, the overhead of re-merging was huge. There was zero point in taking the per-contig gVCFs and concat/bgzipping a new one, just to split it again. When I started down this road, my idea was to make a folder holding each gVCF, and a top-level JSON file to map contig->filepath, so code could intelligently work with these. The latter essentially describes the structure of a GenomicsDB workspace. Unlike concatenating gVCFS, the overhead of moving directories around is practically zero. Sure, I could make a folder of GenomicsDB workspaces, but if I'm already moving them, what's the point in not merging? . I could understand that is the workspace lived on a shared filesystem and was always going to exist in that location (which I still have trouble squaring with the recommendation to back it up prior to appending), then the s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049:1299,simpl,simple,1299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049,2,['simpl'],['simple']
Usability,andlerContext.java:693); at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:681); at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:716); at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:954); at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:244); at org.apache.spark.network.server.TransportRequestHandler.respond(TransportRequestHandler.java:138); at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:110); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:85); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:101); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51); at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244); at io.netty.channel.AbstractChannelHandlerContex,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:3405,Simpl,SimpleChannelInboundHandler,3405,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"aps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we also discussed, this will come with some additional overhead---we'll need to update documentation, workshop slides, tutorials, WDLs, and make sure that any changes in output formats are clearly highlighted in the release notes. I'll leave this effort to @davidbenjamin and @mwalker174. Thanks again for doing this. Let us know how you'd like to proceed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:1739,simpl,simply,1739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,4,"['clear', 'simpl']","['clearly', 'simply']"
Usability,"are the most appealing, so I'll lean into those:. > Option 1 (i.e. trusting the alignments completely). Yeah, I recognize that this puts us closer in theory to the realms of a positional-based variant caller; however, I'm quite invested in the pre-/post- processing implementations I've got built around Mutect2 (not to mention the benefit of simultaneous processing of the normal and tumor samples, pre-filtering, model-based filtering, etc). If Mutect would employ this naive approach to haplotype calling, I suppose it would end up looking like the ""Platypus"" caller, _which_ again might be suited for our needs, but potentially makes option 3 more appealing. > Option 3 ( i.e. Quick-and-dirty (""FreeBayes-ian"") assembly:. This is interesting and would seem to solve my problems (I believe?) by creating a Haplotype-based, somatic variant caller with the Mutect perks/processing steps/output formats. Again, though, I could see the generation of many candidate haplotypes if things are really messy; however, could you not use a simple ""supporting reads""-based approach for haplotype selection. That would make the likelihood calculations fairly straight-forward. It would undeniably be less-sophisticated than the current De Bruijn Graph/Smith Waterman realignment-based approach but could be better for folks that want more control of the expected behaviors of the tool. > Option 5 (Disable realignment portion of assembly):. I'm going to go out on a limb with this one (feel free to shut this line of thought down quick if I'm really off-base). I've never been able to fully understand the code in the `findBestPaths` method (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L307) and I've had troubles figuring out the details of realignment from the official docs. It could be this part of the assembly process that causes me the most troub",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817:1181,simpl,simple,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817,2,['simpl'],['simple']
Usability,ariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFdhbGtlci5qYXZh) | `91.892% <0%> (+0.983%)` | `20% <0%> (+10%)` | :arrow_up: |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `85.381% <0%> (+1.047%)` | `192% <0%> (+66%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `81.311% <0%> (+1.311%)` | `56% <0%> (+34%)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.555% <0%> (+3.697%)` | `28% <0%> (+11%)` | :arrow_up: |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `91.139% <0%> (+6.826%)` | `31% <0%> (+14%)` | :arrow_up: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/4028/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4028#issuecomment-354876686:3419,Simpl,SimpleKeyXsvFuncotationFactory,3419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4028#issuecomment-354876686,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"arnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 16:21:20.459 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 16:21:21.008 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 16:21:21.044 INFO LearnReadOrientationModel - Shutting down engine; [November 26, 2018 4:21:21 PM UTC] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 0.39 minutes.; Runtime.totalMemory()=780140544; Tool returned:; SUCCESS; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:9578,Learn,LearnReadOrientationModel,9578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,8,['Learn'],['LearnReadOrientationModel']
Usability,"ary 16, 2017 3:23:02 PM UTC] Executing as root@3addd2d7b373 on Linux 3.16.0-0.bpo.4-amd64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: Version:c17c8ed-SNAPSHOT; [February 16, 2017 3:23:04 PM UTC] org.broadinstitute.hellbender.tools.exome.PerformSegmentation done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=185597952; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.applySegmentation(PerformSegmentation.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2048,undo,undoSD,2048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,1,['undo'],['undoSD']
Usability,"as discussed with @droazen, I'm not touching this PR until he's done with his experiment. Reassigning to make it clear that I'm not working on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/890#issuecomment-183170746:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/890#issuecomment-183170746,3,['clear'],['clear']
Usability,"as it is now, we read the data twice in MarkDuplicatesSpark because we filter it using predicate `p` and `!p`. We could cache the RDD but it's not clear if it's faster than just re-reading.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1811:147,clear,clear,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1811,1,['clear'],['clear']
Usability,"asta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:2130,Simpl,SimpleLogger,2130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['Simpl'],['SimpleLogger']
Usability,"at is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given that the DRAGEN-GATK variant calling mode is likely to be important going forwards we should investigate genotyping of spanning events and whether there is a way to keep the improved SNP performance without too drastically impacting indel performance. It is clear that assigning spanning event allele likelihoods to the reference is less ""correct"" but it appears to introduce a significant bias against calling multiple events at complex sites that turns out to save the emission of many false positives. One option might be to explore the possibility of calling spanning events all together based on haplotypes that might contain multiple variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6707:4259,clear,clear,4259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707,1,['clear'],['clear']
Usability,at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276:2545,learn,learnAndClearAccumulatedData,2545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276,1,['learn'],['learnAndClearAccumulatedData']
Usability,at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047:1910,learn,learnAndClearAccumulatedData,1910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047,2,['learn'],['learnAndClearAccumulatedData']
Usability,"ationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.DEFAULT_MIN_ALIGNMENT_LENGTH, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.CHIMERIC_ALIGNMENTS_HIGHMQ_THRESHOLD, true);. Assert.assertEquals(assembledBreakpointsFromAlignmentIntervals.size(), 1);; final ChimericAlignment chimericAlignment = assembledBreakpointsFromAlignmentIntervals.get(0);; Assert.assertEquals(chimericAlignment.sourceContigName, ""asm00001:tig0001"");; final NovelAdjacencyReferenceLocations breakpoints = new NovelAdjacencyReferenceLocations(chimericAlignment, contigSequence, SVDiscoveryTestDataProvider.seqDict);; }; ```. In versions of the code prior to #3752 (I think) this set of alignments was being filtered out by the method `isNotSimpleTranslocation` in the `parseOneContig` method of `ChimericAlignment`. Now that check's logic has changed and `isLikelySimpleTranslocation` returns false instead of true and so this alignment is not being filtered out any more. . When it gets to `NovelAdjacencyReferenceLocations.TanDupBreakpointsInference()` both `upstreamBreakpointRefPos` and `downstreamBreakpointRefPos` are being set to zero. It's not immediately clear to me how to fix this. A few thoughts:. - Are we supposed to be processing this `ChimericAlignment` through the main code path right now? ; - Why do we subtract 1 from the start position of the `rightReferenceInterval.getStart()` when setting `downstreamBreakpointRefPos`? In this case the start is 1 so we end up with an invalid coordinate of 0.; - The `upstreamBreakpointRefPos` is also being set to 0 by this line below.. why?. ```; upstreamBreakpointRefPos = leftReferenceInterval.getEnd() - homologyLen; - (complication.getDupSeqRepeatNumOnCtg() - complication.getDupSeqRepeatNumOnRef()) * complication.getDupSeqRepeatUnitRefSpan().size();; ```. @SHuang-Broad I'm not sure what the best way to fix this is, can you take a look when you have a chance?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:3593,clear,clear,3593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,2,['clear'],['clear']
Usability,ationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `84.615% <100%> (+0.302%)` | `18 <1> (+1)` | :arrow_up: |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `82.479% <100%> (-1.854%)` | `123 <1> (-3)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `79.167% <77.419%> (-0.833%)` | `50 <32> (+28)` | |; | [...ools/funcotator/FuncotatorArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JBcmd1bWVudERlZmluaXRpb25zLmphdmE=) | `83.333% <81.25%> (-10%)` | `1 <0> (ø)` | |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.667% <85.714%> (+3.81%)` | `20 <3> (+3)` | :arrow_up: |; | [...itute/hellbender/tools/funcotator/Funcotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0aW9uLmphdmE=) | `33.333% <0%> (-16.667%)` | `3% <0%> (-1%)` | |; | ... and [41 more](https://codecov.io/gh/broadinstitute/gatk/pull/4020/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4020#issuecomment-354791233:3470,Simpl,SimpleKeyXsvFuncotationFactory,3470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4020#issuecomment-354791233,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"ationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6070,Learn,LearnReadOrientationModel,6070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"atkforums.broadinstitute.org/discussion/4858/reference-bases-with-ambiguity-codes-in-dbsnp/p1) . ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85093784). In general, don't know how HC behaves with ambiguous reference bases at all.... I would not be surprised if it just crashes or outputs garbage. Perhaps this should be part of a larger effort to make sure HC, Combine- and GenotypeGVCFs are robust on ambiguous calls. To start, currently GATK/Picard handles bases as uppercase single `byte' representation of the corresponding character. Since we are investing (a mostly wasting) 8 bits already, we could change into a bit mask representation that would allow for quick comparison of ambiguous and non-ambigous base call using bit-wise operations. NO_CALL = 0, A = 1, C = 2, G = 4, T/U = 8, N = 15, etc... . Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. . We can provide separate tools to re-ambiguate the output or reselect the reference allele as the population major allele, so making the user very aware of this. For example he/she should have an decision-making input as to how we are supposed to handle het calls where both alleles are compatible with the reference ambiguous call; I don't think is totally correct to think of these as *hom*-ref calls but if that is what the user wants... Handling ambiguous calls in the reads... I presume that these have low quality and thus are ignored, and if not we should force them to. . ---. @vdauwera commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85098560). I assume ambiguous basecalls in reads are ignored and therefore not an issue. It's really what to do with ambiguous ref bases that concerns m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:1717,clear,clearest,1717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['clear'],['clearest']
Usability,"avadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSparkIntegrationTest`; * Native HMM library code caused the tests to crash on my Mac:; ```; Running Test: Test method testLikelihoodsFromHaplotypes[0](org.broadinstitute.hellbender.utils.pairhmm.VectorLoglessPairHMM@6282d367, true)(org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest); dyld: lazy symbol binding failed: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; dyld: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:1798,clear,clear,1798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,2,['clear'],['clear']
Usability,"averse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. The user mentioned that this didn't happen on GATK 4.1, so I've been comparing both versions of the code. It turns out that the implementation of ""GenotypingEngine.java"" has changed since then, and after some digging, I noticed that the issue is that the newer versions have uninitialized instances of the class ""OneShotLogger"". The fix is simple, I've added the change myself and built GATK again. The user reports that the issue is gone. Just add the following code inside the constructor method:. ``` ; protected GenotypingEngine(final Config configuration,; final SampleList samples,; final boolean doAlleleSpecificCalcs) {; this.configuration = Utils.nonNull(configuration, ""the configuration cannot be null"");; Utils.validate(!samples.asListOfSamples().isEmpty(), ""the sample list cannot be null or empty"");; this.samples = samples;; this.doAlleleSpecificCalcs = doAlleleSpecificCalcs;; logger = LogManager.getLogger(getClass());; this.oneShotLogger = new OneShotLogger(logger); // <------ ADD THIS LINE; numberOfGenomes = this.samples.numberOfSamples() * configuration.genotypeArgs.samplePloidy;; alleleFrequencyCalculator = AlleleFrequencyCalculator.makeCalculator(configuration.genotypeArgs);; }; ```. #### Steps to reproduce; See description, but I can't provide the exact inputs used for it. #### Expected behavior; The null pointer exception shouldn't",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8158:3480,simpl,simple,3480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8158,1,['simpl'],['simple']
Usability,"awTypes` is moved to `AssemblyContigWithFineTunedAlignments.AlignmentSignatureBasicTypes` and reduced into fewer cases (`Suspicious`, `Simple` and `Complex`). - [x] static method `BreakpointsInference.inferFromSimpleChimera()` now moved to state query method `ChimericAlignment.inferType()`. - [x] `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` merged with `ChimericAlignment.hasIncompletePicture()`. ### update how variants are represented. - [x] change `SVLEN` for `CPX` variants to the difference between _[alt haplotype sequence length]_ and _[affected reference region length]_, which is following the technical definition of `SVLEN` in VCF spec. - [x] change `RPL` output to one of these (note that test coverage is expected); - [x] ins/del, when del/ins bases are < 50 and annotate; when type is determined as ins, the POS will be 1 base before the micro-deleted range and END will be end of the micro-deleted range, where the REF allele will be the corresponding reference bases.; - [x] ins and del when both are >= 50, and link by `EVENT`. - [x] change `SVTYPE=DUP` to`SVYTPE=INS` when the duplicated region is shorter than 50 bp (tests). Note that this will lead to `INS` records with `DUP_REPEAT_UNIT_REF_SPAN` and `DUP_SEQ_CIGARS` (when available). In addition, we are currently treating duplication expansion as insertion. ; The VCF spec doesn't force `DUP` records as such.; If we decide to allow `POS` and `END` to designate the beginning and end of the duplicated reference region, we need to make at least the following change:. - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ### bump test coverage. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence` serialization test. - [x] `NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes()` (but only related to `SimpleSvType`'s, BND's will wait for a later PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663:2034,Simpl,SimpleNovelAdjacencyAndChimericAlignmentEvidence,2034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663,2,['Simpl'],"['SimpleNovelAdjacencyAndChimericAlignmentEvidence', 'SimpleSvType']"
Usability,b8d38b223?src=pr&el=desc) will **decrease** coverage by `0.76%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4192 +/- ##; ==============================================; - Coverage 78.466% 77.707% -0.76% ; - Complexity 16637 17108 +471 ; ==============================================; Files 1058 1082 +24 ; Lines 59758 62508 +2750 ; Branches 9746 10264 +518 ; ==============================================; + Hits 46890 48573 +1683 ; - Misses 9091 9984 +893 ; - Partials 3777 3951 +174; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4192?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.889% <0%> (-0.383%)` | `72% <0%> (ø)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `91.351% <0%> (-0.158%)` | `15% <0%> (+7%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4192#issuecomment-358491943:1276,Simpl,SimpleSVType,1276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192#issuecomment-358491943,1,['Simpl'],['SimpleSVType']
Usability,"b9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <ø> (ø)` | `4 <ø> (ø)` | :x: |; | [...institute/hellbender/tools/picard/sam/SortSam.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvc2FtL1NvcnRTYW0uamF2YQ==) | `94.118% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <ø> (ø)` | `12 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <ø> (ø)` | `35 <ø> (ø)` | :x: |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/2327/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=footer). Last update [10b16a6...d4483e8](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:4836,learn,learn,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,2,['learn'],['learn']
Usability,"bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...tools/examples/ExampleStreamingPythonExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlU3RyZWFtaW5nUHl0aG9uRXhlY3V0b3IuamF2YQ==) | `0% <0%> (-96.67%)` | `0% <0%> (-8%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `4.16% <0%> (-95.84%)` | `2% <0%> (-8%)` | |; | [...der/utils/python/PythonScriptExecutorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3JVbml0VGVzdC5qYXZh) | `3.84% <0%> (-94.24%)` | `1% <0%> (-11%)` | |; | [...number/arguments/HybridADVIArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9IeWJyaWRBRFZJQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `0% <0%> (-94.12%)` | `0% <0%> (-3%)` | |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=footer). Last update [f95b6fe...1c00f72](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563:4607,learn,learn,4607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563,2,['learn'],['learn']
Usability,"bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <0%> (+0.8%)` | `36% <0%> (+1%)` | :arrow_up: |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+6.401%)` | `14% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+7.168%)` | `49% <0%> (+16%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=footer). Last update [58cb99e...2a7f196](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597:2544,learn,learn,2544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597,2,['learn'],['learn']
Usability,"before we have 3 separate classes for dealing with assembly contigs with 2 chimeric alignments, ; now we have 1 with simplified logic.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4215:117,simpl,simplified,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215,1,['simpl'],['simplified']
Usability,bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `94.118% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nterval/SimpleAnnotatedIntervalWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `98.148% <ø> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...notatedinterval/SimpleAnnotatedIntervalWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyLmphdmE=) | `77.778% <ø> (+1.852%)` | `7 <0> (+1)` | :arrow_up: |; | [...number/utils/TagGermlineEventsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `7.759% <0%> (-92.241%)` | `2 <0> (-7)` | |; | [...titute/hellbender/utils/IntervalUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzVW5pdFRlc3QuamF2YQ==) | `91.916% <100%> (+0.204%)` | `144 <2> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/IntervalUt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050:1941,Simpl,SimpleAnnotatedIntervalWriter,1941,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050,1,['Simpl'],['SimpleAnnotatedIntervalWriter']
Usability,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2741,learn,learn,2741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094,2,['learn'],['learn']
Usability,build_docker.sh fails due to folders that have not been cleared up,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5369:56,clear,cleared,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5369,2,['clear'],['cleared']
Usability,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:440,simpl,simple,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782,2,['simpl'],['simple']
Usability,"c.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if it is not already overkill. To go bigger by more than an order of magnitude, we'll have to go out of core, which will require more substantial changes to the code. But since the real culprit responsible for hypersegmentation is CBS, rather than insufficient denoising, I'd rather focus on finding a viable segmentation alternative.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:1368,learn,learn,1368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,3,"['Clear', 'learn']","['Clearly', 'learn']"
Usability,"c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `63.265% <100%> (+1.16%)` | `16 <2> (ø)` | :arrow_down: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <80%> (ø)` | `21 <4> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=footer). Last update [9c1d1fb...f1380fe](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739:2582,learn,learn,2582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739,2,['learn'],['learn']
Usability,"c2.internal:8020/output2.bam.parts/_temporary/0/task_20170505170341_0011_r_000000; 17/05/05 17:03:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1921 bytes result sent to driver; 17/05/05 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 10369 ms on localhost (executor driver) (4/4); 17/05/05 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 17:03:58 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.370 s; 17/05/05 17:03:58 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 16.702399 s; 17/05/05 17:03:58 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:46483; 17/05/05 17:03:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 17:03:59 INFO MemoryStore: MemoryStore cleared; 17/05/05 17:03:59 INFO BlockManager: BlockManager stopped; 17/05/05 17:03:59 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 17:03:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 17:03:59 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 5:03:59 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 17:03:59 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0010; 17/05/05 17:03:59 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt1/yarn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:17838,clear,cleared,17838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,2,['clear'],['cleared']
Usability,"c=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :x: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.903% <33.333%> (ø)` | `32 <0> (ø)` | :x: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=footer). Last update [5d2f859...ed0b8ca](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800:2601,learn,learn,2601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800,2,['learn'],['learn']
Usability,cGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8434553Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8435290Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8440096Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T22:45:53.8465702Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8466224Z [0K; 2022-08-16T22:45:53.8466366Z [0K; 2022-08-16T22:45:53.8466494Z [0K; 2022-08-16T22:45:53.8482815Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8483576Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8485557Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T22:45:53.8486273Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect does not exist; 2022-08-16T22:45:53.8489006Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-16T22:45:53.8489149Z @VisibleForTesting; 2022-08-16T22:45:53.8489418Z symbol: class VisibleForTesting; 2022-08-16T22:45:53.8489587Z location: class CommandLineProgram; 2022-08-16T22:45:53.85,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370:21877,Learn,LearnReadOrientationModel,21877,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217253370,1,['Learn'],['LearnReadOrientationModel']
Usability,ceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:217); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.getOrElseU,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:1668,Simpl,SimpleNovelAdjacencyInterpreter,1668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,2,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"ced them to spanning deletions (of the type considered in #4963). The first case involved the following spanning deletion in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:1103,simpl,simpleMerge,1103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['simpl'],['simpleMerge']
Usability,centralize SV inference from simple chimeric alignments,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4215:29,simpl,simple,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215,2,['simpl'],['simple']
Usability,"ces of crashes that I've traced to spanning deletions (of the type considered in #4963).; One case involved the following in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:1078,simpl,simpleMerge,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['simpl'],['simpleMerge']
Usability,"cessing_script = UNKNOWN. Whether this data source is for the b37 reference.; Required and defaults to false.; isB37DataSource = false. Supported types:; simpleXSV -- Arbitrary separated value table (e.g. CSV), keyed off Gene Name OR Transcript IDlocatableXSV -- Arbitrary separated value table (e.g. CSV), keyed off a genome locationgencode -- Custom datasource class for GENCODEcosmic -- Custom datasource class for COSMIC vcf -- Custom datasource class for Variant Call Format (VCF) files; type = locatableXSV; Required field for GENCODE files.Path to the FASTA file from which to load the sequences for GENCODE transcripts:; gencode_fasta_path =. Required field for GENCODE files.; NCBI build version (either hg19 or hg38):; ncbi_build_version =. Required field for simpleXSV files.; Valid values:; GENE_NAME; TRANSCRIPT_ID; xsv_key = GENE_NAME. Required field for simpleXSV files.; The 0-based index of the column containing the key on which to match; xsv_key_column =. Required field for simpleXSV AND locatableXSV files.; The delimiter by which to split the XSV file into columns.; xsv_delimiter = \t. Required field for simpleXSV files.; Whether to permissively match the number of columns in the header and data rows; Valid values:truefalse; xsv_permissive_cols =. Required field for locatableXSV files.; The 0-based index of the column containing the contig for each row; contig_column = 0. Required field for locatableXSV files.The 0-based index of the column containing the start position for each row; start_column = 1. Required field for locatableXSV files.; The 0-based index of the column containing the end position for each row; end_column = 1; ```. A snapshot of InDels_inclAnno.tsv:; ```; Chrom Pos Ref Alt Type Length AnnoType Consequence ConsScore ConsDetail GC CpG motifECount motifEName; motifEHIPos motifEScoreChng oAA nAA GeneID FeatureID GeneName CCDS Intron Exon cDNApos relcDNApos CDSpos relCDSpo; s protPos relProtPos Domain Dst2Splice Dst2SplType minDistTSS minDistTSE S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:5645,simpl,simpleXSV,5645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['simpl'],['simpleXSV']
Usability,"cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.592% <ø> (+1.025%)` | `78% <ø> (+34%)` | :white_check_mark: |; | [...tute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50RGF0YVNvdXJjZS5qYXZh) | `84.106% <ø> (+2.001%)` | `52% <ø> (+18%)` | :white_check_mark: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `72.105% <ø> (+2.54%)` | `4% <ø> (ø)` | :x: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `65.704% <ø> (+8.146%)` | `88% <ø> (+45%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=footer). Last update [6f9de16...7247260](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683:3705,learn,learn,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683,2,['learn'],['learn']
Usability,"ci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <0%> (-2.632%)` | `32% <0%> (-9%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `77.996% <0%> (-0.179%)` | `175% <0%> (-1%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.444% <0%> (-0.15%)` | `16% <0%> (-1%)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.484% <0%> (-0.116%)` | `49% <0%> (-1%)` | |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=footer). Last update [62d58c5...0492c9c](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420:4184,learn,learn,4184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420,2,['learn'],['learn']
Usability,"ciMap.apply(TraverseLociNano.java:267); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano$TraverseLociMap.apply(TraverseLociNano.java:255); 	at org.broadinstitute.gatk.utils.nanoScheduler.NanoScheduler.executeSingleThreaded(NanoScheduler.java:274); 	at org.broadinstitute.gatk.utils.nanoScheduler.NanoScheduler.execute(NanoScheduler.java:245); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:144); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:92); 	at org.broadinstitute.gatk.engine.traversals.TraverseLociNano.traverse(TraverseLociNano.java:48); 	at org.broadinstitute.gatk.engine.executive.ShardTraverser.call(ShardTraverser.java:98); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.7-0-gcfedb67):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: the number of genotypes is too large for ploidy 20 and allele 16: approx. 3247943160; ##### ERROR ------------------------------------------------------------------------------------------; ```. ---; - Original discussion with user; http://gatkforums.broadinstitute.org/gatk/discussion/comment/36309#Comment_36309; - related dsde-docs issue; https://github.com/broadinstitute/dsde-docs/issues/1744",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2946:12086,guid,guide,12086,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2946,1,['guid'],['guide']
Usability,clear diffuse high frequency kmers,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3604:0,clear,clear,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3604,2,['clear'],['clear']
Usability,clearer documentation on use of --max-mnp-distance,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7251:0,clear,clearer,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7251,2,['clear'],['clearer']
Usability,clearer error when values are missing,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7939:0,clear,clearer,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7939,2,['clear'],['clearer']
Usability,clearing the milestone - our alpha does not depend on this pull req.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716:0,clear,clearing,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716,1,['clear'],['clearing']
Usability,"clearly, it's not working properly. @lbergelson what's the status?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198379664:0,clear,clearly,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198379664,1,['clear'],['clearly']
Usability,"closes #230 . deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding `TableFeature`). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/362:134,simpl,simplified,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/362,1,['simpl'],['simplified']
Usability,"closes #230. deleted useless codecs, left only TableCodec (per @ldgauthier's request), removed GenomeLoc (and reference dependency), simplified parsing code and added tests for the codec (and corresponding TableFeature). @droazen please review",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/363:133,simpl,simplified,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/363,1,['simpl'],['simplified']
Usability,closing after discussing with the engine team that it's simpler to roll up one's own comparator; Thanks @magicDGS for looking!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4706#issuecomment-384762571:56,simpl,simpler,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4706#issuecomment-384762571,2,['simpl'],['simpler']
Usability,closing this. we'll move the code when it's more mature and usable by germline cnvs,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1373#issuecomment-166668206:60,usab,usable,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1373#issuecomment-166668206,1,['usab'],['usable']
Usability,closing. `invalid source release: 1.8` is pretty clear,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019:49,clear,clear,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019,1,['clear'],['clear']
Usability,"cmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <0%> (+13.559%)` | `2% <0%> (+1%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=footer). Last update [5ccfd00...8360cbe](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600:3837,learn,learn,3837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600,2,['learn'],['learn']
Usability,"cness of the site is relevant to the false positive deletion.; >; > One could ask what in the GATK engine is responsible.; >; > - The assembly engine, perhaps? No, it is the assembly engine's job to; > propose possible haplotypes, not to call them. In any case, there *is*; > one spanning read with the deletion above the reads shown, so it is a valid; > path in the graph.; > - Pair-HMM? This one confused me for a while, but no. The engine is; > *not* saying that these reads' best alignment to the reference has a; > deletion, which would be false because there is a gap opening penalty.; > Rather, it says that they align equally well (with no deletions) to the ref; > haplotype and to the deletion haplotype. The deletion shown in IGV is the; > deletion of the alt haplotype relative to the reference, not of the reads; > relative to their best haplotype.; > - The bamout writer? Nope, that code is really straightforward and; > does the right thing.; >; > So what's the issue? Well, the bamout writer gets its read alignments from; > the readLikelihoods after the reads have been realigned to their best; > haplotype. In these cases, it turns out that the alignment of the reads to; > their best haplotype, the deletion has a log likelihood better than the; > alignment to the ref haplotype by about 0.00001. The simplest solution; > would be to give an extremely modest prior in favor of the reference and; > break these near-ties in favor of the reference. @droazen; > <https://github.com/droazen> @ldgauthier <https://github.com/ldgauthier>; > @yfarjoun <https://github.com/yfarjoun> if you think this is a good idea; > I can fix it for both HC and M2. Otherwise I'll do an M2-only fix.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4829>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0lv9nhpu6C8LQCF9jGJoX4UAmfJEks5t32IhgaJpZM4UUW5o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393417801:2180,simpl,simplest,2180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393417801,2,['simpl'],['simplest']
Usability,codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.693% <100%> (+0.44%)` | `114 <1> (+1)` | :arrow_up: |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeVVuaXRUZXN0LmphdmE=) | `94.047% <100%> (+0.009%)` | `68 <1> (+1)` | :arrow_up: |; | [...es/xsv/SimpleKeyXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.438% <100%> (+0.05%)` | `24 <1> (+1)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.149% <100%> (-0.851%)` | `29 <1> (ø)` | |; | [...es/xsv/LocatableXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `96.732% <100%> (+0.043%)` | `15 <1> (+1)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | ... and [23 more](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542:3346,Simpl,SimpleKeyXsvFuncotationFactory,3346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,crease** coverage by `0.093%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4608 +/- ##; ===============================================; + Coverage 79.853% 79.946% +0.093% ; - Complexity 17052 17237 +185 ; ===============================================; Files 1067 1067 ; Lines 62029 62497 +468 ; Branches 10037 10157 +120 ; ===============================================; + Hits 49532 49964 +432 ; - Misses 8585 8597 +12 ; - Partials 3912 3936 +24; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4608?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4608/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `81.34% <100%> (+0.615%)` | `144 <0> (+4)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4608/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `88.722% <0%> (+1.222%)` | `47% <0%> (+21%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4608/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.705% <0%> (+1.401%)` | `186% <0%> (+93%)` | :arrow_up: |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4608/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `91.837% <0%> (+1.837%)` | `22% <0%> (+5%)` | :arrow_up: |; | [...ools/funcotator/FuncotatorArgumentDefinitions.java](htt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4608#issuecomment-377048280:1293,Simpl,SimpleKeyXsvFuncotationFactory,1293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4608#issuecomment-377048280,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,createVCFWriter currently has a workaround for a bug in htsjdk that is now fixed. The call to vcWriterBuilder.unsetOption(Options.INDEX_ON_THE_FLY) should be removed and replaced with a call to clearOptions (which used to break but was fixed in https://github.com/samtools/htsjdk/pull/354).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1143:194,clear,clearOptions,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1143,1,['clear'],['clearOptions']
Usability,"cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.applySegmentation(PerformSegmentation.java:185); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.doWork(PerformSegmentation.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.ins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2537,undo,undoSD,2537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,1,['undo'],['undoSD']
Usability,"csc_hg19.fasta --input NA12878_S1_md.bam --output hc_variants_7.vcf --bam-output realigned_slice_7.bam --max-reads-per-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1335,Simpl,SimpleInterval,1335,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['Simpl'],['SimpleInterval']
Usability,"cussion/comment/44650). I've trimmed the command line down to the minimum necessary to generate the error, and I've trimmed the input files to the minimum section needed to generate the failure (a specific single read). You can find the failure below, but I also dug out the location of the failure with a proposed fix. ./gatk/src/main/java/org/broadinstitute/hellbender/utils/recalibration/covariates/ContextCovariate.java line 191 -->. ```; while (bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. The current while loop allows the array index to become negative and walk right off the edge of the read. So a proposed fix is as follows (assuming it does not break the covariate logic) -->. ```; while (currentNPenalty > 0 && bases[currentNPenalty] != 'N') {; final int baseIndex = BaseUtils.simpleBaseToBaseIndex(bases[currentNPenalty]);; currentKey |= (baseIndex << offset);; offset -= 2;; currentNPenalty--;; }; ```. Minimal Command (test.bam attached - added txt extension just so site would let me attach it) -->. ```; gatk-launch BaseRecalibrator -I test.bam -O test.table -R GATK_Bundle_Build38/Homo_sapiens_assembly38.fasta --knownSites GATK_Bundle_Build38/dbsnp_146.hg38.vcf.gz; ```. Error message --> . ```; java.lang.ArrayIndexOutOfBoundsException: -1; 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.contextWith(ContextCovariate.java:191); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.ContextCovariate.recordValues(ContextCovariate.java:68); 	at org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4005:1272,simpl,simpleBaseToBaseIndex,1272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4005,1,['simpl'],['simpleBaseToBaseIndex']
Usability,"d FRD is complicated for several reasons. Naively one would simply define the BDQ and FRD likelihoods on entire haplotypes rather than alleles at one locus. Unresolved difficulties with this include:. - BQD and FRD are defined with respect to one particular variant position. How would we define them for a haplotype that has no particular locus?; - BQD involves the base qualities at one particular variant locus, how would this be defined for an entire haplotype?; - The above is especially thorny for haplotypes that exhibit multiple variants.; - The FRD prior is only defined for individual events, not haplotypes.; - The BQD and FRD models use reads that overlap a variant site, but it is not clear how to use reads that only partially intersect a haplotype.; - BQD and FRD likelihoods are only defined for homozygous haplotypes, but heterozygous combinations of _haplotypes_ contribute to homozygous genotypes all loci where the distinct haplotypes agree. Clearly, generalizing BQD and FRD to entire haplotypes is not straightforward. Nor does it suffice to produce ""raw"" genotype likelihoods using the joint detection approach and then apply BQD and FRD on variant loci afterwards. Some difficulties with this include:. - BQD and FRD require the read-allele likelihoods matrix. Where are these likelihoods supposed to come from? The pre-joint-detection unrigorous ""marginalization"" where to each allele we assign the maximum likelihood over all haplotypes supporting that allele? Some read-allele likelihoods matrix derived from the read-haplotype likelihoods matrix?; - The drawbacks of the faulty ""marginalization"" actually become more severe with joint detection since genotyping multiple alleles together in a single determined span produces more haplotypes, which in turn increases the risk of the read-allele likelihoods cherry-picking from too many different haplotypes for different reads.; - The BQD and FRD models produce likelihoods on an absolute scale that is only meaningful relat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616:1412,Clear,Clearly,1412,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616,1,['Clear'],['Clearly']
Usability,"d from ApplyVQSR. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933570228.; - [ ] Add behavior for dealing with mixed SNP/INDEL sites in separate passes (and note that the current WDL currently does this, to allow for the use of different annotations across SNPs and INDELs). This might include rescuing previously filtered sites, etc. (e.g., by using the option to ignore the first-pass filter in the second pass). Alternatively, one could use a different FILTER name in each pass, which downstream hard-filtering steps could utilize intelligently. Or one might just split multiallelics upstream. In any case, I would hope that we could move towards running both SNPs and INDELs in a single pass with the same annotations as the default mode of operation.; - [ ] Clean up borrowed code in the `VariantType` class for classifying sites as SNP or INDEL. We mostly retained the VQSR code and logic to make head-to-head comparisons easier. Note also that we converted some switch statements to conditionals, etc. (which I think was done properly, but maybe I missed an edge case). See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934776584.; - [ ] Think more about how to treat empty HDF5 arrays. It's possible we should handle this at the WDL level with optional inputs/outputs. Likely only relevant for atypical edge cases. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934845337. Next steps:. - [ ] I'll update the BGMM branch and open a PR.; - [ ] I'll start looking at implementing a simple CARROT test. We can just replicate the Cromwell/WDL test for now.; - [ ] Update that initial implementation with non-trivial data and evaluation scripts. EDIT: I see that #7982 was just filed.; - [ ] Implement a CARROT test with malaria data. We already have some evaluation scripts.; - [x] Expand the WDL to enable additional workflow modes (positive-negative, etc.) and the tests to cover them. Right now only vanilla positive-only is enabled/covered.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008:2071,simpl,simple,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008,2,['simpl'],['simple']
Usability,"d mapping quality score as well as read strandedness information to penalize reads that are likely to have originated from somewhere else on the genome. A number of additional arguments and behaviors have been exposed in order to preserve lower mapping quality reads in the HaplotypeCaller in service.; - Dynamic Read Disqualification, allows for longer/lower base quality reads to be less likely to be rejected by eliminating the hard cap on quality scores and further adjusting the limit based on the average base quality for bases in the read. . Design decisions that I would direct the reviewers attention to as they correspond to potentially dangerous/controversial changes:; - Because FRD/BQD require low quality ends to be included in the models for genotyping, I have added the option to softclipLowQualityEnds (as opposed to their current treatment which involves hardclipping). This has resulted in a lot of code revolving around handling soft reads and making sure that the correct bases get used in the correct places, which often manifests as simply re-clipping the soft-clipped bases where necessary. This might seem expensive but low quality ends are fairly rare and consequently this has a negligible effect on runtime. ; (NOTE: this might cause unintended consequences for annotations, which have not been extensively tested thus far); - The `DRAGENGenotypeLikelihoodCalculator` object is actually an instantiation of the regular `GenotypeLikelihoodCalculator` object that is called normally for the standard variant model calculation and then has its computed tables/values reused for the subsequent calculations. This means there is a risk if not careful of using the table values for the wrong reads/sties if we are not strict about the state of the cache.; - Currently in order to lower the mapping quality threshold for HaplotypeCaller two separate arguments must be called. This is because the mapping-quality threshold is checked twice, once for the read filter plugin `getTool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6634:2187,simpl,simply,2187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6634,1,['simpl'],['simply']
Usability,"d that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2685,feedback,feedback,2685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639,2,['feedback'],['feedback']
Usability,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2366,feedback,feedback,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040,2,['feedback'],['feedback']
Usability,"d. I agree with Laura's code that the spanning deletion alleles should be added to the events in `HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods`. ---. @ronlevine commented on [Tue Jan 24 2017](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-274868889). @davidbenjamin It looks like the issue is with `ReferenceConfidenceModel.getOverlappingVariantContext(final GenomeLoc curPos, final Collection<VariantContext> maybeOverlapping)`, with the stack trace:; ```; ReferenceConfidenceModel.calculateRefConfidence; ReferenceConfidenceModel.getOverlappingVariantContext; HaplotypeCaller.map; ``` ; For `curPos=9:418272`, there are 2 variants, `9:418269-418273 TTTTG*,<NON_REF>,T` and `9:418272 T*,<NON_REF>,C`. This method returns the variant with the right-most start , so the variant with the deletion is ignored. This logic should be changed so that the variants that overlap `curPos` are merged and returned. A utility similar to `GATKVariantContextUtils.simpleMerge` might work. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-283367380). I thought the state I left that branch was that it would output a merged; representation of the two events starting at the deletion position- so the; reference is some string of bases, allele 1 is the deletion, and allele 2; matches the reference for the length of the deletion with the exception of; the SNP. (Allele 2 is not the minimal representation yet.) That's the first; step to get the genotype right. After that we need to break up the events,; clean up the representation, and assign the genotype from the combined; event to both of them. Hopefully that helps. (And hopefully I actually committed the version of; the branch that does what I said.). On Jan 24, 2017 12:06 PM, ""Ron Levine"" <notifications@github.com> wrote:. > @davidbenjamin <https://github.com/davidbenjamin> It looks like the issue; > is with ReferenceConfidenceModel.getOverlap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2960:5474,simpl,simpleMerge,5474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2960,1,['simpl'],['simpleMerge']
Usability,dGUvaGVsbGJlbmRlci91dGlscy9NUlVDYWNoaW5nU0FNU2VxdWVuY2VEaWN0aW9uYXJ5LmphdmE=) | `78.571% <0%> (-14.286%)` | `14% <0%> (-2%)` | |; | [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `87.5% <0%> (-8.333%)` | `15% <0%> (-4%)` | |; | [...ute/hellbender/utils/read/ArtificialReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0FydGlmaWNpYWxSZWFkVXRpbHMuamF2YQ==) | `93.307% <0%> (-0.787%)` | `68% <0%> (-2%)` | |; | [...lbender/tools/copynumber/CollectAllelicCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzLmphdmE=) | `100% <0%> (ø)` | `9% <0%> (ø)` | :arrow_down: |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `89.423% <0%> (ø)` | `126% <0%> (ø)` | :arrow_down: |; | [.../coverage/readcount/HDF5SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2NvdmVyYWdlL3JlYWRjb3VudC9IREY1U2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | | | |; | [...ols/copynumber/coverage/readcount/SimpleCount.java](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2NvdmVyYWdlL3JlYWRjb3VudC9TaW1wbGVDb3VudC5qYXZh) | | | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/3804?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3804#issuecomment-342621934:3347,Simpl,SimpleCount,3347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3804#issuecomment-342621934,1,['Simpl'],['SimpleCount']
Usability,"dGraph only allows a single annotation/track. I'm not sure if the track definition line is intended to hold any metadata other than display parameters, either? https://genome.ucsc.edu/goldenPath/help/bedgraph.html. As for the unmarked column header line, the reason I decided this would be useful in the CNV TSV formats is that it's very easy to throw the table into a pandas or R dataframe for quick analysis, where you can then use the column names to manipulate the table. Typically, pandas/R TSV loading methods let you specify the `@` comment character to strip the SAM header (although we recently ran into some trouble with this in https://github.com/broadinstitute/gatk/pull/581). Note that we *require* a single unmarked column header, which is easy enough to skip (in the case you don't want to use it) if you know it's there. On the other hand, one could argue that if we store the type of each column in the metadata, then any analysis code should technically use that to parse the table (rather than letting pandas/R automatically infer the type of each column). So a marked column header line would make quick analyses a bit more difficult (as users would need to write parsing code), but could encourage more careful downstream code practices. @SHuang-Broad Just to be clear, the way I originally used ""annotation"" refers to any quantity that could be represented by a single type in a column (not in the sense of variant annotation). If string types are allowed, this is indeed pretty flexible! All I care about extracting is the common functionality related to the fact that we have locatable columns. I think the concerns you raise about e.g. SV representation in VCF are a separate matter, but happy to discuss further. I think once we decide what the header needs to be able to represent and what it should look like, this problem is mostly solved. There may be some things to decide about e.g. representation of doubles, NaNs, etc. but I don't think we need to be too rigid here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329:1427,clear,clear,1427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329,2,['clear'],['clear']
Usability,db4e491d4bd0f03593cbf2e3a4bbc72967?src=pr&el=desc) will **decrease** coverage by `0.005%`.; > The diff coverage is `80.769%`. ```diff; @@ Coverage Diff @@; ## master #4010 +/- ##; ===============================================; - Coverage 78.775% 78.769% -0.005% ; + Complexity 16502 16501 -1 ; ===============================================; Files 1065 1065 ; Lines 58788 58788 ; Branches 9578 9578 ; ===============================================; - Hits 46310 46307 -3 ; - Misses 8752 8754 +2 ; - Partials 3726 3727 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4010?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...lbender/tools/copynumber/CollectAllelicCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/4010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzLmphdmE=) | `92% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [.../formats/collections/SimpleIntervalCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlSW50ZXJ2YWxDb2xsZWN0aW9uLmphdmE=) | `50% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...formats/collections/HDF5SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvSERGNVNpbXBsZUNvdW50Q29sbGVjdGlvbi5qYXZh) | `90% <ø> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...s/collections/AlleleFractionSegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4010/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQWxsZWxlRnJhY3Rpb25TZWdtZW50Q29sbGVjdGlvbi5qYXZh) | `45.455% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...formats/col,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4010#issuecomment-353736925:1239,Simpl,SimpleIntervalCollection,1239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4010#issuecomment-353736925,1,['Simpl'],['SimpleIntervalCollection']
Usability,"ddition to sine waves of various frequency at S/N ratio 1:2 (to roughly simulate GC waves). Changepoints arising from the sine waves will be found first, since these give rise to longer segments:. ![wave-kern-no-local](https://user-images.githubusercontent.com/11076296/29322673-4dd9a1ac-81ac-11e7-94f5-5c5494e44ac5.png). CBS similarly finds many false positive breakpoints:. ![wave-cbs](https://user-images.githubusercontent.com/11076296/29322677-5576e4ba-81ac-11e7-888b-07ed5bff27e3.png). However, when we tune down the sine waves to 1:10, ApproxKernSeg still gets tripped up, but CBS looks better:. ![wave-kern-no-local-small-waves](https://user-images.githubusercontent.com/11076296/29322732-815df58c-81ac-11e7-8305-6e1798616336.png); ![wave-cbs-small-waves](https://user-images.githubusercontent.com/11076296/29322737-836b78fe-81ac-11e7-93be-753a40011203.png). To improve ApproxKernSeg, we can 1) make the cost function intensive, by simply dividing by the number of points in a segment, and 2) add to the cost function a local term, given by the cost of making each point a changepoint within a local window of a determined size. This local term was inspired by methods such as SaRa (http://c2s2.yale.edu/software/sara/). The reasoning is that with events at higher S/N ratio, we typically don't need to perform a global test to see whether any given point is a suitable changepoint; using the data locally surrounding the point typically suffices. With these modifications, ApproxKernSeg can handle both scenarios:; ![wave-kern](https://user-images.githubusercontent.com/11076296/29322762-a679dba6-81ac-11e7-9360-083a4e1da398.png); ![wave-kern-small-waves](https://user-images.githubusercontent.com/11076296/29322801-dad82010-81ac-11e7-8238-e057b0072e1b.png). This local window approach is still linear in time, so runtime is still ~1s for the above (about ~10x faster than CBS). One issue still remains, which is that even this improved approach tends to find directly adjacent possible chang",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045:1593,simpl,simply,1593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045,2,['simpl'],['simply']
Usability,"dec.readHeader(AsciiFeatureCodec.java:79); at htsjdk.tribble.AsciiFeatureCodec.readHeader(AsciiFeatureCodec.java:37); at htsjdk.tribble.TribbleIndexedFeatureReader.readHeader(TribbleIndexedFeatureReader.java:261); ... 18 more; ```. java version:; ```; java -version; openjdk version ""1.8.0_222""; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode); ```; I added the cadd folder into data source folder like the structure mentioned in document:; ```; cadd; |- hg19; | |- cadd.config; | |- InDels_inclAnno.tsv; | |- InDels_inclAnno.tsv.gz.tbi; |; |- hg38; | |- cadd.config; | |- InDels_inclAnno.tsv; | |- InDels_inclAnno.tsv.gz.tbi; ```; The config file (cadd.config); ```; name = CADD; version = v1.4; src_file = InDels_inclAnno.tsv; origin_location =; preprocessing_script = UNKNOWN. Whether this data source is for the b37 reference.; Required and defaults to false.; isB37DataSource = false. Supported types:; simpleXSV -- Arbitrary separated value table (e.g. CSV), keyed off Gene Name OR Transcript IDlocatableXSV -- Arbitrary separated value table (e.g. CSV), keyed off a genome locationgencode -- Custom datasource class for GENCODEcosmic -- Custom datasource class for COSMIC vcf -- Custom datasource class for Variant Call Format (VCF) files; type = locatableXSV; Required field for GENCODE files.Path to the FASTA file from which to load the sequences for GENCODE transcripts:; gencode_fasta_path =. Required field for GENCODE files.; NCBI build version (either hg19 or hg38):; ncbi_build_version =. Required field for simpleXSV files.; Valid values:; GENE_NAME; TRANSCRIPT_ID; xsv_key = GENE_NAME. Required field for simpleXSV files.; The 0-based index of the column containing the key on which to match; xsv_key_column =. Required field for simpleXSV AND locatableXSV files.; The delimiter by which to split the XSV file into columns.; xsv_delimiter = \t. Required field for simpleXSV files.; Whether to permissively",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:4805,simpl,simpleXSV,4805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['simpl'],['simpleXSV']
Usability,decov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...pe/AssemblyContigAlignmentSignatureClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50U2lnbmF0dXJlQ2xhc3NpZmllci5qYXZh) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `44.355% <0%> (+1.719%)` | `24 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../discovery/prototype/ContigAlignmentsModifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0NvbnRpZ0FsaWdubWVudHNNb2RpZmllci5qYXZh) | `70.33% <66.667%> (-0.125%)` | `17 <3> (ø)` | |; | [...er/tools/spark/sv/discovery/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/3752?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQ2hpbWVyaWNBbGlnbm1lbnQuamF2YQ==) | `73.684% <87.5%> (-0.861%)` | `37 <0> (ø)` | |; | [...itute/hellbender/tools/spark/sv/utils/SVUtils.java](ht,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3752#issuecomment-340650295:2309,Simpl,SimpleStrandSwitchVariantDetector,2309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3752#issuecomment-340650295,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,decov.io/gh/broadinstitute/gatk/pull/5707?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvRGF0YUxpbmUuamF2YQ==) | `85.593% <0%> (-0.732%)` | `59 <0> (ø)` | |; | [...lbender/tools/copynumber/CondenseIntervalList.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbmRlbnNlSW50ZXJ2YWxMaXN0LmphdmE=) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...tute/hellbender/utils/tsv/TableReaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXJVbml0VGVzdC5qYXZh) | `86.632% <100%> (ø)` | `43 <1> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <100%> (ø)` | `12 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/tsv/TableUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVVdGlscy5qYXZh) | `95.238% <100%> (+0.644%)` | `8 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXIuamF2YQ==) | `60.938% <25.581%> (-19.271%)` | `41 <8> (+2)` | |; | [...oadinstitute/hellbender/utils/tsv/TableWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5707#issuecomment-466295625:1828,Simpl,SimpleCountCollection,1828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5707#issuecomment-466295625,1,['Simpl'],['SimpleCountCollection']
Usability,"del - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrien",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:5724,Learn,LearnReadOrientationModel,5724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"der.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnRea",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:5180,Learn,LearnReadOrientationModel,5180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"der/utils/MannWhitneyU.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYW5uV2hpdG5leVUuamF2YQ==) | `92.793% <92.593%> (+17.237%)` | `48 <48> (+21)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `72.078% <0%> (-1.948%)` | `35% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `84.104% <0%> (+2.358%)` | `36% <0%> (+11%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `42.989% <0%> (+4.441%)` | `46% <0%> (+18%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=footer). Last update [c350a09...3b4f53e](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579:3124,learn,learn,3124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579,2,['learn'],['learn']
Usability,"detected as B37 in HG19 annotation mode. Performing conversion.; 17:14:13.209 WARN FuncotatorEngine - WARNING: You are using B37 as a reference. Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references.; 17:14:13.411 INFO ProgressMeter - Starting traversal; 17:14:13.412 INFO ProgressMeter - Current Locus Elapsed Minutes Features Processed Features/Minute; 17:14:15.391 INFO FuncotateSegments - Shutting down engine; [September 11, 2022 5:14:15 PM GMT] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.30 minutes.; Runtime.totalMemory()=1752170496; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:917445 end:911649; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2939); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:1271,Simpl,SimpleInterval,1271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['Simpl'],['SimpleInterval']
Usability,dinstitute/gatk/pull/3970?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/utils/svd/OjAlgoSingularValueDecomposer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvT2pBbGdvU2luZ3VsYXJWYWx1ZURlY29tcG9zZXIuamF2YQ==) | `100% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...te/hellbender/utils/mcmc/ParameterTableColumn.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlclRhYmxlQ29sdW1uLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...stitute/hellbender/utils/mcmc/ParameterWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcldyaXRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ellbender/utils/SparkToggleCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TcGFya1RvZ2dsZUNvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `0% <0%> (-92.308%)` | `0% <0%> (-6%)` | |; | [...roadinstitute/hellbender/utils/svd/SVDFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU1ZERmFjdG9yeS5qYXZh) | `0% <0%> (-85.714%)` | `0% <0%> (-3%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-352141723:1838,Simpl,SimpleIntervalTestFactory,1838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-352141723,1,['Simpl'],['SimpleIntervalTestFactory']
Usability,discovery/NovelAdjacencyReferenceLocations.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvTm92ZWxBZGphY2VuY3lSZWZlcmVuY2VMb2NhdGlvbnMuamF2YQ==) | `66.346% <0%> (-18.839%)` | `23% <0%> (+9%)` | |; | [...lkers/annotator/allelespecific/AS\_QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19RdWFsQnlEZXB0aC5qYXZh) | `76.667% <0%> (-9.048%)` | `23% <0%> (+17%)` | |; | [...otator/allelespecific/ReducibleAnnotationData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9SZWR1Y2libGVBbm5vdGF0aW9uRGF0YS5qYXZh) | `94.118% <0%> (-5.882%)` | `16% <0%> (+8%)` | |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `23.037% <0%> (-5.35%)` | `13% <0%> (ø)` | |; | [...annotator/allelespecific/AS\_RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `89.565% <0%> (-5.029%)` | `50% <0%> (+33%)` | |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/3713?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `93.6% <0%> (-4.439%)` | `55% <0%> (+30%)` | |; | ... and [57 more](https://codecov.io/gh/broadinstitute/gatk/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3713#issuecomment-337610377:3172,Simpl,SimpleStrandSwitchVariantDetector,3172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3713#issuecomment-337610377,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"dle`, `SvDiscoverFromLocalAssemblyContigAlignmentsSpark`, `SvType`, `AnnotatedVariantProducer`. ### alignment prep (sub package). `AlignmentInterval`, `AlignedContig` (refactor `AssemblyContigWithFineTunedAlignments` into `AlignedContig`), `AlignedContigGenerator`, `AlignedAssembly`, `ContigAlignmentsModifier` (refactor `AlnModType` into it), `GappedAlignmentSplitter`, `StrandSwitch`, `FilterLongReadAlignmentsSAMSpark` (factor out the major methods in the new alignment filter by score into a 1st level class). ### type & location inference (sub package). * imprecise: refactor out methods from to-be-deprecated `DiscoverVariantsFromContigAlignmentsSAMSpark`. * alignment classification: `ChimericAlignment` and `NovelAdjacencyReferenceLocations` (very tricky to decouple the functionalities because both have over 50 uses), `AssemblyContigAlignmentSignatureClassifier`, `VariantDetectorFromLocalAssemblyContigAlignments`. * simple: `SimpleSVType`, `SvTypeInference`, `InsDelVariantDetector`, `BreakpointComplications` (rename to `BreakpointComplicationsForSimpleTypes`). * complex: `BreakEndVariantType`, `SuspectedTransLocDetector`, `SimpleStrandSwitchVariantDetector`. ### deprecated. `DiscoverVariantsFromContigAlignmentsSAMSpark` . It currently provides 3 groups of functionalities:. * novel adjacency detection (for ins, del, small dup, inversion only) by delegating to `ChimericAlignment.parseOneContig` and `NovelAdjacencyReferenceLocations(ChimericAlignment chimericAlignment, byte[] contigSequence, SAMSequenceDictionary)`; this should be deprecated; * exact variant type inference (delegated to `SvTypeInference.inferFromNovelAdjacency()`) and annotation (delegated to `AnnotatedVariantProducer.produceAnnotatedVcFromInferredTypeAndRefLocations()`); this should be deprecated; * imprecise variants detection; this should be kept and factored out. --------; --------. ## Planed steps. 1. repackaging & refactoring (no logic change, see #3934 ); 2. bring in some valuable changes made in ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111:1678,simpl,simple,1678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111,2,"['Simpl', 'simpl']","['SimpleSVType', 'simple']"
Usability,dlerContext.write(AbstractChannelHandlerContext.java:693); at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:681); at io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:716); at io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:954); at io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:244); at org.apache.spark.network.server.TransportRequestHandler.respond(TransportRequestHandler.java:138); at org.apache.spark.network.server.TransportRequestHandler.processFetchRequest(TransportRequestHandler.java:110); at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:85); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:101); at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51); at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103); at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308); at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294); at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244); at io.netty.ch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1491:3365,Simpl,SimpleChannelInboundHandler,3365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1491,1,['Simpl'],['SimpleChannelInboundHandler']
Usability,"done with my review. small edits, 1 bug, and a few performance questions. I'd like to see a simple perf run of HC with and without those changes. All those streams in math-heavy tight loops make me concerned a bit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231096260:92,simpl,simple,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231096260,1,['simpl'],['simple']
Usability,done. moved getSpanningInterval to IntervalUtils and simplified + added tests for it. Moved IntervalUtilsUnitTest to the right package. No empty string in ctor. back to @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-186019881:53,simpl,simplified,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-186019881,1,['simpl'],['simplified']
Usability,"dsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.909% <0%> (+3.831%)` | `46% <0%> (+11%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=footer). Last update [2ecdef4...71a1b94](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:3143,learn,learn,3143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,2,['learn'],['learn']
Usability,"due to recursive implementation of Legendre abscissas in Apache Commons. @vdauwera @takutosato this is very simple; it just caps the number of subdivisions of the integral to avoid the recursive stack overflow. I tested it on absurdly high coverage (100,000) and reproduced the error with the old code. Whichever one of you gets to this first should review. While this isn't the most beautiful thing in the world, it will work reasonably while new integration code is pending.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3335:108,simpl,simple,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3335,1,['simpl'],['simple']
Usability,duplicate (but probably clearer wording) of #175,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1928#issuecomment-227512681:24,clear,clearer,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1928#issuecomment-227512681,1,['clear'],['clearer']
Usability,"e adopt a new default branch name and retire the use of 'master'.*. The use of 'master' as the default branch is quickly tipping into the realm of being archaic, and present the image of being increasingly tone deaf. 'main' is the commonly accepted replacement on GitHub, but I'm stopping short of suggesting the replacement name, just asking ""please retire master"". . ### 'master has a specific technical meaning' . It does. And is also an example of structural racism, which; > refers to the complex interactions of large scale societal systems, practices, ideologies, and programs that produce and and perpetuate inequities for racial minorities. The key aspect of structural or systematic racism is that these macro-level mechanisms operate independent of the intentions and actions of individuals, so that even if individual racism is not present, the adverse conditions and inequalities for racial minorities will continue to exist - [Gee & Ford, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4306458/). _And if you just felt as if you were accused of being a racist, please re-read the above definition again_ I'm addressing the bureaucracy ( which I can not realistically effect much change with, but some of you can).; ; Ultimately, a fair number of people are to varying degrees uncomfortable or threatened by this trope. And on these merits alone are a good reason to ditch master. [The process is straight forward and documentation abounds](https://www.git-tower.com/learn/git/faq/git-rename-master-to-main), [there are even tools to help automate the conversion](https://github.com/dsyer/main-branch-switch). But it will take time, and is not the most exciting work in the world. . Perhaps it's a sticky change as part of all major releases, or otherwise planned for? So, that's my vote, if I were to be asked to vote that is. And, if there are detailed plans in place to make this change, horray! Link them here, and now you have a(nother?) nice honeypot for this topic. John Major",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7621:2057,learn,learn,2057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7621,1,['learn'],['learn']
Usability,"e being processed by a driver script using Open MPI. ```; $ tail -n 1 000?-scattered.interval_list; ==> 0000-scattered.interval_list <==; chr1 10001 990401 + .; ==> 0001-scattered.interval_list <==; chr1 990402 1970802 + .; ==> 0002-scattered.interval_list <==; chr1 1970803 2951203 + .; ==> 0003-scattered.interval_list <==; chr1 2951204 3931604 + .; ==> 0004-scattered.interval_list <==; chr1 3931605 4912005 + .; ==> 0005-scattered.interval_list <==; chr1 4912006 5892406 + .; ==> 0006-scattered.interval_list <==; chr1 5892407 6872807 + .; ==> 0007-scattered.interval_list <==; chr1 6872808 7853208 + .; ==> 0008-scattered.interval_list <==; chr1 7853209 8833609 + .; ==> 0009-scattered.interval_list <==; chr1 8833610 9814010 + .; ```. The H.P.C. administrator and I don't know what you mean by _thread names_. > I'm not sure what you mean by ""name"" of the threads. From a system perspective, threads don't have names distinct from the process as a whole. I guess it's possible that whatever code you're running attaches an internal name to the thread, but that's purely in the domain of your program – it's not something I can see at a system level.; > ; > To be clear, I'm talking about actual runnable tasks at a system level, i.e. multiple ""lightweight processes"" sharing the same address space – i.e. POSIX threads. How your application (or any runtime framework that you build upon, e.g. Java) is launching and distributing work across these, I don't know – again, that's the domain of your application.; > ; > All I can say is that multiple of these threads were active and causing a significant number of contexts switches between then. Since you're binding your processes to a single core, if multiple threads want to run at the same time the operating system needs to constantly switch between then in order for each to make progress, and this ""context switch"" between the threads is a relatively expensive operation. Any tips how I or him could view the thread names during execution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803684782:1465,clear,clear,1465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803684782,2,['clear'],['clear']
Usability,"e deleted, and its use `support = range(lo, hi)` should become `support = new IndexRange(lo, hi)`. Then `IntStream.of(support).mapToDouble(___).toArray()` becomes `range.mapToDouble(___)` and `apply(promote(support), ___)` becomes `support.mapToDouble(___)`. * `final double relErr = 1 + pow(10, -7)` should become a `static` constant. * The steps; ```java; final double maxD1 = arrayMax(d1);; final double[] d2 = apply(apply(d1, d -> d - maxD1), d -> exp(d));; final double sumD2 = sum(d2);; return apply(d2, d -> d/sumD2);; ```; inside `dnHyper` are just a home-brewed way to normalize the log-space array `d1`. Let's go throught the steps: 1) find the max. 2) subtract the max -- subtracting a constant in log-space is equivalent to dividing by a constant in real space, and since we're normalizing in the end this constant is arbitrary. It's done for numerical stability. 3) exponentiate to get an unnormalized real-space array. 4) find the sum. 5) divide by the sum to get the normalized result. The log-10 version of this is `MathUtils::normalizeFromLog10ToLinearSpace(d1)`. You could either calculate `d1` in log-10 space or convert it, replacing the above line with `return MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.applyToArrayInPlace(d1, MathUtils::logToLog10))`. The latter option is simpler. * Import static should be avoided except to escape horrible clutter, which is not the case here. * The second argument of `Utils.validateArg(condition, calculated string expression)` should become `Utils.validateArg(condition, () -> calculated string expression)`. In the first version, the expression is calculated *even if* the condition is satisfied, whereas in the second it is only calculated as needed. It's not critical here but it's a good habit to get into. PS I am a zealot of the Boy Scout Rule (always leave the camp site cleaner than you found it). It is a great way to get familiar with a large code base and a great way to make the code more readable for the next person.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155:1925,simpl,simpler,1925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155,2,['simpl'],['simpler']
Usability,"e due to many outstanding questions. . We currently have no idea how joint detection is supposed to interaction with BQD and FRD. I have tried a few guesses and none have worked (see below for functional equivalence results of the particular guess used in this PR). The interplay of joint detection with BQD and FRD is complicated for several reasons. Naively one would simply define the BDQ and FRD likelihoods on entire haplotypes rather than alleles at one locus. Unresolved difficulties with this include:. - BQD and FRD are defined with respect to one particular variant position. How would we define them for a haplotype that has no particular locus?; - BQD involves the base qualities at one particular variant locus, how would this be defined for an entire haplotype?; - The above is especially thorny for haplotypes that exhibit multiple variants.; - The FRD prior is only defined for individual events, not haplotypes.; - The BQD and FRD models use reads that overlap a variant site, but it is not clear how to use reads that only partially intersect a haplotype.; - BQD and FRD likelihoods are only defined for homozygous haplotypes, but heterozygous combinations of _haplotypes_ contribute to homozygous genotypes all loci where the distinct haplotypes agree. Clearly, generalizing BQD and FRD to entire haplotypes is not straightforward. Nor does it suffice to produce ""raw"" genotype likelihoods using the joint detection approach and then apply BQD and FRD on variant loci afterwards. Some difficulties with this include:. - BQD and FRD require the read-allele likelihoods matrix. Where are these likelihoods supposed to come from? The pre-joint-detection unrigorous ""marginalization"" where to each allele we assign the maximum likelihood over all haplotypes supporting that allele? Some read-allele likelihoods matrix derived from the read-haplotype likelihoods matrix?; - The drawbacks of the faulty ""marginalization"" actually become more severe with joint detection since genotyping m",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616:1148,clear,clear,1148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616,1,['clear'],['clear']
Usability,"e from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/unnecessary releases, but low enough to not be a blocker if we really do need to release a hot fix. ---. @LeeTL1220 commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215793338). Cherry-picking sounds awful to me, but not as awful as the others... I could do number three. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215801993). To clarify my position though - I think we should just never need it and simply coordinate between the various tool teams on a common release schedule. The toolkit would then be released because all tool are ready. ---. @droazen commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215816252). @akiezun We should strive for this, but in practice there will be times when Lee needs a release and we're not ready for one, and we need to have a plan in place to deal with that scenario. Since options 3 and 4 seem to be the only options with votes, let's sit down next week and discuss in detail the pain points of these two options, and make a choice between them.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:5971,simpl,simply,5971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['simpl'],['simply']
Usability,"e is going to be a behavior different between the old iteration pattern. The existing code will iterate variants to establish whitelist of start sites, and then re-query variants overlapping those starts. This is generally identical in practice to MultiVariantWalkerGroupedOnStart; however, when -L is supplied, it can give differences. I'm not sure which I think is correct. . Example, from VariantEvalIntegrationTest.testFunctionClassWithSnpeff():. // The DbSNP VCF has two variants:; // 1 1423281 rs374004343 GGAAGC G . .; // 1 1423281 rs79849353 G A . .; // If we use 1423281 as the interval, we find both. // The SnpEff VCF has these two:; // 1 1423282 . GAAGC G; // 1 1423286 . C G. The SnpEff VCF is provided as -L when running the tool. Both SnpEff and DbSnp will be used as drivingVariants. Therefore when we hit interval 1423282, the DbSnp variant 1423281:GGAAGC>G variant will be included, but not 1423281:G>A. When using MultiVariantWalkerGroupedOnStart, this means only that variant is passed downstream. Previously, VariantEval would simply establish the whitelist of start sites (meaning the lowest from the group, or 1423281) and iterate them. This means that even though 1423282 is the interval from -L, it picks up the overlapping 1423281:GGAAGC>G, which effectively makes 1423281 a whitelisted start site. The existing behavior would iterate each start site and re-query overlapping variants in VariantEvalUtils.bindVariantContexts(). It would call:. List<VariantContext> prior = featureContext.getValues(track, referenceContext.getInterval().getStart());. In this instance, it would query on start=1423281, meaning it picked up both DbSnp sites, even though 1423281:G>A is not within the intervals supplied by -L. This is sort of a fringe case. I dont see how to fix this without reintroducing the expensive re-query step. I'm currently thinking that the existing behavior is probably what's wrong, but I'm going to consider this a little more. My last commit highlights this case",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-730697357:1052,simpl,simply,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-730697357,2,['simpl'],['simply']
Usability,"e some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866) ; ;     at org.broadinstitute.hellbender.tool",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2468,Simpl,SimpleInterval,2468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['Simpl'],['SimpleInterval']
Usability,"e two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239) ;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2572,Simpl,SimpleInterval,2572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['Simpl'],['SimpleInterval']
Usability,ease** coverage by `0.073%`.; > The diff coverage is `72.043%`. ```diff; @@ Coverage Diff @@; ## master #3987 +/- ##; ===============================================; + Coverage 78.571% 78.645% +0.073% ; - Complexity 16245 16320 +75 ; ===============================================; Files 1055 1057 +2 ; Lines 57960 58379 +419 ; Branches 9487 9607 +120 ; ===============================================; + Hits 45540 45912 +372 ; - Misses 8744 8774 +30 ; - Partials 3676 3693 +17; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3987?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3987/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `84.314% <100%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3987/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `82.857% <100%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3987/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `58.974% <57.143%> (ø)` | `14 <5> (?)` | |; | [...r/dataSources/cosmic/CosmicFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3987/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2Nvc21pYy9Db3NtaWNGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `72.619% <72.619%> (ø)` | `16 <16> (?)` | |; | [...ender/utils/svd/OjAlgoSingularValue,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3987#issuecomment-352487947:1295,Simpl,SimpleKeyXsvFuncotationFactory,1295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3987#issuecomment-352487947,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"ec2.internal:8020/output.bam.parts/_temporary/0/task_20170505060336_0011_r_000002; 17/05/05 06:03:53 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 1921 bytes result sent to driver; 17/05/05 06:03:53 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 10792 ms on localhost (executor driver) (4/4); 17/05/05 06:03:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 06:03:53 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.796 s; 17/05/05 06:03:53 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 17.010114 s; 17/05/05 06:03:53 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:35794; 17/05/05 06:03:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 06:03:53 INFO MemoryStore: MemoryStore cleared; 17/05/05 06:03:53 INFO BlockManager: BlockManager stopped; 17/05/05 06:03:53 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 06:03:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 06:03:53 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 6:03:53 AM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 06:03:53 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 06:03:53 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0002; 17/05/05 06:03:53 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 06:03:53 INFO ShutdownHookManager: Deleting directory /mnt1/yarn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666:3820,clear,cleared,3820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666,1,['clear'],['cleared']
Usability,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36067,clear,cleared,36067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['clear'],['cleared']
Usability,ed array size exceeds VM limit; at java.util.Properties$LineReader.readLine(Properties.java:485); at java.util.Properties.load0(Properties.java:353); at java.util.Properties.load(Properties.java:317); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:50); at org.aeonbits.owner.loaders.PropertiesLoader.load(PropertiesLoader.java:43); at org.aeonbits.owner.LoadersManager.load(LoadersManager.java:46); at org.aeonbits.owner.Config$LoadType$2.load(Config.java:129); at org.aeonbits.owner.PropertiesManager.doLoad(PropertiesManager.java:290); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:163); at org.aeonbits.owner.PropertiesManager.load(PropertiesManager.java:153); at org.aeonbits.owner.PropertiesInvocationHandler.<init>(PropertiesInvocationHandler.java:54); at org.aeonbits.owner.DefaultFactory.create(DefaultFactory.java:46); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:87); at org.aeonbits.owner.ConfigCache.getOrCreate(ConfigCache.java:40); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreate(ConfigFactory.java:268); at org.broadinstitute.hellbender.utils.config.ConfigFactory.getOrCreateConfigFromFile(ConfigFactory.java:454); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:439); at org.broadinstitute.hellbender.utils.config.ConfigFactory.initializeConfigurationsFromCommandLineArgs(ConfigFactory.java:414); at org.broadinstitute.hellbender.Main.parseArgsForConfigSetup(Main.java:121); at org.broadinstitute.hellbender.Main.setupConfigAndExtractProgram(Main.java:179); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:204); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. ### Affected version(s); - [x] Latest public release version [version?]; Yes. 4.1.2.0. - [ ] Latest master branch as of [date of test?]; Not tested. #### Steps to reproduce; Yet not clear.; maybe the call stack above will help. ----,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6050:2282,clear,clear,2282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6050,1,['clear'],['clear']
Usability,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4577,simpl,simplifyBAM,4577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,2,['simpl'],['simplifyBAM']
Usability,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1469,simpl,simplifyBAM,1469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,2,['simpl'],['simplifyBAM']
Usability,"ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mZXJtaS9GZXJtaUxpdGVBc3NlbWJsZXIuamF2YQ==) | `80.645% <80.645%> (ø)` | `8 <8> (?)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.308% <ø> (+0.447%)` | `28% <ø> (+28%)` | :white_check_mark: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `87.097% <ø> (+0.986%)` | `59% <ø> (+59%)` | :white_check_mark: |; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `38.462% <ø> (+5.52%)` | `12% <ø> (+12%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=footer). Last update [8a42977...d6fb1ba](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321:3296,learn,learn,3296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321,2,['learn'],['learn']
Usability,"eed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than trying to figure out where the old one is failing would be best.; - [x] For small bins (250bp), the copy-ratio model is currently a bit memory intensive, since it stores an outlier indicator boolean for every data point (it gets by with -Xmx12g for 100 iterations at 250bp). There is no easy away around storing this at the GibbsSampler level (although we could make some non-trivial changes to that code, as @davidbenjamin suggested long ago at https://github.com/broadinstitute/gatk-protected/issues/195). However, I got rid of these at the CopyRatioModeller level. If we want to go down in memory, we cou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:6594,simpl,simply,6594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['simpl'],['simply']
Usability,"een examples outside of what is shown in the docs. Actually, to be honest, most of the examples out in the wild stick to only the most basic of options, so for more advanced uses it really is pretty unclear what such arguments should be. . This is not a generic please write better documentation (though that's always appreciated). This is particularly about 1) The tool usage format documentation 2) the particular mis-specification for interval formats (maybe some interpretive element of the page drops the ':' and '-', but viewing the source doesn't show any sign of them). For resolving one, I think moving a bit closer to the specifications in Linux man pages would help, but those are far from perfect themselves. . Here, even way back in 2013, Geraldine gives the correct version of the format. ; https://gatkforums.broadinstitute.org/gatk/discussion/3395/interval-file-errors. > Hi Kristine,; > ; > Make sure your intervals list is named with either extension .bed or .list as appropriate; it cannot end in .txt. The program gets confused, thinks header lines are intervals and doesn't parse the file correctly. For the record, the simplest format for intervals (which I prefer, personally) is the \<chr\>:\<start\>-\<stop\> format, which doesn't require a sequence dictionary.; > ; > The intervals list specifies which regions of the genome the analysis will be run on. I can't comment on how it's used in MuTect, but in GATK it's typically used to restrict analysis to exome capture targets, or to particular regions of interest. And confirms shortly after in the same thread that this is referring to the GATK formats described (.list and .intervals): . > Oh, if you have the intervals in that format the extension needs to be .interval_list or .list, not bed. You'll need to change the starting zeroes to ones. Sorry, the formatting requirements are a bit obscure, I realize. Where ""that format"" is the \<chr\>:\<start\>-\<stop\> format. Also, I believe .interval_list is now .intervals.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639:5308,simpl,simplest,5308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639,1,['simpl'],['simplest']
Usability,"egion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and completely arbitrary depth of 1000, ignoring dcov. -The HaplotypeCaller does realignment of reads to the haplotypes, potentially causes the depth of coverage to vary at the locus in question. -The GenotypingEngine then computes DP based on the reads that still overlap the locus post-realignment. The end result is that DP for the HaplotypeCaller represents the undownsampled depth of coverage at the locus in question, subject to the hardcoded cap of 1000 and realignment to the haplotypes. In this particular case, the actual depth at locus 1:14464 is 561 (with no downsampling), and the DP value is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that for ActiveRegion walkers it reflects the undownsampled depth subject to things like realignment to the haplotypes (easiest option, but doesn't fix the underlying craziness); 2. Change the ActiveRegion traversal so that it respects the dcov value (could be hard -- the LIBS downsampling process discards reads on-the-fly from previous loci when moving to a new locus, but an active region involves data for multiple loci. The potential performance win for the HC is huge, though, if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the Activ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:3463,undo,undownsampled,3463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"egion, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(hcArgs.maxMnpDistance);. // same things as Mutect2 — we trim on the unmodified region; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(region, allVariationEvents, referenceContext);. // same as Mutect2; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. In addition to the proposed simple fix, this brings up a few code smells:. * One would expect assembly not to modify its input reads, but it does through the side effect of `finalizeRegion`.; * Assembly has both the permanent changes of finalize region and the temporary changes of read error correction.; * `AssemblyResultSet` stores the reads but so does `AssemblyRegion`. Without doing any serious refactoring, perhaps `finalizeRegion` could at least be split off from assembly so that the latter does not stealthily modify reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6686:2460,simpl,simple,2460,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686,1,['simpl'],['simple']
Usability,"egions within the reference,; > and therefore will have fine mapping quality even though they are artifacts.; >; > There are published ""decoy genomes"" -- essentially pseudo-contigs of; > regions missing from the reference, and mapping with BWA in memory to; > *those* might be very helpful.; >; > So, we need to: 1) get our hands on a decoy genome that will play nicely; > with BWA, and 2) talk to the SV team.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-296515266>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCJQob4WqdwDN0R8jvbNGT1l0vSCks5rzBOmgaJpZM4Lb8pz>; > .; >. ---. @davidbenjamin commented on [Wed May 03 2017](https://github.com/broadinstitute/gatk-protected/issues/844#issuecomment-298946022). Copying comments from closed issue #993. Instead of running an aligner in memory, let's first try preprocessing an alignability (to the ref + decoy) resource file. Then we can simply query this file at each called variant. > ENCODE used a kmer size of 36 bp, which is seriously obsolete and will tend to underestimate alignability. However, the GEM program (paper here: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0030377 and binary here: http://algorithms.cnag.cat/wiki/The_GEM_library#Documentation and blog post on how to run it here: http://blog.kokocinski.net/index.php/sequence-mappability-alignability?blog=2) was used by ENCODE to produce this track and we can easily produce it ourselves with any kmer size and any mismatch threshold. > Furthermore, once we make this track we can store this track in memory eg as a `HashedListTargetCollection` and therefore we can query it for every read to get an annotation for the number of uniquely mappable reads (up to some error tolerance). > One more thing: we can also query based on the start position of each read's mate.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2930:4815,simpl,simply,4815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2930,1,['simpl'],['simply']
Usability,"el - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM conve",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3277,Learn,LearnReadOrientationModel,3277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"el - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM conve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6284,Learn,LearnReadOrientationModel,6284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"el=desc) will **decrease** coverage by `-<.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2366 +/- ##; ===============================================; - Coverage 76.201% 76.201% -<.001% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39421 +4 ; Branches 6858 6859 +1 ; ===============================================; + Hits 30036 30039 +3 ; Misses 6775 6775 ; - Partials 2606 2607 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.568% <75%> (-0.488%)` | `74 <2> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=footer). Last update [f45f6a5...75c14f4](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211:1778,learn,learn,1778,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211,2,['learn'],['learn']
Usability,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3454,learn,learn,3454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576,2,['learn'],['learn']
Usability,"elpful to have some very clear guidelines about how number of samples and the number of intervals within each scatter affect both runtime and memory usage. Here's what I've been able to infer from the WDL pipelines, tool docs and experimentation (though I suspect some of it is wrong):. 1. Memory usage is approximately proportional to number of samples, number of intervals, number of bias covariates and max copy number. What the docs don't say is what the default is for the number of bias covariates _and_ how to take these numbers and project an approximate memory usage. 2. It would appear that GermlineCNVCaller will, by default, attempt to use all CPU cores available on the machine. From the WDL I see that setting environment variables `MKL_NUM_THREADS` and `OMP_NUM_THREADS` seems to control the parallelism? It would be nice if `GermlineCNVCaller` took a `--threads` and then set these before spawning the python process. 3. Runtime? This would be really nice to have some guidelines around as I get wildly varying results depending on how I'm running. My experimentation is with a) 20 45X WGS samples, b) bin size = 500bp, c) running on a 96-core general purpose machine at AWS with 384GB of memory. My first attempt a) scattered the genome into 48 shards of approximately 115k bins each, representing ~50mb of genome and b) ran 24 jobs concurrently but failed to set the environment variables to control parallelism. In that attempt the first wave of jobs were still running after 24 hours and getting close to finishing up the initial de-noising epoch, with 3/24 having failed due to memory allocation failures. My second attempt, now running, scattered the genome into 150 shards, and is running 12 jobs at a time with 8 cores each and the environment variables set. On the second attempt it looks like the jobs will finish the first denoising epoch in < 1 hour each. That's far faster than the 6x reduction in runtime you might expect if a) runtime is linear in the number of bins an",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166:1350,guid,guidelines,1350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166,1,['guid'],['guidelines']
Usability,"em to be in position:. 45SrDNA_Jacobsen 9283. That seems to be very polymorphic or noisy even within individual samples, to the point that many lack PLs so perhaps merging would not work or at least the exact model depending annotations (QUAL column and MLEAC/F format field) cannot be updated based on them... I think that best way to move forward here is:; 1. Lift up that maximum number of Genotypes to output PLs based on the ploidy parameter (I think the limit was quite modest perhaps as low as 20).; 2. Implement the alt. allele `culling` or `collapsing` that I mention above in HaplotypeCaller already. ; 3. Implement the alt. allele `re-culling` or `re-collapsing` in GVCF (VCF as well?) merging tools such as CombineGVCFs/GenotypeGVCFs.; 4. Regenotyping and QUAL recalculating tools would need to make sure that PLs less input are handled appropriately, not sure what would happen now if some of the inputs lack PLs... (an Exception?) ; - For example QUAL could be approximated as the max of the input Quals, and QD as the average? ; - Or simple lift them blank?. So it would a bit of work I would say... 3 of the old PTs worth. ---. @vdauwera commented on [Thu May 14 2015](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-102235192). Recording test case while sanitizing: . The files are located here: . ```; gsa1:/humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles; ```. The command I ran:. ```; java -jar /humgen/gsa-hpprojects/GATK/private_unstable_builds/GenomeAnalysisTK_latest_unstable.jar \; -T GenotypeGVCFs \; -R /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/45S_Jacobsen_rearranged.fa \; -V /humgen/gsa-scr1/schandra/GenotypeGVCFs_LargePloidyAndLargeAlleles/Input_ploidy.list \; -o Sheila.GenotypeGVCFs.vcf; ```. Which produces:. ```; ##### ERROR MESSAGE: the combination of ploidy (19) and number of alleles (21) results in a very large number of genotypes (> 2147483647). You need to limit ploidy or the number of alter",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:3168,simpl,simple,3168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['simpl'],['simple']
Usability,"encing data. Given that a major source of coverage variance in targetted sequencing stems from the variance in bait efficiencies, the most reasonable read-depth calculation scheme is to associate **inserts to baits** rather than **single reads to targets**. No more arbitrary interval padding (which was a hacky way to get away not thinking about inserts). There is a subtle problem, though: inserts often overlap with more than one bait. In such cases, we need to have a model for estimating the probability that the insert is captured by either of the overlapping baits. The modeling can be done in the following semi-empirical fashion (thanks @yfarjoun), which needs to be done only once for each capture technology (Agilent, ICE):; - We locate isolated baits (i.e. those that are separated from one another by a few standard deviations of the average insert size); - We take a number of BAMs and calculate the empirical distribution of inserts around the isolated baits; - We fit a simple parametric distribution to the obtained empirical distributions, parameterized by bait length and insert length; we probably don't need to go all-in here, though the reference context of the bait is also likely to be an important covariate. Once these distributions are known, we can easily calculate the membership share of each bait in ambiguous cases and give each bait the appropriate share. Bonus:; -------. The empirical distribution of inserts around baits also allows us to associate a more reasonable GC content to each bait. Since GC bias is a property of the fragments that are pulled by the baits, a reasonable measure of ""GC content"" of each bait has to be calculated from the expected value of the GC content of the fragments that the bait pulls (not the GC content of the baits or targets), and this can be easily calculated from the previously obtained empirical distributions. ---. @mbabadi commented on [Fri Feb 17 2017](https://github.com/broadinstitute/gatk-protected/issues/914#issuecomm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2947:1375,simpl,simple,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2947,1,['simpl'],['simple']
Usability,"end that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnRea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2173,Learn,LearnReadOrientationModel,2173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"entation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6798:3071,guid,guide,3071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798,1,['guid'],['guide']
Usability,"entationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:5622,Learn,LearnReadOrientationModel,5622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,entering as an issue here for simplicity,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/54:30,simpl,simplicity,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/54,1,['simpl'],['simplicity']
Usability,"eport; > Merging [#2550](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2550 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10892 +1 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=footer). Last update [c8ede6e...f810842](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016:1666,learn,learn,1666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016,2,['learn'],['learn']
Usability,"er approach to select best haplotypes that can handle complex graph we might well not need to prune low supported hap early as they seemly they won't be selected if the are not amongst the best haplotypes. . B.1 Now that still would produce a considerable number of unlikely haplotypes that would cause a CPU burden. That can be changed by imposing another kinds of limit, For example we include all haplotypes with scores (likelihoods) that are Q0 - Q40 or we include haplotypes until the sum of their likelihoods is larger than the 99.99% probability mass. . B.2 This could provide a downstream solution to the problem caused by ranging heads recovery (explained above in A.2). B.3 If pruning is to be maintained, it makes more sense to do it at the very end after all dangling ends hav been recovered and the edges supports are finalized. Of course I assuming here that dangling end recovery does the sensible think of updating those supports are the graphs is modified. C. The use of Smith-Waterman in dangling end recovery does not seem totally optimal or even needed. . C.1 Recovering tails quite often this finish with the same sequence as the reference path because in fact they are supposed to end like that by construction (reads are trimmed by AR coordinates). For example, this can be cause because due to the k-mer size there is not enough based after variation for the paths to merge back. In this case you can simply merge the last vertices of the tail and the reference, faster and potentially more accurate. . C.2 Similarly dangling heads, at least part of the sequence of those dangling heads are clearly threadable back into the graph without the need of SW. For example look at the AA…AAAAAGA sequence in the picture below. . C.3 PairHMM runs in effect are performing SW kind of computations and so it is totally possible to use its partial result to find good alignment of dangling ends back to other parts of the graph without the need of running a separate SW thus saving time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/264:2441,simpl,simply,2441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/264,2,"['clear', 'simpl']","['clearly', 'simply']"
Usability,"er-alignment-start 1000 --min-base-quality-score 0 --minimum-mapping-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1454,Simpl,SimpleInterval,1454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['Simpl'],['SimpleInterval']
Usability,"er-images.githubusercontent.com/45641912/139333959-4465b06d-b2ce-4ab2-bae9-285e25168c1d.png); ![image](https://user-images.githubusercontent.com/45641912/139333973-c8e2c1f6-0efd-4f45-9d1e-10f6c4a2baac.png). To allocate more memory for the Funcotate task, one has to define this **small_task_mem** variable at the workflow level. This effectively changes the amount of memory for all tasks that make use of this dictionary, rather than just the Funcotate task. Funcotate has two input variables **default_ram_mb** and **default_disk_space_gb** which have no bearing on the memory and disk space configuration for the task.; ![image](https://user-images.githubusercontent.com/45641912/139334343-8e614e17-27ef-4fef-815d-fe6e8c39ffef.png). This leads to user confusion when they see these variables in the method configuration page, put values in, and don't see their Funcotate task use the specified values.; ![image](https://user-images.githubusercontent.com/45641912/139334535-4b9a0353-910e-4764-a6d2-a454f4d344aa.png). #### Steps to reproduce; Define the input variables **default_ram_mb** and **default_disk_space_gb** for a run of the Mutect2 workflow to be different from the amounts defined by [*small_task_mem*](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L140) and [**disk_space**](https://github.com/broadinstitute/gatk/blob/4.1.8.1/scripts/mutect2_wdl/mutect2.wdl#L407). #### Expected behavior; Defining the input variables **default_ram_mb** and **default_disk_space_gb** allows you to specify your preferred memory and disk space configuration for the Funcotate task. #### Actual behavior; These variables do not define the runtime configuration for the task. Memory is defined by a workflow-level input that isn't clearly connected to Funcotate. #### Suggestion; Utilize the variables **default_ram_mb** and **default_disk_space_gb** that already exist in the task in such a way that modifying them has an impact on the configuration of the task VM.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7532:2686,clear,clearly,2686,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7532,1,['clear'],['clearly']
Usability,"er.utils.MathUtils.log10BinomialProbability(MathUtils.java:646); > 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:639); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); > 	at org.broadinstitute.hellbender.Main.main(Main.java:289). For those files experiencing the error, it disappears when disabling the mitochondria mode for `FilterMutectCalls`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:1469,learn,learnParameters,1469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['learn'],['learnParameters']
Usability,"erage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2521 +/- ##; ===============================================; + Coverage 76.256% 76.261% +0.005% ; Complexity 10864 10864 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; + Hits 30154 30156 +2 ; + Misses 6771 6769 -2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=footer). Last update [7ad3c91...2622598](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656:1842,learn,learn,1842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656,2,['learn'],['learn']
Usability,"erator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 23, 2018 11:06:24 PM EST] org.broadinstitute.hellbender.tools.spark.sv.Structura",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3573,Simpl,SimpleInterval,3573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,erator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7252,Simpl,SimpleInterval,7252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,"erator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.fa.img \; --kmers-t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:14044,Simpl,SimpleInterval,14044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,"erent results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and PCA-only perform comparably, even at small bin sizes (~300bp). From what I've seen, this is true for larger bin sizes (~3kbp), so explicit GC-bias correction may not be necessary. (That is, even at these (purportedly) large bin sizes, the effect of the read-based GC-bias correction is obvious for those samples where it is important. However, the end result is not very different from PCA-only denoising with no GC-bias correction performed.); - [x] <s>Check that changing CBS alpha parameter sufficiently reduces hypersegmentation.</s> <s>Looks like the hybrid p-value calculation in DNACopy is not accurate enough to handle WGS-size data. (Also, it's relatively slow, taking ~30 minutes on ~10M intervals.) Even if I set alpha to 0, I still get a ridiculous number of segments! So I think it's finally time to scrap CBS. I'll look into other R segmentation packages that might give us a quick drop-in solution, but we may want to roll our own simple algorithm (which we will scrap anyway once the coverage model is in for somatic).</s> I've implemented a fast kernel-segmentation method that seems very promising, see below.; - [ ] Investigate performance vs. CGA ReCapSeg pipeline on THCA samples.; - [ ] Investigate concordance with Genome STRiP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:5610,simpl,simple,5610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,2,['simpl'],['simple']
Usability,"erialization step. This optimization is called ""fusing"" and it's generally a very good thing. However in this case, the input PCollection has a single element (the file we want to read), so only one worker is involved. Because of the fusion, that same worker then ends up doing all of the reading work, ruining our day. **The Solutions**. There are multiple ways to solve this problem. ; 1. change transform 1 to have the contig collection as a primary input in the hope that we always have more than one contig. ; This solution's very brittle (our benchmark, for example, reads a single chromosome so the contig list has effectively only one element). I did not pursue it.; 2. Insert a groupby step between the two transforms.; pro: this gets all the workers involved again; con: the groupby itself takes some time, unnecessarily.; 3. Compute the BAMShards at the client and then send those to workers.; pro: this gets all the workers involved again, and they do not have to spend any time on groupby; con: an existing Dataflow bug will cause the program to crash if the shard list is too long. We can work around this, though, by increasing the shard size when we have many.; 4. Bite the bullet and implement a BoundedSource. I implemented solutions 2 and 3. Solution 3 is the fastest. I suspect solution 4 wouldn't be any faster, though it would be more idiomatic for Dataflow. The graph below shows the time in the Dataflow Read phase with the new code when using the groupby method (this includes sharding, groupby, and actually reading the BAM file). ![image](https://cloud.githubusercontent.com/assets/798637/8913044/8db099d0-3464-11e5-8ee3-f2cbebb6ce2b.png). Next Steps. The next step is to pick either solution 3 or 4 (or 2, I suppose, if we want to be expedient). If 3, then we need to change the sharding to deal with large files. If 4, then we need to spend the time and effort writing the new source (and of course testing that it scales as we're expecting). Comments & feedback welcome!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/756:3173,feedback,feedback,3173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/756,1,['feedback'],['feedback']
Usability,"es. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active region traversals, and disallow the -dcov argument for active region walkers. Downsampling would then by controlled solely by the new argument to set the max # of reads per active region.; - Clarifying the meaning of the per-locus DP annotation for the HC given things like realignment of reads to haplotypes and region-based downsampling. ---. Eventually it was agreed that this would never be fixed in Classic GATK but should be taken into account in designing Hellbender's downsampling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5940,undo,undownsampled,5940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,2,['undo'],['undownsampled']
Usability,"es. `CollectFragmentCounts` shows significant coverage depletion at the boundaries + random dropouts (why?). <img width=""1440"" alt=""inv-1-igv"" src=""https://user-images.githubusercontent.com/15305869/37738780-7918dc92-2d2e-11e8-8b6d-9edd34f7a65e.png"">. ![inv-1](https://user-images.githubusercontent.com/15305869/37739610-0fe8c752-2d31-11e8-8eb7-d22477ce00db.png). Here's another example in a less mappable region (the IGV track should [GMA](https://sourceforge.net/p/gma-bio/wiki/Home/) Illumina mappability track):. <img width=""1440"" alt=""inv-2-igv"" src=""https://user-images.githubusercontent.com/15305869/37738896-da832852-2d2e-11e8-8866-c46ea024d586.png"">. ![inv-2](https://user-images.githubusercontent.com/15305869/37739616-14feccbe-2d31-11e8-9217-ea8d19515001.png). Again, IGV does a much better job. In general, keeping only FR pairs seems to lead to noisy coverage, especially in low mappability regions. _Unbalanced Translocation:_; A clear win for IGV, and a good reason for keeping split reads (notice the coverage loss on the left side of the event in `CollectFragmentCounts`). <img width=""1440"" alt=""unbtr-1-igv"" src=""https://user-images.githubusercontent.com/15305869/37738983-1b13bd6e-2d2f-11e8-8568-f473f8d3880b.png"">. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37739626-1b50c964-2d31-11e8-8e8b-46d882e59810.png). An example is in a low complexity region:. <img width=""1440"" alt=""unbtr-2-igv"" src=""https://user-images.githubusercontent.com/15305869/37739176-bec4847a-2d2f-11e8-9ab1-64d2a3857459.png"">. ![unbtr-2](https://user-images.githubusercontent.com/15305869/37739630-1f0f4d28-2d31-11e8-9703-a67af5a442bc.png). No good strategy here -- it's better to blacklist such regions altogether for CNV calling. Another win for IGV. I do not understand the reason for coverage dropouts in `CollectFragmentCounts`. It might have something to do with the SNPs (though, all reads have high MQ). <img width=""1440"" alt=""unbtr-3-igv"" src=""https://user-images.githubusercontent.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551:3782,clear,clear,3782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551,1,['clear'],['clear']
Usability,"et --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change al",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7723,Simpl,SimpleTimer,7723,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['Simpl'],['SimpleTimer']
Usability,"eter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:15:57.599 INFO FilterMutectCalls - Starting pass 0 through the variants; 11:15:57.637 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:15:57.657 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:15:57 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148007936; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:122); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:157); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:3828,learn,learnAndClearAccumulatedData,3828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['learn'],['learnAndClearAccumulatedData']
Usability,"eward for now but will be much easier to revisit (if it's even necessary at all) once the exact AF calculation is replaced with something less baroque. ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217265362). It seems to me that a quick and sound solution is to reduce the number of alternative alleles at this point in HCGenotypeEngine code:. ```; HaplotypeCallerGenotypingEngine.java line 260:; final Map<Allele, List<Haplotype>> alleleMapper = createAlleleMapper(mergeMap, eventMapper);; ```. Haplotypes have associated score, as a pseudo-likelihood,that can be use to sort then and selectively remove those alternative alleles that are only supported by the less likely haplotypes. ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217266027). So the idea is simple, keep removing haplotypes from that map value lists one by one until enough allele's are emptied, so that the number of genotypes does not surpasses a maximum based on the largest ploidy amongst the input samples. Of course, one would need to create some temporary data-structure to make the operation more efficient. . ---. @vruano commented on [Thu May 05 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217267297). Those haplotype scores have not been throughly analyzed but we are already using them to discard haplotypes beyond the maximum allowed per graph kmer size so I don't see the harm in using the for further reduction. . Certainly is a step forward from just throwing an exception back to the user. However, we should output a Warning every time we need to do such a reduction just to keep track. ---. @sooheelee commented on [Fri May 06 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-217443170). Is it possible for the user to mask this 45SrDNA locus for separate analysis? Assuming of course that this locus is of furthe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:5982,simpl,simple,5982,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['simpl'],['simple']
Usability,"f 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; >; > ""break the intervals up into bins""; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646188>:; >; > > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; >; > As Sam said, some of this stuff can probably be handled automatically by; > IntervalArgumentCollection.; > ---------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:7624,Simpl,SimpleInterval,7624,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211,1,['Simpl'],['SimpleInterval']
Usability,"f spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.tra",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:1174,Simpl,SimpleInterval,1174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['Simpl'],['SimpleInterval']
Usability,"f-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.247% <0%> (-18.071%)` | `28% <0%> (-6%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=footer). Last update [781db35...13a10e2](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941:4100,learn,learn,4100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941,2,['learn'],['learn']
Usability,"f-hist 13_tumor-ref.metrics -alt-hist 13_tumor-alt-depth1.metrics -O 13_tumor-artifact-prior-table.tsv; 12:16:19.960 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_R",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:1644,Learn,LearnReadOrientationModel,1644,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,f1c2f237a0caa1ae0e63e4ae?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `59.375%`. ```diff; @@ Coverage Diff @@; ## master #5124 +/- ##; =============================================; + Coverage 86.66% 86.66% +<.001% ; - Complexity 29043 29048 +5 ; =============================================; Files 1808 1808 ; Lines 134662 134686 +24 ; Branches 14935 14938 +3 ; =============================================; + Hits 116698 116719 +21 ; Misses 12552 12552 ; - Partials 5412 5415 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5124?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5124/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `96.97% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5124/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.097% <100%> (ø)` | `27 <0> (ø)` | :arrow_down: |; | [...tils/codecs/xsvLocatableTable/XsvTableFeature.java](https://codecov.io/gh/broadinstitute/gatk/pull/5124/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MveHN2TG9jYXRhYmxlVGFibGUvWHN2VGFibGVGZWF0dXJlLmphdmE=) | `58.571% <100%> (+1.855%)` | `17 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5124/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vUGF0aExpbmVJdGVyYXRvci5qYXZh) | `64.286% <25%> (-10.714%)` | `4 <1> (ø)` | |; | [...LocatableTable/XsvLocatableTableCodecUnitTest.java](https://codeco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5124#issuecomment-414446194:1243,Simpl,SimpleKeyXsvFuncotationFactory,1243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5124#issuecomment-414446194,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,fed7b20b77?src=pr&el=desc) will **decrease** coverage by `0.002%`.; > The diff coverage is `77.901%`. ```diff; @@ Coverage Diff @@; ## master #4593 +/- ##; ===============================================; - Coverage 79.839% 79.837% -0.002% ; - Complexity 16958 16995 +37 ; ===============================================; Files 1062 1063 +1 ; Lines 61680 61802 +122 ; Branches 9983 10008 +25 ; ===============================================; + Hits 49245 49341 +96 ; - Misses 8540 8556 +16 ; - Partials 3895 3905 +10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4593?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../tools/funcotator/dataSources/DataSourceUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4593/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL0RhdGFTb3VyY2VVdGlscy5qYXZh) | `68.047% <0%> (-5.201%)` | `26 <0> (ø)` | |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4593/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.5% <100%> (ø)` | `26 <2> (+1)` | :arrow_up: |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4593/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `83.871% <100%> (ø)` | `26 <2> (ø)` | :arrow_down: |; | [...ncotator/mafOutput/MafOutputRendererConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4593/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `98.98% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...r/dataSou,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4593#issuecomment-376567190:1257,Simpl,SimpleKeyXsvFuncotationFactory,1257,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4593#issuecomment-376567190,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"ference/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlQmFzZXMuamF2YQ==) | `38.46% <0%> (-19.24%)` | `4% <0%> (-2%)` | |; | [...oadinstitute/hellbender/engine/ReferenceShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlU2hhcmQuamF2YQ==) | `62.5% <0%> (-18.75%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/VariantShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFNoYXJkLmphdmE=) | `63.63% <0%> (-13.64%)` | `7% <0%> (-1%)` | |; | [...ne/spark/datasources/ReferenceWindowFunctions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlV2luZG93RnVuY3Rpb25zLmphdmE=) | `12.5% <0%> (-12.5%)` | `1% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=footer). Last update [a74e571...3768ba2](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892:4202,learn,learn,4202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892,2,['learn'],['learn']
Usability,"finally here. closing the main feature requests made in #2703 . Need to wait for #3752 and #3770 . Will generate a separate dummy PR about how to run the whole prototyping holistic SV interpretation tool. Some small patches need to be applied after this PR, basically for dumpster diving into ; * ambiguous events; * events where assembly contigs clearly couldn't tell a complete picture. but all parts of the diving suit are all available after this PR.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805:347,clear,clearly,347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805,1,['clear'],['clearly']
Usability,first simple and naive impl merged in by pull #252,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/104#issuecomment-77252124:6,simpl,simple,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/104#issuecomment-77252124,1,['simpl'],['simple']
Usability,fixes #1398 . @yfarjoun can you review? it's a super simple picard-style CLP for comparing quals between bams (needed for GATK4 validation of BQSR - may be useful for GoTC too (?)),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1415:53,simpl,simple,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1415,1,['simpl'],['simple']
Usability,fixing a bogus test that never worked (fixes #1465); changing functions that generate simple GATKReports to require a sort order; renaming GATKReportTable.TableSortingWay -> Sorting. not directly to master this time...,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1466:86,simpl,simple,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1466,1,['simpl'],['simple']
Usability,for @droazen. a lot of legacy code here with suboptimal test coverage. I only did a very shallow pass over the style issues. I'm mostyl looking for feedback on whether some of those pieces are not needed. I can deal with style later in the review,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1471:148,feedback,feedback,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1471,1,['feedback'],['feedback']
Usability,"fter which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users---not only on performance, but also on the structure of the new workflow. It might also be worth gauging whether a new WDL is warranted. Otherwise, we just need to add some unit tests for correctness of the multisample-segmentation backend class, integration tests for plumbing of the new tool, and perhaps address some of the issues mentioned above. Then I'd say this is good to go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:2724,feedback,feedback,2724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,2,['feedback'],['feedback']
Usability,"g forward. Finally, I don't think we have satisfactorily demonstrated which of the functions accomplished by this code (format conversion, post-hoc blacklisting, germline/""CNLOH"" tagging and imputation) are necessary or cannot be performed by existing code or more streamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1538,clear,clearly,1538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['clear'],['clearly']
Usability,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:5494,simpl,simple,5494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891,2,['simpl'],['simple']
Usability,"g-quality 0 --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdli",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1518,Simpl,SimpleInterval,1518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['Simpl'],['SimpleInterval']
Usability,"gScores.hdf5 /repo/extract.nonAS.snpIndel.posUn.train.snpIndel.posOnly.IF.snp.trainingScores.hdf5. file1 file2; ---------------------------------------; x x / ; x x /data ; x x /data/scores . group : </> and </>; 0 differences found; group : </data> and </data>; 0 differences found; dataset: </data/scores> and </data/scores>; size: [445] [445]; position scores scores difference ; ------------------------------------------------------------; [ 60 ] -0.419202 -0.419202 5.55112e-17 ; 1 differences found; ```. Looks pretty negligible to me! :stuck_out_tongue_closed_eyes: Probably a result of the native code being called by the python/ML packages used in these tools; even minor changes in the compilers across Ubuntu versions might introduce differences like these. A quick fix might be to replace all system calls to `h5diff` in these tests with `h5diff --use-system-epsilon`; seems to do the trick here. But if that doesn't fix all test cases, then perhaps you can relax things with `h5diff -p EPSILON`, where `EPSILON` is a relative threshold. Probably OK to pick something like `1E-6`. OK if I leave it to you to try this or otherwise check the rest of the cases?. Sorry for the inconvenience! I think the exact-match test worked as intended here, but I probably could've put in better messaging originally. Unfortunately, it's a bit awkward to grab the output of system commands. And thanks for dealing with conda again (a necessary evil, unless we want to reimplement the entire field of machine learning in Java)! I'll experiment to see if I can't get the more recent version used in #8561 (23.10) working with the current environment---probably just some minor tweak to the pip version is needed to get around the error you're seeing. You could try unpinning it to see what gets pulled in. It would be great if we could get off the old version of conda, since more recent versions using the libmamba solver are *MUCH* faster and would cut down all of our Docker build times substantially.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848796931:2044,learn,learning,2044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848796931,2,['learn'],['learning']
Usability,gatk-launch usage output with no args is not clear,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1286:45,clear,clear,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1286,2,['clear'],['clear']
Usability,"gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2819,Learn,LearnReadOrientationModel,2819,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,ge of ServiceAccount from CreateVat related WDLs (#7974); - WDL to extract Avro files for Hail import [VS-579] (#7981); - Removed usage of service account from WDLs (#7985); - Document steps for GVS cleanup for base use case [VS-586] (#7989); - Change backticks to single quotes in several error messages - causing shell to attempt to execute. (#7995); - VS-598 - Minor update to AoU Documentation. (#7994); - Allow for incremental addition of data to alt_allele [VS-52] (#7993); - Minor AoU Documentation Update (#7999); - Batch population of alt_allele table from vet_ tables [VS-265] (#7998); - Change drop_state to NONE for Ingest/Extract [VS-607] (#8000); - python -> python3 (#8001); - Generate Hail import/export script [VS-605] (#8002); - clearer error when values are missing (#7939); - Ah [VS-565] output intervals and sample list (#8010); - make CreateAltAlleleTable task volatile (#8011); - Restore withdrawn [VS-581] (#8006); - Km gvs add storage cost and cleanup doc (#8012); - Updating documentation to reflect the changed outputs [VS-565] (#8014); - File of callset samples -> samples marked as 'withdrawn' in GVS [VS-436] (#8009); - fix quota guidelines for CPUs (#8016); - Add in ability to tweak sample-every-Nth-variant parameter for SNP model creation (#8019); - add initial notebook copy pasta (#8008); - add sample_table_timestamp to GetNumSamplesLoaded (#8022); - Batched Avro export [VS-630] (#8020); - Updating references to old GATK for VS-620 (#8023); - VS-517 Use standard version of GetBQTableLastModifiedDatetime in GvsValidateVat (#8024); - Fix bug in GvsWithdrawSamples.wdl (#8026); - Ah 617 exposing the drop_state parameter to the GvsJointVariantCalling wdl used for beta (and internal customer) (#8032); - Expose maximum-training-variants VQSR parameter [VS-634] (#8029); - Callset statistics [VS-560] (#8018); - Check for withdrawn before exporting to AVRO files [VS-646] (#8039); - Small updates to GVS Integration WDL [VS-618] (#8042); - Rework Hail script gener,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8248:27799,clear,clearer,27799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8248,4,"['clear', 'guid']","['clearer', 'guidelines']"
Usability,"ge). `AlignmentInterval`, `AlignedContig` (refactor `AssemblyContigWithFineTunedAlignments` into `AlignedContig`), `AlignedContigGenerator`, `AlignedAssembly`, `ContigAlignmentsModifier` (refactor `AlnModType` into it), `GappedAlignmentSplitter`, `StrandSwitch`, `FilterLongReadAlignmentsSAMSpark` (factor out the major methods in the new alignment filter by score into a 1st level class). ### type & location inference (sub package). * imprecise: refactor out methods from to-be-deprecated `DiscoverVariantsFromContigAlignmentsSAMSpark`. * alignment classification: `ChimericAlignment` and `NovelAdjacencyReferenceLocations` (very tricky to decouple the functionalities because both have over 50 uses), `AssemblyContigAlignmentSignatureClassifier`, `VariantDetectorFromLocalAssemblyContigAlignments`. * simple: `SimpleSVType`, `SvTypeInference`, `InsDelVariantDetector`, `BreakpointComplications` (rename to `BreakpointComplicationsForSimpleTypes`). * complex: `BreakEndVariantType`, `SuspectedTransLocDetector`, `SimpleStrandSwitchVariantDetector`. ### deprecated. `DiscoverVariantsFromContigAlignmentsSAMSpark` . It currently provides 3 groups of functionalities:. * novel adjacency detection (for ins, del, small dup, inversion only) by delegating to `ChimericAlignment.parseOneContig` and `NovelAdjacencyReferenceLocations(ChimericAlignment chimericAlignment, byte[] contigSequence, SAMSequenceDictionary)`; this should be deprecated; * exact variant type inference (delegated to `SvTypeInference.inferFromNovelAdjacency()`) and annotation (delegated to `AnnotatedVariantProducer.produceAnnotatedVcFromInferredTypeAndRefLocations()`); this should be deprecated; * imprecise variants detection; this should be kept and factored out. --------; --------. ## Planed steps. 1. repackaging & refactoring (no logic change, see #3934 ); 2. bring in some valuable changes made in PR #3668; 3. **more test coverage** (ticket #3431); 4. switch; make `StructuralVariationDiscoveryPipelineSpark` call into `S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111:1889,Simpl,SimpleStrandSwitchVariantDetector,1889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `83.871% <100%> (+0.487%)` | `166 <6> (+5)` | :arrow_up: |; | [...e/hellbender/tools/funcotator/FuncotatorUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JVdGlscy5qYXZh) | `80.485% <90%> (+0.539%)` | `175 <6> (+7)` | :arrow_up: |; | [...ats/collections/SimpleCountCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uVW5pdFRlc3QuamF2YQ==) | `83.784% <0%> (-5.105%)` | `4% <0%> (+1%)` | |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `100% <0%> (ø)` | `6% <0%> (+3%)` | :arrow_up: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/utils/io/IOUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzVW5pdFRlc3QuamF2YQ==) | `86.458% <0%> (+0.127%)` | `32% <0%> (+8%)` | :arrow_up: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5106#issuecomment-412982588:3260,Simpl,SimpleCountCollection,3260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5106#issuecomment-412982588,1,['Simpl'],['SimpleCountCollection']
Usability,getBaseQualities is expensive because it allocates a new byte array every time; getSoftStart etc are also costly because they create many objects; getCigar creates a new Cigar object every time. all of those clearly show on the profiler when running BaseRecalibrator. this PR lifts these operations out of the loops they're in. ; @lbergelson please review -,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1475:208,clear,clearly,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1475,1,['clear'],['clearly']
Usability,gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `88.482% <0%> (-0.324%)` | `15% <0%> (+5%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <0%> (ø)` | `18% <0%> (+9%)` | :arrow_up: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <0%> (ø)` | `5% <0%> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <0%> (ø)` | `19% <0%> (?)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.74% <0%> (+0.101%)` | `3% <0%> (+1%)` | :arrow_up: |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547:3476,Simpl,SimpleNovelAdjacencyInterpreter,3476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"given that we only have easy access to scores for positive truth---and hence, no false positives, which precludes calculation of precision and F1. I *think* we could pass a VCF for a sample with gold-standard positives and negatives and use the existing code for extracting labels, but this will require a bit of engineering and be more trouble than it's worth. There are other options---see https://ir.cwi.nl/pub/30479, for example. We might want to experiment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1060,learn,learning,1060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,2,['learn'],['learning']
Usability,"global quantities to 1000 points randomly sampled each MCMC iteration and rescaling likelihoods accordingly) was implemented in #3913 to bring WGS runtime down to reasonable levels. However, this sort of naive subsampling does not accurately preserve the posterior, which leads to some artifacts in posterior estimation. @MartonKN suspected that this negatively affected downstream performance in his caller, since weights of larger segments were underestimated. . For example, the copy-ratio posterior widths should scale with the inverse square root of the number of copy-ratio bins in each segment. However, subsampling yields an artificial break at 1000 bins and screws up the scaling:. ![cr-ss](https://user-images.githubusercontent.com/11076296/51122629-417be180-17e8-11e9-9a8f-e17a5d0563f5.png). To fix this, I implemented minibatch slice sampling as described in http://proceedings.mlr.press/v33/dubois14.pdf. This uses early stopping of sampling as determined by a simple statistical test to perform approximate sampling of the posterior in a way that is more well behaved:. ![cr-mb](https://user-images.githubusercontent.com/11076296/51122680-61aba080-17e8-11e9-992a-f756a267d0ce.png). Note that the scaling levels off for larger segments, but the approximation can be made exact by taking the appropriate parameter to zero (here, this parameter is set to 0.1). However, since subsampling parameters were not exposed in the old code, I have not exposed the parameters for the approximation here. We can do this in a future PR if desired. Changing these parameters can affect runtime and results, but I've set them to reasonable values for now. The implementation involved 1) creating an abstract class to extract some common functionality shared with the old batch SliceSampler (which is now no longer used in production code), 2) implementing the MinibatchSliceSampler as described in the above reference, and 3) adding some hash-based caching functionality to both the batch/minibatch imp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5575:1062,simpl,simple,1062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575,1,['simpl'],['simple']
Usability,"gments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. We should unify the reading and storing of sample names at some point (#2910).; - [x] We will need to replace `SimpleReadCountCollection` (which currently serves as the interface between the old coverage collection files and the new code) with one of these subclasses when `CollectReadCounts` is in. We can also change `NamedSampleFile` depending on what he's implemented.; - [x] We should eventually write proper SAM headers with useful tags to all TSV and HDF5 files generated by our tools that represent annotated intervals that can be associated with a single sample. Documentation:; - [x] I need to update class javadoc and example invocations throughout. The initial PR will already be quite massive, so I'll leave this until later. Perhaps @sooheelee might want to be involved?; - [ ] I will update the white paper at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:10099,simpl,simply,10099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,3,"['Simpl', 'simpl']","['SimpleReadCountCollection', 'simply']"
Usability,"h 1; Command Line: Rscript -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.applySegmentation(PerformSegmentation.java:185); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.doWork(PerformSegmentation.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2488,undo,undosplits,2488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,1,['undo'],['undosplits']
Usability,"h 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:5704,Learn,LearnReadOrientationModel,5704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:8711,Learn,LearnReadOrientationModel,8711,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4340,Learn,LearnReadOrientationModel,4340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7347,Learn,LearnReadOrientationModel,7347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4588,Learn,LearnReadOrientationModel,4588,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7595,Learn,LearnReadOrientationModel,7595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:5827,Learn,LearnReadOrientationModel,5827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:8834,Learn,LearnReadOrientationModel,8834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4836,Learn,LearnReadOrientationModel,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7843,Learn,LearnReadOrientationModel,7843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:5951,Learn,LearnReadOrientationModel,5951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:8958,Learn,LearnReadOrientationModel,8958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4712,Learn,LearnReadOrientationModel,4712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7719,Learn,LearnReadOrientationModel,7719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:6075,Learn,LearnReadOrientationModel,6075,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 16:21:20.459 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:9082,Learn,LearnReadOrientationModel,9082,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4464,Learn,LearnReadOrientationModel,4464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7471,Learn,LearnReadOrientationModel,7471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 12:16:43.443 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 12:16:43.452 INFO LearnReadOrientationModel - Shutting down engine; [November 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:6323,Learn,LearnReadOrientationModel,6323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 16:21:20.459 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 16:21:21.008 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 16:21:21.044 INFO LearnReadOrientationModel - Shutting down engine; [November 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:9330,Learn,LearnReadOrientationModel,9330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 12:16:43.443 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 12:16:43.452 INFO LearnReadOrientationModel - Shutting down engine; [November 26, 2018 12:16:43 PM EST] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:6447,Learn,LearnReadOrientationModel,6447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 16:21:20.459 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 16:21:21.008 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 16:21:21.044 INFO LearnReadOrientationModel - Shutting down engine; [November 26, 2018 4:21:21 PM UTC] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:9454,Learn,LearnReadOrientationModel,9454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 12:16:43.443 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:6199,Learn,LearnReadOrientationModel,6199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 16:21:15.238 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 16:21:15.709 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 16:21:16.222 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 16:21:17.015 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 16:21:17.906 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 16:21:18.677 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 16:21:19.182 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 16:21:19.680 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 16:21:20.459 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 16:21:21.008 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:9206,Learn,LearnReadOrientationModel,9206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 12:16:31.710 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 12:16:32.407 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 12:16:33.215 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 12:16:34.070 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 12:16:34.860 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:4960,Learn,LearnReadOrientationModel,4960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"h 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1909 alt examples, EM converged in 11 steps; 16:21:09.635 INFO LearnReadOrientationModel - Context CAC: with 351720 ref and 3718 alt examples, EM converged in 12 steps; 16:21:10.322 INFO LearnReadOrientationModel - Context CAG: with 547234 ref and 5940 alt examples, EM converged in 12 steps; 16:21:11.103 INFO LearnReadOrientationModel - Context CCA: with 464164 ref and 8212 alt examples, EM converged in 13 steps; 16:21:11.899 INFO LearnReadOrientationModel - Context CCC: with 512128 ref and 7580 alt examples, EM converged in 13 steps; 16:21:12.719 INFO LearnReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 16:21:13.361 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 16:21:14.122 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 16:21:14.667 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:7967,Learn,LearnReadOrientationModel,7967,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,h/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlclVuaXRUZXN0LmphdmE=) | `99.057% <ø> (ø)` | `30 <0> (ø)` | :arrow_down: |; | [...ry/alignment/ContigAlignmentsModifierUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0NvbnRpZ0FsaWdubWVudHNNb2RpZmllclVuaXRUZXN0LmphdmE=) | `99.194% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...very/alignment/AlignedContigGeneratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWduZWRDb250aWdHZW5lcmF0b3JVbml0VGVzdC5qYXZh) | `97.17% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `80.882% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ender/tools/spark/sv/utils/GATKSVVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZDb25zdGFudHMuamF2YQ==) | `0% <ø> (-75%)` | `0 <0> (-1)` | |; | [.../sv/discovery/inference/CpxVariantInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4996/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnRJbnRlcnByZXRlci5qYXZh) | `79.839% <ø> (ø)` | `26 <0> (ø)` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4996#issuecomment-404549419:2002,Simpl,SimpleNovelAdjacencyInterpreter,2002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4996#issuecomment-404549419,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,h/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyLmphdmE=) | `100% <100%> (ø)` | `26 <1> (-1)` | :arrow_down: |; | [...forms/markduplicates/MarkDuplicatesSparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmtVdGlscy5qYXZh) | `91.284% <100%> (-0.079%)` | `65 <0> (ø)` | |; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvTWFya0R1cGxpY2F0ZXNTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `89.933% <100%> (+1.383%)` | `27 <6> (+6)` | :arrow_up: |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9GcmFnbWVudC5qYXZh) | `92.857% <100%> (-0.893%)` | `6 <1> (-1)` | |; | [...ats/collections/SimpleCountCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uVW5pdFRlc3QuamF2YQ==) | `83.784% <0%> (-5.105%)` | `5% <0%> (+2%)` | |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (+1%)` | :arrow_up: |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/5023/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5023#issuecomment-405694045:3561,Simpl,SimpleCountCollectionUnitTest,3561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5023#issuecomment-405694045,2,['Simpl'],"['SimpleCountCollection', 'SimpleCountCollectionUnitTest']"
Usability,"haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `48.837% <0%> (-24.774%)` | `27% <0%> (-9%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [27 more](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=footer). Last update [5d2f859...7a651b7](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306:4172,learn,learn,4172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306,2,['learn'],['learn']
Usability,"hat's happening. We wouldn't expect gatk4 haplotype caller to be that much slower. . It looks like they're running beta2 which is kind of old as well. Can you ask them what exact version they're using?. Can you ask if they have the log (stdout + stderr) for the gatk4 non-spark run? I can't tell what pairhmm they're actually running with and the logs would help with that. . Can you also find out what sort of hardware they're running on? Specifically, is it an intel machine with support for AVX?. A good setting for` --nativePairHmmThreads` is probably 4-8, you won't see any improvement after that. I also noticed that they're setting -XX:+UseParallelGC -XX:ParallelGCThreads=32 for the gatk3. They would be better off setting it to 2-4 threads. Performance gets worse beyond that typically from what I've seen. They can set the same thing for gatk4 using`--javaOptions ' -XX:+UseParallelGC -XX:ParallelGCThreads=4'`. Their spark configuration looks wrong in a number of ways which is probably a big part of why they're not seeing any improvement. In general you want executors with ~4-8 cores and at least 4g of memory per core. I don't know how much memory their nodes have, and I don't know if they're running with autoscaling turned on, but I suspect they're only allocating 1 executor on 1 node and then it's thrashing memory because it's trying to run 32 threads at once. Spark tuning for haplotype caller is going to be complicated though and I don't know how to do it will yet, we will be revisiting it in the next quarter probably. They're also running withs spark 2.1.0, we currently require spark 2.0.2 which is an unfortunately specific version, we're planning on upgrading to spark 2.2.+ in the next quarter. . You should make it clear to them that the results will not be the same between 3, 4, and 4-spark yet and that 4 is in rapid state of flux and has known performance issues that we're planning on working soon. Even so though, that slowdown they're seeing is bizarrely large.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964:1784,clear,clear,1784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964,2,['clear'],['clear']
Usability,"hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `38% <0%> (+9%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `66% <0%> (+13%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `70.47% <0%> (+4.154%)` | `46% <0%> (+18%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=footer). Last update [88c181d...298212c](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625:5035,learn,learn,5035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625,2,['learn'],['learn']
Usability,"he Y chromosome, but possibly in other places as well) due to changes between the two references. ; ; 12:37:55.679 INFO  ProgressMeter - Starting traversal ; ; 12:37:55.679 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Features Processed  Features/Minute ; ; 12:37:56.198 WARN  FuncotatorUtils - Reference allele is different than the reference coding sequence (strand: -, alt = G, ref G != T reference coding seq) @\[chr1:13839497\]!  Substituting given allele for sequence code (TTC->GTC) ; ; 12:37:56.213 INFO  FuncotateSegments - Shutting down engine ; ; \[February 9, 2022 12:37:56 PM EST\] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.24 minutes. ; ; Runtime.totalMemory()=3139436544 ; ; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:29534 end:14501 ; ;     at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59) ; ;     at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2938) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914) ; ;     at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866) ; ;     at org.broadinstitute.hellbender.tools.funcotator.DataSourceF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7676:2501,Simpl,SimpleInterval,2501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7676,1,['Simpl'],['SimpleInterval']
Usability,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3370,learn,learning,3370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,2,['learn'],['learning']
Usability,hey @alexbarrera thanks for writing in. This is a known issue that we are aware of and we have unfortunately dealt with on several occasions (lexocographic vs. numerical sorting of readnames). Would it be possible for you to re-sort your bam using SortSam with -SO queryname to clear this up in your use-case as a workaround?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147#issuecomment-1374035751:278,clear,clear,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147#issuecomment-1374035751,2,['clear'],['clear']
Usability,"hhaW5QcnVuZXIuamF2YQ==) | `83.33% <0%> (-12.23%)` | `5% <0%> (-15%)` | |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `66.66% <0%> (-11.12%)` | `19% <0%> (-1%)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.92% <0%> (-11.04%)` | `17% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/SeqVertex.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxVmVydGV4LmphdmE=) | `92.85% <0%> (-7.15%)` | `10% <0%> (-1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.85% <0%> (-7.15%)` | `4% <0%> (ø)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=footer). Last update [1f6a172...623830b](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397:4479,learn,learn,4479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397,2,['learn'],['learn']
Usability,"hly four types of genotype subsetting you could do:. a) By the sample names (`--sample-name NA12878`); b) JEXL (`--select GQ > 0`); c) JEXL by accessing the variant context object (`--select vc.getGenotype('NA12878').getGQ() > 1`); d) Others (e.g. `--remove-fraction-genotype`). a) does not need ""fully-decode."" It turns out b) was never supported (GATK currently removes all variants and succeed.) And from my experiments, c) does not seem to ever trigger calling `VariantContext.fullyDecode().` In fact the only code path I can see that calls fullyDecode() is by setting the `fully-decode` SelectVariants argument, which seems to just call fullyDecode at the beginning just for the sake of calling it (or so it appears to me. The utility of this command line argument is highly dubious.) . It's possible that apache code does something similar to fully decoding that could affect performance. All that is to say that we cannot achieve performance improvement with our original blueprint simply because this expensive ""fullyDecode"" operation seems to be a mythical operation that is never used in reality. So while I could not speed up SelectVariants, I cleaned up the code and added the following new arguments:. * `--select-genotype`: with this new genotype-specific JEXL argument, we support filtering by genotype fields like 'GQ > 0', where the behavior in the multi-sample case is 'GQ > 0' in at least one sample. I have not added the ability to do 'GQ > 0 for all samples' but it should be a simple (but not easy…) exercise in boolean operations.; * `applyJexlFiltersBeforeFilteringGenotypes`: if set to true, we do the JEXL checking before we subset by samples. In my tests, performance improvement from this option was very modest. Subsetting a ~3k 1kg SV vcf to a single sample was about 30 seconds faster (out of ~20 min total run time) than the default. I kept it in the PR because I thought some user might find it useful, but I wouldn't be opposed to removing it. Tests needed:; - [x] F",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092:1671,simpl,simply,1671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092,1,['simpl'],['simply']
Usability,how about the gatk3 diff engine? should be easy to port and seems usable here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190#issuecomment-96246722:66,usab,usable,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190#issuecomment-96246722,1,['usab'],['usable']
Usability,"hreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Container exited with a non-zero exit code 50. Driver stacktrace:; 17/10/11 14:19:38 INFO spark.ExecutorAllocationManager: Existing executor 2 has been removed (new total is 0); 17/10/11 14:19:38 INFO scheduler.DAGScheduler: Job 0 failed: saveAsNewAPIHadoopFile at ReadsSparkSink.java:203, took 19.909238 s; 17/10/11 14:19:38 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down; 17/10/11 14:19:38 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/11 14:19:38 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/11 14:19:38 INFO storage.MemoryStore: MemoryStore cleared; 17/10/11 14:19:38 INFO storage.BlockManager: BlockManager stopped; 17/10/11 14:19:38 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/11 14:19:38 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/11 14:19:38 INFO spark.SparkContext: Successfully stopped SparkContext; 14:19:38.600 INFO PrintReadsSpark - Shutting down engine; [October 11, 2017 2:19:38 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.48 minutes.; Runtime.totalMemory()=986185728; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 4, com2, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1507683879816_0006_01_000003 on host: com2. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686:31337,clear,cleared,31337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686,1,['clear'],['cleared']
Usability,"https://github.com/broadinstitute/gatk/blob/c6daf7dd02b866907fbfebad150baeb540c35bce/src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/JointGermlineCNVSegmentation.java#L701. I'm running into a recurrent issue in JointGermlineCNVSegmentation, running after PostprocessGermlineCNVCalls in a gCNV pipeline. A number of batches are being merged in parallel - some of those succeed, some fail. It's not clear just yet if this is a deterministic failure, I'll re-run a few times and see if I can answer that. . ```text; org.broadinstitute.hellbender.exceptions.GATKException: Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz @ chrX:6383391-17732942 Q3076.53 of type=NO_VARIATION alleles=[N*] attr={END=17732942} GT=GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20 filters=. ... Caused by: java.lang.IllegalStateException: Encountered genotype with ploidy 1 but 2 alleles.; 	at org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:814); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.correctGenotypePloidy(JointGermlineCNVSegmentation.java:701); 	at org.broadinstitute.hellbender.tools.walkers.sv.JointGermlineCNVSegmentation.prepareGenotype(JointGermlineCNVSegmentation.java:682); ```. The VCF row in question is . ```text; chrX	6383391	CNV_chrX_6383391_17732942	N	.	3076.53	.	END=17732942	GT:CN:NP:QA:QS:QSE:QSS	0:1:581:1:3077:4:20; ```. The characterisation of this row as `type=NO_VARIATION alleles=[N*]` seems... partially correct? There is no variation at this locus, but I'm not sure why alleles is `N*`. In this situation, as I read it, the first clause should be satisfied: 1 allele, and allele is no-call. Instead the variant process is dying in the else side of the condition. Could you clarify if I'm interpreting this correctly?. Relevant versioning:; ```; 13:18:38.320 INFO JointGermlineCNVSegmentation - ------------------------------------------------------------; 13:18:38.321 INFO JointGermlineCNVSegmentation - The Genome Analy",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834:410,clear,clear,410,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834,1,['clear'],['clear']
Usability,https://github.com/mengyao/complete-striped-smith-waterman-library; I've successfully built and run it on linux and mac. Need to investigate performance and usability for us. see also #1629,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1812:157,usab,usability,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1812,1,['usab'],['usability']
Usability,i'm going to delete this until we have a clearer picture of locus walkers in hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/33#issuecomment-94484114:41,clear,clearer,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/33#issuecomment-94484114,1,['clear'],['clearer']
Usability,"i'm removing my assignment then. the requirements are not clear to me. 'until we're all satisfied' is pretty vague, too vague for alpha i think",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190#issuecomment-127382644:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190#issuecomment-127382644,1,['clear'],['clear']
Usability,"iantsFromContigAlignmentsSAMSpark - DUP: 1141; 10:28:46.277 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1266; 10:28:46.483 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 4, 2017 10:28:46 AM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=3954180096. ==============. feature.vcf. 13:51:48.490 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Discovered 6543 variants.; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INV: 229; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DEL: 3679; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - DUP: 1365; 13:51:48.502 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - INS: 1270; 13:51:48.770 INFO DiscoverVariantsFromContigAlignmentsSAMSpark - Shutting down engine; [October 5, 2017 1:51:48 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark done. Elapsed time: 0.49 minutes.; Runtime.totalMemory()=4026531840; ```. No variants that were dropped are simple variants, and they are expected to be brought back with the correct interpretation once complex sv PR series are fully coded. __Two known issues__:; 1. Arguably, these calls may not have high confidence since we are likely NOT having the duplicated region fully assembled. But we could develop a filter later and be less stringent in the discovery stage.; 2. The inserted sequence mapping annotation is still an issue we need to iron out, in the sense that when one ref span is a completely enclosed in the other with some bases in the larger ref span uncovered by the the smaller ref span (i.e. a true containment from both boundaries instead of a one-boundary coincidence), there's actually insert sequence between the two copies of the duplicated sequence (this is why alt haplotype sequence is generated rather than CIGARs).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3668:1855,simpl,simple,1855,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668,1,['simpl'],['simple']
Usability,"ical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm008185:tig00000	missing	classified as ""ambiguous""; unsure of how to deal with a general rule--exact same part of read coverred by one mapping to canonical, one to non-canonical (better AS); if save the canonical, a deletion would be called; asm018220:tig00004	missing	classified as ""ambiguous""; salvagable if re-analysed through old interpretation tool; asm026229:tig00000	missing	classified as ""ambiguous""; fixable if implement a special rule making all split alignments on non-canonical chromosomes as ""bad""; ```. They are relatively simple fixes so I clumped them into a single PR.; If you prefer to review them as separate PR's. I can do that too.; Thanks!; [report.sam.gz](https://github.com/broadinstitute/gatk/files/1786690/report.sam.gz)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:2788,simpl,simple,2788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,2,['simpl'],['simple']
Usability,iderForPik3caTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvRGF0YVByb3ZpZGVyRm9yUGlrM2NhVGVzdERhdGEuamF2YQ==) | `98.684% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `83.871% <100%> (+0.487%)` | `166 <6> (+5)` | :arrow_up: |; | [...e/hellbender/tools/funcotator/FuncotatorUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JVdGlscy5qYXZh) | `80.485% <90%> (+0.539%)` | `175 <6> (+7)` | :arrow_up: |; | [...ats/collections/SimpleCountCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uVW5pdFRlc3QuamF2YQ==) | `83.784% <0%> (-5.105%)` | `4% <0%> (+1%)` | |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `100% <0%> (ø)` | `6% <0%> (+3%)` | :arrow_up: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5106/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/utils/io/IOUtilsUnitTest.java](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5106#issuecomment-412982588:2620,Simpl,SimpleCountCollectionUnitTest,2620,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5106#issuecomment-412982588,1,['Simpl'],['SimpleCountCollectionUnitTest']
Usability,"ied as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inefficient way to write these three files. You end up calling collect on the RDD three different times and then traversing the local collection three times. Why not make a map of contig name to bam file, collect the rdd once, and then traverse the local collection once, writing each read to the appropriate bam file from the map?. Second round comment by @cwhelan ; > This is a better but you are still collecting the RDD and passing over the collection three times. What I meant by my original suggestion was this: Why not make the map go the other way, ie make a Map<String, ReasonForAlignmentClassi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:3324,simpl,simple,3324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['simpl'],['simple']
Usability,"ientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2530,Learn,LearnReadOrientationModel,2530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the ActiveRegion traversal fully respect dcov. I think Mark, in implementing the current scheme, might have been thinking that maintaining the undownsampled reads in memory is actually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5374,undo,undownsampled,5374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"iff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #2515 +/- ##; ===============================================; - Coverage 76.273% 76.268% -0.004% ; - Complexity 10876 10878 +2 ; ===============================================; Files 752 752 ; Lines 39583 39584 +1 ; Branches 6922 6922 ; ===============================================; - Hits 30191 30190 -1 ; - Misses 6772 6774 +2 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <66.667%> (-1.314%)` | `30 <0> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=footer). Last update [d40ccc2...d5c85bb](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799:1927,learn,learn,1927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799,2,['learn'],['learn']
Usability,"iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <0%> (+1.587%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=footer). Last update [5ccfd00...b1d407f](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549:3831,learn,learn,3831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549,2,['learn'],['learn']
Usability,igAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <100%> (ø)` | `13 <4> (+4)` | :arrow_up: |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.639% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...park/sv/discovery/inference/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NoaW1lcmljQWxpZ25tZW50LmphdmE=) | `70.922% <45.455%> (-2.155%)` | `48 <2> (+2)` | |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <46.269%> (ø)` | `5 <5> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <64.211%> (ø)` | `19 <19> (?)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `75.214% <75.676%> (-2.314%)` | `10 <2> (+2)` | |; | ... and [13,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092:3218,Simpl,SimpleNovelAdjacency,3218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092,1,['Simpl'],['SimpleNovelAdjacency']
Usability,"ils/genotyper/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvU2FtcGxlTGlzdC5qYXZh) | `75.676% <0%> (ø)` | `8% <0%> (?)` | |; | [...hellbender/tools/walkers/annotator/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TYW1wbGVMaXN0LmphdmE=) | `81.25% <0%> (+1.658%)` | `9% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [.../broadinstitute/hellbender/tools/exome/Sample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TYW1wbGUuamF2YQ==) | `100% <0%> (+12.308%)` | `5% <0%> (-21%)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `72.727% <0%> (+15.584%)` | `4% <0%> (-4%)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=footer). Last update [62d58c5...fde9d36](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479:3376,learn,learn,3376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479,2,['learn'],['learn']
Usability,"imVariants - Reference allele is too long (212) at position chr2_KI270894v1_alt:202602; skipping that record. Set --reference_window_stop >= 212 ; INFO 21:38:54,233 LeftAlignAndTrimVariants - Reference allele is too long (220) at position chr2_KI270894v1_alt:204859; skipping that record. Set --reference_window_stop >= 220 ; INFO 21:38:54,237 LeftAlignAndTrimVariants - Reference allele is too long (262) at position chr2_KI270894v1_alt:207863; skipping that record. Set --reference_window_stop >= 262 ; 0 variants were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **ma",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7499,Simpl,SimpleTimer,7499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['Simpl'],['SimpleTimer']
Usability,"imple improvements to ReCapSeg caller (#3825).; - [x] Review and merge modeling/WDL PR. (#3913 awaiting review. Note that this PR also deletes the old germline WDL.); - ~~Write MultidimensionalKernelSegmenterUnitTest.~~ (SL, punting, filed #3916); - ~~Write ModelSegmentsIntegrationTest.~~ (SL, punting, filed #3916); - [x] Preliminary PCAWG or HCC1143 purity evaluation. (@LeeTL1220) (LL, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (PR #4010 awaiting review.); - [x] Add SM tag and sequence dictionary headers to all appropriate files and sort accordingly. (SL, #3914 awaiting review); - [x] Update tutorial data. (@MartonKN); - [ ] (Reach) Add VCF output.; - [ ] (Reach) Add PG tags to all files.; - [ ] (Reach) Replace ReCapSeg caller with improved version. (@MartonKN). gCNV pipeline:; - [x] Review and merge Python code (#3838). (MB and SL, PR #3925 awaiting review.); - [x] CLI for ploidy determination (cohort). (@samuelklee); - [x] CLI for ploidy determination (case). (@samuelklee); - [x] CLI for calling (cohort). (@samuelklee); - [x] CLI for calling (case). (@samuelklee); - [ ] CLI for post-processing calls. (@asmirnov239) (AS, PR issued by 12/4); - [x] Python environment. (Update: I've verified that gCNV works on the gsa server with a manual setup of conda (python=3.6) + @mbabadi's pip install---although I do get an ""install mkl"" warning from theano. We can discuss autoloading of this environment after release, but should at least have some clear documentation.); - [x] WDL and Cromwell tests. (SL, PR issued by 12/1); - [x] Preliminary evaluation. (MB, should be done in time for @vdauwera to present at Broad retreat); - [x] Update docs/arguments (w/ Comms, see #3853). This will follow deletion of prototype tools. (all, PE #3925 awaiting review.). Miscellaneous:; - [x] Update PreprocessIntervals behavior for WES. (Issue #3981, PR #4027 awaiting review.)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826:2484,clear,clear,2484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826,1,['clear'],['clear']
Usability,"impleMerge` might work. ---. @ldgauthier commented on [Wed Mar 01 2017](https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-283367380). I thought the state I left that branch was that it would output a merged; representation of the two events starting at the deletion position- so the; reference is some string of bases, allele 1 is the deletion, and allele 2; matches the reference for the length of the deletion with the exception of; the SNP. (Allele 2 is not the minimal representation yet.) That's the first; step to get the genotype right. After that we need to break up the events,; clean up the representation, and assign the genotype from the combined; event to both of them. Hopefully that helps. (And hopefully I actually committed the version of; the branch that does what I said.). On Jan 24, 2017 12:06 PM, ""Ron Levine"" <notifications@github.com> wrote:. > @davidbenjamin <https://github.com/davidbenjamin> It looks like the issue; > is with ReferenceConfidenceModel.getOverlappingVariantContext(final; > GenomeLoc curPos, final Collection<VariantContext> maybeOverlapping),; > with the stack trace:; >; > ReferenceConfidenceModel.calculateRefConfidence; > ReferenceConfidenceModel.getOverlappingVariantContext; > HaplotypeCaller.map; >; > For curPos=9:418272, there are 2 variants, 9:418269-418273; > TTTTG*,<NON_REF>,T and 9:418272 T*,<NON_REF>,C. This method returns the; > variant with the right-most start , so the variant with the deletion is; > ignored. This logic should be changed so that the variants that overlap; > curPos are merged and returned. A utility such as GATKVariantContextUtils.; > simpleMerge might work.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gsa-unstable/issues/1499#issuecomment-274868889>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCAl7601U3RRbph6rOi0E7dqNawRks5rVi-fgaJpZM4KfOWm>; > .; >",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2960:7114,simpl,simpleMerge,7114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2960,1,['simpl'],['simpleMerge']
Usability,"implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you think, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:1854,simpl,simplest,1854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,1,['simpl'],['simplest']
Usability,"in conjunction with a locally modified version of gatk, to communicate with aws. Since we had the code that allows for communication with aws anyway, we decided to share it and maybe it can be part of the gatk toolkit in the future. # How does it work?; The user is able to provide an additional parameter '--s3', adding the nio-spi-for-s3-2.0.0-dev-all.jar file to the java classpath. File locations starting with 's3://' are then able to be provided, resulting of reading/writing of these files to aws. When using this option, however, the aws credentials have to be set correctly, for which you can find more information [here](https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html). Currently, I haven't implemented it for --spark due to a lack of need/inexperience with spark. # Current Issues; We found some issues for which we do not know any solution. If this tool was to be implemented in GATK in the future, these have to be resolved eventually. ## Doesn't work for picard-based tools; First, 'aws-java-nio-spi-for-s3' doesn't seem work for (most) picard tools, since most of them utilise the java.io.File package, which is limited to local filesystem files, as opposed to java.nio.Path (we think).; ## Issues reading genome reference files from AWS; Secondy, most tools that require a reference genome (i.e. BaseRecalibrator, HaplotypeCaller..) do not seem function when provided with a reference genome file stored on AWS. The error we receive can be found underneath and is much less clear. We believe that the issue lies in the interaction between the caching of the indexed reference file and 'aws-java-nio-spi-for-s3', since we tested in a custom java script that the package 'htsjdk' works like intended when the reference genome is read from AWS.; Notably, some tools do not have this issue, such as the the vqsr tools (VariantRecalibrator and applyVQSR).; ![image](https://github.com/broadinstitute/gatk/assets/149685151/24d16941-b40c-4a5a-b8e6-0dc7415c6b1b)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672:1805,clear,clear,1805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672,1,['clear'],['clear']
Usability,"in the count files, and perhaps fail if one is provided for any of the tools (I don’t recall exactly how VCF indexing is triggered by providing one, as seems to be indicated by the tutorial, but hopefully we can disallow external dictionaries while still taking advantage of the relevant engine features for VCF writing). EDIT: Went digging in Slack to try to remind myself of the context of these changes, and found the following PR comment from 1/7 (although it seems to have mysteriously disappeared from GitHub):. > Just so I understand, are we allowing overriding of the sequence dictionary in the shards (and skipping the consistency check) by allowing the parameter --sequence-dictionary to be specified? If so, we might want to document. Otherwise, I'd be inclined to enforce using the sequence dictionary in the shards (and ensuring the consistency check across shards is performed) by changing the null check in getBestAvailableSequenceDictionary to a check that the dictionary has not been set via the command line. EDIT^2: I think I misremembered the details of how #6330 hooked up the sequence dictionary and how getBestAvailableSequenceDictionary in GATKTool works (which probably explains why that comment was deleted...). Now that I actually go back and look, the `--sequence-dictionary` is not hooked up at all, so there is no change to revert in point 4!. Note that after all of this, it will *still* be possible to get into trouble at the gCNV step if you make funky shards (e.g., you could have shard 1 contain intervals from chr1 and chr3, and shard 2 contain intervals from chr2). I don't think it is possible to check for this case early, but you would still fail at PostprocessGermlineCNVCalls as above. Of course, all of these possibilities can be avoided by simply using the WDL, but it will be good to harden checks for those still working at the command line. @ldgauthier @droazen @mwalker174 what do you think? Happy to review later, but OK if I pass this off to you all?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:3971,simpl,simply,3971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,2,['simpl'],['simply']
Usability,ines 63951 63792 -159 ; Branches 9725 9719 -6 ; ==============================================; - Hits 50918 50796 -122 ; + Misses 9146 9113 -33 ; + Partials 3887 3883 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `44.355% <0%> (-0.361%)` | `24 <0> (ø)` | |; | [.../sv/discovery/prototype/InsDelVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0luc0RlbFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `87.826% <100%> (ø)` | `30 <0> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/3746?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQ2hpbWVyaWNBbGlnbm1lbnQuamF2YQ==) | `74.545% <65%> (+1.73%)` | `37 <22> (+7)` | :arrow_up: |; | [...ls/spark/sv/discovery/B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3746#issuecomment-339474962:1595,Simpl,SimpleStrandSwitchVariantDetector,1595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3746#issuecomment-339474962,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"ing HaplotypeCaller with `GENOTYPE_GIVEN_ALLELES` (""GGA"") mode, I came across a couple of cases that crashed, and I traced them to spanning deletions (of the type considered in #4963). The first case involved the following spanning deletion in the `--alleles` input:; ```; 22	16137300	rs567136176	TAG	T; 22	16137302	rs573978809	G	C; ```; and it crashed with:; ```; java.lang.IllegalStateException: Allele in genotype TAG* not in the variant context [G*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:984,simpl,simpleMerge,984,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['simpl'],['simpleMerge']
Usability,"ing been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613152). @ldgauthier Shouldn't a locus without genotypes bypass `AC` validation, given it's defined as: `Allele count in genotypes, for each ALT allele, in the same order as listed`?. ---. @ldgauthier commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262613997). Agreed. ---. @ronlevine commented on [Thu Nov 24 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-262635204). The change should be a lot simpler than proposed. The code can validate the number of alleles before it checks for the presence of genotypes in [VariantContext#validateChromosomeCounts](https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/variantcontext/VariantContext.java#L1236). . ---. @ldgauthier commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263277972). Sorry, I needed to refresh my memory. I actually don't want to bypass AC validation for variants without genotypes, but I think you already figured that out. My proposal was more general, but you're right -- AC and AF should always have the same count as alt alleles and we don't need to check the header for that. When this came up (a year and a half ago!) we were thinking about validating all the info field annotations. ---. @ronlevine commented on [Mon Nov 28 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-263280085). That's exactly what I did in h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:5807,simpl,simpler,5807,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['simpl'],['simpler']
Usability,"institute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:4955,Learn,LearnReadOrientationModel,4955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,institute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `62.963% <0%> (-24.537%)` | `14% <0%> (+4%)` | |; | [...overy/inference/NovelAdjacencyAndAltHaplotype.java](https://codecov.io/gh/broadinstitute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL05vdmVsQWRqYWNlbmN5QW5kQWx0SGFwbG90eXBlLmphdmE=) | `75.556% <0%> (-3.81%)` | `46% <0%> (+17%)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `76.048% <0%> (-0.794%)` | `5% <0%> (+3%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86% <0%> (-0.667%)` | `3% <0%> (ø)` | |; | [.../discovery/inference/ImpreciseVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0ltcHJlY2lzZVZhcmlhbnREZXRlY3Rvci5qYXZh) | `80.952% <0%> (-0.298%)` | `6% <0%> (ø)` | |; | [...ols/spark/sv/discovery/alignment/StrandSwitch.java](https://codecov.io/gh/broadinstitute/gatk/pull/4751/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L1N0cmFuZFN3aXRjaC5qYXZh) | `100% <0%> (ø)` | `2% <0%> (+1%)` | :arrow_up: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4751#issuecomment-387798252:2023,Simpl,SimpleSVType,2023,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4751#issuecomment-387798252,1,['Simpl'],['SimpleSVType']
Usability,"interesting - ok, that's done. and yes, the spurious commits are basically errors learning git rebase. hopefully this covers everything. the change in hasUserSuppliedIntervals() touched a lot of files, but it's a pretty trivial change in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909:82,learn,learning,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909,2,['learn'],['learning']
Usability,ion.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `96.667% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ls/spark/sv/discovery/GappedAlignmentSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvR2FwcGVkQWxpZ25tZW50U3BsaXR0ZXIuamF2YQ==) | `95% <ø> (ø)` | `18 <0> (ø)` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...discovery/prototype/SuspectedTransLocDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N1c3BlY3RlZFRyYW5zTG9jRGV0ZWN0b3IuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (-28.387%)` | `0 <0> (-13)` | |; | ... and [87 more](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255:3760,Simpl,SimpleStrandSwitchVariantDetector,3760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"ipt -e tempLibDir = '/cromwell_root/tmp/root/Rlib.5210694187065743072';source('/cromwell_root/tmp/root/CBS.8616708738798684646.R'); --args --sample_name=NA12878 --targets_file=/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv --output_file=small_NA12878.seg --log2_input=TRUE --min_width=2 --alpha=0.01 --nperm=10000 --pmethod=hybrid --kmax=25 --nmin=200 --eta=0.05 --trim=0.025 --undosplits=none --undoprune=0.05 --undoSD=3; Stdout: $sample_name; [1] ""NA12878"". $targets_file; [1] ""/cromwell_root/broad-dsde-methods/cromwell-execution-24/TumorOnly/f30dd8c6-eec3-45ba-b7f2-f845d308d59d/call-TumorNormalizeSomaticReadCounts/small_NA12878.tn.tsv"". $output_file; [1] ""small_NA12878.seg"". $log2_input; [1] ""TRUE"". $min_width; [1] 2. $alpha; [1] 0.01. $nperm; [1] 10000. $pmethod; [1] ""hybrid"". $kmax; [1] 25. $nmin; [1] 200. $eta; [1] 0.05. $trim; [1] 0.025. $undosplits; [1] ""none"". $undoprune; [1] ""0.05"". $undoSD; [1] 3. $help; [1] FALSE. Stderr: Error in sort(abs(diff(genomdat)))[1:n.keep] : ; only 0's may be mixed with negative subscripts; Calls: source ... segment -> inherits -> smooth.CNA -> trimmed.variance; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:163); 	at org.broadinstitute.hellbender.utils.segmenter.RCBSSegmenter.writeSegmentFile(RCBSSegmenter.java:114); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.applySegmentation(PerformSegmentation.java:185); 	at org.broadinstitute.hellbender.tools.exome.PerformSegmentation.doWork(PerformSegmentation.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:112); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944:2513,undo,undoprune,2513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944,1,['undo'],['undoprune']
Usability,"irichlet mixture of CNV subclones, to start. Graphical model is written down.; - [x] Implement basic algorithm; - CLI roughly implemented in sl_purity_ploidy_mcmc branch. Could stand some refactoring and code cleanup before it is PR ready and needs tests.; - [x] Algorithm improvements; - Currently, the model is initialized assuming a 50-50 normal-tumor split and only a clonal population. This is run for ~100 MCMC iterations, and the result is used to initialize a second run that expands the number of populations. This tends to work reasonably well, but there are situations where the model can get stuck in incorrect, degenerate solutions. Going to try adding some MH steps that will swap populations to see if these can help get the model unstuck.; - Need to add outlier absorption to the model, which appears to be critical for inference of subclonal populations from real data (i.e., ACNV output), which may have spurious segments, oversegmentation, etc. Simple clonal models appear to work reasonably well without this, though.; - [x] Evaluate algorithm on simulated data.; - Implemented simple Queue pipeline for running CLI on simulated ACNV segment files. Takes <2 minutes for ~1000 iterations for each sample, can run 100s of samples in parallel on the gsa clusters.; - Need to write up some scripts to automatically calculate and plot metrics.; - [x] Evaluate algorithm on real data; - Some initial runs on HCC1143 purity series show reasonable results for the clonal model, i.e., purity is recovered within credible intervals (question: what are the error bars on the purities of the samples?). Subclonal performance is a little less clear due to 1) no real ground truth, 2) events in the normal, and 3) lack of outlier absorption.; - Can we get a hold of some cleaner purity series?; - [ ] Document algorithm in technical whitepaper. ---. @samuelklee commented on [Thu Dec 08 2016](https://github.com/broadinstitute/gatk-protected/issues/750#issuecomment-265798051). The first releas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2909:1477,Simpl,Simple,1477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2909,1,['Simpl'],['Simple']
Usability,"is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that for ActiveRegion walkers it reflects the undownsampled depth subject to things like realignment to the haplotypes (easiest option, but doesn't fix the underlying craziness); 2. Change the ActiveRegion traversal so that it respects the dcov value (could be hard -- the LIBS downsampling process discards reads on-the-fly from previous loci when moving to a new locus, but an active region involves data for multiple loci. The potential performance win for the HC is huge, though, if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the ActiveRegion traversal fully respect dcov. I think Mark, in implementing the current scheme, might have been thinking that maintaining the undownsampled reads in memory is actually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid stor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:4629,undo,undownsampled,4629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"is anyone to give a clear description about CollectAllelicCounts, is this need if not doing paired?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5404:20,clear,clear,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5404,2,['clear'],['clear']
Usability,ist; 2022-08-16T00:09:07.4388607Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4389382Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:4: error: package com.google.common.collect does not exist; 2022-08-16T00:09:07.4390173Z src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/SomaticGenotypingEngine.java:5: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4395062Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/F1R2CountsCollector.java:3: error: package com.google.common.primitives does not exist; 2022-08-16T00:09:07.4411457Z src/main/java/org/broadinstitute/hellbender/utils/pileup/PileupBasedAlleles.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428203Z src/main/java/org/broadinstitute/hellbender/tools/walkers/readorientation/LearnReadOrientationModel.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4428971Z src/main/java/org/broadinstitute/hellbender/tools/walkers/annotator/StrandOddsRatio.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431031Z src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:3: error: package com.google.common.annotations does not exist; 2022-08-16T00:09:07.4431538Z [0K; 2022-08-16T00:09:07.4431680Z [0K; 2022-08-16T00:09:07.4431811Z [0K; 2022-08-16T00:09:07.4432994Z [3A[1m<[0;32;1m====[0;39;1m---------> 33% EXECUTING [45m 49s][m[39D[1B[1m> :testOnPackagedReleaseJar > 1727 tests completed[m[50D[1B[1m> :testOnPackagedReleaseJar > Executing test org...help.DocumentationGeneration[m[79D[1B[3A src/main/java/org/broadinstitute/hellbender/utils/variant/writers/SomaticGVCFWriter.java:4: error: package com.google.common.collect doe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480:19191,Learn,LearnReadOrientationModel,19191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217242480,1,['Learn'],['LearnReadOrientationModel']
Usability,it's a nice simple example of a locus walker. blocked by #1464,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1581:12,simpl,simple,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1581,1,['simpl'],['simple']
Usability,"ithm:. For each sample, get its PLs, get the best genotype based on those. Then for the alleles included in that genotype increase their ""best allele score"" by the GQ of the genotype. Then we chose those alleles that have the highest scores. I guess often this is ok when we are dealing with many samples and the ""good"" alleles are present in the top genotypes with high confidence in a few samples and the ""bad"" alleles are not. However one can see how this criterion fails when either we are working with just a few samples (e.g. 1 sample in HC GVCF mode) or with low coverage data. . For example with a single sample only the alleles in the best genotype may have a score different than 0. All the rest have the same probability of been picked up if maxAltAlleles gives us room for more. Despite that the likelihoods of other genotypes may indicate which ones are a better choice amongst the ""loosers"" we throw that info away.; ### Proposed solution. Simply do a quick and dirty AF estimation and choose the alleles with the larger frequencies. This estimate should use all the genotype likelihoods rather than just the top genotype giving a nominal score for all the alleles that would allow us to sort them all and make a better and less arbitrary selection. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-260486156). I believe this was done by @vruano and @SHuang-Broad already -- right guys? Can we close this? . ---. @SHuang-Broad commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1376#issuecomment-260684553). My understanding of the current state is that there are several possible places with alt allele reduction in HC, in order:; 1. The fix I put in, to prevent the calculator from becoming too slow or blow up, so downstream steps won't even include these alleles in their likelihood calculations;; 2. The fix Valentine put in, which happens after the read likelihoods are calcula",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2958:1661,Simpl,Simply,1661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2958,1,['Simpl'],['Simply']
Usability,"itute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f9afec0957; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:38:15 2017 -0500. fixed arg issues in somatic WDL; exposed all missing args to java side; major update to germline WDLs; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4978,progress bar,progress bar,4978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['progress bar'],['progress bar']
Usability,"itute/gatk/pull/2594?src=pr&el=h1) Report; > Merging [#2594](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2ecdef4fba1658930c388676be3e388efd67b6a3?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2594 +/- ##; ===============================================; + Coverage 75.985% 75.987% +0.003% ; - Complexity 11033 11034 +1 ; ===============================================; Files 769 769 ; Lines 40058 40058 ; Branches 6979 6979 ; ===============================================; + Hits 30438 30439 +1 ; Misses 6981 6981 ; + Partials 2639 2638 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <0%> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=footer). Last update [2ecdef4...a853f7c](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515:1630,learn,learn,1630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515,2,['learn'],['learn']
Usability,"ive you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFlB0vsaHipT7i0GC5BcMgDZsS2DHbpaks5uMHNmgaJpZM4SyZJV>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:1294,feedback,feedback,1294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340,2,['feedback'],['feedback']
Usability,java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /gatk/gatk-package-4.1.2.0-local.jar. ```. Here is my commands:. ```bash. gatk \; Mutect2 \; -R hg19.fa \; -I test.bam \; -L myDesign.bed \; --f1r2-tar-gz test.f1r2.tar.gz \; $filterGermline \; -O test-unfiltered.vcf. gatk \; LearnReadOrientationModel \; -I test.f1r2.tar.gz \; -O test.read-orientation-model.tar.gz. gatk \; FilterMutectCalls \; -R hg19.fa \; -V test-unfiltered.vcf \; --ob-priors test.read-orientation-model.tar.gz \; -O test.vcf; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6058:3237,Learn,LearnReadOrientationModel,3237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6058,1,['Learn'],['LearnReadOrientationModel']
Usability,"jbwa was just a proof-of-concept and a pretext to learn JNI. The algorithm was built on the ""simple"" API for BWA, but the internal 'mem' algorithm is much more complicated and the last time (2013) I looked at it, it was not easy to use it as a library (e.g. too many things in the `main`). I remember people at http://cloudgene.uibk.ac.at/ used it. . > FYI, I try to use jbwa in a MapReduce approach. If you interested, I can; > keep u posted.; > We implemented a framework for the execution of MapReduce jobs; > graphically and therefore new use cases are always nice",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-188414763:50,learn,learn,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-188414763,2,"['learn', 'simpl']","['learn', 'simple']"
Usability,"jects as keys; due to the fact that different contigs may produce the same variant; So what I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring dupl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2076,Simpl,SimpleChimera,2076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['Simpl'],['SimpleChimera']
Usability,"jopt-simple docs are here http://pholser.github.io/jopt-simple/. This should close #81, #111 and #67",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/135#issuecomment-70915198:5,simpl,simple,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135#issuecomment-70915198,2,['simpl'],['simple']
Usability,"k/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `86.025% <0%> (+4.561%)` | `30% <0%> (+6%)` | :arrow_up: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.805% <0%> (+4.805%)` | `8% <0%> (+3%)` | :arrow_up: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.297% <0%> (+7.018%)` | `33% <0%> (+11%)` | :arrow_up: |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `85.507% <0%> (+13.093%)` | `17% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `55.233% <0%> (+14.764%)` | `38% <0%> (+10%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=footer). Last update [d054e7a...8ecb688](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877:3770,learn,learn,3770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877,2,['learn'],['learn']
Usability,"kRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit\; --driver-memory 16G \; --num-executors 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it looks like it’s performing pretty well. There is very little data being shuffled relative to the size of the input (~6GB to 133GB input), so it’s not worth looking into optimizing the data structures there. The input data is being read multiple times, so it _might_ be worth seeing if it can be cached by Spark to avoid reading from disk over and over again. This is only worth it if you have sufficie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1684,simpl,simple,1684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,2,['simpl'],['simple']
Usability,kZW5jZS9GaW5kQmFkR2Vub21pY0ttZXJzU3BhcmsuamF2YQ==) | `48.039% <0%> (-3.35%)` | `17% <0%> (+4%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `83.636% <0%> (-2.727%)` | `34% <0%> (+6%)` | |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `84.848% <0%> (-1.818%)` | `15% <0%> (+5%)` | |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `32.673% <0%> (-0.915%)` | `25% <0%> (+12%)` | |; | [...sv/discovery/NovelAdjacencyReferenceLocations.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvTm92ZWxBZGphY2VuY3lSZWZlcmVuY2VMb2NhdGlvbnMuamF2YQ==) | `88.785% <0%> (-0.825%)` | `15% <0%> (+1%)` | |; | [...ls/spark/sv/discovery/GappedAlignmentSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvR2FwcGVkQWxpZ25tZW50U3BsaXR0ZXIuamF2YQ==) | `94.318% <0%> (-0.682%)` | `18% <0%> (ø)` | |; | ... and [62 more](https://codecov.io/gh/broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3653#issuecomment-333869239:3058,Simpl,SimpleStrandSwitchVariantDetector,3058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3653#issuecomment-333869239,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"l or two that use `PythonScriptExecutor` to call into a Python machine-learning library, and do an assessment of maintainability, etc. `PythonScriptExecutor` will come with an attached set of conditions for its use, intended to address the most serious issues raised by the engine and support teams with having Python code in the GATK. We should document these conditions in the docs for `PythonScriptExecutor` when it's implemented:. 1. All tools that use `PythonScriptExecutor` must have a Java-based front-end, with standard GATK (barclay-based) arguments. We put a lot of development effort into our arg parser and into striving for user-interface consistency across tools, and cannot afford to duplicate this effort in Python. Geraldine (CC'd) and the rest of the support team can back me up on this one!. 2. An honest effort should be made to minimize the amount of code written in Python -- as much of each tool's work as possible should be done in Java. In particular, reading/writing final inputs and outputs should happen in Java. This is important for a number of reasons, including the engine team's goal of ensuring universal GCS support, consistent Google authentication handling, etc. Again, we really don't want to have to duplicate that work in Python, or for the tools that call into Python to be inconsistent with the rest of the toolkit. 3. All dependencies (Python and native) of Python libraries used will be clearly documented, and included in the default GATK docker image. I don't think I need to explain why this one is important :) . 4. Before we go any further down this path, we prototype one or two tools using `PythonScriptExecutor`, and do a fair assessment of maintainability and other concerns of the engine/support teams, such as whether it will even be possible to package all dependencies without conflicts. 5. Engine team will continue to search for Java-based solutions while this evaluation is ongoing, but this proposal at least unblocks the CNV team for now.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3501:1613,clear,clearly,1613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501,1,['clear'],['clearly']
Usability,l/3668?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/tools/spark/sv/utils/GATKSVVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZDb25zdGFudHMuamF2YQ==) | `75% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/spark/sv/utils/RDDUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9SRERVdGlscy5qYXZh) | `0% <ø> (-80%)` | `0 <0> (-4)` | |; | [.../sv/discovery/prototype/InsDelVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0luc0RlbFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `28.571% <0%> (ø)` | `13 <0> (?)` | |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `55.652% <0%> (ø)` | `29 <0> (?)` | |; | [...nder/tools/spark/sv/discovery/SvTypeInference.java](https://codecov.io/gh/broadinstitute/gatk/pull/3668/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZUeXBlSW5mZXJlbmNlLmphdmE=) | `79.31% <100%> (ø)` | `7 <0> (?)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3668#issuecomment-334564884:1843,Simpl,SimpleStrandSwitchVariantDetector,1843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3668#issuecomment-334564884,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80% <100%> (ø)` | `119 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <20%> (-0.411%)` | `32 <0> (ø)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `81.818% <50%> (-8.182%)` | `6 <3> (+3)` | |; | [...stitute/hellbender/utils/genotyper/AlleleList.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvQWxsZWxlTGlzdC5qYXZh) | `89.744% <0%> (+1.282%)` | `16% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=footer). Last update [c62914a...cc1b2b9](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643:3833,learn,learn,3833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643,2,['learn'],['learn']
Usability,"l_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in master in the treatment of depth. I think the treatment here is quite natural and may be more robust than the current treatment. @mbabadi is going to take over tuning and tweaking the model from this point in the sl_simple_ploidy branch. Note that I haven't cleaned up some of the code and comments yet, but hopefully the changes are relatively clear. I believe I rebased on one of your other branches, so you should remove the corresponding commit and rebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:3488,clear,clear,3488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890,2,['clear'],['clear']
Usability,"lapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hellbender.tools.copynumber.utils.HDF5Utils.readIntervals(HDF5Utils.java:62); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.lambda$new; $2(HDF5SimpleCountCollection.java:76); 	at htsjdk.samtools.util.Lazy.get(Lazy.java:25); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.getInterva; ls(HDF5SimpleCountCollection.java:85); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readHDF5(Simpl; eCountCollection.java:119); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readAndSubset(; SimpleCountCollection.java:98); ```. with annotated_intervals.tsv . ```; $ grep -v '@' annotated_intervals.tsv | cat -n | head; 1	CONTIG	START	END	GC_CONTENT	SEGMENTAL_DUPLICATION_CONTENT; 2	chr1	10001	110000	0.422350	0.000000; 3	chr1	110001	177417	0.441046	0.000000; 4	chr1	227418	267719	0.391445	0.000000; 5	chr1	317720	417719	0.401850	0.000000; 6	chr1	417720	471368	0.471155	0.000000; 7	chr1	521369	621368	0.436950	0.000000; 8	chr1	621369	721368	0.428550	0.000000; 9	chr1	721369	821368	0.442210	0.000000; 10	chr1	821369	921368	0.606500	0.000000. $ grep -v '@' /annotated_intervals.tsv | cat -n | tail; 28717	chrY	28051429	28151428	0.372550	0.000000; 28718	chrY	28151429	28251428	0.380900	0.000000; 28719	chrY	28251429	28351428	0.390730	0.000000; 28720	chrY	28351429	28451428	0.381580	0.000000; 28721	chrY	28451429	28551428	0.394890	0.000000; 28722	chrY	28551429",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:4652,Simpl,Simpl,4652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['Simpl'],['Simpl']
Usability,"lbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Db250aWdBbGlnbmVyLmphdmE=) | `88.462% <88.889%> (+6.643%)` | `8 <4> (+8)` | :white_check_mark: |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <ø> (-43.75%)` | `3% <ø> (+3%)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2367/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=footer). Last update [9d82097...975121e](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:4931,learn,learn,4931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,2,['learn'],['learn']
Usability,"lbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `96.04% <0%> (+1.865%)` | `76 <0> (ø)` | :arrow_down: |; | [...bender/tools/exome/HashedListTargetCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9IYXNoZWRMaXN0VGFyZ2V0Q29sbGVjdGlvbi5qYXZh) | `90.741% <0%> (+1.65%)` | `43 <0> (ø)` | :arrow_down: |; | [.../utils/read/markduplicates/DuplicationMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0R1cGxpY2F0aW9uTWV0cmljcy5qYXZh) | `85.366% <0%> (+2.033%)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `89.404% <0%> (+0.588%)` | `68 <0> (ø)` | :arrow_down: |; | [...der/utils/locusiterator/AlignmentStateMachine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL0FsaWdubWVudFN0YXRlTWFjaGluZS5qYXZh) | `87.879% <0%> (+1.312%)` | `27 <1> (ø)` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=footer). Last update [62d58c5...cd59cde](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890:4194,learn,learn,4194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890,2,['learn'],['learn']
Usability,"le at PathSplitSource.java:96; 21/01/12 15:50:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 172.9 KB, free 9.2 GB); 21/01/12 15:50:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.5 KB, free 9.2 GB); 21/01/12 15:50:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:46619 (size: 35.5 KB, free: 9.2 GB); 21/01/12 15:50:33 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96; 21/01/12 15:50:33 INFO FileInputFormat: Total input files to process : 1; 21/01/12 15:50:33 INFO SparkUI: Stopped Spark web UI at http://fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:4040; 21/01/12 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/01/12 15:50:33 INFO MemoryStore: MemoryStore cleared; 21/01/12 15:50:33 INFO BlockManager: BlockManager stopped; 21/01/12 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/01/12 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/01/12 15:50:33 INFO SparkContext: Successfully stopped SparkContext; 15:50:33.855 INFO MarkDuplicatesSpark - Shutting down engine; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7035:5382,clear,cleared,5382,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035,1,['clear'],['cleared']
Usability,"le for output: file:/home/deepak/software_library/gatk-4.1.7.0/variants.funcotated.vcf; 16:01:44.020 INFO ProgressMeter - Starting traversal; 16:01:44.020 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:01:44.068 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr1:1-10454 due to alternate allele: <NON_REF>; 16:01:44.116 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 16:01:44.121 INFO Funcotator - Shutting down engine; [12 May, 2020 4:01:44 PM IST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.14 minutes.; Runtime.totalMemory()=2889875456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:-9 end:10464; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:733); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1439); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getBasesInWindowAroundReferenceAllele(FuncotatorUtils.java:1468); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationForSymbolicAltAllele(GencodeFuncotationFactory.java:2560); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFlankFuncotation(GencodeFuncotationFactory.java:2465); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:812); at org.broadinstitute.hellbender.tools.funcotator.dataSources.genco",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:6588,Simpl,SimpleInterval,6588,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['Simpl'],['SimpleInterval']
Usability,"le-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityAvailableReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter NotDuplicateReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter NonZeroReferenceLengthAlignmentReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter WellformedReadFilter`; [January 10, 2018 2:39:19 PM EST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 91.81 minutes.; Runtime.totalMemory()=7215251456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr5 start:71357769 end:71357768; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4120:1540,Simpl,SimpleInterval,1540,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120,1,['Simpl'],['SimpleInterval']
Usability,learn something from kmer-based M2 PoN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2973:0,learn,learn,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2973,2,['learn'],['learn']
Usability,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3487,Simpl,SimpleInterval,3487,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.co,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7166,Simpl,SimpleInterval,7166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,"lection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:13958,Simpl,SimpleInterval,13958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,lines 125-127 fix a bug: need to clear out 1st half window when we switch contigs; changes on lines 62-67 are cosmetic,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3268:33,clear,clear,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3268,1,['clear'],['clear']
Usability,ll/4653?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...decs/xsvLocatableTable/XsvLocatableTableCodec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MveHN2TG9jYXRhYmxlVGFibGUvWHN2TG9jYXRhYmxlVGFibGVDb2RlYy5qYXZh) | `77.512% <0%> (-5.204%)` | `67% <0%> (+7%)` | |; | [...g/broadinstitute/hellbender/utils/io/Resource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9SZXNvdXJjZS5qYXZh) | `55.263% <0%> (-0.292%)` | `7% <0%> (+1%)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `91.667% <0%> (ø)` | `6% <0%> (ø)` | :arrow_down: |; | [.../annotatedregion/SimpleAnnotatedGenomicRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZHJlZ2lvbi9TaW1wbGVBbm5vdGF0ZWRHZW5vbWljUmVnaW9uLmphdmE=) | `75.556% <0%> (ø)` | `10% <0%> (?)` | |; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `82.993% <0%> (+0.116%)` | `40% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4653/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `79.753% <0%> (+0.146%)` | `184% <0%> (-1%)` | :arrow_down: |; | [...ls/copynumber/utils/CombineSegmentBreakpoints.java](https://codecov.io,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-382141714:1843,Simpl,SimpleAnnotatedGenomicRegion,1843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-382141714,1,['Simpl'],['SimpleAnnotatedGenomicRegion']
Usability,"llable,CS_HiSeqPE100xfreebayes_callable,CS_10XSentieonhaplo_callable;filt=CS_CGnormal_filt GT:PS:DP:ADALL:AD:GQ 1|1:241815307_C_T:287:0,98:0,89:1; ```; </details>. while the test callset has the following single record:. <details>; <summary> Test callset </summary>. ```; chr2 241815307 . CA TG 1756.77 PASS AC=1;AF=0.5;AN=2;BaseQRankSum=-0.802;ClippingRankSum=0.521;DP=85;ExcessHet=3.0103;FS=2.902;MLEAC=1;MLEAF=0.5;MQ=60.0;MQRankSum=0.0;QD=20.67;ReadPosRankSum=-1.858;SOR=0.571 GT:AD:DP:F1R2:F2R1:GQ:PL 0/1:37,48:85:16,25,0:21,23,0:99:1785,0,1406; ```; </details>. Next, I looked at the reads from the haplotype assembly BAM supporting each of the three possible alleles in the test callset:. | Allele | # of reads |; | --- | --- |; | ref (`CA`) | 1 read |; | alt1 (`CG`) | 36 reads |; | alt 2 (`TG`) | 48 reads |. You can see the sum of the count of reads in the table is equal to the depth and sum of allelic depths in the VCF record. It is clear from the haplotype assembly BAM that the call should be `1/2` (`CG/TG`), but the finall call is `0/2` (`CA/TG`). . I then re-ran `HaplotypeCaller` without the `--max-mnp-distance 5` argument and got the variant call I expected, which matches the GIAB variant call:. <details>; <summary> Test callset without `--max-mnp-distance 5` </summary>. ```; chr2 241815307 . C T,<NON_REF> 1717.77 . BaseQRankSum=-1.137;ClippingRankSum=1.185;DP=83;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=298800,83;ReadPosRankSum=-1.967 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 0|1:36,47,0:83:15,24,0:21,23,0:99:0|1:241815307_C_T:1746,0,1375,1855,1516,3371:241815307:15,21,24,23; chr2 241815308 . A G,<NON_REF> 3429.77 . BaseQRankSum=0.293;ClippingRankSum=0.601;DP=83;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;MQRankSum=0.000;RAW_MQandDP=298800,83;ReadPosRankSum=-1.420 GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS:SB 1|1:1,82,0:83:1,38,0:0,44,0:99:0|1:241815307_C_T:3458,206,0,3461,246,3500:241815307:1,0,38,44; ```; </details>. I have a work-around where",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5696:2375,clear,clear,2375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696,1,['clear'],['clear']
Usability,"lly a throw-away intermediate file. As far as computational time, this is not that bad (at least for very small intervals/job). I also did not bother running consolidate on these, and imported with a batchSize of 50.; - With the limited interval GenomicsDB workspaces, GenotypeGVCFs runs reasonably well. . So some open questions:. - It's unclear why running GenotypeGVCFs with a GenomicsDB workspace that has intact chromosomes, even when using -L over a small interval, fails to run or runs painfully slowly with extremely high memory. I will try to find time for actual profiling, but this is a little cumbersome since I'm not sure I can run this on my windows dev machine. As noted above, given how awkward maintaining genomicsdb workspaces is, I'm currently thinking that we should view these as transient stores and not bother saving them after one use.; - The scatter method (i.e. many workspaces where each has a very small region) seems like a huge improvement for creating the workspaces. As far as designing intervals: I understand the guidance around quasi-manually defining a genome-specific interval set that puts the borders within SNP-poor and NNNN regions. This said, I wonder if we could simply create the workspace where we take the intervals and pad them by like 1kb or so? This would make the workspaces marginally bigger and duplicate those data, but in the grand scheme of things probably doesnt make much computational difference? One thing I need to verify (and would be great if you know this upfront), is whether using GenomicsDbImport with -L would include any gVCF variant that spans the intervals or whether it just includes gVCF variants that start in those intervals. If this is the former, when it seems like simply padding when creating the workspace and then running GenotypeGVCFs with the argument for ""only-output-genotypes-starting-in-intervals"" would be a genome-agnostic method that accomplishes the same thing?. Anyway, thanks for your continued help on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297:2202,guid,guidance,2202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297,6,"['guid', 'simpl']","['guidance', 'simply']"
Usability,"log4j system properly.; log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.; 23:01:58.560 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///omics/chatchawit/bundle/test/gencode/hg38/gencode.v27.chr_patch_hapl_scaff.annotation.REORDERED.gtf; 23:02:05.335 INFO ProgressMeter - Starting traversal; 23:02:05.337 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 23:02:06.530 INFO Funcotator - Shutting down engine; [April 27, 2018 11:02:06 PM ICT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=3420979200; java.lang.IllegalArgumentException: Invalid interval. Contig:ENST00000342066.7|ENSG00000187634.11|OTTHUMG00000040719.10|OTTHUMT00000276866.2|SAMD11-202|SAMD11|2551|protein_coding| start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getCodingSequenceFromTranscriptFasta(GencodeFuncotationFactory.java:418); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:1177); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotation(GencodeFuncotationFactory.java:619); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnTranscript(GencodeFuncotationFactory.java:575); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotations(GencodeFuncotationFactory.java:487); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.Genc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157:7320,Simpl,SimpleInterval,7320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385021157,1,['Simpl'],['SimpleInterval']
Usability,"louises proposals seems simple and reasonable.... perhaps it should offer to provide a ```Function<R, String>``` to provide a alternative ```toString``` in case the tools natural record ```toString``` does not align well with progress reporting... or perhaps in that case the tool could use an alternative record object that is send to the progress meter instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465:24,simpl,simple,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465,2,['simpl'],['simple']
Usability,"ls.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289). ```. #### Steps to reproduce; Here are the commands run. Can provide additional details if needed.; ```; gatk \; --java-options ""-Xmx32g"" \; M",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276:2695,learn,learnParameters,2695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276,1,['learn'],['learnParameters']
Usability,ls/TagGermlineEventsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `7.759% <0%> (-92.241%)` | `2 <0> (-7)` | |; | [...titute/hellbender/utils/IntervalUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzVW5pdFRlc3QuamF2YQ==) | `91.916% <100%> (+0.204%)` | `144 <2> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.474% <100%> (+0.123%)` | `185 <5> (+5)` | :arrow_up: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [.../germlinetagging/SimpleGermlineTaggerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2dlcm1saW5ldGFnZ2luZy9TaW1wbGVHZXJtbGluZVRhZ2dlclVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...geAnnotatedRegionsByAnnotationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9uc0J5QW5ub3RhdGlvbkludGVncmF0aW9uVGVzdC5qYXZh) | `16.667% <16.667%> (ø)` | `2 <2> (?)` | |; | ... and [183 more](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050:3523,Simpl,SimpleGermlineTaggerUnitTest,3523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050,1,['Simpl'],['SimpleGermlineTaggerUnitTest']
Usability,ls/codecs/gencode/GencodeGtfFeature.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MvZ2VuY29kZS9HZW5jb2RlR3RmRmVhdHVyZS5qYXZh) | `78.977% <0%> (+0.189%)` | `42% <0%> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (+0.851%)` | `66% <0%> (+2%)` | :arrow_up: |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `86.339% <0%> (+1.516%)` | `170% <0%> (+50%)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `84.884% <0%> (+2.027%)` | `19% <0%> (+2%)` | :arrow_up: |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `88.312% <0%> (+3.998%)` | `30% <0%> (+13%)` | :arrow_up: |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/3985/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `81.654% <0%> (+5.389%)` | `102% <0%> (+47%)` | :arrow_up: |; | [...itute/h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3985#issuecomment-352158326:2879,Simpl,SimpleKeyXsvFuncotationFactory,2879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3985#issuecomment-352158326,1,['Simpl'],['SimpleKeyXsvFuncotationFactory']
Usability,"lse; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3845,Learn,LearnReadOrientationModel,3845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"lse; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6852,Learn,LearnReadOrientationModel,6852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"lse; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:19:00.371 INFO BaseRecalibratorSpark - Defaults.USE_CRAM_REF_DOWNLOAD : false; 17:19:00.371 INFO BaseRecalibratorSpark - Deflater IntelDeflater; 17:19:00.372 INFO BaseRecalibratorSpark - Inflater IntelInflater; 17:19:00.372 INFO BaseRecalibratorSpark - Initializing engine; 17:19:00.372 INFO BaseRecalibratorSpark - Done initializing engine; 17:19:00.872 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java clas; 17:22:09.153 INFO BaseRecalibratorSpark - Shutting down engine; [May 17, 2017 5:22:09 PM UTC] org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 3.15 min; Runtime.totalMemory()=15504244736; java.lang.ArrayIndexOutOfBoundsException: 1073741865; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:195); at org.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236)atorg.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236)atorg.apache.spark.broadcast.TorrentBroadcast; anonfun$blockifyObject$2.apply(TorrentBroadcast.scala:236); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); at org.apache.spark.broadcast.TorrentBroadcast$.blockifyObject(TorrentBroadcast.scala:237); at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:107); at org.apache.spark.broadcast.TorrentBroadcast.(TorrentBroadcast.scala:86); at org.apache.spark.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2732:3561,clear,clear,3561,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2732,1,['clear'],['clear']
Usability,ltiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:134); 	at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. #### Steps to reproduce; The error occurs when running a command: ; ```; gatk Mutect2 -R /home/genome/gatk.hg38/Homo_sapiens_assembly38.fasta -L panel_collapsed.bed -I bam/tumour_recalibrated.bam -I bam/normal_recalibrated.bam -tumor tumour -normal normal -germline-resource /home/genome/gatk.hg38/af-only-gnomad.hg38.vcf.gz -pon /home/genome/pon/PON_B1.vcf --genotype-pon-sites --f1r2-tar-gz results/learnOrientation/tumour_lo.tar.gz -O results/Mutect2/tumour.s.vcf.gz -bamout bam/tumour.mutect2.bam --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter --af-of-alleles-not-in-resource 0.000001; ```. #### Expected behavior; Mutect2 producing outputs. #### Actual behavior; Full log: ; [Mutect2_error.txt](https://github.com/broadinstitute/gatk/files/8772744/Mutect2_error.txt). ---. I would be grateful if you could help me to investigate the cause of this error. I couldn't find any clues when googling it and tried `picard ValidateSamFile` but it returns no errors or warnings. Many thanks!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7872:2646,learn,learnOrientation,2646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7872,1,['learn'],['learnOrientation']
Usability,"lues for a even-length list (see Utils::getMedianValue). So the non-AS rank sums end up getting the better of the two values, which aren't even derived from the data they're supposed to represent. Alleles for the win! (The values are slightly different because the AS values get `floor`ed to the nearest tenth as part of the annotation.). Raw data for QD(34.34) vs AS_QD (2.83):; `X 13681128 . G A,C,<NON_REF> . . AS_RAW_BaseQRankSum=|-1.900,1,-1.800,1||;AS_RAW_MQRankSum=|-5.800,1,0.300,1||;AS_RAW_ReadPosRankSum=|1.000,1,1.200,1||;AS_SB_TABLE=99,68|2,2|35,20|0,0;; BaseQRankSum=-1.783e+00;MQRankSum=0.302;RAW_MQ=800193.00;ReadPosRankSum=1.29`; Genotypes with alt reads here are:; `GT:AD:PL`; `./.:53,2,0,0:0,116,1821,159,1827,1870,159,1827,1870,1870; ./.:0,0,55,0:1947,1947,1947,165,165,0,1947,1947,165,1947; ./.:114,2,0,0:0,299,3972,342,3978,4021,342,3978,4021,4021`; In the genotyped VC the A gets dropped and C gets AC=2 (one homVar). Again, we're seeing representation of the dropped alt only in homRef samples. The non-AS rank sum behavior here sucks too, but we're after QD. Unfortunately, most of the work for QD gets done inside GenotypeGVCFs, so I had to debug. AS_QD uses the per-allele probability of AC=0 (so it allows for AC>0 for other alts), which is the same as the probability of all samples being homRef if there's only one alt. In cases like this where there's another alt with some weight in the PLs (however small) then those probabilities will not be the same. Honestly I'm surprised by how different they are -- -188.9 for the log10(P(all homRef)) vs -15.55 for the log10(P(high quality alt AC = 0)). In summary, these data show that the discrepancies in a small subset of cases are expected because biallelics will be the same, but those discrepant sites are not true biallelics. I will also look into the AS_QD calc for multi-allelics. Clearly from the cloud around 30 the AS_QD is maxing out in some cases. This is my opportunity to fix that and finally remove the jitter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-393584192:3124,Clear,Clearly,3124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-393584192,1,['Clear'],['Clearly']
Usability,ly(RDD.scala:710); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); 	at org.apache.spark.scheduler.Task.run(Task.scala:89); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 16/11/16 23:25:11 INFO SparkUI: Stopped Spark web UI at http://172.32.65.22:4040; 16/11/16 23:25:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 16/11/16 23:25:11 INFO MemoryStore: MemoryStore cleared; 16/11/16 23:25:11 INFO BlockManager: BlockManager stopped; 16/11/16 23:25:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 16/11/16 23:25:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 16/11/16 23:25:11 INFO SparkContext: Successfully stopped SparkContext; 16/11/16 23:25:11 INFO ShutdownHookManager: Shutdown hook called; 16/11/16 23:25:11 INFO ShutdownHookManager: Deleting directory /gpfs/ngsdata/sparkcache/spark-29e7cb29-06dd-4145-ad9a-aa75971badb8; 16/11/16 23:25:11 INFO ShutdownHookManager: Deleting directory /gpfs/ngsdata/sparkcache/spark-29e7cb29-06dd-4145-ad9a-aa75971badb8/httpd-7370bdc2-eb41-46d1-9512-2f387b972cac; 16/11/16 23:25:11 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.; + /spark-1.6.2-bin-hadoop2.6//sbin/stop-master.sh,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2268:25067,clear,cleared,25067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2268,1,['clear'],['cleared']
Usability,"m.google.cloud.genomics.gatk.common. I've been working on this bam file issue, correcting errors in the files used for tests. Many of the errors involve reads with FLAGs that indicate that they are in pairs, but the mate is not extant in the file, causing the error. A way to fix this without deleting the offending reads is to set the FLAG to zero and also modify the RNEXT, PNEXT, and TLEN fields, if necessary, so that the read becomes single (provided that the values of all of these fields are not important for the tests). However, when I do this, I find that tests that write and then read bam files fail, because when the just-written file is read back, SAM validation complains that the mate unmapped FLAG is set for an unpaired read. It turns out that the copy of the file written by the test substitutes the value '8' for '0' as the FLAG for the modified reads. The relevant code in GenomicsConvertermakeSamRecord() (line 170) is:. flags += ((read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The effect of this line is that all reads which have null mate positions, even those which the FLAG specifies as unpaired, get the mate unmapped FLAG set, causing the validation errors that i'm seeing. The reason the tests have not failed before is apparently that the existing test files do not contain any reads with FLAGs that specify them as unpaired. A simple fix for this would be to convert the line above to:. flags += ( paired && (read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The redundant parens in the original code suggest that something like this may have been intended,but the google genomics documentation at http://google-genomics.readthedocs.org/en/latest/migrating_tips.html gives the following pseudocode:. flags += read.nextMatePosition.position == null ? 8 : 0 #mate_unmapped. so it looks like the doc supports the existing code. Should I submit this as an issue? . Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033:1566,simpl,simple,1566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033,1,['simpl'],['simple']
Usability,"mE=) | `96.87% <85.71%> (-1.46%)` | `15 <1> (+1)` | |; | [...lotypecaller/AssemblyBasedCallerUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHNVbml0VGVzdC5qYXZh) | `95.77% <95.28%> (-4.23%)` | `45 <43> (+43)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `90.14% <0%> (+0.4%)` | `143% <0%> (ø)` | :arrow_down: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=footer). Last update [8103bde...7d53fb9](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744:4580,learn,learn,4580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744,2,['learn'],['learn']
Usability,make and use a clear convention for the naming of all test files,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1273:15,clear,clear,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1273,2,['clear'],['clear']
Usability,"me: readArguments, type: class org.broadinstitute.hellbender.cmdline.argumentcollections.ReadInputArgumentCollection); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts@5aef1838); - element of array (index: 0); - array (class [Ljava.lang.Object;, size 2); - field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.Object;); - object (class java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts, functionalInterfaceMethod=org/apache/spark/api/java/function/Function.call:(Ljava/lang/Object;)Ljava/lang/Object;, implementation=invokeSpecial org/broadinstitute/hellbender/tools/genome/SparkGenomeReadCounts.lambda$collectReads$24c02dc7$2:(Lhtsjdk/samtools/SAMSequenceDictionary;Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/utils/SimpleInterval;, instantiatedMethodType=(Lorg/broadinstitute/hellbender/utils/read/GATKRead;)Lorg/broadinstitute/hellbender/utils/SimpleInterval;, numCaptured=2]); - writeReplace data (class: java.lang.invoke.SerializedLambda); - object (class org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts$$Lambda$1140/887035829, org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts$$Lambda$1140/887035829@1a912c1e); - field (class: org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, name: fun$1, type: interface org.apache.spark.api.java.function.Function); - object (class org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, <function1>); at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40); at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47); at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101); at org.apache.spark.util.ClosureCleaner$.ensur",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2003:4434,Simpl,SimpleInterval,4434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2003,2,['Simpl'],['SimpleInterval']
Usability,"ment-85098560). I assume ambiguous basecalls in reads are ignored and therefore not an issue. It's really what to do with ambiguous ref bases that concerns me. Currently it seems that HC just accepts them as legitimate bases in certain conditions at least. . I'm not sure I understand this part:. > Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. That comes down to randomly assigning a ref allele at that site, doesn't it? I'm not sure I'm comfortable with that. ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85121261). Not random, A has priority, then C, then G and finally T amongst those that are compatible with the ambiguous code. For Example for N it would be A, but for B would C (as B means C/G/T(U)). ---. @vdauwera commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85123717). Well, I understand that it's alphabetical, but I mean it's not really meaningful -- it's even worse than random since the choice is biased by whatever accident of history caused A to be earlier in the alphabet than C. To be clear I don't have a better idea, but this one bugs me. ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85134672). I think this bias is nothing compare with the one introduced by the reference itself. I don't see why it should it even be part of the VCF output but that would even bug more people. . In any case I think that is the way HC should handle ambiguity internally ... . if instead of having a separate tool to re-ambiguate we do it standard at the last step of HC that should be fine but then I don't know if we would be able to make every body happy at the same time.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:3973,clear,clear,3973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['clear'],['clear']
Usability,"meout; 5. ERROR ShutdownHookManager: ShutdownHookManger shutdown forcefully.; 6. /var/spool/slurmd/job1619084/slurm_script: line 126: syntax error: unexpected end of file. In that order. I'm running this script in parallel on a SLURM scheduler (four cpus with 8Gb mem/cpu). Here is a sample of the last few lines of STDERR, but I'm also attaching the full error output.; [pathseq_TCGA.slurm.1619078_1.err.txt](https://github.com/broadinstitute/gatk/files/1965063/pathseq_TCGA.slurm.1619078_1.err.txt). Thanks so much for any help you can provide!. `; 18/05/01 14:20:59 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.12.137.46, 39719, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),127561,0)); 18/05/01 14:21:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/05/01 14:23:29 INFO MemoryStore: MemoryStore cleared; 18/05/01 14:23:29 INFO BlockManager: BlockManager stopped; 18/05/01 14:23:29 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/05/01 14:24:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/05/01 14:25:36 INFO SparkContext: Successfully stopped SparkContext; 14:25:37.027 INFO PathSeqPipelineSpark - Shutting down engine; [May 1, 2018 2:25:37 PM EDT] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 37.98 minutes.; Runtime.totalMemory()=23999283200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 20 in stage 1.0 failed 1 times, most recent failure: Lost task 20.0 in stage 1.0 (TID 891, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 131031 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4725:1334,clear,cleared,1334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4725,1,['clear'],['cleared']
Usability,"mmandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:5083,Learn,LearnReadOrientationModel,5083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"mmandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx6500m -jar /root/gatk.jar FilterMutectCalls -V gs://fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-MergeVCFs/Abrams_cell-unfiltered.vcf -R gs://fc-0b0cb3ce-e2cb-4aef-a8b2-08e60d78e87c/Canis_lupus_familiaris_assembly3.fasta -O Abrams_cell-filtered.vcf --contamination-table /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-CalculateContamination/contamination.table --tumor-segmentation /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-CalculateContamination/segments.table --ob-priors /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-LearnReadOrientationModel/artifact-priors.tar.gz -stats /cromwell_root/fc-afa03a31-404c-4a93-9f6a-31b673db5c69/0bbb4e0e-7293-4ce5-b81f-d722fcec561a/Mutect2/223610c8-ec63-4439-b339-9503ceb80828/call-MergeStats/merged.stats --filtering-stats filtering.stats --min-median-read-position 10; ```. Both of these tests were run on an interval that included a single chromosome (approximately 24Mb). Thank you for your help!. Best,; Kate. This Issue was generated from your [forums] ; [forums]: https://gatkforums.broadinstitute.org/gatk/discussion/24345/m2-error-with-canine-germline-resource-and-variants-for-contamination-files/p1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:9769,Learn,LearnReadOrientationModel,9769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['Learn'],['LearnReadOrientationModel']
Usability,more tests for SimpleInterval.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1497:15,Simpl,SimpleInterval,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1497,1,['Simpl'],['SimpleInterval']
Usability,mplexity Δ | |; |---|---|---|---|; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `80.444% <100%> (ø)` | `45 <0> (ø)` | :arrow_down: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `13 <4> (ø)` | :arrow_down: |; | [...lbender/utils/iterators/IntervalLocusIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvSW50ZXJ2YWxMb2N1c0l0ZXJhdG9yLmphdmE=) | `92.593% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `93.182% <0%> (ø)` | `48% <0%> (ø)` | :arrow_down: |; | [...lkers/variantutils/ReblockGVCFIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRkludGVncmF0aW9uVGVzdC5qYXZh) | `97.826% <0%> (ø)` | `8% <0%> (ø)` | :arrow_down: |; | [...institute/hellbender/utils/help/HelpConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `4.167% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...ls/genomicsdb/GenomicsDBImportIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458731657:1906,Simpl,SimpleInterval,1906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458731657,1,['Simpl'],['SimpleInterval']
Usability,multithreading needs to be removed from Hellbender code. Code then needs to be simplified accordingly.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/401:79,simpl,simplified,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/401,1,['simpl'],['simplified']
Usability,n(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:944); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); 	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.makeInterpretation(SimpleNovelAdjacencyInterpreter.java:48); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.extractSimpleVariants(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:328); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.dispatchJobs(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:303); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.runTool(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:170); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:534); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:5908,Simpl,SimpleNovelAdjacencyInterpreter,5908,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,n.scala:79); 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133); 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856); 	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387); 	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360); 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239); 	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:789); 	at StudentAws$.delayedEndpoint$StudentAws$1(StudentAws.scala:36); 	at StudentAws$delayedInit$body.apply(StudentAws.scala:8); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at StudentAws$.main(StudentAws.scala:8); 	at StudentAws.main(StudentAws.scala); 23/11/16 12:09:10 INFO SparkContext: Invoking stop() from shutdown hook; 23/11/16 12:09:10 INFO SparkContext: SparkContext is stopping with exitCode 0.; 23/11/16 12:09:10 INFO SparkUI: Stopped Spark web UI at http://SRINIVASiNDRARAVI:4040; 23/11/16 12:09:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 23/11/16 12:09:10 INFO MemoryStore: MemoryStore cleared; 23/11/16 12:09:10 INFO BlockManager: BlockManager stopped; 23/11/16 12:09:10 INFO BlockManagerMaster: BlockManagerMaster stopped; 23/11/16 12:09:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 23/11/16 12:09:10 INFO SparkContext: Successfully stopped SparkContext; 23/11/16 12:09:10 INFO ShutdownHookManager: Shutdown hook called; 23/11/16 12:09:10 INFO ShutdownHookManager: Deleting directory C:\Users\SRINI\AppData\Local\Temp\spark-a5d9bd91-5f37-4677-8a41-0bdf406d0929,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8587:13610,clear,cleared,13610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8587,1,['clear'],['cleared']
Usability,"nEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; A second case involved `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336:3395,simpl,simpleMerge,3395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336,1,['simpl'],['simpleMerge']
Usability,"nReadOrientationModel - Context CCG: with 143118 ref and 4274 alt examples, EM converged in 14 steps; 12:16:35.567 INFO LearnReadOrientationModel - Context CGA: with 74445 ref and 2480 alt examples, EM converged in 14 steps; 12:16:36.368 INFO LearnReadOrientationModel - Context CGC: with 115334 ref and 3741 alt examples, EM converged in 14 steps; 12:16:36.931 INFO LearnReadOrientationModel - Context CTA: with 173673 ref and 1472 alt examples, EM converged in 13 steps; 12:16:37.537 INFO LearnReadOrientationModel - Context CTC: with 439622 ref and 3855 alt examples, EM converged in 12 steps; 12:16:38.010 INFO LearnReadOrientationModel - Context GAA: with 333082 ref and 2101 alt examples, EM converged in 11 steps; 12:16:38.546 INFO LearnReadOrientationModel - Context GAC: with 227508 ref and 2090 alt examples, EM converged in 12 steps; 12:16:39.384 INFO LearnReadOrientationModel - Context GCA: with 340865 ref and 6507 alt examples, EM converged in 14 steps; 12:16:40.330 INFO LearnReadOrientationModel - Context GCC: with 404793 ref and 8210 alt examples, EM converged in 14 steps; 12:16:41.107 INFO LearnReadOrientationModel - Context GGA: with 409382 ref and 6784 alt examples, EM converged in 13 steps; 12:16:41.620 INFO LearnReadOrientationModel - Context GTA: with 153202 ref and 1568 alt examples, EM converged in 12 steps; 12:16:42.114 INFO LearnReadOrientationModel - Context TAA: with 208518 ref and 1131 alt examples, EM converged in 12 steps; 12:16:42.902 INFO LearnReadOrientationModel - Context TCA: with 325628 ref and 6437 alt examples, EM converged in 13 steps; 12:16:43.443 INFO LearnReadOrientationModel - Context AAA: with 426193 ref and 2055 alt examples, EM converged in 12 steps; 12:16:43.452 INFO LearnReadOrientationModel - Shutting down engine; [November 26, 2018 12:16:43 PM EST] org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModel done. Elapsed time: 0.39 minutes.; Runtime.totalMemory()=1543503872; Tool returned:; SUCCESS; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:6571,Learn,LearnReadOrientationModel,6571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,8,['Learn'],['LearnReadOrientationModel']
Usability,"nVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (ø)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=footer). Last update [51360c7...51285dc](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:4915,learn,learn,4915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,2,['learn'],['learn']
Usability,nches 10179 11987 +1808 ; ===============================================; + Hits 50460 56366 +5906 ; - Misses 8648 9368 +720 ; - Partials 3985 4276 +291; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4735?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4735/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `80.612% <26.667%> (+5.726%)` | `55 <0> (+14)` | :arrow_up: |; | [...ce/AssemblyContigAlignmentSignatureClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/4735/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50U2lnbmF0dXJlQ2xhc3NpZmllci5qYXZh) | `58.602% <0%> (-25.269%)` | `30% <0%> (-10%)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4735/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `80.435% <0%> (-19.565%)` | `16% <0%> (+9%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4735/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `88.889% <0%> (-4.659%)` | `45% <0%> (+23%)` | |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/4735/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `91.667% <0%> (-3.571%)` | `11% <0%> (+2%)` | |; | [...r/arguments/CopyNumberArgumen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4735#issuecomment-386333319:1631,Simpl,SimpleNovelAdjacencyInterpreter,1631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4735#issuecomment-386333319,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3112,learn,learn,3112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['learn'],['learn']
Usability,nder/tools/spark/sv/utils/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlV0aWxzLmphdmE=) | `54.487% <0%> (-24.965%)` | `23 <0> (+7)` | |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `44.355% <0%> (+1.719%)` | `24 <0> (ø)` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ark/sv/discovery/prototype/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...pe/AssemblyContigAlignmentSignatureClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/3806?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50U2lnbmF0dXJlQ2xhc3NpZmllci5qYXZh) | `0% <0%> (ø)` | `0 <0> (?)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3806#issuecomment-342541788:3217,Simpl,SimpleStrandSwitchVariantDetector,3217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3806#issuecomment-342541788,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"negligible and dates back to pre-4.0 release. Another concern is that the number of users of this unsupported code is also growing. In fact, it seems like we are actively pointing users to it. This seems unsustainable going forward. Finally, I don't think we have satisfactorily demonstrated which of the functions accomplished by this code (format conversion, post-hoc blacklisting, germline/""CNLOH"" tagging and imputation) are necessary or cannot be performed by existing code or more streamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1331,feedback,feedback,1331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['feedback'],['feedback']
Usability,"nel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:748); 18/04/24 17:42:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:42:11 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:42:11 INFO BlockManager: BlockManager stopped; 18/04/24 17:42:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:42:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:42:11 INFO SparkContext: Successfully stopped SparkContext; 17:42:11.053 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:42:11 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=866648064; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:38456,clear,cleared,38456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['clear'],['cleared']
Usability,"nflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 12:16:28.813 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 12:16:29.461 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 12:16:29.940 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 12:16:30.524 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 12:16:31.007 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3969,Learn,LearnReadOrientationModel,3969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"nflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6527 alt examples, EM converged in 13 steps; 16:21:06.995 INFO LearnReadOrientationModel - Context AGG: with 494947 ref and 7682 alt examples, EM converged in 14 steps; 16:21:07.497 INFO LearnReadOrientationModel - Context ATA: with 180560 ref and 1078 alt examples, EM converged in 12 steps; 16:21:07.964 INFO LearnReadOrientationModel - Context ATC: with 213079 ref and 1522 alt examples, EM converged in 11 steps; 16:21:08.549 INFO LearnReadOrientationModel - Context ATG: with 282561 ref and 2106 alt examples, EM converged in 12 steps; 16:21:09.030 INFO LearnReadOrientationModel - Context CAA: with 284942 ref and 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6976,Learn,LearnReadOrientationModel,6976,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"nflater; 16:36:22.399 INFO Funcotator - GCS max retries/reopens: 20; 16:36:22.399 INFO Funcotator - Requester pays: disabled; 16:36:22.399 INFO Funcotator - Initializing engine; 16:36:22.624 INFO FeatureManager - Using codec VCFCodec to read file file:///home/ppshah/shared/CAS_MOSAIC/mutect/mrn_2507919/WES/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC/KShaw-ROPR0004-DNA-229761-WX01-T_HMCKJDSX2-4-ATTGGCTC_filtered.vcf.gz; 16:36:22.842 INFO Funcotator - Done initializing engine; 16:36:22.842 INFO Funcotator - Validating sequence dictionaries...; 16:36:22.856 INFO Funcotator - Processing user transcripts/defaults/overrides...; 16:36:22.857 INFO Funcotator - Initializing data sources...; 16:36:22.859 INFO DataSourceUtils - Initializing data sources from directory: /home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s; 16:36:22.871 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 16:36:22.871 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.871 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 16:36:22.891 INFO Funcotator - Shutting down engine; [January 10, 2024 at 4:36:22 PM GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=285212672; ***********************************************************************. A USER ERROR has occurred: ERROR: Directory contains more than one config file: file:///home/ppshah/shared/pipelines/mutect/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Any guidance to resolve the issue is appreciated.; Thank you!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8647:5202,guid,guidance,5202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8647,1,['guid'],['guidance']
Usability,"nno.tsv.gz.tbi; |; |- hg38; | |- cadd.config; | |- InDels_inclAnno.tsv; | |- InDels_inclAnno.tsv.gz.tbi; ```; The config file (cadd.config); ```; name = CADD; version = v1.4; src_file = InDels_inclAnno.tsv; origin_location =; preprocessing_script = UNKNOWN. Whether this data source is for the b37 reference.; Required and defaults to false.; isB37DataSource = false. Supported types:; simpleXSV -- Arbitrary separated value table (e.g. CSV), keyed off Gene Name OR Transcript IDlocatableXSV -- Arbitrary separated value table (e.g. CSV), keyed off a genome locationgencode -- Custom datasource class for GENCODEcosmic -- Custom datasource class for COSMIC vcf -- Custom datasource class for Variant Call Format (VCF) files; type = locatableXSV; Required field for GENCODE files.Path to the FASTA file from which to load the sequences for GENCODE transcripts:; gencode_fasta_path =. Required field for GENCODE files.; NCBI build version (either hg19 or hg38):; ncbi_build_version =. Required field for simpleXSV files.; Valid values:; GENE_NAME; TRANSCRIPT_ID; xsv_key = GENE_NAME. Required field for simpleXSV files.; The 0-based index of the column containing the key on which to match; xsv_key_column =. Required field for simpleXSV AND locatableXSV files.; The delimiter by which to split the XSV file into columns.; xsv_delimiter = \t. Required field for simpleXSV files.; Whether to permissively match the number of columns in the header and data rows; Valid values:truefalse; xsv_permissive_cols =. Required field for locatableXSV files.; The 0-based index of the column containing the contig for each row; contig_column = 0. Required field for locatableXSV files.The 0-based index of the column containing the start position for each row; start_column = 1. Required field for locatableXSV files.; The 0-based index of the column containing the end position for each row; end_column = 1; ```. A snapshot of InDels_inclAnno.tsv:; ```; Chrom Pos Ref Alt Type Length AnnoType Consequence ConsScor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223:5421,simpl,simpleXSV,5421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223,1,['simpl'],['simpleXSV']
Usability,"nnot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5732,simpl,simply,5732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['simpl'],['simply']
Usability,no reason to depend on spark when we depend on spark ML lib anyway. Simpler to update 1 dependency than two. @lbergelson wdyt?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2035:68,Simpl,Simpler,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2035,1,['Simpl'],['Simpler']
Usability,not much code here so simple comments only. Absence of another `ReadShard` is weird and more comments would be useful. LGTM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-233708552:22,simpl,simple,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-233708552,1,['simpl'],['simple']
Usability,"now that we have the logic updated for per-assembly-contig view when it comes to SV type and breakpoint location inference, the next step is to take the comprehensive view, that is. * inter-contig view, i.e. mappings of other contigs nearby a potential breakpoint when inferring types ; * depth/coverage information; * evidence target links, i.e pair and split read information. To illustrate: consider a dispersed duplication, where the reference has sequence blocks `A z B` and the sample has sequence blocks arranged as `A z A B`.; Having assembled across the novel adjacency across the `A B` block, simply looking at the contig's alignment may fool us into calling a deletion&mdash;exactly what we are doing now&mdash;while it apparently is the wrong type.; On the other hand, if we have assembled across the `z A` block, without checking depth information, we might be thinking the blocks `A z` is being duplicated (we are not currently, but rather emit `BND` novel adjacency between the reference locations instead of emitting a duplication).; In the better (but not best, which we would have assembled across the whole event and the code currently would correctly emit the correct interpretation) scenario, we could have assembled across both novel adjacencies, and the increased coverage at `A` block, as well as outties pair linking `B` and `A` block, would allow us to formulate the whole picture.; Though difficult, it is what we must do. This ticket is to remind us that when we code our logic in any of these units, be open to other units for a comprehensive model on inference.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4189:603,simpl,simply,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4189,1,['simpl'],['simply']
Usability,"nshot 2018-01-17 13 22 27"" src=""https://user-images.githubusercontent.com/11543866/35060379-501cb8c8-fb8c-11e7-845e-a146fc2ced94.png"">. ## Major wants; - The is_bamout Boolian appears to be hardcoded to `false` in the script. Users need to be able to understand that this option can be changed without ambiguity. So this should become a proper optional variable. @LeeTL1220 tells me this can be overwritten. However, why leave this as misinterpretable to newbie WDL-scriptors? Especially since `wdltools inputs` doesn't include it as a variable at all in the generated inputs list. Please can we make this a proper optional argument that `wdltools inputs` will generate a variable for.; - [ ""${variants_for_contamination}"" == *.vcf ] does not allow *.vcf.gz files. It should accept either.; - Outputs should allow either .vcf or .vcf.gz compression by user-specification. Alternatively, if we want to keep it simple and hardcode, then the preference is for compressed files. Some of us prefer to save on storage.; - Need to be able to specify optional string args for SplitIntervals. I would like to be able to use the BALANCING_WITHOUT_INTERVAL_SUBDIVISION mode. Furthermore, I'd like for the tool to automatically interpret this mode, when not given an -L intervals list, to not split reference contigs. I.e. a contig is an interval. (Perhaps already the tool behavior?); - The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator? . ## Minor wants; - The JSON template in the repo should show the optional variables.; - Script calls for a Picard jar. I don't mind specifying this because I like controlling for the Picard version I use. However, users may want to call the Picard version within the GATK jar. I cannot fathom a simple way to allow switching this out in the script, but perhaps something like the gatk_override option could work. The goal would be to call the Picard tool from a Docker. This better enables provenance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188:1968,simpl,simple,1968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188,1,['simpl'],['simple']
Usability,nstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165). at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.main(Main.java:292); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:5459,learn,learnParameters,5459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['learn'],['learnParameters']
Usability,"nstitute/gatk-protected/issues/950#issuecomment-288598906). The new qual score doesn't subset alleles at all because it doesn't need to. `AlleleSubsettingUtils` handles this upstream of the new qual. We're waiting on the HaplotypeCaller tie-out to eliminate the old qual from GATK 4, however. ---. @vdauwera commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288599388). Ah, do I understand correctly that if the new qual checks out and the old one can be eliminated, this issue no longer applies?. ---. @davidbenjamin commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288601472). Well, it's possible that people aren't satisfied with allele reduction in general (@vruano and @SHuang-Broad have thoughts on this, I believe), but it won't have anything to do with the `AFCalculator`. ---. @davidbenjamin commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288601998). @vdauwera And just to be clear, if I understood correctly everyone was satisfied in November with the new qual and we are just waiting for *HaplotypeCaller* to check out in GATK 4 before making any changes like pulling the plug on the old qual. The reason is that we're looking for GATK 4 results to match as exactly as possible and subbing in the new qual would complicate that. ---. @vdauwera commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288604546). Ah yes my bad -- we are indeed just waiting on the tie outs to get rid of the old qual and make the new one default. I commented before the full context had resurfaced in my memory... Which means it's bedtime for my brain cells. ---. @davidbenjamin commented on [Wed Mar 22 2017](https://github.com/broadinstitute/gatk-protected/issues/950#issuecomment-288606101). Seeing as I just pressed the ""close"" button by mistake my brain cells could benefit from the same.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2958:6119,clear,clear,6119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2958,1,['clear'],['clear']
Usability,"nt calling; > ; > Somatic short variant calling was performed for tumour-normal pairs, first by preparing a panel of normals (PoN) for the OSCC, TCGA and CSCC cohorts separately. To create a PoN, Mutect2 was run in tumour only mode for the normal samples in the cohort at the 3,200 pre-defined intervals. GatherVcfs was used to gather interval VCFs into per sample VCFs. GenomicsDBImport and CreateSomaticPON was used to consolidate sample VCFs and create the PoN resource at the 3,200 pre-defined intervals. Interval VCFs were gathered into a single, cohort PoN VCF using GatherVcfs.; > ; > ; > ; > For each tumour-normal pair, Mutect2 was used for calling SNP and indels at the 3,200 pre-defined intervals, applying settings –f1r2-tar-gz, --germline-resource with gnomAD v3 as input and –panel-of-normals with PoN for the tumour-normal pair’s respective cohort as input. Interval stats files were merged into a single stats file with MergeMutectStats and interval VCFs were gathered with GatherVcfs into a single VCF for each tumour-normal pair, as preparation for further filtering using FilterMutectCalls.; > ; > We applied two additional workflows to prepare metrics and priors before running FilterMutectCalls. LearnReadOrientationModel was applied using f1r2 count metrics obtained from Mutect2 to calculate orientation bias priors. GetPileupSummaries and CalculateContamination tools were used to estimate cross sample contamination. Normal and tumour BAM files in the cohort and common biallelic SNP variants from the gnomAD v3 resource (obtained using SelectVariants with -select-type SNP -restrict-alleles-to BIALLELIC -select “AD > 0.05” –lenient settings applied) were used as inputs for GetPileupSummaries. We applied the -tumor-segmentation option in CalculateContamination.; > ; > A final, refined callset for each TN-pair was obtained by applying FilterMutectCalls to the tumor-normal VCFs with the –stats, --tumor-segmentation, --contamination-table and –ob-priors settings applied.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656499472:4477,Learn,LearnReadOrientationModel,4477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674#issuecomment-656499472,1,['Learn'],['LearnReadOrientationModel']
Usability,ntException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:151); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); Using GATK jar /gatk/gatk-package-4.1.2.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1910,learn,learnParameters,1910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['learn'],['learnParameters']
Usability,ntReInterpreterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnRSZUludGVycHJldGVyU3BhcmsuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `83.333% <100%> (+0.14%)` | `30 <0> (ø)` | :arrow_down: |; | [...s/spark/sv/discovery/SvDiscoveryInputMetaData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlcnlJbnB1dE1ldGFEYXRhLmphdmE=) | `100% <100%> (ø)` | `7 <5> (+5)` | :arrow_up: |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `74.667% <100%> (+0.694%)` | `11 <1> (ø)` | :arrow_down: |; | [.../sv/discovery/inference/CpxVariantInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnRJbnRlcnByZXRlci5qYXZh) | `68.382% <50%> (ø)` | `25 <1> (ø)` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4602/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `77.982% <86.364%> (+1.14%)` | `2 <2> (,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-379487429:2245,Simpl,SimpleNovelAdjacencyInterpreter,2245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-379487429,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"ntationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 12:16:27.027 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 12:16:27.911 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3349,Learn,LearnReadOrientationModel,3349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"ntationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:20:59.209 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 16:20:59.209 INFO LearnReadOrientationModel - Inflater: IntelInflater; 16:20:59.209 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 16:20:59.209 INFO LearnReadOrientationModel - Requester pays: disabled; 16:20:59.209 INFO LearnReadOrientationModel - Initializing engine; 16:20:59.352 INFO LearnReadOrientationModel - Done initializing engine; 16:21:00.402 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 16:21:01.086 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 16:21:01.611 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 16:21:02.365 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 16:21:03.088 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 16:21:03.785 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 16:21:04.441 INFO LearnReadOrientationModel - Context ACT: with 257420 ref and 3512 alt examples, EM converged in 13 steps; 16:21:05.269 INFO LearnReadOrientationModel - Context AGA: with 393111 ref and 6728 alt examples, EM converged in 13 steps; 16:21:06.090 INFO LearnReadOrientationModel - Context AGC: with 358648 ref and 6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:6356,Learn,LearnReadOrientationModel,6356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,ntedData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvblNlZ21lbnRlZERhdGEuamF2YQ==) | `94.444% <0%> (-2.614%)` | `8% <0%> (-1%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `79.167% <0%> (-0.833%)` | `10% <0%> (ø)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.608% <0%> (-0.253%)` | `144% <0%> (-1%)` | |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `82.171% <0%> (ø)` | `28% <0%> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (ø)` | :arrow_down: |; | [...er/tools/copynumber/CollectAllelicCountsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzU3BhcmsuamF2YQ==) | `96% <0%> (ø)` | `10% <0%> (ø)` | :arrow_down: |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5586#issuecomment-455261011:3404,Simpl,SimpleCountCollection,3404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5586#issuecomment-455261011,1,['Simpl'],['SimpleCountCollection']
Usability,"nts; 11:15:57.637 INFO FilterMutectCalls - Finished pass 0 through the variants; 11:15:57.657 INFO FilterMutectCalls - Shutting down engine; [November 7, 2019 11:15:57 AM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2148007936; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:122); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:157); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); /home/warkre/miniconda3/envs/gatk4.1.4.0/bin/gatk:80: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?; if len(args) is 0 or (l",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6255:3979,learn,learnParameters,3979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6255,1,['learn'],['learnParameters']
Usability,"o be special and left untouched by BQSR. Currently, there is no easy way to convert base qualities to two. The only instances I am aware of is (i) for SamToFastq, which then unaligns the reads and (ii) MergeBamAlignment, which isn't necessarily a part of everyone's workflow. Also, MergeBamAlignment's `CLIP_ADAPTERS` softclips XT tagged sequence, which then becomes fair game for our assembly-based callers. MarkIlluminaAdapters uses aligned reads to mark those with 3' adapter sequence with the XT tag. The XT tag values note the start of the 3' adapter sequence in the read. During MergeBamAlignment, one must especially request that this XT tag is retained in the merged output. Because our assembly-based callers throw out CIGAR strings from the aligner when reassembling reads, so as to use soft-clipped sequence that may contain true variants we wish to resolve, adapter sequence can be incorporated into the graph. This is not an issue for libraries with low levels of adapter read through and for germline calling as we prune nodes in the graph that have less than two reads supporting it. . However, for somatic cases and for libraries where there is considerable adapter read through, the current solution is to hard-clip adapter sequences out of reads or to toss these reads altogether so as not to increase the extent of spurious calls. The issue with hard-clipping is that our reads become malformed due to a mismatch in CIGAR string and sequence length. These the GATK engine filters. So the solution is to either correct the CIGAR strings or to go back and re-align the clipped reads or again to toss the reads. It would be great not to have to throw out reads that include some adapter sequence in somatic workflows that call down to the lowest allele fraction variants. It seems this would simply be a matter of a tool or feature that replaces adapter sequence marked with the XT tag with base qualities of 2 and special handling by our callers of sequence with base quality of two.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3540:2083,simpl,simply,2083,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3540,1,['simpl'],['simply']
Usability,"ocessIntervals and is updating the caller. Added segmentation classes and tests for ModelSegments CNV pipeline.; -I added implementations of copy-ratio, allele-fraction, and ""multidimensional"" (joint) segmentation. All implementations are pretty boilerplate; they simply partition by contig and then call out to KernelSegmenter. Note that there is some logic in multidimensional segmentation that only uses the first het in each copy-ratio interval and if any are available, and imputes the alt-allele fraction to 0.5 if not.; -Makes sense for @mbabadi to review this, since he reviewed the KernelSegmenter PR. Added modeling classes and tests for ModelSegments CNV pipeline.; -Most of this code is copied from the old MCMC code. However, I've done some overall code cleanup and refactoring, especially to remove some overextraction of methods in the allele-fraction likelihoods (see #2860). I also added downsampling and scaling of likelihoods to cut down on runtime. Tests have been simplified and rewritten to use simulated data.; -@LeeTL1220 do you think you could take a look?. Added ModelSegments CLI.; -Mostly control flow to handle optional inputs and validation, but there is some ugly and not well documented code that essentially does the GetHetCoverage step. We'll refactor later, I filed #3915.; -@asmirnov239 can review. This is lower priority than the gCNV VCF writing. Deleted gCNV WDL and Cromwell tests.; -Trivial to review. Added WDL and Cromwell tests for ModelSegments CNV pipeline.; -This includes the cost optimizations from @meganshand and @jsotobroad (sorry guys, I wasn't sure how to track your contributions while fixing up commits!) I also added tests for both GC/no-GC pair workflows.; -@MartonKN should review to gain familiarity with the WDL. Note that this WDL has already been through many revisions from @meganshand, @jsotobroad, and @LeeTL1220, so hopefully there shouldn't be too much for you to find serious fault with. Note that I punted on adding Multidimension",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3913:1425,simpl,simplified,1425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3913,1,['simpl'],['simplified']
Usability,"ocumentation request. ### Tool(s) or class(es) involved; Almost all of them. ### Description ; A sane argument format syntax. Take -L, obviously you give it something like 1:1-5 right? Wrong. If you actually read the documentation, that isn't obvious at all, it says: ; List[String] [] ; Great... so what is that? Yeah, it's the Java type or something right? That's what you're putting in end user facing documentation though, and that's terrible. What you actually want as input there is either 1) a string representing an interval or 2) a string representing a filename which will contain intervals. A list of type string doesn't really express what goes there. ; Sure Intervals are a bit of a special case, they've got their own entire article: https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists. In which the GATK format described appears to be incorrect: . > B. GATK-style .list or .intervals; > ; > This is a simpler format, where intervals are in the form \<chr\> \<start\> \<stop\>, and no sequence dictionary is necessary. This file format also uses 1-based coordinates. Note that only the \<chr\> part is strictly required; if you just want to specify chromosomes/ contigs as opposed to specific coordinate ranges, you don't need to specify the rest. Both \<chr\> \<start\> \<stop\> and \<chr\> can be present in the same file. You can also specify intervals in this format directly at the command line instead of writing them in a file. As a relative GATK noob, maybe I'm making a dumb interpretation mistake, but I don't see how \<chr\> \<start\> \<stop\> matches the format that seems to be in actual sample files provided by GATK, which is: \<chr\>:\<start\>-\<stop\>, . My point is though, if I'm making such a dumb mistake then probably tons and tons of other people are too when they first read it. I know a colleague of mine did as well the first time he tried using intervals. . Can we get a format description for arguments that is actually",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639:960,simpl,simpler,960,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639,1,['simpl'],['simpler']
Usability,"ode for adding and removing haplotypes based on pileup alleles has become a `void` method of this class, where it belongs. Here and elsewhere I introduce snappy variable and function named referring to ""good"" and ""bad"" alleles, which I find visually much clearer. The code is basically the same as before but somewhat streamified. I extracted a `makeHaplotypeWithInsertedEvent` method to eliminate some code duplication between GGA and pileup force-calling.; - `HaplotypeCallerEngine` and `Mutect2Engine`: Force-calling alleles are split into biallelic `Events`. Duplicated code for finding all pileup events, then sifting them into good event to force-call and bad events to remove is extracted as `PileupBasedAlleles.goodAndBadPileupEvents`. Computing `allVariationEvents` is much simpler because 1) it now uses `Event` instead of `VariantContext` and 2) `Event` overrides `equals` and `hashCode`.; - `PileupBasedAlleles`: `getPileupVariantContexts` and sorting into good and bad pileup variants has been unified into `goodAndBadPileupEvents()`. It has additionally been somewhat rewritten for conciseness. Also, instead of the somewhat kludgy method of making `VariantContext` with four temporary attributes, then filtering based on those attributes, it calculates the filtering status immediately and uses `Events`. Also fixed the somewhat-misleading use of the word `alt` to mean `SNP`.; - `AssemblyBasedCallerUtils`: `applyPileupEventsAsForcedAlleles`, along with several helper methods that it calls, has been moved into `AssemblyResultResult`, where it is now a void member method.; - `GATKVariantContextUtils` mainly just using `Event` instead of `VariantContext`, which simplifies the code for splitting a `VariantContext` into biallelics. After going through this exercise I realize that it's not actually so much. The diff's bark is worse than its bite. The overwhelming majority of changes are either replacing `VariantContext` with `Event` or moving methods to more appropriate classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702:1771,simpl,simplifies,1771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702,2,['simpl'],['simplifies']
Usability,"ode:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg., output arg for BQSR is now a more standard `-O`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:1715,usab,usable,1715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['usab'],['usable']
Usability,"odeFuncotations (easily seen in the other transcripts field). It turns out that the transcript type field has different values for each transcript. This causes many transcripts to no longer be categorized as protein coding. Therefore, the ground truth (mostly/totally in `FuncotatorIntegrationTest`) had to be modified. *Please carefully review the ground truth changes*.; - Introduces the `CompsiteOutputRenderer`, which is composed of multiple output renderers. This is used when output type is `SEG`, so that it can write both output files simultaneously.; - Introduces the `GeneListOutputRenderer`. This does not write anything to disk until the entire input file is processed. The actual writing happens during the `close()` command. This is necessary since it cannot actually render its output until all segments have been seen. This output renderer also relies heavily on specific funcotation fields being in the input `FuncotationMap`. Internally, the gene list output renderer uses the `SimpleTsvOutputRenderer` (see below) to do the actual writing.; - Introduces the `SimpleTsvOutputRenderer`. This output renderer is very flexible and renders a tab-separated text file based on several output rules. Formats are driven through config files. And developers can limit the output columns to ignore extraneous funcotation fields. Note that excluded fields are honored, regardless. If a configuration + parameter combination would result in this class producing an empty file, an exception is thrown. More notes are in the javadocs of the class.; - Currently, only the `GencodeFuncotationFactory` can actually funcotate segments. ; - Code base currently enforces only small mutations when running `Funcotator` (segs are funcotated as CANNOT_DETERMINE) and only segments when running `FuncotateSegments` (small mutations produce exception). This is enforced with flags in the code. The backend does not disallow a mixture for future use. This may prove important when funcotating CNVs from VCFs p",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941:1957,Simpl,SimpleTsvOutputRenderer,1957,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941,1,['Simpl'],['SimpleTsvOutputRenderer']
Usability,odecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2F0aGVyUGlsZXVwU3VtbWFyaWVzLmphdmE=) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `12 <10> (?)` | |; | [...orientation/LearnReadOrientationModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...s/walkers/contamination/PileupSummaryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `6 <5> (+4)` | :arrow_up: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.745% <100%> (+0.074%)` | `45 <2> (+2)` | :arrow_up: |; | [...ers/readorientation/LearnReadOrientationModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsLmphdmE=) | `92% <80%> (-4.078%)` | `36 <12> (+6)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576:3441,Learn,LearnReadOrientationModelEngineUnitTest,3441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576,2,['Learn'],"['LearnReadOrientationModel', 'LearnReadOrientationModelEngineUnitTest']"
Usability,"off-target/bin hets as well with some care.; - Old code and models are used for modeling. Since the old allele-fraction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instead of assuming the null hypothesis of het (f = 0.5) and accepting a site when we cannot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5426,learn,learn,5426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['learn'],['learn']
Usability,og10-probability must be 0 or less; > 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); > 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:646); > 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:639); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$calculateQuantileBackgroundResponsibilities$10(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.utils.MathUtils.applyToArray(MathUtils.java:1035); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.calculateQuantileBackgroundResponsibilities(SomaticClusteringModel.java:271); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:165); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); > 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); > 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); > 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1085); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); > 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); > 	at org.broadinstitute.hellb,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8455:1316,learn,learnAndClearAccumulatedData,1316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8455,1,['learn'],['learnAndClearAccumulatedData']
Usability,"oks for the start of a BAM record within the BGZF block boundary. The latter is the part that uses heuristics to find the record start and for which we’ve fixed some bugs (https://github.com/HadoopGenomics/Hadoop-BAM/pull/25, https://github.com/HadoopGenomics/Hadoop-BAM/pull/29). The guessing algorithm is discussed in some detail in http://bioinformatics.oxfordjournals.org/content/suppl/2013/05/10/bts054.DC1/supplement.pdf. Hadoop-BAM has the concept of a “splitting” index file (with extension .splitting-bai). It contains the virtual file offsets for every nth read in a BAM (where n is 4096 by default). The input format code then uses the index to get the next read (or at least the next one in the index) that starts after the HDFS block boundary for the split. As far as I can tell, the code for creating splitting index files isn’t easy to run on files in HDFS (SplittingBAMIndexer runs on local filesystem files), so it may be that splitting index files are not widely used. . The standard BAM index (.bai) is not used by Hadoop-BAM for generating splits. ADAM has IndexedBamInputFormat (see https://github.com/bigdatagenomics/adam/pull/732 and https://github.com/bigdatagenomics/adam/issues/787), which seems to be focused on reading a subset of a file, since it doesn’t respect HDFS locality (mappers would not run on the machine hosting the input data). It's not clear to me how we could use .bai files to get an even distribution of splits, and to get decent locality. Note that Matti Niemenmaa's thesis on Hadoop-BAM states. > Note that BAM and BCF can be, and commonly are, indexed. As the; > index contains the precise positions of many records in the file, one might; > think that it could be used for aligning splits accurately. Unfortunately; > their indexing schemes are not suitable for the task, due to at least all of; > the following reasons... And the reasons are listed on p46 of https://aaltodoc.aalto.fi/bitstream/handle/123456789/11886/master_niemenmaa_matti_2013.pdf.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1091#issuecomment-156428631:1499,clear,clear,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1091#issuecomment-156428631,1,['clear'],['clear']
Usability,"olders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller results from all genomic shards) and in the cloud, with minimal duplication of output from bundling when running locally, if possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2668,clear,clearly,2668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,2,['clear'],['clearly']
Usability,ollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvSERGNVNpbXBsZUNvdW50Q29sbGVjdGlvbi5qYXZh) | `90% <ø> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...er/formats/collections/AllelicCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQWxsZWxpY0NvdW50Q29sbGVjdGlvbi5qYXZh) | `100% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...collections/MultidimensionalSegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvTXVsdGlkaW1lbnNpb25hbFNlZ21lbnRDb2xsZWN0aW9uLmphdmE=) | `42.857% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ormats/collections/CopyRatioSegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQ29weVJhdGlvU2VnbWVudENvbGxlY3Rpb24uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...s/collections/AlleleFractionSegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3925/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQWxsZWxlRnJhY3Rpb25TZWdtZW50Q29sbGVjdGlvbi5qYXZh) | `45.455% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...der/tools/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-349684656:2630,Simpl,SimpleCountCollection,2630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-349684656,1,['Simpl'],['SimpleCountCollection']
Usability,"on for Mutect, and I believe also HaplotypeCaller, we count soft clips as a potential sign of a variant. This is because the aligner might soft clip the last few bases of a read that follow a deletion rather than call the deletion. For example, if the reference and read are:. TTCCAGAGTGTGTCAC (reference); TTC____________GTCAC (read). the alignment might choose to soft clip the GTCAC rather than call a deletion on the CAGAGTGT. In somatic calling it is expensive to call too many active regions, so perhaps we should only count eg the soft-clipped bases GTCAC as evidence of variation if that kmer appears downstream in the reference. @fleharty is this understanding of soft-clips being possible deletions (but not insertions or SNVs) correct?. ---. @fleharty commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303733706). @davidbenjamin . I certainly agree with you that soft-clips can be due to deletions. It's not at all clear to me that they wouldn't happen with an insertion. Consider:. ---ATGAACAGATATAACAGAT (reference); ---ATGAA(AGGTAA)CAGATATAACAGAT (read). I don't see why a soft clip might not show up on this read after ATGAA.; I'm not really sure I understand why some things are soft-clipped to be honest. I've seen plenty of things that were soft-clipped, but appear to match the reference perfectly (maybe I'm remembering this incorrectly). I suspect that soft-clips are hardly ever correctly associated with SNVs though. ---. @davidbenjamin commented on [Wed May 24 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303771734). @fleharty Thanks for the input!. ---. @ldgauthier commented on [Thu May 25 2017](https://github.com/broadinstitute/gatk-protected/issues/1094#issuecomment-303996178). You'll also likely see a difference in behavior for exomes vs genomes; because exomes (still) use bwa-aln and genomes use bwa-mem. I don't; remember the details off the top of my head, but I looked into",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3014:1118,clear,clear,1118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3014,1,['clear'],['clear']
Usability,"on profiling, it's clear that the engine adds almost no overhead on top of htsjdk iterators - see screenshot from jprofiler; ![image](https://cloud.githubusercontent.com/assets/1993519/10667806/52a4f7e6-78a7-11e5-9ad2-b11d97d4647f.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1036#issuecomment-150240722:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1036#issuecomment-150240722,1,['clear'],['clear']
Usability,"onTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/CompareIntervalLists.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0cy5qYXZh) | `93.33% <93.33%> (ø)` | `4 <4> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.88% <0%> (+0.35%)` | `188% <0%> (+1%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=footer). Last update [a74e571...8f85021](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370:2761,learn,learn,2761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370,2,['learn'],['learn']
Usability,"once we get to 0 for AyeAye, we should just change this to a style-guide item and not accept pull reqs with warnings in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/118#issuecomment-70675377:67,guid,guide,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/118#issuecomment-70675377,1,['guid'],['guide']
Usability,"one iterations:. 0) Initialize allele frequencies to the mean of the Dirichlet heterozygosity prior; i.e. ~1 for ref, ~1/1000 for each alt, plus any allele counts from the resources. Genotype priors come from the multinomial distribution (one genotype is a draw of 2 alleles) of these allele frequencies.; 1) (E step) genotype posteriors are the product of genotype likelihoods with the priors from step 0). Pseudocounts are the sum of expected posterior allele counts.; 2) (M step) MLE allele frequencies are the mode of the Dirichlet parameterized by the sum of the original step 0) prior+resources pseudocounts with the E step pseudocounts from step 1). Hmmm that does sound a lot like what the code is doing now. I suppose it's defensible after all. ---. @ldgauthier commented on [Thu May 19 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-220347447). So it sounds to me like the action item here is to fix the Dirichlet heterozygosity prior. I like the idea of adding one count for the ref and 1/1000 for each alt (rather than, for example, 1000 for ref and one for alt) so the heterozygosity prior does something in the absence of external resource counts, but doesn't overwhelms them if they are present. @davidbenjamin Can you think of a more rigorous justification for the scaling of counts between sample genotype allele counts and the heterozygosity?. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-260474993). Is this still alive? To be continued in GATK3 or 4?. ---. @ldgauthier commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-260646009). You can move to GATK4. ---. @davidbenjamin commented on [Sun Nov 20 2016](https://github.com/broadinstitute/gatk-protected/issues/792#issuecomment-261761138). @vdauwera @ldgauthier the new qual score model does exactly this. IMO we should simply have this CLI use `AlleleFrequencyCalculator`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2918:6663,simpl,simply,6663,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2918,1,['simpl'],['simply']
Usability,"ons.java:31); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:20:59.209 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:4844,Learn,LearnReadOrientationModel,4844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"ook like LIBS is actually down-sampling. Don't have time to debug more so passing on to David. ---. @droazen said (over multiple comments):. I am looking into this. LIBS is actually calling into the downsamplers correctly in the test case that Eric provided. You can see this by examining readStates.size() for each locus -- it never exceeds the -dcov target of 200. The problem must lie elsewhere -- I'll continue to step through this in the debugger. [...]. After some more debugging and consultation with Ryan, I've found that DP values exceeding dcov are to be expected given the way the ActiveRegion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and completely arbitrary depth of 1000, ignoring dcov. -The HaplotypeCaller does realignment of reads to the haplotypes, potentially causes the depth of coverage to vary at the locus in question. -The GenotypingEngine then computes DP based on the reads that still overlap the locus post-realignment. The end result is that DP for the HaplotypeCaller represents the undownsampled depth of coverage at the locus in question, subject to the hardcoded cap of 1000 and realignment to the haplotypes. In this particular case, the actual depth at locus 1:14464 is 561 (with no downsampling), and the DP value is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:2863,undo,undownsampled,2863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,ools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:151); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1760,learn,learnAndClearAccumulatedData,1760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['learn'],['learnAndClearAccumulatedData']
Usability,ools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `83.871% <0%> (-2.971%)` | `22% <0%> (+8%)` | |; | [...lignment/AssemblyContigAlignmentsConfigPicker.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlci5qYXZh) | `72.8% <0%> (-1.427%)` | `39% <0%> (+10%)` | |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `62.319% <0%> (-0.472%)` | `28% <0%> (+11%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (-0.383%)` | `73% <0%> (-1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `76.08% <0%> (-0.057%)` | `61% <0%> (+6%)` | |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4195#issuecomment-359219837:3559,Simpl,SimpleSVType,3559,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4195#issuecomment-359219837,1,['Simpl'],['SimpleSVType']
Usability,"oposed algorithm description:. Answer: thanks for looking! That's what I intended as I'm not sure if the algorithm itself would face strong critics. If that's the case, time spent on coding is not worth it IMO. In fact ideally I'd like to write a design doc or something similar, and only code after the design is agreed on. --------. > I would of course prefer not to have to have a hard filter on length. This would mean we would never call a large inversion even if it exists. . Answer: Totally agree. Now looking back, it get clearer to me that this proposal contains two parts: the filtering part, and the breakpoint linking part, separated into two major classes `InversionBreakendPreFilter` and `LinkedInversionBreakpointsInference`. That being said, it doesn't make much sense to separate them into two PRs because _currently_ the filtering part is designed around the linking part, i.e. it is trying to check which BND's are suitable to the logic implemented in the linking part, and if the logic isn't applicable to an BND, the BND simply slips through without generating any new interpretations. So `InversionBreakendPreFilter` is a filter and a classifier at the same time, it function is really diverting different BND's to be handled by different logics, and it definitely should be improved.; If you buy this argument, I am also fully aware of the code design issue that it is preferable to NOT divert&mdash;gather&mdash;send through different handlers like it currently is for calling variants from the assembly contigs, instead it should be a single stream pass through all the BND's. I'll try to follow the preferred design. > What about some other filters more specifically aimed at the artifacts that cause these false large calls? I think it's a good idea to check annotations -- ie. do the mates lie at two regions that are segmental duplications of each other, or one side of the mate looks like a transposable element insertion? I guess it's ok to put in a tool with this limit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:1215,simpl,simply,1215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,2,['simpl'],['simply']
Usability,"opping non-autosomes, as requested...; 16:51:59.672 INFO SparkGenomeReadCounts - Starting Spark coverage collection...; 17/07/21 16:52:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 463.4 KB, free 15.8 GB); 17/07/21 16:52:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 52.9 KB, free 15.8 GB); 17/07/21 16:52:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.41.105.80:34818 (size: 52.9 KB, free: 15.8 GB); 17/07/21 16:52:00 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:109; 17/07/21 16:52:00 INFO FileInputFormat: Total input paths to process : 1; 17/07/21 16:52:08 INFO SparkUI: Stopped Spark web UI at http://192.41.105.80:4040; 17/07/21 16:52:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/07/21 16:52:08 INFO MemoryStore: MemoryStore cleared; 17/07/21 16:52:08 INFO BlockManager: BlockManager stopped; 17/07/21 16:52:08 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/07/21 16:52:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/07/21 16:52:08 INFO SparkContext: Successfully stopped SparkContext; 16:52:08.357 INFO SparkGenomeReadCounts - Shutting down engine; [21 July 2017 16:52:08 BST] org.broadinstitute.hellbender.tools.genome.SparkGenomeReadCounts done. Elapsed time: 0.18 minutes.; Runtime.totalMemory()=4171235328; java.lang.NumberFormatException: For input string: ""A*01""; at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); at java.lang.Integer.parseInt(Integer.java:580); at java.lang.Integer.parseInt(Integer.java:615); at org.seqdoop.hadoop_bam.BAMInputFormat.getIntervals(BAMInputFormat.java:104); at org.seqdoop.hadoop_bam.BAMInputFormat.filterByInterval(BAMInputFormat.java:284); at org.seqdoop.hadoop_bam.BAMInputFormat.getSplits(BAMInputFormat.java:158); at org.seqdoop.hadoop_bam.AnySAMInputFormat.getSplits(AnySAM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360:5987,clear,cleared,5987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360,1,['clear'],['cleared']
Usability,options used in tests: ; --compress; -n ; --simplifyBAM; -L 1; -L unmapped; --readGroup; --sample_name,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/154#issuecomment-71864180:44,simpl,simplifyBAM,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/154#issuecomment-71864180,1,['simpl'],['simplifyBAM']
Usability,"or allele, so making the user very aware of this. For example he/she should have an decision-making input as to how we are supposed to handle het calls where both alleles are compatible with the reference ambiguous call; I don't think is totally correct to think of these as *hom*-ref calls but if that is what the user wants... Handling ambiguous calls in the reads... I presume that these have low quality and thus are ignored, and if not we should force them to. . ---. @vdauwera commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85098560). I assume ambiguous basecalls in reads are ignored and therefore not an issue. It's really what to do with ambiguous ref bases that concerns me. Currently it seems that HC just accepts them as legitimate bases in certain conditions at least. . I'm not sure I understand this part:. > Handling ambiguous reference base calls... IMO the easiest and clearest is to disambiguate using a standard alphabetical priority, A, C, G or T whichever is the first compatible base is the reference. Then we just generate non-ambigous output accordingly to this choice. That comes down to randomly assigning a ref allele at that site, doesn't it? I'm not sure I'm comfortable with that. ---. @vruano commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85121261). Not random, A has priority, then C, then G and finally T amongst those that are compatible with the ambiguous code. For Example for N it would be A, but for B would C (as B means C/G/T(U)). ---. @vdauwera commented on [Mon Mar 23 2015](https://github.com/broadinstitute/gsa-unstable/issues/829#issuecomment-85123717). Well, I understand that it's alphabetical, but I mean it's not really meaningful -- it's even worse than random since the choice is biased by whatever accident of history caused A to be earlier in the alphabet than C. To be clear I don't have a better idea, but this one bugs me. ---. @vru",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2914:2980,clear,clearest,2980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2914,1,['clear'],['clearest']
Usability,"ored as bytes in memory (estimated size 23.6 KB, free 360.5 MB); 19/04/08 19:03:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-xx.xx.xx.xx.ec2.internal:38471 (size: 23.6 KB, free: 365.8 MB); 19/04/08 19:03:27 INFO SparkContext: Created broadcast 4 from newAPIHadoopFile at PathSplitSource.java:96; 19/04/08 19:03:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.9 MB, free 323.6 MB); 19/04/08 19:03:28 INFO SparkUI: Stopped Spark web UI at http://ip-xx.xx.xx.xx.ec2.internal:4040; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Interrupting monitor thread; 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Shutting down all executors; 19/04/08 19:03:28 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 19/04/08 19:03:28 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 19/04/08 19:03:28 INFO YarnClientSchedulerBackend: Stopped; 19/04/08 19:03:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 19/04/08 19:03:28 INFO MemoryStore: MemoryStore cleared; 19/04/08 19:03:28 INFO BlockManager: BlockManager stopped; 19/04/08 19:03:28 INFO BlockManagerMaster: BlockManagerMaster stopped; 19/04/08 19:03:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 19/04/08 19:03:28 INFO SparkContext: Successfully stopped SparkContext; 19:03:28.389 INFO HaplotypeCallerSpark - Shutting down engine; [April 8, 2019 7:03:28 PM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=941096960; Exception in thread ""main"" java.lang.StackOverflowError; 	at java.util.HashMap.putMapEntries(HashMap.java:501); 	at java.util.HashMap.<init>(HashMap.java:490); 	at com.esotericsoftware.kryo.Generics.<init>(Generics.java:47); 	at com.esotericsoftware.kryo.serializers.FieldSerializerGenericsUtil.buildGenericsScop",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869:17809,clear,cleared,17809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869,1,['clear'],['cleared']
Usability,"org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75); at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:309); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 18/04/23 20:42:02 INFO DAGScheduler: Job 0 failed: first at ReadsSparkSource.java:221, took 11.814317 s; 18/04/23 20:42:02 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.xx:4040; 18/04/23 20:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/23 20:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/23 20:42:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/23 20:42:03 INFO MemoryStore: MemoryStore cleared; 18/04/23 20:42:03 INFO BlockManager: BlockManager stopped; 18/04/23 20:42:03 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/23 20:42:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/23 20:42:03 INFO SparkContext: Successfully stopped SparkContext; 20:42:03.045 INFO PathSeqPipelineSpark - Shutting down engine; [April 23, 2018 8:42:03 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 0.43 minutes.; Runtime.totalMemory()=793247744; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, xx.xx.xx.xx, executor 0): java.lang.IllegalStateException: unread block data; at java.io.ObjectInputStream$BlockDataInputStream.setBlockDataMode(ObjectInputStream.java:2740); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1567); at java.io.ObjectInputStream.defau",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694:16977,clear,cleared,16977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694,1,['clear'],['cleared']
Usability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:1952,simpl,simpler,1952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,4,['simpl'],"['simple', 'simpler']"
Usability,"otate(refSequenceDictionary);; > + }; > +; > + private static List<AlignmentInterval> deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may be experimented with, but it seems unlikely in the near future (their own quirkiness, lack of API for JNI, etc); it seems more and more likely to me that eventually it's inevitable to have a custom alignment module in a high-quality SV pipeline, but again, the near future has other top priorities.; > ; > What do you think?; > ; > —; > You are receiving this because you",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:1966,simpl,simply,1966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,2,['simpl'],['simply']
Usability,"otator - Initializing Funcotator Engine...; 16:01:43.983 INFO Funcotator - Creating a VCF file for output: file:/home/deepak/software_library/gatk-4.1.7.0/variants.funcotated.vcf; 16:01:44.020 INFO ProgressMeter - Starting traversal; 16:01:44.020 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:01:44.068 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr1:1-10454 due to alternate allele: <NON_REF>; 16:01:44.116 INFO VcfFuncotationFactory - dbSNP 9606_b150 cache hits/total: 0/0; 16:01:44.121 INFO Funcotator - Shutting down engine; [12 May, 2020 4:01:44 PM IST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.14 minutes.; Runtime.totalMemory()=2889875456; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:-9 end:10464; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:733); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createReferenceSnippet(FuncotatorUtils.java:1439); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getBasesInWindowAroundReferenceAllele(FuncotatorUtils.java:1468); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationForSymbolicAltAllele(GencodeFuncotationFactory.java:2560); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFlankFuncotation(GencodeFuncotationFactory.java:2465); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncot",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:6502,Simpl,SimpleInterval,6502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['Simpl'],['SimpleInterval']
Usability,"ouldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing, so that it can evolve freely without affecting anyone else. For `SlidingWindowWalker`, which we still want to merge, I recommend making the traversal do **exactly** what you want for your use case, as clearly and simply as possible, without worrying about serving as a base class for other traversals. Ping me once you're happy with it, and I'll re-review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:2317,simpl,simplicity,2317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,3,"['clear', 'simpl']","['clearly', 'simplicity', 'simply']"
Usability,"ound first, since these give rise to longer segments:. ![wave-kern-no-local](https://user-images.githubusercontent.com/11076296/29322673-4dd9a1ac-81ac-11e7-94f5-5c5494e44ac5.png). CBS similarly finds many false positive breakpoints:. ![wave-cbs](https://user-images.githubusercontent.com/11076296/29322677-5576e4ba-81ac-11e7-888b-07ed5bff27e3.png). However, when we tune down the sine waves to 1:10, ApproxKernSeg still gets tripped up, but CBS looks better:. ![wave-kern-no-local-small-waves](https://user-images.githubusercontent.com/11076296/29322732-815df58c-81ac-11e7-8305-6e1798616336.png); ![wave-cbs-small-waves](https://user-images.githubusercontent.com/11076296/29322737-836b78fe-81ac-11e7-93be-753a40011203.png). To improve ApproxKernSeg, we can 1) make the cost function intensive, by simply dividing by the number of points in a segment, and 2) add to the cost function a local term, given by the cost of making each point a changepoint within a local window of a determined size. This local term was inspired by methods such as SaRa (http://c2s2.yale.edu/software/sara/). The reasoning is that with events at higher S/N ratio, we typically don't need to perform a global test to see whether any given point is a suitable changepoint; using the data locally surrounding the point typically suffices. With these modifications, ApproxKernSeg can handle both scenarios:; ![wave-kern](https://user-images.githubusercontent.com/11076296/29322762-a679dba6-81ac-11e7-9360-083a4e1da398.png); ![wave-kern-small-waves](https://user-images.githubusercontent.com/11076296/29322801-dad82010-81ac-11e7-8238-e057b0072e1b.png). This local window approach is still linear in time, so runtime is still ~1s for the above (about ~10x faster than CBS). One issue still remains, which is that even this improved approach tends to find directly adjacent possible changepoints around a true changepoint before moving on to another true changepoint. We can probably clean this up with some simple postprocessing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045:2774,simpl,simple,2774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045,2,['simpl'],['simple']
Usability,ources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_some_missing.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/ice_trunc_targets_with_bait_counts.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotyper_agilent_targets_trunc.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_basic.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/sexgenotyper/sex_genotypes_broadies_extended.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-basic-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-full-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-intermediate-with-phase-posteriors.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/snps-simplified-for-allelic-fraction-transformation.tsv; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.dict; src/test/resources/org/broadinstitute/hellbender/tools/exome/test_reference.fasta.fai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bai; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.bam; src/test/resources/org/broadinstitute/hellbender/tools/expected.originalQuals.chr1.1-1K.bam.QT_10_CT_15_X_CCCCC.tmp; src/test/resources/org/broadinstitute/hellbender/tools/FixCallSetSampleOrdering/badlySorted1000-batch-size13.vcf.idx; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.bam.bai; src/test/resources/org/broadinstitute/hellbender/tools/flag_stat.fasta; src/test/resources/org/broadinstitute/hellbender/tools/genome/HCC1143_chr22_27M_37M.tiny.bam; src/test/resources/org/broadinstitute/hellbender/tools/gen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3905:35527,simpl,simplified-for-allelic-fraction-transformation,35527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3905,1,['simpl'],['simplified-for-allelic-fraction-transformation']
Usability,"p [often](https://gatk.broadinstitute.org/hc/en-us/community/posts/4566282375835-Mutect2-AF-does-not-match-AD-and-DP) in the GATK forum and it feels like having clear documentation around this would be helpful. . My impression is that Mutect2 might be using an AD ""1-read-per-allele"" prior and incorporating that into its reported AF. From the [article on informative reads](https://gatk.broadinstitute.org/hc/en-us/articles/360035532252-Allele-Depth-AD-is-lower-than-expected), once you're at the sample level (FORMAT field), both DP and AD appear to include only informative alleles. It is tempting to think that AF would be computed from them directly (e.g., `AD_alt / DP`, which is equivalent to `AD_alt/[AD_alt+AD_ref]` in the biallelic case since only informative reads are retained). However, as noted in those linked forum posts, Mutect2 (in my case, version 4.2.5.0) does not produce AF values that can be computed from the AD values in that way. Rather, the AF value appears to incorporate a prior. . I investigated this across a range of allele depths in real calls. Here are some examples. The format is:; |AlleleDepthRef,AlleleDepthAlt | DP | AF[provided by Mutect2] | AF[if I calculate it myself]|; | ------- | ------- | ----- | ------- |; | 0,1|1|0.667|1.000 |; | 23,4|27|0.170|0.148 |; | 39,125|164|0.758|0.762 | . The intuition here is that there is a huge discrepancy between the Mutect2 AF and the AF I calculate when AD (or DP) is small (first row), and the error gets smaller as DP increases. The formula that Mutect2 seems to use to compute AF is:. ```py; # Formula that Mutect2 seems to use to calculate AF of the alternative allele in a biallelic scenario; Mutect2_AF = (ADalt+1) / (ADalt+1 + ADref+1). # Which is equivalent to:; Mutect2_AF = (ADalt + 1) / (DP + 2); ```. 1. Is my inference about a prior weight being added by Mutect2 prior to computing AF accurate?; 2. If so, is it intended behavior?; 3. If so, can the VCF header field be a bit more informative about this?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8080:2002,intuit,intuition,2002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8080,1,['intuit'],['intuition']
Usability,"pMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22570,clear,cleared,22570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['clear'],['cleared']
Usability,parkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:217); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:811); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335); 	at org.apache.spark.rdd.RDD,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:1780,Simpl,SimpleNovelAdjacencyInterpreter,1780,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,2,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"perfect. Maybe it's as simple as switching all HashSets to LinkedHashSet; (and same for maps). On Tue, Apr 21, 2015 at 10:02 AM, Matt Sooknah notifications@github.com; wrote:. > Ah yes, I remember this now - they haven't been failing in Picard per se,; > it's just when we tried compiling under Java 8. The info in that issue; > should make the fix much easier, if it's indeed the same thing.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/364#issuecomment-94805095; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/364#issuecomment-94807857:23,simpl,simple,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364#issuecomment-94807857,1,['simpl'],['simple']
Usability,"ppear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the difference between the positive and the negative scores, for example.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:2653,simpl,simply,2653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,4,['simpl'],['simply']
Usability,pr&el=desc) will **increase** coverage by `0.004%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5287 +/- ##; ===============================================; + Coverage 86.773% 86.776% +0.004% ; - Complexity 29864 29888 +24 ; ===============================================; Files 1830 1834 +4 ; Lines 138368 138473 +105 ; Branches 15237 15241 +4 ; ===============================================; + Hits 120066 120162 +96 ; - Misses 12753 12760 +7 ; - Partials 5549 5551 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5287?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...pynumber/datacollection/AllelicCountCollector.java](https://codecov.io/gh/broadinstitute/gatk/pull/5287/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2RhdGFjb2xsZWN0aW9uL0FsbGVsaWNDb3VudENvbGxlY3Rvci5qYXZh) | `65.789% <0%> (-14.856%)` | `13% <0%> (ø)` | |; | [...ynumber/formats/metadata/SimpleSampleMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/5287/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvbWV0YWRhdGEvU2ltcGxlU2FtcGxlTWV0YWRhdGEuamF2YQ==) | `76.471% <0%> (ø)` | `6% <0%> (ø)` | :arrow_down: |; | [...er/tools/copynumber/CollectAllelicCountsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5287/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzU3BhcmsuamF2YQ==) | `96% <0%> (ø)` | `10% <0%> (?)` | |; | [...bender/tools/examples/ExampleLocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5287/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `92% <0%> (ø)` | `6% <0%> (?)` | |; | [...mber/CollectAllelicCountsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5287#issuecomment-427535500:1282,Simpl,SimpleSampleMetadata,1282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5287#issuecomment-427535500,1,['Simpl'],['SimpleSampleMetadata']
Usability,"pr&el=h1) Report; > Merging [#2548](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2548 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10893 +2 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `85.185% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=footer). Last update [c8ede6e...b79b75d](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475:1655,learn,learn,1655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475,2,['learn'],['learn']
Usability,pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <100%> (ø)` | `13 <4> (+4)` | :arrow_up: |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.639% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...park/sv/discovery/inference/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NoaW1lcmljQWxpZ25tZW50LmphdmE=) | `70.922% <45.455%> (-2.155%)` | `48 <2> (+2)` | |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <46.269%> (ø)` | `5 <5> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <64.211%> (ø)` | `19 <19> (?)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `75.214% <75.676%> (-2.314%)` | `10 <2> (+2)` | |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092:3529,Simpl,SimpleNovelAdjacencyInterpreter,3529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,profile and optimize simple variant walkers: CountVariants,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1036:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1036,2,['simpl'],['simple']
Usability,"ps on separate branches, and merges to master only when everything in a branch is ""release-ready"". In this scenario master itself is always (theoretically, at least) ready for release. This solves the original problem of release of some tools being blocked by others, but creates some other problems: last-minute merge conflicts across dev teams, large amounts of code being held back for months while it undergoes testing, harder to share code across groups, more complex git workflows for everyone.; 4. Everyone is free to merge development versions of tools to master (as is currently the case), and most of the time we try to release everything in the GATK together. On rare occasions when, eg., CNV needs a release now and HC is not ready, we create a branch off of the last tagged release, cherry-pick the CNV tools (or whatever) into it, and release that. Then when the HC stabilizes and master is once again releasable, we do the next release from master. I've renamed this issue to make the problem we're trying to solve clearer. @akiezun @lbergelson @LeeTL1220 @vdauwera would you vote for any of the above options? Do you have alternate proposals that solve the same problem and you think are better? Should we seek professional (release engineering) help?. ---. @akiezun commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215761749). only 4 seems remotely sane to me. ---. @vdauwera commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-215779225). 3 and 4 both produce an acceptable result for me but I could see 3 being too hard on the dev team. So I'll go with 4. I think the inconvenience of cutting a special cherry picked release is enough to dissuade casual/unnecessary releases, but low enough to not be a blocker if we really do need to release a hot fix. ---. @LeeTL1220 commented on [Fri Apr 29 2016](https://github.com/broadinstitute/gatk-protected/issues/473#issuecomment-2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2851:4692,clear,clearer,4692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2851,1,['clear'],['clearer']
Usability,"r cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1930,Simpl,SimpleNovelAdjacencyAndChimericAlignmentEvidence,1930,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,1,['Simpl'],['SimpleNovelAdjacencyAndChimericAlignmentEvidence']
Usability,"r credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing eng",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2281,Learn,LearnReadOrientationModel,2281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"r definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. I am pretty sure that most common germline regions are being blacklisted already. The hotspots addressed in this PR (faux-CNLoH) could be added, but I think we will find new areas and a few of these areas were rather big. I have users that are actively using this from the branch, for reasons other than the faux-CNLoH pruning. Results are improving without an appreciable hit to sensitivity, which we got when using parameters like num_changepoints_penalty_factor. As a compromise, I can always default the CNLoH piece to `false`, since there are other useful changes on this branch. (Users did not have as strong an opinion about the faux-CNLoH pruning, since GISTIC does not use MAF and ABSOLUTE requires a manual review). > simple filtering based on CR-AF as described above could be implemented. If the normal is available, we can make IS_NORMAL calls simply based on the overlap of the ModelSegments posteriors (with corresponding qualities). If not, then some heuristic determination of the normal state from the tumor alone as in Marton's caller could be performed. This would combine the IS_NORMAL calling and filtering steps into one simple tool. The output could be a tagged/filtered ModelSegments .seg file and the corresponding VCF. And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874:2262,simpl,simple,2262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874,6,['simpl'],"['simple', 'simply']"
Usability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.01% <100%> (+0.04%)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/funcotator/metadata/TumorNormalPair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1R1bW9yTm9ybWFsUGFpci5qYXZh) | `63.63% <63.63%> (ø)` | `5 <5> (?)` | |; | [...cotator/mafOutput/CustomMafFuncotationCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9DdXN0b21NYWZGdW5jb3RhdGlvbkNyZWF0b3IuamF2YQ==) | `90% <90%> (ø)` | `17 <17> (?)` | |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95% <95%> (ø)` | `9 <9> (?)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `86.18% <0%> (+0.65%)` | `43% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=footer). Last update [9d8fdac...0e8a045](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987:3490,learn,learn,3490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987,2,['learn'],['learn']
Usability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `82.5% <83.33%> (+4.72%)` | `12 <2> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `72.22% <85.71%> (-5.2%)` | `8 <3> (-2)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `72.51% <0%> (+0.94%)` | `38% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=footer). Last update [2ee7df3...e40ce5e](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250:4360,learn,learn,4360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250,2,['learn'],['learn']
Usability,"r, we could certainly fail earlier, before the expensive GermlineCNVCaller step. As mentioned above, we will need to do some work to enable this; I would suggest:. 1) we enable passing of dictionaries from `-L` Picard interval lists at the engine level (and I would add consistency checks if multiple interval lists are provided here as well),; 2) we add checks to all relevant gCNV tools of read-count dictionaries against the intervals dictionary,; 3) we change the behavior of `CopyNumberArgumentValidationUtils.resolveIntervals` so that it fails if provided an unsorted IAC, rather than sorting the contained intervals w.r.t. the count dictionary upon creation of the returned `SimpleIntervalCollection` (this can be done independently of the first two items and would have caused the failing shard to fail earlier; however, the other two items are required to cause all shards to fail earlier),; 4) we revert the change made to PostprocessGermlineCNVCalls, so that external dictionaries provided via `--sequence-dictionary` do not override those in the count files, and perhaps fail if one is provided for any of the tools (I don’t recall exactly how VCF indexing is triggered by providing one, as seems to be indicated by the tutorial, but hopefully we can disallow external dictionaries while still taking advantage of the relevant engine features for VCF writing). EDIT: Went digging in Slack to try to remind myself of the context of these changes, and found the following PR comment from 1/7 (although it seems to have mysteriously disappeared from GitHub):. > Just so I understand, are we allowing overriding of the sequence dictionary in the shards (and skipping the consistency check) by allowing the parameter --sequence-dictionary to be specified? If so, we might want to document. Otherwise, I'd be inclined to enforce using the sequence dictionary in the shards (and ensuring the consistency check across shards is performed) by changing the null check in getBestAvailableSequenceDict",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:1818,Simpl,SimpleIntervalCollection,1818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,1,['Simpl'],['SimpleIntervalCollection']
Usability,"r.GermlineCNVCaller done. Elapsed t; ime: 0.90 minutes.; Runtime.totalMemory()=2374500352; Exception in thread ""main"" java.lang.InternalError: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hellbender.tools.copynumber.utils.HDF5Utils.readIntervals(HDF5Utils.java:62); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.lambda$new; $2(HDF5SimpleCountCollection.java:76); 	at htsjdk.samtools.util.Lazy.get(Lazy.java:25); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.getInterva; ls(HDF5SimpleCountCollection.java:85); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readHDF5(Simpl; eCountCollection.java:119); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readAndSubset(; SimpleCountCollection.java:98); ```. with annotated_intervals.tsv . ```; $ grep -v '@' annotated_intervals.tsv | cat -n | head; 1	CONTIG	START	END	GC_CONTENT	SEGMENTAL_DUPLICATION_CONTENT; 2	chr1	10001	110000	0.422350	0.000000; 3	chr1	110001	177417	0.441046	0.000000; 4	chr1	227418	267719	0.391445	0.000000; 5	chr1	317720	417719	0.401850	0.000000; 6	chr1	417720	471368	0.471155	0.000000; 7	chr1	521369	621368	0.436950	0.000000; 8	chr1	621369	721368	0.428550	0.000000; 9	chr1	721369	821368	0.442210	0.000000; 10	chr1	821369	921368	0.606500	0.000000. $ grep -v '@' /annotated_intervals.tsv | cat -n | tail; 28717	chrY	28051429	28151428	0.372550	0.000000; 28718	chrY	28151429	28251428	0.380900	0.000000; 28719	chrY	28251429	28351428	0.390730	0.000000; 28720	chrY	28351429	28451428	0.381580	0.000000; 28721	chrY	28451429	28551428	0.394890	0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:4621,Simpl,SimpleCountCollection,4621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['Simpl'],['SimpleCountCollection']
Usability,"r.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 18/01/09 18:31:26 INFO server.AbstractConnector: Stopped Spark@283ab206{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 18/01/09 18:31:26 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.1.4:4040; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/01/09 18:31:26 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/01/09 18:31:26 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/01/09 18:31:26 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/01/09 18:31:26 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/01/09 18:31:26 INFO memory.MemoryStore: MemoryStore cleared; 18/01/09 18:31:26 INFO storage.BlockManager: BlockManager stopped; 18/01/09 18:31:26 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/01/09 18:31:26 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/01/09 18:31:26 INFO spark.SparkContext: Successfully stopped SparkContext; 18:31:26.896 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [January 9, 2018 6:31:26 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 0.89 minutes.; Runtime.totalMemory()=881328128; ***********************************************************************. A USER ERROR has occurred: Input files reference and reads have incompatible contigs: No overlapping contigs found.; reference contigs = [chrM, chr1, chr2, chr3, chr4, chr5, chr6, chr7, chr8, chr9, chr10, chr11, chr12, chr13, chr14, chr15, chr16, chr17, chr18, chr19, chr20, chr21, chr22, chrX, chrY, chr1_gl000191_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4112:30657,clear,cleared,30657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112,1,['clear'],['cleared']
Usability,"r2 files from all shards."". @davidbenjamin. --------------; Hi there,. I have a simulated dataset of related samples and currently running Mutect2 on it (10 tumor samples WGS with 130x); I managed to run everything through and now FilterMutectCalls crashes after the first pass through the variants with. ```; [October 1, 2019 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 370.68 minutes.; Runtime.totalMemory()=20597702656; java.lang.IllegalArgumentException: beta must be greater than 0 but got -87566.7500301585; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:14); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:42); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.learn(BinomialCluster.java:33); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.lambda$learnAndClearAccumulatedData$7(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.utils.IndexRange.forEach(IndexRange.java:116); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:131); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:156); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:151); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1039); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202:1400,learn,learn,1400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202,1,['learn'],['learn']
Usability,"rEngine - WARNING: You are using B37 as a reference. Funcotator will convert your variants to GRCh37, and this will be fine in the vast majority of cases. There MAY be some errors (e.g. in the Y chromosome, but possibly in other places as well) due to changes between the two references.; 17:14:13.411 INFO ProgressMeter - Starting traversal; 17:14:13.412 INFO ProgressMeter - Current Locus Elapsed Minutes Features Processed Features/Minute; 17:14:15.391 INFO FuncotateSegments - Shutting down engine; [September 11, 2022 5:14:15 PM GMT] org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments done. Elapsed time: 0.30 minutes.; Runtime.totalMemory()=1752170496; java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:917445 end:911649; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:804); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:35); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.findInclusiveExonIndex(SegmentExonUtils.java:95); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.segment.SegmentExonUtils.determineSegmentExonPosition(SegmentExonUtils.java:63); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2939); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSegmentFuncotations(GencodeFuncotationFactory.java:2914); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnSegment(GencodeFuncotationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239); at org.broadinstitute.hellbender.tools.funcotator.DataSource",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:1357,Simpl,SimpleInterval,1357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,2,['Simpl'],['SimpleInterval']
Usability,"ra commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260494000). @vruano Are you currently working on this? Or can this be moved into the GATK4 repo for future work? . ---. @vruano commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260503444). Working on it on GATK3 but I could merge it into GATK4 whenever is ready if you prefer. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-260509332). Ok great, totally fine to do in 3 but please do port to 4 when it's ready. Do you have an order of magnitude sense of when it might be ready? Meaning days/weeks/months (for release scheduling purposes). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285721454). In the last methods meeting I presented the results of our first effort to improve accuracy calling in STR. As far as unfiltered single and trio calls are concerned the recommendation is to apply the new model with PCR+ data. However, for PCR- dataset one either can choose not apply any correction or to apply the new model train on PCR- data... the latter seems to have slightly F1 values however for the sake of simplicity it might just make sense no to apply any correct; either way is good. The presentation I gave can be found [here](https://drive.google.com/open?id=0Bzt9p0vCNxlHWlZVUHZfdXR5MTg). ---. @vruano commented on [Fri Mar 10 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-285722791). It seems that at some point Planatir will take a look and see whether it improves calls once filtered with VQSR. ---. @vdauwera commented on [Mon Mar 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/1425#issuecomment-287822174). Is there a PR associated with this issue? Will there be a new feature to release? Need to know for release scheduling purposes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2519:1963,simpl,simplicity,1963,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2519,1,['simpl'],['simplicity']
Usability,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2178,learn,learn,2178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825,2,['learn'],['learn']
Usability,"rage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2468 +/- ##; ===============================================; + Coverage 76.268% 76.275% +0.008% ; - Complexity 10876 10879 +3 ; ===============================================; Files 752 752 ; Lines 39583 39583 ; Branches 6922 6922 ; ===============================================; + Hits 30189 30192 +3 ; + Misses 6774 6772 -2 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=footer). Last update [c62914a...4bebcdf](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580:1809,learn,learn,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580,2,['learn'],['learn']
Usability,"rage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2427 +/- ##; ===============================================; + Coverage 76.218% 76.221% +0.003% ; - Complexity 10819 10821 +2 ; ===============================================; Files 750 750 ; Lines 39420 39421 +1 ; Branches 6883 6883 ; ===============================================; + Hits 30045 30047 +2 ; Misses 6757 6757 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `83.607% <100%> (+0.273%)` | `31 <4> (+1)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=footer). Last update [fcd103c...fc95362](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101:1843,learn,learn,1843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101,2,['learn'],['learn']
Usability,ranches 9747 10098 +351 ; ==============================================; + Hits 46958 47777 +819 ; - Misses 9103 9859 +756 ; - Partials 3777 3904 +127; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4181?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `71.839% <0%> (-28.161%)` | `35% <0%> (+26%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `88.889% <0%> (-0.766%)` | `72% <0%> (-2%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQ2hpbWVyaWNBbGlnbm1lbnQuamF2YQ==) | `73.077% <0%> (ø)` | `46% <0%> (?)` | |; | [...ols/spark/sv/discovery/AlignedContigGenerator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358335145:1638,Simpl,SimpleSVType,1638,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358335145,1,['Simpl'],['SimpleSVType']
Usability,"rated by GvsExtractCallset. . It ignores basically everything except genotypes, because PGENs do not store all the other fields and annotations that the VCFs might have. It will also skip over any sites in the VCFs with >254 alleles because those will not be present in the PGEN files. Any differences are written to diff files, in the form of the differing lines in the VCFs being compared. The code for this comparison tool lives [here](https://github.com/KevinCLydon/pgen_vcf_comparator) in a repo I created under my GitHub account. (I didn't create it under the Broad org because it's sort of half-baked and bad and not actually meant to be used by anyone other than me.) I don't know if y'all want to continue using this tool, but I'm happy to discuss it more if it would actually be useful to you. ## To-dos / caveats. ### PGEN-JNI; The version of PGEN-JNI I'm referencing in the current build.gradle file is a beta version that is hosted on artifactory. Functionally, this is totally fine, but we want to get a 1.0 version of it hosted publicly. Chris Norman, who developed the tool is currently very working on this and very close to done. Once he's completed this, I want to run a sanity test or two against a small subset of the Delta callset just to make sure everything is functioning as intended. ### Merging by chromosome arm; Right now, the last step of the PGEN extract workflow merges the PGEN files by contig name, so the final result is one trio of files (.pgen, .psam, and .pvar.zst) per chromosome. There was discussion about changing this to merge instead by chromosome arm. I want to make this change, but it's not super simple, so I've prioritized getting this version of the code ready for merging before tackling that. ### The PGEN format; As I mentioned above, Plink 2.0 and the PGEN file format are still not in full release, so the format could be subject to change in the future, which will require updates to our PGEN writing code and could possibly introduce problems.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708:13676,simpl,simple,13676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708,1,['simpl'],['simple']
Usability,"ratively and the literal git blame) for PosteriorLikelihoodsUtils nomenclature problems. I either initiated them or didn't fix them when I refactored. I also intuitively prefer resources only without using the input AC, but that being said we've seen better results using both, specifically for a Finnish cohort with 100 founders. In the DSDE/ATGU meetings the use of the input AC was discussed as being analogous to a single step of EM. Would the true EM apply a different update for each sample in the callset?. ---. @davidbenjamin commented on [Tue May 17 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecomment-219833193). The better results using the double-counting might have something to do with the incorrect prior -- if the prior is skewing toward homozygosity, then double-counting your variant data might counteract this and rescue some variant genotypes, which will be mainly hets. The EM model that people implicitly seem to have in mind is alternating E steps on each sample to get genotype posteriors with M steps to learn the allele frequencies. So let's work out what happens if you do just one iterations:. 0) Initialize allele frequencies to the mean of the Dirichlet heterozygosity prior; i.e. ~1 for ref, ~1/1000 for each alt, plus any allele counts from the resources. Genotype priors come from the multinomial distribution (one genotype is a draw of 2 alleles) of these allele frequencies.; 1) (E step) genotype posteriors are the product of genotype likelihoods with the priors from step 0). Pseudocounts are the sum of expected posterior allele counts.; 2) (M step) MLE allele frequencies are the mode of the Dirichlet parameterized by the sum of the original step 0) prior+resources pseudocounts with the E step pseudocounts from step 1). Hmmm that does sound a lot like what the code is doing now. I suppose it's defensible after all. ---. @ldgauthier commented on [Thu May 19 2016](https://github.com/broadinstitute/gsa-unstable/issues/1185#issuecom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2918:4640,learn,learn,4640,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2918,1,['learn'],['learn']
Usability,rc=pr&el=desc) will **increase** coverage by `0.164%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3653 +/- ##; ===============================================; + Coverage 79.384% 79.548% +0.164% ; - Complexity 17292 17780 +488 ; ===============================================; Files 1140 1146 +6 ; Lines 62494 65112 +2618 ; Branches 9489 10115 +626 ; ===============================================; + Hits 49610 51795 +2185 ; - Misses 9108 9427 +319 ; - Partials 3776 3890 +114; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ls/spark/sv/discovery/BreakpointComplications.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtwb2ludENvbXBsaWNhdGlvbnMuamF2YQ==) | `80.573% <0%> (-8.362%)` | `102% <0%> (+41%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `89.691% <0%> (-5.961%)` | `2% <0%> (+1%)` | |; | [...ols/spark/sv/utils/PairedStrandedIntervalTree.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9QYWlyZWRTdHJhbmRlZEludGVydmFsVHJlZS5qYXZh) | `87.302% <0%> (-4.59%)` | `17% <0%> (+8%)` | |; | [...ls/spark/sv/evidence/FindBadGenomicKmersSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3653?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQmFkR2Vub21pY0ttZXJzU3BhcmsuamF2YQ==) | `48.039% <0%> (-3.35%)` | `17% <0%> (+4%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/36,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3653#issuecomment-333869239:1287,Simpl,SimpleSVType,1287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3653#issuecomment-333869239,1,['Simpl'],['SimpleSVType']
Usability,rc=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...hellbender/engine/spark/IntervalWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSW50ZXJ2YWxXYWxrZXJDb250ZXh0LmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ls/walkers/mutect/filtering/BaseQualityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvQmFzZVF1YWxpdHlGaWx0ZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...nder/tools/readersplitters/SampleNameSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9yZWFkZXJzcGxpdHRlcnMvU2FtcGxlTmFtZVNwbGl0dGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...lbender/tools/walkers/mutect/clustering/Datum.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL0RhdHVtLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-7%)` | |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25SZWFkU2hhcmRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [.../examples/metrics/single/ExampleSingleMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474567553:1892,Simpl,SimpleSVD,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474567553,1,['Simpl'],['SimpleSVD']
Usability,"re falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:2397,simpl,simple-perl,2397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,2,['simpl'],['simple-perl']
Usability,"re first, then split. Splitting the gapped alignments was introduced originally to have a centralized logic in inferring type and location of the events. . The tension is that AS is used in the scoring but becomes practically useless after that. >> Correct, but I am having thoughts about this now (not to pick only one—that; would be wrong—but to ditch them altogether probably under some condition; and redo the alignment step), exactly because of this behavior I observe.; Think about the case where one originating gapped (say insertion); alignment, after splitting, has one of the two children contained in; another alignment (not its sibling, that's impossible) in terms of their; read span. Now the originating gapped alignment probably should be filtered; out, or not, because if we keep it, an insertion would be called but; apparently there are alternative explanations due to the other alignment.; I'm not sure how to deal with this case, and if this scenario is common; enough. It probably is the case that such alignments happen mostly in STR; regions, so getting the exact alignments correct there is no easy task.; ; > Is that enough of a concern to worry about. In such a case I feel like we; should probably just pick the longer, gapped alignment, since it explains; more of the contig. But you have a better sense of how that fits in with; the rest of your scheme. The comments I put in the code/todo was not clear (my bad). ; What the code is currently doing is what's suggested, that is: ; skipping the alignment that is BEFORE the child alignment from the gap-split, IFF that alignment contains the child alignment in terms of their spans on the read/contig; (I've updated the doc in the code as well). If you are concerned about the first child alignment from the same gapped alignment being skipped, don't worry, that is impossible because child alignments of the same gapped alignment cannot overlap on the read. --------. Do these cover your major concerns @cwhelan?; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980:2219,clear,clear,2219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980,2,['clear'],['clear']
Usability,"real patients' lives. Almost all of these institutions are likely to use clinical WES assays due to cost reasons and will thus have been directly affected by this issue _for the last three years_. Also, almost all of these institutions will never learn of this bug since they likely trusted in the developers to have proper functional regression tests in place. If this is indeed the best the Broad can do as an institution, then I will take your offer of providing a build of Mutect2 4.1.8.1 with the log4j vulnerability patched out - thank you. The one thing that I am asking for in addition (for the sake of the overall oncology bioinformatics community), however, is that you conduct a best effort to notify organizations (universities, hospitals, and biotechs/pharmaceuticals that you know are using Mutect2) and best-practise workflow owners (Nextflow, Snakemake, WDL, CWL etc. that include Mutect2) of the forced downgrade. Also, I think it makes sense to include a very prominent warning into the Mutect2 READMEs and GATK best practice documentations and guides. I know that this is work, too, but with success comes responsibility, and I can just hope that providing proper warnings uses less developer bandwidth than applying binary search to find out which of these [10 commits between 4.1.8.1 and 4.1.9.0 that are touching variant filtering (see below)](https://github.com/broadinstitute/gatk/compare/4.1.8.1...4.1.9.0) broke your flagship product enough to abandon it. (For anyone looking at this issue later, these are the commits I think are most likely to be related to this issue, and which I would propose to systematically leave out of the 4.1.9.0 build to test whether variant calling specificity is restored; assuming the 10 commits are independent and leaving each out in turn produces a working build, this would mean producing 10 Mutect2 builds for functional regression testing (the latter of which @ddrichel could do if we would receive the 10 builds from the GATK team)):. ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226:1629,guid,guides,1629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226,2,['guid'],['guides']
Usability,"refer i post this kind of question elsewhere, please let me know. My lab creates a large dataset of macaque variant data. We regularly add new samples to a dataset that currently has ~2300 WGS/WXS datasets. We largely follow the GATK short variant calling pipeline. Our gVCF data are aggregated into a GenomicsDb workspace, followed by GenotypeGVCFs. As is, whenever we get new samples, we append them to this growing GenomicsDb workspace, and then re-call all of the genotypes. These steps are getting slower and slower (even when scatter/gathered on a cluster), and I'm concerned it's going to become untenable. Plus it's just really inefficient to constantly re-call 1000s of datasets at 40m genome-wide sites. My question is: do you have any experience with analogous datasets, where you have a large base of ""static"" datasets with regular additions of new data? It would be quite nice to avoid constantly re-genotyping the existing datasets. We could in theory just run GenotypeGVCFs on the incoming data and do a simple merge with the existing data. Are you aware of anyone running a process that looks more like this?. There are some caveats to this: 1) for the incoming batches of data, we could run GenotypeGVCF where we force it to call genotypes from every site that exists in the current dataset. This would promote consistent calling across a common set of sites, 2) after we genotype the incoming batch, we could compare the sites present in that against the sites in the current data. It's likely there would be a handful of novel sites. We could re-run GenotypeGVCFs on the existing data specifically on those new sites (presumably the existing animals are largely WT at those positions), and merge those new sites with the existing data, 3) we then merge the incoming data with the updated core data, which should each have genotypes called at the identical set of sites. Are there any discussions happening about managing/updating large variant datasets like this? Thanks for any ide",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7526:1029,simpl,simple,1029,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7526,1,['simpl'],['simple']
Usability,"relatively straightforward port of CGP. I made minimal changes. Test data is sharable and copied from GATK3. Note: this is going to protected for merging before it's usable,. @lbergelson can you review?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1555:166,usab,usable,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1555,1,['usab'],['usable']
Usability,rg.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:944); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361); 	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.makeInterpretation(SimpleNovelAdjacencyInterpreter.java:48); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.extractSimpleVariants(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:328); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.dispatchJobs(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:303); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvDiscoverFromLocalAssemblyContigAlignmentsSpark.runTool(SvDiscoverFromLocalAssemblyContigAlignmentsSpark.java:170); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:534); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instan,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:5857,Simpl,SimpleNovelAdjacencyInterpreter,5857,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,1,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,rging=ALL interval_padding=0 reference_sequence=human_g1k_v37.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=dbsnp_138.b37.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/home/unix/droazen/bundle_snippets/dbsnp_138.b37.20.21.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViolation=false invertMendelianViolation=false mendelianViolationQualThreshold=0.0 selec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269:1570,simpl,simplifyBAM,1570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269,1,['simpl'],['simplifyBAM']
Usability,"rn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2431 +/- ##; ==========================================; Coverage ? 42.757% ; Complexity ? 5801 ; ==========================================; Files ? 750 ; Lines ? 39425 ; Branches ? 6885 ; ==========================================; Hits ? 16857 ; Misses ? 20600 ; Partials ? 1968; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `86.667% <100%> (ø)` | `11 <0> (?)` | |; | [...dinstitute/hellbender/utils/report/GATKReport.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydC5qYXZh) | `40.196% <66.667%> (ø)` | `16 <0> (?)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=footer). Last update [dc15e61...0d5d1b1](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250:1678,learn,learn,1678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250,2,['learn'],['learn']
Usability,roadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165). at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.main(Main.java:292),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6850:5309,learn,learnAndClearAccumulatedData,5309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850,1,['learn'],['learnAndClearAccumulatedData']
Usability,rror: H5DreadVL_str: failed to read variable length strings; 	at ncsa.hdf.hdf5lib.H5.H5DreadVL(Native Method); 	at org.broadinstitute.hdf5.HDF5File.lambda$readStringArray$0(HDF5File.java:161); 	at org.broadinstitute.hdf5.HDF5File.readDataset(HDF5File.java:349); 	at org.broadinstitute.hdf5.HDF5File.readStringArray(HDF5File.java:150); 	at org.broadinstitute.hellbender.tools.copynumber.utils.HDF5Utils.readIntervals(HDF5Utils.java:62); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.lambda$new; $2(HDF5SimpleCountCollection.java:76); 	at htsjdk.samtools.util.Lazy.get(Lazy.java:25); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.HDF5SimpleCountCollection.getInterva; ls(HDF5SimpleCountCollection.java:85); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readHDF5(Simpl; eCountCollection.java:119); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.SimpleCountCollection.readAndSubset(; SimpleCountCollection.java:98); ```. with annotated_intervals.tsv . ```; $ grep -v '@' annotated_intervals.tsv | cat -n | head; 1	CONTIG	START	END	GC_CONTENT	SEGMENTAL_DUPLICATION_CONTENT; 2	chr1	10001	110000	0.422350	0.000000; 3	chr1	110001	177417	0.441046	0.000000; 4	chr1	227418	267719	0.391445	0.000000; 5	chr1	317720	417719	0.401850	0.000000; 6	chr1	417720	471368	0.471155	0.000000; 7	chr1	521369	621368	0.436950	0.000000; 8	chr1	621369	721368	0.428550	0.000000; 9	chr1	721369	821368	0.442210	0.000000; 10	chr1	821369	921368	0.606500	0.000000. $ grep -v '@' /annotated_intervals.tsv | cat -n | tail; 28717	chrY	28051429	28151428	0.372550	0.000000; 28718	chrY	28151429	28251428	0.380900	0.000000; 28719	chrY	28251429	28351428	0.390730	0.000000; 28720	chrY	28351429	28451428	0.381580	0.000000; 28721	chrY	28451429	28551428	0.394890	0.000000; 28722	chrY	28551429	28651428	0.380360	0.000000; 28723	chrY	28651429	28751428	0.392380	0.000000; 28724	chrY	28751429	28819361	0.4,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7202:4758,Simpl,SimpleCountCollection,4758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7202,1,['Simpl'],['SimpleCountCollection']
Usability,"rs 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it looks like it’s performing pretty well. There is very little data being shuffled relative to the size of the input (~6GB to 133GB input), so it’s not worth looking into optimizing the data structures there. The input data is being read multiple times, so it _might_ be worth seeing if it can be cached by Spark to avoid reading from disk over and over again. This is only worth it if you have sufficient memory available across the cluster to hold the input (which will be bigger than the on-disk size) _plus_ enou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1742,simpl,simple,1742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,2,['simpl'],['simple']
Usability,"rsion(s); 4.5.0.0. ### Description ; According to the filter's description, setting the `--soft-clipped-leading-trailing-ratio` to 0.9 should mean that reads will be filtered out if over 90% of their bases are soft-clipped at either the beginning or end. Therefore, a higher value indicates a more lenient filter, resulting in fewer reads being excluded. However, it seems that the current implementation retains reads with a ratio of 0.9 to 1.0 instead of excluding them, which is the opposite of what the description suggests. In practice, increasing the threshold from 0.3 to 0.6 and then to 0.9 results in more reads being filtered out, which is contrary to the expected behavior. #### Steps to reproduce; 1. Increase the threshold of `--soft-clipped-leading-trailing-ratio` from 0.3 to 0.6, and then to 0.9.; 2. Observe that more reads are being filtered out with higher thresholds. Refer to the attached log for detailed observations: [SoftClippedReadFilter_test.log](https://github.com/user-attachments/files/15935665/SoftClippedReadFilter_test.log). #### Expected behavior; Filter out reads where the ratio of soft-clipped bases to total bases exceeds the given threshold. For example, set the threshold to 0.9 and filter out reads with a ratio > 0.9. #### Actual behavior; Filter out reads where the ratio of soft-clipped bases to total bases is less than the given threshold. For example, set the threshold to 0.9 and filter out reads with a ratio < 0.9. #### Simple Solution Proposal; I believe the issue might be resolved by inverting the comparison operators in the relevant sections of the code. Specifically:. - Change the `>` to `<` in line 66 and line 95 of ; **`src/main/java/org/broadinstitute/hellbender/engine/filters/SoftClippedReadFilter.java`**. This change should make the `test()` function of the `ReadFilter` class return `false` when the ratio exceeds the threshold, aligning with the intended functionality where `true` means retaining the `GATKRead` in the `ReadFilter`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8887:1558,Simpl,Simple,1558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8887,1,['Simpl'],['Simple']
Usability,running RevertBaseQualityScores from Version:4.alpha-70-g10d9ec1-SNAPSHOT on /seq/picard_aggregation/G77386/NA12878/v1/NA12878.bam. ```; java.lang.IllegalArgumentException: end must be >= start. start:13984870 end:13984869; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:45); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$18(ReadWalker.java:79); at org.broadinstitute.hellbender.engine.ReadWalker$$Lambda$45/1492875057.accept(Unknown Source); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:78); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:448); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:98); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:146); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:165); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1473:263,Simpl,SimpleInterval,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1473,6,['Simpl'],['SimpleInterval']
Usability,"running wgs1 with current code in master, we get the following stack trace:. Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01001938v1_decoy start:0 end:0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:686); 	at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:60); 	at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:36); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:78); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:293); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:42); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.DiscoverVariantsFromContigAlignmentsSAMSpark.lambda$discoverNovelAdjacencyFromChimericAlignments$7(DiscoverVariantsFromContigAlignmentsSAMSpark.java:409); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.tryAdvance(ArrayList.java:1351); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); 	at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:161); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at org.apache.spark.shuffle.sor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874:306,Simpl,SimpleInterval,306,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874,4,['Simpl'],['SimpleInterval']
Usability,"s 30169 30168 -1 ; + Misses 6771 6768 -3 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <100%> (ø)` | `2 <0> (ø)` | :x: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `84.211% <100%> (-0.164%)` | `53 <0> (ø)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `66.316% <33.333%> (+2.03%)` | `28 <4> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=footer). Last update [987e2f9...05211ec](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447:2186,learn,learn,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447,2,['learn'],['learn']
Usability,s 65015 65015 ; Branches 10124 10124 ; ===============================================; + Hits 51965 51970 +5 ; + Misses 9016 9012 -4 ; + Partials 4034 4033 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...v/evidence/experimental/FindSmallIndelRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9leHBlcmltZW50YWwvRmluZFNtYWxsSW5kZWxSZWdpb25zLmphdmE=) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `33.588% <0%> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `55.652% <16.667%> (ø)` | `29 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `54.857% <0%> (-1.143%)` | `28% <0%> (-1%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3556#issuecomment-328135262:1591,Simpl,SimpleStrandSwitchVariantDetector,1591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3556#issuecomment-328135262,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"s are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be available, as it is in this workflow (tumor-only would require some work to identify the normal state, as mentioned previously). I'd rather just roll that, evaluate it, and merge it instead. Key here is that we sidestep the deficiencies of the current CR-only caller, which also shares the blame for this ""CNLOH"" issue (since these events aren't called in the normal and don't become candidates for tagging, as currently implemented). > And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me. I've already expanded the scope of https://github.com/broadinstitute/gatk/issues/4115 to include this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:3618,simpl,simply,3618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['simpl'],['simply']
Usability,"s method than our previous probabilistic approaches. Even SNP segmentation will be much cheaper. > What is the name of this approach? ""KernSeg""?. Not sure...I couldn't find an R package, although an R/C implementation is mentioned in the paper. But the python implementation is straightforward and a pure Java implementation should not be so bad. There are some cythonized numpy methods that my python implementation used, but I think equivalent implementations of these methods should be relatively fast in pure Java as well. > What variant of the algorithm did you implement? the paper lists several. I implemented what they call ApproxKSeg. It's an approximate version that combines binary segmentation with the low-rank approximation to the Gaussian kernel. > I haven't read the paper in detail yet, but is it possible to choose a conservatively large number of possible break points and then filter bad break points, possibly based on the rapid decline of the change point probability? i.e. does the algorithm naturally produce change point probabilities?. Yes, you can oversegment and then choose which breakpoints to retain. However, there are no proper changepoint probabilities, only changepoint costs. Adding a penalty term based on the number of changepoints seems to perform relatively well in simple tests, but one could certainly devise other ways to filter changepoints (some of which could yield probabilities, if you are willing to assume a probabilistic model). I think we should just think of this as a fast, heuristic, non-parametric method for finding breakpoints in multidimensional data. > Is it possible to throw in additional change points incrementally, without doing extra work, until a certain criterion is met? (see above). The version I implemented adds changepoints via binary segmentation. The time complexity required to split a segment is linear in the number of points contained in the segment, although some care must be taken in the implementation to ensure this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321140715:2802,simpl,simple,2802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321140715,2,['simpl'],['simple']
Usability,"s strategy will cause us to miss obvious hets in the tumor (~80x). This is now relevant for two reasons: 1) it seems that we will want to run the filter with more stringent parameters, as higher base error rates are causing homs to leak past the filter, which in turn affects the fit of the allele-fraction model (which only attempts to model hets) by biasing normal segments towards unbalanced, and 2) we now want to run ModelSegments separately on the normal to allow for the filtering of germline events. So we want to be more stringent with low-coverage normals without affecting our high-coverage tumors. For example, here's some hg38 NovaSeq FFPE WGS data from a ~40x normal:. ![download](https://user-images.githubusercontent.com/11076296/43977946-9bd0a1bc-9cb3-11e8-9d7f-016a99c1c173.png). Compare to an hg19 TCGA WGS ~40x normal:. ![download 1](https://user-images.githubusercontent.com/11076296/43978051-f8820770-9cb3-11e8-8e16-13b51792614f.png). The hom-ref tail in the first plot is much fatter and clearly leaks into the het cloud. Also curious is that the het cloud is far less binomial (or even beta-binomial---note also the absence of the tail extending to the origin). I am still not sure why the incoming data looks different. There are several confounding factors: NovaSeq vs. HiSeq, hg38 vs. hg19, AF > 2% gnomAD sites vs. AF > 10% 1000G sites, FFPE vs. frozen, etc. I have not seen enough examples/combinations to be able to say which are the most important factors. Changing the genotyping/filtering strategy can get around this change in the data without a corresponding change in the allele-fraction model for now, but getting the data to look as good as possible upstream would be even better. Another thought: would be nice if the strategy was easily compatible with an eventual implementation of multi-sample segmentation, which would require that the same sites are used in both the tumor and the normal. We would want to strike a balance between maximizing the number of ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218:1448,clear,clearly,1448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218,2,['clear'],['clearly']
Usability,"s supergroup 0 2017-10-11 14:19 /gatk4/output_2.bam.parts. **The spark-submit:**. bash-4.2$ spark-submit; Usage: spark-submit [options] <app jar | python file> [app arguments]; Usage: spark-submit --kill [submission ID] --master [spark://...]; Usage: spark-submit --status [submission ID] --master [spark://...]. Options:; --master MASTER_URL spark://host:port, mesos://host:port, yarn, or local.; --deploy-mode DEPLOY_MODE Whether to launch the driver program locally (""client"") or; on one of the worker machines inside the cluster (""cluster""); (Default: client).; --class CLASS_NAME Your application's main class (for Java / Scala apps).; --name NAME A name of your application.; --jars JARS Comma-separated list of local jars to include on the driver; and executor classpaths.; ....... **the spark-shell**; bash-4.2$ spark-shell; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Failed to created SparkJLineReader: java.io.IOException: Permission denied; Falling back to SimpleReader.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 1.6.0; /_/. Using Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_91); Type in expressions to have them evaluated.; Type :help for more information.; Spark context available as sc (master = yarn-client, app id = application_1507683879816_0007).; Wed Oct 11 14:25:24 CST 2017 Thread[main,5,main] java.io.FileNotFoundException: derby.log (Permission denied); ----------------------------------------------------------------; Wed Oct 11 14:25:24 CST 2017:; Booting Derby version The Apache Software Foundation - Apache Derby - 10.11.1.1 - (1616546): instance a816c00e-015f-0a1b-f1bd-00002ce33928 ; on database directory /tmp/spark-98953d35-8594-4907-b4a5-0870f1d17b3e/metastore with class loader sun.misc.Launcher$AppClassLoader@5c647e05 ; Loaded from file:/opt/cloudera/parcels/CDH-5.12.1-1.cdh5.12.1.p0.3/jars/derby-10.11.1.1.jar; java.vendor=Ora",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240:1174,Simpl,SimpleReader,1174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-335696240,1,['Simpl'],['SimpleReader']
Usability,"s that will swap populations to see if these can help get the model unstuck.; - Need to add outlier absorption to the model, which appears to be critical for inference of subclonal populations from real data (i.e., ACNV output), which may have spurious segments, oversegmentation, etc. Simple clonal models appear to work reasonably well without this, though.; - [x] Evaluate algorithm on simulated data.; - Implemented simple Queue pipeline for running CLI on simulated ACNV segment files. Takes <2 minutes for ~1000 iterations for each sample, can run 100s of samples in parallel on the gsa clusters.; - Need to write up some scripts to automatically calculate and plot metrics.; - [x] Evaluate algorithm on real data; - Some initial runs on HCC1143 purity series show reasonable results for the clonal model, i.e., purity is recovered within credible intervals (question: what are the error bars on the purities of the samples?). Subclonal performance is a little less clear due to 1) no real ground truth, 2) events in the normal, and 3) lack of outlier absorption.; - Can we get a hold of some cleaner purity series?; - [ ] Document algorithm in technical whitepaper. ---. @samuelklee commented on [Thu Dec 08 2016](https://github.com/broadinstitute/gatk-protected/issues/750#issuecomment-265798051). The first release of this tool will most likely include the following:. - Some refactoring to MCMC package and addition of an EnsembleSampler, which implements affine-invariant ensemble sampling from Goodman & Weare 2010 (this is the same method used by the emcee python package). This method is critical for sampling our highly multimodal posterior well. - Output of 1) all population fraction / ploidy MCMC samples, and 2) average variant profile and 3) posterior summaries at the posterior mode (determined by naive binning of samples). - No plotting. Early next quarter:. - [ ] Unit tests for EnsembleSampler. - [ ] Allowing for >1 tumor population. The model already allows for this, but so",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2909:2163,clear,clear,2163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2909,1,['clear'],['clear']
Usability,"s were aligned; INFO 21:38:54,554 ProgressMeter - done 3.31246907E8 31.8 m 5.0 s 99.7% 31.8 m 5.0 s ; INFO 21:38:54,554 ProgressMeter - Total runtime 1905.29 secs, 31.75 min, 0.53 hours ; ------------------------------------------------------------------------------------------; Done. There were 4 WARN messages, the first 4 are repeated below.; WARN 17:39:57,688 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; WARN 18:13:42,039 SimpleTimer - Clock drift of -1,503,348,737,016,211,299 - -1,503,346,772,578,127,937 = 1,964,438,083,362 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 20:14:18,043 SimpleTimer - Clock drift of -1,503,355,916,564,964,097 - -1,503,348,737,015,111,124 = 7,179,549,852,973 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; WARN 21:10:35,064 SimpleTimer - Clock drift of -1,503,359,203,412,549,926 - -1,503,355,916,564,817,209 = 3,286,847,732,717 nanoseconds detected, vs. max allowable drift of 5,000,000,000. Assuming checkpoint/restart event. ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```. ### Notice the following line from above. > 0 variants were aligned. Also, it would be great if the tool, which appears to keep track of the lengths of reference alleles that are too long, could give me the **maximum length** reference allele so that I can go back and set the `--reference_window_stop` argument appropriately in a second round so that I can left-align _all_ of my variants. . ### MD5 and looking into the files, we see input and output are different and in fact the tool did change allele representations:; ```; WMCF9-CB5:Mutect2 shlee$ gzcat zeta_af-only-gnomad_Hg19toGRCh38.vcf.gz | grep -v '##' > zeta_headless.txt; WMCF9-CB5:Mutect2 shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 6d93f1ea32c99a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487:7947,Simpl,SimpleTimer,7947,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487,1,['Simpl'],['SimpleTimer']
Usability,"s.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ------------; ### On the problem of having a confusing TODO for ; `boolean SimpleChimera.isCandidateInvertedDuplication()`. The todo message. > TODO: 5/5/18 Note that the use of the following predicate is currently obsoleted by; {@link AssemblyContigWithFineTunedAlignments#hasIncompletePictureFromTwoAlignments()}; because the contigs with this alignment signature is classified as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:2441,Simpl,SimpleChimera,2441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['Simpl'],['SimpleChimera']
Usability,s.ReferenceFileSparkSource.getReferenceBases(ReferenceFileSparkSource.java:60); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.getRefBaseString(BreakEndVariantType.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType.access$200(BreakEndVariantType.java:20); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.<init>(BreakEndVariantType.java:253); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.BreakEndVariantType$InterChromosomeBreakend.getOrderedMates(BreakEndVariantType.java:261); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyAndAltHaplotype.toSimpleOrBNDTypes(NovelAdjacencyAndAltHaplotype.java:246); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.inferType(SimpleNovelAdjacencyInterpreter.java:129); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.SimpleNovelAdjacencyInterpreter.lambda$inferTypeFromSingleContigSimpleChimera$24ddc343$1(SimpleNovelAdjacencyInterpreter.java:107); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:217); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1094); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1085); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1020); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1085); 	at org.apache.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6070:1626,Simpl,SimpleNovelAdjacencyInterpreter,1626,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6070,2,['Simpl'],['SimpleNovelAdjacencyInterpreter']
Usability,"s.java:304); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:4627,Learn,LearnReadOrientationModel,4627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"s; - [x] GetSampleName; - [x] PathSeqBuildKmers; - [x] PathSeqBuildReferenceTaxonomy; - [x] PathSeqBwaSpark; - [x] PathSeqFilterSpark; - [x] PathSeqPipelineSpark; - [x] PathSeqScoreSpark; - [x] ASEReadCounter; - [x] CompareBaseQualities; - [x] FixMisencodedBaseQualityReads; - [x] LeftAlignIndels; - [x] RevertBaseQualityScores; - [x] SplitNCigarReads; - [x] UnmarkDuplicates; - [x] DiscoverVariantsFromContigAlignmentsSAMSpark; - [x] FindBadGenomicKmersSpark; - [x] FindBreakpointEvidenceSpark; - [x] StructuralVariationDiscoveryPipelineSpark; - [x] BwaSpark; - [x] MarkDuplicatesSpark; - [x] MeanQualityByCycleSpark; - [x] ParallelCopyGCSDirectoryIntoHDFSSpark; - [x] QualityScoreDistributionSpark; - [x] SortReadFileSpark; - [x] AnnotatePairOrientation; - [x] CountVariants; - [x] GatherVcfsCloud; - [x] GenomicsDBImport; - [x] BwaMemIndexImageCreator; - [x] CompareDuplicatesSpark; - [x] ConvertHeaderlessHadoopBamShardToBam. 32 total. #### Those needing tags within the Picard repo:; - [x] CollectIndependentReplicateMetrics; - [x] CollectWgsMetricsWithNonZeroCoverage; - [x] UmiAwareMarkDuplicatesWithMateCigar; - [x] CrosscheckReadGroupFingerprints; - [x] SetNmAndUqTags; - [x] SimpleMarkDuplicatesWithMateCigar. Also added `@BetaFeature` tag and `(Experimental)` label in summary to first three, given they are currently categorized under ; ```; Alpha Tools: | Tools that are currently UNSUPPORTED until further testing and maturation.; -- | --; ```. ---; ### Tools missing from `--list` that show up in gatkDocs ; - [x] CallCopyRatioSegments `added beta tag`; - PlotDenoisedCopyRatios; - PlotModeledSegments. These in fact have the `CommandLineArgumentProperties` and should show up if I build from master. They just don't show up for beta.6. Added `@BetaFeature` tag to CallCopyRatioSegments. ### Tools missing altogether from lists and docs; - [ ] DepthOfCoverage; - [ ] VariantAnnotator; - [ ] CombineGVCFs; - [ ] Funcotator; - there are likely others; we will get to them as they come up",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3847:1625,Simpl,SimpleMarkDuplicatesWithMateCigar,1625,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3847,1,['Simpl'],['SimpleMarkDuplicatesWithMateCigar']
Usability,"sbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclN0cnVjdHVyYWxWYXJpYW50c0Zyb21BbGlnbmVkQ29udGlnc1NBTVNwYXJrLmphdmE=) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `100% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DaGltZXJpY0FsaWdubWVudC5qYXZh) | `57.831% <33.333%> (ø)` | `25 <1> (ø)` | :arrow_down: |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `66.917% <66.667%> (ø)` | `38 <1> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/SVVariantConsensusDiscovery.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNEaXNjb3ZlcnkuamF2YQ==) | `82.653% <73.913%> (ø)` | `25 <1> (?)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=footer). Last update [d054e7a...4ffa301](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361:4153,learn,learn,4153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361,2,['learn'],['learn']
Usability,"scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. 8/02/23 23:06:24 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/02/23 23:06:24 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/02/23 23:06:24 INFO spark.SparkContext: Successfully stopped SparkContext; 23:06:24.240 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 23, 2018 11:06:24 PM EST] org.broadinstitute.hellbender.tools.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:3551,Simpl,SimpleInterval,3551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:7230,Simpl,SimpleInterval,7230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,"scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:99); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Invalid interval. Contig:chrUn_JTFH01000312v1_decoy start:0 end:0; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations$BreakpointsInference.getLeftJustifiedBreakpoints(NovelAdjacencyReferenceLocations.java:86); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.leftJustifyBreakpoints(NovelAdjacencyReferenceLocations.java:301); at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.NovelAdjacencyReferenceLocations.<init>(NovelAdjacencyReferenceLocations.java:46); ... 18 more; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Shutdown hook called; 18/02/23 23:06:24 INFO util.ShutdownHookManager: Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/farrell/spark-94fa6743-3d29-4748-b8f8-d13a52dfed31; ```. The command line is:. ```; gatk --java-options ""-Djava.io.tmpdir=tmp"" StructuralVariationDiscoveryPipelineSpark \; -R $REF \; --aligner-index-image GRCh38_full_analysis_set_plus_decoy_hla.f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458:14022,Simpl,SimpleInterval,14022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458,1,['Simpl'],['SimpleInterval']
Usability,"scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); ... 24 more; 05:12:04.045 INFO HaplotypeCallerSpark - Shutting down engine; [May 18, 2017 5:12:04 AM UTC] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 131.63 minutes.; Runtime.totalMemory()=16201547776; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 1 times, most recent failure: Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayI; ndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.Res",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:6589,clear,clear,6589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['clear'],['clear']
Usability,"scales (noting that longer window lengths allow for more subtle changepoints to be detected) works well in practice. For example, here are what the cost functions look like for window sizes of 8, 16, 32, and 64:. ![2](https://user-images.githubusercontent.com/11076296/29582011-210d37b8-8749-11e7-9383-0c657232347e.png). ![3](https://user-images.githubusercontent.com/11076296/29582016-23fbc6a6-8749-11e7-951e-f618e8489a0b.png). ![4](https://user-images.githubusercontent.com/11076296/29582044-3eb20a1e-8749-11e7-84a0-3734bad15e1f.png). ![5](https://user-images.githubusercontent.com/11076296/29582047-410ac490-8749-11e7-8a98-b2098cf1b5ea.png); 4) For each of these cost functions, find (up to) the _C<sub>max</sub>_ most significant local minima. The problem of finding local minima of a noisy function can be solved by using topological persistence (e.g., https://people.mpi-inf.mpg.de/~weinkauf/notes/persistence1d.html and http://www2.iap.fr/users/sousbie/web/html/indexd3dd.html?post/Persistence-and-simplification). A straightforward watershed algorithm can sort all local minima by persistence in linear time after an initial sort of the data.; 5) These sets of local minima from all window sizes together provide the pool of candidate changepoints (some of which may overlap exactly or approximately). We perform backwards selection using the global segmentation cost. That is, we compute the global segmentation cost given all the candidate changepoints, calculate the cost change for removing each of the changepoints individually, remove the changepoint with the minimum cost change, and repeat. This gives the global cost as a function of the number of changepoints _C_.; 6) Add a penalty _a C + b C log(N / C)_ to the global cost and find the minimum to determine the number of changepoints. For the above simulated data, _a = 2_ and _b = 2_ works well, recovering all of the changepoints in the above example with no false positives:; ![6](https://user-images.githubusercontent.com/1107",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586:2004,simpl,simplification,2004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586,2,['simpl'],['simplification']
Usability,"se** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2511 +/- ##; ===============================================; - Coverage 76.259% 76.256% -0.003% ; + Complexity 10865 10864 -1 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; - Hits 30155 30154 -1 ; Misses 6771 6771 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `94.083% <ø> (ø)` | `73 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=footer). Last update [724fbd0...1a7a561](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091:1800,learn,learn,1800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091,2,['learn'],['learn']
Usability,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:853,clear,cleared,853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617,2,['clear'],['cleared']
Usability,simple tests added in #884,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/709#issuecomment-160836902:0,simpl,simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/709#issuecomment-160836902,1,['simpl'],['simple']
Usability,simplify BQSR covariates handling,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/185:0,simpl,simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/185,2,['simpl'],['simplify']
Usability,simplify logic slightly,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8634:0,simpl,simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8634,2,['simpl'],['simplify']
Usability,simplify tests that use ReadsProcessingPipelineTestData,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4318:0,simpl,simplify,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4318,2,['simpl'],['simplify']
Usability,simply rebasing does not do it. back to @lbergelson for advice,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/844#issuecomment-142767158:0,simpl,simply,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/844#issuecomment-142767158,1,['simpl'],['simply']
Usability,"spark.scheduler.TaskSetManager: Lost task 20.5 in stage 50.0 (TID 45798, shuang-g94794-chmi-chmi3-wgs1-cram-bam-feature-w-2.c.broad-dsde-methods.internal, executor 44): htsjdk.samtools.SAMException: Unable to load chr14(100526932, 100526932) from /reference/Homo_sapiens_assembly38.fasta; 	at htsjdk.samtools.reference.AbstractIndexedFastaSequenceFile.getSubsequenceAt(AbstractIndexedFastaSequenceFile.java:207); 	at htsjdk.samtools.reference.IndexedFastaSequenceFile.getSubsequenceAt(IndexedFastaSequenceFile.java:49); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceHadoopSparkSource.getReferenceBases(ReferenceHadoopSparkSource.java:31); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceBases(ReferenceMultiSparkSource.java:89); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SvType.extractRefBases(SvType.java:161); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.SimpleSVType$DuplicationTandem.<init>(SimpleSVType.java:190); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.inferSimpleTypeFromNovelAdjacency(ContigChimericAlignmentIterativeInterpreter.java:229); 	at org.broadinstitute.hellbender.tools.spark.sv.discovery.inference.ContigChimericAlignmentIterativeInterpreter.lambda$discoverVariantsFromChimeras$610a78cb$1(ContigChimericAlignmentIterativeInterpreter.java:84); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collecti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6064:1459,Simpl,SimpleSVType,1459,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6064,1,['Simpl'],['SimpleSVType']
Usability,src=pr&el=desc) will **decrease** coverage by `6.127%`.; > The diff coverage is `89.756%`. ```diff; @@ Coverage Diff @@; ## master #5252 +/- ##; ===============================================; - Coverage 86.757% 80.631% -6.127% ; + Complexity 29763 28463 -1300 ; ===============================================; Files 1825 1830 +5 ; Lines 137699 138368 +669 ; Branches 15176 15237 +61 ; ===============================================; - Hits 119464 111567 -7897 ; - Misses 12721 21438 +8717 ; + Partials 5514 5363 -151; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5252?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `94.118% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nterval/SimpleAnnotatedIntervalWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `98.148% <ø> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...notatedinterval/SimpleAnnotatedIntervalWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5252/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL1NpbXBsZUFubm90YXRlZEludGVydmFsV3JpdGVyLmphdmE=) | `77.778% <ø> (+1.852%)` | `7 <0> (+1)` | :arrow_up: |; | [,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050:1261,Simpl,SimpleAnnotatedIntervalWriterUnitTest,1261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5252#issuecomment-426488050,1,['Simpl'],['SimpleAnnotatedIntervalWriterUnitTest']
Usability,"ssibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs here). Will try to track down the source of the discrepancy. EDIT 3: Added segment union based on single-changepoint detection using kernel segmentation.; - [x] Segment union should be replaced by a proper joint kernel segmentation. EDIT: I've added this, but there could be some minor improvements. Right now, only use one het per copy-ratio interval and throw away those off-target/bin. There are a few percent of targets/bins that have more than one het, and we could potentially rescue the off-target/bin hets as well with some care.; - Old code and models are used for modeling. Since the old allele-fraction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:3676,simpl,simple,3676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['simpl'],['simple']
Usability,such tests mostly exist in VectorPairHMMUnitTest that @gspowley wrote. I think we could just move them there and add a simple java implementation of `computeLikelihoods` that is pretty much a copy of code from `LoglessPairHMM`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2030#issuecomment-234598263:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2030#issuecomment-234598263,1,['simpl'],['simple']
Usability,"sultSize=0 \; --conf spark.driver.userClassPathFirst=true \; --conf spark.executor.userClassPathFirst=true \; --conf spark.io.compression.codec=lzf \; --conf spark.yarn.executor.memoryOverhead=600 \; --executor-memory ${execMem}g \; --num-executors $execs \; --executor-cores $cores \; bin/cleanHellbender/gatk/build/libs/gatk-all-*-spark.jar \; ReadsPipelineSpark \; --sparkMaster yarn-client \; -I hdfs:///user/akiezun/CEUTrio.HiSeq.WEx.b37.NA12892.bam \; -R hdfs:///user/droazen/bqsr/human_g1k_v37.2bit \; --programName ${name} \; -O $bamout \; --knownSites hdfs:////user/akiezun/dbsnp_138.b37.excluding_sites_after_129.vcf \; --emit_original_quals \; --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES; ```. exec=24; cores=5; execMem=25. fails with . ```; java.lang.IllegalArgumentException: SimpleInterval is 1 based, so start must be >= 1, start: 0; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:58); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:33); at org.broadinstitute.hellbender.utils.baq.BAQ.getReferenceWindowForRead(BAQ.java:525); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:46); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine$BQSRReferenceWindowFunction.apply(BaseRecalibrationEngine.java:41); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithRefBases.lambda$addBases$c54addeb$1(BroadcastJoinReadsWithRefBases.java:52); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1234:1152,Simpl,SimpleInterval,1152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1234,1,['Simpl'],['SimpleInterval']
Usability,"sv; 12:16:19.960 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Applications/genomicstools/gatk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:1736,Learn,LearnReadOrientationModel,1736,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"t annoying things that I repeatedly encountered during the Java 17 port that we should look into. . **Log Spam Issues:** (these result in lots of error log spam that make the logs super hard to scan when there is a failure):. - The WDL test logs are riddled with “localization by hard link failed” and ""Docker not found"" failures, which makes it hard to scan them for real failures. Can we eliminate/fix these ?; - The logs have a few gradle task dependency warnings - we should hunt down the cause. ; - We routinely pull ~800 branches every time we run git clone for a CI job. Can we do shallow git clones?; - We're using deprecated gradle features that result in warnings in the logs, these should be updated.; - The test runner seems to serialize (via toString) every argument to every test method. Many of these have *huge* ""toString"" representations (i.e., `org.broadinstitute.hellbender.tools.spark.sv.integration.ExtractOriginalAlignmentRecordsByNameSparkIntegrationTest`) that fill the logs with reams of huge test values. We should codify/unify the test case wrapper class that we use in htsjdk for these cases. . **Other Issues:**. - We should review the shadowJar contents - it includes some surprising stuff (i.e., the publish-picard.sh script we use to publish picard).; - Do we still need the unpacktestjar task in `dockertest.gradle`, to work around testNG inability to find tests in a jar ?; - The test matrix job names all look the same in the github UI because only the first N characters are displayed, and they all have the same prefix. We should rename them so they start with unique prefixes.; - The library it.unimi.dsi:fastutil:7.0.61 appears to not be used [Fix] (reported in IntelliJ/Project Structure/Problems).; - It's non-intuitive that the *Dockerfile* builds the `run_unit_tests.sh` script. Is that necessary - can this not be built on demand ? Also, it should be named to run_tests.sh, since it doesn't run unit tests, but rather whatever test group it is told to run.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8087:1790,intuit,intuitive,1790,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8087,1,['intuit'],['intuitive']
Usability,"t gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high priority, so thanks for kicking off the evaluations, and thanks for your willingness to discuss our options. Let me know if you agree with the rest of the plan!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:3031,feedback,feedback,3031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639,2,['feedback'],['feedback']
Usability,"t shows how to utilize Spark. There is an example from ChrisW in <https://github.com/broadinstitute/gatk/issues/3853>:. ```; 	-- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. ---; ## DiscoverVariantsFromContigAlignmentsSAMSpark. 1. ""Parse"" is vague. How about: ; Parses aligned contig assemblies of genomic breakpoints and calls structural variants. And `6. ` from above. ---; ## ExtractOriginalAlignmentRecordsByNameSpark. 1. Subsets reads by names; 2. I think you mean FilterSamReads (Picard) and not PrintReads. AFAIK, PrintReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` from above. ---; ## FilterLongReadAlignmentsSAMSpark. 1. In the one-line summary, I'm not clear on what is meant by ""Filters"". Based on the result file, seems like it collects metrics on each contig alignment.; 2. ; 3. If metrics, then DiagnosticsAndQCProgramGroup.java. And `6. ` from above. ---; ## FindBadGenomicKmersSpark. 1. The term ""copy number"" should be reserved in reference to CNV analyses. So instead, how about:; Identify sequence contexts that occur at high frequency in a reference; 2. Please define a kmer. If only a reference fasta is required (as listed under Inputs) great. But if the tool also depends on a FAI index and DICT dictionary, please do include them. Also, it would be good to provide an example of how such information is used in SV discovery, e.g. ""the resulting file can be given to FindBreakpointEvidenceSpark, which will then ignore such sequence contexts during analysis."" Also would be good to mention that the default kmer size (--k-size 51) is optimized for human if indeed this is the case.; 3. ReferenceProgramGroup.java. And `6. ` from above. ---; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:2421,clear,clear,2421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,2,['clear'],['clear']
Usability,"t(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 8318",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:2992,Learn,LearnReadOrientationModel,2992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,taWNzREJDb25zdGFudHMuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...roadinstitute/hellbender/engine/FeatureWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZVdhbGtlci5qYXZh) | `90.323% <100%> (+0.667%)` | `9 <1> (ø)` | :arrow_down: |; | [...tcollections/ReferenceInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvUmVmZXJlbmNlSW5wdXRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `3 <2> (+2)` | :arrow_up: |; | [...oadinstitute/hellbender/engine/FeatureManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.275% <100%> (+0.275%)` | `47 <3> (+1)` | :arrow_up: |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `94.048% <100%> (ø)` | `46 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/VariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFdhbGtlci5qYXZh) | `90.909% <100%> (+0.909%)` | `10 <0> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `100% <100%> (ø)` | `14 <2> (ø)` | :arrow_down: |; | [...nstitute/hellbender/engine/MultiVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2626?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9l,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2626#issuecomment-297561163:2141,Simpl,SimpleInterval,2141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2626#issuecomment-297561163,1,['Simpl'],['SimpleInterval']
Usability,tent=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudEJhc2VzLmphdmE=) | `0.000% <0.000%> (-100.000%)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/7818/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `0.000% <0.000%> (-100.000%)` | :arrow_down: |; | [...g/broadinstitute/hellbender/utils/mcmc/Decile.java](https://codecov.io/gh/broadinstitute/gatk/pull/7818/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL0RlY2lsZS5qYXZh) | `0.000% <0.000%> (-100.000%)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/7818/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0.000% <0.000%> (-100.000%)` | :arrow_down: |; | [...adinstitute/hellbender/engine/ReferenceWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/7818/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlV2Fsa2VyLmphdmE=) | `0.000% <0.000%> (-100.000%)` | :arrow_down: |; | [...adinstitute/hellbender/utils/R/RScriptLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/7818/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7818#issuecomment-1110214199:2940,Simpl,SimpleSVD,2940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7818#issuecomment-1110214199,1,['Simpl'],['SimpleSVD']
Usability,tests for CigarUtils + refactored methods in CigarUtils. ; Did not add tests to isValid because pull req #380 is addressing this method. There's a potential issue in countRefBasesBasedOnCigar - it's not clear why the implementation does what it does. @amilev can you comment on the intended semantics of this method and whether it can/should use `CigarOperator.consumesReferenceBases`?. addresses #153 and #450 ; @vruano please review.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/455:203,clear,clear,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/455,1,['clear'],['clear']
Usability,"thanks @gspowley I'll measure it again tomorrow. I see the KMP code has an array allocation - I wonder if this accounts for the relatively small difference between string and KMP. I'll also try again with my mud-room implementation and compare. Also, my Mac is clearly slower than what you're running on :) I'll try David's suggestion too and limit to active regions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204227646:261,clear,clearly,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204227646,1,['clear'],['clearly']
Usability,thanks for the review @kcibul. I made some changes accordingly. re: PrepareCallset file of sample names. That would be nice! It would make this workflow simpler and it also simplifies the access requirements for PrepareCallset. re: Dockstore. We actually ruled this out because Terra says that the definition of a method configuration can change automatically if its updated in dockstore. Which can be useful but it adds a security risk since a compromised Dockstore can change the definition of the production AoU extraction WDL which runs with highly elevated permissions. We already have a script that creates method configurations from github so I can probably add something a little hacky to resolve relative imports to the raw github file that it refers to.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686:153,simpl,simpler,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686,4,['simpl'],"['simpler', 'simplifies']"
Usability,"that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstream of the interval end. . - I created `StrandedInterval` mostly just as a data container since I was often passing around an interval and an associated strand, and using them in conjunction with the `PairedStrandedIntervalTree` data structure. My goal with those was to have them be utility classes that could be used by anyone without regards to the particular mechanics of imprecise evidence clustering I've implemented here. I'd prefer to put the definition of how we're interpreting the interval and strand in our logic classes (`BreakpointEvidence`, `EvidenceTargetLink`, and EvidenceTargetLinkClusterer`). Does that make sense?. - A ""distal target region"" can be represented by a `StrandedInterval`. So can the original, proximal (non-distal) location of the breakpoint evidence. An `EvidenceTargetLink` has the two `StrandedInterval` objects representing the proximal and distal locations, and the count of evidence types in the link cluster. Does that make things more clear?. I've added some ASCII-art visual examples to `DiscordantReadPairEvidence.getDistalTargets` and `SplitRead.getDistalTargets`. Do those help?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:2977,clear,clear,2977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,2,['clear'],['clear']
Usability,"the code should be reviewed with Murphy's Machine Learning book, chapter 21.6; @davidbenjamin @yfarjoun @cseed please review and comment - there are some not optimal decisions left over from the gatk3 implementation but the focus here is on getting a tested version that matches a known textbook or paper that we can build upon",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/387:50,Learn,Learning,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/387,1,['Learn'],['Learning']
Usability,"the design is simple - filters should filter, not blow up. There could be a tool that takes a set of filters and blows up if they fail. But the filter's job is to filter not blow up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76831428:14,simpl,simple,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76831428,1,['simpl'],['simple']
Usability,"the invalid reads strikes back - i got this when running the ReadsPipelineSpark on qurynamesorted file `hdfs:///user/akiezun/data/CEUTrio.HiSeq.WEx.b37.NA12892.readnamesort.bam`:. ```; Job aborted due to stage failure: Task 47 in stage 2.0 failed 4 times, most recent failure: Lost task 47.3 in stage 2.0 (TID 680, dataflow05.broadinstitute.org): java.lang.IllegalArgumentException: ; Invalid interval. Contig:20 start:62720124 end:62720123; at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:59); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:34); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:46); at org.broadinstitute.hellbender.engine.spark.BroadcastJoinReadsWithVariants.lambda$join$3d1c3858$1(BroadcastJoinReadsWithVariants.java:27); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1030); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:30); at org.broadinstitute.hellbender.tools.spark.transforms.BaseRecalibratorSparkFn.lambda$apply$26a6df3e$1(BaseRecalibratorSparkFn.java:28); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:156); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297); at org.apache.spark.rdd.RDD.iterat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1560:481,Simpl,SimpleInterval,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1560,6,['Simpl'],['SimpleInterval']
Usability,"the simplest example, for sanity checking of instalations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/920:4,simpl,simplest,4,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/920,1,['simpl'],['simplest']
Usability,the tests that use ReadsProcessingPipelineData are complicated because they use multiple implementations of GATKRead. Since we're removing our second implementation we should consider simplifying the test code.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4318:184,simpl,simplifying,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4318,1,['simpl'],['simplifying']
Usability,"the transcript type field has different values for each transcript. This causes many transcripts to no longer be categorized as protein coding. Therefore, the ground truth (mostly/totally in `FuncotatorIntegrationTest`) had to be modified. *Please carefully review the ground truth changes*.; - Introduces the `CompsiteOutputRenderer`, which is composed of multiple output renderers. This is used when output type is `SEG`, so that it can write both output files simultaneously.; - Introduces the `GeneListOutputRenderer`. This does not write anything to disk until the entire input file is processed. The actual writing happens during the `close()` command. This is necessary since it cannot actually render its output until all segments have been seen. This output renderer also relies heavily on specific funcotation fields being in the input `FuncotationMap`. Internally, the gene list output renderer uses the `SimpleTsvOutputRenderer` (see below) to do the actual writing.; - Introduces the `SimpleTsvOutputRenderer`. This output renderer is very flexible and renders a tab-separated text file based on several output rules. Formats are driven through config files. And developers can limit the output columns to ignore extraneous funcotation fields. Note that excluded fields are honored, regardless. If a configuration + parameter combination would result in this class producing an empty file, an exception is thrown. More notes are in the javadocs of the class.; - Currently, only the `GencodeFuncotationFactory` can actually funcotate segments. ; - Code base currently enforces only small mutations when running `Funcotator` (segs are funcotated as CANNOT_DETERMINE) and only segments when running `FuncotateSegments` (small mutations produce exception). This is enforced with flags in the code. The backend does not disallow a mixture for future use. This may prove important when funcotating CNVs from VCFs produced by tools other than `ModelSegments`.; - Added copy creation method for F",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5941:2039,Simpl,SimpleTsvOutputRenderer,2039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5941,1,['Simpl'],['SimpleTsvOutputRenderer']
Usability,"there is one thing i dont like - if i revert the change i made in removeNonRefAndUnusedAltAlleles(), the one to simplify, these tests pass locally for me, with the test files as-is. do you see this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582253636:112,simpl,simplify,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582253636,2,['simpl'],['simplify']
Usability,"these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be available, as it is in this workflow (tumor-only would require some work to identify the normal state, as mentioned previously). I'd rather just roll that, evaluate ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:2913,clear,clearly,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['clear'],['clearly']
Usability,this PR puts together BWA and MarkDuplicates. This is a prelude to BWA+MD+BQSR (but simpler because BQSR requires a 2bit reference and bwa wants a fasta reference). It extracts the core BWA/Spark code into a BwaSparkEngine and call that from both BwaSpark and the new pipeline. . It also improves the handling of sorting order for spark writing - adds a way to sort by queryname (relevant for mark duplicates). @tomwhite can you review?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1927:84,simpl,simpler,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1927,1,['simpl'],['simpler']
Usability,"this for a first workflow to target?. 1) Run ExtractVariantAnnotations on a training set of chromosomes. You can keep training/truth labels as in Best Practices, for now.; 2) Run TrainVariantAnnotationsModel on that. We'll use the truth scores generated here for any sensitivity conversions---i.e., we'll be calibrating scores only to the truth sites that are contained in the training set of chromosomes.; 3) Use the trained model to run a single shard of ScoreVariantAnnotations on a validation set of chromosomes.; 4) Run some variation of the above script on the resulting outputs to determine SNP and INDEL score thresholds for optimizing the corresponding LL scores. We can also add some code to the script to use the truth scores from step 2 to convert these score thresholds into truth-sensitivity thresholds.; 5) Provide these truth-sensitivity thresholds to ScoreVariantAnnotations and use them to hard filter. Evaluate on a test set of chromosomes. If all looks good, we can later move steps 3-4 into the train tool and automate the passing of sensitivities in 5 via outputs in the model directory. This will let us keep the basic interface of ScoreVariantAnnotations the same, but we'll have to add a few basic parameters to TrainVariantAnnotationsModel to control the train/validation split. So I think all this branch is missing is step 5---we'll simply need to add command-line parameters for the SNP/INDEL sensitivity thresholds and then do the hard filtering in the VCF writing method highlighted above. Do you think you can handle implementing that in this branch, and then the rest at the WDL level? I can help with the python script for the LL stuff (or anything else), if needed. Not sure if you got a chance to check out what your collaborators are doing in the methods you're looking to compare against, but it would be good to understand if this basic scheme for train/validation/test splitting can be replicated over there. You'll want to compare apples to apples, after all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084:1440,simpl,simply,1440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084,2,['simpl'],['simply']
Usability,"this is a script which can be used after running gradle installDist to run spark jobs; it can be used identically to ths build/install/bin/gatk script, but has extra features for dealing with spark. running a spark tool and supplying the option --sparkTarget with LOCAL, CLUSTER, or GCS has special behavior; LOCAL will run the tool in the in memory spark runner; CLUSTER along with an appropriate --sparkMaster will run on an accessible spark cluster using spark-submit; arguments to spark-submit may be specified before the arguments to GATK by separating them with a --; GCS will submit jobs to google dataproc using gcloud; common arguments for spark submit will be adapted to match the gcloud formating; this will fail if gcloud isn't installed. if GATK_GCS_STAGING is specified, the jar will be uploaded and cached in the specified bucket for rapid re-use. input files will not be autouploaded to the cloud. --dry-run may be specified before the --, this will only print the commands that will be run instead of actually running them. Adding DataProcArgumentReplace simple tool to convert spark-submit args into gcloud args.; This conversion is not guarenteed to translate all spark command line options to matching gcloud ones.; If you find options that are not translated or are miss-translated please file an issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1211:1072,simpl,simple,1072,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1211,1,['simpl'],['simple']
Usability,"this is the initial port of the Allele Specific annotation for HaplotypeCaller. It mostly focuses on the GVCF mode (ie outputs the 'raw' data). I have a branch in protected https://github.com/broadinstitute/gatk-protected/tree/ak_haplotypecaller_allele_specific_annotations that uses those and I verified that the annotations are correctly output and their values are much closer that before to those from GATK3.5. I did not port any code related to combining the annotations in GenotypeGVCFs or CombinedGVCFs etc. Also, no code for VariantAnnotator or UnifiedGenotyper was ported - gatk4 does not have those tools right now. @droazen can you review? Sorry, this is a whole bunch of code and it's not the final version yet (in particular, little effort was put into redesigning the framework - that will wait until we have integration tests so we can keep the results stable while improving design and code). We also need to add tickets to:; - turn dithering off/on in RankSum tests (it's always off for now to simplify testing); - use AlleleSpecific annotations in the VCF mode; - (later) port code for combining annotations",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1825:1011,simpl,simplify,1011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1825,1,['simpl'],['simplify']
Usability,those came up clearly on HaplotypeCaller profiles and allocated many megabytes of objects for now reason,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1795:14,clear,clearly,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1795,1,['clear'],['clearly']
Usability,"thub.com/broadinstitute/gatk-protected/issues/149). Plots required to choose some of the parameters use along the pipeline:; To have an idea how they look like and how they would be used you can refer to XHMM tutorial:; https://atgu.mgh.harvard.edu/xhmm/tutorial.shtml. These can be totally in R and you may choose to reuse XHMM original code make reference to the appropriate license; they are quite simple so probably it is not necessary:; - min and max average sample coverage (to filter extreme samples).; - Plot a histogram of the average sample target coverage to choose this cut-offs. ; - min and max std dev. coverage across targets per sample (to filter extreme targets).; - Plot another histogram but in this case of the std .dev target coverage.; - min and max average and std. dev target coverage (to filter extreme targets); - Basically the ""transpose of the two plots above so that we can filter extreme targets:; - Histogram of the mean coverage per target across samples; - Histogram of the std. dev coverage per target across samples.; - Principal components variance explained plot.; - Y is the variance explained by the component (~ eigen value).; - X is the component index where 0 is the first component and i is the ith component.; Consequently this graph is monotonic decreasing.; - Would be nice to get the component vs covariate plot to find out whether we are getting rid ; of known biases like GC content but this one may take a bit more time an might not be necessary for now in practice. . The first few plots could be done by a script that takes in a read counts file.; The principal components one may access the .pon file directly perhaps using a cran package to read hdf5 files. Otherwise you might need to write a simple tool to extract those variances from the .pon. ---. @samuelklee commented on [Wed Aug 17 2016](https://github.com/broadinstitute/gatk-protected/issues/149#issuecomment-240525897). The new germline CNV tool should have some plotting capabilities.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2826:1797,simpl,simple,1797,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2826,1,['simpl'],['simple']
Usability,"tionModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:16:20.178 INFO LearnReadOrientationModel - Deflater: IntelDeflater; 12:16:20.178 INFO LearnReadOrientationModel - Inflater: IntelInflater; 12:16:20.178 INFO LearnReadOrientationModel - GCS max retries/reopens: 20; 12:16:20.179 INFO LearnReadOrientationModel - Requester pays: disabled; 12:16:20.179 INFO LearnReadOrientationModel - Initializing engine; 12:16:20.264 INFO LearnReadOrientationModel - Done initializing engine; 12:16:22.006 INFO LearnReadOrientationModel - Context AAC: with 217930 ref and 1616 alt examples, EM converged in 12 steps; 12:16:22.710 INFO LearnReadOrientationModel - Context AAG: with 354938 ref and 3337 alt examples, EM converged in 12 steps; 12:16:23.278 INFO LearnReadOrientationModel - Context AAT: with 252561 ref and 1308 alt examples, EM converged in 11 steps; 12:16:24.064 INFO LearnReadOrientationModel - Context ACA: with 323210 ref and 5248 alt examples, EM converged in 13 steps; 12:16:24.802 INFO LearnReadOrientationModel - Context ACC: with 284921 ref and 4351 alt examples, EM converged in 13 steps; 12:16:25.586 INFO LearnReadOrientationModel - Context ACG: with 83185 ref and 2548 alt examples, EM converged in 13 steps; 12:16:26.245 INFO ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:3063,Learn,LearnReadOrientationModel,3063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"tire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5853,simpl,simple,5853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['simpl'],['simple']
Usability,"titute/gatk/pull/2566?src=pr&el=h1) Report; > Merging [#2566](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **decrease** coverage by `0.015%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; ==============================================; - Coverage 76.386% 76.37% -0.015% ; + Complexity 10898 10895 -3 ; ==============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ==============================================; - Hits 30212 30206 -6 ; - Misses 6727 6732 +5 ; - Partials 2613 2614 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `85.714% <0%> (-4.762%)` | `7% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `85.95% <0%> (-4.132%)` | `55% <0%> (-2%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=footer). Last update [6859a12...1df1909](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459:1629,learn,learn,1629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459,2,['learn'],['learn']
Usability,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4447,learn,learn,4447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781,2,['learn'],['learn']
Usability,"tk/gatk-4.0.11.0/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.dylib; Nov 26, 2018 12:16:20 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:16:20.176 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 12:16:20.177 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:16:20.177 INFO LearnReadOrientationModel - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:16:20.177 INFO LearnReadOrientationModel - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:16:20.177 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 12:16:19 PM EST; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.177 INFO LearnReadOrientationModel - ------------------------------------------------------------; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 12:16:20.178 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:16:20.178 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615:1861,Learn,LearnReadOrientationModel,1861,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441721615,1,['Learn'],['LearnReadOrientationModel']
Usability,"tor:91 - Exception in task 8.0 in stage 1.0 (TID 345); java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); 05:09:00.455 WARN TaskSetManager:66 - Lost task 8.0 in stage 1.0 (TID 345, localhost): java.lang.ArrayIndexOutOfBoundsException: 16777215; at com.esotericsoftware.kryo.util.IdentityObjectIntMap.clear(IdentityObjectIntMap.java:382); at com.esotericsoftware.kryo.util.MapReferenceResolver.reset(MapReferenceResolver.java:65); at com.esotericsoftware.kryo.Kryo.reset(Kryo.java:865); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:630); at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:297); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:313); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). 05:09:00.456 ERROR TaskSetManager:70 - Task 8 in stage 1.0 failed 1 times; aborting job; 05:09:10.808 ERROR MapOutputTrackerMaster:91 - Error communicating with MapOutputTracker; java.lang.NullPointerException; at org.apache.spark.MapOutputTracker.askTracker(MapOutputTracker.scala:100); at org.apache.spark.MapOutputTracker.getStatuses(MapOutputTracker.scala:202); at org.apache.spa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3019:1498,clear,clear,1498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3019,1,['clear'],['clear']
Usability,"treamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1818,feedback,feedback,1818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,2,['feedback'],['feedback']
Usability,"tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.88% <66.66%> (-1.26%)` | `63 <3> (+3)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `81.09% <0%> (+0.6%)` | `42% <0%> (ø)` | :arrow_down: |; | [...walkers/haplotypecaller/AssemblyRegionTrimmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseVJlZ2lvblRyaW1tZXIuamF2YQ==) | `62.72% <0%> (+2.72%)` | `20% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=footer). Last update [9c4a27b...bf39362](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502:3773,learn,learn,3773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502,2,['learn'],['learn']
Usability,"ts for each mapped site is not a good idea. I don't know how supplementary reads are differentiated (MAPQ?--I can look into this), since the way I learned how to run bwa mem asks that all supplementary alignments be treated as secondary alignments (with the `-M` option). It seems important to confirm whether these supplementary alignments that get flagged secondary (with the `-M) also get MAPQ of 0 or have other nonzero MAPQs. We want our tools, including HaplotypeCaller, to differentiate supplementary alignments and secondary alignments and use supplementary alignments in variant discovery. . Secondary alignments are meant for multimappers (multiple valid mapping locations) and supplementary alignments are meant for chimeric reads (say two records for the same read where one half aligns to the left and the other half aligns to the right of a very large deletion against the reference). This means that we should run bwa mem without the `-M` option. . Ok, so I'm going to resume thinking HaplotypeCaller filters on MAPQ of 20. ---. @sooheelee commented on [Wed May 11 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-218558684). The implications of this is that (I think) for any workflow that cares about detecting indels in the size range that BWA-MEM would create supplementary alignment records for would then require that we run BWA-MEM without the `-M` option that we currently recommend. We want both types of mappings. ---. @vdauwera commented on [Wed May 11 2016](https://github.com/broadinstitute/gsa-unstable/issues/1360#issuecomment-218591369). For anyone confused about the difference between secondary and supplementary alignments: http://seqanswers.com/forums/showthread.php?t=40239. Currently we actually *don't* want our variant calling tools to distinguish them -- we prefer to consider them unusable. My understanding is that the size of events that lead to supplementary alignments fall into the scope of structural variation, and any reads",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2916:8232,resume,resume,8232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2916,1,['resume'],['resume']
Usability,tute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (ø)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (ø)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (ø)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9SZWFkQ2xpcHBlci5qYXZh) | `71.038% <0%> (+1.639%)` | `75% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:2153,Simpl,SimpleRepeatMaskTransformer,2153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Simpl'],['SimpleRepeatMaskTransformer']
Usability,"tute/gsa-unstable/issues/855#issuecomment-260456840). @SHuang-Broad @vruano Is this (making the HC allele culling available to GenotypeGVCFs too) still on your radar(s)?. ---. @SHuang-Broad commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260687763). @vdauwera yes it is on mine. ---. @vdauwera commented on [Tue Nov 15 2016](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-260714842). Are you planning/working on this in GATK3 or GATK4? Would be good to know where the issue should live. . ---. @vdauwera commented on [Wed Feb 08 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-278478318). @SHuang-Broad ping... ---. @SHuang-Broad commented on [Wed Feb 15 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-280102484). @vdauwera sorry this went off my attention for a while. I did attempt to port a similar change a while back, but discovered that it was not so simple: the fix worked in HC code by removing alt alleles looking at the supporting haplotype scores. Such scores are not available in `GenotypeGVCFs` so either we would have to, like Valentin suggested, make sure the tools handle input without PLs, which is a direction that I looked into and found that the pay/cost is not good (if I recall correctly, most of the places that handles the input does not require valid PL but there are several that's difficult to handle). Then I began wondering how the new QUAL calculating method David Benjamin has put in will make such problems obsolete. So I would say if I find time beyond finishing my SV duty, I would chase down if the new QUAL method indeed will resolve all these, and that will definitely happen in GATK 4. ---. @vdauwera commented on [Mon Feb 20 2017](https://github.com/broadinstitute/gsa-unstable/issues/855#issuecomment-281073466). Ah, interesting, thanks Steve. Do you have any sense of when you might be able to look further into this? This ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2955:9879,simpl,simple,9879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2955,1,['simpl'],['simple']
Usability,"ty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935); at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459); at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138); at java.lang.Thread.run(Thread.java:745); 2019-02-17 16:25:50 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-02-17 16:25:50 INFO MemoryStore:54 - MemoryStore cleared; 2019-02-17 16:25:50 INFO BlockManager:54 - BlockManager stopped; 2019-02-17 16:25:50 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-02-17 16:25:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-02-17 16:25:50 INFO SparkContext:54 - Successfully stopped SparkContext; 16:25:50.893 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [February 17, 2019 4:25:50 PM EST] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 5.28 minutes.; Runtime.totalMemory()=5059379200; org.apache.spark.SparkException: Job aborted due to stage failure: Task 181 in stage 5.0 failed 4 times, most recent failure: Lost task 181.3 in stage 5.0 (TID 1139, scc-q02.scc.bu.edu, executor 24): java.lang.IllegalArgumentException: provided start is negative: -1; at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SVIntervalConstructorArgsValidator.lambda$static$3(SVInterval.java:76); at org.broadinstitute.hellbender.tools.spark.sv.utils.SVInterval$SV",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5685:46466,clear,cleared,46466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685,1,['clear'],['cleared']
Usability,"ually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active region traversals, and disallow the -dcov argument for active region walkers. Downsampling would then by controlled solely by the new argument to set the max # of reads per active region.; - Clarifying the meaning of the per-locus DP annotation for the HC given things like realignment of ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5708,undo,undownsampled,5708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"ud.storage.StorageOptions.<init>(StorageOptions.java:83); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289). 16:20:59.204 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.205 INFO LearnReadOrientationModel - The Genome Analysis Toolkit (GATK) v4.0.11.0; 16:20:59.205 INFO LearnReadOrientationModel - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:20:59.206 INFO LearnReadOrientationModel - Executing as root@3231a24c7afb on Linux v4.9.125-linuxkit amd64; 16:20:59.206 INFO LearnReadOrientationModel - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13; 16:20:59.207 INFO LearnReadOrientationModel - Start Date/Time: November 26, 2018 4:20:57 PM UTC; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.207 INFO LearnReadOrientationModel - ------------------------------------------------------------; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Version: 2.16.1; 16:20:59.208 INFO LearnReadOrientationModel - Picard Version: 2.18.13; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:20:59.208 INFO LearnReadOrientationModel - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:20:59.209 INFO LearnReadOrientationModel - HTS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447:4719,Learn,LearnReadOrientationModel,4719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447,1,['Learn'],['LearnReadOrientationModel']
Usability,"unts.hdf5 --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/-724059439/P0000992.b37.counts.hdf5 --input /gatk/local_mnt/cromwell-executions/CNVGermlineCohortWorkflow/098a389e-b298-4324-8a8c-9f46f05708b5/call-GermlineCNVCallerCohortMode/shard-12910/inputs/1773956498/P0001010.b37.counts.hdf5 --contig-ploidy-calls contig-ploidy-calls-dir --interval-merging-rule OVERLAPPING_ONLY --output out --output-prefix csi_batch1-4_wes_gcnv_pon --verbosity DEBUG --p-alt 1e-6 --p-active 1e-2 --cnv-coherence-length 10000.0 --class-coherence-length 10000.0 --max-copy-number 5 --max-bias-factors 5 --mapping-error-rate 0.01 --interval-psi-scale 0.001 --sample-psi-scale 0.0001 --depth-correction-tau 10000.0 --log-mean-bias-standard-deviation 0.1 --init-ard-rel-unexplained-variance 0.1 --num-gc-bins 20 --gc-curve-standard-deviation 1.0 --copy-number-posterior-expectation-mode HYBRID --enable-bias-factors true --active-class-padding-hybrid-mode 50000 --learning-rate 0.05 --adamax-beta-1 0.9 --adamax-beta-2 0.99 --log-emission-samples-per-round 50 --log-emission-sampling-median-rel-error 0.005 --log-emission-sampling-rounds 10 --max-advi-iter-first-epoch 5000 --max-advi-iter-subsequent-epochs 100 --min-training-epochs 10 --max-training-epochs 100 --initial-temperature 2.0 --num-thermal-advi-iters 2500 --convergence-snr-averaging-window 500 --convergence-snr-trigger-threshold 0.1 --convergence-snr-countdown-window 10 --max-calling-iters 10 --caller-update-convergence-threshold 0.001 --caller-internal-admixing-rate 0.75 --caller-external-admixing-rate 1.00 --disable-annealing false. [2019-02-22 23:49:20,42] [info] WorkflowManagerActor WorkflowActor-098a389e-b298-4324-8a8c-9f46f05708b5 is in a terminal state: WorkflowFailedState; [2019-02-22 23:50:01,65] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2019-02-22 23:50:02,38] [info] Workflow polling stopped; [2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714:29702,learn,learning-rate,29702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714,1,['learn'],['learning-rate']
Usability,"usand or more variants with --variant sample1.g.vcf ... --variant sample10000.g.vcf as in the example, this may even involve using xargs on some systems, so I looked in the documentation. I do see an option for giving the sample arguments in some sort of file form:; https://gatk.broadinstitute.org/hc/en-us/articles/360041416212-CombineGVCFs#--arguments_file; But again, what is: List[File] [] ?; Does this have a page describing what it actually needs like intervals does? It doesn't link to one, a quick Googling doesn't find one. The tool indices are ultimately much less useful if we don't know 1) The actual format and 2) what it does. These things are sometimes present, but often not. ; The docs also don't cover some less technical things. E.g. I see some people in the forums say they do hierarchical merging of the GVCFs, the tool presents itself as though it expects the full list of GVCFs to merge at once. Maybe it is worth mentioning that, (other places say that you can merge new samples in later, but they do not make it clear that you shouldn't do them at once*).; *Or maybe I'm the only one that has crazy memory use when doing them at one time? . Please don't take this as an unappreciative criticism. I know that a ton of work has been put into GATK education and I have seen many of those materials: e.g. the numerous workshops on GATK https://drive.google.com/drive/folders/1y7q0gJ-ohNDhKG85UTRTwW1Jkq4HJ5M3 I also realize that many of you are probably very experienced with GATK and these things may seem obvious. Please take a step back though and consider if this documentation is adequate from the perspective of a technically competent new user reading the documentation that has not seen examples outside of what is shown in the docs. Actually, to be honest, most of the examples out in the wild stick to only the most basic of options, so for more advanced uses it really is pretty unclear what such arguments should be. . This is not a generic please write better docum",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639:3492,clear,clear,3492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639,1,['clear'],['clear']
Usability,use getExecutorCores to guide parallelism in AlignContigsAndCallBreakpointsSpark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1967:24,guid,guide,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1967,2,['guid'],['guide']
Usability,"used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding all this, if you're happy with the code as it stands, feel free to merge.; Back to you, review done.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5153:1346,clear,clearer,1346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5153,2,"['clear', 'simpl']","['clearer', 'simplify']"
Usability,"used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding all this, if you're happy with the code as it stands, feel free to merge.; Back to you, review done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706:1221,clear,clearer,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706,4,"['clear', 'simpl']","['clearer', 'simplify']"
Usability,"using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. . supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`using jopt-simple to do the actual parsing. Right now it's just been dropped in to handle decomposing the arguments into key->value pairs. In future it could also handle more of the argument checking and help formatting. supports short (-h) and long (--help) styles; supports boolean flags with or without an argument; options are now case sensitive. argument collections can be specified with `@ArgumentCollection`; `NestedOptions` removed -> replaced by `ArgumentCollection`. `Option.fullName()` is now respected if specified, if it isn't it defaults to use the field name; `Overrideable` has been removed from `Option`; Arguments must now be uniquely specified (no arguments targeting multiple fields any more) and no redefining existing ones.; The ability to override a specified option is a useful one, so it might need to be reimplemented at some point.; Collection defaults are now replaced rather than appended too. also opportunistically fixed a broken test in `CreateSequenceDictionaryTest`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/135:11,simpl,simple,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135,2,['simpl'],['simple']
Usability,"ute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; The second case included the following `--alleles` input:; ```; 22	16464044	rs571268158	CCAGGTCT	C; 22	16464051	rs569099729	T	C; ```; and it crashed similarly, with:; ```; java.lang.IllegalStateException: Allele in genotype CCAGGTCT* not in the variant context [T*, *, C]; 	at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:221); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:150); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:236); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5337:3320,simpl,simpleMerge,3320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5337,1,['simpl'],['simpleMerge']
Usability,"uthier/scratch/supportingMultiA.vcf; > Should fail AC/AF validation at; > 1 768589 . A C,G 76 PASS AC=1;AF=0.00047;AN=2120; > See results using:; > ; > use VCFtools; > vcf-validator /humgen/gsa-hpprojects/dev/gauthier/scratch/supportingMultiA.vcf; > ; > which outputs:; > INFO field at 1:768589 .. INFO tag [AC=1] expected different number of; > values (expected 2, found 1),INFO tag [AF=0.00047] expected different; > number of values (expected 2, found 1); > Notes; > ; > Currently, all the validation modes call out to HTSJDK. Do we want to put; > the new functionality there as well?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gsa-unstable/issues/1053. ---. @ldgauthier commented on [Fri Jul 17 2015](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-122308040). Today I learned that the way we currently build GATK, you can't point to a local htsjdk jar anymore, so this task will be two-fold:; 1) Make a PR to htsjdk with a new function in the VariantContext class for validateInfoFieldCounts(VCFInfoHeaderLine headerLine) or similar; add a test to VariantContextUnitTest.java; 2) After change 1) is merged, update ValidateVariants accordingly to use the new function and add a test to its integration tests. ---. @vdauwera commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222213763). @ldgauthier is this still a thing? (in the sense of not having been addressed in htsjdk). ---. @ldgauthier commented on [Fri May 27 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-222214083). Still a thing. No work has been done here AFAIK. ---. @vdauwera commented on [Mon Nov 14 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-260465013). This seems like fairly low-hanging fruit -- @ronlevine . ---. @ronlevine commented on [Wed Nov 23 2016](https://github.com/broadinstitute/gsa-unstable/issues/1053#issuecomment-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2507:4175,learn,learned,4175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2507,1,['learn'],['learned']
Usability,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35819,clear,cleared,35819,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['clear'],['cleared']
Usability,"vYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.109% <ø> (-0.84%)` | `26% <ø> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <ø> (-0.694%)` | `36% <ø> (-1%)` | |; | [...org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2MuamF2YQ==) | `67.797% <ø> (-0.565%)` | `85% <ø> (-1%)` | |; | [...lbender/tools/walkers/vqsr/VariantDataManager.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudERhdGFNYW5hZ2VyLmphdmE=) | `66.228% <ø> (-0.439%)` | `78% <ø> (-1%)` | |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2399/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=footer). Last update [3c10554...9d80a51](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658:4890,learn,learn,4890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658,2,['learn'],['learn']
Usability,"va-options ""-Xmx4g"" HaplotypeCaller -R $HOME/GRCh37files/hs37d5.fa -I /mnt/fast/test.bam -O test.out.vcf.gz -L 22 --genotyping-mode GENOTYPE_GIVEN_ALLELES --alleles test.vcf.gz`, the resulting error is:; ```; java.lang.IllegalStateException: Allele in genotype GGTTTGTTT not in the variant context [GGTTTGTTT*, GGTTTGTTTGTTT, GGTTTGTTTGTTTGTTT, G]; at htsjdk.variant.variantcontext.VariantContext.validateGenotypes(VariantContext.java:1360); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1298); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:401); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:494); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:488); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:864); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.simpleMerge(GATKVariantContextUtils.java:646); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.makeMergedVariantContext(AssemblyBasedCallerUtils.java:228); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerGenotypingEngine.assignGenotypeLikelihoods(HaplotypeCallerGenotypingEngine.java:157); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:599); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:240); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5355:41771,simpl,simpleMerge,41771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5355,1,['simpl'],['simpleMerge']
Usability,"va:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:56:39 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 45.308012 s; 18/04/24 17:56:39 INFO SparkUI: Stopped Spark web UI at http://xx.xx.xx.16:4040; 18/04/24 17:56:39 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:56:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:56:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:56:39 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:56:39 INFO BlockManager: BlockManager stopped; 18/04/24 17:56:39 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:56:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:56:39 INFO SparkContext: Successfully stopped SparkContext; 17:56:39.758 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:56:39 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 1.75 minutes.; Runtime.totalMemory()=821559296; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 4 times, most recent failure: Lost task 1.3 in stage 2.0 (TID 10, xx.xx.xx.16, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4699:37709,clear,cleared,37709,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4699,1,['clear'],['cleared']
Usability,"valFileToList(IntervalUtils.java:375); 	at org.broadinstitute.hellbender.utils.IntervalUtils.parseIntervalArguments(IntervalUtils.java:279); 	at org.broadinstitute.hellbender.utils.IntervalUtils.loadIntervals(IntervalUtils.java:226); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.parseIntervals(IntervalArgumentCollection.java:174); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getTraversalParameters(IntervalArgumentCollection.java:155); 	at org.broadinstitute.hellbender.cmdline.argumentcollections.IntervalArgumentCollection.getIntervals(IntervalArgumentCollection.java:111); 	at org.broadinstitute.hellbender.engine.GATKTool.initializeIntervals(GATKTool.java:513); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:708); 	at org.broadinstitute.hellbender.engine.ReadWalker.onStartup(ReadWalker.java:50); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:137); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.lang.NumberFormatException: For input string: ""100 ""; 	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65); 	at java.lang.Integer.parseInt(Integer.java:580); 	at java.lang.Integer.parseInt(Integer.java:615); 	at org.broadinstitute.hellbender.utils.SimpleInterval.parsePositionThrowOnFailure(SimpleInterval.java:141); 	at org.broadinstitute.hellbender.utils.IntervalUtils.getResolvedIntervals(IntervalUtils.java:1122); 	at org.broadinstitute.hellbender.utils.GenomeLocParser.parseGenomeLoc(GenomeLocParser.java:308)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6371:2567,Simpl,SimpleInterval,2567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6371,2,['Simpl'],['SimpleInterval']
Usability,"vals/glob-0fc990c5ca95eebc97c4c204e3e303e1/0000-scattered.interval_list -O output.vcf --f1r2-tar-gz f1r2.tar.gz --af-of-alleles-not-in-resource 0.0007 --downsampling-stride 20 --max-reads-per-alignment-start 6 --max-suspicious-reads-per-alignment-start 6`; ```. The germline resource is a VCF of approximately 80 million SNPs and indels (including multi allelic sites) called from a large number of canine WGS. It is formatted as a VCF with no sample information:; ```; chr1 240 . TG T 464.40 PASS AC=4;AF=0.011;AN=332;BaseQRankSum=0.674;ClippingRankSum=0;DP=14798;ExcessHet=0.0026;FS=5.63;InbreedingCoeff=-0.005;MLEAC=14;MLEAF=0.017;MQ=7.49;MQRankSum=-0.967;QD=22.11;ReadPosRankSum=0.967;SOR=3.18; ```. The VCF for variants for contamination is a subset of this VCF, with only biallelic SNPs with AF between 0.01 and 0.2. Initially, it was formatted the same as the above file. As part of debugging, I tried removing everything from the INFO field of the variants for contamination file, except allele frequency, and I tried using that simplified VCF both for the germline resource and the variants for contamination file. This seemed to fix the index out of bounds error, but the job then failed at the filtering step, with the following error:. ```; java.lang.IllegalArgumentException: log10p: Log10-probability must be 0 or less; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:724); 	at org.broadinstitute.hellbender.utils.MathUtils.log10BinomialProbability(MathUtils.java:934); 	at org.broadinstitute.hellbender.utils.MathUtils.binomialProbability(MathUtils.java:927); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:56); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098:4799,simpl,simplified,4799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098,1,['simpl'],['simplified']
Usability,"vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=footer). Last update [a85e0ff...1d6ce76](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637:4051,learn,learn,4051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637,2,['learn'],['learn']
Usability,walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `1.031% <0%> (-98.969%)` | `1% <0%> (-7%)` | |; | [...ers/vqsr/FilterVariantTranchesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.053% <0%> (-98.947%)` | `1% <0%> (-5%)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.205% <0%> (-98.795%)` | `1% <0%> (-20%)` | |; | [...tion/LearnReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.724% <0%> (-98.276%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.754% <0%> (-98.246%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.041% <0%> (-97.959%)` | `2% <0%> (-13%)` | |; | ... and [154 more](https://co,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5795#issuecomment-472522509:3207,Learn,LearnReadOrientationModelIntegrationTest,3207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5795#issuecomment-472522509,1,['Learn'],['LearnReadOrientationModelIntegrationTest']
Usability,"we need a simple abstract map/reduce tool that would just loop over data and call map, reduce in a sequence. It'll make it easier to migrate walkers that way.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/20:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/20,1,['simpl'],['simple']
Usability,we need a way to bind to a BWA-MEM library to align reads programmatically from within the GATK. . SVs need it and it would simplify the reads pipeline to have it start with a fasta. Commandline behavior we need: `bwa mem -K 100000000 -p` (we may not care about multithreading); - `-K` is undocumented - reading code shows it refers to `fixed_chunk_size` which then sets `actual_chunk_size` @lh3 can you help us understand what it `-K` does?; - `-p` is for interleaved input,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1517:124,simpl,simplify,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1517,2,"['simpl', 'undo']","['simplify', 'undocumented']"
Usability,we now have a 1+3 matrix which is as follows:. required to pass:; non-cloud non-bucket tests on google dataflow. not required to pass:; non cloud non-bucket tests on spark; cloud and bucket tests on google; cloud and bucket tests on spark. moving TERM out of matrix; setting up service account with guide from https://github.com/GoogleCloudPlatform/appengine-try-python-webapp2/blob/master/.travis.yml; adding install_gcloud.sh copied from a google repo; fixing gs:path; adding key for bucket tests. resolves #656 . Once the google cloud tests are all passing we should move them to the required to pass section,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/685:299,guid,guide,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/685,1,['guid'],['guide']
Usability,"what `merge()` returns is a `Locatable` though, so it would be clear that it isn't a `SamRecord` or a `VariantContext`. Merge is a bit of a strange one, because you would need to return some concrete implementation. I guess the most pure thing to do would be to return an anonymous implementation of Locatable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79219917:63,clear,clear,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79219917,1,['clear'],['clear']
Usability,"write a new tool for dealing with targetted sequencing; > data. Since a major source of coverage variance in targetted sequencing is; > different capture efficiencies, the most reasonable read-depth calculation; > scheme is to associate *inserts to baits* rather than *single reads to; > targets*.; >; > There is a subtle problem, though: inserts often overlap with more than; > one bait. In such cases, we need to have a model for estimating the; > probability that the insert is captured by either of the overlapping baits.; > The modeling can be done in the following semi-empirical fashion (thanks; > @yfarjoun <https://github.com/yfarjoun>), which needs to be done only; > once each capture technology (Agilent, ICE):; >; > - We locate isolated baits (i.e. those that are separated from one; > another by a few standard deviations of the average insert size); > - We take a number of BAMs and calculate the empirical distribution of; > inserts around the isolated baits; > - We build a simple parametric model for the obtained empirical; > distributions, parametrized by bait length and insert length; we probably; > don't need to go all-in here, though the reference context of the bait is; > also likely to be an important covariate.; >; > Once these distributions are known, we can easily calculate the membership; > share of each bait in ambiguous cases and give each bait the appropriate; > share.; > Bonus:; >; > The empirical distribution of inserts around baits also allows us to; > associate a more reasonable GC content to each bait. Since GC bias is a; > property of the fragments that are pulled by the baits, a reasonable; > measure of ""GC content"" of each bait has to be calculated from the expected; > value of the GC content of the fragments that the bait pulls (not the GC; > content of the baits or targets), and this can be easily calculated from; > the previously obtained empirical distributions.; >; > —; > You are receiving this because you were mentioned.; > Reply to this",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2947:4765,simpl,simple,4765,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2947,1,['simpl'],['simple']
Usability,"yes, it seems to. it seems this was a simple bug where GenotypeGVCFsEngine.removeNonRefAlleles() wasnt working as intended for multi-allelic sites; however, I'm not sure I understand the entire genotyping process well enough to be certain on this. we can iterate on #6406",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-577344229:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-577344229,2,['simpl'],['simple']
Usability,"you mean, for spark? Up to you - we'll only be comparing results between runs on your setup anyway. For my experiments I used 10 nodes of 16 CPUs each and stuff runs in <10-15 minutes then. If you go for fewer cores, it'll simply take longer - not a big deal here because the requirement is that those run overnight",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227219320:223,simpl,simply,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227219320,1,['simpl'],['simply']
Usability,"ype?; - The above is especially thorny for haplotypes that exhibit multiple variants.; - The FRD prior is only defined for individual events, not haplotypes.; - The BQD and FRD models use reads that overlap a variant site, but it is not clear how to use reads that only partially intersect a haplotype.; - BQD and FRD likelihoods are only defined for homozygous haplotypes, but heterozygous combinations of _haplotypes_ contribute to homozygous genotypes all loci where the distinct haplotypes agree. Clearly, generalizing BQD and FRD to entire haplotypes is not straightforward. Nor does it suffice to produce ""raw"" genotype likelihoods using the joint detection approach and then apply BQD and FRD on variant loci afterwards. Some difficulties with this include:. - BQD and FRD require the read-allele likelihoods matrix. Where are these likelihoods supposed to come from? The pre-joint-detection unrigorous ""marginalization"" where to each allele we assign the maximum likelihood over all haplotypes supporting that allele? Some read-allele likelihoods matrix derived from the read-haplotype likelihoods matrix?; - The drawbacks of the faulty ""marginalization"" actually become more severe with joint detection since genotyping multiple alleles together in a single determined span produces more haplotypes, which in turn increases the risk of the read-allele likelihoods cherry-picking from too many different haplotypes for different reads.; - The BQD and FRD models produce likelihoods on an absolute scale that is only meaningful relative to genotyping likelihoods from the pre-joint-detection approach. They do not inherently ""play nicely"" with the posterior probabilities produced by joint detection.; - BQD and FRD as currently implemented in the GATK modify likelihoods _before_ applying a prior, whereas joint detection yields posterior probabilities. Are we supposed to somehow un-apply the prior to joint detection likelihoods, apply BQD and FRD, then re-apply the prior? It is not clear.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616:2905,clear,clear,2905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616,1,['clear'],['clear']
Usability,"ypeCaller or Mutect2 to ignore reads whose mate maps to a different contig. This filter is not at the engine level but rather deep within the assembler and was made disable-able in the summer. I do not know the reasoning behind ignoring read pairs that map across chromosomes. My assumption is that (at least previously) these types of mappings tended to be artifactual and so we wanted to discount them to improve specificity. I think it prudent we assess whether this still holds true for more recent sequencing data and processing pipelines.; - For example, I also know that BWA prefers mappings that place mates within a standard insert distance, e.g. on the same contig. ; - Also, for chimeric reads produced by weird sequencer bridging reactions, we have dual barcodes that would then discount such reads in the `0x200` QCFAIL pool. **Here, I am asking for a simple feature at the engine level**; What I would like is an option for tools that employ the `MateOnSameContigOrNoMappedMateReadFilter` to count mates on what should be molecularly contiguous (but represented as different contigs in the reference) as on the same contig for ALT-aware alignments. The dictionary section of the header will indicate ALT-aware alignment with an AH tag and an asterisk if processed through MergeBamAlignment. Corresponding ALT to primary assembly pairings are given by the `.alt` file used in alt-aware alignment and post-processing and the parameter would ask for this. What this feature enables is for us to continue discounting read pairs that map across chromosomes while correctly counting read pairs split across primary assembly and ALT contigs. . - Alternatively, or additionally, it might be good to have a stand-alone tool that can change the mate pair designations. MergeBamAlignment has some options to change mate pair designations to some extent for other criteria. It may be that adding ALT-aware designations as an additional options to MergeBamAlignment could be useful. In this case, I ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3764:2742,simpl,simple,2742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3764,1,['simpl'],['simple']
Usability,"zL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvbk1vZGVsLmphdmE=) | `92.39% <92.39%> (ø)` | `39 <39> (?)` | |; | [.../walkers/contamination/ContaminationSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblNlZ21lbnRlci5qYXZh) | `96.42% <96.42%> (ø)` | `9 <9> (?)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `91.6% <0%> (-2.1%)` | `144% <0%> (+6%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL1RyYW5zY3JpcHRTZWxlY3Rpb25Nb2RlLmphdmE=) | `89.71% <0%> (-1.87%)` | `1% <0%> (ø)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.95% <0%> (-1.68%)` | `17% <0%> (ø)` | |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=footer). Last update [864b180...1183b3d](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631:4517,learn,learn,4517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631,2,['learn'],['learn']
Usability,zY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `96.667% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `86.047% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [.../sv/discovery/prototype/InsDelVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0luc0RlbFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `28.387% <0%> (+0.539%)` | `13 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3673?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+3.247%)` | `39% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3673#issuecomment-334861994:2215,Simpl,SimpleStrandSwitchVariantDetector,2215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3673#issuecomment-334861994,1,['Simpl'],['SimpleStrandSwitchVariantDetector']
Usability,"zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `93.296% <100%> (+81.997%)` | `34 <2> (+30)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `76.994% <78.261%> (+36.525%)` | `44 <1> (+16)` | :arrow_up: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `90.476% <90.476%> (ø)` | `4 <4> (?)` | |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `95.833% <95.833%> (ø)` | `0 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `50.888% <0%> (-1.183%)` | `23% <0%> (-1%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=footer). Last update [bf993d8...dc817a8](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558:4225,learn,learn,4225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558,2,['learn'],['learn']
Usability,"zdC5qYXZh) | `97.82% <100%> (+0.26%)` | `8 <1> (+1)` | :arrow_up: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `78.26% <100%> (+2.45%)` | `25 <6> (+6)` | :arrow_up: |; | [...bender/tools/walkers/variantutils/ReblockGVCF.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRi5qYXZh) | `81.52% <100%> (+1.17%)` | `46 <0> (+3)` | :arrow_up: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `83.6% <77.35%> (-10.21%)` | `41 <25> (+1)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `87.44% <83.33%> (+0.15%)` | `24 <2> (ø)` | :arrow_down: |; | ... and [19 more](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=footer). Last update [868a32e...49c474d](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112:4466,learn,learn,4466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112,2,['learn'],['learn']
Usability,"ze: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 2 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 3 from newAPIHadoopFile at SamSource.java:108; 18:35:30.930 INFO FileInputFormat - Total input files to process : 1; 20/10/08 18:35:30 INFO SparkUI: Stopped Spark web UI at http://mpcb006.cm.cluster:4040; 20/10/08 18:35:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/10/08 18:35:30 INFO MemoryStore: MemoryStore cleared; 20/10/08 18:35:30 INFO BlockManager: BlockManager stopped; 20/10/08 18:35:30 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/08 18:35:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/08 18:35:30 INFO SparkContext: Successfully stopped SparkContext; 18:35:30.994 INFO MarkDuplicatesSpark - Shutting down engine; [October 8, 2020 at 6:35:30 PM CEST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2579496960. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875:8436,clear,cleared,8436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875,1,['clear'],['cleared']
Usability,"zed setting. ### Tool(s) or class(es) involved; GenomicsDBImport v.4.2.6.1 (current). ### Description ; As far as I understand it the joint germline variant calling process is like this (imagine 100 samples):; 1. Call variants using `Haplotypecaller` using the gVCF output flag for each sample; 2. use the multiple gVCFs (1 per sample) and a set of intervals (WGS_intervals.bed as an example) to build a Genomics DB store using `GenomicsDBImport`; 3. Use `GenotypeGVCFs` using the output of `GenomicsDBImport` as the input to consolidate the multiple samples into 1 multi-sample vcf. My question comes from the parallelization/interval splitting during step 2. If I parallelize the GenomicsDBImport across each interval. I would end up with ~300 intervals and subsequently, ~300 GenomicsDB directory paths since I am not adding new samples to an existing DB, then the specified output DB path, ""Must be an empty or non-existent directory"", which will contain the relevant interval calls for the 100 samples. . Am I supposed to use the 300 directory paths as input into a single `GenotypeGVCFs` call? Or process each of the 300 intervals into 300 multi-sample vcf files (each with 100 samples) and then merge those into a single vcf file using `GatherVcfs` or some other merging tool. The examples posted and documentation for `GenomicsDBImport` relay the need for intervals to work effectively, and so does [an old broad lecture recording](https://www.youtube.com/watch?v=XrHt5yBlp80&t=1243s). . Essentially it boils down to when and how to process and merge the same set of samples (100) over the many intervals (300). If I had 300 compute nodes (as an example) I want to parallelize as much of this as possible. so that each node can process an interval set, and at the end of the process I have 1 VCF file with 100 samples covering the entire range of intervals. I hope that was clear. Please let me know if you need any more info, or if I should be asking somewhere else. Thanks in advance!. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7898:2073,clear,clear,2073,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7898,1,['clear'],['clear']
Usability,| [...decs/xsvLocatableTable/XsvLocatableTableCodec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3MveHN2TG9jYXRhYmxlVGFibGUvWHN2TG9jYXRhYmxlVGFibGVDb2RlYy5qYXZh) | `78.947% <0%> (-3.769%)` | `69% <0%> (+9%)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `90.909% <0%> (-0.758%)` | `11% <0%> (+5%)` | |; | [...lkers/ReferenceConfidenceVariantContextMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1JlZmVyZW5jZUNvbmZpZGVuY2VWYXJpYW50Q29udGV4dE1lcmdlci5qYXZh) | `94.979% <0%> (-0.278%)` | `69% <0%> (-2%)` | |; | [...lugin/DefaultGATKReadFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vRGVmYXVsdEdBVEtSZWFkRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `8% <0%> (+4%)` | :arrow_up: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [.../annotatedregion/SimpleAnnotatedGenomicRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZHJlZ2lvbi9TaW1wbGVBbm5vdGF0ZWRHZW5vbWljUmVnaW9uLmphdmE=) | `82.222% <0%> (ø)` | `14% <0%> (?)` | |; | ... and [11 more](https://codecov.io/gh/broadinstitute/gatk/pull/4652/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4652#issuecomment-381172945:3472,Simpl,SimpleIntervalTestFactory,3472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4652#issuecomment-381172945,2,['Simpl'],"['SimpleAnnotatedGenomicRegion', 'SimpleIntervalTestFactory']"
Usability,"| [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `100% <0%> (ø)` | `27% <0%> (+13%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `93.411% <0%> (+1.639%)` | `135% <0%> (+58%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `93.75% <0%> (+2.083%)` | `7% <0%> (+1%)` | :arrow_up: |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `92.188% <0%> (+2.714%)` | `26% <0%> (+12%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=footer). Last update [12c7a2d...7488ed4](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056:3689,learn,learn,3689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056,2,['learn'],['learn']
Usability,| |; |---|---|---|---|; | [...ynumber/formats/records/AlleleFractionSegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9BbGxlbGVGcmFjdGlvblNlZ21lbnQuamF2YQ==) | `39.286% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...ls/copynumber/plotting/PlotDenoisedCopyRatios.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3Bsb3R0aW5nL1Bsb3REZW5vaXNlZENvcHlSYXRpb3MuamF2YQ==) | `100% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `90.909% <50%> (-9.091%)` | `2 <1> (ø)` | |; | [...tools/copynumber/caller/SimpleCopyRatioCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2NhbGxlci9TaW1wbGVDb3B5UmF0aW9DYWxsZXIuamF2YQ==) | `95.652% <90%> (-1.271%)` | `17 <3> (+2)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (+0.383%)` | `73% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4263#issuecomment-360624176:1895,Simpl,SimpleCopyRatioCaller,1895,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4263#issuecomment-360624176,1,['Simpl'],['SimpleCopyRatioCaller']
Usability,"~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:1271) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2810) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49) ~[gatk-package-4.4.0.0-local.jar:4.4.0.0]; 11:00:54.078 INFO AbstractConnector - Stopped Spark@2f829853{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}; 11:00:54.091 INFO SparkUI - Stopped Spark web UI at http://172.20.19.130:4040; 11:00:54.122 INFO MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!; 11:00:54.175 INFO MemoryStore - MemoryStore cleared; 11:00:54.175 INFO BlockManager - BlockManager stopped; 11:00:54.193 INFO BlockManagerMaster - BlockManagerMaster stopped; 11:00:54.211 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!; 11:00:54.302 INFO SparkContext - Successfully stopped SparkContext; 11:00:54.303 INFO SortSamSpark - Shutting down engine; [August 11, 2024 at 11:00:54 AM CST] org.broadinstitute.hellbender.tools.spark.pipelines.SortSamSpark done. Elapsed time: 27.81 minutes.; Runtime.totalMemory()=1926292832256; org.apache.spark.SparkException: Job aborted.; at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:106); at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsNewAPIHadoopDataset$1(PairRDDFunctions.scala:1078); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8949:24254,clear,cleared,24254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8949,1,['clear'],['cleared']
Usability,ø)` | :arrow_down: |; | [...r/allelic/alleliccount/AllelicCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FsbGVsaWMvYWxsZWxpY2NvdW50L0FsbGVsaWNDb3VudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (+32.143%)` | `5 <5> (-1)` | :arrow_down: |; | [...lbender/tools/copynumber/CollectAllelicCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzLmphdmE=) | `100% <100%> (ø)` | `9 <1> (ø)` | :arrow_down: |; | [...s/copynumber/formats/metadata/SampleNameUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvbWV0YWRhdGEvU2FtcGxlTmFtZVV0aWxzLmphdmE=) | `47.826% <47.826%> (ø)` | `3 <3> (?)` | |; | [...ynumber/formats/metadata/SimpleSampleMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvbWV0YWRhdGEvU2ltcGxlU2FtcGxlTWV0YWRhdGEuamF2YQ==) | `63.636% <63.636%> (ø)` | `4 <4> (?)` | |; | [...er/formats/collections/SampleRecordCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2FtcGxlUmVjb3JkQ29sbGVjdGlvbi5qYXZh) | `80% <80%> (ø)` | `7 <7> (?)` | |; | [...formats/collections/SampleLocatableCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3716?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2FtcGxlTG9jYXRhYmxlQ29sbGVjdGlvbi5qYXZh) | `95% <95%> (ø)` | `7 <7> (?)` | |; | [...sv/discovery/NovelAdjacencyReferenceLocations.java](https://codecov.io/gh/br,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3716#issuecomment-337928980:2572,Simpl,SimpleSampleMetadata,2572,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3716#issuecomment-337928980,1,['Simpl'],['SimpleSampleMetadata']
Usability,…lean up comments and function names to make the functionality clearer. Tests will be added soon - we need to add more framework for unit testing MarkDuplicatesDataflow and outputting a metrics file; so we can check the number of optical duplicates in tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/631:63,clear,clearer,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631,1,['clear'],['clearer']
Usability,"…m for shuffle jobs. This is a first attempt at #1403 to get feedback on the approach. For aggregating tools that don’t have a shuffle (like CountReadsSpark), the existing 10MB per split is an issue since it dramatically slows down processing. Increasing the split size can be done via -bps, but that is not at all obvious and shouldn’t be necessary. The change I’ve made here uses the default split size for Hadoop (which is 128MB on HDFS). For tools that do have a shuffle, I’ve added a -P argument for all of them, which sets the level of parallelism to use for the shuffle. If not set it defaults to one partition per 10MB of input, which is the existing default. Note that for tools that write an output BAM, the level of parallelism set by -P is used for writing a single BAM (the default, since shardedOutput is false), since the reads are first sorted and written to multiple BAM files before finally being merged. Question: there’s a lot of duplicated code here. Would it be a good idea to have a ParallelismArgumentCollection and a ShardedOutputParallel collection? Note that some tools need a -P but not -shardedOutput (e.g. CompareDuplicatesSpark).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432:61,feedback,feedback,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432,1,['feedback'],['feedback']
Usability,"…ose options to customize scoring scheme. - Simplifies HostAlignmentReadFilter by using only the alignment identity, defined as the number of matches minus deletions, instead of both identity and coverage, as it seems to have negligible impact on results.; - Similarly, PSScorer uses an identity threshold only and not coverage to filter pathogen alignments. In addition, an option is added to better handle second-best matches. For a given read (or pair), if the best alignment has identity score N, PSScorer now ignores hits with identity score less than N x (1 - x), where x is the ""identity margin.""; - Option to divide abundance scores by genome length; - Option to report normalized abundance scores as a percentage within each kingdom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3537:44,Simpl,Simplifies,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537,1,['Simpl'],['Simplifies']
